{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dataconv/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "CITE_MARKER = '#AUTHOR_TAG'\n",
    "SPECIAL_TOKEN = ['#TAUTHOR_TAG']\n",
    "\n",
    "rand_state = 69\n",
    "train_prob = 0.7  # Specify the probability if needed\n",
    "dev_prob = 0.1    # Specify the probability if needed\n",
    "test_prob = 0.2   # Specify the probability if needed\n",
    "model_names =  [\"allenai/scibert_scivocab_uncased\",\"McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp\",\"McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp\"]\n",
    "\n",
    "input_path = '/home/dataconv/deallab/lasse/CCE_Data/raw_data/finecite/'\n",
    "ouput_path = f'/home/dataconv/deallab/lasse/CCE_Data/model_training/data/seq_tagger/fine_cite/'\n",
    "os.makedirs(ouput_path, exist_ok=True)\n",
    "\n",
    "tokenizers = []\n",
    "for model_name in model_names:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': [CITE_MARKER, *SPECIAL_TOKEN]})\n",
    "    tokenizers.append(tokenizer)\n",
    "\n",
    "input_df = pd.read_csv(os.path.join(input_path, 'full_data.csv'))\n",
    "\n",
    "# To Do\n",
    "# CHANGE: for new form of ref markers\n",
    "# includee #AUTHOR_TAG for ever tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper\n",
    "def eval_context(context:str, token_legth:int):\n",
    "    res = eval(context)\n",
    "    if len(res) != token_legth:\n",
    "        print(f'The context was {len(res)-token_legth} labels longer than the tokens')\n",
    "        res=res[:token_legth]\n",
    "    return res\n",
    "\n",
    "def flatten(lists):\n",
    "    return [x for list in lists for x in list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_majority_token_sentence_segment_df(data_df):\n",
    "    res_df = pd.DataFrame(columns=['id', 'segments','labels'])\n",
    "    for i in range(len(data_df)):\n",
    "        #set variables\n",
    "        id = data_df.loc[i, 'id']\n",
    "        target_citation_loc = data_df.loc[i, 'target_reference_location']\n",
    "        token_string = data_df.loc[i, 'paragraph'].replace(' ','').replace('\\'','')\n",
    "        token_list = re.sub(r'<ref[^\\>]+>[^\\<]+<\\/ref>', CITE_MARKER, token_string).split(';')\n",
    "        token_list[target_citation_loc] = '#TAUTHOR_TAG'\n",
    "        contexts = [eval_context(data_df.loc[i, 'context_location1'], len(token_list))]\n",
    "        # if data_df.loc[i, 'context_location2']:\n",
    "        #     contexts.append(eval_context(data_df.loc[i, 'context_location2'], len(token_list)))\n",
    "        \n",
    "        #build token_id to sent_id, sent_id to token_id, token_id to context_label lookup\n",
    "        token_id_to_sent_id = {}\n",
    "        sent_id_to_token_id = {}\n",
    "        token_id = 0\n",
    "        sent_list = nltk.sent_tokenize(' '.join(token_list))\n",
    "        for sent_id, sent in enumerate(sent_list):\n",
    "            sent_id_to_token_id[sent_id] = []\n",
    "            sent_token = sent.split(' ')\n",
    "            for token in sent_token:\n",
    "                token_id_to_sent_id[token_id] = sent_id\n",
    "                sent_id_to_token_id[sent_id].append(token_id)\n",
    "                token_id += 1\n",
    "        # assert whether token_ids span the same length as the token_list\n",
    "        if token_id != len(token_list):\n",
    "            print('There is a mismatch between token id and token list length')\n",
    "            continue\n",
    "        \n",
    "        for idx, context in enumerate(contexts):\n",
    "            context_id = f'{id}_{idx}'\n",
    "            if not any(context): continue\n",
    "            if context[target_citation_loc] == 0:\n",
    "                context[target_citation_loc] = context[target_citation_loc-1] if context[target_citation_loc-1] != 0 else 1\n",
    "                print(f'set target reference market to {context[target_citation_loc]}')\n",
    "            \n",
    "            #select context, context sentences, calculate majority and priority tokens\n",
    "            majority_token = []\n",
    "            \n",
    "            for sent_id in sent_id_to_token_id:\n",
    "                sent_token_ids = sent_id_to_token_id[sent_id]\n",
    "                sent_labels = [context[id] for id in sent_token_ids]\n",
    "                #majority and priority token\n",
    "                if not any(sent_labels):\n",
    "                    majority_token.append(0)\n",
    "                    continue\n",
    "                majority_token.append(next(max_count[0] for max_count in Counter(sent_labels).most_common() if max_count[0] != 0))\n",
    "            \n",
    "            #assert existing majority and priority token for each sentence\n",
    "            assert len(majority_token) == len(sent_list), 'There is a mismatch of the majority token legth and the number of context sentences'  \n",
    "\n",
    "            res_df.loc[len(res_df)] = [context_id, sent_list, majority_token]\n",
    "    return res_df\n",
    "         \n",
    "def return_priority_token_sentence_segment_df(data_df):\n",
    "    res_df = pd.DataFrame(columns=['id', 'segments','labels'])\n",
    "    for i in range(len(data_df)):\n",
    "        #set variables\n",
    "        id = data_df.loc[i, 'id']\n",
    "        target_citation_loc = data_df.loc[i, 'target_reference_location']\n",
    "        token_string = data_df.loc[i, 'paragraph'].replace(' ','').replace('\\'','')\n",
    "        token_list = re.sub(r'<ref[^\\>]+>[^\\<]+<\\/ref>', CITE_MARKER, token_string).split(';')\n",
    "        token_list[target_citation_loc] = '#TAUTHOR_TAG'\n",
    "        contexts = [eval_context(data_df.loc[i, 'context_location1'], len(token_list))]\n",
    "        # if data_df.loc[i, 'context_location2']:\n",
    "        #     contexts.append(eval_context(data_df.loc[i, 'context_location2'], len(token_list)))\n",
    "        \n",
    "        #build token_id to sent_id, sent_id to token_id, token_id to context_label lookup\n",
    "        token_id_to_sent_id = {}\n",
    "        sent_id_to_token_id = {}\n",
    "        token_id = 0\n",
    "        sent_list = nltk.sent_tokenize(' '.join(token_list))\n",
    "        for sent_id, sent in enumerate(sent_list):\n",
    "            sent_id_to_token_id[sent_id] = []\n",
    "            sent_token = sent.split(' ')\n",
    "            for token in sent_token:\n",
    "                token_id_to_sent_id[token_id] = sent_id\n",
    "                sent_id_to_token_id[sent_id].append(token_id)\n",
    "                token_id += 1\n",
    "        # assert whether token_ids span the same length as the token_list\n",
    "        if token_id != len(token_list):\n",
    "            print('There is a mismatch between token id and token list length')\n",
    "            continue        \n",
    "        for idx, context in enumerate(contexts):\n",
    "            context_id = f'{id}_{idx}'\n",
    "            if not any(context): continue\n",
    "            if context[target_citation_loc] == 0:\n",
    "                context[target_citation_loc] = context[target_citation_loc-1] if context[target_citation_loc-1] != 0 else 1\n",
    "                print(f'set target reference market to {context[target_citation_loc]}')\n",
    "            \n",
    "            #select context, context sentences, calculate majority and priority tokens\n",
    "            priority_token = []\n",
    "            \n",
    "            for sent_id in sent_id_to_token_id:\n",
    "                sent_token_ids = sent_id_to_token_id[sent_id]\n",
    "                sent_labels = [context[id] for id in sent_token_ids]\n",
    "                #majority and priority token\n",
    "                if not any(sent_labels):\n",
    "                    priority_token.append(0)\n",
    "                    continue\n",
    "                priority_token.append(min([label for label in sent_labels if label != 0]))\n",
    "                \n",
    "            #assert existing majority and priority token for each sentence\n",
    "            assert len(priority_token) == len(sent_list), 'There is a mismatch of the priority token length and the number of context sentences'  \n",
    "\n",
    "            res_df.loc[len(res_df)] = [context_id, sent_list, priority_token]\n",
    "    return res_df\n",
    "\n",
    "def return_token_segment_df(data_df, tokenizer):\n",
    "    res_df = pd.DataFrame(columns=['id', 'segments','labels'])\n",
    "\n",
    "    for i in range(len(data_df)):\n",
    "        #set variables\n",
    "        id = data_df.loc[i, 'id']\n",
    "        target_citation_loc = data_df.loc[i, 'target_reference_location']\n",
    "        token_string = data_df.loc[i, 'paragraph'].replace(' ','').replace('\\'','')\n",
    "        token_list = re.sub(r'<ref[^\\>]+>[^\\<]+<\\/ref>', CITE_MARKER, token_string).split(';')\n",
    "        token_list[target_citation_loc] = '#TAUTHOR_TAG'\n",
    "        contexts = [eval_context(data_df.loc[i, 'context_location1'], len(token_list))]\n",
    "        # if data_df.loc[i, 'context_location2']:\n",
    "        #     contexts.append(eval_context(data_df.loc[i, 'context_location2'], len(token_list)))\n",
    "        \n",
    "        for idx, context in enumerate(contexts):\n",
    "            context_id = f'{id}_{idx}'\n",
    "            if not any(context): continue\n",
    "            if context[target_citation_loc] == 0:\n",
    "                context[target_citation_loc] = context[target_citation_loc-1] if context[target_citation_loc-1] != 0 else 1\n",
    "                print(f'set target reference market to {context[target_citation_loc]}')\n",
    "            \n",
    "            tokenized_token_list = []\n",
    "            tokenized_token_labels = []\n",
    "            for idx, token in enumerate(token_list):\n",
    "                tokenized_tokens = tokenizer.tokenize(token)\n",
    "                for tokenized_token in tokenized_tokens:\n",
    "                    tokenized_token_list.append(tokenized_token)\n",
    "                    tokenized_token_labels.append(context[idx]) \n",
    "            assert len(tokenized_token_list) == len(tokenized_token_labels), 'The length of the tokenized tokens, and the associated labels do not have the same length'\n",
    "\n",
    "            res_df.loc[len(res_df)] = [context_id, tokenized_token_list, tokenized_token_labels]\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "There is a mismatch between token id and token list length\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "There is a mismatch between token id and token list length\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "There is a mismatch between token id and token list length\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 2\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 3\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n",
      "set target reference market to 1\n"
     ]
    }
   ],
   "source": [
    "data_frames = []\n",
    "segment_class = []\n",
    "scope_weights_by_segment_class={}\n",
    "total_weights_by_segment_class={}\n",
    "\n",
    "\n",
    "# compute majority token sentence segments\n",
    "data_frames.append(return_majority_token_sentence_segment_df(input_df))\n",
    "segment_class.append('sentence_majo')\n",
    "\n",
    "#compute priority token sentence segments\n",
    "data_frames.append(return_priority_token_sentence_segment_df(input_df))\n",
    "segment_class.append('sentence_prio')\n",
    "\n",
    "for i, tokenizer in enumerate(tokenizers):\n",
    "    data_frames.append(return_token_segment_df(input_df, tokenizer))\n",
    "    segment_class.append('token_' + re.search(r'scibert|llama|mistral',model_names[i].lower()).group(0))\n",
    "    \n",
    "for i, res_df in enumerate(data_frames):\n",
    "    folder_path  = os.path.join(ouput_path,f'{segment_class[i]}_{rand_state}__{train_prob}-{dev_prob}-{test_prob}'.replace('.', ''))\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    train_df, test_df = train_test_split(res_df, test_size=0.2, random_state=rand_state)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.125, random_state=rand_state)\n",
    "    train_df.to_csv(os.path.join(folder_path,'train.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join(folder_path,'test.csv'), index=False)\n",
    "    val_df.to_csv(os.path.join(folder_path,'val.csv'), index=False)\n",
    "    total = len(train_df)\n",
    "    counter = Counter(flatten(train_df['labels'].to_list()))\n",
    "    sorted_counter = sorted(counter.items())\n",
    "    counter_sum = sum(counter.values())\n",
    "    ratio_scopes = [counter_sum / (len(counter) * c )for l, c in sorted_counter]\n",
    "    scope_weights_by_segment_class[segment_class[i]] = ratio_scopes\n",
    "    \n",
    "    ratio_total = [counter_sum/ (2 * sum([c for l, c in sorted_counter if l == 0])), counter_sum/ (2 * sum([c for l, c in sorted_counter if l != 0]))]\n",
    "    total_weights_by_segment_class[segment_class[i]] = ratio_total\n",
    "\n",
    "with open(os.path.join('./output/finecite_scopes_weights.json'), 'w') as f_out:\n",
    "    json.dump(scope_weights_by_segment_class, f_out)\n",
    "\n",
    "with open(os.path.join('./output/finecite_total_weights.json'), 'w') as f_out:\n",
    "    json.dump(total_weights_by_segment_class, f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

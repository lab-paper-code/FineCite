token_context,word_context,seg_context,sent_cotext,label
"['tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in#AUTHOR_TAG andStockwell et al. ( 1973 ) .', 'Figure 16 gives the number of ver']","['tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in#AUTHOR_TAG andStockwell et al. ( 1973 ) .', 'Figure 16 gives the number of verbs classified under each']","['tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in#AUTHOR_TAG andStockwell et al. ( 1973 ) .', 'Figure 16 gives the number of ver']","['tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in#AUTHOR_TAG andStockwell et al. ( 1973 ) .', 'Figure 16 gives the number of verbs classified under each category by these authors and the number successfully classified into the same categories by the system']",5
"['', 'As#AUTHOR_TAG points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage, this simple and conventional access strategy is perfectly adequate.', 'The use of such standard database indexing techniques makes it possible for an active dictionary process to be very']","['', 'As#AUTHOR_TAG points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage, this simple and conventional access strategy is perfectly adequate.', 'The use of such standard database indexing techniques makes it possible for an active dictionary process to be very undemanding with respect to main memory utilisation.', '']","['', 'As#AUTHOR_TAG points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage, this simple and conventional access strategy is perfectly adequate.', 'The use of such standard database indexing techniques makes it possible for an active dictionary process to be very']","['', 'As#AUTHOR_TAG points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage, this simple and conventional access strategy is perfectly adequate.', 'The use of such standard database indexing techniques makes it possible for an active dictionary process to be very undemanding with respect to main memory utilisation.', '']",0
"['research described below is taking place in the context of three collaborative projects( #AUTHOR_TAG ; Russell et al. , 1986 ; Phillips and Thompson , 1986 ) to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['research described below is taking place in the context of three collaborative projects( #AUTHOR_TAG ; Russell et al. , 1986 ; Phillips and Thompson , 1986 ) to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['', 'The research described below is taking place in the context of three collaborative projects( #AUTHOR_TAG ; Russell et al. , 1986 ; Phillips and Thompson , 1986 ) to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['', 'The research described below is taking place in the context of three collaborative projects( #AUTHOR_TAG ; Russell et al. , 1986 ; Phillips and Thompson , 1986 ) to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']",0
"['isting text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g.#AUTHOR_TAG ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And']","['isting text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g.#AUTHOR_TAG ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And']","['isting text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g.#AUTHOR_TAG ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And']","['isting text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g.#AUTHOR_TAG ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '']",4
"['previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer( #AUTHOR_TAG ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', '']","['previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer( #AUTHOR_TAG ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', '']","['previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer( #AUTHOR_TAG ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', '']","['previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer( #AUTHOR_TAG ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', '']",0
"['1983 ;#AUTHOR_TAG ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '']","['investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; Luce et al. 1983 ;#AUTHOR_TAG ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '']","['g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; Luce et al. 1983 ;#AUTHOR_TAG ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '']","['isting text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; Luce et al. 1983 ;#AUTHOR_TAG ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '']",4
"['have built an experimental text-to-speech system that uses our analysis of prosody to generate phrase boundaries for the Olive -- Liberman synthesizer( #AUTHOR_TAG ) .', '']","['have built an experimental text-to-speech system that uses our analysis of prosody to generate phrase boundaries for the Olive -- Liberman synthesizer( #AUTHOR_TAG ) .', '']","['have built an experimental text-to-speech system that uses our analysis of prosody to generate phrase boundaries for the Olive -- Liberman synthesizer( #AUTHOR_TAG ) .', '']","['have built an experimental text-to-speech system that uses our analysis of prosody to generate phrase boundaries for the Olive -- Liberman synthesizer( #AUTHOR_TAG ) .', '']",5
"['see Section 2.1.3.).', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', '#AUTHOR_TAG andLitman and Hirschberg ( 1990 ) also examine the relation between discourse and prosodic phrasing .', 'Their work succeeds in distinguishing the use of items like now, so, and well as discourse cues from their denotative lexical use on the basis of a complex combination of pitch accent type and phrasing']","['(see Section 2.1.3.).', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', '#AUTHOR_TAG andLitman and Hirschberg ( 1990 ) also examine the relation between discourse and prosodic phrasing .', 'Their work succeeds in distinguishing the use of items like now, so, and well as discourse cues from their denotative lexical use on the basis of a complex combination of pitch accent type and phrasing']","['see Section 2.1.3.).', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', '#AUTHOR_TAG andLitman and Hirschberg ( 1990 ) also examine the relation between discourse and prosodic phrasing .', 'Their work succeeds in distinguishing the use of items like now, so, and well as discourse cues from their denotative lexical use on the basis of a complex combination of pitch accent type and phrasing']","['', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', '#AUTHOR_TAG andLitman and Hirschberg ( 1990 ) also examine the relation between discourse and prosodic phrasing .', 'Their work succeeds in distinguishing the use of items like now, so, and well as discourse cues from their denotative lexical use on the basis of a complex combination of pitch accent type and phrasing']",0
"['', 'For example, in considering the connection between syntax and phrasing, the linguistic literature most often refers to examples of embedded sentences.', 'Sentences like 12 , from#AUTHOR_TAG , are frequently cited .', '(Square brackets mark off the NP constituents that contain embed- ded sentences']","['', 'For example, in considering the connection between syntax and phrasing, the linguistic literature most often refers to examples of embedded sentences.', 'Sentences like 12 , from#AUTHOR_TAG , are frequently cited .', '(Square brackets mark off the NP constituents that contain embed- ded sentences']","['', 'For example, in considering the connection between syntax and phrasing, the linguistic literature most often refers to examples of embedded sentences.', 'Sentences like 12 , from#AUTHOR_TAG , are frequently cited .', '(Square brackets mark off the NP constituents that contain embed- ded sentences']","['', ""However, this claim is controversial because of the misa'dgnments that occur between the two levels of phrasing."", 'For example, in considering the connection between syntax and phrasing, the linguistic literature most often refers to examples of embedded sentences.', 'Sentences like 12 , from#AUTHOR_TAG , are frequently cited .', '(Square brackets mark off the NP constituents that contain embed- ded sentences']",0
"['previous work( #AUTHOR_TAG ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', 'This']","['previous work( #AUTHOR_TAG ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', 'This']","['previous work( #AUTHOR_TAG ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', 'This paper re']","['previous work( #AUTHOR_TAG ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', '']",2
"['', '#AUTHOR_TAG proposes readjustment rules similar to those of Chomsky and Halle , but he claims that the readjustment of structure is part of the grammar , not part of the performance model .', 'He']","['rules outside the grammar proper.', '#AUTHOR_TAG proposes readjustment rules similar to those of Chomsky and Halle , but he claims that the readjustment of structure is part of the grammar , not part of the performance model .', 'He']","['special rules outside the grammar proper.', '#AUTHOR_TAG proposes readjustment rules similar to those of Chomsky and Halle , but he claims that the readjustment of structure is part of the grammar , not part of the performance model .', 'He']","['', 'Thus phrasing, in their approach, is only indirectly related to syntax, since readjustment is done by special rules outside the grammar proper.', '#AUTHOR_TAG proposes readjustment rules similar to those of Chomsky and Halle , but he claims that the readjustment of structure is part of the grammar , not part of the performance model .', 'He thus makes explicit what is often a tacit assumption in both the linguistic and psycholinguistic literature2--that there is a direct connection between syntactic constituency and prosodic phrasing, with apparent misalignments readjusted before syntax interface,; with prosodic phonology']",0
"['psycholinguistic studies ofMartin ( 1970 ) ,Allen ( 1975 ) ,Hillinger et al. ( 1976 ) ,Grosjean et al. ( 1979 ) ,Dommergues and Grosjean ( 1983 ) , and#AUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '']","['psycholinguistic studies ofMartin ( 1970 ) ,Allen ( 1975 ) ,Hillinger et al. ( 1976 ) ,Grosjean et al. ( 1979 ) ,Dommergues and Grosjean ( 1983 ) , and#AUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '']","['psycholinguistic studies ofMartin ( 1970 ) ,Allen ( 1975 ) ,Hillinger et al. ( 1976 ) ,Grosjean et al. ( 1979 ) ,Dommergues and Grosjean ( 1983 ) , and#AUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '']","['psycholinguistic studies ofMartin ( 1970 ) ,Allen ( 1975 ) ,Hillinger et al. ( 1976 ) ,Grosjean et al. ( 1979 ) ,Dommergues and Grosjean ( 1983 ) , and#AUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '']",0
"['asing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in#AUTHOR_TAG , which ""are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when there is no good reason to take some other option"" (p. 251) .', 'This approach to prosodic phrase boundary determination brings us']","['', '3 Such phrasing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in#AUTHOR_TAG , which ""are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when there is no good reason to take some other option"" (p. 251) .', 'This approach to prosodic phrase boundary determination brings us']","['3 Such phrasing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in#AUTHOR_TAG , which ""are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when there is no good reason to take some other option"" (p. 251) .', 'This approach to prosodic phrase boundary determination brings us']","['', '3 Such phrasing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in#AUTHOR_TAG , which ""are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when there is no good reason to take some other option"" (p. 251) .', 'This approach to prosodic phrase boundary determination brings us closer to a framework in which phonological, syntactic, and discourse features all contribute to prosodic phrasing']",1
"['for such mismatches, ""readjustment rules"" that change constituent structure by adjoining each embedded sente, nce to the node dominating it have been posited.', 'The result is a flattened structure that more accurately reflects the prosodic phrasing.', 'In#AUTHOR_TAG , this flattening process is not part of the grammar .', '']","['for such mismatches, ""readjustment rules"" that change constituent structure by adjoining each embedded sente, nce to the node dominating it have been posited.', 'The result is a flattened structure that more accurately reflects the prosodic phrasing.', 'In#AUTHOR_TAG , this flattening process is not part of the grammar .', '']","['for such mismatches, ""readjustment rules"" that change constituent structure by adjoining each embedded sente, nce to the node dominating it have been posited.', 'The result is a flattened structure that more accurately reflects the prosodic phrasing.', 'In#AUTHOR_TAG , this flattening process is not part of the grammar .', '']","['', 'Sentences like 12, fromChomsky (1965) To account for such mismatches, ""readjustment rules"" that change constituent structure by adjoining each embedded sente, nce to the node dominating it have been posited.', 'The result is a flattened structure that more accurately reflects the prosodic phrasing.', 'In#AUTHOR_TAG , this flattening process is not part of the grammar .', 'Rather, it is viewed as ""... a performance factor, related to the difficulty of producing right branching structures such as [ 12]"" (p.', '372).', '']",0
"[', we require that the prosody rules build a binary tree whose terminals are phonological words and whose node labels are indices that mark boundary salience.', 'An alternative representation based on#AUTHOR_TAG is presented inSelkirk ( 1984 ) , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .', '']","['G&G, we require that the prosody rules build a binary tree whose terminals are phonological words and whose node labels are indices that mark boundary salience.', 'An alternative representation based on#AUTHOR_TAG is presented inSelkirk ( 1984 ) , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .', '']","['G&G, we require that the prosody rules build a binary tree whose terminals are phonological words and whose node labels are indices that mark boundary salience.', 'An alternative representation based on#AUTHOR_TAG is presented inSelkirk ( 1984 ) , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .', '']","['G&G, we require that the prosody rules build a binary tree whose terminals are phonological words and whose node labels are indices that mark boundary salience.', 'An alternative representation based on#AUTHOR_TAG is presented inSelkirk ( 1984 ) , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .', '']",1
"['syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', '#AUTHOR_TAG claims that prosodic phrase boundaries will co-occur with grammatical functions such as subject , predicate , modifier , and adjunct .', '']","['syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', '#AUTHOR_TAG claims that prosodic phrase boundaries will co-occur with grammatical functions such as subject , predicate , modifier , and adjunct .', '']","['syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', '#AUTHOR_TAG claims that prosodic phrase boundaries will co-occur with grammatical functions such as subject , predicate , modifier , and adjunct .', '']","['syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', '#AUTHOR_TAG claims that prosodic phrase boundaries will co-occur with grammatical functions such as subject , predicate , modifier , and adjunct .', '']",0
"['psycholinguistic studies ofMartin ( 1970 ) ,#AUTHOR_TAG ,Hillinger et al. ( 1976 ) ,Grosjean et al. ( 1979 ) ,Dommergues and Grosjean ( 1983 ) , andGee and Grosjean ( 1983 ) , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '']","['psycholinguistic studies ofMartin ( 1970 ) ,#AUTHOR_TAG ,Hillinger et al. ( 1976 ) ,Grosjean et al. ( 1979 ) ,Dommergues and Grosjean ( 1983 ) , andGee and Grosjean ( 1983 ) , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '']","['psycholinguistic studies ofMartin ( 1970 ) ,#AUTHOR_TAG ,Hillinger et al. ( 1976 ) ,Grosjean et al. ( 1979 ) ,Dommergues and Grosjean ( 1983 ) , andGee and Grosjean ( 1983 ) , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '']","['psycholinguistic studies ofMartin ( 1970 ) ,#AUTHOR_TAG ,Hillinger et al. ( 1976 ) ,Grosjean et al. ( 1979 ) ,Dommergues and Grosjean ( 1983 ) , andGee and Grosjean ( 1983 ) , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '']",0
"['', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ;#AUTHOR_TAG ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And']","['', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ;#AUTHOR_TAG ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And']","['', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ;#AUTHOR_TAG ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And']","['isting text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ;#AUTHOR_TAG ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '']",4
"['', 'Although a grid may be more descriptively suitable for some aspects of prosody ( for example ,#AUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nominals ) , we are not aware of any evidence for or against a grid representation of discourseneutral phrasing']","['', 'Although a grid may be more descriptively suitable for some aspects of prosody ( for example ,#AUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nominals ) , we are not aware of any evidence for or against a grid representation of discourseneutral phrasing']","['', 'Although a grid may be more descriptively suitable for some aspects of prosody ( for example ,#AUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nominals ) , we are not aware of any evidence for or against a grid representation of discourseneutral phrasing']","['', 'Although a grid may be more descriptively suitable for some aspects of prosody ( for example ,#AUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nominals ) , we are not aware of any evidence for or against a grid representation of discourseneutral phrasing']",1
"['', 'Previous versions of our work , as described in#AUTHOR_TAG also assume that phrasing is dependent on predicate-argument structure .', 'The problem here is that the phrasing in observed data often ignores the argument status of constituents.', '']","['', 'Previous versions of our work , as described in#AUTHOR_TAG also assume that phrasing is dependent on predicate-argument structure .', 'The problem here is that the phrasing in observed data often ignores the argument status of constituents.', '']","['', 'Previous versions of our work , as described in#AUTHOR_TAG also assume that phrasing is dependent on predicate-argument structure .', 'The problem here is that the phrasing in observed data often ignores the argument status of constituents.', '']","['', 'Previous versions of our work , as described in#AUTHOR_TAG also assume that phrasing is dependent on predicate-argument structure .', 'The problem here is that the phrasing in observed data often ignores the argument status of constituents.', '']",2
"['', 'This observation has led some researchers , e.g. ,#AUTHOR_TAG , to claim a direct mapping between the syntactic phrase and the prosodic phrase .', '']","['', 'This observation has led some researchers , e.g. ,#AUTHOR_TAG , to claim a direct mapping between the syntactic phrase and the prosodic phrase .', '']","['', 'This observation has led some researchers , e.g. ,#AUTHOR_TAG , to claim a direct mapping between the syntactic phrase and the prosodic phrase .', '']","['', 'This observation has led some researchers , e.g. ,#AUTHOR_TAG , to claim a direct mapping between the syntactic phrase and the prosodic phrase .', ""However, this claim is controversial because of the misa'dgnments that occur between the two levels of phrasing."", '']",0
['4 The most explicit version of this approach is the analysis presented in#AUTHOR_TAG ( henceforth G&G )'],['.4 The most explicit version of this approach is the analysis presented in#AUTHOR_TAG ( henceforth G&G )'],['4 The most explicit version of this approach is the analysis presented in#AUTHOR_TAG ( henceforth G&G )'],['#AUTHOR_TAG'],1
"['', 'The relation between discourse and prosodic phrasing has been examined in some detail by#AUTHOR_TAG , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse .', 'Bing also observes that constituents that refer to items newly introduced into a discourse tend to be longer.', 'This may be the reason that word count and syllable count play a prominent role in prosodic phrasing (see Section 2.1.3']","['', 'The relation between discourse and prosodic phrasing has been examined in some detail by#AUTHOR_TAG , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse .', 'Bing also observes that constituents that refer to items newly introduced into a discourse tend to be longer.', 'This may be the reason that word count and syllable count play a prominent role in prosodic phrasing (see Section 2.1.3.).', 'To our']","['', 'The relation between discourse and prosodic phrasing has been examined in some detail by#AUTHOR_TAG , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse .', 'Bing also observes that constituents that refer to items newly introduced into a discourse tend to be longer.', 'This may be the reason that word count and syllable count play a prominent role in prosodic phrasing (see Section 2.1.3.).', 'To our']","['', 'The relation between discourse and prosodic phrasing has been examined in some detail by#AUTHOR_TAG , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse .', 'Bing also observes that constituents that refer to items newly introduced into a discourse tend to be longer.', 'This may be the reason that word count and syllable count play a prominent role in prosodic phrasing (see Section 2.1.3.).', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', '']",0
"['rules for phonological word formation are adopted , for the most part , from G & G ,#AUTHOR_TAG , and the account of monosyllabic destressing inSelkirk ( 1984 ) .', 'Thus in our analysis, rules of phonological word formation apply to the non-null terminal nodes in a syntax tree.', 'If the']","['rules for phonological word formation are adopted , for the most part , from G & G ,#AUTHOR_TAG , and the account of monosyllabic destressing inSelkirk ( 1984 ) .', 'Thus in our analysis, rules of phonological word formation apply to the non-null terminal nodes in a syntax tree.', 'If the']","['rules for phonological word formation are adopted , for the most part , from G & G ,#AUTHOR_TAG , and the account of monosyllabic destressing inSelkirk ( 1984 ) .', 'Thus in our analysis, rules of phonological word formation apply to the non-null terminal nodes in a syntax tree.', 'If the terminal is']","['rules for phonological word formation are adopted , for the most part , from G & G ,#AUTHOR_TAG , and the account of monosyllabic destressing inSelkirk ( 1984 ) .', 'Thus in our analysis, rules of phonological word formation apply to the non-null terminal nodes in a syntax tree.', '']",5
"['the cooperative principle of#AUTHOR_TAG , 1978 ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ;']","['the cooperative principle of#AUTHOR_TAG , 1978 ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ;']","['the cooperative principle of#AUTHOR_TAG , 1978 ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ;']","['', 'Secondly , the cooperative principle of#AUTHOR_TAG , 1978 ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ; and this seems to imply that he should appeal only to the most direct knowledge of the reader .', '']",4
"['this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.', 'We are going to make such a comparison with the theories proposed by J.#AUTHOR_TAG , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W.Kintch ( 1983 ) , who are more interested in addressing psychological and cognitive aspects of discourse coherence .', 'The quoted works seem to be good representatives for each of the directions; they also point to related']","['this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.', 'We are going to make such a comparison with the theories proposed by J.#AUTHOR_TAG , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W.Kintch ( 1983 ) , who are more interested in addressing psychological and cognitive aspects of discourse coherence .', 'The quoted works seem to be good representatives for each of the directions; they also point to related literature']","['this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.', 'We are going to make such a comparison with the theories proposed by J.#AUTHOR_TAG , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W.Kintch ( 1983 ) , who are more interested in addressing psychological and cognitive aspects of discourse coherence .', 'The quoted works seem to be good representatives for each of the directions; they also point to related']","['this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.', 'We are going to make such a comparison with the theories proposed by J.#AUTHOR_TAG , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W.Kintch ( 1983 ) , who are more interested in addressing psychological and cognitive aspects of discourse coherence .', 'The quoted works seem to be good representatives for each of the directions; they also point to related literature']",1
"['techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure as- sumption"" (ibid.), ""domain circumscription"" (cf.#AUTHOR_TAG) , and their kin.', 'Similarly']","['techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure as- sumption"" (ibid.), ""domain circumscription"" (cf.#AUTHOR_TAG) , and their kin.', 'Similarly, the notion of R+ M-abduction is']","['techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure as- sumption"" (ibid.), ""domain circumscription"" (cf.#AUTHOR_TAG) , and their kin.', 'Similarly']","['techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure as- sumption"" (ibid.), ""domain circumscription"" (cf.#AUTHOR_TAG) , and their kin.', '']",1
['.#AUTHOR_TAG discussed sentences of the form * This is a chair but you can sit on it'],['.#AUTHOR_TAG discussed sentences of the form * This is a chair but you can sit on it'],['.#AUTHOR_TAG discussed sentences of the form * This is a chair but you can sit on it'],['.#AUTHOR_TAG discussed sentences of the form * This is a chair but you can sit on it'],0
"['', 'Opposition (called ""adversative"" or ""contrary-to-expectation"" by Halliday and Hasan 1976;cf. also#AUTHOR_TAG , p. 672 )']","['', 'Opposition (called ""adversative"" or ""contrary-to-expectation"" by Halliday and Hasan 1976;cf. also#AUTHOR_TAG , p. 672 )']","['have three subfunctions: . .', 'Opposition (called ""adversative"" or ""contrary-to-expectation"" by Halliday and Hasan 1976;cf. also#AUTHOR_TAG , p. 672 )']","['', 'Opposition (called ""adversative"" or ""contrary-to-expectation"" by Halliday and Hasan 1976;cf. also#AUTHOR_TAG , p. 672 )']",0
"['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 ,#AUTHOR_TAG , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 ,#AUTHOR_TAG , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 ,#AUTHOR_TAG , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 ,#AUTHOR_TAG , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']",1
"[""words ( e.g. , `` colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ;#AUTHOR_TAG , p. 546 ) gives 10 definitions of a sentence""]","[""words ( e.g. , `` colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ;#AUTHOR_TAG , p. 546 ) gives 10 definitions of a sentence""]","[""words ( e.g. , `` colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ;#AUTHOR_TAG , p. 546 ) gives 10 definitions of a sentence""]","['', ""This problem may be similar to the situation in which current formal grammars allow nonsensical but parsable collections of words ( e.g. , `` colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ;#AUTHOR_TAG , p. 546 ) gives 10 definitions of a sentence""]",0
"['', 'This Principle of Finitism is also assumed by#AUTHOR_TAG ,Jackendoff ( 1983 ) ,Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['the logic.', 'This Principle of Finitism is also assumed by#AUTHOR_TAG ,Jackendoff ( 1983 ) ,Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['describing the logic.', 'This Principle of Finitism is also assumed by#AUTHOR_TAG ,Jackendoff ( 1983 ) ,Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['', 'This Principle of Finitism is also assumed by#AUTHOR_TAG ,Jackendoff ( 1983 ) ,Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .', '']",1
"['', ""But , obviously , there are other possibilities -- for instance , the discourse representation structures ( DRS 's ) of#AUTHOR_TAG , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora ."", '']","['', ""But , obviously , there are other possibilities -- for instance , the discourse representation structures ( DRS 's ) of#AUTHOR_TAG , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora ."", '']","['', ""But , obviously , there are other possibilities -- for instance , the discourse representation structures ( DRS 's ) of#AUTHOR_TAG , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora ."", '']","['', ""But , obviously , there are other possibilities -- for instance , the discourse representation structures ( DRS 's ) of#AUTHOR_TAG , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora ."", '']",1
"['is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping( #AUTHOR_TAG ) must play a role , too .', '']","['of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping( #AUTHOR_TAG ) must play a role , too .', '']","['is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping( #AUTHOR_TAG ) must play a role , too .', '']","['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping( #AUTHOR_TAG ) must play a role , too .', 'Determining the relative importance of those factors, the above metarules, and syntactic clues, appears to be an interesting topic in itself']",0
"['to#AUTHOR_TAG , p. 67 ) , these two sentences are incoherent .', 'However, the same fragment, augmented with the third sentence Mary told him yesterday that the French spinach crop failed and Turkey is the only country... (ibid.)', 'suddenly (for Hobbs) becomes coherent.', 'It']","['to#AUTHOR_TAG , p. 67 ) , these two sentences are incoherent .', 'However, the same fragment, augmented with the third sentence Mary told him yesterday that the French spinach crop failed and Turkey is the only country... (ibid.)', 'suddenly (for Hobbs) becomes coherent.', 'It']","['to#AUTHOR_TAG , p. 67 ) , these two sentences are incoherent .', 'However, the same fragment, augmented with the third sentence Mary told him yesterday that the French spinach crop failed and Turkey is the only country... (ibid.)', 'suddenly (for Hobbs) becomes coherent.', 'It seems that any analysis of coherence in terms of the relation between subsequent sentences cannot explain this sudden change; after all, the first two sentences didn']","['to#AUTHOR_TAG , p. 67 ) , these two sentences are incoherent .', 'However, the same fragment, augmented with the third sentence Mary told him yesterday that the French spinach crop failed and Turkey is the only country... (ibid.)', 'suddenly (for Hobbs) becomes coherent.', ""It seems that any analysis of coherence in terms of the relation between subsequent sentences cannot explain this sudden change; after all, the first two sentences didn't change when the third one was added."", '']",1
"['choosing most plausible interpretations of predicates.', 'For instance , relating ""they"" to ""apples"" in the sentence ( cfXXX#AUTHOR_TAG p. 195 ; Zadrozny 1987a ) : We bought the boys apples because they were so']","['choosing most plausible interpretations of predicates.', 'For instance , relating ""they"" to ""apples"" in the sentence ( cfXXX#AUTHOR_TAG p. 195 ; Zadrozny 1987a ) : We bought the boys apples because they were so']","['choosing most plausible interpretations of predicates.', 'For instance , relating ""they"" to ""apples"" in the sentence ( cfXXX#AUTHOR_TAG p. 195 ; Zadrozny 1987a ) : We bought the boys apples because they were so']","['', 'It should not come as a surprise that we can now use this apparatus for text/discourse analysis; after all, many natural language inferences are based on defaults, and quite often they can be reduced to choosing most plausible interpretations of predicates.', 'For instance , relating ""they"" to ""apples"" in the sentence ( cfXXX#AUTHOR_TAG p. 195 ; Zadrozny 1987a ) : We bought the boys apples because they were so']",0
"['spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found inBlack and Bower ( 1979 ) and#AUTHOR_TAG']","['spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found inBlack and Bower ( 1979 ) and#AUTHOR_TAG']","['spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found inBlack and Bower ( 1979 ) and#AUTHOR_TAG']","['', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found inBlack and Bower ( 1979 ) and#AUTHOR_TAG']",0
"['furthermore , our reading of the analysis of five paragraphs by#AUTHOR_TAG strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .', '']","['furthermore , our reading of the analysis of five paragraphs by#AUTHOR_TAG strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .', '']","['furthermore , our reading of the analysis of five paragraphs by#AUTHOR_TAG strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .', '']","['', 'Finally , it has been shown byGroesser ( 1981 ) that the ratio of derived to explicit information necessary for understanding a piece of text is about 8:1 ; furthermore , our reading of the analysis of five paragraphs by#AUTHOR_TAG strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .', '']",4
"['last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX#AUTHOR_TAG ) .', 'Brachman et al. 1985']","['last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX#AUTHOR_TAG ) .', 'Brachman et al. 1985).', ""KRYPTON's A-box, encoding the object theory as a set of assertions,""]","['last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX#AUTHOR_TAG ) .', 'Brachman et al. 1985']","['last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX#AUTHOR_TAG ) .', 'Brachman et al. 1985).', '']",1
"['.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of#AUTHOR_TAG , the `` diagnosis from first principles '' ofReiter ( 1987 ) , `` explainability '' ofPoole ( 1988 ) , and the subset principle ofBerwick ( 1986 )""]","['kin.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of#AUTHOR_TAG , the `` diagnosis from first principles '' ofReiter ( 1987 ) , `` explainability '' ofPoole ( 1988 ) , and the subset principle ofBerwick ( 1986 )""]","['.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of#AUTHOR_TAG , the `` diagnosis from first principles '' ofReiter ( 1987 ) , `` explainability '' ofPoole ( 1988 ) , and the subset principle ofBerwick ( 1986 ) ."", '']","['techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure assumption"" (ibid.),', '""domain circumscription"" (cf.', 'Etherington and Mercer 1987), and their kin.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of#AUTHOR_TAG , the `` diagnosis from first principles '' ofReiter ( 1987 ) , `` explainability '' ofPoole ( 1988 ) , and the subset principle ofBerwick ( 1986 ) ."", '']",1
"['', 'The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ;#AUTHOR_TAG ) to see what a formal interpretation of events in time might look like .', '']","['', 'The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ;#AUTHOR_TAG ) to see what a formal interpretation of events in time might look like .', '']","['', 'The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ;#AUTHOR_TAG ) to see what a formal interpretation of events in time might look like .', '']","['', 'The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ;#AUTHOR_TAG ) to see what a formal interpretation of events in time might look like .', '']",0
"['', 'According to#AUTHOR_TAG , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .', 'Paragraphs therefore give hierarchical structure to sentences.']","['', 'According to#AUTHOR_TAG , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .', 'Paragraphs therefore give hierarchical structure to sentences. Hinds discusses three major types of paragraphs, and their']","['', 'According to#AUTHOR_TAG , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .', 'Paragraphs therefore give hierarchical structure to sentences.']","['', 'According to#AUTHOR_TAG , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .', 'Paragraphs therefore give hierarchical structure to sentences. Hinds discusses three major types of paragraphs, and their corresponding segment types.', 'The three types are procedural (how-to), ex- pository (essay), and narrative (in this case, spontaneous conversation).', 'For each type, its segments are distinguished by bearing distinct relationships to the paragraph topic (which is central, but nowhere clearly defined).', '']",0
"['.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' ofReggia ( 1985 ) , the `` diagnosis from first principles '' of#AUTHOR_TAG , `` explainability '' ofPoole ( 1988 ) , and the subset principle ofBerwick ( 1986 ) ."", '']","['kin.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' ofReggia ( 1985 ) , the `` diagnosis from first principles '' of#AUTHOR_TAG , `` explainability '' ofPoole ( 1988 ) , and the subset principle ofBerwick ( 1986 ) ."", '']","['.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' ofReggia ( 1985 ) , the `` diagnosis from first principles '' of#AUTHOR_TAG , `` explainability '' ofPoole ( 1988 ) , and the subset principle ofBerwick ( 1986 ) ."", '']","['', '""domain circumscription"" (cf.', 'Etherington and Mercer 1987), and their kin.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' ofReggia ( 1985 ) , the `` diagnosis from first principles '' of#AUTHOR_TAG , `` explainability '' ofPoole ( 1988 ) , and the subset principle ofBerwick ( 1986 ) ."", '']",1
"['in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ;#AUTHOR_TAG ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', '']","['in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ;#AUTHOR_TAG ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', '']","['in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ;#AUTHOR_TAG ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', '']","['in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ;#AUTHOR_TAG ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', ""But we won't pursue this topic further here""]",1
"['explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=) of L is going to be used only in Section 5 for dealing with noun phrase references.', ""This means that natural language expressions such as `` A is B , '' `` A is the same as B , '' etc. are not directly represented by logical equality ; similarly , `` not '' is often not treated as logical negation ; cfXXX#AUTHOR_TAG ."", 'Hintikka (1985)']","['explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=) of L is going to be used only in Section 5 for dealing with noun phrase references.', ""This means that natural language expressions such as `` A is B , '' `` A is the same as B , '' etc. are not directly represented by logical equality ; similarly , `` not '' is often not treated as logical negation ; cfXXX#AUTHOR_TAG ."", 'Hintikka (1985)']","['explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=) of L is going to be used only in Section 5 for dealing with noun phrase references.', ""This means that natural language expressions such as `` A is B , '' `` A is the same as B , '' etc. are not directly represented by logical equality ; similarly , `` not '' is often not treated as logical negation ; cfXXX#AUTHOR_TAG ."", 'Hintikka (1985)']","['explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=) of L is going to be used only in Section 5 for dealing with noun phrase references.', ""This means that natural language expressions such as `` A is B , '' `` A is the same as B , '' etc. are not directly represented by logical equality ; similarly , `` not '' is often not treated as logical negation ; cfXXX#AUTHOR_TAG ."", 'Hintikka (1985)']",1
"[': The notions of strong provability and strong R + M-abduction can be in- troduced by replacing ""there exists"" by ""all"" in the above definitions (cf.#AUTHOR_TAG b ).', 'We will have, however, no need for ""strong"" notions in this paper']","[': The notions of strong provability and strong R + M-abduction can be in- troduced by replacing ""there exists"" by ""all"" in the above definitions (cf.#AUTHOR_TAG b ).', 'We will have, however, no need for ""strong"" notions in this paper.', '']","[': The notions of strong provability and strong R + M-abduction can be in- troduced by replacing ""there exists"" by ""all"" in the above definitions (cf.#AUTHOR_TAG b ).', 'We will have, however, no need for ""strong"" notions in this paper.', '']","[': The notions of strong provability and strong R + M-abduction can be in- troduced by replacing ""there exists"" by ""all"" in the above definitions (cf.#AUTHOR_TAG b ).', 'We will have, however, no need for ""strong"" notions in this paper.', '']",1
"['ing selectional restrictions ( semantic feature information ,#AUTHOR_TAG ) does not solve the problem , because isolated features offer only part of the background knowledge necessary for reference disambiguation .', '']","['ing selectional restrictions ( semantic feature information ,#AUTHOR_TAG ) does not solve the problem , because isolated features offer only part of the background knowledge necessary for reference disambiguation .', '']","['ing selectional restrictions ( semantic feature information ,#AUTHOR_TAG ) does not solve the problem , because isolated features offer only part of the background knowledge necessary for reference disambiguation .', '']","['ing selectional restrictions ( semantic feature information ,#AUTHOR_TAG ) does not solve the problem , because isolated features offer only part of the background knowledge necessary for reference disambiguation .', '']",0
"['', 'The reader may consult recent papers on this subject ( e.g.#AUTHOR_TAG ; Webber 1987 ) to see what a formal interpretation of events in time might look like .', '']","['', 'The reader may consult recent papers on this subject ( e.g.#AUTHOR_TAG ; Webber 1987 ) to see what a formal interpretation of events in time might look like .', '']","['', 'The reader may consult recent papers on this subject ( e.g.#AUTHOR_TAG ; Webber 1987 ) to see what a formal interpretation of events in time might look like .', '']","['', 'The reader may consult recent papers on this subject ( e.g.#AUTHOR_TAG ; Webber 1987 ) to see what a formal interpretation of events in time might look like .', '']",0
"['hest"" path, fint is the most plausible (relative to R) interpretation of the words that appear in the sentence.', 'Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX#AUTHOR_TAG a , 1987b ) .', 'Zadrozny 1987aZadrozny , 1987 b.', '']","['it is the ""highest"" path, fint is the most plausible (relative to R) interpretation of the words that appear in the sentence.', 'Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX#AUTHOR_TAG a , 1987b ) .', 'Zadrozny 1987aZadrozny , 1987 b.', '']","['it is the ""highest"" path, fint is the most plausible (relative to R) interpretation of the words that appear in the sentence.', 'Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX#AUTHOR_TAG a , 1987b ) .', 'Zadrozny 1987aZadrozny , 1987 b.', '']","['it is the ""highest"" path, fint is the most plausible (relative to R) interpretation of the words that appear in the sentence.', 'Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX#AUTHOR_TAG a , 1987b ) .', 'Zadrozny 1987aZadrozny , 1987 b.', '']",0
"['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 ,#AUTHOR_TAG , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 ,#AUTHOR_TAG , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 ,#AUTHOR_TAG , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 ,#AUTHOR_TAG , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']",1
"['it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX#AUTHOR_TAG ) .', 'Mycielski 1981']","['it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX#AUTHOR_TAG ) .', 'Mycielski 1981']","['it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX#AUTHOR_TAG ) .', 'Mycielski 1981']","['', 'As a logical postulate it is not very radical ; it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX#AUTHOR_TAG ) .', 'Mycielski 1981']",0
"['have shown elsewhere( #AUTHOR_TAG ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory']","['have shown elsewhere( #AUTHOR_TAG ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory']","['have shown elsewhere( #AUTHOR_TAG ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory']","['have shown elsewhere( #AUTHOR_TAG ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory']",2
"['necessity of this kind of merging of arguments has been recognized before :#AUTHOR_TAG call it abductive unification/matching ,Hobbs ( 1978  , 1979 ) refers to such operations using the terms knitting or petty conversational implicature']","['necessity of this kind of merging of arguments has been recognized before :#AUTHOR_TAG call it abductive unification/matching ,Hobbs ( 1978  , 1979 ) refers to such operations using the terms knitting or petty conversational implicature']","['necessity of this kind of merging of arguments has been recognized before :#AUTHOR_TAG call it abductive unification/matching ,Hobbs ( 1978  , 1979 ) refers to such operations using the terms knitting or petty conversational implicature']","['necessity of this kind of merging of arguments has been recognized before :#AUTHOR_TAG call it abductive unification/matching ,Hobbs ( 1978  , 1979 ) refers to such operations using the terms knitting or petty conversational implicature']",0
"['', 'The logical notation of#AUTHOR_TAG is more sophisticated , and may be considered another possibility .', '']","['', 'The logical notation of#AUTHOR_TAG is more sophisticated , and may be considered another possibility .', '']","['', 'The logical notation of#AUTHOR_TAG is more sophisticated , and may be considered another possibility .', '']","['', 'The logical notation of#AUTHOR_TAG is more sophisticated , and may be considered another possibility .', '']",1
"['', 'This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) ,#AUTHOR_TAG ,Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['', 'This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) ,#AUTHOR_TAG ,Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['', 'This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) ,#AUTHOR_TAG ,Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['', 'This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) ,#AUTHOR_TAG ,Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .', '']",1
"['`` the linguistic-logical notions of consequent and presupposition#AUTHOR_TAG :112 ) have collected convincing evidence of the existence of language chunks -- real structures , not just orthographic conventions -- that are smaller than a discourse , larger']","['`` the linguistic-logical notions of consequent and presupposition#AUTHOR_TAG :112 ) have collected convincing evidence of the existence of language chunks -- real structures , not just orthographic conventions -- that are smaller than a discourse , larger']","['`` the linguistic-logical notions of consequent and presupposition#AUTHOR_TAG :112 ) have collected convincing evidence of the existence of language chunks -- real structures , not just orthographic conventions -- that are smaller than a discourse , larger']","['', 'He lists , classifies , and discusses various types of inference , by which he means , generally , `` the linguistic-logical notions of consequent and presupposition#AUTHOR_TAG :112 ) have collected convincing evidence of the existence of language chunks -- real structures , not just orthographic conventions -- that are smaller than a discourse , larger than a sentence , generally composed of sentences , and recursive in nature ( like sentences ) .', 'These chunks are sometimes called ""episodes,"" and sometimes ""paragraphs.""', '']",0
"['', 'We investigate here only the ""grounding"" in logical theories.', 'However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX#AUTHOR_TAG ) .', '']","['', 'We investigate here only the ""grounding"" in logical theories.', 'However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX#AUTHOR_TAG ) .', '']","['', 'We investigate here only the ""grounding"" in logical theories.', 'However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX#AUTHOR_TAG ) .', 'Woods 1987']","['', 'We investigate here only the ""grounding"" in logical theories.', 'However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX#AUTHOR_TAG ) .', 'Woods 1987']",0
"['.', ""Jackendoff's (1983) formalism is richer and resembles more closely an English grammar."", ""#AUTHOR_TAG , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''"", 'Therefore a formalism of the kind he advocates would probably be most suitable for an implementation of our semantics.', 'It will also be a model for our simplified logical notation (cf.', '']","['possibility.', ""Jackendoff's (1983) formalism is richer and resembles more closely an English grammar."", ""#AUTHOR_TAG , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''"", 'Therefore a formalism of the kind he advocates would probably be most suitable for an implementation of our semantics.', 'It will also be a model for our simplified logical notation (cf.', '']","['', ""Jackendoff's (1983) formalism is richer and resembles more closely an English grammar."", ""#AUTHOR_TAG , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''"", 'Therefore a formalism of the kind he advocates would probably be most suitable for an implementation of our semantics.', 'It will also be a model for our simplified logical notation (cf.', '']","['', ""Jackendoff's (1983) formalism is richer and resembles more closely an English grammar."", ""#AUTHOR_TAG , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''"", 'Therefore a formalism of the kind he advocates would probably be most suitable for an implementation of our semantics.', 'It will also be a model for our simplified logical notation (cf.', '']",1
"['example of psycholinguistically oriented research work can be found in#AUTHOR_TAG .', 'These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholinguistic studies that confirm the validity of paragraph units can be found inBlack and Bower (1979) andHaberlandt et al. (1980)']","['example of psycholinguistically oriented research work can be found in#AUTHOR_TAG .', 'These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholinguistic studies that confirm the validity of paragraph units can be found inBlack and Bower (1979) andHaberlandt et al. (1980)']","['example of psycholinguistically oriented research work can be found in#AUTHOR_TAG .', 'These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholinguistic studies that confirm the validity of paragraph units can be found inBlack and Bower (1979) andHaberlandt et al. (1980)']","['example of psycholinguistically oriented research work can be found in#AUTHOR_TAG .', 'These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholinguistic studies that confirm the validity of paragraph units can be found inBlack and Bower (1979) andHaberlandt et al. (1980)']",0
"['.', '(Other reference works could be treated as additional sources of world knowledge.)', 'This type of consultation uses existing natural language texts as a referential level for processing purposes.', 'It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit.', ""#AUTHOR_TAG , p. 112 ) , for example , bemoans the fact that his `` theory lacks a world knowledge component , a mental ` encyclopedia , ' which could be invoked to generate inferences ... '' ."", '']","['and thesauri.', '(Other reference works could be treated as additional sources of world knowledge.)', 'This type of consultation uses existing natural language texts as a referential level for processing purposes.', 'It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit.', ""#AUTHOR_TAG , p. 112 ) , for example , bemoans the fact that his `` theory lacks a world knowledge component , a mental ` encyclopedia , ' which could be invoked to generate inferences ... '' ."", '']","['.', '(Other reference works could be treated as additional sources of world knowledge.)', 'This type of consultation uses existing natural language texts as a referential level for processing purposes.', 'It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit.', ""#AUTHOR_TAG , p. 112 ) , for example , bemoans the fact that his `` theory lacks a world knowledge component , a mental ` encyclopedia , ' which could be invoked to generate inferences ... '' ."", '']","['demonstrates that information needed to identify and resolve anaphoric references can be found, to an interesting extent, in standard dictionaries and thesauri.', '(Other reference works could be treated as additional sources of world knowledge.)', 'This type of consultation uses existing natural language texts as a referential level for processing purposes.', 'It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit.', ""#AUTHOR_TAG , p. 112 ) , for example , bemoans the fact that his `` theory lacks a world knowledge component , a mental ` encyclopedia , ' which could be invoked to generate inferences ... '' ."", '']",0
"['6.1.1 Was the Use of a Gricean Maxim Necessary?', 'Can one deal effectivelywith the problem of reference without axiomatized Gricean maxims, for instance by using only ""petty conversational implicature""( #AUTHOR_TAG ) , or the metarules of Section 5.2?', 'It seems to us that the answer is no']","['6.1.1 Was the Use of a Gricean Maxim Necessary?', 'Can one deal effectivelywith the problem of reference without axiomatized Gricean maxims, for instance by using only ""petty conversational implicature""( #AUTHOR_TAG ) , or the metarules of Section 5.2?', 'It seems to us that the answer is no']","['6.1.1 Was the Use of a Gricean Maxim Necessary?', 'Can one deal effectivelywith the problem of reference without axiomatized Gricean maxims, for instance by using only ""petty conversational implicature""( #AUTHOR_TAG ) , or the metarules of Section 5.2?', 'It seems to us that the answer is no']","['6.1.1 Was the Use of a Gricean Maxim Necessary?', 'Can one deal effectivelywith the problem of reference without axiomatized Gricean maxims, for instance by using only ""petty conversational implicature""( #AUTHOR_TAG ) , or the metarules of Section 5.2?', 'It seems to us that the answer is no']",0
"['adopt the three-level semantics as a formal tool for the analysis of paragraphs.', 'This semantics was constructed( #AUTHOR_TAG a , 1987b ) as a formal framework for default and commonsense reasoning .', 'It should not come as a surprise that we can now use this apparatus for text/discourse analysis']","['adopt the three-level semantics as a formal tool for the analysis of paragraphs.', 'This semantics was constructed( #AUTHOR_TAG a , 1987b ) as a formal framework for default and commonsense reasoning .', 'It should not come as a surprise that we can now use this apparatus for text/discourse analysis;']","['adopt the three-level semantics as a formal tool for the analysis of paragraphs.', 'This semantics was constructed( #AUTHOR_TAG a , 1987b ) as a formal framework for default and commonsense reasoning .', 'It should not come as a surprise that we can now use this apparatus for text/discourse analysis;']","['adopt the three-level semantics as a formal tool for the analysis of paragraphs.', 'This semantics was constructed( #AUTHOR_TAG a , 1987b ) as a formal framework for default and commonsense reasoning .', '']",5
"['the notion of R + M-abduction is spiritually related to the ""abductive inference"" ofReggia (1985) , the ""diagnosis from first principles"" ofReiter (1987) , ""explainability"" ofPoole (1988) , and the subset principle of#AUTHOR_TAG .', '']","['the notion of R + M-abduction is spiritually related to the ""abductive inference"" ofReggia (1985) , the ""diagnosis from first principles"" ofReiter (1987) , ""explainability"" ofPoole (1988) , and the subset principle of#AUTHOR_TAG .', '']","['the notion of R + M-abduction is spiritually related to the ""abductive inference"" ofReggia (1985) , the ""diagnosis from first principles"" ofReiter (1987) , ""explainability"" ofPoole (1988) , and the subset principle of#AUTHOR_TAG .', '']","['', 'Similarly, the notion of R + M-abduction is spiritually related to the ""abductive inference"" ofReggia (1985) , the ""diagnosis from first principles"" ofReiter (1987) , ""explainability"" ofPoole (1988) , and the subset principle of#AUTHOR_TAG .', '']",1
"['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 ,#AUTHOR_TAG ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 ,#AUTHOR_TAG ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 ,#AUTHOR_TAG ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']","['there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 ,#AUTHOR_TAG ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']",1
"['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ;#AUTHOR_TAG ) or quantifier scoping ( Webber 1983 ) must play a role , too .', '']","['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ;#AUTHOR_TAG ) or quantifier scoping ( Webber 1983 ) must play a role , too .', '']","['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ;#AUTHOR_TAG ) or quantifier scoping ( Webber 1983 ) must play a role , too .', '']","['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ;#AUTHOR_TAG ) or quantifier scoping ( Webber 1983 ) must play a role , too .', 'Determining the relative importance of those factors, the above metarules, and syntactic clues, appears to be an interesting topic in itself']",0
"['referential structures we are going to use are collections of logical theories, but the concept of reference is more general.', 'Some of the intuitions we associate with this notion have been very well expressed by#AUTHOR_TAG , pp. 7-8 ) : ... Semantics is constrained by our models of ourselves and our worlds .', 'We have models of']","['referential structures we are going to use are collections of logical theories, but the concept of reference is more general.', 'Some of the intuitions we associate with this notion have been very well expressed by#AUTHOR_TAG , pp. 7-8 ) : ... Semantics is constrained by our models of ourselves and our worlds .', 'We have models of']","['referential structures we are going to use are collections of logical theories, but the concept of reference is more general.', 'Some of the intuitions we associate with this notion have been very well expressed by#AUTHOR_TAG , pp. 7-8 ) : ... Semantics is constrained by our models of ourselves and our worlds .', 'We have models of']","['referential structures we are going to use are collections of logical theories, but the concept of reference is more general.', 'Some of the intuitions we associate with this notion have been very well expressed by#AUTHOR_TAG , pp. 7-8 ) : ... Semantics is constrained by our models of ourselves and our worlds .', '']",0
['version of marker passing ( Hirst 1987 ;#AUTHOR_TAG )'],['version of marker passing ( Hirst 1987 ;#AUTHOR_TAG )'],['version of marker passing ( Hirst 1987 ;#AUTHOR_TAG )'],"['idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing ( Hirst 1987 ;#AUTHOR_TAG ) , with one difference : the activation spreads to theories that share a predicate , not through the IS-A hierarchy , and is limited to elementary facts about predicates appearing in the text""]",1
"['in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX#AUTHOR_TAG ; Frisch 1987 ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', '']","['in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX#AUTHOR_TAG ; Frisch 1987 ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', '']","['in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX#AUTHOR_TAG ; Frisch 1987 ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', '']","['in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX#AUTHOR_TAG ; Frisch 1987 ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', ""But we won't pursue this topic further here""]",1
"['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus( #AUTHOR_TAG , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too']","['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus( #AUTHOR_TAG , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too']","['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus( #AUTHOR_TAG , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too .', '']","['have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus( #AUTHOR_TAG , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too .', '']",0
"['', 'This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose( #AUTHOR_TAG , p. 329 )']","['', 'This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose( #AUTHOR_TAG , p. 329 )']","['', 'This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose( #AUTHOR_TAG , p. 329 )']","['', 'This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose( #AUTHOR_TAG , p. 329 )']",4
"['can also hope for some fine-tuning of the notion of topic, which would prevent many offensive examples.', 'This approach is taken in computational syntactic grammars (e.g.', '#AUTHOR_TAG ) ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the so-called grammatical strings of a language']","['can also hope for some fine-tuning of the notion of topic, which would prevent many offensive examples.', 'This approach is taken in computational syntactic grammars (e.g.', '#AUTHOR_TAG ) ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the so-called grammatical strings of a language']","['can also hope for some fine-tuning of the notion of topic, which would prevent many offensive examples.', 'This approach is taken in computational syntactic grammars (e.g.', '#AUTHOR_TAG ) ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the so-called grammatical strings of a language']","['can also hope for some fine-tuning of the notion of topic, which would prevent many offensive examples.', 'This approach is taken in computational syntactic grammars (e.g.', '#AUTHOR_TAG ) ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the so-called grammatical strings of a language']",0
"['idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing( #AUTHOR_TAG ; Charn""]","['idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing( #AUTHOR_TAG ; Charniak 1983""]","['idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing( #AUTHOR_TAG ; Charn""]",['( #AUTHOR_TAG'],1
"['', 'We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by#AUTHOR_TAG']","['a rule.', 'We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by#AUTHOR_TAG']","['such a rule.', 'We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by#AUTHOR_TAG']","['', 'We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by#AUTHOR_TAG']",2
"['', 'Opposition ( called ""adversative"" or ""contrary-to-expectation"" by#AUTHOR_TAG ; cfXXX also Quirk et al. 1972 , p. 672 )']","['', 'Opposition ( called ""adversative"" or ""contrary-to-expectation"" by#AUTHOR_TAG ; cfXXX also Quirk et al. 1972 , p. 672 )']","[', ""but"" does not behave quite like the other two--semantically, ""but"" signals a contradiction, and in this role it seems to have three subfunctions: . .', 'Opposition ( called ""adversative"" or ""contrary-to-expectation"" by#AUTHOR_TAG ; cfXXX also Quirk et al. 1972 , p. 672 )']","['ives are function words--like conjunctions and some adverbs--that are responsible simultaneously for maintaining cohesiveness within the text and for signaling the nature of the relationships that hold between and among various text units.', '""And,"" ""or,"" and ""but"" are the three main coordinating connectives in English.', 'However, ""but"" does not behave quite like the other two--semantically, ""but"" signals a contradiction, and in this role it seems to have three subfunctions: . .', 'Opposition ( called ""adversative"" or ""contrary-to-expectation"" by#AUTHOR_TAG ; cfXXX also Quirk et al. 1972 , p. 672 )']",0
"['there are other discussions of the paragraph as a central element of discourse (e.g.', '#AUTHOR_TAG , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure']","['there are other discussions of the paragraph as a central element of discourse (e.g.', '#AUTHOR_TAG , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure']","['there are other discussions of the paragraph as a central element of discourse (e.g.', '#AUTHOR_TAG , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']","['there are other discussions of the paragraph as a central element of discourse (e.g.', '#AUTHOR_TAG , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '']",1
"['', 'This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) ,Jackendoff ( 1983 ) ,#AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['', 'This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) ,Jackendoff ( 1983 ) ,#AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['', 'This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) ,Jackendoff ( 1983 ) ,#AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', '']","['', 'This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) ,Jackendoff ( 1983 ) ,#AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', '']",1
"['spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in#AUTHOR_TAG andHaberlandt et al. ( 1980 )']","['spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in#AUTHOR_TAG andHaberlandt et al. ( 1980 )']","['spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in#AUTHOR_TAG andHaberlandt et al. ( 1980 )']","['', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in#AUTHOR_TAG andHaberlandt et al. ( 1980 )']",0
"['have shown elsewhere ( Jensen and Binot 1988 ;#AUTHOR_TAG a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory']","['have shown elsewhere ( Jensen and Binot 1988 ;#AUTHOR_TAG a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory']","['have shown elsewhere ( Jensen and Binot 1988 ;#AUTHOR_TAG a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory']","['have shown elsewhere ( Jensen and Binot 1988 ;#AUTHOR_TAG a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory']",2
"['', 'The partial theories pick up from the referential level the most obvious or the most important information about a formula.', 'This immediate information may be insufficient to decide the truth of certain predicates.', 'It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX#AUTHOR_TAG b ) .', 'Zadrozny 1987b']","['', 'The partial theories pick up from the referential level the most obvious or the most important information about a formula.', 'This immediate information may be insufficient to decide the truth of certain predicates.', 'It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX#AUTHOR_TAG b ) .', 'Zadrozny 1987b']","['', 'The partial theories pick up from the referential level the most obvious or the most important information about a formula.', 'This immediate information may be insufficient to decide the truth of certain predicates.', 'It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX#AUTHOR_TAG b ) .', 'Zadrozny 1987b']","['', 'The partial theories pick up from the referential level the most obvious or the most important information about a formula.', 'This immediate information may be insufficient to decide the truth of certain predicates.', 'It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX#AUTHOR_TAG b ) .', 'Zadrozny 1987b']",1
"['ing selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the background knowledge necessary for reference disambiguation.', ""Later ,#AUTHOR_TAG , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base""]","['ing selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the background knowledge necessary for reference disambiguation.', ""Later ,#AUTHOR_TAG , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base""]","['ing selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the background knowledge necessary for reference disambiguation.', ""Later ,#AUTHOR_TAG , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base""]","['ing selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the background knowledge necessary for reference disambiguation.', ""Later ,#AUTHOR_TAG , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base""]",0
"['necessity of this kind of merging of arguments has been recognized before : Charniak and McDermott ( 1985 ) call it abductive unification/matching ,#AUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature']","['necessity of this kind of merging of arguments has been recognized before : Charniak and McDermott ( 1985 ) call it abductive unification/matching ,#AUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature']","['necessity of this kind of merging of arguments has been recognized before : Charniak and McDermott ( 1985 ) call it abductive unification/matching ,#AUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature']","['necessity of this kind of merging of arguments has been recognized before : Charniak and McDermott ( 1985 ) call it abductive unification/matching ,#AUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature']",0
"['we may need also a quotation operator ;#AUTHOR_TAG describes how first order logic can be augmented with such an operator .', '']","['we may need also a quotation operator ;#AUTHOR_TAG describes how first order logic can be augmented with such an operator .', '']","['we may need also a quotation operator ;#AUTHOR_TAG describes how first order logic can be augmented with such an operator .', '']","['', 'Since sentences can refer to events described by other sentences , we may need also a quotation operator ;#AUTHOR_TAG describes how first order logic can be augmented with such an operator .', '']",0
"['paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings.', ""For instance ,#AUTHOR_TAG , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's""]","['paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings.', ""For instance ,#AUTHOR_TAG , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's""]","['paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings.', ""For instance ,#AUTHOR_TAG , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's""]","['paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings.', ""For instance ,#AUTHOR_TAG , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's favorite fruit ? ''"", 'The pairing of these two sentences may be said to create a small paragraph.', '']",4
"['', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,#AUTHOR_TAG , andYoung ( 1989 )']","['', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,#AUTHOR_TAG , andYoung ( 1989 )']","['the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,#AUTHOR_TAG , andYoung ( 1989 )']","['', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,#AUTHOR_TAG , andYoung ( 1989 )']",0
['formula for the test set perplexity( #AUTHOR_TAG ) is :1'],['formula for the test set perplexity( #AUTHOR_TAG ) is :1'],['formula for the test set perplexity( #AUTHOR_TAG ) is :1'],['formula for the test set perplexity( #AUTHOR_TAG ) is :1'],0
"['', 'The third version ( VOYAGER ) serves as an interface both with a recognizer and with a functioning database back-end( #AUTHOR_TAG ) .', 'The']","['', 'The third version ( VOYAGER ) serves as an interface both with a recognizer and with a functioning database back-end( #AUTHOR_TAG ) .', 'The']","['', 'The third version ( VOYAGER ) serves as an interface both with a recognizer and with a functioning database back-end( #AUTHOR_TAG ) .', '']","['', 'The third version ( VOYAGER ) serves as an interface both with a recognizer and with a functioning database back-end( #AUTHOR_TAG ) .', '']",5
"['subject.', 'Subsequent processing by the natural language and response generation components was done automatically by the computer( #AUTHOR_TAG )']","['subject.', 'Subsequent processing by the natural language and response generation components was done automatically by the computer( #AUTHOR_TAG )']","['the subject.', 'Subsequent processing by the natural language and response generation components was done automatically by the computer( #AUTHOR_TAG )']","['', 'Instead, an experimenter in a separate room typed in the utterances as spoken by the subject.', 'Subsequent processing by the natural language and response generation components was done automatically by the computer( #AUTHOR_TAG )']",5
[''],[''],[''],[''],0
"['', 'This approach resembles the work byGrishman et al. ( 1986 ) and#AUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']","['', 'This approach resembles the work byGrishman et al. ( 1986 ) and#AUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']","['', 'This approach resembles the work byGrishman et al. ( 1986 ) and#AUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']","['', 'This approach resembles the work byGrishman et al. ( 1986 ) and#AUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']",1
"['', 'The search algorithm is the standard Viterbi search( #AUTHOR_TAG ) , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence']","['', 'The search algorithm is the standard Viterbi search( #AUTHOR_TAG ) , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence']","['', 'The search algorithm is the standard Viterbi search( #AUTHOR_TAG ) , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence']","['', 'The search algorithm is the standard Viterbi search( #AUTHOR_TAG ) , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence']",5
['antic filters can also be used to prevent multiple versions of the same case frame( #AUTHOR_TAG ) showing up as complements'],['antic filters can also be used to prevent multiple versions of the same case frame( #AUTHOR_TAG ) showing up as complements'],"['antic filters can also be used to prevent multiple versions of the same case frame( #AUTHOR_TAG ) showing up as complements .', '']","['antic filters can also be used to prevent multiple versions of the same case frame( #AUTHOR_TAG ) showing up as complements .', '']",5
"['in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in#AUTHOR_TAG ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,Niemann ( 1990 ) , andYoung ( 1989 )']","['in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in#AUTHOR_TAG ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,Niemann ( 1990 ) , andYoung ( 1989 )']","['in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in#AUTHOR_TAG ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,Niemann ( 1990 ) , andYoung ( 1989 )']","['', 'Current advances in research and development of spoken language systems 2 can be found, for example, in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in#AUTHOR_TAG ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,Niemann ( 1990 ) , andYoung ( 1989 )']",0
"['izer.', ""We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance( #AUTHOR_TAG ) ."", '']","['search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', ""We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance( #AUTHOR_TAG ) ."", '']","[', each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', ""We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance( #AUTHOR_TAG ) ."", '']","['as in the loosely coupled system the parser acts as a filter only on completed candidate solutions (Zue et al. 1991), the tightly coupled system allows the parser to discard partial theories that have no way of continuing.', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', ""We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance( #AUTHOR_TAG ) ."", '']",5
"['date, four distinct domain-specific versions of TINA have been implemented.', 'The first version ( TIMIT ) was developed for the 450 phonetically rich sentences of the TIMIT database( #AUTHOR_TAG ) .', '']","['date, four distinct domain-specific versions of TINA have been implemented.', 'The first version ( TIMIT ) was developed for the 450 phonetically rich sentences of the TIMIT database( #AUTHOR_TAG ) .', '']","['date, four distinct domain-specific versions of TINA have been implemented.', 'The first version ( TIMIT ) was developed for the 450 phonetically rich sentences of the TIMIT database( #AUTHOR_TAG ) .', '']","['date, four distinct domain-specific versions of TINA have been implemented.', 'The first version ( TIMIT ) was developed for the 450 phonetically rich sentences of the TIMIT database( #AUTHOR_TAG ) .', '']",5
"['actly how to get from the parse tree to an appropriate meaning representation is a current research topic in our group.', 'However , the method we are currently using in the ATIS domain( #AUTHOR_TAG ) represents our most promising approach to this problem .', 'We have decided to limit semantic frame types to']","['actly how to get from the parse tree to an appropriate meaning representation is a current research topic in our group.', 'However , the method we are currently using in the ATIS domain( #AUTHOR_TAG ) represents our most promising approach to this problem .', 'We have decided to limit semantic frame types to']","['actly how to get from the parse tree to an appropriate meaning representation is a current research topic in our group.', 'However , the method we are currently using in the ATIS domain( #AUTHOR_TAG ) represents our most promising approach to this problem .', 'We have decided to limit semantic frame types to']","['actly how to get from the parse tree to an appropriate meaning representation is a current research topic in our group.', 'However , the method we are currently using in the ATIS domain( #AUTHOR_TAG ) represents our most promising approach to this problem .', 'We have decided to limit semantic frame types to a small set of choices such as CLAUSE (for a sentence-level concept, such as request), PREDICATE (for a functional operation), REFERENCE (essentially proper noun), and QSET (for a set of objects).', '']",3
"['', 'The second one, ATIS( #AUTHOR_TAG et al. 1991), is a system for accessing data in the Official 80 Stephanie Seneff TINA: A Natural Language System for Spoken Language Applications Airline Guide and booking flights.', '']","['MIT and Harvard University.', 'The second one, ATIS( #AUTHOR_TAG et al. 1991), is a system for accessing data in the Official 80 Stephanie Seneff TINA: A Natural Language System for Spoken Language Applications Airline Guide and booking flights.', '']","['MIT and Harvard University.', 'The second one, ATIS( #AUTHOR_TAG et al. 1991), is a system for accessing data in the Official 80 Stephanie Seneff TINA: A Natural Language System for Spoken Language Applications Airline Guide and booking flights.', '']","['', 'The second one, ATIS( #AUTHOR_TAG et al. 1991), is a system for accessing data in the Official 80 Stephanie Seneff TINA: A Natural Language System for Spoken Language Applications Airline Guide and booking flights.', '']",5
"['', 'This approach resembles the work by#AUTHOR_TAG andHirschman et al. ( 1975 ) on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']","['', 'This approach resembles the work by#AUTHOR_TAG andHirschman et al. ( 1975 ) on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']","['', 'This approach resembles the work by#AUTHOR_TAG andHirschman et al. ( 1975 ) on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']","['', 'This approach resembles the work by#AUTHOR_TAG andHirschman et al. ( 1975 ) on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']",1
"['as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model( #AUTHOR_TAG )']","['as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model( #AUTHOR_TAG )']","['as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model( #AUTHOR_TAG )']","['', 'Unless it is desired to intentionally filter these out as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model( #AUTHOR_TAG )']",0
"['', 'To a first approximation , a CURRENT-FOCUS reaches only nodes that are c-commanded( #AUTHOR_TAG ) by its generator .', '']","['', 'To a first approximation , a CURRENT-FOCUS reaches only nodes that are c-commanded( #AUTHOR_TAG ) by its generator .', '']","['', 'To a first approximation , a CURRENT-FOCUS reaches only nodes that are c-commanded( #AUTHOR_TAG ) by its generator .', '']","['', 'To a first approximation , a CURRENT-FOCUS reaches only nodes that are c-commanded( #AUTHOR_TAG ) by its generator .', '']",0
"['_currently have two application domains that can carry on a spoken dialog with a user.', 'One , the VOYAGER domain( #AUTHOR_TAG ) , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .', '']","['_currently have two application domains that can carry on a spoken dialog with a user.', 'One , the VOYAGER domain( #AUTHOR_TAG ) , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .', '']","['_currently have two application domains that can carry on a spoken dialog with a user.', 'One , the VOYAGER domain( #AUTHOR_TAG ) , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .', '']","['_currently have two application domains that can carry on a spoken dialog with a user.', 'One , the VOYAGER domain( #AUTHOR_TAG ) , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .', '']",5
"[""example used to illustrate the power of ATNs( #AUTHOR_TAG ) , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator""]","[""example used to illustrate the power of ATNs( #AUTHOR_TAG ) , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator""]","[""example used to illustrate the power of ATNs( #AUTHOR_TAG ) , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator ."", '']","[""example used to illustrate the power of ATNs( #AUTHOR_TAG ) , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator ."", '']",1
"['.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,#AUTHOR_TAG ,Niemann ( 1990 ) , andYoung ( 1989 )']","['the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,#AUTHOR_TAG ,Niemann ( 1990 ) , andYoung ( 1989 )']","['the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,#AUTHOR_TAG ,Niemann ( 1990 ) , andYoung ( 1989 )']","['', 'Current advances in research and development of spoken language systems 2 can be found, for example, in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,#AUTHOR_TAG ,Niemann ( 1990 ) , andYoung ( 1989 )']",0
"['', 'The second version ( RM ) concerns the Resource Management task( #AUTHOR_TAG ) that has been popular within the DARPA community in recent years .', 'The third version (']","['', 'The second version ( RM ) concerns the Resource Management task( #AUTHOR_TAG ) that has been popular within the DARPA community in recent years .', 'The third version']","['', 'The second version ( RM ) concerns the Resource Management task( #AUTHOR_TAG ) that has been popular within the DARPA community in recent years .', 'The third version (']","['', 'The second version ( RM ) concerns the Resource Management task( #AUTHOR_TAG ) that has been popular within the DARPA community in recent years .', '']",5
"['', 'For the A * algorithm( #AUTHOR_TAG ) as applied to speech recognition , the actual path score is typically augmented with an estimated score for the unseen portion .', '']","['', 'For the A * algorithm( #AUTHOR_TAG ) as applied to speech recognition , the actual path score is typically augmented with an estimated score for the unseen portion .', '']","['', 'For the A * algorithm( #AUTHOR_TAG ) as applied to speech recognition , the actual path score is typically augmented with an estimated score for the unseen portion .', '']","['', 'For the A * algorithm( #AUTHOR_TAG ) as applied to speech recognition , the actual path score is typically augmented with an estimated score for the unseen portion .', 'Unless some kind of normalization is done, the short theories have an unfair advantage, simply because fewer probability scores have been multiplied.', '']",5
"['', 'The recognizer for these systems is the SUMMIT system( #AUTHOR_TAG ) , which uses a segmental-based framework and includes an auditory model in the front-end processing .', 'The lexicon is entered as phonetic pronunciations that are then augmented to account for a number of phonological rules.', 'The search']","['', 'The recognizer for these systems is the SUMMIT system( #AUTHOR_TAG ) , which uses a segmental-based framework and includes an auditory model in the front-end processing .', 'The lexicon is entered as phonetic pronunciations that are then augmented to account for a number of phonological rules.', 'The search']","['', 'The recognizer for these systems is the SUMMIT system( #AUTHOR_TAG ) , which uses a segmental-based framework and includes an auditory model in the front-end processing .', 'The lexicon is entered as phonetic pronunciations that are then augmented to account for a number of phonological rules.', 'The search algorithm is the standard Viterbi search (Viterbi 196']","['', 'The recognizer for these systems is the SUMMIT system( #AUTHOR_TAG ) , which uses a segmental-based framework and includes an auditory model in the front-end processing .', 'The lexicon is entered as phonetic pronunciations that are then augmented to account for a number of phonological rules.', '']",5
"['', 'The gap mechanism resembles the Hold register idea of ATNs( #AUTHOR_TAG ) and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff']","['', 'The gap mechanism resembles the Hold register idea of ATNs( #AUTHOR_TAG ) and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff']","['', 'The gap mechanism resembles the Hold register idea of ATNs( #AUTHOR_TAG ) and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff . ),']","['', 'The gap mechanism resembles the Hold register idea of ATNs( #AUTHOR_TAG ) and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff . ), but it is different from these in that the process of filling the Hold register equivalent involves two steps separately initiated by two independent nodes']",1
"['.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,Niemann ( 1990 ) , and#AUTHOR_TAG']","['the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,Niemann ( 1990 ) , and#AUTHOR_TAG']","['the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,Niemann ( 1990 ) , and#AUTHOR_TAG']","['', 'Current advances in research and development of spoken language systems 2 can be found, for example, in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described inBoisen et al. ( 1989 ) ,De Mattia and Giachin ( 1989 ) ,Niedermair ( 1989 ) ,Niemann ( 1990 ) , and#AUTHOR_TAG']",0
"['', ""We have since improved the interface by incorporating a capability in the recognizer to propose additional solutions in turn once the first one fails to parse( #AUTHOR_TAG ) To produce these `` N-best '' alternatives , we make use of a standard A * search algorithm""]","['', ""We have since improved the interface by incorporating a capability in the recognizer to propose additional solutions in turn once the first one fails to parse( #AUTHOR_TAG ) To produce these `` N-best '' alternatives , we make use of a standard A * search algorithm""]","['', ""We have since improved the interface by incorporating a capability in the recognizer to propose additional solutions in turn once the first one fails to parse( #AUTHOR_TAG ) To produce these `` N-best '' alternatives , we make use of a standard A * search algorithm""]","['', ""We have since improved the interface by incorporating a capability in the recognizer to propose additional solutions in turn once the first one fails to parse( #AUTHOR_TAG ) To produce these `` N-best '' alternatives , we make use of a standard A * search algorithm ( Hart 1968 , Jelinek 1976 ) ."", '']",5
"['as in the loosely coupled system the parser acts as a filter only on completed candidate solutions( #AUTHOR_TAG ) , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', '']","['as in the loosely coupled system the parser acts as a filter only on completed candidate solutions( #AUTHOR_TAG ) , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', '']","['as in the loosely coupled system the parser acts as a filter only on completed candidate solutions( #AUTHOR_TAG ) , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', '']","['as in the loosely coupled system the parser acts as a filter only on completed candidate solutions( #AUTHOR_TAG ) , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', '']",5
"['thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by#AUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps : A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1 .', 'This description can then be given the standard set-theoretical interpretation ofKing (1989']","['thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by#AUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps : A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1 .', 'This description can then be given the standard set-theoretical interpretation ofKing (1989']","['thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by#AUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps : A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1 .', 'This description can then be given the standard set-theoretical interpretation ofKing (1989']","['thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by#AUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps : A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1 .', 'This description can then be given the standard set-theoretical interpretation ofKing (1989 , 1994']",0
"['', 'The reader is referred to#AUTHOR_TAG for a more detailed discussion of our use of constraint propagation']","['', 'The reader is referred to#AUTHOR_TAG for a more detailed discussion of our use of constraint propagation']","['', 'The reader is referred to#AUTHOR_TAG for a more detailed discussion of our use of constraint propagation']","['', 'The reader is referred to#AUTHOR_TAG for a more detailed discussion of our use of constraint propagation']",0
"['common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB ( Copestake 1992 ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules( #AUTHOR_TAG , 31 ) .', '']","['common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB ( Copestake 1992 ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules( #AUTHOR_TAG , 31 ) .', '']","['common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB ( Copestake 1992 ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules( #AUTHOR_TAG , 31 ) .', '']","['common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB ( Copestake 1992 ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules( #AUTHOR_TAG , 31 ) .', '']",1
"['way these predicates interconnect is represented in Figure 19.', '27#AUTHOR_TAG argue that semi-productivity of lexical rules , which can be understood as a generalization of exceptions to lexical rules , can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry .', '']","['way these predicates interconnect is represented in Figure 19.', '27#AUTHOR_TAG argue that semi-productivity of lexical rules , which can be understood as a generalization of exceptions to lexical rules , can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry .', '']","['way these predicates interconnect is represented in Figure 19.', '27#AUTHOR_TAG argue that semi-productivity of lexical rules , which can be understood as a generalization of exceptions to lexical rules , can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry .', '']","['way these predicates interconnect is represented in Figure 19.', '27#AUTHOR_TAG argue that semi-productivity of lexical rules , which can be understood as a generalization of exceptions to lexical rules , can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry .', '']",0
"['9) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Extraction Lexical Rule( #AUTHOR_TAG ) to operate on those raised elements.', '']","['that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Extraction Lexical Rule( #AUTHOR_TAG ) to operate on those raised elements.', '']","['that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Extraction Lexical Rule( #AUTHOR_TAG ) to operate on those raised elements.', 'Also an analysis treating adjunct extraction']","['', '/b4home.html 1 This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Extraction Lexical Rule( #AUTHOR_TAG ) to operate on those raised elements.', '']",0
"['xical rules to be grammatical with respect to the theory.', 'Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata.', 'This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as , for example , adopted in the LKB system( #AUTHOR_TAG ) .', '']","['setup, the DLR formalization therefore requires all words feeding lexical rules to be grammatical with respect to the theory.', 'Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata.', 'This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as , for example , adopted in the LKB system( #AUTHOR_TAG ) .', '']","['xical rules to be grammatical with respect to the theory.', 'Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata.', 'This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as , for example , adopted in the LKB system( #AUTHOR_TAG ) .', '']","['', 'Contrary to the MLR setup, the DLR formalization therefore requires all words feeding lexical rules to be grammatical with respect to the theory.', 'Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata.', 'This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as , for example , adopted in the LKB system( #AUTHOR_TAG ) .', '']",0
"['This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body( #AUTHOR_TAG ) .', '']","['This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body( #AUTHOR_TAG ) .', '']","['9 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body( #AUTHOR_TAG ) .', '']","['', 'As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body( #AUTHOR_TAG ) .', '']",1
"['In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ;#AUTHOR_TAG ) can be used to circumvent constraint propagation .', '']","['In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ;#AUTHOR_TAG ) can be used to circumvent constraint propagation .', '']","['In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ;#AUTHOR_TAG ) can be used to circumvent constraint propagation .', '']","['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ;#AUTHOR_TAG ) can be used to circumvent constraint propagation .', '']",0
"['2 In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in#AUTHOR_TAG .', 'The reader interested in that language and its precise interpretation can find the relevant details in that paper.', '13 A']","['In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in#AUTHOR_TAG .', 'The reader interested in that language and its precise interpretation can find the relevant details in that paper.', '13 A']","['2 In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in#AUTHOR_TAG .', 'The reader interested in that language and its precise interpretation can find the relevant details in that paper.', '13 A']","['', '12 In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in#AUTHOR_TAG .', 'The reader interested in that language and its precise interpretation can find the relevant details in that paper.', '13 A more detailed presentation can be found in Minnen (in preparation).', '']",0
"['6 The Partial-VP Topicalization Lexical Rule proposed by#AUTHOR_TAG , 10 ) is a linguistic example .', 'The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries serving as its input.', 'In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement']","['including a comparison of both approaches is provided in Calcagno, Meurers, and Pollard (in preparation).', '6 The Partial-VP Topicalization Lexical Rule proposed by#AUTHOR_TAG , 10 ) is a linguistic example .', 'The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries serving as its input.', 'In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement']","['6 The Partial-VP Topicalization Lexical Rule proposed by#AUTHOR_TAG , 10 ) is a linguistic example .', 'The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries serving as its input.', 'In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement']","['', '5 An in-depth discussion including a comparison of both approaches is provided in Calcagno, Meurers, and Pollard (in preparation).', '6 The Partial-VP Topicalization Lexical Rule proposed by#AUTHOR_TAG , 10 ) is a linguistic example .', 'The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries serving as its input.', 'In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement']",0
"['4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ;#AUTHOR_TAG ) .', '5 An']","['', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ;#AUTHOR_TAG ) .', '5 An in-depth discussion including a comparison']","['4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ;#AUTHOR_TAG ) .', '5 An in-depth discussion including a comparison']","['', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ;#AUTHOR_TAG ) .', '5 An in-depth discussion including a comparison of both approaches is provided in Calcagno, Meurers, and Pollard (in preparation).', '']",0
"['ical rule.', 'Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up( #AUTHOR_TAG )']","['a lexical rule.', 'Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up( #AUTHOR_TAG )']","['a lexical rule.', 'Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up( #AUTHOR_TAG )']","['', 'Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up( #AUTHOR_TAG )']",0
"['', 'As shown in#AUTHOR_TAG this is a well-motivated convention since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries']","['', 'As shown in#AUTHOR_TAG this is a well-motivated convention since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries']","['', 'As shown in#AUTHOR_TAG this is a well-motivated convention since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries']","['', 'As shown in#AUTHOR_TAG this is a well-motivated convention since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries']",4
"['elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques( #AUTHOR_TAG ) .', '']","['elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques( #AUTHOR_TAG ) .', '']","['elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques( #AUTHOR_TAG ) .', '']","['elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques( #AUTHOR_TAG ) .', '']",5
"['information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993; Oliva 1994; Frank 1994;#AUTHOR_TAG ; Sanfilippo 1995).', 'The lex']","['information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993; Oliva 1994; Frank 1994;#AUTHOR_TAG ; Sanfilippo 1995).', 'The lexical']","['ical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993; Oliva 1994; Frank 1994;#AUTHOR_TAG ; Sanfilippo 1995).', 'The lexical entries are only partially']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993; Oliva 1994; Frank 1994;#AUTHOR_TAG ; Sanfilippo 1995).', '']",1
"['', 'A similar method is included in PATR-II( #AUTHOR_TAG ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .', '']","['', 'A similar method is included in PATR-II( #AUTHOR_TAG ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .', '']","['', 'A similar method is included in PATR-II( #AUTHOR_TAG ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .', '']","['', 'A similar method is included in PATR-II( #AUTHOR_TAG ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .', '']",1
"['991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ;#AUTHOR_TAG ) .', '']","['be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ;#AUTHOR_TAG ) .', '']","['xical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ;#AUTHOR_TAG ) .', '']","['', 'A similar method is included in PATR-II ( Shieber et al. 1983 ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ;#AUTHOR_TAG ) .', '']",1
"['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ;#AUTHOR_TAG ) and the .', 'lexical rules (DLRs; Meurers 1995).', '']","['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ;#AUTHOR_TAG ) and the .', 'lexical rules (DLRs; Meurers 1995).', '']","['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ;#AUTHOR_TAG ) and the .', 'lexical rules (DLRs; Meurers 1995).', '']","['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ;#AUTHOR_TAG ) and the .', 'lexical rules (DLRs; Meurers 1995).', '']",0
"['xical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and#AUTHOR_TAG ; Gotz and Meurers 1997a ) .', '']","['computational treatment of lexical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and#AUTHOR_TAG ; Gotz and Meurers 1997a ) .', '']","['xical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and#AUTHOR_TAG ; Gotz and Meurers 1997a ) .', '']","['computational treatment of lexical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and#AUTHOR_TAG ; Gotz and Meurers 1997a ) .', '']",5
"['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ;#AUTHOR_TAG ; Calcagno and Pollard 1995 ) and the .', 'lexical rules (DLRs; Meurers 1995).', '']","['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ;#AUTHOR_TAG ; Calcagno and Pollard 1995 ) and the .', 'lexical rules (DLRs; Meurers 1995).', '']","['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ;#AUTHOR_TAG ; Calcagno and Pollard 1995 ) and the .', 'lexical rules (DLRs; Meurers 1995).', '']","['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ;#AUTHOR_TAG ; Calcagno and Pollard 1995 ) and the .', 'lexical rules (DLRs; Meurers 1995).', '']",0
"['1 This is, for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement( #AUTHOR_TAG ) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via']","['1 This is, for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement( #AUTHOR_TAG ) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via lexical rules (van Noord and']","['html 1 This is, for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement( #AUTHOR_TAG ) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via']","['', '/b4home.html 1 This is, for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement( #AUTHOR_TAG ) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon']",0
"['common computational treatment of lexical rules adopted , for example , in the ALE system( #AUTHOR_TAG ) consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time .', 'While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation.', '']","['common computational treatment of lexical rules adopted , for example , in the ALE system( #AUTHOR_TAG ) consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time .', 'While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation.', '']","['common computational treatment of lexical rules adopted , for example , in the ALE system( #AUTHOR_TAG ) consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time .', 'While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation.', '']","['common computational treatment of lexical rules adopted , for example , in the ALE system( #AUTHOR_TAG ) consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time .', 'While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation.', '']",1
"['logic that provides the formal architecture required byPollard and Sag ( 1994 ) was defined by#AUTHOR_TAG , 1994 ) .', 'The formal language of']","['logic that provides the formal architecture required byPollard and Sag ( 1994 ) was defined by#AUTHOR_TAG , 1994 ) .', 'The formal language of']","['logic that provides the formal architecture required byPollard and Sag ( 1994 ) was defined by#AUTHOR_TAG , 1994 ) .', 'The formal language of']","['logic that provides the formal architecture required byPollard and Sag ( 1994 ) was defined by#AUTHOR_TAG , 1994 ) .', 'The formal language of King allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects.', '']",0
"['', 'The unfolding transformation is also referred to as partial execution , for example , by#AUTHOR_TAG .', '']","['', 'The unfolding transformation is also referred to as partial execution , for example , by#AUTHOR_TAG .', '']","['', 'The unfolding transformation is also referred to as partial execution , for example , by#AUTHOR_TAG .', '']","['elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques ( Tamaki and Sato 1984 ) .29', 'The unfolding transformation is also referred to as partial execution , for example , by#AUTHOR_TAG .', 'Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time.', '']",0
"['xical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system( #AUTHOR_TAG ; Emele 1994 ) .', '']","['be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system( #AUTHOR_TAG ; Emele 1994 ) .', '']","['xical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system( #AUTHOR_TAG ; Emele 1994 ) .', '']","['', 'A similar method is included in PATR-II ( Shieber et al. 1983 ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system( #AUTHOR_TAG ; Emele 1994 ) .', '']",1
"['xical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1.', ""This description can then be given the standard set-theoretical interpretation of#AUTHOR_TAG , 1994 ) . '"", '11 10 Note']","['a formal lexical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1.', ""This description can then be given the standard set-theoretical interpretation of#AUTHOR_TAG , 1994 ) . '"", '11 10 Note']","['thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided byMeurers (1995) defines a formal lexical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1.', ""This description can then be given the standard set-theoretical interpretation of#AUTHOR_TAG , 1994 ) . '"", '11 10 Note']","['thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided byMeurers (1995) defines a formal lexical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1.', ""This description can then be given the standard set-theoretical interpretation of#AUTHOR_TAG , 1994 ) . '"", '']",0
"['ed as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ;#AUTHOR_TAG ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical']","['as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ;#AUTHOR_TAG ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical']","['ed as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ;#AUTHOR_TAG ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ;#AUTHOR_TAG ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', '']",1
['11#AUTHOR_TAG proposes to unify these two steps by including an update operator in the description language'],['11#AUTHOR_TAG proposes to unify these two steps by including an update operator in the description language'],['11#AUTHOR_TAG proposes to unify these two steps by including an update operator in the description language'],['11#AUTHOR_TAG proposes to unify these two steps by including an update operator in the description language'],0
"['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints( #AUTHOR_TAG ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .', 'Encoding']","['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints( #AUTHOR_TAG ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .', 'Encoding']","['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints( #AUTHOR_TAG ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .', 'Enc']","['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints( #AUTHOR_TAG ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .', '']",0
"['powerful mechanism of lexical rules( #AUTHOR_TAG ) has been used in many natural language processing systems .', 'In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper']","['powerful mechanism of lexical rules( #AUTHOR_TAG ) has been used in many natural language processing systems .', 'In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper']","['powerful mechanism of lexical rules( #AUTHOR_TAG ) has been used in many natural language processing systems .', 'In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper']","['powerful mechanism of lexical rules( #AUTHOR_TAG ) has been used in many natural language processing systems .', 'In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper']",0
"['', 'This idea of preserving properties can be considered an instance of the well-known frame problem in AT( #AUTHOR_TAG ) , and we will therefore refer to the specifications left implicit by the linguist as the frame specification , or simply frame , of a lexical rule .', 'Not']","['', 'This idea of preserving properties can be considered an instance of the well-known frame problem in AT( #AUTHOR_TAG ) , and we will therefore refer to the specifications left implicit by the linguist as the frame specification , or simply frame , of a lexical rule .', 'Not']","['', 'This idea of preserving properties can be considered an instance of the well-known frame problem in AT( #AUTHOR_TAG ) , and we will therefore refer to the specifications left implicit by the linguist as the frame specification , or simply frame , of a lexical rule .', 'Not']","['', 'This idea of preserving properties can be considered an instance of the well-known frame problem in AT( #AUTHOR_TAG ) , and we will therefore refer to the specifications left implicit by the linguist as the frame specification , or simply frame , of a lexical rule .', '']",1
"['', 'Using an accumulator passing technique( #AUTHOR_TAG ) , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .', '']","['', 'Using an accumulator passing technique( #AUTHOR_TAG ) , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .', '']","['', 'Using an accumulator passing technique( #AUTHOR_TAG ) , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .', '']","['', 'Each transition in the automaton is translated into a definite relation in which the corresponding lexical rule predicate is called, and each final state is encoded by a unit clause.', 'Using an accumulator passing technique( #AUTHOR_TAG ) , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .', '']",5
"['15#AUTHOR_TAG show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .', 'We here assume unification as the application criterion, which formally corresponds to the conjunction of descriptions and their conversion to normal form (G6tz 1994).', 'Computationally, a subsumption test could equally well be used in our compiler']","['We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects.', '15#AUTHOR_TAG show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .', 'We here assume unification as the application criterion, which formally corresponds to the conjunction of descriptions and their conversion to normal form (G6tz 1994).', 'Computationally, a subsumption test could equally well be used in our compiler']","['15#AUTHOR_TAG show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .', 'We here assume unification as the application criterion, which formally corresponds to the conjunction of descriptions and their conversion to normal form (G6tz 1994).', 'Computationally, a subsumption test could equally well be used in our compiler']","['', '14 We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects.', '15#AUTHOR_TAG show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .', 'We here assume unification as the application criterion, which formally corresponds to the conjunction of descriptions and their conversion to normal form (G6tz 1994).', 'Computationally, a subsumption test could equally well be used in our compiler']",0
"['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992;#AUTHOR_TAG ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992;#AUTHOR_TAG ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992;#AUTHOR_TAG ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992;#AUTHOR_TAG ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', '']",1
"['information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; Oliva 1994 ;#AUTHOR_TAG ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially']","['information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; Oliva 1994 ;#AUTHOR_TAG ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially']","['ical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; Oliva 1994 ;#AUTHOR_TAG ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; Oliva 1994 ;#AUTHOR_TAG ; Opalka 1995 ; Sanfilippo 1995 ) .', '']",1
"['', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and#AUTHOR_TAG ; Gerdemann 1995 ) .', '5']","['', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and#AUTHOR_TAG ; Gerdemann 1995 ) .', '5']","['', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and#AUTHOR_TAG ; Gerdemann 1995 ) .', '']","['', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and#AUTHOR_TAG ; Gerdemann 1995 ) .', '']",0
"['that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule( #AUTHOR_TAG ) to operate on those raised elements .', '']","['that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule( #AUTHOR_TAG ) to operate on those raised elements .', '']","['that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule( #AUTHOR_TAG ) to operate on those raised elements .', 'Also an analysis treating adjunct extraction via']",['( #AUTHOR_TAG )'],0
"['A linguistic example based on the signature given by#AUTHOR_TAG would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given byPollard and Sag (1994, p. 360 , fn. 20).', '']","['16 A linguistic example based on the signature given by#AUTHOR_TAG would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given byPollard and Sag (1994, p. 360 , fn. 20).', '']","['16 A linguistic example based on the signature given by#AUTHOR_TAG would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given byPollard and Sag (1994, p. 360 , fn. 20).', '']","['16 A linguistic example based on the signature given by#AUTHOR_TAG would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given byPollard and Sag (1994, p. 360 , fn. 20).', '']",0
"['', 'The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and#AUTHOR_TAG , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program']","['', 'The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and#AUTHOR_TAG , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program']","['', 'The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and#AUTHOR_TAG , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program']","['', 'The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and#AUTHOR_TAG , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program']",2
"['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification( #AUTHOR_TAG ; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; Sanfilippo 1995 )']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification( #AUTHOR_TAG ; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; Sanfilippo 1995 )']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification( #AUTHOR_TAG ; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; Sanfilippo 1995 )']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification( #AUTHOR_TAG ; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy']",1
"['information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ;#AUTHOR_TAG ) .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attach']","['information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ;#AUTHOR_TAG ) .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy']","['ical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ;#AUTHOR_TAG ) .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy']","['ical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ;#AUTHOR_TAG ) .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy']",1
"['This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule( #AUTHOR_TAG ) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via']","['This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule( #AUTHOR_TAG ) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via lexical rules']","['html 1 This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule( #AUTHOR_TAG ) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via']","['', '/b4home.html 1 This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule( #AUTHOR_TAG ) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon']",0
"['on the research results reported in#AUTHOR_TAG , 1996 ) , we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG .', '']","['on the research results reported in#AUTHOR_TAG , 1996 ) , we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG .', '']","['on the research results reported in#AUTHOR_TAG , 1996 ) , we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG .', '']","['on the research results reported in#AUTHOR_TAG , 1996 ) , we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG .', '']",4
"['common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB( #AUTHOR_TAG ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules ( Copestake 1993 , 31 ) .', '']","['common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB( #AUTHOR_TAG ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules ( Copestake 1993 , 31 ) .', '']","['common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB( #AUTHOR_TAG ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules ( Copestake 1993 , 31 ) .', '']","['common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB( #AUTHOR_TAG ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules ( Copestake 1993 , 31 ) .', '']",1
"[', it seems to be necessary to split up the lexical rule to make each instance deal with a specific case.', 'In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value.', 'In the latter case, we can also take care of transferring the value of z.', 'However , as discussed by#AUTHOR_TAG , creating several instances of lexical rules can be avoided .', '']","['a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case.', 'In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value.', 'In the latter case, we can also take care of transferring the value of z.', 'However , as discussed by#AUTHOR_TAG , creating several instances of lexical rules can be avoided .', '']","['applying a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case.', 'In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value.', 'In the latter case, we can also take care of transferring the value of z.', 'However , as discussed by#AUTHOR_TAG , creating several instances of lexical rules can be avoided .', '']","['ensure that no information is lost as a result of applying a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case.', 'In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value.', 'In the latter case, we can also take care of transferring the value of z.', 'However , as discussed by#AUTHOR_TAG , creating several instances of lexical rules can be avoided .', '']",4
"['example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented byPollard and Sag ( 1987  , 215 ) in terms of the setup of#AUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 °']","['example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented byPollard and Sag ( 1987  , 215 ) in terms of the setup of#AUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 °']","['example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented byPollard and Sag ( 1987  , 215 ) in terms of the setup of#AUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 °']","['', 'Consider , for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented byPollard and Sag ( 1987  , 215 ) in terms of the setup of#AUTHOR_TAG , ch .', '']",0
"['ical rules have not gone unchallenged as a mechanism for expressing generalizations over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ;#AUTHOR_TAG ; Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).', 'The lexical entries are']","['ical rules have not gone unchallenged as a mechanism for expressing generalizations over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ;#AUTHOR_TAG ; Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).', 'The lexical entries are']","['ical rules have not gone unchallenged as a mechanism for expressing generalizations over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ;#AUTHOR_TAG ; Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).', 'The lexical entries']","['ical rules have not gone unchallenged as a mechanism for expressing generalizations over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ;#AUTHOR_TAG ; Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).', '']",1
"[', for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by#AUTHOR_TAG , 215 ) in terms of the setup ofPollard and Sag ( 1994  , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form']","[', for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by#AUTHOR_TAG , 215 ) in terms of the setup ofPollard and Sag ( 1994  , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2']","[', for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by#AUTHOR_TAG , 215 ) in terms of the setup ofPollard and Sag ( 1994  , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2']","['', 'Consider , for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by#AUTHOR_TAG , 215 ) in terms of the setup ofPollard and Sag ( 1994  , ch .', '']",1
"['setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the description-level lexical rules ( DLRs ;']","['setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the description-level lexical rules ( DLRs ;']","['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the description-level lexical rules ( DLRs ;']","['the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the description-level lexical rules ( DLRs ;']",0
"['', '#AUTHOR_TAG present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .', 'N']","['', '#AUTHOR_TAG present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .', 'NER']","['', '#AUTHOR_TAG present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .', 'N']","['', '#AUTHOR_TAG present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .', '']",0
"['', 'For this mention-pair coreference model Ï\x86 ( u , v ) , we use the same set of features used in#AUTHOR_TAG']","['', 'For this mention-pair coreference model Ï\x86 ( u , v ) , we use the same set of features used in#AUTHOR_TAG']","['', 'For this mention-pair coreference model Ï\x86 ( u , v ) , we use the same set of features used in#AUTHOR_TAG']","['', 'For this mention-pair coreference model Ï\x86 ( u , v ) , we use the same set of features used in#AUTHOR_TAG']",5
"['ufacturers"".', 'In fact , most of the features3 implemented in existing coreference resolution systems rely solely on mention heads( #AUTHOR_TAG )']","['the mention heads are sufficient to support the decisions: ""they"" refers to ""companies"", and ""They"" refers to ""manufacturers"".', 'In fact , most of the features3 implemented in existing coreference resolution systems rely solely on mention heads( #AUTHOR_TAG )']","['ufacturers"".', 'In fact , most of the features3 implemented in existing coreference resolution systems rely solely on mention heads( #AUTHOR_TAG )']","['', 'In both cases, the mention heads are sufficient to support the decisions: ""they"" refers to ""companies"", and ""They"" refers to ""manufacturers"".', 'In fact , most of the features3 implemented in existing coreference resolution systems rely solely on mention heads( #AUTHOR_TAG )']",0
"['', 'For Berkeley system , we use the reported results from#AUTHOR_TAG']","['', 'For Berkeley system , we use the reported results from#AUTHOR_TAG']","['', 'For Berkeley system , we use the reported results from#AUTHOR_TAG']","['', 'For Berkeley system , we use the reported results from#AUTHOR_TAG']",1
"['We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system( Lee et al. , 2011 ) , Berkeley system( #AUTHOR_TAG ) and HOTCoref system ( Bj Â¨ orkelund andKuhn , 2014 ) .', '']","['We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system( Lee et al. , 2011 ) , Berkeley system( #AUTHOR_TAG ) and HOTCoref system ( Bj Â¨ orkelund andKuhn , 2014 ) .', '']","['We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system( Lee et al. , 2011 ) , Berkeley system( #AUTHOR_TAG ) and HOTCoref system ( Bj Â¨ orkelund andKuhn , 2014 ) .', '']","['', 'Baseline Systems We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system( Lee et al. , 2011 ) , Berkeley system( #AUTHOR_TAG ) and HOTCoref system ( Bj Â¨ orkelund andKuhn , 2014 ) .', '']",1
"['2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents( Culotta et al. , 2007 ; #AUTHOR_TAG ) .', '']","['ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents( Culotta et al. , 2007 ; #AUTHOR_TAG ) .', '']","['ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents( Culotta et al. , 2007 ; #AUTHOR_TAG ) .', 'The OntoNotes-5.0 dataset,']","['ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents( Culotta et al. , 2007 ; #AUTHOR_TAG ) .', '']",5
"['%.', 'We then use Illinois Chunker( Punyakanok and Roth , 2001 ) 6 to extract more noun phrases from the text and employ Collins head rules( #AUTHOR_TAG ) to identify their heads .', 'When these extracted heads do not overlap with gold mention heads, we treat them as negative examples']","['', 'We then use Illinois Chunker( Punyakanok and Roth , 2001 ) 6 to extract more noun phrases from the text and employ Collins head rules( #AUTHOR_TAG ) to identify their heads .', 'When these extracted heads do not overlap with gold mention heads, we treat them as negative examples']","['%.', 'We then use Illinois Chunker( Punyakanok and Roth , 2001 ) 6 to extract more noun phrases from the text and employ Collins head rules( #AUTHOR_TAG ) to identify their heads .', 'When these extracted heads do not overlap with gold mention heads, we treat them as negative examples']","['', 'We then use Illinois Chunker( Punyakanok and Roth , 2001 ) 6 to extract more noun phrases from the text and employ Collins head rules( #AUTHOR_TAG ) to identify their heads .', 'When these extracted heads do not overlap with gold mention heads, we treat them as negative examples']",5
"['ention detection is rarely studied as a stand-alone research problem (Recasens et al. (2013) is one key exception).', 'Most coreference resolution work simply mentions it in passing as a module in the pipelined system( #AUTHOR_TAG ; Durrett and Klein , 2013 ; Lee et al. , 2011 ;  Bj Â¨ orkelund andKuhn , 2014 ) .', '']","['ention detection is rarely studied as a stand-alone research problem (Recasens et al. (2013) is one key exception).', 'Most coreference resolution work simply mentions it in passing as a module in the pipelined system( #AUTHOR_TAG ; Durrett and Klein , 2013 ; Lee et al. , 2011 ;  Bj Â¨ orkelund andKuhn , 2014 ) .', '']","['ention detection is rarely studied as a stand-alone research problem (Recasens et al. (2013) is one key exception).', 'Most coreference resolution work simply mentions it in passing as a module in the pipelined system( #AUTHOR_TAG ; Durrett and Klein , 2013 ; Lee et al. , 2011 ;  Bj Â¨ orkelund andKuhn , 2014 ) .', '']","['ention detection is rarely studied as a stand-alone research problem (Recasens et al. (2013) is one key exception).', 'Most coreference resolution work simply mentions it in passing as a module in the pipelined system( #AUTHOR_TAG ; Durrett and Klein , 2013 ; Lee et al. , 2011 ;  Bj Â¨ orkelund andKuhn , 2014 ) .', '']",0
"['on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in#AUTHOR_TAG .', 'The BILOUrepresentation suggests learning classifiers that identify the Beginning']","['on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in#AUTHOR_TAG .', 'The BILOUrepresentation suggests learning classifiers that identify the Beginning, Inside and Last tokens of multi-token chunks as']","['on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in#AUTHOR_TAG .', 'The BILOUrepresentation suggests learning classifiers that identify the Beginning, Inside and Last tokens of multi-token chunks as']","['on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in#AUTHOR_TAG .', 'The BILOUrepresentation suggests learning classifiers that identify the Beginning, Inside and Last tokens of multi-token chunks as well as Unit-length chunks.', '']",4
"['OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task( #AUTHOR_TAG ) , contains 3,145 annotated documents .', 'These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs.', '']","['OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task( #AUTHOR_TAG ) , contains 3,145 annotated documents .', 'These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs.', '']","['', 'The OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task( #AUTHOR_TAG ) , contains 3,145 annotated documents .', 'These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs.', '']","['', 'The OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task( #AUTHOR_TAG ) , contains 3,145 annotated documents .', 'These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs.', '']",5
"['', 'Developed Systems Our developed system is built on the work by#AUTHOR_TAG , using Constrained Latent Left-Linking Model ( CL3M ) as our mention-pair coreference model in the joint framework10 .', '']","['', 'Developed Systems Our developed system is built on the work by#AUTHOR_TAG , using Constrained Latent Left-Linking Model ( CL3M ) as our mention-pair coreference model in the joint framework10 .', '']","['', 'Developed Systems Our developed system is built on the work by#AUTHOR_TAG , using Constrained Latent Left-Linking Model ( CL3M ) as our mention-pair coreference model in the joint framework10 .', '']","['', 'Developed Systems Our developed system is built on the work by#AUTHOR_TAG , using Constrained Latent Left-Linking Model ( CL3M ) as our mention-pair coreference model in the joint framework10 .', '']",5
"['', 'In this paper , we use the Constrained Latent Left-Linking Model ( CL3M ) described in#AUTHOR_TAG in our experiments']","['', 'In this paper , we use the Constrained Latent Left-Linking Model ( CL3M ) described in#AUTHOR_TAG in our experiments']","['', 'In this paper , we use the Constrained Latent Left-Linking Model ( CL3M ) described in#AUTHOR_TAG in our experiments']","['', 'In this paper , we use the Constrained Latent Left-Linking Model ( CL3M ) described in#AUTHOR_TAG in our experiments']",5
"['2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents( #AUTHOR_TAG ; Bengtson and Roth , 2008 ) .', '']","['ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents( #AUTHOR_TAG ; Bengtson and Roth , 2008 ) .', '']","['ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents( #AUTHOR_TAG ; Bengtson and Roth , 2008 ) .', 'The OntoNotes-5.0 dataset,']","['ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents( #AUTHOR_TAG ; Bengtson and Roth , 2008 ) .', '']",5
"['details can be found in#AUTHOR_TAG et al. (2013).', 'The difference here is that we also consider the validity of mention heads using �(u),�(m']","['details can be found in#AUTHOR_TAG et al. (2013).', 'The difference here is that we also consider the validity of mention heads using �(u),�(m']","['details can be found in#AUTHOR_TAG et al. (2013).', 'The difference here is that we also consider the validity of mention heads using �(u),�(m']","['details can be found in#AUTHOR_TAG et al. (2013).', 'The difference here is that we also consider the validity of mention heads using �(u),�(m']",0
"['recent works suggest studying coreference jointly with other tasks.', 'Lee et al. ( 2012 ) model entity coreference and event coreference jointly ;#AUTHOR_TAG consider joint coreference and entity-linking .', '']","['recent works suggest studying coreference jointly with other tasks.', 'Lee et al. ( 2012 ) model entity coreference and event coreference jointly ;#AUTHOR_TAG consider joint coreference and entity-linking .', '']","['recent works suggest studying coreference jointly with other tasks.', 'Lee et al. ( 2012 ) model entity coreference and event coreference jointly ;#AUTHOR_TAG consider joint coreference and entity-linking .', '']","['recent works suggest studying coreference jointly with other tasks.', 'Lee et al. ( 2012 ) model entity coreference and event coreference jointly ;#AUTHOR_TAG consider joint coreference and entity-linking .', '']",0
"[', we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules( #AUTHOR_TAG ) with gold constituency parsing information and gold named entity information .', '']","[', we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules( #AUTHOR_TAG ) with gold constituency parsing information and gold named entity information .', '']","[', we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules( #AUTHOR_TAG ) with gold constituency parsing information and gold named entity information .', '']","['', 'Therefore , we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules( #AUTHOR_TAG ) with gold constituency parsing information and gold named entity information .', '']",5
"['section describes our joint coreference resolution and mention head detection framework.', 'Our work is inspired by the latent left-linking model in#AUTHOR_TAG and the ILP formulation fromChang et al. ( 2011 ) .', '']","['section describes our joint coreference resolution and mention head detection framework.', 'Our work is inspired by the latent left-linking model in#AUTHOR_TAG and the ILP formulation fromChang et al. ( 2011 ) .', '']","['section describes our joint coreference resolution and mention head detection framework.', 'Our work is inspired by the latent left-linking model in#AUTHOR_TAG and the ILP formulation fromChang et al. ( 2011 ) .', '']","['section describes our joint coreference resolution and mention head detection framework.', 'Our work is inspired by the latent left-linking model in#AUTHOR_TAG and the ILP formulation fromChang et al. ( 2011 ) .', '']",5
"['present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0( #AUTHOR_TAG ) .', '(Hovy et al., 2006) .', '']","['present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0( #AUTHOR_TAG ) .', '(Hovy et al., 2006) .', '']","['present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0( #AUTHOR_TAG ) .', '(Hovy et al., 2006) .', '']","['present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0( #AUTHOR_TAG ) .', '(Hovy et al., 2006) .', '']",5
"['we extend the category generator of our previous work, which we will call P CAT .', 'We can define PCAT using a probabilistic grammar( #AUTHOR_TAG ) .', 'The grammar may first generate a start or end category (']","['we extend the category generator of our previous work, which we will call P CAT .', 'We can define PCAT using a probabilistic grammar( #AUTHOR_TAG ) .', 'The grammar may first generate a start or end category (']","['we extend the category generator of our previous work, which we will call P CAT .', 'We can define PCAT using a probabilistic grammar( #AUTHOR_TAG ) .', 'The grammar may first generate a start or end category (']","['', 'We can define PCAT using a probabilistic grammar( #AUTHOR_TAG ) .', 'The grammar may first generate a start or end category ( S , E ) with probability p se or a special tokendeletion category ( D ; explained in §5) with probability p del , or a standard CCG category C']",0
"[""'s CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) ."", 'They found that modeling constituent context aids in parser learning because it is able to capture the observation that the same contexts tend to appear repeatedly in a corpus, even with different constituents.', '']","[""'s CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) ."", 'They found that modeling constituent context aids in parser learning because it is able to capture the observation that the same contexts tend to appear repeatedly in a corpus, even with different constituents.', '']","[""'s CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) ."", 'They found that modeling constituent context aids in parser learning because it is able to capture the observation that the same contexts tend to appear repeatedly in a corpus, even with different constituents.', '']","[""'s CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) ."", 'They found that modeling constituent context aids in parser learning because it is able to capture the observation that the same contexts tend to appear repeatedly in a corpus, even with different constituents.', '']",0
"['', 'In order to estimate the parameters of our model , we develop a blocked sampler based on that of#AUTHOR_TAG to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .', '']","['', 'In order to estimate the parameters of our model , we develop a blocked sampler based on that of#AUTHOR_TAG to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .', '']","['', 'In order to estimate the parameters of our model , we develop a blocked sampler based on that of#AUTHOR_TAG to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .', '']","['', 'In order to estimate the parameters of our model , we develop a blocked sampler based on that of#AUTHOR_TAG to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .', '']",5
"['', 'We evaluated on the English CCGBank( Hockenmaier and Steedman , 2007 ) , which is a transformation of the Penn Treebank( #AUTHOR_TAG ) ; the']","['SCM extends.', 'We evaluated on the English CCGBank( Hockenmaier and Steedman , 2007 ) , which is a transformation of the Penn Treebank( #AUTHOR_TAG ) ; the']","['SCM extends.', 'We evaluated on the English CCGBank( Hockenmaier and Steedman , 2007 ) , which is a transformation of the Penn Treebank( #AUTHOR_TAG ) ;']",['( #AUTHOR_TAG )'],5
"[""right-side context of a non-terminal category -- the probability of generating a category to the right of the current constituent 's category -- corresponds directly to the category transitions used for the HMM supertagger of#AUTHOR_TAG ."", ""Thus, the right-side context prior mean θ RCTX-0 t can be biased in exactly the same way as the HMM supertagger's transitions: toward context supertags that connect to the constituent label""]","[""right-side context of a non-terminal category -- the probability of generating a category to the right of the current constituent 's category -- corresponds directly to the category transitions used for the HMM supertagger of#AUTHOR_TAG ."", ""Thus, the right-side context prior mean θ RCTX-0 t can be biased in exactly the same way as the HMM supertagger's transitions: toward context supertags that connect to the constituent label""]","[""right-side context of a non-terminal category -- the probability of generating a category to the right of the current constituent 's category -- corresponds directly to the category transitions used for the HMM supertagger of#AUTHOR_TAG ."", ""Thus, the right-side context prior mean θ RCTX-0 t can be biased in exactly the same way as the HMM supertagger's transitions: toward context supertags that connect to the constituent label""]","[""right-side context of a non-terminal category -- the probability of generating a category to the right of the current constituent 's category -- corresponds directly to the category transitions used for the HMM supertagger of#AUTHOR_TAG ."", ""Thus, the right-side context prior mean θ RCTX-0 t can be biased in exactly the same way as the HMM supertagger's transitions: toward context supertags that connect to the constituent label""]",1
"['set.', 'We use the same splits as#AUTHOR_TAG .', 'Since these treebanks use special representations for conjunctions, we chose to rewrite the trees to use conjunction categories of the form (X\\X)/']","['set.', 'We use the same splits as#AUTHOR_TAG .', 'Since these treebanks use special representations for conjunctions, we chose to rewrite the trees to use conjunction categories of the form (X\\X)/X rather than introducing special conjunction rules.', '']","['a test set.', 'We use the same splits as#AUTHOR_TAG .', 'Since these treebanks use special representations for conjunctions, we chose to rewrite the trees to use conjunction categories of the form (X\\X)/X rather than introducing special conjunction rules.', '']","['corpus was divided into four distinct data sets: a set from which we extract the tag dictionaries, a set of raw (unannotated) sentences, a development set, and a test set.', 'We use the same splits as#AUTHOR_TAG .', 'Since these treebanks use special representations for conjunctions, we chose to rewrite the trees to use conjunction categories of the form (X\\X)/X rather than introducing special conjunction rules.', '']",5
"['', 'This is similar to the ""deletion"" strategy employed by#AUTHOR_TAG , but we do it directly in the grammar .', 'We add un']","['', 'This is similar to the ""deletion"" strategy employed by#AUTHOR_TAG , but we do it directly in the grammar .', 'We add unary']","['', 'This is similar to the ""deletion"" strategy employed by#AUTHOR_TAG , but we do it directly in the grammar .', 'We add un']","['', 'This is similar to the ""deletion"" strategy employed by#AUTHOR_TAG , but we do it directly in the grammar .', 'We add unary rules of the form D →u for every potential supertag u in the tree.', '']",1
"['', 'We previously showed that incorporating this intuition into a Bayesian prior can help train a CCG supertagger( #AUTHOR_TAG )']","['', 'We previously showed that incorporating this intuition into a Bayesian prior can help train a CCG supertagger( #AUTHOR_TAG )']","['', 'We previously showed that incorporating this intuition into a Bayesian prior can help train a CCG supertagger( #AUTHOR_TAG )']","['', 'We previously showed that incorporating this intuition into a Bayesian prior can help train a CCG supertagger( #AUTHOR_TAG )']",2
"['employ the same procedure as our previous work for setting the terminal production prior distributions _TERM-0(w) by estimating word-given- category relationships from the weak supervision : the tag dictionary and raw corpus( #AUTHOR_TAG ; Garrette et al. , 2015 ) .']","['employ the same procedure as our previous work for setting the terminal production prior distributions _TERM-0(w) by estimating word-given- category relationships from the weak supervision : the tag dictionary and raw corpus( #AUTHOR_TAG ; Garrette et al. , 2015 ) .4', 'This procedure attempts to automatically estimate the frequency of each word/tag combination by dividing the number of raw-corpus occurrences of each word in the dictionary evenly across all of its associated tags.', 'These']","['employ the same procedure as our previous work for setting the terminal production prior distributions _TERM-0(w) by estimating word-given- category relationships from the weak supervision : the tag dictionary and raw corpus( #AUTHOR_TAG ; Garrette et al. , 2015 ) .4', 'This procedure attempts to automatically estimate the frequency of each word/tag combination by dividing the number of raw-corpus occurrences of each word in the dictionary evenly across all of its associated tags.', 'These counts are then combined with']","['employ the same procedure as our previous work for setting the terminal production prior distributions _TERM-0(w) by estimating word-given- category relationships from the weak supervision : the tag dictionary and raw corpus( #AUTHOR_TAG ; Garrette et al. , 2015 ) .4', 'This procedure attempts to automatically estimate the frequency of each word/tag combination by dividing the number of raw-corpus occurrences of each word in the dictionary evenly across all of its associated tags.', '']",5
"['CCM, this model is deficient since the same supertags are generated multiple times, and parses with conflicting supertags are not valid.', 'Since we are not generating from the model , this does not introduce difficulties( #AUTHOR_TAG )']","['CCM, this model is deficient since the same supertags are generated multiple times, and parses with conflicting supertags are not valid.', 'Since we are not generating from the model , this does not introduce difficulties( #AUTHOR_TAG )']","['CCM, this model is deficient since the same supertags are generated multiple times, and parses with conflicting supertags are not valid.', 'Since we are not generating from the model , this does not introduce difficulties( #AUTHOR_TAG )']","['CCM, this model is deficient since the same supertags are generated multiple times, and parses with conflicting supertags are not valid.', 'Since we are not generating from the model , this does not introduce difficulties( #AUTHOR_TAG )']",4
"['.', 'We further add rules for combining with punctuation to the left and right and allow for the merge rule X â\x86\x92 X X of#AUTHOR_TAG']","['binary grammar rules.', 'We further add rules for combining with punctuation to the left and right and allow for the merge rule X â\x86\x92 X X of#AUTHOR_TAG']","['binary grammar rules.', 'We further add rules for combining with punctuation to the left and right and allow for the merge rule X â\x86\x92 X X of#AUTHOR_TAG']","['', 'We further add rules for combining with punctuation to the left and right and allow for the merge rule X â\x86\x92 X X of#AUTHOR_TAG']",5
"['sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed byGoodman ( 1998 ) and used by#AUTHOR_TAG that samples entire parse trees .', '']","['sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed byGoodman ( 1998 ) and used by#AUTHOR_TAG that samples entire parse trees .', '']","['sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed byGoodman ( 1998 ) and used by#AUTHOR_TAG that samples entire parse trees .', '']","['sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed byGoodman ( 1998 ) and used by#AUTHOR_TAG that samples entire parse trees .', '']",5
"['', 'Our strategy is based on the approach presented by#AUTHOR_TAG .', 'At a']","['solution.', 'Our strategy is based on the approach presented by#AUTHOR_TAG .', 'At a']","['an approximate solution.', 'Our strategy is based on the approach presented by#AUTHOR_TAG .', 'At a high level, we alternate between resampling model parameters (_ROOT']","['', 'Our strategy is based on the approach presented by#AUTHOR_TAG .', 'At a high level, we alternate between resampling model parameters (_ROOT, _BIN, _ ,_ ,_,_ ,_ ) given the current set of parse trees and resampling those trees given the current model parameters and observed word sequences.', '']",5
"['important example is the constituentcontext model ( CCM ) of#AUTHOR_TAG , which was specifically designed to capture the linguistic observation made byRadford ( 1988 ) that there are regularities to the contexts in which constituents appear']","['important example is the constituentcontext model ( CCM ) of#AUTHOR_TAG , which was specifically designed to capture the linguistic observation made byRadford ( 1988 ) that there are regularities to the contexts in which constituents appear']","['important example is the constituentcontext model ( CCM ) of#AUTHOR_TAG , which was specifically designed to capture the linguistic observation made byRadford ( 1988 ) that there are regularities to the contexts in which constituents appear .', 'This phenomenon, known as substitutability']","['important example is the constituentcontext model ( CCM ) of#AUTHOR_TAG , which was specifically designed to capture the linguistic observation made byRadford ( 1988 ) that there are regularities to the contexts in which constituents appear .', 'This phenomenon, known as substitutability, says that phrases of the same type appear in similar contexts.', 'For example, the part-of-speech (POS) sequence ADJ NOUN frequently occurs between the tags DET and VERB.', 'This DET-VERB context also frequently applies to the single-word sequence NOUN and to ADJ ADJ NOUN.', '']",0
"['', 'We follow#AUTHOR_TAG in allowing a small set of generic , linguistically-plausible unary and binary grammar rules .', '']","['', 'We follow#AUTHOR_TAG in allowing a small set of generic , linguistically-plausible unary and binary grammar rules .', '']","['', 'We follow#AUTHOR_TAG in allowing a small set of generic , linguistically-plausible unary and binary grammar rules .', '']","['', 'We follow#AUTHOR_TAG in allowing a small set of generic , linguistically-plausible unary and binary grammar rules .', '']",5
"['.', 'Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by#AUTHOR_TAG .', 'The']","['', 'Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by#AUTHOR_TAG .', 'The']","['', 'Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by#AUTHOR_TAG .', 'The motivation for the features was to capture declaratively decisions made by the randomized SPG.', '']","['', 'Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by#AUTHOR_TAG .', 'The motivation for the features was to capture declaratively decisions made by the randomized SPG.', '']",1
"['vious work in sentence planning in the natural language generation ( NLG ) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus ( see( #AUTHOR_TAG ) for a recent example with further references ) .', 'This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions(Hovy and Wanner, 1996) , and it is difficult to']","['vious work in sentence planning in the natural language generation ( NLG ) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus ( see( #AUTHOR_TAG ) for a recent example with further references ) .', 'This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions(Hovy and Wanner, 1996) , and it is difficult to']","['vious work in sentence planning in the natural language generation ( NLG ) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus ( see( #AUTHOR_TAG ) for a recent example with further references ) .', 'This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions(Hovy and Wanner, 1996) , and it is difficult to']","['vious work in sentence planning in the natural language generation ( NLG ) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus ( see( #AUTHOR_TAG ) for a recent example with further references ) .', 'This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions(Hovy and Wanner, 1996) , and it is difficult to develop new applications quickly.', '']",0
"['Our primary contribution is', 'a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to( #AUTHOR_TAG ; Freund et al. , 1998 )']","['Our primary contribution is', 'a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to( #AUTHOR_TAG ; Freund et al. , 1998 )']","['Our primary contribution is', 'a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to( #AUTHOR_TAG ; Freund et al. , 1998 )']","['', 'a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to( #AUTHOR_TAG ; Freund et al. , 1998 )']",1
"['', 'These operations are not domain-specific and are similar to those of previous aggregation components( Rambow and Korelsky ,1992 ; #AUTHOR_TAG ; Danlos , 2000 ) , although the various MERGE operations are , to our knowledge , novel in this form']","['', 'These operations are not domain-specific and are similar to those of previous aggregation components( Rambow and Korelsky ,1992 ; #AUTHOR_TAG ; Danlos , 2000 ) , although the various MERGE operations are , to our knowledge , novel in this form']","['', 'These operations are not domain-specific and are similar to those of previous aggregation components( Rambow and Korelsky ,1992 ; #AUTHOR_TAG ; Danlos , 2000 ) , although the various MERGE operations are , to our knowledge , novel in this form']","['', 'These operations are not domain-specific and are similar to those of previous aggregation components( Rambow and Korelsky ,1992 ; #AUTHOR_TAG ; Danlos , 2000 ) , although the various MERGE operations are , to our knowledge , novel in this form']",0
"['', 'The representations used byDanlos ( 2000 ) ,Gardent and Webber ( 1998 ) , or#AUTHOR_TAG are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes']","['', 'The representations used byDanlos ( 2000 ) ,Gardent and Webber ( 1998 ) , or#AUTHOR_TAG are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes']","['is inspired by(Lavoie and Rambow, 1998) .', 'The representations used byDanlos ( 2000 ) ,Gardent and Webber ( 1998 ) , or#AUTHOR_TAG are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes .', '']","['', 'The representations used byDanlos ( 2000 ) ,Gardent and Webber ( 1998 ) , or#AUTHOR_TAG are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes .', '']",0
"['2The algorithm was implemented by the the authors , following the description in#AUTHOR_TAG']","['2The algorithm was implemented by the the authors , following the description in#AUTHOR_TAG']","['2The algorithm was implemented by the the authors , following the description in#AUTHOR_TAG']","['2The algorithm was implemented by the the authors , following the description in#AUTHOR_TAG']",5
"['paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system( #AUTHOR_TAG )']","['paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system( #AUTHOR_TAG )']","['paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system( #AUTHOR_TAG )']","['paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system( #AUTHOR_TAG )']",1
"['data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by#AUTHOR_TAG']","['data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by#AUTHOR_TAG']","['data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by#AUTHOR_TAG']","['data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by#AUTHOR_TAG']",5
"[""\x80¢ The regular TBL , as described in section 2 ; â\x80¢ An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; â\x80¢ The FastTBL algorithm ; â\x80¢ The ICA algorithm( #AUTHOR_TAG )""]","[""\x80¢ The regular TBL , as described in section 2 ; â\x80¢ An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; â\x80¢ The FastTBL algorithm ; â\x80¢ The ICA algorithm( #AUTHOR_TAG )""]","[""\x80¢ The regular TBL , as described in section 2 ; â\x80¢ An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; â\x80¢ The FastTBL algorithm ; â\x80¢ The ICA algorithm( #AUTHOR_TAG )""]","[""\x80¢ The regular TBL , as described in section 2 ; â\x80¢ An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; â\x80¢ The FastTBL algorithm ; â\x80¢ The ICA algorithm( #AUTHOR_TAG )""]",1
['ICA system( #AUTHOR_TAG ) aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance'],['ICA system( #AUTHOR_TAG ) aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance'],['ICA system( #AUTHOR_TAG ) aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance'],['ICA system( #AUTHOR_TAG ) aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance'],0
"['the tree-cut technique described above , our previous work( #AUTHOR_TAG ) extracted systematic polysemy from WordNet .', '']","['the tree-cut technique described above , our previous work( #AUTHOR_TAG ) extracted systematic polysemy from WordNet .', '']","['the tree-cut technique described above , our previous work( #AUTHOR_TAG ) extracted systematic polysemy from WordNet .', '']","['the tree-cut technique described above , our previous work( #AUTHOR_TAG ) extracted systematic polysemy from WordNet .', '']",2
"['', 'In our previous work( #AUTHOR_TAG ) , we applied this method to a small subset of WordNet nouns and showed potential applicability .', '']","['', 'In our previous work( #AUTHOR_TAG ) , we applied this method to a small subset of WordNet nouns and showed potential applicability .', '']","['', 'In our previous work( #AUTHOR_TAG ) , we applied this method to a small subset of WordNet nouns and showed potential applicability .', '']","['', 'In our previous work( #AUTHOR_TAG ) , we applied this method to a small subset of WordNet nouns and showed potential applicability .', 'In the current work, we applied the method to all nouns and verbs in WordNet, and built a lexicon in which word senses are partitioned by systematic polysemy.', '']",2
"['order to obtain semantic representations of each word , we apply our previous strategy( #AUTHOR_TAG ) .', '']","['order to obtain semantic representations of each word , we apply our previous strategy( #AUTHOR_TAG ) .', '']","['order to obtain semantic representations of each word , we apply our previous strategy( #AUTHOR_TAG ) .', '']","['order to obtain semantic representations of each word , we apply our previous strategy( #AUTHOR_TAG ) .', '']",2
"['', 'Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes-Riley and Litman , 2011 a ;#AUTHOR_TAG ) , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges( Schuller et al. , 2010 ; Schuller et al. , 2009 b ) and made freely']","['', 'Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes-Riley and Litman , 2011 a ;#AUTHOR_TAG ) , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges( Schuller et al. , 2010 ; Schuller et al. , 2009 b ) and made freely']","['', 'Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes-Riley and Litman , 2011 a ;#AUTHOR_TAG ) , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges( Schuller et al. , 2010 ; Schuller et al. , 2009 b ) and made freely']","['', 'Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes-Riley and Litman , 2011 a ;#AUTHOR_TAG ) , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges( Schuller et al. , 2010 ; Schuller et al. , 2009 b ) and made freely available in the openSMILE Toolkit( Florian et al. , 2010 ) .', '']",2
"['ite state transducers , which can be learned from bilingual corpora , have been proposed for automatic translation( Amengual et al. , 2000 ) , as have been bilingual stochastic grammars( #AUTHOR_TAG )']","['ite state transducers , which can be learned from bilingual corpora , have been proposed for automatic translation( Amengual et al. , 2000 ) , as have been bilingual stochastic grammars( #AUTHOR_TAG )']","['ite state transducers , which can be learned from bilingual corpora , have been proposed for automatic translation( Amengual et al. , 2000 ) , as have been bilingual stochastic grammars( #AUTHOR_TAG )']","['ite state transducers , which can be learned from bilingual corpora , have been proposed for automatic translation( Amengual et al. , 2000 ) , as have been bilingual stochastic grammars( #AUTHOR_TAG )']",0
['also shows the structural identity to bilingual grammars as used in( #AUTHOR_TAG )'],['also shows the structural identity to bilingual grammars as used in( #AUTHOR_TAG )'],['also shows the structural identity to bilingual grammars as used in( #AUTHOR_TAG )'],['also shows the structural identity to bilingual grammars as used in( #AUTHOR_TAG )'],5
['can be shown( #AUTHOR_TAG ) that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values .3 There is no requirement that the components of f represent disjoint or'],['can be shown( #AUTHOR_TAG ) that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values .3 There is no requirement that the components of f represent disjoint or statistically independent events'],['can be shown( #AUTHOR_TAG ) that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values .3 There is no requirement that the components of f represent disjoint or'],['can be shown( #AUTHOR_TAG ) that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values .3 There is no requirement that the components of f represent disjoint or statistically independent events'],4
['describe an efficient algorithm for accomplishing this in which approximations to Pst ( TIS ) are computed in parallel for all ( new ) features ft by holding all weights in the existing model fixed and optimizing only over a8t'],['describe an efficient algorithm for accomplishing this in which approximations to Pst ( TIS ) are computed in parallel for all ( new ) features ft by holding all weights in the existing model fixed and optimizing only over a8t'],['describe an efficient algorithm for accomplishing this in which approximations to Pst ( TIS ) are computed in parallel for all ( new ) features ft by holding all weights in the existing model fixed and optimizing only over a8t'],['describe an efficient algorithm for accomplishing this in which approximations to Pst ( TIS ) are computed in parallel for all ( new ) features ft by holding all weights in the existing model fixed and optimizing only over a8t'],0
['statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence ( MEMD ) modeling( #AUTHOR_TAG )'],['statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence ( MEMD ) modeling( #AUTHOR_TAG )'],['statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence ( MEMD ) modeling( #AUTHOR_TAG )'],['statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence ( MEMD ) modeling( #AUTHOR_TAG )'],5
"['( #AUTHOR_TAG ) show , lexical information improves on NP and VP chunking as well']","['( #AUTHOR_TAG ) show , lexical information improves on NP and VP chunking as well']","['( #AUTHOR_TAG ) show , lexical information improves on NP and VP chunking as well']","['( #AUTHOR_TAG ) show , lexical information improves on NP and VP chunking as well']",3
"['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by#AUTHOR_TAG ,Collins ( 1997 ) , andRatnaparkhi ( 1997 ) , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by#AUTHOR_TAG ,Collins ( 1997 ) , andRatnaparkhi ( 1997 ) , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by#AUTHOR_TAG ,Collins ( 1997 ) , andRatnaparkhi ( 1997 ) , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by#AUTHOR_TAG ,Collins ( 1997 ) , andRatnaparkhi ( 1997 ) , and became a common testbed']",1
"['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,Magerman ( 1995 ) ,#AUTHOR_TAG ,Ratnaparkhi ( 1997 ) , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,Magerman ( 1995 ) ,#AUTHOR_TAG ,Ratnaparkhi ( 1997 ) , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,Magerman ( 1995 ) ,#AUTHOR_TAG ,Ratnaparkhi ( 1997 ) , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,Magerman ( 1995 ) ,#AUTHOR_TAG ,Ratnaparkhi ( 1997 ) , andSekine ( 1998 ) )']",0
"['is not aimed at handling dependencies , which require heavy use of lexical information( #AUTHOR_TAG , for PP attachment )']","['is not aimed at handling dependencies , which require heavy use of lexical information( #AUTHOR_TAG , for PP attachment )']","['is not aimed at handling dependencies , which require heavy use of lexical information( #AUTHOR_TAG , for PP attachment )']","['is not aimed at handling dependencies , which require heavy use of lexical information( #AUTHOR_TAG , for PP attachment )']",1
['approach for partial parsing was presented by#AUTHOR_TAG'],['approach for partial parsing was presented by#AUTHOR_TAG'],['approach for partial parsing was presented by#AUTHOR_TAG'],['approach for partial parsing was presented by#AUTHOR_TAG'],0
"['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,Magerman ( 1995 ) ,Collins ( 1997 ) ,#AUTHOR_TAG , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,Magerman ( 1995 ) ,Collins ( 1997 ) ,#AUTHOR_TAG , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,Magerman ( 1995 ) ,Collins ( 1997 ) ,#AUTHOR_TAG , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,Magerman ( 1995 ) ,Collins ( 1997 ) ,#AUTHOR_TAG , andSekine ( 1998 ) )']",0
"['results are lower than those of full parsers , e.g. ,#AUTHOR_TAG as might be expected since much less structural data , and no lexical data are being used']","['results are lower than those of full parsers , e.g. ,#AUTHOR_TAG as might be expected since much less structural data , and no lexical data are being used']","['results are lower than those of full parsers , e.g. ,#AUTHOR_TAG as might be expected since much less structural data , and no lexical data are being used']","['results are lower than those of full parsers , e.g. ,#AUTHOR_TAG as might be expected since much less structural data , and no lexical data are being used']",1
"['a similar vain toSkut and Brants ( 1998 ) and#AUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures']","['a similar vain toSkut and Brants ( 1998 ) and#AUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures']","['a similar vain toSkut and Brants ( 1998 ) and#AUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures']","['a similar vain toSkut and Brants ( 1998 ) and#AUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures']",3
"['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,#AUTHOR_TAG ,Collins ( 1997 ) ,Ratnaparkhi ( 1997 ) , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,#AUTHOR_TAG ,Collins ( 1997 ) ,Ratnaparkhi ( 1997 ) , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,#AUTHOR_TAG ,Collins ( 1997 ) ,Ratnaparkhi ( 1997 ) , andSekine ( 1998 ) )']","['variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. ,Bod ( 1992 ) ,#AUTHOR_TAG ,Collins ( 1997 ) ,Ratnaparkhi ( 1997 ) , andSekine ( 1998 ) )']",0
"['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used byMagerman ( 1995 ) ,Collins ( 1997 ) , and#AUTHOR_TAG , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used byMagerman ( 1995 ) ,Collins ( 1997 ) , and#AUTHOR_TAG , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used byMagerman ( 1995 ) ,Collins ( 1997 ) , and#AUTHOR_TAG , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used byMagerman ( 1995 ) ,Collins ( 1997 ) , and#AUTHOR_TAG , and became a common testbed']",1
"['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used byMagerman ( 1995 ) ,#AUTHOR_TAG , andRatnaparkhi ( 1997 ) , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used byMagerman ( 1995 ) ,#AUTHOR_TAG , andRatnaparkhi ( 1997 ) , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used byMagerman ( 1995 ) ,#AUTHOR_TAG , andRatnaparkhi ( 1997 ) , and became a common testbed']","['system was trained on the Penn Treebank( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used byMagerman ( 1995 ) ,#AUTHOR_TAG , andRatnaparkhi ( 1997 ) , and became a common testbed']",1
"['approach to partial parsing was presented by#AUTHOR_TAG , who extended a shallow-parsing technique to partial parsing']","['approach to partial parsing was presented by#AUTHOR_TAG , who extended a shallow-parsing technique to partial parsing']","['approach to partial parsing was presented by#AUTHOR_TAG , who extended a shallow-parsing technique to partial parsing']","['approach to partial parsing was presented by#AUTHOR_TAG , who extended a shallow-parsing technique to partial parsing']",0
"['a similar vain to#AUTHOR_TAG andBuchholz et al. ( 1999 ) , the method extends an existing flat shallow-parsing method to handle composite structures']","['a similar vain to#AUTHOR_TAG andBuchholz et al. ( 1999 ) , the method extends an existing flat shallow-parsing method to handle composite structures']","['a similar vain to#AUTHOR_TAG andBuchholz et al. ( 1999 ) , the method extends an existing flat shallow-parsing method to handle composite structures']","['a similar vain to#AUTHOR_TAG andBuchholz et al. ( 1999 ) , the method extends an existing flat shallow-parsing method to handle composite structures']",3
"['', 'To quantify the relative strengths of these transitive inferences ,#AUTHOR_TAG propose to assign a weight to each link .', 'Say the order a, b occurs m times and the pair {a, b} occurs n times in total.', 'Then the weight of the pair a → b is']","['', 'To quantify the relative strengths of these transitive inferences ,#AUTHOR_TAG propose to assign a weight to each link .', 'Say the order a, b occurs m times and the pair {a, b} occurs n times in total.', 'Then the weight of the pair a → b is']","['', 'To quantify the relative strengths of these transitive inferences ,#AUTHOR_TAG propose to assign a weight to each link .', 'Say the order a, b occurs m times and the pair {a, b} occurs n times in total.', 'Then the weight of the pair a → b is']","['uitively, the evidence for the first order is quite a bit stronger than the evidence for the second.', 'The first ordered pairs are more frequent, as are the individual adjectives involved.', 'To quantify the relative strengths of these transitive inferences ,#AUTHOR_TAG propose to assign a weight to each link .', 'Say the order a, b occurs m times and the pair {a, b} occurs n times in total.', 'Then the weight of the pair a → b is']",0
"['distributional clustering techniques ( Sch Â¨ utze , 1992 ;#AUTHOR_TAG ) could be applied to extract semantic classes from the corpus itself .', 'Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results']","['distributional clustering techniques ( Sch Â¨ utze , 1992 ;#AUTHOR_TAG ) could be applied to extract semantic classes from the corpus itself .', 'Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results']","['distributional clustering techniques ( Sch Â¨ utze , 1992 ;#AUTHOR_TAG ) could be applied to extract semantic classes from the corpus itself .', 'Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results']","['', 'More generally , distributional clustering techniques ( Sch Â¨ utze , 1992 ;#AUTHOR_TAG ) could be applied to extract semantic classes from the corpus itself .', 'Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results']",3
"['simplest strategy for ordering adjectives is what#AUTHOR_TAG call the direct evidence method .', '']","['simplest strategy for ordering adjectives is what#AUTHOR_TAG call the direct evidence method .', '']","['simplest strategy for ordering adjectives is what#AUTHOR_TAG call the direct evidence method .', '']","['simplest strategy for ordering adjectives is what#AUTHOR_TAG call the direct evidence method .', 'To order the pair {a, b}, count how many times the ordered sequences a, b and b, a appear in the training data and output the pair in the order which occurred more often']",0
"['be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature(Dietterich, 1997) .', 'In particular , boosting( Schapire , 1999 ; #AUTHOR_TAG ) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly']","['be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature(Dietterich, 1997) .', 'In particular , boosting( Schapire , 1999 ; #AUTHOR_TAG ) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly']","['worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature(Dietterich, 1997) .', 'In particular , boosting( Schapire , 1999 ; #AUTHOR_TAG ) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly']","['', 'It would be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature(Dietterich, 1997) .', 'In particular , boosting( Schapire , 1999 ; #AUTHOR_TAG ) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly']",3
"['', '#AUTHOR_TAG propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .', '']","['', '#AUTHOR_TAG propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .', '']","['', '#AUTHOR_TAG propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .', '']","['', '#AUTHOR_TAG propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .', '']",0
"['problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system.', ""One approach to this more general problem , taken by the ` Nitrogen ' generator( #AUTHOR_TAG a ;Langkilde and Knight , 1998 b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."", 'Langkilde and']","['problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system.', ""One approach to this more general problem , taken by the ` Nitrogen ' generator( #AUTHOR_TAG a ;Langkilde and Knight , 1998 b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."", 'Langkilde and']","['problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system.', ""One approach to this more general problem , taken by the ` Nitrogen ' generator( #AUTHOR_TAG a ;Langkilde and Knight , 1998 b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."", 'Langkilde and']","['problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system.', ""One approach to this more general problem , taken by the ` Nitrogen ' generator( #AUTHOR_TAG a ;Langkilde and Knight , 1998 b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."", '']",5
"['availability of toolkits for this weighted case(Mohri et al., 1998; vanNoord and Gerdemann, 2001) promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition( Pereira and Riley , 1997 ) and machine translation( #AUTHOR_TAG ) ."", '']","['availability of toolkits for this weighted case(Mohri et al., 1998; vanNoord and Gerdemann, 2001) promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition( Pereira and Riley , 1997 ) and machine translation( #AUTHOR_TAG ) ."", '']","['availability of toolkits for this weighted case(Mohri et al., 1998; vanNoord and Gerdemann, 2001) promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition( Pereira and Riley , 1997 ) and machine translation( #AUTHOR_TAG ) ."", '']","['availability of toolkits for this weighted case(Mohri et al., 1998; vanNoord and Gerdemann, 2001) promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition( Pereira and Riley , 1997 ) and machine translation( #AUTHOR_TAG ) ."", '']",0
"['log(strength) values are called weights, but this paper uses ""weight"" to mean something else.', 'fÎ¸ on demand( #AUTHOR_TAG ) can pay off here , since only part of fÎ¸ may be needed subsequently .']","['log(strength) values are called weights, but this paper uses ""weight"" to mean something else.', 'fÎ¸ on demand( #AUTHOR_TAG ) can pay off here , since only part of fÎ¸ may be needed subsequently .']","['log(strength) values are called weights, but this paper uses ""weight"" to mean something else.', 'fÎ¸ on demand( #AUTHOR_TAG ) can pay off here , since only part of fÎ¸ may be needed subsequently .']","['10 Traditionally log(strength) values are called weights, but this paper uses ""weight"" to mean something else.', 'fÎ¸ on demand( #AUTHOR_TAG ) can pay off here , since only part of fÎ¸ may be needed subsequently .']",0
"['', '#AUTHOR_TAG give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .', '']","['', '#AUTHOR_TAG give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .', '']","['', '#AUTHOR_TAG give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .', '']","['', '#AUTHOR_TAG give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .', '']",5
"['� and ⊗ operations.', 'For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm( #AUTHOR_TAG ) .', '']","['of ⊕ and ⊗ operations.', 'For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm( #AUTHOR_TAG ) .', '']","['� and ⊗ operations.', 'For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm( #AUTHOR_TAG ) .', '']","['In many cases of interest, T i is an acyclic graph. 20', ""hen Tarjan's method computes w 0j for each j in topologically sorted order, thereby finding t i in a linear number of ⊕ and ⊗ operations."", 'For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm( #AUTHOR_TAG ) .', '']",0
"['availability of toolkits for this weighted case( #AUTHOR_TAG ; vanNoord and Gerdemann , 2001 ) promises to unify much of statistical NLP .', '']","['availability of toolkits for this weighted case( #AUTHOR_TAG ; vanNoord and Gerdemann , 2001 ) promises to unify much of statistical NLP .', '']","['availability of toolkits for this weighted case( #AUTHOR_TAG ; vanNoord and Gerdemann , 2001 ) promises to unify much of statistical NLP .', '']","['availability of toolkits for this weighted case( #AUTHOR_TAG ; vanNoord and Gerdemann , 2001 ) promises to unify much of statistical NLP .', '']",0
"['outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm( Baum , 1972 ) trains only Hidden Markov Models , while( #AUTHOR_TAG ) trains only stochastic edit distance']","['outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm( Baum , 1972 ) trains only Hidden Markov Models , while( #AUTHOR_TAG ) trains only stochastic edit distance']","['these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm( Baum , 1972 ) trains only Hidden Markov Models , while( #AUTHOR_TAG ) trains only stochastic edit distance']","[', there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm( Baum , 1972 ) trains only Hidden Markov Models , while( #AUTHOR_TAG ) trains only stochastic edit distance']",0
"[', â\x88\x97 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations( #AUTHOR_TAG )']","[', â\x88\x97 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations( #AUTHOR_TAG )']","[', â\x88\x97 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations( #AUTHOR_TAG )']","['', 'The forward and backward probabilities , p0j and pkn , can be computed using single-source algebraic path for the simpler semiring ( R , + , x , â\x88\x97 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations( #AUTHOR_TAG )']",0
"['4To prove ( 1 ) â\x87\x92 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch Â¨ utzenberger construction( #AUTHOR_TAG ) , taking care to write each regexp in the construction as a constant times a probabilistic regexp .', 'A']","['4To prove ( 1 ) â\x87\x92 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch Â¨ utzenberger construction( #AUTHOR_TAG ) , taking care to write each regexp in the construction as a constant times a probabilistic regexp .', 'A']","['4To prove ( 1 ) â\x87\x92 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch Â¨ utzenberger construction( #AUTHOR_TAG ) , taking care to write each regexp in the construction as a constant times a probabilistic regexp .', '']","['4To prove ( 1 ) â\x87\x92 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch Â¨ utzenberger construction( #AUTHOR_TAG ) , taking care to write each regexp in the construction as a constant times a probabilistic regexp .', '']",5
"[') = (−p, −v) and (p, v) −1 = (p −1 , −p −1 vp −1 ).', 'Division is commonly used in defining f θ (for normalization). 19', 'Multiple edges from j to k are summed into a single edge.', '(Mohri, 2002) .', 'Efficient hardware implementation is also possible via chip-level parallelism( #AUTHOR_TAG )']","['and subtraction are also possible: −(p, v) = (−p, −v) and (p, v) −1 = (p −1 , −p −1 vp −1 ).', 'Division is commonly used in defining f θ (for normalization). 19', 'Multiple edges from j to k are summed into a single edge.', '(Mohri, 2002) .', 'Efficient hardware implementation is also possible via chip-level parallelism( #AUTHOR_TAG )']","['and subtraction are also possible: −(p, v) = (−p, −v) and (p, v) −1 = (p −1 , −p −1 vp −1 ).', 'Division is commonly used in defining f θ (for normalization). 19', 'Multiple edges from j to k are summed into a single edge.', '(Mohri, 2002) .', 'Efficient hardware implementation is also possible via chip-level parallelism( #AUTHOR_TAG )']","['and subtraction are also possible: −(p, v) = (−p, −v) and (p, v) −1 = (p −1 , −p −1 vp −1 ).', 'Division is commonly used in defining f θ (for normalization). 19', 'Multiple edges from j to k are summed into a single edge.', '(Mohri, 2002) .', 'Efficient hardware implementation is also possible via chip-level parallelism( #AUTHOR_TAG )']",3
"['', 'Per-state joint normalization( #AUTHOR_TAG b , Â§ 8.2 ) is similar but drops the dependence on a .', '']","['', 'Per-state joint normalization( #AUTHOR_TAG b , Â§ 8.2 ) is similar but drops the dependence on a .', '']","['', 'Per-state joint normalization( #AUTHOR_TAG b , Â§ 8.2 ) is similar but drops the dependence on a .', '']","['', 'Per-state joint normalization( #AUTHOR_TAG b , Â§ 8.2 ) is similar but drops the dependence on a .', '']",1
"['EM algorithm( #AUTHOR_TAG ) can maximize these functions .', '']","['EM algorithm( #AUTHOR_TAG ) can maximize these functions .', '']","['EM algorithm( #AUTHOR_TAG ) can maximize these functions .', '']","['EM algorithm( #AUTHOR_TAG ) can maximize these functions .', 'Roughly, the E step guesses hidden information: if (x i , y i ) was generated from the current f θ , which FST paths stand a chance of having been the path used?', '']",5
"['defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules( Mohri and Sproat , 1996 ) , ( 3 ) by compilation of decision trees( #AUTHOR_TAG ) , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and vanNoord , 1999 ) ,5 ( 5 ) by conditionalization of a']","['defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules( Mohri and Sproat , 1996 ) , ( 3 ) by compilation of decision trees( #AUTHOR_TAG ) , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and vanNoord , 1999 ) ,5 ( 5 ) by conditionalization of a']","['defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules( Mohri and Sproat , 1996 ) , ( 3 ) by compilation of decision trees( #AUTHOR_TAG ) , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and vanNoord , 1999 ) ,5 ( 5 ) by conditionalization of']","['defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules( Mohri and Sproat , 1996 ) , ( 3 ) by compilation of decision trees( #AUTHOR_TAG ) , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and vanNoord , 1999 ) ,5 ( 5 ) by conditionalization of a joint relation as discussed below']",0
"['for some important remarks on efficiency : â\x80¢ Computing ti is an instance of the well-known algebraic path problem( #AUTHOR_TAG ; Tar an , 1981a ) . Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed W']","['for some important remarks on efficiency : â\x80¢ Computing ti is an instance of the well-known algebraic path problem( #AUTHOR_TAG ; Tar an , 1981a ) . Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and un- weighted).', '']","['for some important remarks on efficiency : â\x80¢ Computing ti is an instance of the well-known algebraic path problem( #AUTHOR_TAG ; Tar an , 1981a ) . Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed W']","['for some important remarks on efficiency : â\x80¢ Computing ti is an instance of the well-known algebraic path problem( #AUTHOR_TAG ; Tar an , 1981a ) . Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and un- weighted).', '']",0
"['distribution as desired.', 'Such approaches have been tried recently in restricted cases ( McCallum et al. , 2000 ; Eisner , 2001 b ;#AUTHOR_TAG )']","['globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases ( McCallum et al. , 2000 ; Eisner , 2001 b ;#AUTHOR_TAG )']","['globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases ( McCallum et al. , 2000 ; Eisner , 2001 b ;#AUTHOR_TAG )']","[':e −→, and a:ae −→ share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases ( McCallum et al. , 2000 ; Eisner , 2001 b ;#AUTHOR_TAG )']",0
"['imum-posterior estimation tries to maximize P (θ) • i f θ (x i , y i ) where P (θ) is a prior probability.', 'In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting( #AUTHOR_TAG )']","['imum-posterior estimation tries to maximize P (θ) • i f θ (x i , y i ) where P (θ) is a prior probability.', 'In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting( #AUTHOR_TAG )']","['imum-posterior estimation tries to maximize P (θ) • i f θ (x i , y i ) where P (θ) is a prior probability.', 'In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting( #AUTHOR_TAG )']","['imum-posterior estimation tries to maximize P (θ) • i f θ (x i , y i ) where P (θ) is a prior probability.', 'In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting( #AUTHOR_TAG )']",5
"['may be given as regular sets in which input and output were observed to fall.', 'For example , in ordinary HMM training , xi = E * and represents a completely hidden state sequence ( cfXXX#AUTHOR_TAG , who allows any regular set ) , while yi is a single string representing a completely observed emission sequence .1']","['�_ may be given as regular sets in which input and output were observed to fall.', 'For example , in ordinary HMM training , xi = E * and represents a completely hidden state sequence ( cfXXX#AUTHOR_TAG , who allows any regular set ) , while yi is a single string representing a completely observed emission sequence .1']","['may be given as regular sets in which input and output were observed to fall.', 'For example , in ordinary HMM training , xi = E * and represents a completely hidden state sequence ( cfXXX#AUTHOR_TAG , who allows any regular set ) , while yi is a single string representing a completely observed emission sequence .1']","['', 'Samples need not be fully observed (partly supervised training): thus xi _ __, yi _ �_ may be given as regular sets in which input and output were observed to fall.', 'For example , in ordinary HMM training , xi = E * and represents a completely hidden state sequence ( cfXXX#AUTHOR_TAG , who allows any regular set ) , while yi is a single string representing a completely observed emission sequence .1']",0
"['availability of toolkits for this weighted case(Mohri et al., 1998; vanNoord and Gerdemann, 2001) promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition( #AUTHOR_TAG ) and machine translation ( Knight and Al-Onaizan , 1998 ) ."", '']","['availability of toolkits for this weighted case(Mohri et al., 1998; vanNoord and Gerdemann, 2001) promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition( #AUTHOR_TAG ) and machine translation ( Knight and Al-Onaizan , 1998 ) ."", '']","['availability of toolkits for this weighted case(Mohri et al., 1998; vanNoord and Gerdemann, 2001) promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition( #AUTHOR_TAG ) and machine translation ( Knight and Al-Onaizan , 1998 ) ."", '']","['availability of toolkits for this weighted case(Mohri et al., 1998; vanNoord and Gerdemann, 2001) promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition( #AUTHOR_TAG ) and machine translation ( Knight and Al-Onaizan , 1998 ) ."", '']",0
"['since then the real work is done by an c-closure step( #AUTHOR_TAG ) that implements the all-pairs version of algebraic path , whereas all we need is the single-source version']","['since then the real work is done by an c-closure step( #AUTHOR_TAG ) that implements the all-pairs version of algebraic path , whereas all we need is the single-source version']","['since then the real work is done by an c-closure step( #AUTHOR_TAG ) that implements the all-pairs version of algebraic path , whereas all we need is the single-source version .', '']",['( #AUTHOR_TAG )'],0
"['An easy approach is to normalize the options at each state to make the FST Markovian.', 'Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation.', 'Undesirable consequences of this fact have been termed ""label bias""( #AUTHOR_TAG ) .', '']","['An easy approach is to normalize the options at each state to make the FST Markovian.', 'Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation.', 'Undesirable consequences of this fact have been termed ""label bias""( #AUTHOR_TAG ) .', '']","['An easy approach is to normalize the options at each state to make the FST Markovian.', 'Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation.', 'Undesirable consequences of this fact have been termed ""label bias""( #AUTHOR_TAG ) .', '']","['An easy approach is to normalize the options at each state to make the FST Markovian.', 'Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation.', 'Undesirable consequences of this fact have been termed ""label bias""( #AUTHOR_TAG ) .', 'Also, in the conditional case such per-state normalization is only correct if all states accept all input suffixes (since ""dead ends"" leak probability mass). 8', '']",0
"['brief version of this work, with some additional material, first appeared as( #AUTHOR_TAG a ) .', 'A leisurely journal-length version with more details has been prepared and is available']","['brief version of this work, with some additional material, first appeared as( #AUTHOR_TAG a ) .', 'A leisurely journal-length version with more details has been prepared and is available']","['brief version of this work, with some additional material, first appeared as( #AUTHOR_TAG a ) .', 'A leisurely journal-length version with more details has been prepared and is available']","['brief version of this work, with some additional material, first appeared as( #AUTHOR_TAG a ) .', 'A leisurely journal-length version with more details has been prepared and is available']",2
"['', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7 −→ arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs( Nederhof , 2000 ; #AUTHOR_TAG ) , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution""]","['', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7 −→ arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs( Nederhof , 2000 ; #AUTHOR_TAG ) , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution""]","['', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7 −→ arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs( Nederhof , 2000 ; #AUTHOR_TAG ) , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution""]","['', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7 −→ arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs( Nederhof , 2000 ; #AUTHOR_TAG ) , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution""]",0
"['defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules( #AUTHOR_TAG ) , ( 3 ) by compilation of decision trees( Sproat and Riley , 1996 ) , ( 4 ) as a relation that']","['defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules( #AUTHOR_TAG ) , ( 3 ) by compilation of decision trees( Sproat and Riley , 1996 ) , ( 4 ) as a relation that']","['defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules( #AUTHOR_TAG ) , ( 3 ) by compilation of decision trees( Sproat and Riley , 1996 ) , ( 4 ) as a relation that']","['defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules( #AUTHOR_TAG ) , ( 3 ) by compilation of decision trees( Sproat and Riley , 1996 ) , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and vanNoord , 1999 ) ,5 ( 5 ) by conditionalization of a joint relation as discussed below']",0
"['distribution as desired.', 'Such approaches have been tried recently in restricted cases( #AUTHOR_TAG ; Eisner , 2001 b ;Lafferty et al. , 2001 )']","['globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases( #AUTHOR_TAG ; Eisner , 2001 b ;Lafferty et al. , 2001 )']","['globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases( #AUTHOR_TAG ; Eisner , 2001 b ;Lafferty et al. , 2001 )']","[':e −→, and a:ae −→ share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases( #AUTHOR_TAG ; Eisner , 2001 b ;Lafferty et al. , 2001 )']",0
"['', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7 −→ arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs( #AUTHOR_TAG ; Mohri and Nederhof , 2001 ) , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution""]","['', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7 −→ arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs( #AUTHOR_TAG ; Mohri and Nederhof , 2001 ) , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution""]","['', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7 −→ arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs( #AUTHOR_TAG ; Mohri and Nederhof , 2001 ) , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution""]","['', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7 −→ arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs( #AUTHOR_TAG ; Mohri and Nederhof , 2001 ) , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution""]",0
"['outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm( #AUTHOR_TAG ) trains only Hidden Markov Models , while( Ristad and Yianilos , 1996 ) trains only stochastic edit distance']","['outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm( #AUTHOR_TAG ) trains only Hidden Markov Models , while( Ristad and Yianilos , 1996 ) trains only stochastic edit distance']","['these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm( #AUTHOR_TAG ) trains only Hidden Markov Models , while( Ristad and Yianilos , 1996 ) trains only stochastic edit distance']","[', there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm( #AUTHOR_TAG ) trains only Hidden Markov Models , while( Ristad and Yianilos , 1996 ) trains only stochastic edit distance']",0
"['distribution as desired.', 'Such approaches have been tried recently in restricted cases( McCallum et al. , 2000 ; #AUTHOR_TAG b ;Lafferty et al. , 2001 )']","['globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases( McCallum et al. , 2000 ; #AUTHOR_TAG b ;Lafferty et al. , 2001 )']","['globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases( McCallum et al. , 2000 ; #AUTHOR_TAG b ;Lafferty et al. , 2001 )']","[':e −→, and a:ae −→ share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases( McCallum et al. , 2000 ; #AUTHOR_TAG b ;Lafferty et al. , 2001 )']",0
"['', 'The M step then treats c as fixed , observed data and adjusts 0 until the predicted vector of total feature counts equals c , using Improved Iterative Scaling ( Della#AUTHOR_TAG ; Chen and', 'For globally normalized, joint models, the predicted vector is ec f (Σ * , ∆ * ).', '']","['', 'The M step then treats c as fixed , observed data and adjusts 0 until the predicted vector of total feature counts equals c , using Improved Iterative Scaling ( Della#AUTHOR_TAG ; Chen and', 'For globally normalized, joint models, the predicted vector is ec f (Σ * , ∆ * ).', '']","['', 'The M step then treats c as fixed , observed data and adjusts 0 until the predicted vector of total feature counts equals c , using Improved Iterative Scaling ( Della#AUTHOR_TAG ; Chen and', 'For globally normalized, joint models, the predicted vector is ec f (Σ * , ∆ * ).', '']","['', 'The M step then treats c as fixed , observed data and adjusts 0 until the predicted vector of total feature counts equals c , using Improved Iterative Scaling ( Della#AUTHOR_TAG ; Chen and', 'For globally normalized, joint models, the predicted vector is ec f (Σ * , ∆ * ).', '']",5
"['central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1( #AUTHOR_TAG ; Knight and Graehl , 1998 ) .', 'The general form is illustrated by 3 Conceptually, the parameters represent the probabilities of reading another a (λ); reading']","['central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1( #AUTHOR_TAG ; Knight and Graehl , 1998 ) .', 'The general form is illustrated by 3 Conceptually, the parameters represent the probabilities of reading another a (λ); reading']","['central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1( #AUTHOR_TAG ; Knight and Graehl , 1998 ) .', 'The general form is illustrated by 3 Conceptually, the parameters represent the probabilities of reading another a (λ); reading another b (ν); transducing b to p rather than q (µ);']","['central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1( #AUTHOR_TAG ; Knight and Graehl , 1998 ) .', 'The general form is illustrated by 3 Conceptually, the parameters represent the probabilities of reading another a (λ); reading another b (ν); transducing b to p rather than q (µ); starting to transduce p to rather than x (ρ). 4 To prove (1)⇒(3), express f as an FST and apply the well-known Kleene-Schützenberger construction(Berstel and Reutenauer, 1988) , taking care to write each regexp in the construction as a constant times a probabilistic regexp.', '']",0
"['system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq#AUTHOR_TAG , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and', 'Additionally, several model organism databases or nomen']","['system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq#AUTHOR_TAG , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and', 'Additionally, several model organism databases or nomenclature databases were']","['system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq#AUTHOR_TAG , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and', 'Additionally, several model organism databases or nomen']","['system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq#AUTHOR_TAG , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and', 'Additionally, several model organism databases or nomenclature databases were used.', '']",5
"[', fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD )#AUTHOR_TAG , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] ,']","[', fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD )#AUTHOR_TAG , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] ,']","['18 ] , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD )#AUTHOR_TAG , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Human Nomenclature Database']",['#AUTHOR_TAG'],5
"['molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD )#AUTHOR_TAG , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD )']","['molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD )#AUTHOR_TAG , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD )']","['molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD )#AUTHOR_TAG , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD )']",['#AUTHOR_TAG'],5
"[', rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase#AUTHOR_TAG ,']","[', rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase#AUTHOR_TAG ,']","['fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase#AUTHOR_TAG , Human Nomenclature Database']",['#AUTHOR_TAG'],5
"['UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM )#AUTHOR_TAG .', 'It contains three knowledge sources: the Metathesaurus (META), the SPECIALIST lexicon, and the Semantic Network.', 'The META provides a uniform, integrated platform for over 60 biomedical vocabularies and classifications, and group different names for the same concept.', 'The SPECIALIST']","['UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM )#AUTHOR_TAG .', 'It contains three knowledge sources: the Metathesaurus (META), the SPECIALIST lexicon, and the Semantic Network.', 'The META provides a uniform, integrated platform for over 60 biomedical vocabularies and classifications, and group different names for the same concept.', 'The SPECIALIST lexicon contains syntactic information for many terms,']","['UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM )#AUTHOR_TAG .', 'It contains three knowledge sources: the Metathesaurus (META), the SPECIALIST lexicon, and the Semantic Network.', 'The META provides a uniform, integrated platform for over 60 biomedical vocabularies and classifications, and group different names for the same concept.', 'The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including']","['UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM )#AUTHOR_TAG .', 'It contains three knowledge sources: the Metathesaurus (META), the SPECIALIST lexicon, and the Semantic Network.', 'The META provides a uniform, integrated platform for over 60 biomedical vocabularies and classifications, and group different names for the same concept.', 'The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.', 'The Semantic Network contains information about the types or categories (e.g., ""Disease or Syndrome"", ""Virus"") to which all META concepts have been assigned']",0
"['the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible#AUTHOR_TAG .', 'One requirement for NLP is the ability to accurately recognize terms that represent biological entities in free text.', 'Another requirement is the ability to associate these terms with corresponding biological entities (']","['the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible#AUTHOR_TAG .', 'One requirement for NLP is the ability to accurately recognize terms that represent biological entities in free text.', 'Another requirement is the ability to associate these terms with corresponding biological entities (i.e., records in']","['the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible#AUTHOR_TAG .', 'One requirement for NLP is the ability to accurately recognize terms that represent biological entities in free text.', 'Another requirement is the ability to associate these terms with corresponding biological entities (']","['the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible#AUTHOR_TAG .', 'One requirement for NLP is the ability to accurately recognize terms that represent biological entities in free text.', 'Another requirement is the ability to associate these terms with corresponding biological entities (i.e., records in biological databases) in order to be used by other automated systems for literature mining.', '']",0
"[', Online Mendelian Inheritance in Man ( OMIM )#AUTHOR_TAG , and Enzyme Nomenclature']","[', Online Mendelian Inheritance in Man ( OMIM )#AUTHOR_TAG , and Enzyme Nomenclature']","['23 ] , Online Mendelian Inheritance in Man ( OMIM )#AUTHOR_TAG , and Enzyme Nomenclature Database ( ECNUM ) [ 25 ,']",['#AUTHOR_TAG'],5
['clusters based on the CD-HIT algorithm#AUTHOR_TAG'],['clusters based on the CD-HIT algorithm#AUTHOR_TAG'],['clusters based on the CD-HIT algorithm#AUTHOR_TAG'],['#AUTHOR_TAG'],5
"[', fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD )#AUTHOR_TAG , worm -- WormBase [ 22 ] ,']","[', fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD )#AUTHOR_TAG , worm -- WormBase [ 22 ] ,']","[', fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD )#AUTHOR_TAG , worm -- WormBase [ 22 ] , Human Nomenclature Database']",['#AUTHOR_TAG'],5
"['system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR )#AUTHOR_TAG , and', 'Additionally, several model organism databases or nomenclature databases were used.', 'Correspondences among records from these databases are identified using the']","['system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR )#AUTHOR_TAG , and', 'Additionally, several model organism databases or nomenclature databases were used.', 'Correspondences among records from these databases are identified using the']","['system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR )#AUTHOR_TAG , and', 'Additionally, several model organism databases or nomenclature databases were used.', 'Correspondences among records from these databases are identified using']","['system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR )#AUTHOR_TAG , and', 'Additionally, several model organism databases or nomenclature databases were used.', '']",5
"['databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase#AUTHOR_TAG , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database']","['molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase#AUTHOR_TAG , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database']","['molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase#AUTHOR_TAG , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database']",['#AUTHOR_TAG'],5
"['4 ] , and Enzyme Nomenclature Database ( ECNUM )#AUTHOR_TAG']","['Inheritance in Man ( OMIM ) [ 24 ] , and Enzyme Nomenclature Database ( ECNUM )#AUTHOR_TAG']","['4 ] , and Enzyme Nomenclature Database ( ECNUM )#AUTHOR_TAG']",['#AUTHOR_TAG'],5
"['our experiments, we use naive Bayes as the learning algorithm.', 'The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.', 'These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work( #AUTHOR_TAG )']","['our experiments, we use naive Bayes as the learning algorithm.', 'The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.', 'These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work( #AUTHOR_TAG )']","['our experiments, we use naive Bayes as the learning algorithm.', 'The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.', 'These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work( #AUTHOR_TAG )']","['our experiments, we use naive Bayes as the learning algorithm.', 'The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.', 'These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work( #AUTHOR_TAG )']",2
"['', 'While these approaches have been reasonably successful ( seeMitkov ( 2002 ) ) ,#AUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '']","['', 'While these approaches have been reasonably successful ( seeMitkov ( 2002 ) ) ,#AUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '']","[',Tetreault (2001) ).', 'While these approaches have been reasonably successful ( seeMitkov ( 2002 ) ) ,#AUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '']","['', 'In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g.,Mitkov (1998) ,Tetreault (2001) ).', 'While these approaches have been reasonably successful ( seeMitkov ( 2002 ) ) ,#AUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '']",0
"['importantly, the ACE participants do not evaluate the role of induced SC knowledge in coreference resolution: many of them evaluate coreference performance on perfect mentions (e.g.,#AUTHOR_TAG ) ; and for those that do report per- formance on automatically extracted mentions, they do not explain whether or how the induced SC information is used in their coreference algorithms']","['importantly, the ACE participants do not evaluate the role of induced SC knowledge in coreference resolution: many of them evaluate coreference performance on perfect mentions (e.g.,#AUTHOR_TAG ) ; and for those that do report per- formance on automatically extracted mentions, they do not explain whether or how the induced SC information is used in their coreference algorithms']","['importantly, the ACE participants do not evaluate the role of induced SC knowledge in coreference resolution: many of them evaluate coreference performance on perfect mentions (e.g.,#AUTHOR_TAG ) ; and for those that do report per- formance on automatically extracted mentions, they do not explain whether or how the induced SC information is used in their coreference algorithms']","['', 'More importantly, the ACE participants do not evaluate the role of induced SC knowledge in coreference resolution: many of them evaluate coreference performance on perfect mentions (e.g.,#AUTHOR_TAG ) ; and for those that do report per- formance on automatically extracted mentions, they do not explain whether or how the induced SC information is used in their coreference algorithms']",1
"['.', 'In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. ,Mitkov ( 1998 ) ,#AUTHOR_TAG ) .', '']","['the past decade, knowledge-lean approaches have significantly influenced research in noun phrase (NP) coreference resolution -the problem of determining which NPs refer to the same real-world entity in a document.', 'In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. ,Mitkov ( 1998 ) ,#AUTHOR_TAG ) .', '']","['the past decade, knowledge-lean approaches have significantly influenced research in noun phrase (NP) coreference resolution -the problem of determining which NPs refer to the same real-world entity in a document.', 'In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. ,Mitkov ( 1998 ) ,#AUTHOR_TAG ) .', '']","['the past decade, knowledge-lean approaches have significantly influenced research in noun phrase (NP) coreference resolution -the problem of determining which NPs refer to the same real-world entity in a document.', 'In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. ,Mitkov ( 1998 ) ,#AUTHOR_TAG ) .', '']",0
"['instead, we use the BBN Entity Type Corpus( #AUTHOR_TAG ) , which consists of all the Penn Treebank Wall Street Journal articles with the ACE mentions manually identified and annotated with their SCs.', 'This provides us with a training set that is approximately five times bigger than that of ACE.', '']","['our SC classifier; instead, we use the BBN Entity Type Corpus( #AUTHOR_TAG ) , which consists of all the Penn Treebank Wall Street Journal articles with the ACE mentions manually identified and annotated with their SCs.', 'This provides us with a training set that is approximately five times bigger than that of ACE.', '']","['our SC classifier; instead, we use the BBN Entity Type Corpus( #AUTHOR_TAG ) , which consists of all the Penn Treebank Wall Street Journal articles with the ACE mentions manually identified and annotated with their SCs.', 'This provides us with a training set that is approximately five times bigger than that of ACE.', '']",['( #AUTHOR_TAG )'],5
"['knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g.,Mitkov (1998) ,Tetreault (2001) ).', 'While these approaches have been reasonably successful ( see#AUTHOR_TAG ) ,Kehler et al. ( 2004 ) speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '']","['knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g.,Mitkov (1998) ,Tetreault (2001) ).', 'While these approaches have been reasonably successful ( see#AUTHOR_TAG ) ,Kehler et al. ( 2004 ) speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '']","['knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g.,Mitkov (1998) ,Tetreault (2001) ).', 'While these approaches have been reasonably successful ( see#AUTHOR_TAG ) ,Kehler et al. ( 2004 ) speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '']","['', 'In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g.,Mitkov (1998) ,Tetreault (2001) ).', 'While these approaches have been reasonably successful ( see#AUTHOR_TAG ) ,Kehler et al. ( 2004 ) speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '']",0
"['; and (3) train an SVM classifier (using the LIBSVM package( #AUTHOR_TAG ) ) on these 20% of the instances, where each instance, i, is represented by a PER ORG GPE FAC LOC OTH Training Test 19']","['instances; and (3) train an SVM classifier (using the LIBSVM package( #AUTHOR_TAG ) ) on these 20% of the instances, where each instance, i, is represented by a PER ORG GPE FAC LOC OTH Training Test 19.8']","['and (3) train an SVM classifier (using the LIBSVM package( #AUTHOR_TAG ) ) on these 20% of the instances, where each instance, i, is represented by']",['( #AUTHOR_TAG )'],5
"[""NE : We use BBN 's IdentiFinder( #AUTHOR_TAG ) , a MUC-style NE recognizer to determine the NE type of NPZ ."", '']","[""NE : We use BBN 's IdentiFinder( #AUTHOR_TAG ) , a MUC-style NE recognizer to determine the NE type of NPZ ."", '']","[""NE : We use BBN 's IdentiFinder( #AUTHOR_TAG ) , a MUC-style NE recognizer to determine the NE type of NPZ ."", '']","[""4 ) NE : We use BBN 's IdentiFinder( #AUTHOR_TAG ) , a MUC-style NE recognizer to determine the NE type of NPZ ."", '']",5
"['learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. ,Soon et al. ( 2001 ) ,#AUTHOR_TAG ) .', 'It is not easy to measure the accuracy']","['learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. ,Soon et al. ( 2001 ) ,#AUTHOR_TAG ) .', 'It is not easy to measure the accuracy']","['learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. ,Soon et al. ( 2001 ) ,#AUTHOR_TAG ) .', 'It is not easy to measure the accuracy']","['', 'However , learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. ,Soon et al. ( 2001 ) ,#AUTHOR_TAG ) .', '']",0
"[': We use the DL learner as described in#AUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation( Yarowsky , 1995 ) and NE classification( Collins and Singer , 1999 ) .', '']","[': We use the DL learner as described in#AUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation( Yarowsky , 1995 ) and NE classification( Collins and Singer , 1999 ) .', '']","[': We use the DL learner as described in#AUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation( Yarowsky , 1995 ) and NE classification( Collins and Singer , 1999 ) .', '']","['algorithms.', 'We experiment with four learners commonly employed in language learning : Decision List ( DL ) : We use the DL learner as described in#AUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation( Yarowsky , 1995 ) and NE classification( Collins and Singer , 1999 ) .', '']",5
"['.', 'We report performance in terms of two metrics : ( 1 ) the Fmeasure score as computed by the commonly-used MUC scorer( #AUTHOR_TAG ) , and ( 2 ) the accuracy on the anaphoric references , computed as the fraction of anaphoric references correctly resolved .', '']","['texts.', 'We report performance in terms of two metrics : ( 1 ) the Fmeasure score as computed by the commonly-used MUC scorer( #AUTHOR_TAG ) , and ( 2 ) the accuracy on the anaphoric references , computed as the fraction of anaphoric references correctly resolved .', '']","['the 97 test texts.', 'We report performance in terms of two metrics : ( 1 ) the Fmeasure score as computed by the commonly-used MUC scorer( #AUTHOR_TAG ) , and ( 2 ) the accuracy on the anaphoric references , computed as the fraction of anaphoric references correctly resolved .', '']","['', 'We report performance in terms of two metrics : ( 1 ) the Fmeasure score as computed by the commonly-used MUC scorer( #AUTHOR_TAG ) , and ( 2 ) the accuracy on the anaphoric references , computed as the fraction of anaphoric references correctly resolved .', '']",5
"['.', 'Following#AUTHOR_TAG , we select as the antecedent of each NP, NPj, the closest preceding NP that is classified as coreferent with NPj.', 'If no such NP exists, no antecedent is selected for NPj']","['training, the decision tree classifier is used to select an antecedent for each NP in a test text.', 'Following#AUTHOR_TAG , we select as the antecedent of each NP, NPj, the closest preceding NP that is classified as coreferent with NPj.', 'If no such NP exists, no antecedent is selected for NPj']","['training, the decision tree classifier is used to select an antecedent for each NP in a test text.', 'Following#AUTHOR_TAG , we select as the antecedent of each NP, NPj, the closest preceding NP that is classified as coreferent with NPj.', 'If no such NP exists, no antecedent is selected for NPj']","['training, the decision tree classifier is used to select an antecedent for each NP in a test text.', 'Following#AUTHOR_TAG , we select as the antecedent of each NP, NPj, the closest preceding NP that is classified as coreferent with NPj.', 'If no such NP exists, no antecedent is selected for NPj']",4
"['ACE participants have also adopted a corpus-based approach to SC determination that is investigated as part of the mention detection (MD) task ( e.g. ,#AUTHOR_TAG ) .', 'Briefly, the goal of MD is to identify the boundary of a mention, its mention type (e.g., pronoun, name), and its semantic type (e.g., person, location).', '']","['ACE participants have also adopted a corpus-based approach to SC determination that is investigated as part of the mention detection (MD) task ( e.g. ,#AUTHOR_TAG ) .', 'Briefly, the goal of MD is to identify the boundary of a mention, its mention type (e.g., pronoun, name), and its semantic type (e.g., person, location).', '']","['ACE participants have also adopted a corpus-based approach to SC determination that is investigated as part of the mention detection (MD) task ( e.g. ,#AUTHOR_TAG ) .', 'Briefly, the goal of MD is to identify the boundary of a mention, its mention type (e.g., pronoun, name), and its semantic type (e.g., person, location).', '']","['ACE participants have also adopted a corpus-based approach to SC determination that is investigated as part of the mention detection (MD) task ( e.g. ,#AUTHOR_TAG ) .', 'Briefly, the goal of MD is to identify the boundary of a mention, its mention type (e.g., pronoun, name), and its semantic type (e.g., person, location).', '']",1
"['; and a negative instance is created for NPj paired with each of the intervening NPs, NPi+\x0e, NPi+2, � � �, NPj positional features that have been employed by high- performing resolvers such asNg and Cardie (2002) and#AUTHOR_TAG , as described below']","['and a negative instance is created for NPj paired with each of the intervening NPs, NPi+\x0e, NPi+2, � � �, NPj positional features that have been employed by high- performing resolvers such asNg and Cardie (2002) and#AUTHOR_TAG , as described below']","['and a negative instance is created for NPj paired with each of the intervening NPs, NPi+\x0e, NPi+2, � � �, NPj positional features that have been employed by high- performing resolvers such asNg and Cardie (2002) and#AUTHOR_TAG , as described below']","['', 'Following previous work (e.g.,Soon et al. (2001) andPonzetto and Strube (2006) ), we generate training instances as follows: a positive instance is created for each anaphoric NP, NPj, and its closest antecedent, NPi; and a negative instance is created for NPj paired with each of the intervening NPs, NPi+\x0e, NPi+2, � � �, NPj positional features that have been employed by high- performing resolvers such asNg and Cardie (2002) and#AUTHOR_TAG , as described below']",1
"['baseline coreference system uses the C4 .5 decision tree learner( #AUTHOR_TAG ) to acquire a classifier on the training texts for determining whether two NPs are coreferent .', '']","['baseline coreference system uses the C4 .5 decision tree learner( #AUTHOR_TAG ) to acquire a classifier on the training texts for determining whether two NPs are coreferent .', '']","['baseline coreference system uses the C4 .5 decision tree learner( #AUTHOR_TAG ) to acquire a classifier on the training texts for determining whether two NPs are coreferent .', '']","['baseline coreference system uses the C4 .5 decision tree learner( #AUTHOR_TAG ) to acquire a classifier on the training texts for determining whether two NPs are coreferent .', '']",5
"['', 'Each instance is represented by 33 lexical, grammatical, semantic, andpositional features that have been employed by high- performing resolvers such as#AUTHOR_TAG andYang et al. (2003) , as described below']","['', 'Each instance is represented by 33 lexical, grammatical, semantic, andpositional features that have been employed by high- performing resolvers such as#AUTHOR_TAG andYang et al. (2003) , as described below']","['', 'Each instance is represented by 33 lexical, grammatical, semantic, andpositional features that have been employed by high- performing resolvers such as#AUTHOR_TAG andYang et al. (2003) , as described below']","['', 'Each instance is represented by 33 lexical, grammatical, semantic, andpositional features that have been employed by high- performing resolvers such as#AUTHOR_TAG andYang et al. (2003) , as described below']",1
"['', 'Following#AUTHOR_TAG , we consider an anaphoric reference , NPi , correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition .', '']","['', 'Following#AUTHOR_TAG , we consider an anaphoric reference , NPi , correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition .', '']","['', 'Following#AUTHOR_TAG , we consider an anaphoric reference , NPi , correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition .', '']","['', 'Following#AUTHOR_TAG , we consider an anaphoric reference , NPi , correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition .', '']",5
"['researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( see#AUTHOR_TAG )']","['researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( see#AUTHOR_TAG )']","['researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( see#AUTHOR_TAG )']","['', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( see#AUTHOR_TAG )']",0
"['because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. ,#AUTHOR_TAG ,Markert and Nissim ( 2005 ) ) .', 'It is not easy']","['because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. ,#AUTHOR_TAG ,Markert and Nissim ( 2005 ) ) .', 'It is not easy']","['because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. ,#AUTHOR_TAG ,Markert and Nissim ( 2005 ) ) .', 'It is not easy']","['', 'However , learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. ,#AUTHOR_TAG ,Markert and Nissim ( 2005 ) ) .', '']",0
"['baseline coreference system uses the C4.5 decision tree learner(Quinlan, 1993) to acquire a classifier on the training texts for determining whether two NPs are coreferent.', 'Following previous work ( e.g. ,#AUTHOR_TAG andPonzetto and Strube ( 2006 ) ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .', '., NP j−1 .', '']","['baseline coreference system uses the C4.5 decision tree learner(Quinlan, 1993) to acquire a classifier on the training texts for determining whether two NPs are coreferent.', 'Following previous work ( e.g. ,#AUTHOR_TAG andPonzetto and Strube ( 2006 ) ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .', '., NP j−1 .', '']","['baseline coreference system uses the C4.5 decision tree learner(Quinlan, 1993) to acquire a classifier on the training texts for determining whether two NPs are coreferent.', 'Following previous work ( e.g. ,#AUTHOR_TAG andPonzetto and Strube ( 2006 ) ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .', '., NP j−1 .', '']","['baseline coreference system uses the C4.5 decision tree learner(Quinlan, 1993) to acquire a classifier on the training texts for determining whether two NPs are coreferent.', 'Following previous work ( e.g. ,#AUTHOR_TAG andPonzetto and Strube ( 2006 ) ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .', '., NP j−1 .', '']",5
"[': We use the DL learner as described inCollins and Singer ( 1999 ) , motivated by its success in the related tasks of word sense disambiguation( #AUTHOR_TAG ) and NE classification( Collins and Singer , 1999 ) .', '']","[': We use the DL learner as described inCollins and Singer ( 1999 ) , motivated by its success in the related tasks of word sense disambiguation( #AUTHOR_TAG ) and NE classification( Collins and Singer , 1999 ) .', '']","[': We use the DL learner as described inCollins and Singer ( 1999 ) , motivated by its success in the related tasks of word sense disambiguation( #AUTHOR_TAG ) and NE classification( Collins and Singer , 1999 ) .', '']","['', 'We experiment with four learners commonly employed in language learning : Decision List ( DL ) : We use the DL learner as described inCollins and Singer ( 1999 ) , motivated by its success in the related tasks of word sense disambiguation( #AUTHOR_TAG ) and NE classification( Collins and Singer , 1999 ) .', '']",4
"['researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( #AUTHOR_TAG ) , and the contextual role played by an NP ( seeBean and Riloff ( 2004 ) )']","['researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( #AUTHOR_TAG ) , and the contextual role played by an NP ( seeBean and Riloff ( 2004 ) )']","['researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( #AUTHOR_TAG ) , and the contextual role played by an NP ( seeBean and Riloff ( 2004 ) )']","['', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( #AUTHOR_TAG ) , and the contextual role played by an NP ( seeBean and Riloff ( 2004 ) )']",0
"['', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,#AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( seeBean and Riloff ( 2004 ) )']","['', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,#AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( seeBean and Riloff ( 2004 ) )']","['', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,#AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( seeBean and Riloff ( 2004 ) )']","['', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. ,#AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. ,Poesio et al. ( 2004 ) ) or Wikipedia( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( seeBean and Riloff ( 2004 ) )']",0
"['in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs ( see#AUTHOR_TAG a ) ) .', 'Motivated by this observation, we']","['in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs ( see#AUTHOR_TAG a ) ) .', 'Motivated by this observation, we']","['in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs ( see#AUTHOR_TAG a ) ) .', 'Motivated by this observation, we']","['', '( 7 ) NEIGHBOR : Research in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs ( see#AUTHOR_TAG a ) ) .', 'Motivated by this observation, we']",4
"[', we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. ,#AUTHOR_TAG ) .', '']","['first-sense heuristic used in the previous feature may not be accurate in capturing the SC of an NP , we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. ,#AUTHOR_TAG ) .', '']","['the first-sense heuristic used in the previous feature may not be accurate in capturing the SC of an NP , we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. ,#AUTHOR_TAG ) .', '']",['#AUTHOR_TAG )'],4
"['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( Fujie et al. , 2004 ; #AUTHOR_TAG ; Morency et al. , 2007 ; Morency et al. , 2009 ) .', 'Our']","['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( Fujie et al. , 2004 ; #AUTHOR_TAG ; Morency et al. , 2007 ; Morency et al. , 2009 ) .', 'Our']","['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( Fujie et al. , 2004 ; #AUTHOR_TAG ; Morency et al. , 2007 ; Morency et al. , 2009 ) .', 'Our']","['', 'Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( Fujie et al. , 2004 ; #AUTHOR_TAG ; Morency et al. , 2007 ; Morency et al. , 2009 ) .', '']",0
"['communicative head gestures in the videos were found and annotated with ANVIL using a subset of the attributes defined in the MUMIN annotation scheme( #AUTHOR_TAG ) .', 'The MU-']","['communicative head gestures in the videos were found and annotated with ANVIL using a subset of the attributes defined in the MUMIN annotation scheme( #AUTHOR_TAG ) .', 'The MU-MIN']","['communicative head gestures in the videos were found and annotated with ANVIL using a subset of the attributes defined in the MUMIN annotation scheme( #AUTHOR_TAG ) .', 'The MU-MIN scheme']","['communicative head gestures in the videos were found and annotated with ANVIL using a subset of the attributes defined in the MUMIN annotation scheme( #AUTHOR_TAG ) .', 'The MU-MIN scheme is a general framework for the study of gestures in interpersonal communication.', '']",5
"['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', 'Sridhar et al. ( 2009 ) obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while#AUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '']","['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', 'Sridhar et al. ( 2009 ) obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while#AUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '']","['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', 'Sridhar et al. ( 2009 ) obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while#AUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '']","['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', 'Sridhar et al. ( 2009 ) obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while#AUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '']",0
"['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( #AUTHOR_TAG ; Morency et al. , 2005 ; Morency et al. , 2007 ; Morency et al. , 2009 ) .', 'Our']","['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( #AUTHOR_TAG ; Morency et al. , 2005 ; Morency et al. , 2007 ; Morency et al. , 2009 ) .', 'Our']","['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( #AUTHOR_TAG ; Morency et al. , 2005 ; Morency et al. , 2007 ; Morency et al. , 2009 ) .', 'Our']","['', 'Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( #AUTHOR_TAG ; Morency et al. , 2005 ; Morency et al. , 2007 ; Morency et al. , 2009 ) .', '']",0
"['authors in communication studies have pointed out that head movements are relevant to feedback phenomena ( see#AUTHOR_TAG for an overview ) .', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', '']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena ( see#AUTHOR_TAG for an overview ) .', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', '']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena ( see#AUTHOR_TAG for an overview ) .', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', '']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena ( see#AUTHOR_TAG for an overview ) .', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', '']",0
"['', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa( Cohen , 1960 ) 1 and corrected kappa( #AUTHOR_TAG ) 2 ."", '']","['', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa( Cohen , 1960 ) 1 and corrected kappa( #AUTHOR_TAG ) 2 ."", '']","['', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa( Cohen , 1960 ) 1 and corrected kappa( #AUTHOR_TAG ) 2 ."", '']","['', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa( Cohen , 1960 ) 1 and corrected kappa( #AUTHOR_TAG ) 2 ."", '']",5
['pauses and dialogue structure in annotated English map-task dialogues( #AUTHOR_TAG ) and find correlations between the various modalities both within and across speakers'],['pauses and dialogue structure in annotated English map-task dialogues( #AUTHOR_TAG ) and find correlations between the various modalities both within and across speakers'],"['pauses and dialogue structure in annotated English map-task dialogues( #AUTHOR_TAG ) and find correlations between the various modalities both within and across speakers .', '']","['', 'Louwerse et al. ( 2006 ) andLouwerse et al. ( 2007 ) study the relation between eye gaze , facial expression , pauses and dialogue structure in annotated English map-task dialogues( #AUTHOR_TAG ) and find correlations between the various modalities both within and across speakers .', '']",0
"['as shown in Table 4.', 'These two sets of data were used for automatic dialogue act classification , which was run in the Weka system( #AUTHOR_TAG ) .', 'We experimented with various Weka classifiers, comprising Hidden Naive Bayes, SMO, ID3, LADTree and Decision Table .', '']","['as shown in Table 4.', 'These two sets of data were used for automatic dialogue act classification , which was run in the Weka system( #AUTHOR_TAG ) .', 'We experimented with various Weka classifiers, comprising Hidden Naive Bayes, SMO, ID3, LADTree and Decision Table .', '']","['as shown in Table 4.', 'These two sets of data were used for automatic dialogue act classification , which was run in the Weka system( #AUTHOR_TAG ) .', 'We experimented with various Weka classifiers, comprising Hidden Naive Bayes, SMO, ID3, LADTree and Decision Table .', '']","['', 'These two sets of data were used for automatic dialogue act classification , which was run in the Weka system( #AUTHOR_TAG ) .', 'We experimented with various Weka classifiers, comprising Hidden Naive Bayes, SMO, ID3, LADTree and Decision Table .', '']",5
"['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', '#AUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , whileGravano and Hirschberg ( 2009 ) examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '']","['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', '#AUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , whileGravano and Hirschberg ( 2009 ) examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '']","['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', '#AUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , whileGravano and Hirschberg ( 2009 ) examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '']","['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', '#AUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , whileGravano and Hirschberg ( 2009 ) examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '']",0
"['', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa( #AUTHOR_TAG ) 1 and corrected kappa( Brennan and Prediger , 1981 ) 2 ."", '']","['', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa( #AUTHOR_TAG ) 1 and corrected kappa( Brennan and Prediger , 1981 ) 2 ."", '']","['', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa( #AUTHOR_TAG ) 1 and corrected kappa( Brennan and Prediger , 1981 ) 2 ."", '']","['', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa( #AUTHOR_TAG ) 1 and corrected kappa( Brennan and Prediger , 1981 ) 2 ."", '']",5
"['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( Fujie et al. , 2004 ; Morency et al. , 2005 ; #AUTHOR_TAG ; Morency et al. , 2009 ) .', 'Our']","['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( Fujie et al. , 2004 ; Morency et al. , 2005 ; #AUTHOR_TAG ; Morency et al. , 2009 ) .', 'Our']","['feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( Fujie et al. , 2004 ; Morency et al. , 2005 ; #AUTHOR_TAG ; Morency et al. , 2009 ) .', 'Our']","['', 'Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication( Fujie et al. , 2004 ; Morency et al. , 2005 ; #AUTHOR_TAG ; Morency et al. , 2009 ) .', '']",0
"[', thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see#AUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent(Fleiss, 1971) ."", '']","['time, thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see#AUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent(Fleiss, 1971) ."", '']","['and a TurnElicit at the same time, thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see#AUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent(Fleiss, 1971) ."", '']","['', 'For example, a yes can be an Answer to a question, an Agree and a TurnElicit at the same time, thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see#AUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent(Fleiss, 1971) ."", '']",0
"['', 'Related are also the studies by Rieks op denAkker and Schulz ( 2008 ) and#AUTHOR_TAG : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus']","['', 'Related are also the studies by Rieks op denAkker and Schulz ( 2008 ) and#AUTHOR_TAG : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus']","['', 'Related are also the studies by Rieks op denAkker and Schulz ( 2008 ) and#AUTHOR_TAG : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus']","['', 'Related are also the studies by Rieks op denAkker and Schulz ( 2008 ) and#AUTHOR_TAG : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus']",0
"['authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see McClave (2000) for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example ,#AUTHOR_TAG andJokinen et al. ( 2008 ) find that machine learning algorithms can be trained to recognise some of the functions of head movements , whileReidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see McClave (2000) for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example ,#AUTHOR_TAG andJokinen et al. ( 2008 ) find that machine learning algorithms can be trained to recognise some of the functions of head movements , whileReidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see McClave (2000) for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example ,#AUTHOR_TAG andJokinen et al. ( 2008 ) find that machine learning algorithms can be trained to recognise some of the functions of head movements , whileReidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related are also the studies']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see McClave (2000) for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example ,#AUTHOR_TAG andJokinen et al. ( 2008 ) find that machine learning algorithms can be trained to recognise some of the functions of head movements , whileReidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .', '']",0
"['authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see McClave (2000) for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example ,Jokinen and Ragni ( 2007 ) and#AUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , whileReidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see McClave (2000) for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example ,Jokinen and Ragni ( 2007 ) and#AUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , whileReidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see McClave (2000) for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example ,Jokinen and Ragni ( 2007 ) and#AUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , whileReidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .', '']","['authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see McClave (2000) for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example ,Jokinen and Ragni ( 2007 ) and#AUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , whileReidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .', '']",0
"['thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, seeArtstein and Poesio (2008) , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent( #AUTHOR_TAG ) ."", '']","['thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, seeArtstein and Poesio (2008) , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent( #AUTHOR_TAG ) ."", '']","['thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, seeArtstein and Poesio (2008) , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent( #AUTHOR_TAG ) ."", '']","['', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, seeArtstein and Poesio (2008) , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent( #AUTHOR_TAG ) ."", '']",0
"['ures we also measured agreement on gesture segmentation.', 'The figures obtained are given in Table 3.', 'These results are slightly worse than those obtained in previous studies using the same annotation scheme( #AUTHOR_TAG ) , but are still sat -isfactory given the high number of categories provided by the scheme']","['the case for the annotations on feedback expressions.', 'In the case of gestures we also measured agreement on gesture segmentation.', 'The figures obtained are given in Table 3.', 'These results are slightly worse than those obtained in previous studies using the same annotation scheme( #AUTHOR_TAG ) , but are still sat -isfactory given the high number of categories provided by the scheme']","['ures we also measured agreement on gesture segmentation.', 'The figures obtained are given in Table 3.', 'These results are slightly worse than those obtained in previous studies using the same annotation scheme( #AUTHOR_TAG ) , but are still sat -isfactory given the high number of categories provided by the scheme']","['', 'The annotations of this video were then used to measure inter-coder agreement in ANVIL as it was the case for the annotations on feedback expressions.', 'In the case of gestures we also measured agreement on gesture segmentation.', 'The figures obtained are given in Table 3.', 'These results are slightly worse than those obtained in previous studies using the same annotation scheme( #AUTHOR_TAG ) , but are still sat -isfactory given the high number of categories provided by the scheme']",1
"['', 'The results , which partly confirm those obtained on a smaller dataset in#AUTHOR_TAG , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions']","['', 'The results , which partly confirm those obtained on a smaller dataset in#AUTHOR_TAG , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions']","['', 'The results , which partly confirm those obtained on a smaller dataset in#AUTHOR_TAG , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions .', '']","['', 'The results , which partly confirm those obtained on a smaller dataset in#AUTHOR_TAG , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions .', '']",1
"['', 'The best results on most of our data were obtained using Hidden Naive Bayes ( HNB )( #AUTHOR_TAG ) .', 'Therefore, here we show the results of this classifier.', '']","['', 'The best results on most of our data were obtained using Hidden Naive Bayes ( HNB )( #AUTHOR_TAG ) .', 'Therefore, here we show the results of this classifier.', '']","['', 'The best results on most of our data were obtained using Hidden Naive Bayes ( HNB )( #AUTHOR_TAG ) .', 'Therefore, here we show the results of this classifier.', '']","['', 'The best results on most of our data were obtained using Hidden Naive Bayes ( HNB )( #AUTHOR_TAG ) .', 'Therefore, here we show the results of this classifier.', '']",5
"['', 'For this study, we added semantic labels -including dialogue acts -and gesture annotation.', 'Both kinds of annotation were carried out using ANVIL( #AUTHOR_TAG ) .', '']","['', 'For this study, we added semantic labels -including dialogue acts -and gesture annotation.', 'Both kinds of annotation were carried out using ANVIL( #AUTHOR_TAG ) .', '']","['', 'For this study, we added semantic labels -including dialogue acts -and gesture annotation.', 'Both kinds of annotation were carried out using ANVIL( #AUTHOR_TAG ) .', '']","['', 'For this study, we added semantic labels -including dialogue acts -and gesture annotation.', 'Both kinds of annotation were carried out using ANVIL( #AUTHOR_TAG ) .', '']",5
"[', for more information see Gr�nnum (2006).', 'The Praat tool was used( #AUTHOR_TAG )']","['version was produced with the supervision of an expert annotator, for more information see Gr�nnum (2006).', 'The Praat tool was used( #AUTHOR_TAG )']","['version was produced with the supervision of an expert annotator, for more information see Gr�nnum (2006).', 'The Praat tool was used( #AUTHOR_TAG )']","['onetic and prosodic segmentation and annotation were performed independently and in parallel by two annotators and then an agreed upon version was produced with the supervision of an expert annotator, for more information see Gr�nnum (2006).', 'The Praat tool was used( #AUTHOR_TAG )']",5
"['knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', ""The diagnoser , based on#AUTHOR_TAG b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer ."", '']","['knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', ""The diagnoser , based on#AUTHOR_TAG b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer ."", '']","['knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', ""The diagnoser , based on#AUTHOR_TAG b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer ."", '']","['knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', ""The diagnoser , based on#AUTHOR_TAG b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer ."", '']",2
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; #AUTHOR_TAG ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; #AUTHOR_TAG ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; #AUTHOR_TAG ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; #AUTHOR_TAG ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"['strategy decision , and a FUF/SURGE( #AUTHOR_TAG ) generation system to produce the appropriate text']","['strategy decision , and a FUF/SURGE( #AUTHOR_TAG ) generation system to produce the appropriate text']","['the strategy decision , and a FUF/SURGE( #AUTHOR_TAG ) generation system to produce the appropriate text .', '']","['', 'The system uses a domain-specific content planner to produce input to the surface realizer based on the strategy decision , and a FUF/SURGE( #AUTHOR_TAG ) generation system to produce the appropriate text .', '']",5
"['', 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain( #AUTHOR_TAG ) .', 'Using a deep']","['', 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain( #AUTHOR_TAG ) .', 'Using a deep']","['', 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain( #AUTHOR_TAG ) .', 'Using a deep generator to automatically generate system feedback gives us a level of control over the output']","['', 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain( #AUTHOR_TAG ) .', 'Using a deep generator to automatically generate system feedback gives us a level of control over the output and will allow us to devise experiments to study those issues in more detail']",3
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( #AUTHOR_TAG ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( #AUTHOR_TAG ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( #AUTHOR_TAG ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( #AUTHOR_TAG ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"['action between components is coordinated by the dialogue manager which uses the informationstate approach( #AUTHOR_TAG ) .', 'The dialogue state is represented by a cumulative answer analysis which tracks, over multiple']","['action between components is coordinated by the dialogue manager which uses the informationstate approach( #AUTHOR_TAG ) .', 'The dialogue state is represented by a cumulative answer analysis which tracks, over multiple turns, the correct, incorrect, and not-yet-mentioned parts of the answer.', 'Once the complete answer has been accumulated, the system accepts it and moves on.', 'Tutor hints can contribute']","['action between components is coordinated by the dialogue manager which uses the informationstate approach( #AUTHOR_TAG ) .', 'The dialogue state is represented by a cumulative answer analysis which tracks, over multiple']","['action between components is coordinated by the dialogue manager which uses the informationstate approach( #AUTHOR_TAG ) .', 'The dialogue state is represented by a cumulative answer analysis which tracks, over multiple turns, the correct, incorrect, and not-yet-mentioned parts of the answer.', 'Once the complete answer has been accumulated, the system accepts it and moves on.', 'Tutor hints can contribute parts of the answer to the cumulative state as well, allowing the system to jointly construct the solution with the student']",5
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; #AUTHOR_TAG ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; #AUTHOR_TAG ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; #AUTHOR_TAG ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; #AUTHOR_TAG ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"['key issue we are planning to investigate is that of linguistic alignment.', ""The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed( #AUTHOR_TAG ) ."", 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain(Ward and Litman, 2006)']","['key issue we are planning to investigate is that of linguistic alignment.', ""The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed( #AUTHOR_TAG ) ."", 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain(Ward and Litman, 2006)']","['the key issue we are planning to investigate is that of linguistic alignment.', ""The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed( #AUTHOR_TAG ) ."", 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain(Ward and Litman, 2006) .', '']","['dialogue management and generation, the key issue we are planning to investigate is that of linguistic alignment.', ""The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed( #AUTHOR_TAG ) ."", 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain(Ward and Litman, 2006) .', '']",3
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; #AUTHOR_TAG ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; #AUTHOR_TAG ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; #AUTHOR_TAG ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; #AUTHOR_TAG ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; #AUTHOR_TAG ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; #AUTHOR_TAG ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; #AUTHOR_TAG ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; #AUTHOR_TAG ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"['1 In addition to a remediation policy , the tutorial planner implements an error recovery policy( #AUTHOR_TAG ) .', '']","['.1 In addition to a remediation policy , the tutorial planner implements an error recovery policy( #AUTHOR_TAG ) .', '']","['1 In addition to a remediation policy , the tutorial planner implements an error recovery policy( #AUTHOR_TAG ) .', '']","['tutorial policy makes a high-level decision as to which strategy to use (for example, ""acknowledge the correct part and give a high specificity hint"") based on the answer analysis and dialogue context.', 'At present , the system takes into consideration the number of incorrect answers received in response to the current question and the number of uninterpretable answers .1 In addition to a remediation policy , the tutorial planner implements an error recovery policy( #AUTHOR_TAG ) .', '']",5
"[""contextual interpreter then uses a reference resolution approach similar to#AUTHOR_TAG , and an ontology mapping mechanism( Dzikovska et al. , 2008 a ) to produce a domain-specific semantic representation of the student 's output""]","[""contextual interpreter then uses a reference resolution approach similar to#AUTHOR_TAG , and an ontology mapping mechanism( Dzikovska et al. , 2008 a ) to produce a domain-specific semantic representation of the student 's output""]","['a domain-independent semantic representation including high-level word senses and semantic role labels.', ""The contextual interpreter then uses a reference resolution approach similar to#AUTHOR_TAG , and an ontology mapping mechanism( Dzikovska et al. , 2008 a ) to produce a domain-specific semantic representation of the student 's output ."", '']","['use the TRIPS dialogue parser(Allen et al., 2007) to parse the utterances.', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', ""The contextual interpreter then uses a reference resolution approach similar to#AUTHOR_TAG , and an ontology mapping mechanism( Dzikovska et al. , 2008 a ) to produce a domain-specific semantic representation of the student 's output ."", '']",1
"['BEETLE II system architecture is designed to overcome these limitations( #AUTHOR_TAG ) .', 'It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically.', 'This allows the system to consistently apply the same tutorial policy across a range of questions.', '']","['BEETLE II system architecture is designed to overcome these limitations( #AUTHOR_TAG ) .', 'It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically.', 'This allows the system to consistently apply the same tutorial policy across a range of questions.', '']","['BEETLE II system architecture is designed to overcome these limitations( #AUTHOR_TAG ) .', 'It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically.', 'This allows the system to consistently apply the same tutorial policy across a range of questions.', '']","['BEETLE II system architecture is designed to overcome these limitations( #AUTHOR_TAG ) .', 'It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically.', 'This allows the system to consistently apply the same tutorial policy across a range of questions.', 'To some extent, this comes at the expense of being able to address individual student misconceptions.', '']",0
"['', 'At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to#AUTHOR_TAG']","['', 'At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to#AUTHOR_TAG']","['', 'At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to#AUTHOR_TAG']","['', 'At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to#AUTHOR_TAG']",3
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; #AUTHOR_TAG ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; #AUTHOR_TAG ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; #AUTHOR_TAG ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ;  VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; #AUTHOR_TAG ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; #AUTHOR_TAG ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; #AUTHOR_TAG ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; #AUTHOR_TAG ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; #AUTHOR_TAG ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"[""and an ontology mapping mechanism( #AUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '']","[""and an ontology mapping mechanism( #AUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '']","[""and an ontology mapping mechanism( #AUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '']","['', ""The contextual interpreter then uses a reference resolution approach similar toByron ( 2002 ) , and an ontology mapping mechanism( #AUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '']",5
['factors such as student confidence could be considered as well( #AUTHOR_TAG )'],['factors such as student confidence could be considered as well( #AUTHOR_TAG )'],['factors such as student confidence could be considered as well( #AUTHOR_TAG )'],['factors such as student confidence could be considered as well( #AUTHOR_TAG )'],3
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; #AUTHOR_TAG ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; #AUTHOR_TAG ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; #AUTHOR_TAG ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; #AUTHOR_TAG ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; #AUTHOR_TAG ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; #AUTHOR_TAG ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; #AUTHOR_TAG ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step']","['the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; #AUTHOR_TAG ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '']",0
"['', 'Our recovery policy is modeled on the TargetedHelp( #AUTHOR_TAG ) policy used in task-oriented dialogue .', '']","['', 'Our recovery policy is modeled on the TargetedHelp( #AUTHOR_TAG ) policy used in task-oriented dialogue .', '']","['', 'Our recovery policy is modeled on the TargetedHelp( #AUTHOR_TAG ) policy used in task-oriented dialogue .', '']","['', 'Our recovery policy is modeled on the TargetedHelp( #AUTHOR_TAG ) policy used in task-oriented dialogue .', '']",2
"['use the TRIPS dialogue parser( #AUTHOR_TAG ) to parse the utterances .', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', '']","['use the TRIPS dialogue parser( #AUTHOR_TAG ) to parse the utterances .', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', '']","['use the TRIPS dialogue parser( #AUTHOR_TAG ) to parse the utterances .', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', '']","['use the TRIPS dialogue parser( #AUTHOR_TAG ) to parse the utterances .', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', '']",5
"['system uses a knowledge base implemented in the KM representation language( Clark and Porter , 1999 ; #AUTHOR_TAG ) to represent the state of the world .', 'At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits']","['system uses a knowledge base implemented in the KM representation language( Clark and Porter , 1999 ; #AUTHOR_TAG ) to represent the state of the world .', 'At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits']","['system uses a knowledge base implemented in the KM representation language( Clark and Porter , 1999 ; #AUTHOR_TAG ) to represent the state of the world .', 'At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits']","['system uses a knowledge base implemented in the KM representation language( Clark and Porter , 1999 ; #AUTHOR_TAG ) to represent the state of the world .', 'At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits']",5
"['current approaches to monolingual TE , either syntactically oriented( Rus et al. , 2005 ) , or applying logical inference( Tatu and Moldovan , 2005 ) , or adopting transformation-based techniques( #AUTHOR_TAG ; Bar-Haim et al. , 2008 ) , incorporate different types of']","['current approaches to monolingual TE , either syntactically oriented( Rus et al. , 2005 ) , or applying logical inference( Tatu and Moldovan , 2005 ) , or adopting transformation-based techniques( #AUTHOR_TAG ; Bar-Haim et al. , 2008 ) , incorporate different types of lexical knowledge to support textual inference']","['current approaches to monolingual TE , either syntactically oriented( Rus et al. , 2005 ) , or applying logical inference( Tatu and Moldovan , 2005 ) , or adopting transformation-based techniques( #AUTHOR_TAG ; Bar-Haim et al. , 2008 ) , incorporate different types of']","['current approaches to monolingual TE , either syntactically oriented( Rus et al. , 2005 ) , or applying logical inference( Tatu and Moldovan , 2005 ) , or adopting transformation-based techniques( #AUTHOR_TAG ; Bar-Haim et al. , 2008 ) , incorporate different types of lexical knowledge to support textual inference .', '']",0
"['rase tables (PHT) contain pairs of corresponding phrases in two languages, together with association probabilities.', 'They are widely used in MT as a way to figure out how to translate input in one language into output in another language( #AUTHOR_TAG ) .', 'There are several methods to build phrase tables.', '']","['rase tables (PHT) contain pairs of corresponding phrases in two languages, together with association probabilities.', 'They are widely used in MT as a way to figure out how to translate input in one language into output in another language( #AUTHOR_TAG ) .', 'There are several methods to build phrase tables.', '']","['rase tables (PHT) contain pairs of corresponding phrases in two languages, together with association probabilities.', 'They are widely used in MT as a way to figure out how to translate input in one language into output in another language( #AUTHOR_TAG ) .', 'There are several methods to build phrase tables.', '']","['rase tables (PHT) contain pairs of corresponding phrases in two languages, together with association probabilities.', 'They are widely used in MT as a way to figure out how to translate input in one language into output in another language( #AUTHOR_TAG ) .', 'There are several methods to build phrase tables.', '']",0
"[', DIRT( #AUTHOR_TAG ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs']","[', DIRT( #AUTHOR_TAG ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs,']","[', DIRT( #AUTHOR_TAG ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs']","[', DIRT( #AUTHOR_TAG ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are fre- quently used as a source of precise entailment rules between predicates.', '']",0
"['current approaches to monolingual TE , either syntactically oriented( Rus et al. , 2005 ) , or applying logical inference ( Tatu and#AUTHOR_TAG ) , or adopting transformation-based techniques( Kouleykov and Magnini , 2005 ;  Bar-Haim et al. , 2008 ) , incorporate different types of']","['current approaches to monolingual TE , either syntactically oriented( Rus et al. , 2005 ) , or applying logical inference ( Tatu and#AUTHOR_TAG ) , or adopting transformation-based techniques( Kouleykov and Magnini , 2005 ;  Bar-Haim et al. , 2008 ) , incorporate different types of lexical knowledge to support textual inference .', '']","['current approaches to monolingual TE , either syntactically oriented( Rus et al. , 2005 ) , or applying logical inference ( Tatu and#AUTHOR_TAG ) , or adopting transformation-based techniques( Kouleykov and Magnini , 2005 ;  Bar-Haim et al. , 2008 ) , incorporate different types of']","['current approaches to monolingual TE , either syntactically oriented( Rus et al. , 2005 ) , or applying logical inference ( Tatu and#AUTHOR_TAG ) , or adopting transformation-based techniques( Kouleykov and Magnini , 2005 ;  Bar-Haim et al. , 2008 ) , incorporate different types of lexical knowledge to support textual inference .', '']",0
"['', 'Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by( #AUTHOR_TAG ) .', ""The method relies on translation-validation cycles, defined as separate jobs routed to MTurk's workforce."", 'Translation jobs return one Spanish version for each hypothesis.', '']","['', 'Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by( #AUTHOR_TAG ) .', ""The method relies on translation-validation cycles, defined as separate jobs routed to MTurk's workforce."", 'Translation jobs return one Spanish version for each hypothesis.', 'Validation jobs ask multiple workers to check the correctness of each translation using the original English sentence as reference.', '']","['', 'Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by( #AUTHOR_TAG ) .', ""The method relies on translation-validation cycles, defined as separate jobs routed to MTurk's workforce."", 'Translation jobs return one Spanish version for each hypothesis.', '']","['', 'Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by( #AUTHOR_TAG ) .', ""The method relies on translation-validation cycles, defined as separate jobs routed to MTurk's workforce."", 'Translation jobs return one Spanish version for each hypothesis.', 'Validation jobs ask multiple workers to check the correctness of each translation using the original English sentence as reference.', 'At each cycle, the translated hypothesis accepted by the majority of trustful validators 5 are stored in the CLTE corpus, while wrong translations are sent back to workers in a new translation job.', '']",5
"['-lingual Textual Entailment ( CLTE ) has been proposed by( #AUTHOR_TAG ) as an extension of Textual Entailment( Dagan and Glickman , 2004 ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', '']","['-lingual Textual Entailment ( CLTE ) has been proposed by( #AUTHOR_TAG ) as an extension of Textual Entailment( Dagan and Glickman , 2004 ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', '']","['-lingual Textual Entailment ( CLTE ) has been proposed by( #AUTHOR_TAG ) as an extension of Textual Entailment( Dagan and Glickman , 2004 ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', '']","['-lingual Textual Entailment ( CLTE ) has been proposed by( #AUTHOR_TAG ) as an extension of Textual Entailment( Dagan and Glickman , 2004 ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', '']",0
"['system.', 'Using the basic solution proposed by( #AUTHOR_TAG ) as a term of comparison , we experiment with different sources of multilingual lexical knowledge to address the following questions']","['system.', 'Using the basic solution proposed by( #AUTHOR_TAG ) as a term of comparison , we experiment with different sources of multilingual lexical knowledge to address the following questions']","['any TE system.', 'Using the basic solution proposed by( #AUTHOR_TAG ) as a term of comparison , we experiment with different sources of multilingual lexical knowledge to address the following questions']","['', 'Using the basic solution proposed by( #AUTHOR_TAG ) as a term of comparison , we experiment with different sources of multilingual lexical knowledge to address the following questions']",1
"['tokenization , and used the Giza + +( #AUTHOR_TAG ) to align the tokenized corpora at the word level .', '']","['tokenization , and used the Giza + +( #AUTHOR_TAG ) to align the tokenized corpora at the word level .', '']","['tokenization , and used the Giza + +( #AUTHOR_TAG ) to align the tokenized corpora at the word level .', '']","['', 'We run TreeTagger( Schmid , 1994 ) for tokenization , and used the Giza + +( #AUTHOR_TAG ) to align the tokenized corpora at the word level .', '']",5
"['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization( #AUTHOR_TAG ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( Dinu and Wang , 2009 )']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization( #AUTHOR_TAG ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( Dinu and Wang , 2009 )']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization( #AUTHOR_TAG ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( Dinu and Wang , 2009 ) .', '']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization( #AUTHOR_TAG ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( Dinu and Wang , 2009 ) .', '']",4
"[', even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works( #AUTHOR_TAG ; Zhao et al. , 2009 ; Kouylekov et al. , 2009 ) indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words']","[', even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works( #AUTHOR_TAG ; Zhao et al. , 2009 ; Kouylekov et al. , 2009 ) indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words']","[', even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works( #AUTHOR_TAG ; Zhao et al. , 2009 ; Kouylekov et al. , 2009 ) indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words']","['the consensus on the usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, as they always represent one component in complex architectures that may use them in different ways.', 'As emerges from the ablation tests reported in(Bentivogli et al., 2010) , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works( #AUTHOR_TAG ; Zhao et al. , 2009 ; Kouylekov et al. , 2009 ) indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words']",0
"['combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight( #AUTHOR_TAG ) , using each score as a feature']","['combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight( #AUTHOR_TAG ) , using each score as a feature']","['combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight( #AUTHOR_TAG ) , using each score as a feature']","['combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight( #AUTHOR_TAG ) , using each score as a feature']",5
"['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( #AUTHOR_TAG ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( Dinu and Wang , 2009 )']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( #AUTHOR_TAG ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( Dinu and Wang , 2009 )']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( #AUTHOR_TAG ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( Dinu and Wang , 2009 ) .', '']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( #AUTHOR_TAG ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( Dinu and Wang , 2009 ) .', '']",4
"['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010; Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( #AUTHOR_TAG ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte-']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010; Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( #AUTHOR_TAG ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010; Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( #AUTHOR_TAG ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte-']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010; Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( #AUTHOR_TAG ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', '']",0
"['', 'Multilingual lexical databases aligned with the English WordNet ( e.g. MultiWordNet( #AUTHOR_TAG ) ) have been created for several languages , with different degrees of coverage .', 'As an example, the 57,424 synsets of the Spanish section of MultiWordNet aligned to English cover just around 50% of the WordNet�s synsets, thus making the coverage issue even more problematic than for TE.', '']","['', 'Multilingual lexical databases aligned with the English WordNet ( e.g. MultiWordNet( #AUTHOR_TAG ) ) have been created for several languages , with different degrees of coverage .', 'As an example, the 57,424 synsets of the Spanish section of MultiWordNet aligned to English cover just around 50% of the WordNet�s synsets, thus making the coverage issue even more problematic than for TE.', '']","['', 'Multilingual lexical databases aligned with the English WordNet ( e.g. MultiWordNet( #AUTHOR_TAG ) ) have been created for several languages , with different degrees of coverage .', 'As an example, the 57,424 synsets of the Spanish section of MultiWordNet aligned to English cover just around 50% of the WordNet�s synsets, thus making the coverage issue even more problematic than for TE.', '']","['', 'Multilingual lexical databases aligned with the English WordNet ( e.g. MultiWordNet( #AUTHOR_TAG ) ) have been created for several languages , with different degrees of coverage .', 'As an example, the 57,424 synsets of the Spanish section of MultiWordNet aligned to English cover just around 50% of the WordNet�s synsets, thus making the coverage issue even more problematic than for TE.', '']",0
"['', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( #AUTHOR_TAG ) .', '']","['the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( #AUTHOR_TAG ) .', '']","['', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( #AUTHOR_TAG ) .', '']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( Denkowski and Lavie , 2010 ) , and TE( #AUTHOR_TAG ) .', '']",4
"['', 'One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus( #AUTHOR_TAG ) .', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', '']","['', 'One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus( #AUTHOR_TAG ) .', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', '']","['', 'One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus( #AUTHOR_TAG ) .', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', '']","['', 'One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus( #AUTHOR_TAG ) .', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', '']",0
"['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010;Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( #AUTHOR_TAG ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs,']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010;Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( #AUTHOR_TAG ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs,']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010;Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( #AUTHOR_TAG ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs,']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010;Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( Baker et al. , 1998 ) , and Wikipedia( #AUTHOR_TAG ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', '']",0
"['-lingual Textual Entailment ( CLTE ) has been proposed by( Mehdad et al. , 2010 ) as an extension of Textual Entailment( #AUTHOR_TAG ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult']","['-lingual Textual Entailment ( CLTE ) has been proposed by( Mehdad et al. , 2010 ) as an extension of Textual Entailment( #AUTHOR_TAG ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult,']","['-lingual Textual Entailment ( CLTE ) has been proposed by( Mehdad et al. , 2010 ) as an extension of Textual Entailment( #AUTHOR_TAG ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult']","['-lingual Textual Entailment ( CLTE ) has been proposed by( Mehdad et al. , 2010 ) as an extension of Textual Entailment( #AUTHOR_TAG ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', '']",0
"['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010; Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( #AUTHOR_TAG ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010; Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( #AUTHOR_TAG ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010; Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( #AUTHOR_TAG ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', 'DIRT is a collection of']","['WordNet, the RTE literature documents the use of a variety of lexical information sources(Bentivogli et al., 2010; Dagan et al., 2009) .', 'These include, just to mention the most popular ones , DIRT( Lin and Pantel , 2001 ) , VerbOcean( Chklovski and Pantel , 2004 ) , FrameNet( #AUTHOR_TAG ) , and Wikipedia( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .', '']",0
"['', 'After the extraction , pruning techniques( #AUTHOR_TAG ) can be applied to increase the precision of the extracted paraphrases']","['phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', 'After the extraction , pruning techniques( #AUTHOR_TAG ) can be applied to increase the precision of the extracted paraphrases']","['', 'After the extraction , pruning techniques( #AUTHOR_TAG ) can be applied to increase the precision of the extracted paraphrases']","['', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', 'After the extraction , pruning techniques( #AUTHOR_TAG ) can be applied to increase the precision of the extracted paraphrases']",0
"['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( #AUTHOR_TAG ) , and TE( Dinu and Wang , 2009 )']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( #AUTHOR_TAG ) , and TE( Dinu and Wang , 2009 )']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( #AUTHOR_TAG ) , and TE( Dinu and Wang , 2009 ) .', '']","['aphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation( Iordanskaja et al. , 1991 ) , multidocument summarization ( McKeown et al. , 2002 ) , automatic evaluation of MT( #AUTHOR_TAG ) , and TE( Dinu and Wang , 2009 ) .', '']",4
"[', even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works( Bannard and Callison-Burch , 2005 ; #AUTHOR_TAG ; Kouylekov et al. , 2009 ) indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words']","[', even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works( Bannard and Callison-Burch , 2005 ; #AUTHOR_TAG ; Kouylekov et al. , 2009 ) indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words']","[', even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works( Bannard and Callison-Burch , 2005 ; #AUTHOR_TAG ; Kouylekov et al. , 2009 ) indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words']","['the consensus on the usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, as they always represent one component in complex architectures that may use them in different ways.', 'As emerges from the ablation tests reported in(Bentivogli et al., 2010) , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works( Bannard and Callison-Burch , 2005 ; #AUTHOR_TAG ; Kouylekov et al. , 2009 ) indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words']",0
"[""the sake of completeness , we report in this section also the results obtained adopting the `` basic solution '' proposed by( #AUTHOR_TAG ) ."", 'Although it was presented as an approach to CLTE, the proposed method brings the problem back to the monolingual case by translating H into the language of']","[""the sake of completeness , we report in this section also the results obtained adopting the `` basic solution '' proposed by( #AUTHOR_TAG ) ."", 'Although it was presented as an approach to CLTE, the proposed method brings the problem back to the monolingual case by translating H into the language of T.']","[""the sake of completeness , we report in this section also the results obtained adopting the `` basic solution '' proposed by( #AUTHOR_TAG ) ."", 'Although it was presented as an approach to CLTE, the proposed method brings the problem back to the monolingual case by translating H into the language of']","[""the sake of completeness , we report in this section also the results obtained adopting the `` basic solution '' proposed by( #AUTHOR_TAG ) ."", '']",1
"['CLTE.', 'On one side, we plan to explore alternative ways to build phrase and paraphrase tables.', 'One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by( #AUTHOR_TAG ) .', '']","['CLTE.', 'On one side, we plan to explore alternative ways to build phrase and paraphrase tables.', 'One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by( #AUTHOR_TAG ) .', '']","['CLTE.', 'On one side, we plan to explore alternative ways to build phrase and paraphrase tables.', 'One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by( #AUTHOR_TAG ) .', 'Another interesting direction is to investigate the potential of paraphrase patterns (i.e.', 'patterns including']","['future work will address both the extraction of lexical information from bilingual parallel corpora, and its use for TE and CLTE.', 'On one side, we plan to explore alternative ways to build phrase and paraphrase tables.', 'One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by( #AUTHOR_TAG ) .', 'Another interesting direction is to investigate the potential of paraphrase patterns (i.e.', '']",3
"['(WIKI).', 'We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool( #AUTHOR_TAG ) to measure the relatedness between words in the dataset .', '']","['(WIKI).', 'We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool( #AUTHOR_TAG ) to measure the relatedness between words in the dataset .', '']","['(WIKI).', 'We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool( #AUTHOR_TAG ) to measure the relatedness between words in the dataset .', '']","['(WIKI).', 'We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool( #AUTHOR_TAG ) to measure the relatedness between words in the dataset .', '']",5
"['.', 'Second , in line with the findings of( #AUTHOR_TAG ) , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .', '63.50%).', 'Third, the accuracy obtained over the CLTE corpus using combined phrase and paraphrase tables (62.88%, as reported in Table 1) is comparable to the best result gained over the automatically translated dataset (63.50%).', '']","['table.', 'Second , in line with the findings of( #AUTHOR_TAG ) , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .', '63.50%).', 'Third, the accuracy obtained over the CLTE corpus using combined phrase and paraphrase tables (62.88%, as reported in Table 1) is comparable to the best result gained over the automatically translated dataset (63.50%).', '']","['', 'Second , in line with the findings of( #AUTHOR_TAG ) , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .', '63.50%).', 'Third, the accuracy obtained over the CLTE corpus using combined phrase and paraphrase tables (62.88%, as reported in Table 1) is comparable to the best result gained over the automatically translated dataset (63.50%).', '']","['', 'This suggests that the noise introduced by incorrect translations can be tackled by increasing the coverage of the paraphrase table.', 'Second , in line with the findings of( #AUTHOR_TAG ) , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .', '63.50%).', 'Third, the accuracy obtained over the CLTE corpus using combined phrase and paraphrase tables (62.88%, as reported in Table 1) is comparable to the best result gained over the automatically translated dataset (63.50%).', '']",1
"['sequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit( #AUTHOR_TAG ) .', '']","['', 'Subsequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit( #AUTHOR_TAG ) .', '']","['sequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit( #AUTHOR_TAG ) .', '']","['', 'Subsequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit( #AUTHOR_TAG ) .', '']",5
"['WordNet , the RTE literature documents the use of a variety of lexical information sources( Bentivogli et al. , 2010 ; #AUTHOR_TAG ) .', 'These include, just to mention the most popular ones, DIRT(Lin and Pantel, 2001) , VerbOcean(Chklovski and Pantel, 2004) , FrameNet(Baker et al., 1998) , andWikipedia Kouylekov et al., 2009) .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet']","['WordNet , the RTE literature documents the use of a variety of lexical information sources( Bentivogli et al. , 2010 ; #AUTHOR_TAG ) .', 'These include, just to mention the most popular ones, DIRT(Lin and Pantel, 2001) , VerbOcean(Chklovski and Pantel, 2004) , FrameNet(Baker et al., 1998) , andWikipedia Kouylekov et al., 2009) .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet']","['WordNet , the RTE literature documents the use of a variety of lexical information sources( Bentivogli et al. , 2010 ; #AUTHOR_TAG ) .', 'These include, just to mention the most popular ones, DIRT(Lin and Pantel, 2001) , VerbOcean(Chklovski and Pantel, 2004) , FrameNet(Baker et al., 1998) , andWikipedia Kouylekov et al., 2009) .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet']","['WordNet , the RTE literature documents the use of a variety of lexical information sources( Bentivogli et al. , 2010 ; #AUTHOR_TAG ) .', 'These include, just to mention the most popular ones, DIRT(Lin and Pantel, 2001) , VerbOcean(Chklovski and Pantel, 2004) , FrameNet(Baker et al., 1998) , andWikipedia Kouylekov et al., 2009) .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', '']",0
"['questions are typically answered by designing appropriate priming experiments( #AUTHOR_TAG ) or other lexical decision tasks .', 'The reaction time of the subjects for recognizing various lexical items under appropriate conditions reveals important facts about their organization in the brain.', '(See Sec. 2 for models of morphological organization and access and related experiments']","['questions are typically answered by designing appropriate priming experiments( #AUTHOR_TAG ) or other lexical decision tasks .', 'The reaction time of the subjects for recognizing various lexical items under appropriate conditions reveals important facts about their organization in the brain.', '(See Sec. 2 for models of morphological organization and access and related experiments']","['questions are typically answered by designing appropriate priming experiments( #AUTHOR_TAG ) or other lexical decision tasks .', 'The reaction time of the subjects for recognizing various lexical items under appropriate conditions reveals important facts about their organization in the brain.', '(See Sec. 2 for models of morphological organization and access and related experiments']","['questions are typically answered by designing appropriate priming experiments( #AUTHOR_TAG ) or other lexical decision tasks .', 'The reaction time of the subjects for recognizing various lexical items under appropriate conditions reveals important facts about their organization in the brain.', '(See Sec. 2 for models of morphological organization and access and related experiments']",0
"['', 'We measure the inter annotator agreement using the Fleiss Kappa( #AUTHOR_TAG ) measure ( x ) where the agreement lies around 0.79 .', 'Next']","['', 'We measure the inter annotator agreement using the Fleiss Kappa( #AUTHOR_TAG ) measure ( x ) where the agreement lies around 0.79 .', 'Next,']","['', 'We measure the inter annotator agreement using the Fleiss Kappa( #AUTHOR_TAG ) measure ( x ) where the agreement lies around 0.79 .', 'Next']","['', 'We measure the inter annotator agreement using the Fleiss Kappa( #AUTHOR_TAG ) measure ( x ) where the agreement lies around 0.79 .', 'Next, out of the common verb sequences that were annotated by all the three linguists, we randomly choose 300 V1+V2 pairs and presented them to 36 native Bangla speakers.', 'We ask each subjects to give a']",5
"['to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', 'Similar findings have been proposed by#AUTHOR_TAG that points out V1 and V2 are paired on the basis of their semantic compatibility , which is subject to syntactic constraints .', '']","['to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', 'Similar findings have been proposed by#AUTHOR_TAG that points out V1 and V2 are paired on the basis of their semantic compatibility , which is subject to syntactic constraints .', '']","['to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', 'Similar findings have been proposed by#AUTHOR_TAG that points out V1 and V2 are paired on the basis of their semantic compatibility , which is subject to syntactic constraints .', '']","['', 'Bashir (1993) tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', 'Similar findings have been proposed by#AUTHOR_TAG that points out V1 and V2 are paired on the basis of their semantic compatibility , which is subject to syntactic constraints .', '']",0
"['order to validate such claim we perform a lexical', 'decision experiment using native Bangla speakers with 92 different verb sequences. We followed the same experimental procedure as discussed in( #AUTHOR_TAG ) for English polymorphemic words .']","['order to validate such claim we perform a lexical', 'decision experiment using native Bangla speakers with 92 different verb sequences. We followed the same experimental procedure as discussed in( #AUTHOR_TAG ) for English polymorphemic words .']","['order to validate such claim we perform a lexical', 'decision experiment using native Bangla speakers with 92 different verb sequences. We followed the same experimental procedure as discussed in( #AUTHOR_TAG ) for English polymorphemic words .']","['', 'to a single expression of meaning. In order to validate such claim we perform a lexical', 'decision experiment using native Bangla speakers with 92 different verb sequences. We followed the same experimental procedure as discussed in( #AUTHOR_TAG ) for English polymorphemic words . However, rather than derived', '']",5
"['', '#AUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', '']","['', '#AUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', '']","['', '#AUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', '']","['', '#AUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', '']",0
"['has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', '(Taft, 1975) with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by( Bertram et al. , 2000 ; Bradley , 1980 ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ;  Taft 1975 ;#AUTHOR_TAG ) where it has been claimed that words having low surface frequency tends to decompose .', '']","['has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', '(Taft, 1975) with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by( Bertram et al. , 2000 ; Bradley , 1980 ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ;  Taft 1975 ;#AUTHOR_TAG ) where it has been claimed that words having low surface frequency tends to decompose .', '']","['has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', '(Taft, 1975) with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by( Bertram et al. , 2000 ; Bradley , 1980 ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ;  Taft 1975 ;#AUTHOR_TAG ) where it has been claimed that words having low surface frequency tends to decompose .', '']","['has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', '(Taft, 1975) with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by( Bertram et al. , 2000 ; Bradley , 1980 ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ;  Taft 1975 ;#AUTHOR_TAG ) where it has been claimed that words having low surface frequency tends to decompose .', '']",0
"['the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', 'Most of the studies are designed to support one of the two mutually exclusive paradigms: the full-listing and the morphemic model.', 'The full-listing model claims that polymorphic words are represented as a whole in the human mental lexicon( #AUTHOR_TAG ; Butterworth , 1983 ) .', '']","['the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', 'Most of the studies are designed to support one of the two mutually exclusive paradigms: the full-listing and the morphemic model.', 'The full-listing model claims that polymorphic words are represented as a whole in the human mental lexicon( #AUTHOR_TAG ; Butterworth , 1983 ) .', '']","['the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', 'Most of the studies are designed to support one of the two mutually exclusive paradigms: the full-listing and the morphemic model.', 'The full-listing model claims that polymorphic words are represented as a whole in the human mental lexicon( #AUTHOR_TAG ; Butterworth , 1983 ) .', '']","['the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', 'Most of the studies are designed to support one of the two mutually exclusive paradigms: the full-listing and the morphemic model.', 'The full-listing model claims that polymorphic words are represented as a whole in the human mental lexicon( #AUTHOR_TAG ; Butterworth , 1983 ) .', 'On the other hand, morphemic model argues that morphologically complex words are decomposed and represented in terms of the smaller morphemic units.', '']",0
"['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ; #AUTHOR_TAG ; Drews and Zwitserlood , 1995 ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cous']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ; #AUTHOR_TAG ; Drews and Zwitserlood , 1995 ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ; #AUTHOR_TAG ; Drews and Zwitserlood , 1995 ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ; #AUTHOR_TAG ; Drews and Zwitserlood , 1995 ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '']",0
"['.', '#AUTHOR_TAG argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .', '']","['auxiliaries.', '#AUTHOR_TAG argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .', '']","['', '#AUTHOR_TAG argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .', '']","['', '#AUTHOR_TAG argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .', '']",0
"['respect to this , we apply the different priming and other lexical decision experiments , described in literature( #AUTHOR_TAG ; Bentin , S. andFeldman , 1990 ) specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .', '']","['respect to this , we apply the different priming and other lexical decision experiments , described in literature( #AUTHOR_TAG ; Bentin , S. andFeldman , 1990 ) specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .', '']","['respect to this , we apply the different priming and other lexical decision experiments , described in literature( #AUTHOR_TAG ; Bentin , S. andFeldman , 1990 ) specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .', '']","['respect to this , we apply the different priming and other lexical decision experiments , described in literature( #AUTHOR_TAG ; Bentin , S. andFeldman , 1990 ) specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .', '']",5
"['apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in( #AUTHOR_TAG ; Rastle et al. , 2000 ; Marslen-Wilson et al. , 1994 ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .', '']","['apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in( #AUTHOR_TAG ; Rastle et al. , 2000 ; Marslen-Wilson et al. , 1994 ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .', 'Here, the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for masked priming).', 'The']","['apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in( #AUTHOR_TAG ; Rastle et al. , 2000 ; Marslen-Wilson et al. , 1994 ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .', '']","['apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in( #AUTHOR_TAG ; Rastle et al. , 2000 ; Marslen-Wilson et al. , 1994 ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .', 'Here, the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for masked priming).', '']",5
"['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages( Marslen-Wilson et al. , 2008 ; #AUTHOR_TAG ; Grainger , et al. , 1991 ;Drews and Zwitserlood , 1995 ) .', '']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages( Marslen-Wilson et al. , 2008 ; #AUTHOR_TAG ; Grainger , et al. , 1991 ;Drews and Zwitserlood , 1995 ) .', '']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages( Marslen-Wilson et al. , 2008 ; #AUTHOR_TAG ; Grainger , et al. , 1991 ;Drews and Zwitserlood , 1995 ) .', '']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages( Marslen-Wilson et al. , 2008 ; #AUTHOR_TAG ; Grainger , et al. , 1991 ;Drews and Zwitserlood , 1995 ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '']",0
"['apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in( Forster and Davis , 1984 ; Rastle et al. , 2000 ; #AUTHOR_TAG ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .', '']","['apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in( Forster and Davis , 1984 ; Rastle et al. , 2000 ; #AUTHOR_TAG ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .', 'Here, the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for masked priming).', 'The']","['apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in( Forster and Davis , 1984 ; Rastle et al. , 2000 ; #AUTHOR_TAG ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .', '']","['apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in( Forster and Davis , 1984 ; Rastle et al. , 2000 ; #AUTHOR_TAG ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .', 'Here, the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for masked priming).', '']",5
"['', 'Their computational significance arises from the issue of their storage in lexical resources like WordNet( #AUTHOR_TAG ) and raises the questions like , how to store morphologically complex words , in a lexical resource like WordNet keeping in mind the storage and access efficiency']","['', 'Their computational significance arises from the issue of their storage in lexical resources like WordNet( #AUTHOR_TAG ) and raises the questions like , how to store morphologically complex words , in a lexical resource like WordNet keeping in mind the storage and access efficiency']","['', 'Their computational significance arises from the issue of their storage in lexical resources like WordNet( #AUTHOR_TAG ) and raises the questions like , how to store morphologically complex words , in a lexical resource like WordNet keeping in mind the storage and access efficiency']","['', 'Their computational significance arises from the issue of their storage in lexical resources like WordNet( #AUTHOR_TAG ) and raises the questions like , how to store morphologically complex words , in a lexical resource like WordNet keeping in mind the storage and access efficiency']",0
"['', 'On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent( #AUTHOR_TAG ) .', 'Therefore, the findings from experiments in one language cannot be generalized to all languages making it important to conduct similar experimentations in other languages']","['', 'On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent( #AUTHOR_TAG ) .', 'Therefore, the findings from experiments in one language cannot be generalized to all languages making it important to conduct similar experimentations in other languages']","['', 'On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent( #AUTHOR_TAG ) .', 'Therefore, the findings from experiments in one language cannot be generalized to all languages making it important to conduct similar experimentations in other languages']","['', 'Moreover, Indian languages show some distinct phenomena like, compound and composite verbs for which no such investigations have been conducted yet.', 'On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent( #AUTHOR_TAG ) .', 'Therefore, the findings from experiments in one language cannot be generalized to all languages making it important to conduct similar experimentations in other languages']",0
"['to these two paradigms is the partial decomposition model that argues that different types of morphological forms are processed separately.', 'For instance , the derived morphological forms are believed to be represented as a whole , whereas the representation of the inflected forms follows the morphemic model( #AUTHOR_TAG )']","['', 'Intermediate to these two paradigms is the partial decomposition model that argues that different types of morphological forms are processed separately.', 'For instance , the derived morphological forms are believed to be represented as a whole , whereas the representation of the inflected forms follows the morphemic model( #AUTHOR_TAG )']","['to these two paradigms is the partial decomposition model that argues that different types of morphological forms are processed separately.', 'For instance , the derived morphological forms are believed to be represented as a whole , whereas the representation of the inflected forms follows the morphemic model( #AUTHOR_TAG )']","['', 'Intermediate to these two paradigms is the partial decomposition model that argues that different types of morphological forms are processed separately.', 'For instance , the derived morphological forms are believed to be represented as a whole , whereas the representation of the inflected forms follows the morphemic model( #AUTHOR_TAG )']",0
"['plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '#AUTHOR_TAG considers the second verb V2 as an aspectual complex comparable to the auxiliaries .', '']","['plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '#AUTHOR_TAG considers the second verb V2 as an aspectual complex comparable to the auxiliaries .', '']","['plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '#AUTHOR_TAG considers the second verb V2 as an aspectual complex comparable to the auxiliaries .', '']","['plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '#AUTHOR_TAG considers the second verb V2 as an aspectual complex comparable to the auxiliaries .', '']",0
"['has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', '(Taft, 1975) with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by( Bertram et al. , 2000 ; #AUTHOR_TAG ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ;  Taft 1975 ;Taft , 2004 ) where it has been claimed that words having low surface frequency tends to decompose .', '']","['has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', '(Taft, 1975) with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by( Bertram et al. , 2000 ; #AUTHOR_TAG ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ;  Taft 1975 ;Taft , 2004 ) where it has been claimed that words having low surface frequency tends to decompose .', '']","['has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', '(Taft, 1975) with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by( Bertram et al. , 2000 ; #AUTHOR_TAG ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ;  Taft 1975 ;Taft , 2004 ) where it has been claimed that words having low surface frequency tends to decompose .', '']","['has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', '(Taft, 1975) with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by( Bertram et al. , 2000 ; #AUTHOR_TAG ; Burani et al. , 1987 ; Burani et al. , 1984 ; Schreuder et al. , 1997 ;  Taft 1975 ;Taft , 2004 ) where it has been claimed that words having low surface frequency tends to decompose .', '']",0
"['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ;  Grainger , et al. , 1991 ;#AUTHOR_TAG ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ;  Grainger , et al. , 1991 ;#AUTHOR_TAG ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ;  Grainger , et al. , 1991 ;#AUTHOR_TAG ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-']","['is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ;  Grainger , et al. , 1991 ;#AUTHOR_TAG ) .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '']",0

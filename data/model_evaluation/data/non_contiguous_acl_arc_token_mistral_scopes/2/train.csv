token_context,word_context,seg_context,sent_cotext,label
"['The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory: FoG (Kittredge and Polgu~re, 1991), LFS #AUTHOR_TAG , and JOYCE #AUTHOR_TAG .', 'The framework was originally developed for the realization of deep-syntactic structures in NLG #TAUTHOR_TAG .']","['The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory: FoG (Kittredge and Polgu~re, 1991), LFS #AUTHOR_TAG , and JOYCE #AUTHOR_TAG .', 'The framework was originally developed for the realization of deep-syntactic structures in NLG #TAUTHOR_TAG .']","['The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory: FoG (Kittredge and Polgu~re, 1991), LFS #AUTHOR_TAG , and JOYCE #AUTHOR_TAG .', 'The framework was originally developed for the realization of deep-syntactic structures in NLG #TAUTHOR_TAG .']","['The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory: FoG (Kittredge and Polgu~re, 1991), LFS #AUTHOR_TAG , and JOYCE #AUTHOR_TAG .', 'The framework was originally developed for the realization of deep-syntactic structures in NLG #TAUTHOR_TAG .']",0
"['these a dependency structure a very useful for since gives linguists a representation that allows them to abstract over numerous crossuistic divergences due language specificPol', 'Figure 2 illustrates a DSyntS from a meteorological application , MeteoCogent #AUTHOR_TAG , represented using the standard graphical notation and also the RealPro ASCII notation used internally in the framework #TAUTHOR_TAG .']","['these a dependency structure a very useful for since gives linguists a representation that allows them to abstract over numerous crosslinguistic divergences due language specific', 'Figure 2 illustrates a DSyntS from a meteorological application , MeteoCogent #AUTHOR_TAG , represented using the standard graphical notation and also the RealPro ASCII notation used internally in the framework #TAUTHOR_TAG .']","['these characteristics a dependency tree structure a very useful representation for since it gives linguists a representation that allows them to abstract over numerous crosslinguistic divergences due language specificPol', 'Figure 2 illustrates a DSyntS from a meteorological application , MeteoCogent #AUTHOR_TAG , represented using the standard graphical notation and also the RealPro ASCII notation used internally in the framework #TAUTHOR_TAG .']","['', 'Figure 2 illustrates a DSyntS from a meteorological application , MeteoCogent #AUTHOR_TAG , represented using the standard graphical notation and also the RealPro ASCII notation used internally in the framework #TAUTHOR_TAG .']",2
"['--o II a failli pleuvoir.', 'More details on how the structural divergences described in #TAUTHOR_TAG can be accounted for using our formalism can be found in #AUTHOR_TAG .']","['--o II a failli pleuvoir.', 'More details on how the structural divergences described in #TAUTHOR_TAG can be accounted for using our formalism can be found in #AUTHOR_TAG .']","['--o II a failli pleuvoir.', 'More details on how the structural divergences described in #TAUTHOR_TAG can be accounted for using our formalism can be found in #AUTHOR_TAG .']","['--o II a failli pleuvoir.', 'More details on how the structural divergences described in #TAUTHOR_TAG can be accounted for using our formalism can be found in #AUTHOR_TAG .']",0
"['', 'transfer', 'Our work extends directions taken in systems such as Ariane #AUTHOR_TAG FoG #AUTHOR_TAG , JOYCE ( Rambow and #TAUTHOR_TAG , and LFS #AUTHOR_TAG .', 'Although adopts the general in the abovementioned systems practical integrate better with emerging-based approaches']","['', 'transfer', 'Our work extends directions taken in systems such as Ariane #AUTHOR_TAG FoG #AUTHOR_TAG , JOYCE ( Rambow and #TAUTHOR_TAG , and LFS #AUTHOR_TAG .', 'Although adopts the general in the abovementioned systems, practical, integrate better with emerging statistics-based approaches']","['', 'transfer', 'Our work extends directions taken in systems such as Ariane #AUTHOR_TAG FoG #AUTHOR_TAG , JOYCE ( Rambow and #TAUTHOR_TAG , and LFS #AUTHOR_TAG .', 'Although it adopts the general principles in the abovementioned systems, practical integrate better with emerging statistics-based approaches']","['', '', 'Our work extends directions taken in systems such as Ariane #AUTHOR_TAG , FoG #AUTHOR_TAG , JOYCE ( Rambow and #TAUTHOR_TAG , and LFS #AUTHOR_TAG .', '']",2
"['The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory : FoG #AUTHOR_TAG , LFS #AUTHOR_TAG , and JOYCE ( Rambow and #TAUTHOR_TAG .', 'The framework was originally developed for the realization of deep-syntactic structures in NLG .']","['The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory : FoG #AUTHOR_TAG , LFS #AUTHOR_TAG , and JOYCE ( Rambow and #TAUTHOR_TAG .', 'The framework was originally developed for the realization of deep-syntactic structures in NLG .']","['The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory : FoG #AUTHOR_TAG , LFS #AUTHOR_TAG , and JOYCE ( Rambow and #TAUTHOR_TAG .', 'The framework was originally developed for the realization of deep-syntactic structures in NLG .']","['The framework represents a generalization of several predecessor NLG systems based on Meaning-Text Theory : FoG #AUTHOR_TAG , LFS #AUTHOR_TAG , and JOYCE ( Rambow and #TAUTHOR_TAG .', 'The framework was originally developed for the realization of deep-syntactic structures in NLG .']",2
"['text AS format ation is not is sentence boundary information', '', ""of speech taggers typically require input in the format of a single sentence per line ( for example Brill 's tagger #TAUTHOR_TAG ) and parsers generally aim to produce a tree spanning each sentence .""]","['text ASR format ation is not is sentence boundary information.', '', ""of speech taggers typically require input in the format of a single sentence per line ( for example Brill 's tagger #TAUTHOR_TAG ) and parsers generally aim to produce a tree spanning each sentence .""]","['Example text AS format ation is not is sentence boundary information.', '', ""of speech taggers typically require input in the format of a single sentence per line ( for example Brill 's tagger #TAUTHOR_TAG ) and parsers generally aim to produce a tree spanning each sentence .""]","['', '', ""Part of speech taggers typically require input in the format of a single sentence per line ( for example Brill 's tagger #TAUTHOR_TAG ) and parsers generally aim to produce a tree spanning each sentence .""]",0
"['resolved coreference usingIZZLE,our implementation a bual coreference res', 'is a multilingual enhancement of COCKTAIL #TAUTHOR_TAG , a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information .', 'COCKTAIL was applied separately on the and the Ro- manian texts coreferring links were identified for each English and Romanian document respectively', 'referential expressions corefer with non-aligned anaphors, SWZLE derived newis for', '']","['resolved coreference using SWIZZLE,our implementation a bilingual coreference', 'is a multilingual enhancement of COCKTAIL #TAUTHOR_TAG , a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information .', 'COCKTAIL was applied separately on the and the Ro- manian texts, coreferring links were identified for each English and Romanian document respectively.', 'referential expressions corefer with non-aligned anaphors, SWIZZLE derived new for', '']","['we resolved coreference using SWIZZLE,our implementation a bilingual coreference resolver.', 'is a multilingual enhancement of COCKTAIL #TAUTHOR_TAG , a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information .', 'COCKTAIL was applied separately on the English and the Ro- manian texts, coreferring links were identified for each English and Romanian document respectively.', 'referential expressions corefer with non-aligned anaphors, SWIZZLE derived for', '']","['', 'SWIZZLE is a multilingual enhancement of COCKTAIL #TAUTHOR_TAG , a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information .', 'When COCKTAIL was applied separately on the English and the Ro- manian texts, coreferring links were identified for each English and Romanian document respectively.', 'When aligned referential expressions corefer with non-aligned anaphors, SWIZZLE derived new heuris- tics for coreference.', '']",2
"['some the-performing and most robust coreference resolution systems employ knowledge-', '', 'The acquisition of such knowledge is time-consuming, difficult, and error-prone.', 'Nevertheless , recent results show that knowledge-poor methods perform with amazing accuracy ( cfXXX #TAUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG ) .', '', '', '', '', '']","['some the best-performing and most robust coreference resolution systems employ knowledge-based', '', 'The acquisition of such knowledge is time-consuming, difficult, and error-prone.', 'Nevertheless , recent results show that knowledge-poor methods perform with amazing accuracy ( cfXXX #TAUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG ) .', '', '', '', '', '']","['some the best-performing and most robust coreference resolution systems employ knowledge-', '', 'The acquisition of such knowledge is time-consuming, difficult, and error-prone.', 'Nevertheless , recent results show that knowledge-poor methods perform with amazing accuracy ( cfXXX #TAUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG ) .', '', '', '', '', '']","['Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques.', '', 'The acquisition of such knowledge is time-consuming, difficult, and error-prone.', 'Nevertheless , recent results show that knowledge-poor methods perform with amazing accuracy ( cfXXX #TAUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG ) .', '', '', '', '', '']",0
"['The third class of heuristics resolves coreference by coercing nominals.', 'Sometimes coercions involve only derivational morphology - linking verbs with their nominalizations.', 'other, coerc are as paths of meronyms.-part re- lations) and hypernyms (e.g. is-a relations).', 'Consistency checks implemented for this class of coref- erence are conservative: either the adjs must be identical or the adj of theent be less specific than the antecedent.', 'Table 1 lists the top performing heuristics ofCKILfor pronominal and nominal coreference.', 'Examples of the heuristics operation on the MUC data are presented presented in Table2.', 'Details of the top performing heuristics of COCKTAIL were reported in #TAUTHOR_TAG .']","['The third class of heuristics resolves coreference by coercing nominals.', 'Sometimes coercions involve only derivational morphology - linking verbs with their nominalizations.', 'other occasions, coercions are as paths of meronyms is-part re- lations) and hypernyms (e.g. is-a relations).', 'Consistency checks implemented for this class of coref- erence are conservative: either the adjuncts must be identical or the adjunct of the referent be less specific than the antecedent.', 'Table 1 lists the top performing heuristics of COCKTAILfor pronominal and nominal coreference.', 'Examples of the heuristics operation on the MUC data are presented presented in Table 2.', 'Details of the top performing heuristics of COCKTAIL were reported in #TAUTHOR_TAG .']","['The third class of heuristics resolves coreference by coercing nominals.', 'Sometimes coercions involve only derivational morphology - linking verbs with their nominalizations.', 'other occasions, coercions are obtained as paths of meronyms. is-part re- lations) and hypernyms (e.g. is-a relations).', 'Consistency checks implemented for this class of coref- erence are conservative: either the adjuncts must be identical or the adjunct of the referent must be less specific than the antecedent.', 'Table 1 lists the top performing heuristics ofCKILfor pronominal and nominal coreference.', 'Examples of the heuristics operation on the MUC data are presented presented in Table2.', 'Details of the top performing heuristics of COCKTAIL were reported in #TAUTHOR_TAG .']","['The third class of heuristics resolves coreference by coercing nominals.', 'Sometimes coercions involve only derivational morphology - linking verbs with their nominalizations.', 'On other occasions, coercions are obtained as paths of meronyms (e.g. is-part re- lations) and hypernyms (e.g. is-a relations).', 'Consistency checks implemented for this class of coref- erence are conservative: either the adjuncts must be identical or the adjunct of the referent must be less specific than the antecedent.', 'Table 1 lists the top performing heuristics of COCKTAILfor pronominal and nominal coreference.', 'Examples of the heuristics operation on the MUC data are presented presented in Table 2.', 'Details of the top performing heuristics of COCKTAIL were reported in #TAUTHOR_TAG .']",0
"['and', '', 'timeconsum', ', recent results show that knowledge-poor methods perform with amazing accuracy (cf.', ' #AUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG ).', 'AC #AUTHOR_TAG a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases ofonominal', 'For this research , we used a coreference resolution system ( #TAUTHOR_TAG ) that implements different sets of heuristics corresponding to various forms of coreference .', 'CK', '', '', '']","['and', '', '', 'Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf.', ' #AUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG ).', ' #AUTHOR_TAG a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal', 'For this research , we used a coreference resolution system ( #TAUTHOR_TAG ) that implements different sets of heuristics corresponding to various forms of coreference .', '', '', '', '']","['and', '', 'timeconsum', ', recent results show that knowledge-poor methods perform with amazing accuracy (cf.', ' #AUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG ).', ' #AUTHOR_TAG a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases ofonom', 'For this research , we used a coreference resolution system ( #TAUTHOR_TAG ) that implements different sets of heuristics corresponding to various forms of coreference .', 'CK', '', '', '']","['', '', '', 'Nevertheless, recent results show that knowledge-poor methods perform with amazing accuracy (cf.', ' #AUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG ).', 'For example, CogNIAC #AUTHOR_TAG , a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference.', 'For this research , we used a coreference resolution system ( #TAUTHOR_TAG ) that implements different sets of heuristics corresponding to various forms of coreference .', '', '', '', '']",5
"['To deal with these issues we propose a multicomponent architecture where individual components specialize in identifying particular type of unknown word.', 'For, the missp will specialize in identifying misspell, the abbreviation component will specialize in identifying abbreviations, etc.', 'Each component will return a confidence measure of the reliability of its prediction , c.f. #TAUTHOR_TAG .', 'The results from each component are evaluated to determine the final category of the word.']","['To deal with these issues we propose a multicomponent architecture where individual components specialize in identifying particular type of unknown word.', 'For example, the misspelling will specialize in identifying misspellings, the abbreviation component will specialize in identifying abbreviations, etc.', 'Each component will return a confidence measure of the reliability of its prediction , c.f. #TAUTHOR_TAG .', 'The results from each component are evaluated to determine the final category of the word.']","['To deal with these issues we propose a multicomponent architecture where individual components specialize in identifying one particular type of unknown word.', 'For, the misspelling identifier will specialize in identifying misspellings, the abbreviation component will specialize in identifying abbreviations, etc.', 'Each component will return a confidence measure of the reliability of its prediction , c.f. #TAUTHOR_TAG .', 'The results from each component are evaluated to determine the final category of the word.']","['To deal with these issues we propose a multicomponent architecture where individual components specialize in identifying one particular type of unknown word.', 'For example, the misspelling identifier will specialize in identifying misspellings, the abbreviation component will specialize in identifying abbreviations, etc.', 'Each component will return a confidence measure of the reliability of its prediction , c.f. #TAUTHOR_TAG .', 'The results from each component are evaluated to determine the final category of the word.']",4
"['The first feature represents the part of speech of the word.', 'We use an in-house statistical tagger ( based on #TAUTHOR_TAG ) to tag the text in which the unknown word occurs .', 'The tag set used is a simplified version of the tags used in the machinereadable version of the Oxford Advanced Learners Dictionary (OALD).', 'The tag set contains just one tag to identify nouns.']","['The first feature represents the part of speech of the word.', 'We use an in-house statistical tagger ( based on #TAUTHOR_TAG ) to tag the text in which the unknown word occurs .', 'The tag set used is a simplified version of the tags used in the machinereadable version of the Oxford Advanced Learners Dictionary (OALD).', 'The tag set contains just one tag to identify nouns.']","['The first feature represents the part of speech of the word.', 'We use an in-house statistical tagger ( based on #TAUTHOR_TAG ) to tag the text in which the unknown word occurs .', 'The tag set used is a simplified version of the tags used in the machinereadable version of the Oxford Advanced Learners Dictionary (OALD).', 'The tag set contains just one tag to identify nouns.']","['The first feature represents the part of speech of the word.', 'We use an in-house statistical tagger ( based on #TAUTHOR_TAG ) to tag the text in which the unknown word occurs .', 'The tag set used is a simplified version of the tags used in the machinereadable version of the Oxford Advanced Learners Dictionary (OALD).', 'The tag set contains just one tag to identify nouns.']",5
"['Research that is more similar in goal to that outlined in this paper is Vosse #TAUTHOR_TAG .', 'Vosse uses a simple algorithm to identify three classes of unknown words: misspellings, neologisms, and names.', 'Capitalization is his sole means of identifying names.', 'However, capitalization information is not available in closed captions.', 'his system in we', 'anMyze', '']","['Research that is more similar in goal to that outlined in this paper is Vosse #TAUTHOR_TAG .', 'Vosse uses a simple algorithm to identify three classes of unknown words: misspellings, neologisms, and names.', 'Capitalization is his sole means of identifying names.', 'However, capitalization information is not available in closed captions.', 'his system ineffective we', 'anMyze', '']","['Research that is more similar in goal to that outlined in this paper is Vosse #TAUTHOR_TAG .', 'Vosse uses a simple algorithm to identify three classes of unknown words: misspellings, neologisms, and names.', 'Capitalization is his sole means of identifying names.', 'However, capitalization information is not available in closed captions.', 'his system in we are', 'anMyze', '']","['Research that is more similar in goal to that outlined in this paper is Vosse #TAUTHOR_TAG .', 'Vosse uses a simple algorithm to identify three classes of unknown words: misspellings, neologisms, and names.', 'Capitalization is his sole means of identifying names.', 'However, capitalization information is not available in closed captions.', '', '', '']",1
"['Corpus frequency : #TAUTHOR_TAG differentiates between misspellings and neologisms ( new words ) in terms of their frequency .', 'His algorithm classifies unknown words that appear infrequently as misspellings, and those that appear more frequently as neologisms.', 'ions']","['Corpus frequency : #TAUTHOR_TAG differentiates between misspellings and neologisms ( new words ) in terms of their frequency .', 'His algorithm classifies unknown words that appear infrequently as misspellings, and those that appear more frequently as neologisms.', '']","['Corpus frequency : #TAUTHOR_TAG differentiates between misspellings and neologisms ( new words ) in terms of their frequency .', 'His algorithm classifies unknown words that appear infrequently as misspellings, and those that appear more frequently as neologisms.', 'ions']","['Corpus frequency : #TAUTHOR_TAG differentiates between misspellings and neologisms ( new words ) in terms of their frequency .', 'His algorithm classifies unknown words that appear infrequently as misspellings, and those that appear more frequently as neologisms.', '']",5
"['The the first that we of to analyze a corpus of logs a dialogue system for the purpose of learning to predict situations', 'Our work builds on earlier research on learning to identify dialogues in which the user experienced poor speech recognizer performance #TAUTHOR_TAG .', '', '']","['The the first that we of to analyze a corpus of logs a dialogue system for the purpose of learning to predict situations.', 'Our work builds on earlier research on learning to identify dialogues in which the user experienced poor speech recognizer performance #TAUTHOR_TAG .', '', '']","['The research the first that we know of to analyze a corpus of logs a dialogue system for the purpose of learning to predict', 'Our work builds on earlier research on learning to identify dialogues in which the user experienced poor speech recognizer performance #TAUTHOR_TAG .', '', '']","['The research reported here is the first that we know of to automatically analyze a corpus of logs from a spoken dialogue system for the purpose of learning to predict problematic situations.', 'Our work builds on earlier research on learning to identify dialogues in which the user experienced poor speech recognizer performance #TAUTHOR_TAG .', '', '']",2
"['M as running percentages (percentreprompts,ir percentsubdials).', 'The use of running tallies and percentages is based on the assumption that these features are likely to produce generalized predictors #TAUTHOR_TAG .']","['as running percentages (percent-reprompts, percent-subdials).', 'The use of running tallies and percentages is based on the assumption that these features are likely to produce generalized predictors #TAUTHOR_TAG .']","['as running percentages (percentreprompts, percentconfirms, percent-subdials).', 'The use of running tallies and percentages is based on the assumption that these features are likely to produce generalized predictors #TAUTHOR_TAG .']","['', 'The use of running tallies and percentages is based on the assumption that these features are likely to produce generalized predictors #TAUTHOR_TAG .']",4
"['where f (•) extracts a feature vector from a classified, θ are the corresponding weights of those features, and Z θ (x) def = y ux is a normalizer', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let { 1 ... v 17744 } be the set of word types with count ≥ 4 in the 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y u(x, is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let {v 1 ..., v 17744 } be the set of word types with count ≥ 4 in the 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y ux is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let V = {v 1 ... v 17744 } be the set of word types with count ≥ 4 in the full 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y u(x, y) is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'Specifically, let V = {v 1 , ..., v 17744 } be the set of word types with count ≥ 4 in the full 2000-document corpus.', '', '', '', '']",5
"['this approach', ""In future work we plan to experiment with richer representations , e.g. including long-range n-grams #AUTHOR_TAG , class n-grams #TAUTHOR_TAG , grammatical features #AUTHOR_TAG , etc ' .""]","['this approach.', ""In future work we plan to experiment with richer representations , e.g. including long-range n-grams #AUTHOR_TAG , class n-grams #TAUTHOR_TAG , grammatical features #AUTHOR_TAG , etc ' .""]","['this work approach', ""In future work we plan to experiment with richer representations , e.g. including long-range n-grams #AUTHOR_TAG , class n-grams #TAUTHOR_TAG , grammatical features #AUTHOR_TAG , etc ' .""]","['', ""In future work we plan to experiment with richer representations , e.g. including long-range n-grams #AUTHOR_TAG , class n-grams #TAUTHOR_TAG , grammatical features #AUTHOR_TAG , etc ' .""]",3
"['Self-supervised boosting was presented as a general method for estimation, and was not tested in the context of language.', '', '', '', 'Unfortunately , as shown in #TAUTHOR_TAG , with the represetation of sentences that we use , linear classifiers can not discriminate real sentences from sentences sampled from a trigram , which is the model we use as a baseline , so here we resort to a non-linear large-margin classifier ( see section 3 for details ) .', '', '', '', '']","['Self-supervised boosting was presented as a general method for estimation, and was not tested in the context of language modeling.', '', '', '', 'Unfortunately , as shown in #TAUTHOR_TAG , with the represetation of sentences that we use , linear classifiers can not discriminate real sentences from sentences sampled from a trigram , which is the model we use as a baseline , so here we resort to a non-linear large-margin classifier ( see section 3 for details ) .', '', '', '', '']","['Self-supervised boosting was presented as a general method for density estimation, and was not tested in the context of language modeling.', '', '', '', 'Unfortunately , as shown in #TAUTHOR_TAG , with the represetation of sentences that we use , linear classifiers can not discriminate real sentences from sentences sampled from a trigram , which is the model we use as a baseline , so here we resort to a non-linear large-margin classifier ( see section 3 for details ) .', '', '', '', '']","['Self-supervised boosting was presented as a general method for density estimation, and was not tested in the context of language modeling.', '', '', '', 'Unfortunately , as shown in #TAUTHOR_TAG , with the represetation of sentences that we use , linear classifiers can not discriminate real sentences from sentences sampled from a trigram , which is the model we use as a baseline , so here we resort to a non-linear large-margin classifier ( see section 3 for details ) .', '', '', '', '']",4
"['For our features we used-ifiers', 'The code for theifier was generously provided Daisuanara.', 'This code was extensively optimized to take advantage of the very sparse sentence representation described above.', 'As shown in #TAUTHOR_TAG , using this representation , a linear classifier can not distinguish sentences sampled from a trigram and real sentences .', 'Therefore, we used a 3rd order polynomial kernel, which was found to give good results.', '']","['For our features we used classifiers', 'The code for the classifier was generously provided Daisuke Okanohara.', 'This code was extensively optimized to take advantage of the very sparse sentence representation described above.', 'As shown in #TAUTHOR_TAG , using this representation , a linear classifier can not distinguish sentences sampled from a trigram and real sentences .', 'Therefore, we used a 3rd order polynomial kernel, which was found to give good results.', '']","['For our features we used-', 'The code for the classifier was generously provided Daisuke Okanohara.', 'This code was extensively optimized to take advantage of the very sparse sentence representation described above.', 'As shown in #TAUTHOR_TAG , using this representation , a linear classifier can not distinguish sentences sampled from a trigram and real sentences .', 'Therefore, we used a 3rd order polynomial kernel, which was found to give good results.', '']","['', 'The code for the classifier was generously provided by Daisuke Okanohara.', 'This code was extensively optimized to take advantage of the very sparse sentence representation described above.', 'As shown in #TAUTHOR_TAG , using this representation , a linear classifier can not distinguish sentences sampled from a trigram and real sentences .', 'Therefore, we used a 3rd order polynomial kernel, which was found to give good results.', '']",4
"['Baseline language model : For P0 we used a trigram with modified kneser-ney smoothing [ Chen and #TAUTHOR_TAG ] , which is still considered one of the best smoothing methods for n-gram language models .', '', '', '', '']","['Baseline language model : For P0 we used a trigram with modified kneser-ney smoothing [ Chen and #TAUTHOR_TAG ] , which is still considered one of the best smoothing methods for n-gram language models .', '', '', '', '']","['Baseline language model : For P0 we used a trigram with modified kneser-ney smoothing [ Chen and #TAUTHOR_TAG ] , which is still considered one of the best smoothing methods for n-gram language models .', '', '', '', '']","['Baseline language model : For P0 we used a trigram with modified kneser-ney smoothing [ Chen and #TAUTHOR_TAG ] , which is still considered one of the best smoothing methods for n-gram language models .', '', '', '', '']",5
"['The features can be easily obtained by modifying the TAT extraction algorithm described in #TAUTHOR_TAG .', 'a TAT is extracted from a word-aligned, source-parsed parallel sentence, context features and', '', '']","['The features can be easily obtained by modifying the TAT extraction algorithm described in #TAUTHOR_TAG .', 'a TAT is extracted from a word-aligned, source-parsed parallel sentence, contextual features and', '', '']","['The features can be easily obtained by modifying the TAT extraction algorithm described in #TAUTHOR_TAG .', 'a TAT is extracted from a word-aligned, source-parsed parallel sentence, the contextual features and', '', '']","['The features can be easily obtained by modifying the TAT extraction algorithm described in #TAUTHOR_TAG .', '', '', '']",2
"['Belief propagation improves non-projective dependency parsing with features that would make exact inference in', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #TAUTHOR_TAG and history-based parsing ( Nivre and Mc #AUTHOR_TAG .', 'We could also introduce']","['Belief propagation improves non-projective dependency parsing with features that would make exact inference', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #TAUTHOR_TAG and history-based parsing ( Nivre and Mc #AUTHOR_TAG .', 'We could also introduce']","['Belief propagation improves non-projective dependency parsing with features that would make exact inference intractable.', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #TAUTHOR_TAG and history-based parsing ( Nivre and Mc #AUTHOR_TAG .', 'We could also introduce']","['Belief propagation improves non-projective dependency parsing with features that would make exact inference intractable.', 'For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #TAUTHOR_TAG and history-based parsing ( Nivre and Mc #AUTHOR_TAG .', '']",3
"['Belief propagation improves non-projective dependency parsing with features that would make exact inference in', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #TAUTHOR_TAG and history-based parsing ( Nivre and Mc #AUTHOR_TAG .', 'We could also introduce']","['Belief propagation improves non-projective dependency parsing with features that would make exact inference', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #TAUTHOR_TAG and history-based parsing ( Nivre and Mc #AUTHOR_TAG .', 'We could also introduce']","['Belief propagation improves non-projective dependency parsing with features that would make exact inference intractable.', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #TAUTHOR_TAG and history-based parsing ( Nivre and Mc #AUTHOR_TAG .', 'We could also introduce']","['Belief propagation improves non-projective dependency parsing with features that would make exact inference intractable.', 'For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #TAUTHOR_TAG and history-based parsing ( Nivre and Mc #AUTHOR_TAG .', '']",3
"['Belief propagation improves non-projective dependency parsing with features that would make exactference.', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #AUTHOR_TAG and history-based parsing #TAUTHOR_TAG .', 'We could also']","['Belief propagation improves non-projective dependency parsing with features that would make exact inference', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #AUTHOR_TAG and history-based parsing #TAUTHOR_TAG .', 'We could also']","['Belief propagation improves non-projective dependency parsing with features that would make', 'We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #AUTHOR_TAG and history-based parsing #TAUTHOR_TAG .', 'We could also']","['Belief propagation improves non-projective dependency parsing with features that would make exact inference intractable.', 'For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking #AUTHOR_TAG and history-based parsing #TAUTHOR_TAG .', '']",3
"['', '', 'We could also introduce new variables , e.g. , nonterminal refinements #TAUTHOR_TAG , orREE ) that augment the parse with representations of control , binding , etc. #AUTHOR_TAG Buch .']","['', '', 'We could also introduce new variables , e.g. , nonterminal refinements #TAUTHOR_TAG , or ) that augment the parse with representations of control , binding , etc. #AUTHOR_TAG .']","['', '', 'We could also introduce new variables , e.g. , nonterminal refinements #TAUTHOR_TAG , orREE ) that augment the parse with representations of control , binding , etc. #AUTHOR_TAG Buch #AUTHOR_TAG .']","['', '', 'We could also introduce new variables , e.g. , nonterminal refinements #TAUTHOR_TAG , or secondary links Mid ( not constrained by TREE/PTREE ) that augment the parse with representations of control , binding , etc. #AUTHOR_TAG Buch- #AUTHOR_TAG .']",3
"['(Section 3', 'Experiments ( Section 5 ) show that forestbased extraction improves BLEU score by over 1 point on a state-of-the-art tree-to-string system #TAUTHOR_TAG , which is also 0.5 points better than ( and twice as fast as ) extracting on 30-best parses .', '']","['(Section 3),', 'Experiments ( Section 5 ) show that forestbased extraction improves BLEU score by over 1 point on a state-of-the-art tree-to-string system #TAUTHOR_TAG , which is also 0.5 points better than ( and twice as fast as ) extracting on 30-best parses .', '']","['(Section 3', 'Experiments ( Section 5 ) show that forestbased extraction improves BLEU score by over 1 point on a state-of-the-art tree-to-string system #TAUTHOR_TAG , which is also 0.5 points better than ( and twice as fast as ) extracting on 30-best parses .', '']","['', 'Experiments ( Section 5 ) show that forestbased extraction improves BLEU score by over 1 point on a state-of-the-art tree-to-string system #TAUTHOR_TAG , which is also 0.5 points better than ( and twice as fast as ) extracting on 30-best parses .', '']",2
"['The is also used in machine translation decoding, for example to characterize the search space of decoding with integrated language models #AUTHOR_TAG', 'The first direct application of parse forest in translation is our previous work #TAUTHOR_TAG which translates a packed forest from a parser ; it is also the base system in our experiments ( see below ) .', '']","['The is also used in machine translation decoding, for example to characterize the search space of decoding with integrated language models #AUTHOR_TAG', 'The first direct application of parse forest in translation is our previous work #TAUTHOR_TAG which translates a packed forest from a parser ; it is also the base system in our experiments ( see below ) .', '']","['is also used in machine translation decoding, for example to characterize the search space of decoding with integrated language models #AUTHOR_TAG .', 'The first direct application of parse forest in translation is our previous work #TAUTHOR_TAG which translates a packed forest from a parser ; it is also the base system in our experiments ( see below ) .', '']","['The forest concept is also used in machine translation decoding, for example to characterize the search space of decoding with integrated language models #AUTHOR_TAG .', 'The first direct application of parse forest in translation is our previous work #TAUTHOR_TAG which translates a packed forest from a parser ; it is also the base system in our experiments ( see below ) .', '']",2
"['', '', '', '', 'the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction #TAUTHOR_TAG , and Machine Translation ( Boas 2002 ) .', 'efforts many researchers (Ceras and Mque2']","['', '', '', '', 'the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction #TAUTHOR_TAG , and Machine Translation ( Boas 2002 ) .', 'efforts many researchers (Carreras and']","['', '', '', '', 'the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction #TAUTHOR_TAG , and Machine Translation ( Boas 2002 ) .', 'the efforts many researchers (Ceras and Mque']","['', '', '', '', 'Since the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction #TAUTHOR_TAG , and Machine Translation ( Boas 2002 ) .', '']",0
"['To prove that our method is effective , we also make a comparison between the performances of our system and #TAUTHOR_TAG , #AUTHOR_TAG .', ' #AUTHOR_TAG is the best SRL system until now and it has the same data setting with ours.', 'The results are presented in Table6', '', '']","['To prove that our method is effective , we also make a comparison between the performances of our system and #TAUTHOR_TAG , #AUTHOR_TAG .', ' #AUTHOR_TAG is the best SRL system until now and it has the same data setting with ours.', 'The results are presented in Table 6', '', '']","['To prove that our method is effective , we also make a comparison between the performances of our system and #TAUTHOR_TAG , #AUTHOR_TAG .', ' #AUTHOR_TAG is the best SRL system until now and it has the same data setting with ours.', 'The results are presented in Table6', '', '']","['To prove that our method is effective , we also make a comparison between the performances of our system and #TAUTHOR_TAG , #AUTHOR_TAG .', ' #AUTHOR_TAG is the best SRL system until now and it has the same data setting with ours.', '', '', '']",1
"['was defined', '', '', 'Agent.', 'Since the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering #TAUTHOR_TAG , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation ( Boas 2002 ) .', 'the efforts many (Ceras and Mrque2 and this']","['was defined', '', '', 'Agent, etc.', 'Since the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering #TAUTHOR_TAG , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation ( Boas 2002 ) .', 'the efforts many (Carreras and Màrquez and this']","['was first defined', '', '', 'Agent', 'Since the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering #TAUTHOR_TAG , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation ( Boas 2002 ) .', 'the efforts many researchers (Ceras and Mrque2 and']","['', '', '', '', 'Since the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering #TAUTHOR_TAG , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation ( Boas 2002 ) .', '']",0
"['sem pred.', 'The semantic categories of verbs and other words are extracted from the Semantic Knowledge-base of Contemporary Chinese #TAUTHOR_TAG .']","['predicate word.', 'The semantic categories of verbs and other words are extracted from the Semantic Knowledge-base of Contemporary Chinese #TAUTHOR_TAG .']","['sem pred.', 'The semantic categories of verbs and other words are extracted from the Semantic Knowledge-base of Contemporary Chinese #TAUTHOR_TAG .']","['', 'The semantic categories of verbs and other words are extracted from the Semantic Knowledge-base of Contemporary Chinese #TAUTHOR_TAG .']",5
"['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG did very encouraging work on the feature calibration of semantic role labeling .', 'They found out that different features suited for different sub tasks of SRL, i.e. semantic role identification and classification.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL (Xue andPalmer 2005, Xue 2008) reassured these findings.']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG did very encouraging work on the feature calibration of semantic role labeling .', 'They found out that different features suited for different sub tasks of SRL, i.e. semantic role identification and classification.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL (Xue andPalmer 2005, Xue 2008) reassured these findings.']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG did very encouraging work on the feature calibration of semantic role labeling .', 'They found out that different features suited for different sub tasks of SRL, i.e. semantic role identification and classification.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL (Xue andPalmer 2005, Xue 2008) reassured these findings.']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG did very encouraging work on the feature calibration of semantic role labeling .', 'They found out that different features suited for different sub tasks of SRL, i.e. semantic role identification and classification.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL (Xue andPalmer 2005, Xue 2008) reassured these findings.']",0
"['still', 'transplant machine', '', '', 'This paper made the first attempt on Chinese SRL and produced promising results.', 'After the PropBank #TAUTHOR_TAG was built , #AUTHOR_TAG and #AUTHOR_TAG have produced more complete and systematic research on Chinese SRL .', 'attempt idea', '', '', '', '', '', '']","['still', 'transplant machine', '', '', 'This paper made the first attempt on Chinese SRL and produced promising results.', 'After the PropBank #TAUTHOR_TAG was built , #AUTHOR_TAG and #AUTHOR_TAG have produced more complete and systematic research on Chinese SRL .', 'attempt idea', '', '', '', '', '', '']","['is still', 'transplant', '', '', 'This paper made the first attempt on Chinese SRL and produced promising results.', 'After the PropBank #TAUTHOR_TAG was built , #AUTHOR_TAG and #AUTHOR_TAG have produced more complete and systematic research on Chinese SRL .', 'the idea', '', '', '', '', '', '']","['', '', '', '', 'This paper made the first attempt on Chinese SRL and produced promising results.', 'After the PropBank #TAUTHOR_TAG was built , #AUTHOR_TAG and #AUTHOR_TAG have produced more complete and systematic research on Chinese SRL .', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', '', '', '', 'sub tasks and.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL #TAUTHOR_TAG , Xue 2008 ) reassured these findings .']","['', '', '', '', '', '', '', '', '', '', 'sub tasks and classification.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL #TAUTHOR_TAG , Xue 2008 ) reassured these findings .']","['', '', '', '', '', '', '', '', '', '', 'different sub tasks and.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL #TAUTHOR_TAG , Xue 2008 ) reassured these findings .']","['', '', '', '', '', '', '', '', '', '', '', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL #TAUTHOR_TAG , Xue 2008 ) reassured these findings .']",4
"[' #TAUTHOR_TAG has built a semantic role classifier exploiting the interdependence of semantic roles .', 'It has turned the single point classification problem into the sequence labeling problem with the introduction of semantic context features.', 'Se- mantic context features indicates the features ex- tracted from the arguments around the current one.', '', '', '', '', '', '']","[' #TAUTHOR_TAG has built a semantic role classifier exploiting the interdependence of semantic roles .', 'It has turned the single point classification problem into the sequence labeling problem with the introduction of semantic context features.', 'Se- mantic context features indicates the features ex- tracted from the arguments around the current one.', '', '', '', '', '', '']","[' #TAUTHOR_TAG has built a semantic role classifier exploiting the interdependence of semantic roles .', 'It has turned the single point classification problem into the sequence labeling problem with the introduction of semantic context features.', 'Se- mantic context features indicates the features ex- tracted from the arguments around the current one.', '', '', '', '', '', '']","[' #TAUTHOR_TAG has built a semantic role classifier exploiting the interdependence of semantic roles .', 'It has turned the single point classification problem into the sequence labeling problem with the introduction of semantic context features.', 'Se- mantic context features indicates the features ex- tracted from the arguments around the current one.', '', '', '', '', '', '']",5
"['Although we make discriminations of arguments and adjuncts, the analysis is still coarse-grained.', ' #TAUTHOR_TAG has made the first attempt working on the single semantic role level to make further improvement .', 'limited the amount of the research target ARG2 is few in Prop', '', '']","['Although we make discriminations of arguments and adjuncts, the analysis is still coarse-grained.', ' #TAUTHOR_TAG has made the first attempt working on the single semantic role level to make further improvement .', 'limited the amount of the research target, ARG2, is few in', '', '']","['Although we make discriminations of arguments and adjuncts, the analysis is still coarse-grained.', ' #TAUTHOR_TAG has made the first attempt working on the single semantic role level to make further improvement .', 'limited the amount of the research target, ARG2, is few in Prop', '', '']","['Although we make discriminations of arguments and adjuncts, the analysis is still coarse-grained.', ' #TAUTHOR_TAG has made the first attempt working on the single semantic role level to make further improvement .', '', '', '']",1
"['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']",0
"['To prove that our method is effective , we also make a comparison between the performances of our system and #AUTHOR_TAG , #TAUTHOR_TAG .', ' #AUTHOR_TAG is the best SRL system until now and it has the same data setting with ours.', 'The results are presented in Table 6 three Gold', '', '']","['To prove that our method is effective , we also make a comparison between the performances of our system and #AUTHOR_TAG , #TAUTHOR_TAG .', ' #AUTHOR_TAG is the best SRL system until now and it has the same data setting with ours.', 'The results are presented in Table 6 three Gold', '', '']","['To prove that our method is effective , we also make a comparison between the performances of our system and #AUTHOR_TAG , #TAUTHOR_TAG .', ' #AUTHOR_TAG is the best SRL system until now and it has the same data setting with ours.', 'The results are presented in Table 6', '', '']","['To prove that our method is effective , we also make a comparison between the performances of our system and #AUTHOR_TAG , #TAUTHOR_TAG .', ' #AUTHOR_TAG is the best SRL system until now and it has the same data setting with ours.', '', '', '']",1
"['Previous semantic role classifiers always did the classification problem in one-step.', 'this we SRC in two', 'The architectures of hierarch semantic role classifiers can 2 Extra features e.g.', 'predicate may be still useful because that the information, provided by the high-level description of selfdescriptive features, e.g.', 'phrase type, are limited.', 'be found in figure 2 , which is similar with that in #TAUTHOR_TAG .']","['Previous semantic role classifiers always did the classification problem in one-step.', 'this we SRC in two', 'The architectures of hierarchical semantic role classifiers can 2 Extra features e.g.', 'predicate may be still useful because that the information, provided by the high-level description of selfdescriptive features, e.g.', 'phrase type, are limited.', 'be found in figure 2 , which is similar with that in #TAUTHOR_TAG .']","['Previous semantic role classifiers always did the classification problem in one-step.', 'we did SRC in', 'The architectures of hierarchical semantic role classifiers can 2 Extra features e.g.', 'predicate may be still useful because that the information, provided by the high-level description of selfdescriptive features, e.g.', 'phrase type, are limited.', 'be found in figure 2 , which is similar with that in #TAUTHOR_TAG .']","['Previous semantic role classifiers always did the classification problem in one-step.', '', 'The architectures of hierarchical semantic role classifiers can 2 Extra features e.g.', 'predicate may be still useful because that the information, provided by the high-level description of selfdescriptive features, e.g.', 'phrase type, are limited.', 'be found in figure 2 , which is similar with that in #TAUTHOR_TAG .']",1
"['frame first , last , and its P , predicate + head word , predicate + phrase type , path to BA and BEI , verb class 3 , verb class + head word , verb class + phrase type , from #TAUTHOR_TAG .']","['frame first , last , and its POS , predicate + head word , predicate + phrase type , path to BA and BEI , verb class 3 , verb class + head word , verb class + phrase type , from #TAUTHOR_TAG .']","['cat frame first word , last word , and its P , predicate + head word , predicate + phrase type , path to BA and BEI , verb class 3 , verb class + head word , verb class + phrase type , from #TAUTHOR_TAG .']","['Position , subcat frame , phrase type , first word , last word , subcat frame + , predicate , path , head word and its POS , predicate + head word , predicate + phrase type , path to BA and BEI , verb class 3 , verb class + head word , verb class + phrase type , from #TAUTHOR_TAG .']",5
"['', '', '', '', 'arguments can useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation #TAUTHOR_TAG .', 'With the efforts of many researchers (Carreras and Màrquez 2004, Moschitti 2004, et al 22 different machine learning methods and linguistics resources are applied in this task, which has madeRL task progress']","['', '', '', '', 'arguments can useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation #TAUTHOR_TAG .', 'With the efforts of many researchers (Carreras and Màrquez 2004, Moschitti 2004, et al different machine learning methods and linguistics resources are applied in this task, which has made SRL task progress']","['', '', '', '', 'the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation #TAUTHOR_TAG .', 'With the efforts of many researchers (Carreras and Màrquez 2004, Moschitti 2004, et al 22, different machine learning methods and linguistics resources are applied in this task, which has madeRL task progress fast.']","['', '', '', '', 'Since the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation #TAUTHOR_TAG .', 'With the efforts of many researchers (Carreras and Màrquez 2004, Moschitti 2004, Pradhan et al 2005, Zhang et al 2007, different machine learning methods and linguistics resources are applied in this task, which has made SRL task progress fast.']",0
"['', '', '', '', '', '', '', '', '', 'We use the same data setting with #TAUTHOR_TAG , however a bit different from #AUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', 'We use the same data setting with #TAUTHOR_TAG , however a bit different from #AUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', 'We use the same data setting with #TAUTHOR_TAG , however a bit different from #AUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', 'We use the same data setting with #TAUTHOR_TAG , however a bit different from #AUTHOR_TAG .']",5
"['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG .', ' #AUTHOR_TAG preliminary SRL without any large semantically annotpus', '', '', '( 3 built and #AUTHOR_TAG more', '', '', '', '', '', 'crucial', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG .', ' #AUTHOR_TAG preliminary SRL without any large semantically annotated corpus', '', '', 'built, and #AUTHOR_TAG more', '', '', '', '', '', 'crucial.', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG .', ' #AUTHOR_TAG the preliminary work Chinese SRL without any large semantically annotated corpus', '', '', '( built and #AUTHOR_TAG more', '', '', '', '', '', 'crucial', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG .', ' #AUTHOR_TAG did the preliminary work on Chinese SRL without any large semantically annotated corpus of Chinese.', '', '', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', '', '', '', '.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL ( Xue and Palmer 2005 , #TAUTHOR_TAG reassured these findings .']","['', '', '', '', '', '', '', '', '', '', 'classification.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL ( Xue and Palmer 2005 , #TAUTHOR_TAG reassured these findings .']","['', '', '', '', '', '', '', '', '', '', '.', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL ( Xue and Palmer 2005 , #TAUTHOR_TAG reassured these findings .']","['', '', '', '', '', '', '', '', '', '', '', 'For semantic analysis, developing features that capture the right kind of information is crucial.', 'Experiments on Chinese SRL ( Xue and Palmer 2005 , #TAUTHOR_TAG reassured these findings .']",0
"['', '', '', '', '', 'Xuemer was built and', ' #TAUTHOR_TAG has made some preliminary attempt on the idea of hierarchical semantic role labeling.', '', '', '', '', '', '']","['', '', '', '', '', '(Xue Palmer was built, and', ' #TAUTHOR_TAG has made some preliminary attempt on the idea of hierarchical semantic role labeling.', '', '', '', '', '', '']","['', '', '', '', '', 'Xue was built and', ' #TAUTHOR_TAG has made some preliminary attempt on the idea of hierarchical semantic role labeling.', '', '', '', '', '', '']","['', '', '', '', '', '', ' #TAUTHOR_TAG has made some preliminary attempt on the idea of hierarchical semantic role labeling.', '', '', '', '', '', '']",0
"['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']","['Compared to the research on English, the research on Chinese SRL is still in its infancy stage.', 'Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']",0
"['use', '', '', '', '', '', '', '', 'cbb', 'We use the same data setting with #AUTHOR_TAG , however a bit different from #TAUTHOR_TAG .']","['use', '', '', '', '', '', '', '', '', 'We use the same data setting with #AUTHOR_TAG , however a bit different from #TAUTHOR_TAG .']","['We use', '', '', '', '', '', '', '', 'cbb', 'We use the same data setting with #AUTHOR_TAG , however a bit different from #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', 'We use the same data setting with #AUTHOR_TAG , however a bit different from #TAUTHOR_TAG .']",1
['The candidate feature templates include : Voice from #TAUTHOR_TAG .'],['The candidate feature templates include : Voice from #TAUTHOR_TAG .'],['The candidate feature templates include : Voice from #TAUTHOR_TAG .'],['The candidate feature templates include : Voice from #TAUTHOR_TAG .'],5
"['The Chinese PropBank has labeled the predicateargument structures of sentences from the Chinese TreeBank #TAUTHOR_TAG .', 'It is constituted of two parts.', 'One is the labeled data, which indicates the positions of the predicates and its arguments in the Chinese Treebank.', 'The other is a dictionary which lists the frames of all the labeled predicates.', 'Figure ', '', '', '', '']","['The Chinese PropBank has labeled the predicateargument structures of sentences from the Chinese TreeBank #TAUTHOR_TAG .', 'It is constituted of two parts.', 'One is the labeled data, which indicates the positions of the predicates and its arguments in the Chinese Treebank.', 'The other is a dictionary which lists the frames of all the labeled predicates.', 'Figure 1', '', '', '', '']","['The Chinese PropBank has labeled the predicateargument structures of sentences from the Chinese TreeBank #TAUTHOR_TAG .', 'It is constituted of two parts.', 'One is the labeled data, which indicates the positions of the predicates and its arguments in the Chinese Treebank.', 'The other is a dictionary which lists the frames of all the labeled predicates.', 'Figure 1', '', '', '', '']","['The Chinese PropBank has labeled the predicateargument structures of sentences from the Chinese TreeBank #TAUTHOR_TAG .', 'It is constituted of two parts.', 'One is the labeled data, which indicates the positions of the predicates and its arguments in the Chinese Treebank.', 'The other is a dictionary which lists the frames of all the labeled predicates.', '', '', '', '', '']",5
"['Semantic Role labeling ( SRL ) was first defined in #TAUTHOR_TAG .', 'The purpose of SRL task is to identify and classify the semantic roles of each predicate in a sentence.', 'The semantic roles are marked and each of them is assigned a tag of the sem relation with the', 'ical tags include Agent, Patient, Source, etc. and some adjuncts such as Temporal, Manner, Extent, etc', 'can useful information, the SRL is crucial to many natural language processing tasks, such as Question and Answering (Narayanan and Harabagiu 24), Information ExtractionSurde3 Machine TransBo', '2 and linguistics this, made']","['Semantic Role labeling ( SRL ) was first defined in #TAUTHOR_TAG .', 'The purpose of SRL task is to identify and classify the semantic roles of each predicate in a sentence.', 'The semantic roles are marked and each of them is assigned a tag of the semantic relation with the', 'Typical tags include Agent, Patient, Source, etc. and some adjuncts such as Temporal, Manner, Extent, etc.', 'can useful information, the SRL is crucial to many natural language processing tasks, such as Question and Answering (Narayanan and Harabagiu 2004), Information Extraction Machine Translation', 'and linguistics this task, made']","['Semantic Role labeling ( SRL ) was first defined in #TAUTHOR_TAG .', 'The purpose of SRL task is to identify and classify the semantic roles of each predicate in a sentence.', 'The semantic roles are marked and each of them is assigned a tag of the semantic relation with', 'ical tags include Agent, Patient, Source, etc. and some adjuncts such as Temporal, Manner, Extent, etc.', 'can provide useful semantic information, the SRL is crucial to many natural language processing tasks, such as Question and Answering (Narayanan and Harabagiu 2004), Information ExtractionSurde3 Machine TranslationBo', '2 and linguistics resources this task, has made']","['Semantic Role labeling ( SRL ) was first defined in #TAUTHOR_TAG .', 'The purpose of SRL task is to identify and classify the semantic roles of each predicate in a sentence.', 'The semantic roles are marked and each of them is assigned a tag which indicates the type of the semantic relation with the related predicate.', 'Typical tags include Agent, Patient, Source, etc. and some adjuncts such as Temporal, Manner, Extent, etc.', 'Since the arguments can provide useful semantic information, the SRL is crucial to many natural language processing tasks, such as Question and Answering (Narayanan and Harabagiu 2004), Information Extraction (Surdeanu et al. 2003), and Machine Translation (Boas 2002).', '']",0
"['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguitying the structure of.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of names.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of names.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']",0
"['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguitying the structure of.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of names.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of names.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']",0
"['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguitying the structure of.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of names.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of names.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']",0
"['', '', 'indocument coreference resolution has been applied to produce summaries of text surroundingrences', 'text is present in most as the only feature and sometimes in combination with otherssee for instance #AUTHOR_TAG -', 'Other representations use the link structure #TAUTHOR_TAG or generate graph representations of the extracted features #AUTHOR_TAG .', '', '', '', '']","['', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences', 'text is present in most as the only feature and sometimes in combination with otherssee for instance #AUTHOR_TAG -.', 'Other representations use the link structure #TAUTHOR_TAG or generate graph representations of the extracted features #AUTHOR_TAG .', '', '', '', '']","['', '', 'indocument coreference resolution has been applied to produce summaries of text surroundingrences', 'is present in most as the only feature and sometimes in combination with otherssee for instance #AUTHOR_TAG -', 'Other representations use the link structure #TAUTHOR_TAG or generate graph representations of the extracted features #AUTHOR_TAG .', '', '', '', '']","['', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless, the full document text is present in most systems, sometimes as the only feature #AUTHOR_TAG and sometimes in combination with otherssee for instance #AUTHOR_TAG -.', 'Other representations use the link structure #TAUTHOR_TAG or generate graph representations of the extracted features #AUTHOR_TAG .', '', '', '', '']",0
"['', '', 'has been', '', '', 'Some researchers #TAUTHOR_TAG have explored the use of Wikipedia information to improve the disambiguation process .', 'Wikipediaions', 'brit and be in way', '']","['', '', 'has been', '', '', 'Some researchers #TAUTHOR_TAG have explored the use of Wikipedia information to improve the disambiguation process .', 'Wikipedia mentions', 'and be in way.', '']","['', '', 'has been applied', '', '', 'Some researchers #TAUTHOR_TAG have explored the use of Wikipedia information to improve the disambiguation process .', 'Wikipedia', 'and in', '']","['', '', '', '', '', 'Some researchers #TAUTHOR_TAG have explored the use of Wikipedia information to improve the disambiguation process .', '', '', '']",0
"['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense DisambiguationW Crossdocument Coreference', 'of early person ambig focuses the W.', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own #TAUTHOR_TAG .']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense Disambiguation Cross-document Coreference', 'of early person ambiguity focuses the WSD literature.', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own #TAUTHOR_TAG .']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense DisambiguationW Crossdocument Coreference', 'of person name ambiguity focuses the WSD literature.', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own #TAUTHOR_TAG .']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense Disambiguation (WSD) #AUTHOR_TAG and Cross-document Coreference (CDC) #AUTHOR_TAG .', '', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own #TAUTHOR_TAG .']",0
"['2The WePS-1 corpus includes data from the Web03 testbed #TAUTHOR_TAG which follows similar annotation guidelines , although the number of document per ambiguous name is more variable .']","['2The WePS-1 corpus includes data from the Web03 testbed #TAUTHOR_TAG which follows similar annotation guidelines , although the number of document per ambiguous name is more variable .']","['2The WePS-1 corpus includes data from the Web03 testbed #TAUTHOR_TAG which follows similar annotation guidelines , although the number of document per ambiguous name is more variable .']","['2The WePS-1 corpus includes data from the Web03 testbed #TAUTHOR_TAG which follows similar annotation guidelines , although the number of document per ambiguous name is more variable .']",5
"['Many different features have been used to represent documents where an ambiguous name is mentioned.', 'The most basic is a Bag of Words (BoW) representation of the document text.', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #TAUTHOR_TAG .', 'is present in only feature', '', '', '', '', '']","['Many different features have been used to represent documents where an ambiguous name is mentioned.', 'The most basic is a Bag of Words (BoW) representation of the document text.', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #TAUTHOR_TAG .', 'is present in only feature', '', '', '', '', '']","['Many different features have been used to represent documents where an ambiguous name is mentioned.', 'The most basic is a Bag of Words (BoW) representation of the document text.', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #TAUTHOR_TAG .', 'is present in the only feature', '', '', '', '', '']","['Many different features have been used to represent documents where an ambiguous name is mentioned.', 'The most basic is a Bag of Words (BoW) representation of the document text.', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense DisambiguationW Crossdocument Coreference', 'of early person ambig focuses the W.', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own #TAUTHOR_TAG .']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense Disambiguation Cross-document Coreference', 'of early person ambiguity focuses the WSD literature.', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own #TAUTHOR_TAG .']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense DisambiguationW Crossdocument Coreference', 'of person name ambiguity focuses the WSD literature.', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own #TAUTHOR_TAG .']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense Disambiguation (WSD) #AUTHOR_TAG and Cross-document Coreference (CDC) #AUTHOR_TAG .', '', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own #TAUTHOR_TAG .']",0
"['have to an ambig is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #AUTHOR_TAG and sometimes in combination with others see for instance #TAUTHOR_TAG - .', 'link #AUTHOR_TAG or extracted features #AUTHOR_TAG .', '', '', '', '']","['have to an ambiguous is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #AUTHOR_TAG and sometimes in combination with others see for instance #TAUTHOR_TAG - .', 'link #AUTHOR_TAG or extracted features #AUTHOR_TAG .', '', '', '', '']","['to an ambiguous name is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #AUTHOR_TAG and sometimes in combination with others see for instance #TAUTHOR_TAG - .', ' #AUTHOR_TAG or the extracted features #AUTHOR_TAG .', '', '', '', '']","['', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #AUTHOR_TAG and sometimes in combination with others see for instance #TAUTHOR_TAG - .', '', '', '', '', '']",0
"['ambig is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences the', 'Nevertheless, the full document text is present in most systems, sometimes as the only feature #AUTHOR_TAG and sometimes in combination with otherssee for instance #AUTHOR_TAG -.', 'Other representations use the link structure #AUTHOR_TAG or generate graph representations of the extracted features #TAUTHOR_TAG .', '', '', '', '']","['ambiguous is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences the', 'Nevertheless, the full document text is present in most systems, sometimes as the only feature #AUTHOR_TAG and sometimes in combination with otherssee for instance #AUTHOR_TAG -.', 'Other representations use the link structure #AUTHOR_TAG or generate graph representations of the extracted features #TAUTHOR_TAG .', '', '', '', '']","['is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences the name', 'Nevertheless, the full document text is present in most systems, sometimes as the only feature #AUTHOR_TAG and sometimes in combination with otherssee for instance #AUTHOR_TAG -.', 'Other representations use the link structure #AUTHOR_TAG or generate graph representations of the extracted features #TAUTHOR_TAG .', '', '', '', '']","['', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless, the full document text is present in most systems, sometimes as the only feature #AUTHOR_TAG and sometimes in combination with otherssee for instance #AUTHOR_TAG -.', 'Other representations use the link structure #AUTHOR_TAG or generate graph representations of the extracted features #TAUTHOR_TAG .', '', '', '', '']",0
"['A study of the query log of the AllTheWeb and Altavista search sites gives an idea of the relevance of the people search task : 11-17 % of the queries were composed of a person name with additional terms and 4 % were identified as person names #TAUTHOR_TAG .', '', 'WW more are mentioned', '']","['A study of the query log of the AllTheWeb and Altavista search sites gives an idea of the relevance of the people search task : 11-17 % of the queries were composed of a person name with additional terms and 4 % were identified as person names #TAUTHOR_TAG .', '', 'WWW more are mentioned', '']","['A study of the query log of the AllTheWeb and Altavista search sites gives an idea of the relevance of the people search task : 11-17 % of the queries were composed of a person name with additional terms and 4 % were identified as person names #TAUTHOR_TAG .', '', 'more are mentioned', '']","['A study of the query log of the AllTheWeb and Altavista search sites gives an idea of the relevance of the people search task : 11-17 % of the queries were composed of a person name with additional terms and 4 % were identified as person names #TAUTHOR_TAG .', '', '', '']",0
"['', '', '', '', ' #TAUTHOR_TAG the performace of NEs versus BoW features', '', '']","['', '', '', '', ' #TAUTHOR_TAG the performace of NEs versus BoW features', '', '']","['', '', '', '', ' #TAUTHOR_TAG the performace of NEs versus BoW features .', '', '']","['', '', '', '', ' #TAUTHOR_TAG compared the performace of NEs versus BoW features .', '', '']",0
"['Many different features have been used to represent documents where an ambiguous name is mentioned.', 'The most basic is a Bag of Words (BoW) representation of the document text.', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #TAUTHOR_TAG .', 'is present in only feature', '', '', '', '', '']","['Many different features have been used to represent documents where an ambiguous name is mentioned.', 'The most basic is a Bag of Words (BoW) representation of the document text.', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #TAUTHOR_TAG .', 'is present in only feature', '', '', '', '', '']","['Many different features have been used to represent documents where an ambiguous name is mentioned.', 'The most basic is a Bag of Words (BoW) representation of the document text.', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #TAUTHOR_TAG .', 'is present in the only feature', '', '', '', '', '']","['Many different features have been used to represent documents where an ambiguous name is mentioned.', 'The most basic is a Bag of Words (BoW) representation of the document text.', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['OAK 7 is a rule based English analyser that includes many functionalities (POS tagger, stemmer, chunker, Named Entity (NE) tagger, dependency analyser, parser, etc).', 'It provides a fine grained NE recognition covering 100 different NE types #TAUTHOR_TAG .', 'arseness of most of these fine-grained NE types, we have merged them in coarser groups: event, facility, location, person, organisation, product, periodx, timex and numex']","['OAK 7 is a rule based English analyser that includes many functionalities (POS tagger, stemmer, chunker, Named Entity (NE) tagger, dependency analyser, parser, etc).', 'It provides a fine grained NE recognition covering 100 different NE types #TAUTHOR_TAG .', 'sparseness of most of these fine-grained NE types, we have merged them in coarser groups: event, facility, location, person, organisation, product, periodx, timex and numex.']","['OAK 7 is a rule based English analyser that includes many functionalities (POS tagger, stemmer, chunker, Named Entity (NE) tagger, dependency analyser, parser, etc).', 'It provides a fine grained NE recognition covering 100 different NE types #TAUTHOR_TAG .', 'the sparseness of most of these fine-grained NE types, we have merged them in coarser groups: event, facility, location, person, organisation, product, periodx, timex and numex']","['OAK 7 is a rule based English analyser that includes many functionalities (POS tagger, stemmer, chunker, Named Entity (NE) tagger, dependency analyser, parser, etc).', 'It provides a fine grained NE recognition covering 100 different NE types #TAUTHOR_TAG .', 'Given the sparseness of most of these fine-grained NE types, we have merged them in coarser groups: event, facility, location, person, organisation, product, periodx, timex and numex.']",5
"['A study of the query log of the AllTheWeb and Altista search sites gives an idea of the relevance of the people search task: 11-17% of the queries were composed of a person name with additional terms and 4% were identified as person names #AUTHOR_TAG .', 'According to the data available from 1990 U.S. Census Bureau , only 90,000 different names are shared by 100 million people #TAUTHOR_TAG .', 'As the amount of information in the WWW grows, more of these people are mentioned in different web pages.', ', a query for a common name in the Web will usually produce a list of results where different people are mentioned.']","['A study of the query log of the AllTheWeb and Altavista search sites gives an idea of the relevance of the people search task: 11-17% of the queries were composed of a person name with additional terms and 4% were identified as person names #AUTHOR_TAG .', 'According to the data available from 1990 U.S. Census Bureau , only 90,000 different names are shared by 100 million people #TAUTHOR_TAG .', 'As the amount of information in the WWW grows, more of these people are mentioned in different web pages.', 'Therefore, a query for a common name in the Web will usually produce a list of results where different people are mentioned.']","['A study of the query log of the AllTheWeb and Altista search sites gives an idea of the relevance of the people search task: 11-17% of the queries were composed of a person name with additional terms and 4% were identified as person names #AUTHOR_TAG .', 'According to the data available from 1990 U.S. Census Bureau , only 90,000 different names are shared by 100 million people #TAUTHOR_TAG .', 'As the amount of information in the WWW grows, more of these people are mentioned in different web pages.', ', a query for a common name in the Web will usually produce a list of results where different people are mentioned.']","['A study of the query log of the AllTheWeb and Altavista search sites gives an idea of the relevance of the people search task: 11-17% of the queries were composed of a person name with additional terms and 4% were identified as person names #AUTHOR_TAG .', 'According to the data available from 1990 U.S. Census Bureau , only 90,000 different names are shared by 100 million people #TAUTHOR_TAG .', 'As the amount of information in the WWW grows, more of these people are mentioned in different web pages.', 'Therefore, a query for a common name in the Web will usually produce a list of results where different people are mentioned.']",0
"['', '', 'has been', '', '', 'Some researchers #TAUTHOR_TAG have explored the use of Wikipedia information to improve the disambiguation process .', 'Wikipediaions', 'brit and be in way', '']","['', '', 'has been', '', '', 'Some researchers #TAUTHOR_TAG have explored the use of Wikipedia information to improve the disambiguation process .', 'Wikipedia mentions', 'and be in way.', '']","['', '', 'has been applied', '', '', 'Some researchers #TAUTHOR_TAG have explored the use of Wikipedia information to improve the disambiguation process .', 'Wikipedia', 'and in', '']","['', '', '', '', '', 'Some researchers #TAUTHOR_TAG have explored the use of Wikipedia information to improve the disambiguation process .', '', '', '']",0
"['This leaves to the user the task of finding the pages relevant to the person he is interested in.', 'The user might refine the original query with additional terms, but this risks excluding relevant documents in the process.', 'dom the sharing', 'The Web People Search task , as defined in the first WePS evaluation campaign #TAUTHOR_TAG , consists of grouping search results for a given name according to the different people that share it .']","['This leaves to the user the task of finding the pages relevant to the person he is interested in.', 'The user might refine the original query with additional terms, but this risks excluding relevant documents in the process.', 'dominate the sharing', 'The Web People Search task , as defined in the first WePS evaluation campaign #TAUTHOR_TAG , consists of grouping search results for a given name according to the different people that share it .']","['This situation leaves to the user the task of finding the pages relevant to the particular person he is interested in.', 'The user might refine the original query with additional terms, but this risks excluding relevant documents in the process.', 'dom the task', 'The Web People Search task , as defined in the first WePS evaluation campaign #TAUTHOR_TAG , consists of grouping search results for a given name according to the different people that share it .']","['This situation leaves to the user the task of finding the pages relevant to the particular person he is interested in.', 'The user might refine the original query with additional terms, but this risks excluding relevant documents in the process.', '', 'The Web People Search task , as defined in the first WePS evaluation campaign #TAUTHOR_TAG , consists of grouping search results for a given name according to the different people that share it .']",0
"['We have used the testbeds from WePS-1 #TAUTHOR_TAG , 2007)2 and WePS-2 #AUTHOR_TAG evaluation campaigns 3.']","['We have used the testbeds from WePS-1 #TAUTHOR_TAG , 2007)2 and WePS-2 #AUTHOR_TAG evaluation campaigns 3.']","['We have used the testbeds from WePS-1 #TAUTHOR_TAG , 2007)2 and WePS-2 #AUTHOR_TAG evaluation campaigns 3.']","['We have used the testbeds from WePS-1 #TAUTHOR_TAG , 2007)2 and WePS-2 #AUTHOR_TAG evaluation campaigns 3.']",5
"['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguitying the structure of.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of names.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']","['The most used feature for the Web People Search task, however, are NEs.', ' #AUTHOR_TAG introduced a rule-based approach that tackles both variation and ambiguity analysing the structure of names.', 'In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance #TAUTHOR_TAG .', '', '', '', '']",0
"['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks : Word Sense Disambiguation ( WSD ) #AUTHOR_TAG and Cross-document Coreference ( CDC ) #TAUTHOR_TAG .', 'Most of early research work on person name ambiguity focuses on the CDC problem or uses found in the W.', 'It is only recently that the web ambiguity has been approached as problem and defined anLP task']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks : Word Sense Disambiguation ( WSD ) #AUTHOR_TAG and Cross-document Coreference ( CDC ) #TAUTHOR_TAG .', 'Most of early research work on person name ambiguity focuses on the CDC problem or uses found in the WSD literature.', 'It is only recently that the web ambiguity has been approached as problem and defined an NLP task']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks : Word Sense Disambiguation ( WSD ) #AUTHOR_TAG and Cross-document Coreference ( CDC ) #TAUTHOR_TAG .', 'Most of early research work on person name ambiguity focuses on the CDC problem or uses found in the WSD literature.', 'It is only recently that the web name ambiguity has been approached as and defined']","['The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks : Word Sense Disambiguation ( WSD ) #AUTHOR_TAG and Cross-document Coreference ( CDC ) #TAUTHOR_TAG .', 'Most of early research work on person name ambiguity focuses on the CDC problem or uses methods found in the WSD literature.', 'It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task -Web People Search -on its own #AUTHOR_TAG .']",0
"['', '', 'and', 'In 2009 , the second WePS campaign showed similar trends regarding the use of NE features #TAUTHOR_TAG .', '', '', '']","['', '', 'and', 'In 2009 , the second WePS campaign showed similar trends regarding the use of NE features #TAUTHOR_TAG .', '', '', '']","['', '', 'and', 'In 2009 , the second WePS campaign showed similar trends regarding the use of NE features #TAUTHOR_TAG .', '', '', '']","['', '', '', 'In 2009 , the second WePS campaign showed similar trends regarding the use of NE features #TAUTHOR_TAG .', '', '', '']",0
"['Many different have to documents an ambiguous is', 'The most', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #TAUTHOR_TAG and sometimes in combination with others see for instance #AUTHOR_TAG - .', 'link #AUTHOR_TAG #AUTHOR_TAG .', '', '', '', '']","['Many different have to documents an ambiguous is', 'The most', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #TAUTHOR_TAG and sometimes in combination with others see for instance #AUTHOR_TAG - .', 'link #AUTHOR_TAG #AUTHOR_TAG .', '', '', '', '']","['Many different features to documents an ambiguous name is', 'The most', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #TAUTHOR_TAG and sometimes in combination with others see for instance #AUTHOR_TAG - .', ' #AUTHOR_TAG #AUTHOR_TAG .', '', '', '', '']","['Many different features have been used to represent documents where an ambiguous name is mentioned.', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #TAUTHOR_TAG and sometimes in combination with others see for instance #AUTHOR_TAG - .', '', '', '', '', '']",0
"['have to an ambig is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #AUTHOR_TAG and sometimes in combination with others see for instance #TAUTHOR_TAG - .', 'link #AUTHOR_TAG or extracted features #AUTHOR_TAG .', '', '', '', '']","['have to an ambiguous is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #AUTHOR_TAG and sometimes in combination with others see for instance #TAUTHOR_TAG - .', 'link #AUTHOR_TAG or extracted features #AUTHOR_TAG .', '', '', '', '']","['to an ambiguous name is', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #AUTHOR_TAG and sometimes in combination with others see for instance #TAUTHOR_TAG - .', ' #AUTHOR_TAG or the extracted features #AUTHOR_TAG .', '', '', '', '']","['', '', 'Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name #AUTHOR_TAG .', 'Nevertheless , the full document text is present in most systems , sometimes as the only feature #AUTHOR_TAG and sometimes in combination with others see for instance #TAUTHOR_TAG - .', '', '', '', '', '']",0
"['our future plans include looking into optimal ways of acquiring SPs for verb classification.', 'Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to Word-Net classes.', ' #AUTHOR_TAG have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach #TAUTHOR_TAG .', 'The number and type ( of GRs for whichs can be reliably sp']","['our future plans include looking into optimal ways of acquiring SPs for verb classification.', 'Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to Word-Net classes.', ' #AUTHOR_TAG have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach #TAUTHOR_TAG .', 'The number and type (and of GRs for which SPs can be reliably']","['our future plans include looking into optimal ways of acquiring SPs for verb classification.', 'Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to Word-Net classes.', ' #AUTHOR_TAG have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach #TAUTHOR_TAG .', 'The number and type ( of GRs for whichs can be reliably sp']","['In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification.', 'Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to Word-Net classes.', ' #AUTHOR_TAG have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach #TAUTHOR_TAG .', '']",3
"['our future plans include looking into optimal ways of acquiring SPs for verb classification.', 'Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to Word-Net classes.', ' #AUTHOR_TAG have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach #TAUTHOR_TAG .', 'The number and type ( of GRs for whichs can be reliably sp']","['our future plans include looking into optimal ways of acquiring SPs for verb classification.', 'Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to Word-Net classes.', ' #AUTHOR_TAG have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach #TAUTHOR_TAG .', 'The number and type (and of GRs for which SPs can be reliably']","['our future plans include looking into optimal ways of acquiring SPs for verb classification.', 'Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to Word-Net classes.', ' #AUTHOR_TAG have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach #TAUTHOR_TAG .', 'The number and type ( of GRs for whichs can be reliably sp']","['In addition to the ideas mentioned earlier, our future plans include looking into optimal ways of acquiring SPs for verb classification.', 'Considerable research has been done on SP acquisition most of which has involved collecting argument headwords from data and generalizing to Word-Net classes.', ' #AUTHOR_TAG have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach #TAUTHOR_TAG .', '']",3
"['ject based on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #TAUTHOR_TAG for self training', '']","['based on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #TAUTHOR_TAG for self training', '']","['on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #TAUTHOR_TAG for self training .', '']","['We conjecture based on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #TAUTHOR_TAG for self training .', '']",3
"['ject based on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #TAUTHOR_TAG for self training', '']","['based on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #TAUTHOR_TAG for self training', '']","['on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #TAUTHOR_TAG for self training .', '']","['We conjecture based on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #TAUTHOR_TAG for self training .', '']",3
"['the EM training algorithm is able to exploit the information available in both gold and labeled data with more complex.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #AUTHOR_TAG for self training.', 'Self-training should also benefit other discriminatively trained parsers with latent annotations #TAUTHOR_TAG , although training would be much slower compared to using generative models , as in our case .']","['the EM training algorithm is able to exploit the information available in both gold and labeled data with more complex', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #AUTHOR_TAG for self training.', 'Self-training should also benefit other discriminatively trained parsers with latent annotations #TAUTHOR_TAG , although training would be much slower compared to using generative models , as in our case .']","['the EM training algorithm is able to exploit the information available in both gold and labeled data with more.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #AUTHOR_TAG for self training.', 'Self-training should also benefit other discriminatively trained parsers with latent annotations #TAUTHOR_TAG , although training would be much slower compared to using generative models , as in our case .']","['We conjecture based on our analysis that the EM training algorithm is able to exploit the information available in both gold and automatically labeled data with more complex grammars while being less affected by over-fitting.', 'Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches #AUTHOR_TAG for self training.', 'Self-training should also benefit other discriminatively trained parsers with latent annotations #TAUTHOR_TAG , although training would be much slower compared to using generative models , as in our case .']",3
"['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']",3
"['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']",3
"['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #TAUTHOR_TAG .']",3
"['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #AUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #AUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #AUTHOR_TAG .']","['Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG or shallow semantic trees , #AUTHOR_TAG .']",3
"['', 'build', 'When we run our classifiers on resource-tight environments such as cell-phones , we can use a random feature mixing technique #TAUTHOR_TAG or a memory-efficient trie implementation based on a succinct data structure #AUTHOR_TAG to reduce required memory usage .']","['', 'build', 'When we run our classifiers on resource-tight environments such as cell-phones , we can use a random feature mixing technique #TAUTHOR_TAG or a memory-efficient trie implementation based on a succinct data structure #AUTHOR_TAG to reduce required memory usage .']","['', '', 'When we run our classifiers on resource-tight environments such as cell-phones , we can use a random feature mixing technique #TAUTHOR_TAG or a memory-efficient trie implementation based on a succinct data structure #AUTHOR_TAG to reduce required memory usage .']","['', '', 'When we run our classifiers on resource-tight environments such as cell-phones , we can use a random feature mixing technique #TAUTHOR_TAG or a memory-efficient trie implementation based on a succinct data structure #AUTHOR_TAG to reduce required memory usage .']",3
"['The reordering models we describe follow our previous work using function word models for translation #TAUTHOR_TAG .', 'The core hypothesis in this work is that function words provide robust clues to the reordering patterns of the phrases surrounding them.', 'this insight for alignment ', '']","['The reordering models we describe follow our previous work using function word models for translation #TAUTHOR_TAG .', 'The core hypothesis in this work is that function words provide robust clues to the reordering patterns of the phrases surrounding them.', 'this insight for alignment,', '']","['The reordering models we describe follow our previous work using function word models for translation #TAUTHOR_TAG .', 'The core hypothesis in this work is that function words provide robust clues to the reordering patterns of the phrases surrounding them.', 'this insight for alignment', '']","['The reordering models we describe follow our previous work using function word models for translation #TAUTHOR_TAG .', 'The core hypothesis in this work is that function words provide robust clues to the reordering patterns of the phrases surrounding them.', '', '']",2
"['Our reordering model is closely related7 with respect to conditioning the reordering items', 'model fixed words.', 'With respect to the focus on function words , our reordering model is closely related to the UALIGN system #TAUTHOR_TAG .', 'However, U uses deep syntactic analysis and hand-crafted heuristics in its model.']","['Our reordering model is closely related with respect to conditioning the reordering items.', 'model fixed words.', 'With respect to the focus on function words , our reordering model is closely related to the UALIGN system #TAUTHOR_TAG .', 'However, UALIGN uses deep syntactic analysis and hand-crafted heuristics in its model.']","['Our reordering model is closely related with respect to conditioning the reordering predictions', 'model function words.', 'With respect to the focus on function words , our reordering model is closely related to the UALIGN system #TAUTHOR_TAG .', 'However, UALIGN uses deep syntactic analysis and hand-crafted heuristics in its model.']","['Our reordering model is closely related to the model proposed by #AUTHOR_TAG ;2007a), with respect to conditioning the reordering predictions on lexical items.', '', 'With respect to the focus on function words , our reordering model is closely related to the UALIGN system #TAUTHOR_TAG .', 'However, UALIGN uses deep syntactic analysis and hand-crafted heuristics in its model.']",1
"['To model o ( Li , S â\x86\x92 T ) , o ( Ri , S â\x86\x92 T ) , i.e. the reordering of the neighboring phrases of a function word , we employ the orientation model introduced by #TAUTHOR_TAG .', ', this model takes the form of probability distribution P ori (o(L i,S→T ), o(R i,S→T )|Y i,S→T ), which conditions the reordering on the lexical identity of the function word alignment (but independent of the lexical identity of its neighboring phrases).', ', the reordering into one of the following four orientation values (borrowed from #AUTHOR_TAG ) with respect to the function wordacentap andap', '', '']","['To model o ( Li , S â\x86\x92 T ) , o ( Ri , S â\x86\x92 T ) , i.e. the reordering of the neighboring phrases of a function word , we employ the orientation model introduced by #TAUTHOR_TAG .', 'this model takes the form of probability distribution P ori (o(L i,S→T ), o(R i,S→T )|Y i,S→T ), which conditions the reordering on the lexical identity of the function word alignment (but independent of the lexical identity of its neighboring phrases).', 'particular, the reordering into one of the following four orientation values (borrowed from #AUTHOR_TAG ) with respect to the function word: Gap and Gap', '', '']","['To model o ( Li , S â\x86\x92 T ) , o ( Ri , S â\x86\x92 T ) , i.e. the reordering of the neighboring phrases of a function word , we employ the orientation model introduced by #TAUTHOR_TAG .', ', this model takes the form of probability distribution P ori (o(L i,S→T ), o(R i,S→T )|Y i,S→T ), which conditions the reordering on the lexical identity of the function word alignment (but independent of the lexical identity of its neighboring phrases).', ', o the reordering into one of the following four orientation values (borrowed from #AUTHOR_TAG ) with respect to the function word and', '', '']","['To model o ( Li , S â\x86\x92 T ) , o ( Ri , S â\x86\x92 T ) , i.e. the reordering of the neighboring phrases of a function word , we employ the orientation model introduced by #TAUTHOR_TAG .', 'Formally, this model takes the form of probability distribution P ori (o(L i,S→T ), o(R i,S→T )|Y i,S→T ), which conditions the reordering on the lexical identity of the function word alignment (but independent of the lexical identity of its neighboring phrases).', '', '', '']",5
"['The reordering models we describe follow our previous work using function word models for translation #TAUTHOR_TAG .', 'The core hypothesis in this work is that function words provide robust clues to the reordering patterns of the phrases surrounding them.', 'this insight for alignment ', '']","['The reordering models we describe follow our previous work using function word models for translation #TAUTHOR_TAG .', 'The core hypothesis in this work is that function words provide robust clues to the reordering patterns of the phrases surrounding them.', 'this insight for alignment,', '']","['The reordering models we describe follow our previous work using function word models for translation #TAUTHOR_TAG .', 'The core hypothesis in this work is that function words provide robust clues to the reordering patterns of the phrases surrounding them.', 'this insight for alignment', '']","['The reordering models we describe follow our previous work using function word models for translation #TAUTHOR_TAG .', 'The core hypothesis in this work is that function words provide robust clues to the reordering patterns of the phrases surrounding them.', '', '']",2
"['To model d ( FWi â\x88\x92 1 , S â\x86\x92 T ) , d ( FWi +1 , S â\x86\x92 T ) , i.e. whether Li , S â\x86\x92 T and Ri , S â\x86\x92 T extend beyond the neighboring function word phrase pairs , we utilize the pairwise dominance model of #TAUTHOR_TAG .', 'Taking d(F W i−1,S→T ) as a case in point, this model takes the form']","['To model d ( FWi â\x88\x92 1 , S â\x86\x92 T ) , d ( FWi +1 , S â\x86\x92 T ) , i.e. whether Li , S â\x86\x92 T and Ri , S â\x86\x92 T extend beyond the neighboring function word phrase pairs , we utilize the pairwise dominance model of #TAUTHOR_TAG .', 'Taking d(F W i−1,S→T ) as a case in point, this model takes the form']","['To model d ( FWi â\x88\x92 1 , S â\x86\x92 T ) , d ( FWi +1 , S â\x86\x92 T ) , i.e. whether Li , S â\x86\x92 T and Ri , S â\x86\x92 T extend beyond the neighboring function word phrase pairs , we utilize the pairwise dominance model of #TAUTHOR_TAG .', 'Taking d(F W i−1,S→T ) as a case in point, this model takes the form']","['To model d ( FWi â\x88\x92 1 , S â\x86\x92 T ) , d ( FWi +1 , S â\x86\x92 T ) , i.e. whether Li , S â\x86\x92 T and Ri , S â\x86\x92 T extend beyond the neighboring function word phrase pairs , we utilize the pairwise dominance model of #TAUTHOR_TAG .', 'Taking d(F W i−1,S→T ) as a case in point, this model takes the form']",5
"['In our previous work #TAUTHOR_TAG , we started an initial investigation on conversation entailment .', 'We have collected a dataset of 875 instances.', 'Each instance consists of a conversation segment and a hypothesis (as described in Section 1).', 'The hypotheses are statements about conversation participants and are further categorized into four types: about their profile information, their beliefs and opinions, their desires, and their communicative intentions.', 'We developed an approach that work on entail.', '', '']","['In our previous work #TAUTHOR_TAG , we started an initial investigation on conversation entailment .', 'We have collected a dataset of 875 instances.', 'Each instance consists of a conversation segment and a hypothesis (as described in Section 1).', 'The hypotheses are statements about conversation participants and are further categorized into four types: about their profile information, their beliefs and opinions, their desires, and their communicative intentions.', 'We developed an approach that work on entailment.', '', '']","['In our previous work #TAUTHOR_TAG , we started an initial investigation on conversation entailment .', 'We have collected a dataset of 875 instances.', 'Each instance consists of a conversation segment and a hypothesis (as described in Section 1).', 'The hypotheses are statements about conversation participants and are further categorized into four types: about their profile information, their beliefs and opinions, their desires, and their communicative intentions.', 'We developed an approach that previous work onual entailment.', '', '']","['In our previous work #TAUTHOR_TAG , we started an initial investigation on conversation entailment .', 'We have collected a dataset of 875 instances.', 'Each instance consists of a conversation segment and a hypothesis (as described in Section 1).', 'The hypotheses are statements about conversation participants and are further categorized into four types: about their profile information, their beliefs and opinions, their desires, and their communicative intentions.', 'We developed an approach that is motivated by previous work on textual entailment.', '', '']",2
"['Using the implicit modeling of argument consistency , we follow the same approach as in our previous work #TAUTHOR_TAG and trained a logistic regression model to predict verb alignment based on the features in Table 1 .']","['Using the implicit modeling of argument consistency , we follow the same approach as in our previous work #TAUTHOR_TAG and trained a logistic regression model to predict verb alignment based on the features in Table 1 .']","['Using the implicit modeling of argument consistency , we follow the same approach as in our previous work #TAUTHOR_TAG and trained a logistic regression model to predict verb alignment based on the features in Table 1 .']","['Using the implicit modeling of argument consistency , we follow the same approach as in our previous work #TAUTHOR_TAG and trained a logistic regression model to predict verb alignment based on the features in Table 1 .']",2
"['Note that in our original work #TAUTHOR_TAG , only development data were used to show some initial observations.', 'Here we trained our mod- els on the development data and results shown are from the testing data.']","['Note that in our original work #TAUTHOR_TAG , only development data were used to show some initial observations.', 'Here we trained our mod- els on the development data and results shown are from the testing data.']","['Note that in our original work #TAUTHOR_TAG , only development data were used to show some initial observations.', 'Here we trained our mod- els on the development data and results shown are from the testing data.']","['Note that in our original work #TAUTHOR_TAG , only development data were used to show some initial observations.', 'Here we trained our mod- els on the development data and results shown are from the testing data.']",1
"['', '', '', '', 'Figure 3 shows an Example. in this figure the alignment between x 5 = suggests from the hypothesis and u 4 = opinion from the conversation segment is a pseudo alignment, which directly maps a verb term in the hypothesis to an utterance term represented by its dialogue act.', 'This alignment is obtained by following the same set of rules learned from the development dataset as in #TAUTHOR_TAG .']","['', '', '', '', 'Figure 3 shows an Example in this figure the alignment between x 5 = suggests from the hypothesis and u 4 = opinion from the conversation segment is a pseudo alignment, which directly maps a verb term in the hypothesis to an utterance term represented by its dialogue act.', 'This alignment is obtained by following the same set of rules learned from the development dataset as in #TAUTHOR_TAG .']","['', '', '', '', 'Figure 3 shows an example Example 2. in this figure the alignment between x 5 = suggests from the hypothesis and u 4 = opinion from the conversation segment is a pseudo alignment, which directly maps a verb term in the hypothesis to an utterance term represented by its dialogue act.', 'This alignment is obtained by following the same set of rules learned from the development dataset as in #TAUTHOR_TAG .']","['', '', '', '', 'Figure 3 shows an example of alignment between the conversation terms and hypothesis terms in Example 2. Note that in this figure the alignment between x 5 = suggests from the hypothesis and u 4 = opinion from the conversation segment is a pseudo alignment, which directly maps a verb term in the hypothesis to an utterance term represented by its dialogue act.', 'This alignment is obtained by following the same set of rules learned from the development dataset as in #TAUTHOR_TAG .']",5
"['To address this limitation , our previous work #TAUTHOR_TAG has initiated an investigation on the problem of conversation entailment .', 'The problem was formulated as follows: given a conversation discourse D and a hypothesis H concerning its participant, the goal was to identify whether D entails H.', ', as in Example , the hypothesis can be entailed from the segment the', '', '']","['To address this limitation , our previous work #TAUTHOR_TAG has initiated an investigation on the problem of conversation entailment .', 'The problem was formulated as follows: given a conversation discourse D and a hypothesis H concerning its participant, the goal was to identify whether D entails H.', 'instance, as in Example 1, the hypothesis can be entailed from the segment the', '', '']","['To address this limitation , our previous work #TAUTHOR_TAG has initiated an investigation on the problem of conversation entailment .', 'The problem was formulated as follows: given a conversation discourse D and a hypothesis H concerning its participant, the goal was to identify whether D entails H.', ', as in Example 1, the first hypothesis can be entailed from the conversation segment', '', '']","['To address this limitation , our previous work #TAUTHOR_TAG has initiated an investigation on the problem of conversation entailment .', 'The problem was formulated as follows: given a conversation discourse D and a hypothesis H concerning its participant, the goal was to identify whether D entails H.', 'For instance, as in Example 1, the first hypothesis can be entailed from the conversation segment while the second hypothesis cannot.', '', '']",2
"['In our previous work #TAUTHOR_TAG , conversation entailment is formulated as the following : given a conversation segment D which is represented by a set of clauses D = d1 â\x88§ ... â\x88§ dm , and a hypothesis H represented by another set of clauses H = h1 â\x88§ ... â\x88§ hn , the prediction on whether D entails H is determined by the product of probabilities that each hypothesis clause hj is entailed from all the conversation segment clauses d1 ... dm as follows .', 'This based a is entailed from segment is condition independent']","['In our previous work #TAUTHOR_TAG , conversation entailment is formulated as the following : given a conversation segment D which is represented by a set of clauses D = d1 â\x88§ ... â\x88§ dm , and a hypothesis H represented by another set of clauses H = h1 â\x88§ ... â\x88§ hn , the prediction on whether D entails H is determined by the product of probabilities that each hypothesis clause hj is entailed from all the conversation segment clauses d1 ... dm as follows .', 'This based a is entailed from segment is conditionally independent']","['In our previous work #TAUTHOR_TAG , conversation entailment is formulated as the following : given a conversation segment D which is represented by a set of clauses D = d1 â\x88§ ... â\x88§ dm , and a hypothesis H represented by another set of clauses H = h1 â\x88§ ... â\x88§ hn , the prediction on whether D entails H is determined by the product of probabilities that each hypothesis clause hj is entailed from all the conversation segment clauses d1 ... dm as follows .', 'This is based a clause is entailed from is conditionally independent']","['In our previous work #TAUTHOR_TAG , conversation entailment is formulated as the following : given a conversation segment D which is represented by a set of clauses D = d1 â\x88§ ... â\x88§ dm , and a hypothesis H represented by another set of clauses H = h1 â\x88§ ... â\x88§ hn , the prediction on whether D entails H is determined by the product of probabilities that each hypothesis clause hj is entailed from all the conversation segment clauses d1 ... dm as follows .', '']",2
"['Linear learning machines are one of the most popular machines used for classification problems.', 'The objective of a typical classification problem is to learn a function that separates the data into different classes.', 'The data is usually in the form of features extracted from abstract objects like strings, trees', 'A of learning using complex functions is that complex functions do not general well thus tend to over', '', '', '', '', '', '', '', '', '', '', 'our classification task', 'we present the ""discrete"" structures followed by the kernel we used.', 'We use the structures previously used by #TAUTHOR_TAG , and propose one new structure .', 'Although we experimented with all of their structures, 3 here we only present the ones that perform best for our classification task.', 'derived from a the underlying', '', '', '']","['Linear learning machines are one of the most popular machines used for classification problems.', 'The objective of a typical classification problem is to learn a function that separates the data into different classes.', 'The data is usually in the form of features extracted from abstract objects like strings, trees,', 'A of learning using complex functions is that complex functions do not generalize well thus tend to', '', '', '', '', '', '', '', '', '', '', 'our classification task.', 'we present the ""discrete"" structures followed by the kernel we used.', 'We use the structures previously used by #TAUTHOR_TAG , and propose one new structure .', 'Although we experimented with all of their structures, 3 here we only present the ones that perform best for our classification task.', 'derived from a the underlying', '', '', '']","['Linear learning machines are one of the most popular machines used for classification problems.', 'The objective of a typical classification problem is to learn a function that separates the data into different classes.', 'The data is usually in the form of features extracted from abstract objects like strings', 'of learning using complex functions is that complex functions do not generalize well thus tend to over', '', '', '', '', '', '', '', '', '', '', 'our classification task.', 'we present the ""discrete"" structures followed by the kernel we used.', 'We use the structures previously used by #TAUTHOR_TAG , and propose one new structure .', 'Although we experimented with all of their structures, 3 here we only present the ones that perform best for our classification task.', 'are derived from a variation', '', '', '']","['Linear learning machines are one of the most popular machines used for classification problems.', 'The objective of a typical classification problem is to learn a function that separates the data into different classes.', 'The data is usually in the form of features extracted from abstract objects like strings, trees, etc.', 'A drawback of learning by using complex functions is that complex functions do not generalize well and thus tend to over-fit.', '', '', '', '', '', '', '', '', '', '', '', 'Now we present the ""discrete"" structures followed by the kernel we used.', 'We use the structures previously used by #TAUTHOR_TAG , and propose one new structure .', 'Although we experimented with all of their structures, 3 here we only present the ones that perform best for our classification task.', '', '', '', '']",5
"['', '', '', '', 'dependency structures perform the.', 'This revalidates the observation of #TAUTHOR_TAG that phrase structure representations and dependency representations add complimentary value to the learning task .', '']","['', '', '', '', 'structures perform the best.', 'This revalidates the observation of #TAUTHOR_TAG that phrase structure representations and dependency representations add complimentary value to the learning task .', '']","['', '', '', '', 'dependencybased structures perform the best.', 'This revalidates the observation of #TAUTHOR_TAG that phrase structure representations and dependency representations add complimentary value to the learning task .', '']","['', '', '', '', '', 'This revalidates the observation of #TAUTHOR_TAG that phrase structure representations and dependency representations add complimentary value to the learning task .', '']",1
"['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'inserted) the', 'Here , the PET and GR kernel perform similar : this is different from the results of #TAUTHOR_TAG where GR performed much worse than PET']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'inserted nodes) the', 'Here , the PET and GR kernel perform similar : this is different from the results of #TAUTHOR_TAG where GR performed much worse than PET']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'are inserted', 'Here , the PET and GR kernel perform similar : this is different from the results of #TAUTHOR_TAG where GR performed much worse than PET']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Here , the PET and GR kernel perform similar : this is different from the results of #TAUTHOR_TAG where GR performed much worse than PET']",1
"['Our results also confirm the insights gained by #TAUTHOR_TAG , who observed that in crossdomain polarity analysis adding more training data is not always beneficial .', 'Apparently even the smallest training dataset (cameras) contain enough feature instances to learn a model which performs well on the testing data.']","['Our results also confirm the insights gained by #TAUTHOR_TAG , who observed that in crossdomain polarity analysis adding more training data is not always beneficial .', 'Apparently even the smallest training dataset (cameras) contain enough feature instances to learn a model which performs well on the testing data.']","['Our results also confirm the insights gained by #TAUTHOR_TAG , who observed that in crossdomain polarity analysis adding more training data is not always beneficial .', 'Apparently even the smallest training dataset (cameras) contain enough feature instances to learn a model which performs well on the testing data.']","['Our results also confirm the insights gained by #TAUTHOR_TAG , who observed that in crossdomain polarity analysis adding more training data is not always beneficial .', 'Apparently even the smallest training dataset (cameras) contain enough feature instances to learn a model which performs well on the testing data.']",1
"['', '', '', '', '', 'employ the opinion target vocabularies are substantially', 'For future work , we might investigate how machine learning algorithms , which are specifically designed for the problem of domain adaptation #TAUTHOR_TAG , perform in comparison to our approach .', '', '', '', '']","['', '', '', '', '', 'employ the opinion target vocabularies are substantially', 'For future work , we might investigate how machine learning algorithms , which are specifically designed for the problem of domain adaptation #TAUTHOR_TAG , perform in comparison to our approach .', '', '', '', '']","['', '', '', '', '', 'we employ the opinion target vocabularies are substantially', 'For future work , we might investigate how machine learning algorithms , which are specifically designed for the problem of domain adaptation #TAUTHOR_TAG , perform in comparison to our approach .', '', '', '', '']","['', '', '', '', '', '', 'For future work , we might investigate how machine learning algorithms , which are specifically designed for the problem of domain adaptation #TAUTHOR_TAG , perform in comparison to our approach .', '', '', '', '']",3
"['', '', '', '', '', 'employ the opinion target vocabularies are substantially', 'For future work , we might investigate how machine learning algorithms , which are specifically designed for the problem of domain adaptation #TAUTHOR_TAG , perform in comparison to our approach .', '', '', '', '']","['', '', '', '', '', 'employ the opinion target vocabularies are substantially', 'For future work , we might investigate how machine learning algorithms , which are specifically designed for the problem of domain adaptation #TAUTHOR_TAG , perform in comparison to our approach .', '', '', '', '']","['', '', '', '', '', 'we employ the opinion target vocabularies are substantially', 'For future work , we might investigate how machine learning algorithms , which are specifically designed for the problem of domain adaptation #TAUTHOR_TAG , perform in comparison to our approach .', '', '', '', '']","['', '', '', '', '', '', 'For future work , we might investigate how machine learning algorithms , which are specifically designed for the problem of domain adaptation #TAUTHOR_TAG , perform in comparison to our approach .', '', '', '', '']",3
"['An implementation of the transition-based dependency parsing frame- work #TAUTHOR_TAG using an arc-eager transi- tion strategy and are trained using the percep- tron algorithm as in #AUTHOR_TAG with a beam size of 8. Beams with varying sizes can be used to produce k-best lists.', '', '']","['An implementation of the transition-based dependency parsing frame- work #TAUTHOR_TAG using an arc-eager transi- tion strategy and are trained using the percep- tron algorithm as in #AUTHOR_TAG with a beam size of 8. Beams with varying sizes can be used to produce k-best lists.', '', '']","['An implementation of the transition-based dependency parsing frame- work #TAUTHOR_TAG using an arc-eager transi- tion strategy and are trained using the percep- tron algorithm as in #AUTHOR_TAG with a beam size of 8. Beams with varying sizes can be used to produce k-best lists.', '', '']","['An implementation of the transition-based dependency parsing frame- work #TAUTHOR_TAG using an arc-eager transi- tion strategy and are trained using the percep- tron algorithm as in #AUTHOR_TAG with a beam size of 8. Beams with varying sizes can be used to produce k-best lists.', '', '']",5
"['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation ( Mann and Mc #AUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #TAUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation ( Mann and Mc #AUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #TAUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation ( Mann and Mc #AUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #TAUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation ( Mann and Mc #AUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #TAUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']",0
"['', 'We use the non-projective k-best MST algorithm to generate k-best lists #TAUTHOR_TAG , where k = 8 for the experiments in this paper .', '', '']","['', 'We use the non-projective k-best MST algorithm to generate k-best lists #TAUTHOR_TAG , where k = 8 for the experiments in this paper .', '', '']","['', 'We use the non-projective k-best MST algorithm to generate k-best lists #TAUTHOR_TAG , where k = 8 for the experiments in this paper .', '', '']","['', 'We use the non-projective k-best MST algorithm to generate k-best lists #TAUTHOR_TAG , where k = 8 for the experiments in this paper .', '', '']",5
"['Another application of the augmented-loss framework is to improve parser domain portability in the presence of partially labeled data.', 'Consider, for example, the case of questions.', ' #TAUTHOR_TAG observed that dependency parsers tend to do quite poorly when parsing questions due to their limited exposure to them in the news corpora from the PennTreebank .', 'Table', '', '', '', '', '']","['Another application of the augmented-loss framework is to improve parser domain portability in the presence of partially labeled data.', 'Consider, for example, the case of questions.', ' #TAUTHOR_TAG observed that dependency parsers tend to do quite poorly when parsing questions due to their limited exposure to them in the news corpora from the PennTreebank .', 'Table', '', '', '', '', '']","['Another application of the augmented-loss framework is to improve parser domain portability in the presence of partially labeled data.', 'Consider, for example, the case of questions.', ' #TAUTHOR_TAG observed that dependency parsers tend to do quite poorly when parsing questions due to their limited exposure to them in the news corpora from the PennTreebank .', 'Table', '', '', '', '', '']","['Another application of the augmented-loss framework is to improve parser domain portability in the presence of partially labeled data.', 'Consider, for example, the case of questions.', ' #TAUTHOR_TAG observed that dependency parsers tend to do quite poorly when parsing questions due to their limited exposure to them in the news corpora from the PennTreebank .', '', '', '', '', '', '']",1
['1Our rules are similar to those from #TAUTHOR_TAG .'],['1Our rules are similar to those from #TAUTHOR_TAG .'],['1Our rules are similar to those from #TAUTHOR_TAG .'],['1Our rules are similar to those from #TAUTHOR_TAG .'],1
"['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #TAUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #TAUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #TAUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #TAUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']",0
"['An implementation of graph- based parsing algorithms with an arc-factored parameterization #TAUTHOR_TAG .', '', '', '']","['An implementation of graph- based parsing algorithms with an arc-factored parameterization #TAUTHOR_TAG .', '', '', '']","['An implementation of graph- based parsing algorithms with an arc-factored parameterization #TAUTHOR_TAG .', '', '', '']","['An implementation of graph- based parsing algorithms with an arc-factored parameterization #TAUTHOR_TAG .', '', '', '']",5
"['A recent study by also investigates the task of training parsers to improve MT reordering.', 'In that work, a is used to a re to produce k-best lists.', 'The parse with the reordering is then fixed and added back to the training set and a new parser is trained on resulting data', 'method is called targeted self-training as it is similar in vein to self-training #TAUTHOR_TAG , with the exception that the new parse data is targeted to produce accurate word reorderings', '', '', '', '', '', '', '']","['A recent study by also investigates the task of training parsers to improve MT reordering.', 'In that work, a is used to a reordered to produce k-best lists.', 'The parse with the reordering is then fixed and added back to the training set and a new parser is trained on resulting data.', 'method is called targeted self-training as it is similar in vein to self-training #TAUTHOR_TAG , with the exception that the new parse data is targeted to produce accurate word reorderings', '', '', '', '', '', '', '']","['A recent study by also investigates the task of training parsers to improve MT reordering.', 'In that work, a parser is used to a set re to produce k-best lists.', 'The parse with the best reordering score is then fixed and added back to the training set and a new parser is trained on resulting data.', 'The method is called targeted self-training as it is similar in vein to self-training #TAUTHOR_TAG , with the exception that the new parse data is targeted to produce accurate word reorderings .', '', '', '', '', '', '', '']","['A recent study by also investigates the task of training parsers to improve MT reordering.', 'In that work, a parser is used to first parse a set of manually reordered sentences to produce k-best lists.', 'The parse with the best reordering score is then fixed and added back to the training set and a new parser is trained on resulting data.', 'The method is called targeted self-training as it is similar in vein to self-training #TAUTHOR_TAG , with the exception that the new parse data is targeted to produce accurate word reorderings .', '', '', '', '', '', '', '']",1
"['', '', 'Though we could have used a further downstream measure like BLEU , METEOR has also been shown to directly correlate with translation quality #TAUTHOR_TAG and is simpler to measure .', '']","['', '', 'Though we could have used a further downstream measure like BLEU , METEOR has also been shown to directly correlate with translation quality #TAUTHOR_TAG and is simpler to measure .', '']","['', '', 'Though we could have used a further downstream measure like BLEU , METEOR has also been shown to directly correlate with translation quality #TAUTHOR_TAG and is simpler to measure .', '']","['', '', 'Though we could have used a further downstream measure like BLEU , METEOR has also been shown to directly correlate with translation quality #TAUTHOR_TAG and is simpler to measure .', '']",4
"['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #TAUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #TAUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #TAUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #TAUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']",0
"['• Transition-based: An implementation of the transition-based dependency parsing framework #AUTHOR_TAG using an arc-eager transition strategy and are trained using the perceptron algorithm as in #TAUTHOR_TAG with a beam size of 8 . Beams with varying sizes can be used to produce k-best lists.', '', '']","['• Transition-based: An implementation of the transition-based dependency parsing framework #AUTHOR_TAG using an arc-eager transition strategy and are trained using the perceptron algorithm as in #TAUTHOR_TAG with a beam size of 8 . Beams with varying sizes can be used to produce k-best lists.', '', '']","['• Transition-based: An implementation of the transition-based dependency parsing framework #AUTHOR_TAG using an arc-eager transition strategy and are trained using the perceptron algorithm as in #TAUTHOR_TAG with a beam size of 8 . Beams with varying sizes can be used to produce k-best lists.', '', '']","['• Transition-based: An implementation of the transition-based dependency parsing framework #AUTHOR_TAG using an arc-eager transition strategy and are trained using the perceptron algorithm as in #TAUTHOR_TAG with a beam size of 8 . Beams with varying sizes can be used to produce k-best lists.', '', '']",5
"['The and of- dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The and of dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The accuracy and of-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering sentiment analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', '', '', '', '']",0
"['In terms of treebank data , the primary training corpus is the Penn Wall Street Journal Treebank ( PTB ) #TAUTHOR_TAG .', 'We also make use of the Brown corpus, and the Question Treebank (QTB) #AUTHOR_TAG']","['In terms of treebank data , the primary training corpus is the Penn Wall Street Journal Treebank ( PTB ) #TAUTHOR_TAG .', 'We also make use of the Brown corpus, and the Question Treebank (QTB) #AUTHOR_TAG']","['In terms of treebank data , the primary training corpus is the Penn Wall Street Journal Treebank ( PTB ) #TAUTHOR_TAG .', 'We also make use of the Brown corpus, and the Question Treebank (QTB) #AUTHOR_TAG']","['In terms of treebank data , the primary training corpus is the Penn Wall Street Journal Treebank ( PTB ) #TAUTHOR_TAG .', 'We also make use of the Brown corpus, and the Question Treebank (QTB) #AUTHOR_TAG']",5
"['The and of- dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The and of dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The accuracy and of-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering sentiment analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', '', '', '', '']",0
"['The work that is most similar to ours is that of #TAUTHOR_TAG , who introduced the Constraint Driven Learning algorithm ( CODL ) .', 'Their algorithm specifically optimizes a loss function with the addition of constraints based on unlabeled data (what we call extrinsic datasets).', 'For each unlabeled example, they use the current model along with their set of constraints to select a set of k automatically labeled examples which best meet the constraints.', 'These induced examples are then added to their training set and, after processing each unlabeled dataset, they perform full model optimization with the concatenation of training data and newly generated training items.', 'The augmented can be', '', '', '', '']","['The work that is most similar to ours is that of #TAUTHOR_TAG , who introduced the Constraint Driven Learning algorithm ( CODL ) .', 'Their algorithm specifically optimizes a loss function with the addition of constraints based on unlabeled data (what we call extrinsic datasets).', 'For each unlabeled example, they use the current model along with their set of constraints to select a set of k automatically labeled examples which best meet the constraints.', 'These induced examples are then added to their training set and, after processing each unlabeled dataset, they perform full model optimization with the concatenation of training data and newly generated training items.', 'The augmented-loss can be', '', '', '', '']","['The work that is most similar to ours is that of #TAUTHOR_TAG , who introduced the Constraint Driven Learning algorithm ( CODL ) .', 'Their algorithm specifically optimizes a loss function with the addition of constraints based on unlabeled data (what we call extrinsic datasets).', 'For each unlabeled example, they use the current model along with their set of constraints to select a set of k automatically labeled examples which best meet the constraints.', 'These induced examples are then added to their training set and, after processing each unlabeled dataset, they perform full model optimization with the concatenation of training data and newly generated training items.', 'The augmented-loss algorithm can be viewed', '', '', '', '']","['The work that is most similar to ours is that of #TAUTHOR_TAG , who introduced the Constraint Driven Learning algorithm ( CODL ) .', 'Their algorithm specifically optimizes a loss function with the addition of constraints based on unlabeled data (what we call extrinsic datasets).', 'For each unlabeled example, they use the current model along with their set of constraints to select a set of k automatically labeled examples which best meet the constraints.', 'These induced examples are then added to their training set and, after processing each unlabeled dataset, they perform full model optimization with the concatenation of training data and newly generated training items.', '', '', '', '', '']",1
"['investig', '', '', '', '', '', 'evaluate the method on alternate extrinsic loss functions', ' #TAUTHOR_TAG presented a perceptron-based algorithm for learning the phrase-translation parameters in a statistical machine translation system .', 'to the-ranker loss function here, they use a k-best lists of hypotheses in order to identify parameters which can improve a global objective function: BLEU score.', 'In their work, they are interested in learning a parameterization over translation phrases (including the underlying wordalignment) which optimizes the BLEU score.', 'Their is considerably they want to incorporate additional features into their model and define an objective function which allows them to do so for objective to adapt the parser model parameters to downstream tasks or alternative intrinsicing']","['investigates', '', '', '', '', '', 'evaluate the method on alternate extrinsic loss functions.', ' #TAUTHOR_TAG presented a perceptron-based algorithm for learning the phrase-translation parameters in a statistical machine translation system .', 'to the inline-ranker loss function here, they use a k-best lists of hypotheses in order to identify parameters which can improve a global objective function: BLEU score.', 'In their work, they are interested in learning a parameterization over translation phrases (including the underlying wordalignment) which optimizes the BLEU score.', 'Their is considerably they want to incorporate additional features into their model and define an objective function which allows them to do so; for objective to adapt the parser model parameters to downstream tasks or alternative intrinsic']","['investig', '', '', '', '', '', 'evaluate the method on alternate extrinsic loss functions.', ' #TAUTHOR_TAG presented a perceptron-based algorithm for learning the phrase-translation parameters in a statistical machine translation system .', 'to the inline-ranker loss function here, they use a k-best lists of hypotheses in order to identify parameters which can improve a global objective function: BLEU score.', 'In their work, they are interested in learning a parameterization over translation phrases (including the underlying wordalignment) which optimizes the BLEU score.', 'Their is considerably they want to incorporate additional features into their model and define an objective function which allows them to do so; for to adapt the parser model parameters to downstream tasks or alternative intrinsicing']","['', '', '', '', '', '', 'Furthermore, we also evaluate the method on alternate extrinsic loss functions.', ' #TAUTHOR_TAG presented a perceptron-based algorithm for learning the phrase-translation parameters in a statistical machine translation system .', 'Similar to the inline-ranker loss function presented here, they use a k-best lists of hypotheses in order to identify parameters which can improve a global objective function: BLEU score.', 'In their work, they are interested in learning a parameterization over translation phrases (including the underlying wordalignment) which optimizes the BLEU score.', 'Their goal is considerably different; they want to incorporate additional features into their model and define an objective function which allows them to do so; whereas, we are interested in allowing for multiple objective functions in order to adapt the parser model parameters to downstream tasks or alternative intrinsic (parsing) objectives.']",1
"['A recent study by #TAUTHOR_TAG also investigates the task of training parsers to improve MT reordering .', 'In that work, a parser is used to first parse a set of manually reordered sentences to produce k-best lists.', 'The parse with the best reordering score is then fixed and added back to the training set and a new parser is trained on resulting data.', 'The method is called targeted self-training it is similar in vein to selftrainingMc with exception that', '', '', '', '', '', '', '']","['A recent study by #TAUTHOR_TAG also investigates the task of training parsers to improve MT reordering .', 'In that work, a parser is used to first parse a set of manually reordered sentences to produce k-best lists.', 'The parse with the best reordering score is then fixed and added back to the training set and a new parser is trained on resulting data.', 'The method is called targeted self-training it is similar in vein to self-training with exception that', '', '', '', '', '', '', '']","['A recent study by #TAUTHOR_TAG also investigates the task of training parsers to improve MT reordering .', 'In that work, a parser is used to first parse a set of manually reordered sentences to produce k-best lists.', 'The parse with the best reordering score is then fixed and added back to the training set and a new parser is trained on resulting data.', 'The method is called targeted self-training it is similar in vein to selftrainingMc with the exception that', '', '', '', '', '', '', '']","['A recent study by #TAUTHOR_TAG also investigates the task of training parsers to improve MT reordering .', 'In that work, a parser is used to first parse a set of manually reordered sentences to produce k-best lists.', 'The parse with the best reordering score is then fixed and added back to the training set and a new parser is trained on resulting data.', '', '', '', '', '', '', '', '']",1
"['', '', '', '', '', '', 'Optimizing for dependency length is particularly important as parsers tend to do worse on longer dependencies (Mc #AUTHOR_TAG and these dependencies are typically the most meaningful for down- stream tasks, e.g., main verb dependencies for tasks like information extraction #TAUTHOR_TAG and textual entailment #AUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency length is particularly important as parsers tend to do worse on longer dependencies (Mc #AUTHOR_TAG and these dependencies are typically the most meaningful for down- stream tasks, e.g., main verb dependencies for tasks like information extraction #TAUTHOR_TAG and textual entailment #AUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies (Mc #AUTHOR_TAG and these dependencies are typically the most meaningful for down- stream tasks, e.g., main verb dependencies for tasks like information extraction #TAUTHOR_TAG and textual entailment #AUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies (Mc #AUTHOR_TAG and these dependencies are typically the most meaningful for down- stream tasks, e.g., main verb dependencies for tasks like information extraction #TAUTHOR_TAG and textual entailment #AUTHOR_TAG .']",0
"['separ', '', '', '', '', '3).', 'def', 'Proof.', 'Identical to the standard perceptron proof , e.g. , #TAUTHOR_TAG , by inserting in loss-separability for normal separability .']","['', '', '', '', '', 'y).', '', 'Proof.', 'Identical to the standard perceptron proof , e.g. , #TAUTHOR_TAG , by inserting in loss-separability for normal separability .']","['separ', '', '', '', '', '3).', '', 'Proof.', 'Identical to the standard perceptron proof , e.g. , #TAUTHOR_TAG , by inserting in loss-separability for normal separability .']","['', '', '', '', '', '', '', 'Proof.', 'Identical to the standard perceptron proof , e.g. , #TAUTHOR_TAG , by inserting in loss-separability for normal separability .']",0
"['', '', '', '', '', '', 'Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies #TAUTHOR_TAG and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks like information extraction #AUTHOR_TAG and textual entailment #AUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies #TAUTHOR_TAG and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks like information extraction #AUTHOR_TAG and textual entailment #AUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies #TAUTHOR_TAG and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks like information extraction #AUTHOR_TAG and textual entailment #AUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies #TAUTHOR_TAG and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks like information extraction #AUTHOR_TAG and textual entailment #AUTHOR_TAG .']",4
"['The and of- dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The and of dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The accuracy and of-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering sentiment analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', '', '', '', '']",0
"['One obvious approach to this problem is to employ parser reranking #TAUTHOR_TAG .', 'In such a setting, an auxiliary reranker is added in a pipeline following the parser.', 'The standard setting involves training the base parser and applying it to a development set (this is often done in a cross-ated jack-knife training framework).', 'The reranker can then be trained to optimize for the down or extrinsic', 'the original base']","['One obvious approach to this problem is to employ parser reranking #TAUTHOR_TAG .', 'In such a setting, an auxiliary reranker is added in a pipeline following the parser.', 'The standard setting involves training the base parser and applying it to a development set (this is often done in a cross-validated jack-knife training framework).', 'The reranker can then be trained to optimize for the downstream or extrinsic', 'the original base']","['One obvious approach to this problem is to employ parser reranking #TAUTHOR_TAG .', 'In such a setting, an auxiliary reranker is added in a pipeline following the parser.', 'The standard setting involves training the base parser and applying it to a development set (this is often done in a cross-validated jack-knife training framework).', 'The reranker can then be trained to optimize for the downstream or extr', 'the original base parser.']","['One obvious approach to this problem is to employ parser reranking #TAUTHOR_TAG .', 'In such a setting, an auxiliary reranker is added in a pipeline following the parser.', 'The standard setting involves training the base parser and applying it to a development set (this is often done in a cross-validated jack-knife training framework).', 'The reranker can then be trained to optimize for the downstream or extrinsic objective.', '']",0
"['', '', '', '', '', '', 'Optimizing for dependency length is particularly important as parsers tend to do worse on longer dependencies (Mc #AUTHOR_TAG and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks like information extraction #AUTHOR_TAG and textual entailment #TAUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency length is particularly important as parsers tend to do worse on longer dependencies (Mc #AUTHOR_TAG and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks like information extraction #AUTHOR_TAG and textual entailment #TAUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies (Mc #AUTHOR_TAG and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks like information extraction #AUTHOR_TAG and textual entailment #TAUTHOR_TAG .']","['', '', '', '', '', '', 'Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies (Mc #AUTHOR_TAG and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks like information extraction #AUTHOR_TAG and textual entailment #TAUTHOR_TAG .']",0
"['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation ( Mann and Mc #AUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #TAUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation ( Mann and Mc #AUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #TAUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation ( Mann and Mc #AUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #TAUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation ( Mann and Mc #AUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #TAUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']",1
"['An implementation of the transition-based dependency parsing framework #TAUTHOR_TAG using an arc-eager transition strategy and are trained using the perceptron algorithm as in #AUTHOR_TAG with a beam size of 8 .', 'Beams with varying sizes can be used to produce k-best lists.', '', '']","['An implementation of the transition-based dependency parsing framework #TAUTHOR_TAG using an arc-eager transition strategy and are trained using the perceptron algorithm as in #AUTHOR_TAG with a beam size of 8 .', 'Beams with varying sizes can be used to produce k-best lists.', '', '']","['An implementation of the transition-based dependency parsing framework #TAUTHOR_TAG using an arc-eager transition strategy and are trained using the perceptron algorithm as in #AUTHOR_TAG with a beam size of 8 .', 'Beams with varying sizes can be used to produce k-best lists.', '', '']","['An implementation of the transition-based dependency parsing framework #TAUTHOR_TAG using an arc-eager transition strategy and are trained using the perceptron algorithm as in #AUTHOR_TAG with a beam size of 8 .', 'Beams with varying sizes can be used to produce k-best lists.', '', '']",5
"['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation #TAUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #AUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the to framework draw connections to it.', 'In these the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation #TAUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #AUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the to framework draw connections to it', 'In these the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation #TAUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #AUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the to framework we draw connections to it', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']","['There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.', 'This includes work on generalized expectation #TAUTHOR_TAG , posterior regularization #AUTHOR_TAG and constraint driven learning #AUTHOR_TAG .', 'The work of #AUTHOR_TAG on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5.', 'In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.', '', '']",0
"['next present a set of scoring functions can be usedanker loss, resulting in augmented-loss for each one.', '', 'one', 'For some experiments we also measure the standard intrinsic parser metrics unlabeled attachment score ( UAS ) and labeled attachment score ( LAS ) #TAUTHOR_TAG .']","['next present a set of scoring functions can be used reranker loss framework, resulting in augmented-loss for each one.', '', 'one', 'For some experiments we also measure the standard intrinsic parser metrics unlabeled attachment score ( UAS ) and labeled attachment score ( LAS ) #TAUTHOR_TAG .']","['we present a set of scoring functions can be used the inline reranker loss framework, resulting in a new augmented-loss for each one.', '', '', 'For some experiments we also measure the standard intrinsic parser metrics unlabeled attachment score ( UAS ) and labeled attachment score ( LAS ) #TAUTHOR_TAG .']","['In the next section, we present a set of scoring functions that can be used in the inline reranker loss framework, resulting in a new augmented-loss for each one.', '', '', 'For some experiments we also measure the standard intrinsic parser metrics unlabeled attachment score ( UAS ) and labeled attachment score ( LAS ) #TAUTHOR_TAG .']",5
"['The and of- dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The and of dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The accuracy and of-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This on question answering sentiment analysis MT reordering , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', 'There', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #AUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks.', 'In most cases , the accuracy of parsers degrades when run on out-of-domain data #TAUTHOR_TAG .', 'But these accuracies are measured with respect to gold-standard out-of-domain parse trees.', '', '', '', '']",0
"['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #TAUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #TAUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #TAUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']","['The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.', 'This includes work on question answering #TAUTHOR_TAG , sentiment analysis #AUTHOR_TAG , MT reordering #AUTHOR_TAG , and many other tasks .', '', '', '', '', '', '']",0
['criteria and data used in our experiments are based on the work of #TAUTHOR_TAG .'],['criteria and data used in our experiments are based on the work of #TAUTHOR_TAG .'],['criteria and data used in our experiments are based on the work of #TAUTHOR_TAG .'],['criteria and data used in our experiments are based on the work of #TAUTHOR_TAG .'],5
"['In this paper , inspired by KNN-SVM #TAUTHOR_TAG , we propose a local training method , which trains sentence-wise weights instead of a single weight , to address the above two problems .', 'with online', '', '', '']","['In this paper , inspired by KNN-SVM #TAUTHOR_TAG , we propose a local training method , which trains sentence-wise weights instead of a single weight , to address the above two problems .', 'with online', '', '', '']","['In this paper , inspired by KNN-SVM #TAUTHOR_TAG , we propose a local training method , which trains sentence-wise weights instead of a single weight , to address the above two problems .', 'with', '', '', '']","['In this paper , inspired by KNN-SVM #TAUTHOR_TAG , we propose a local training method , which trains sentence-wise weights instead of a single weight , to address the above two problems .', '', '', '', '']",4
"['Due to the existence of L2 norm in objective function (5), the optimization algorithm MERT can not be applied for this question since the exact line search routine does not hold here.', 'Motivated by #TAUTHOR_TAG , 2003; #AUTHOR_TAG , we approximate the Error in (5) by the expected loss, and then derive the following function: x 2IIW−WbII2+ A � j=1 Systems NIST0 N05 N .39 6.3 25.34 19.07 Moses hier 33.68 26.94 26.28 18.65-Hiero 31.24 27.07 26.32 9. Table', '']","['Due to the existence of L2 norm in objective function (5), the optimization algorithm MERT can not be applied for this question since the exact line search routine does not hold here.', 'Motivated by #TAUTHOR_TAG , 2003; #AUTHOR_TAG , we approximate the Error in (5) by the expected loss, and then derive the following function: x 2IIW−WbII2+ A � j=1 Systems NIST02 NIST05 30.39 26.31 25.34 19.07 Moses hier 33.68 26.94 26.28 18.65 In-Hiero 31.24 27.07 26.32 19.03 Table', '']","['Due to the existence of L2 norm in objective function (5), the optimization algorithm MERT can not be applied for this question since the exact line search routine does not hold here.', 'Motivated by #TAUTHOR_TAG , 2003; #AUTHOR_TAG , we approximate the Error in (5) by the expected loss, and then derive the following function: x 2IIW−WbII2+ A � j=1 Systems NIST02 NIST05 NIST06 NIST08 Moses 30.39 26.31 25.34 19.07 Moses hier 33.68 26.94 26.28 18.65 In-Hiero 31.24 27.07 26.32 19.03 Table 1: The performance comparison', '']","['Due to the existence of L2 norm in objective function (5), the optimization algorithm MERT can not be applied for this question since the exact line search routine does not hold here.', '', '']",4
"[' #TAUTHOR_TAG introduced the log-linear model for statistical machine translation ( SMT ) , in which translation is considered as the following optimization problem :']","[' #TAUTHOR_TAG introduced the log-linear model for statistical machine translation ( SMT ) , in which translation is considered as the following optimization problem :']","[' #TAUTHOR_TAG introduced the log-linear model for statistical machine translation ( SMT ) , in which translation is considered as the following optimization problem :']","[' #TAUTHOR_TAG introduced the log-linear model for statistical machine translation ( SMT ) , in which translation is considered as the following optimization problem :']",0
"['Our method resorts to some translation examples , which is similar as example-based translation or translation memory #TAUTHOR_TAG .', 'of using translation examples to construct translation rules for enlarging the decoding, we employed them to discriminatively learn local weights']","['Our method resorts to some translation examples , which is similar as example-based translation or translation memory #TAUTHOR_TAG .', 'of using translation examples to construct translation rules for enlarging the decoding space, we employed them to discriminatively learn local weights.']","['Our method resorts to some translation examples , which is similar as example-based translation or translation memory #TAUTHOR_TAG .', 'of using translation examples to construct translation rules for enlarging the decoding space, we employed them to discriminatively learn local weights.']","['Our method resorts to some translation examples , which is similar as example-based translation or translation memory #TAUTHOR_TAG .', 'Instead of using translation examples to construct translation rules for enlarging the decoding space, we employed them to discriminatively learn local weights.']",1
"['', '', '', 'if we use LSH technique #TAUTHOR_TAG in retrieval process , the local method can be easily scaled to a larger training data .']","['', '', '', 'if we use LSH technique #TAUTHOR_TAG in retrieval process , the local method can be easily scaled to a larger training data .']","['', '', '', 'if we use LSH technique #TAUTHOR_TAG in retrieval process , the local method can be easily scaled to a larger training data .']","['', '', '', 'Actually , if we use LSH technique #TAUTHOR_TAG in retrieval process , the local method can be easily scaled to a larger training data .']",3
"['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it', '.']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it.', 'functions.']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it', '']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', ' #AUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it.', '']",1
"['The local training method #TAUTHOR_TAG is widely employed in computer vision #AUTHOR_TAG .', 'the', '']","['The local training method #TAUTHOR_TAG is widely employed in computer vision #AUTHOR_TAG .', 'the', '']","['The local training method #TAUTHOR_TAG is widely employed in computer vision #AUTHOR_TAG .', 'the', '']","['The local training method #TAUTHOR_TAG is widely employed in computer vision #AUTHOR_TAG .', '', '']",0
"['where f and ( are', 'feature vector a . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set', '', '', '']","['where f and (e are', 'feature vector a . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']","['where f and ( are', 'a feature vector a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']","['', 'h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']",0
"[' #AUTHOR_TAGpus to', 'We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits #AUTHOR_TAG with modified Kneser-Ney smoothing #TAUTHOR_TAG .', '', '', '']","[' #AUTHOR_TAG corpus to', 'We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits #AUTHOR_TAG with modified Kneser-Ney smoothing #TAUTHOR_TAG .', '', '', '']","[' #AUTHOR_TAG to', 'We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits #AUTHOR_TAG with modified Kneser-Ney smoothing #TAUTHOR_TAG .', '', '', '']","['', 'We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits #AUTHOR_TAG with modified Kneser-Ney smoothing #TAUTHOR_TAG .', '', '', '']",5
"[' #AUTHOR_TAGpus', 'We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits #TAUTHOR_TAG with modified Kneser-Ney smoothing #AUTHOR_TAG .', '', '', '']","[' #AUTHOR_TAG corpus', 'We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits #TAUTHOR_TAG with modified Kneser-Ney smoothing #AUTHOR_TAG .', '', '', '']","[' #AUTHOR_TAG', 'We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits #TAUTHOR_TAG with modified Kneser-Ney smoothing #AUTHOR_TAG .', '', '', '']","['', 'We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits #TAUTHOR_TAG with modified Kneser-Ney smoothing #AUTHOR_TAG .', '', '', '']",5
"['where f and ( are', 'feature vector a . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set', '', '', '']","['where f and (e are', 'feature vector a . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']","['where f and ( are', 'a feature vector a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']","['', 'h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']",0
"['Compared with retraining mode, incremental training can improve the training efficiency.', 'In the field of machine learning research , incremental training has been employed in the work #TAUTHOR_TAG , but there is little work for tuning parameters of statistical machine translation .', 'The biggest difficulty lies in that the fea- ture vector of a given training example, i.e. translation example, is unavailable until actually decoding the example, since the derivation is a latent variable.', '']","['Compared with retraining mode, incremental training can improve the training efficiency.', 'In the field of machine learning research , incremental training has been employed in the work #TAUTHOR_TAG , but there is little work for tuning parameters of statistical machine translation .', 'The biggest difficulty lies in that the fea- ture vector of a given training example, i.e. translation example, is unavailable until actually decoding the example, since the derivation is a latent variable.', '']","['Compared with retraining mode, incremental training can improve the training efficiency.', 'In the field of machine learning research , incremental training has been employed in the work #TAUTHOR_TAG , but there is little work for tuning parameters of statistical machine translation .', 'The biggest difficulty lies in that the fea- ture vector of a given training example, i.e. translation example, is unavailable until actually decoding the example, since the derivation is a latent variable.', '']","['Compared with retraining mode, incremental training can improve the training efficiency.', 'In the field of machine learning research , incremental training has been employed in the work #TAUTHOR_TAG , but there is little work for tuning parameters of statistical machine translation .', 'The biggest difficulty lies in that the fea- ture vector of a given training example, i.e. translation example, is unavailable until actually decoding the example, since the derivation is a latent variable.', '']",0
"['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used estimation to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used estimation to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', ' #AUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']",1
"['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used estimation to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used estimation to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', 'used to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']","['Several works have proposed discriminative tech- niques to train log-linear model for SMT.', ' #AUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']",1
"['', '', 'm-', '', 'The significance testing is performed by paired bootstrap re-sampling #TAUTHOR_TAG .']","['', '', '', '', 'The significance testing is performed by paired bootstrap re-sampling #TAUTHOR_TAG .']","['', '', 'm-', '', 'The significance testing is performed by paired bootstrap re-sampling #TAUTHOR_TAG .']","['', '', '', '', 'The significance testing is performed by paired bootstrap re-sampling #TAUTHOR_TAG .']",5
"['(b). The nonlinearly separable classification problem transformed from (a) via tuning as ranking #TAUTHOR_TAG , 2011).', 'Since score of e11 is greater than that of e12, (1, 0) corresponds to a possitive example denoted as ”•”, and (−1, 0) corresponds to a negative example denoted as ”*”.', 'the classification', '']","['(b). The nonlinearly separable classification problem transformed from (a) via tuning as ranking #TAUTHOR_TAG , 2011).', 'Since score of e11 is greater than that of e12, (1, 0) corresponds to a possitive example denoted as ”•”, and (−1, 0) corresponds to a negative example denoted as ”*”.', 'the classification', '']","['(b). The nonlinearly separable classification problem transformed from (a) via tuning as ranking #TAUTHOR_TAG , 2011).', 'Since score of e11 is greater than that of e12, (1, 0) corresponds to a possitive example denoted as ”•”, and (−1, 0) corresponds to a negative example denoted as ”*”.', 'the transformed classification problem', '']","['(b). The nonlinearly separable classification problem transformed from (a) via tuning as ranking #TAUTHOR_TAG , 2011).', 'Since score of e11 is greater than that of e12, (1, 0) corresponds to a possitive example denoted as ”•”, and (−1, 0) corresponds to a negative example denoted as ”*”.', '', '']",0
"['Several works have proposed discriminative techniques to train log-linear model for SMT.', ' #TAUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', 'employed an evaluation metric as a loss function and directly optimized it', '']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', ' #TAUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', 'employed an evaluation metric as a loss function and directly optimized it.', '']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', ' #TAUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', 'employed an evaluation metric as a loss function and directly optimized it', '']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', ' #TAUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', ' #AUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it.', '']",1
"['The metric we consider here is derived from an example-based machine translation.', 'To retrieve translation examples for a test sentence , #TAUTHOR_TAG defined a metric based on the combination of edit distance and TF-IDF ( Manning and Sch Â¨ utze , 1999 ) as follows :']","['The metric we consider here is derived from an example-based machine translation.', 'To retrieve translation examples for a test sentence , #TAUTHOR_TAG defined a metric based on the combination of edit distance and TF-IDF ( Manning and Sch Â¨ utze , 1999 ) as follows :']","['The metric we consider here is derived from an example-based machine translation.', 'To retrieve translation examples for a test sentence , #TAUTHOR_TAG defined a metric based on the combination of edit distance and TF-IDF ( Manning and Sch Â¨ utze , 1999 ) as follows :']","['The metric we consider here is derived from an example-based machine translation.', 'To retrieve translation examples for a test sentence , #TAUTHOR_TAG defined a metric based on the combination of edit distance and TF-IDF ( Manning and Sch Â¨ utze , 1999 ) as follows :']",5
"['where f and ( are', 'feature vector a . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set', '', '', '']","['where f and (e are', 'feature vector a . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']","['where f and ( are', 'a feature vector a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']","['', 'h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #TAUTHOR_TAG , margin #AUTHOR_TAG and ranking #AUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']",0
"['', '', '', '', 'We employ the idea of ultraconservative update #TAUTHOR_TAG to propose two incremental methods for local training in Algorithm 2 as follows .']","['', '', '', '', 'We employ the idea of ultraconservative update #TAUTHOR_TAG to propose two incremental methods for local training in Algorithm 2 as follows .']","['', '', '', '', 'We employ the idea of ultraconservative update #TAUTHOR_TAG to propose two incremental methods for local training in Algorithm 2 as follows .']","['', '', '', '', 'We employ the idea of ultraconservative update #TAUTHOR_TAG to propose two incremental methods for local training in Algorithm 2 as follows .']",5
"['Several works have proposed discriminative techniques to train log-linear model for SMT.', 'used to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '.']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', 'used to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', 'functions.']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', 'used to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', ' #AUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', ' #TAUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it .', '']",1
"['We use an in-house developed hierarchical phrase-based translation #TAUTHOR_TAG as our baseline system , and we denote it as In-Hiero .', 'To obtain satisfactory baseline performance, we tune In-Hiero system for 5 times using MERT, and then se- #AUTHOR_TAG', '', '']","['We use an in-house developed hierarchical phrase-based translation #TAUTHOR_TAG as our baseline system , and we denote it as In-Hiero .', 'To obtain satisfactory baseline performance, we tune In-Hiero system for 5 times using MERT, and then se- #AUTHOR_TAG', '', '']","['We use an in-house developed hierarchical phrase-based translation #TAUTHOR_TAG as our baseline system , and we denote it as In-Hiero .', 'To obtain satisfactory baseline performance, we tune In-Hiero system for 5 times using MERT, and then se- #AUTHOR_TAG .', '', '']","['We use an in-house developed hierarchical phrase-based translation #TAUTHOR_TAG as our baseline system , and we denote it as In-Hiero .', 'To obtain satisfactory baseline performance, we tune In-Hiero system for 5 times using MERT, and then se- #AUTHOR_TAG .', '', '']",5
"['We run GIZA + + #TAUTHOR_TAG on the training corpus in both directions #AUTHOR_TAG to obtain the word alignment for each sentence pair .', '', '', '', '']","['We run GIZA + + #TAUTHOR_TAG on the training corpus in both directions #AUTHOR_TAG to obtain the word alignment for each sentence pair .', '', '', '', '']","['We run GIZA + + #TAUTHOR_TAG on the training corpus in both directions #AUTHOR_TAG to obtain the word alignment for each sentence pair .', '', '', '', '']","['We run GIZA + + #TAUTHOR_TAG on the training corpus in both directions #AUTHOR_TAG to obtain the word alignment for each sentence pair .', '', '', '', '']",5
"['Several works have proposed discriminative techniques to train log-linear model for SMT.', 'used estimation weights for MT.', ' #AUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it.', ' #TAUTHOR_TAG proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions .']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', 'used estimation weights for MT.', ' #AUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it.', ' #TAUTHOR_TAG proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions .']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', 'used weights for MT.', ' #AUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it.', ' #TAUTHOR_TAG proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions .']","['Several works have proposed discriminative techniques to train log-linear model for SMT.', ' #AUTHOR_TAG used maximum likelihood estimation to learn weights for MT.', ' #AUTHOR_TAG employed an evaluation metric as a loss function and directly optimized it.', ' #TAUTHOR_TAG proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions .']",1
"['where f and ( are', 'feature vector . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #AUTHOR_TAG , margin #AUTHOR_TAG and ranking #TAUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a set', '', '', '']","['where f and (e are', 'feature vector . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #AUTHOR_TAG , margin #AUTHOR_TAG and ranking #TAUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a set.', '', '', '']","['where f and ( are', 'a feature vector a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #AUTHOR_TAG , margin #AUTHOR_TAG and ranking #TAUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']","['', 'h is a feature vector which is scaled by a weight W . Parameter estimation is one of the most important components in SMT, and various training methods have been proposed to tune W .', 'Some methods are based on likelihood #AUTHOR_TAG , error rate #AUTHOR_TAG , margin #AUTHOR_TAG and ranking #TAUTHOR_TAG , and among which minimum error rate training ( MERT ) #AUTHOR_TAG is the most popular one .', 'All these training methods follow the same pipeline: they train only a single weight on a given development set, and then use it to translate all the sentences in a test set.', '', '', '']",0
"[', our result shows that the graphbased approaches perform quite competitively under the condition of perfect knowledge and perception.', 'Although evaluated on different data sets , this result is consistent with results from previous work #TAUTHOR_TAG .', '']","['Furthermore, our result shows that the graphbased approaches perform quite competitively under the condition of perfect knowledge and perception.', 'Although evaluated on different data sets , this result is consistent with results from previous work #TAUTHOR_TAG .', '']","[', our result shows that the graphbased approaches perform quite competitively under the condition of perfect knowledge and perception.', 'Although evaluated on different data sets , this result is consistent with results from previous work #TAUTHOR_TAG .', '']","['Furthermore, our result shows that the graphbased approaches perform quite competitively under the condition of perfect knowledge and perception.', 'Although evaluated on different data sets , this result is consistent with results from previous work #TAUTHOR_TAG .', '']",1
"['Grounded semantics provides a bridge to connect symbolic labels or words with lower level visual features #AUTHOR_TAG .', 'Previous work has developed various approaches for grounded semantics mainly for the reference resolution task , i.e. , identifying visual objects in the environment given language descriptions #TAUTHOR_TAG .', 'For ax']","['Grounded semantics provides a bridge to connect symbolic labels or words with lower level visual features #AUTHOR_TAG .', 'Previous work has developed various approaches for grounded semantics mainly for the reference resolution task , i.e. , identifying visual objects in the environment given language descriptions #TAUTHOR_TAG .', 'For a']","['Grounded semantics provides a bridge to connect symbolic labels or words with lower level visual features #AUTHOR_TAG .', 'Previous work has developed various approaches for grounded semantics mainly for the reference resolution task , i.e. , identifying visual objects in the environment given language descriptions #TAUTHOR_TAG .', 'For a lexicon']","['Grounded semantics provides a bridge to connect symbolic labels or words with lower level visual features #AUTHOR_TAG .', 'Previous work has developed various approaches for grounded semantics mainly for the reference resolution task , i.e. , identifying visual objects in the environment given language descriptions #TAUTHOR_TAG .', '']",2
"['How this mismatched perceptual basis affects referential communication in situated dialogue was investigated in our previous work #TAUTHOR_TAG .', 'In that work, the main focus is on reference resolution: given referential descriptions from human partners, how to identify referents in the environment even though the robot only has imperfect perception of the environment.', 'Since robots need to collaborate with human partners to a joint perceptual basis, expression generation (REG) an important in situated', '', '']","['How this mismatched perceptual basis affects referential communication in situated dialogue was investigated in our previous work #TAUTHOR_TAG .', 'In that work, the main focus is on reference resolution: given referential descriptions from human partners, how to identify referents in the environment even though the robot only has imperfect perception of the environment.', 'Since robots need to collaborate with human partners to a joint perceptual basis, expression generation (REG) an important in situated', '', '']","['How this mismatched perceptual basis affects referential communication in situated dialogue was investigated in our previous work #TAUTHOR_TAG .', 'In that work, the main focus is on reference resolution: given referential descriptions from human partners, how to identify referents in the environment even though the robot only has imperfect perception of the environment.', 'Since robots need to collaborate with human partners to a joint perceptual basis, referring expression generation (REG) an equally important problem in', '', '']","['How this mismatched perceptual basis affects referential communication in situated dialogue was investigated in our previous work #TAUTHOR_TAG .', 'In that work, the main focus is on reference resolution: given referential descriptions from human partners, how to identify referents in the environment even though the robot only has imperfect perception of the environment.', 'Since robots need to collaborate with human partners to establish a joint perceptual basis, referring expression generation (REG) becomes an equally important problem in situated dialogue.', '', '']",2
"['approaches mult research have by abstracting away raw perceptual information and using high-level representations instead.', '', '', '', 'this topic', 'In a similar vein , #TAUTHOR_TAG showed that a different feature-topic model improved predictions on a fill-in-the-blank task .', '', '']","['approaches research have by abstracting away raw perceptual information and using high-level representations instead.', '', '', '', 'this topic', 'In a similar vein , #TAUTHOR_TAG showed that a different feature-topic model improved predictions on a fill-in-the-blank task .', '', '']","['Many approaches mult research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', '', '', '', 'this work', 'In a similar vein , #TAUTHOR_TAG showed that a different feature-topic model improved predictions on a fill-in-the-blank task .', '', '']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', '', '', '', '', 'In a similar vein , #TAUTHOR_TAG showed that a different feature-topic model improved predictions on a fill-in-the-blank task .', '', '']",0
"['Many approaches to multimodal research have succeeded by abstracting away raw perceptual in- formation and using high-level representations in- stead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'Within the latter cat egory, the two most common representations have been association norms, subjects are givenue words']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual in- formation and using high-level representations in- stead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'Within the latter cat- egory, the two most common representations have been association norms, subjects are given cue words']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual in- formation and using high-level representations in- stead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'Within the latter cat egory, the two most common representations have been association norms, subjects are given words']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual in- formation and using high-level representations in- stead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', '']",0
"['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', 'They use a Bag of Visual Words ( BoVW ) model #TAUTHOR_TAG to create a bimodal vocabulary describing documents .', 'The topic model using the bimodal vocforms a purelyual word association and word prediction', '', '', '', '']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', 'They use a Bag of Visual Words ( BoVW ) model #TAUTHOR_TAG to create a bimodal vocabulary describing documents .', 'The topic model using the bimodal vocabulary a purely textual word association and word prediction.', '', '', '', '']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', 'They use a Bag of Visual Words ( BoVW ) model #TAUTHOR_TAG to create a bimodal vocabulary describing documents .', 'The topic model using the bimodal vocforms a purelyual word association and', '', '', '', '']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', 'They use a Bag of Visual Words ( BoVW ) model #TAUTHOR_TAG to create a bimodal vocabulary describing documents .', 'The topic model using the bimodal vocabulary outperforms a purely textual based model in word association and word similarity prediction.', '', '', '', '']",0
"['computer techniques have improved over the, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b', '', '', '', '', ' #AUTHOR_TAG show that visual attribute classifiers , which have been immensely successful in object recognition #TAUTHOR_TAG , subst for feature', 'Other work on modeling the meanings of verbs using video recognition has begun promise #AUTHOR_TAG']","['computer techniques have improved over the decade, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b).', '', '', '', '', ' #AUTHOR_TAG show that visual attribute classifiers , which have been immensely successful in object recognition #TAUTHOR_TAG , substitutes for feature', 'Other work on modeling the meanings of verbs using video recognition has begun promise #AUTHOR_TAG']","['computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b).', '', '', '', '', ' #AUTHOR_TAG show that visual attribute classifiers , which have been immensely successful in object recognition #TAUTHOR_TAG , for feature', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #AUTHOR_TAG .']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', '', '', '', '', 'More recently , #AUTHOR_TAG show that visual attribute classifiers , which have been immensely successful in object recognition #TAUTHOR_TAG , act as excellent substitutes for feature', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #AUTHOR_TAG .']",0
"['The language grounding', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #TAUTHOR_TAG .']","['The language grounding', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #TAUTHOR_TAG .']","['The language grounding problem', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #TAUTHOR_TAG .']","['', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #TAUTHOR_TAG .']",0
"['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'these approaches have differed in model definition enhance']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'these approaches have differed in model definition, enhance']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'these approaches have differed in model definition enhance']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', '']",0
"['That is, we simply take the original mLDA model of #TAUTHOR_TAG (2009) and generalize it in the same way they generalize LDA.', 'task become more observed task remains roughly difficulty tuple conditionally independent']","['That is, we simply take the original mLDA model of #TAUTHOR_TAG (2009) and generalize it in the same way they generalize LDA.', 'task become more observed task remains roughly difficulty, tuple conditionally independent']","['That is, we simply take the original mLDA model of #TAUTHOR_TAG (2009) and generalize it in the same way they generalize LDA.', 'should become more the task remains roughly a tuple are conditionally independent']","['That is, we simply take the original mLDA model of #TAUTHOR_TAG (2009) and generalize it in the same way they generalize LDA.', '']",2
"['The language grounding problem has come in many different flavors with just as many different approaches.', 'Some approaches apply semantic parsing , where words and sentences are mapped to logical structure meaning #TAUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some tasks']","['The language grounding problem has come in many different flavors with just as many different approaches.', 'Some approaches apply semantic parsing , where words and sentences are mapped to logical structure meaning #TAUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some tasks']","['The language grounding problem has come in many different flavors with just as many different approaches.', 'Some approaches apply semantic parsing , where words and sentences are mapped to logical structure meaning #TAUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts tasks']","['The language grounding problem has come in many different flavors with just as many different approaches.', 'Some approaches apply semantic parsing , where words and sentences are mapped to logical structure meaning #TAUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', '']",0
"[' #TAUTHOR_TAG extend LDA to allow for the inference of document and topic distributions in a multimodal corpus .', 'their, a document consists of a set of (word, feature) pairs and documents stilled mi', '', 'The process is amended to']","[' #TAUTHOR_TAG extend LDA to allow for the inference of document and topic distributions in a multimodal corpus .', 'their model, a document consists of a set of (word, feature) pairs, and documents still modeled mixtures', '', 'The process is amended to']","[' #TAUTHOR_TAG extend LDA to allow for the inference of document and topic distributions in a multimodal corpus .', 'their, a document consists of a set of (word, feature) pairs and documents are stilled mi', '', 'The generative process is amended to']","[' #TAUTHOR_TAG extend LDA to allow for the inference of document and topic distributions in a multimodal corpus .', '', '', '']",0
"['', '', '', 's', 'The keypoints are clustered into 5,000 visual codewords ( centroids ) using k-means clustering #TAUTHOR_TAG , and images are then quantized over the 5,000 codewords .', '', '']","['', '', '', '', 'The keypoints are clustered into 5,000 visual codewords ( centroids ) using k-means clustering #TAUTHOR_TAG , and images are then quantized over the 5,000 codewords .', '', '']","['', '', '', '', 'The keypoints are clustered into 5,000 visual codewords ( centroids ) using k-means clustering #TAUTHOR_TAG , and images are then quantized over the 5,000 codewords .', '', '']","['', '', '', '', 'The keypoints are clustered into 5,000 visual codewords ( centroids ) using k-means clustering #TAUTHOR_TAG , and images are then quantized over the 5,000 codewords .', '', '']",5
"['Table 1 shows our results for each of our selected models with our compositionality evaluation.', 'The 2D models employing feature norms and association norms do significantly better than the text-only model (two-tailed t-test).', 'This result is consistent with other works using this model with these features #TAUTHOR_TAG .']","['Table 1 shows our results for each of our selected models with our compositionality evaluation.', 'The 2D models employing feature norms and association norms do significantly better than the text-only model (two-tailed t-test).', 'This result is consistent with other works using this model with these features #TAUTHOR_TAG .']","['Table 1 shows our results for each of our selected models with our compositionality evaluation.', 'The 2D models employing feature norms and association norms do significantly better than the text-only model (two-tailed t-test).', 'This result is consistent with other works using this model with these features #TAUTHOR_TAG .']","['Table 1 shows our results for each of our selected models with our compositionality evaluation.', 'The 2D models employing feature norms and association norms do significantly better than the text-only model (two-tailed t-test).', 'This result is consistent with other works using this model with these features #TAUTHOR_TAG .']",1
"['computer techniques have improved the, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b', '', '', '', '', 'features', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #TAUTHOR_TAG .']","['computer techniques have improved the decade, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b).', '', '', '', '', 'feature', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #TAUTHOR_TAG .']","['computer vision techniques have improved the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b).', '', '', '', '', 'feature norms.', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #TAUTHOR_TAG .']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', '', '', '', '', '', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #TAUTHOR_TAG .']",0
"['Many approaches to multimal research have by abstracting away raw perceptual in- formation and-level representations in- stead.', 'Some works abstract perception via the us- age of symbolic logic representations #AUTHOR_TAG , while others choose to employ concepts elicited from psych- guistic and cognition studies.', 'Within the latter category, the two most common representations have been association norms, where subjects are given a cue word and name the first ( or several ) associated words that come to mind ( e.g. , #AUTHOR_TAG ) , and feature norms , where subjects are given a cue word and asked to describe typical properties of the cue concept ( e.g. , #TAUTHOR_TAG .']","['Many approaches to multimodal research have by abstracting away raw perceptual in- formation and high-level representations in- stead.', 'Some works abstract perception via the us- age of symbolic logic representations #AUTHOR_TAG , while others choose to employ concepts elicited from psycholin- guistic and cognition studies.', 'Within the latter category, the two most common representations have been association norms, where subjects are given a cue word and name the first ( or several ) associated words that come to mind ( e.g. , #AUTHOR_TAG ) , and feature norms , where subjects are given a cue word and asked to describe typical properties of the cue concept ( e.g. , #TAUTHOR_TAG .']","['Many approaches to multimal research have succeeded by abstracting away raw perceptual in- formation and using high-level representations in- stead.', 'Some works abstract perception via the us- age of symbolic logic representations #AUTHOR_TAG , while others choose to employ concepts elicited from psych- guistic and cognition studies.', 'Within the latter category, the two most common representations have been association norms, where subjects are given a cue word and name the first ( or several ) associated words that come to mind ( e.g. , #AUTHOR_TAG ) , and feature norms , where subjects are given a cue word and asked to describe typical properties of the cue concept ( e.g. , #TAUTHOR_TAG .']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual in- formation and using high-level representations in- stead.', 'Some works abstract perception via the us- age of symbolic logic representations #AUTHOR_TAG , while others choose to employ concepts elicited from psycholin- guistic and cognition studies.', 'Within the latter category, the two most common representations have been association norms, where subjects are given a cue word and name the first ( or several ) associated words that come to mind ( e.g. , #AUTHOR_TAG ) , and feature norms , where subjects are given a cue word and asked to describe typical properties of the cue concept ( e.g. , #TAUTHOR_TAG .']",0
"['The language grounding problem has come in many different flavors with just as many different ap- proaches.', 'Some approaches apply semantic parsing, where words and sentences are mapped to logical structure meaning #AUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions , such as interpreting navigation directions #TAUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts tack tasks suchaption']","['The language grounding problem has come in many different flavors with just as many different ap- proaches.', 'Some approaches apply semantic parsing, where words and sentences are mapped to logical structure meaning #AUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions , such as interpreting navigation directions #TAUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts tackled tasks such caption']","['The language grounding problem has come in many different flavors with just as many different ap- proaches.', 'Some approaches apply semantic parsing, where words and sentences are mapped to logical structure meaning #AUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions , such as interpreting navigation directions #TAUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts tasks such']","['The language grounding problem has come in many different flavors with just as many different ap- proaches.', 'Some approaches apply semantic parsing, where words and sentences are mapped to logical structure meaning #AUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions , such as interpreting navigation directions #TAUTHOR_TAG or robot commands #AUTHOR_TAG .', '']",0
"['The language', '', 'automatic m language instructions to execut, such as or', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #TAUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['The language', '', 'automatic mappings language instructions to executable actions, such as or', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #TAUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['', '', 'automatic mappings natural language instructions to execut, such as or', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #TAUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['', '', '', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #TAUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']",0
"['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #TAUTHOR_TAG .', 'Although these approaches have differed in model definition, the general goal in this line of research has been to enhance word meaning with perceptual information in to most criticing words words #AUTHOR_TAG']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #TAUTHOR_TAG .', 'Although these approaches have differed in model definition, the general goal in this line of research has been to enhance word meaning with perceptual information in to most criticisms words words"" #AUTHOR_TAG']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #TAUTHOR_TAG .', 'Although these approaches have differed in model definition, the general goal in this line of research has been to enhance word meaning with perceptual information in to most words']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #TAUTHOR_TAG .', '']",0
"['evaluate our algorithms we first need to generate multimodal corpora for each of our non- textual modalities.', ""We use the same method as #TAUTHOR_TAG for generating our multimodal corpora : for each word token in the text corpus , a feature is selected stochastically from the word 's feature distribution , creating a word-feature pair ."", 'Words grounded features are all given the placeholder feature, word.', '', '']","['evaluate our algorithms, we first need to generate multimodal corpora for each of our non- textual modalities.', ""We use the same method as #TAUTHOR_TAG for generating our multimodal corpora : for each word token in the text corpus , a feature is selected stochastically from the word 's feature distribution , creating a word-feature pair ."", 'Words grounded features are all given the placeholder feature, word-', '', '']","['evaluate our algorithms we first need to generate multimodal corpora for each of our non- textual modalities.', ""We use the same method as #TAUTHOR_TAG for generating our multimodal corpora : for each word token in the text corpus , a feature is selected stochastically from the word 's feature distribution , creating a word-feature pair ."", 'Words grounded features are all given the same placeholder feature,', '', '']","['In order to evaluate our algorithms, we first need to generate multimodal corpora for each of our non- textual modalities.', ""We use the same method as #TAUTHOR_TAG for generating our multimodal corpora : for each word token in the text corpus , a feature is selected stochastically from the word 's feature distribution , creating a word-feature pair ."", 'Words without grounded features are all given the same placeholder feature, also resulting in a word- feature pair.5', '', '']",5
"['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']",0
"['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #TAUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #AUTHOR_TAG .', 'It has also been to be useful', '', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #TAUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #AUTHOR_TAG .', 'It has also been to be useful', '', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #TAUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #AUTHOR_TAG .', 'It has also been shown to be useful', '', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #TAUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #AUTHOR_TAG .', '', '', '', '']",5
"['', '', 'object words which share associ are related through settings and objects that with them.', ""This seems to provide additional evidence of #TAUTHOR_TAG b ) 's suggestion that something like a distributional hypothesis of images is plausible .""]","['', '', 'words which share associates are related through settings and objects that with them.', ""This seems to provide additional evidence of #TAUTHOR_TAG b ) 's suggestion that something like a distributional hypothesis of images is plausible .""]","['', '', 'object words which share associates are related through common settings and objects that with them.', ""This seems to provide additional evidence of #TAUTHOR_TAG b ) 's suggestion that something like a distributional hypothesis of images is plausible .""]","['', '', '', ""This seems to provide additional evidence of #TAUTHOR_TAG b ) 's suggestion that something like a distributional hypothesis of images is plausible .""]",1
"['compute G', '', '', 'It is frequently used in tasks like scene identification , and #TAUTHOR_TAG shows that distance in GIST space correlates well with semantic distance in WordNet .', 'G, each textual word is represented as theroid GIST vector of all its images, forming the GIST modality.']","['compute GIST', '', '', 'It is frequently used in tasks like scene identification , and #TAUTHOR_TAG shows that distance in GIST space correlates well with semantic distance in WordNet .', 'GIST vectors, each textual word is represented as the centroid GIST vector of all its images, forming the GIST modality.']","['compute G', '', '', 'It is frequently used in tasks like scene identification , and #TAUTHOR_TAG shows that distance in GIST space correlates well with semantic distance in WordNet .', ', each textual word is represented as the centroid GIST vector of all its images, forming the GIST modality.']","['', '', '', 'It is frequently used in tasks like scene identification , and #TAUTHOR_TAG shows that distance in GIST space correlates well with semantic distance in WordNet .', 'After computing the GIST vectors, each textual word is represented as the centroid GIST vector of all its images, forming the GIST modality.']",4
"['As computer vision techniques have improved over the decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', 'They a WW model #AUTHOR_TAG to create a bimodal vocabulary describing documents', 'The topic using the bodal vocabulary outperforms a purely textual model in word association and wordity prediction', ' #TAUTHOR_TAG a ) show how a BoVW model may be easily combined with a distributional vector space model of language using only vector concatenation .', '', '', '']","['As computer vision techniques have improved over the decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', 'They a Words model #AUTHOR_TAG to create a bimodal vocabulary describing documents.', 'The topic using the bimodal vocabulary outperforms a purely textual model in word association and word similarity prediction.', ' #TAUTHOR_TAG a ) show how a BoVW model may be easily combined with a distributional vector space model of language using only vector concatenation .', '', '', '']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', 'They use a BagW) model #AUTHOR_TAG to create a bimodal vocabulary describing documents.', 'The topic model using the bimodal vocabulary outperforms a purely textual model in word association and word similarity prediction.', ' #TAUTHOR_TAG a ) show how a BoVW model may be easily combined with a distributional vector space model of language using only vector concatenation .', '', '', '']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', 'They use a Bag of Visual Words (BoVW) model #AUTHOR_TAG to create a bimodal vocabulary describing documents.', 'The topic model using the bimodal vocabulary outperforms a purely textual based model in word association and word similarity prediction.', ' #TAUTHOR_TAG a ) show how a BoVW model may be easily combined with a distributional vector space model of language using only vector concatenation .', '', '', '']",0
"['The languageing', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG', 'Some efforts have tackled tasks such as automatic image caption generation #TAUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['The language grounding', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG', 'Some efforts have tackled tasks such as automatic image caption generation #TAUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['The language grounding problem', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation #TAUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation #TAUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']",0
"['For our Text modality , we use deWaC , a large German web corpus created by the WaCKy group #TAUTHOR_TAG containing approximately 1.7 B word tokens .', 'We filtered the corpus by: removing words with unprintable characters or encoding troubles; removing all stopwords; removing word types with a total frequency of less than 500; and removing documents with a length than 100.', 'The resulting corpus has 138883 documents consisting758 word types and 466M word tokens.']","['For our Text modality , we use deWaC , a large German web corpus created by the WaCKy group #TAUTHOR_TAG containing approximately 1.7 B word tokens .', 'We filtered the corpus by: removing words with unprintable characters or encoding troubles; removing all stopwords; removing word types with a total frequency of less than 500; and removing documents with a length than 100.', 'The resulting corpus has 1,038,883 documents consisting word types and 466M word tokens.']","['For our Text modality , we use deWaC , a large German web corpus created by the WaCKy group #TAUTHOR_TAG containing approximately 1.7 B word tokens .', 'We filtered the corpus by: removing words with unprintable characters or encoding troubles; removing all stopwords; removing word types with a total frequency of less than 500; and removing documents with a length than 100.', 'The resulting corpus has 138883 documents consisting758 word types and 466M word tokens.']","['For our Text modality , we use deWaC , a large German web corpus created by the WaCKy group #TAUTHOR_TAG containing approximately 1.7 B word tokens .', 'We filtered the corpus by: removing words with unprintable characters or encoding troubles; removing all stopwords; removing word types with a total frequency of less than 500; and removing documents with a length shorter than 100.', 'The resulting corpus has 1,038,883 documents consisting of 75,678 word types and 466M word tokens.']",5
"['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #AUTHOR_TAG and #AUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #TAUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #AUTHOR_TAG and #AUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #TAUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #AUTHOR_TAG and #AUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #TAUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #AUTHOR_TAG and #AUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #TAUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']",0
"['approaches mult research have by abstracting away raw perceptual information and using high-level representations instead', '', '', '', '', 'blank', ' #TAUTHOR_TAG take an entirely different approach by showing that one can successfully infer held out feature norms from weighted mixtures based on textual similarity .', '']","['approaches research have by abstracting away raw perceptual information and using high-level representations instead.', '', '', '', '', '', ' #TAUTHOR_TAG take an entirely different approach by showing that one can successfully infer held out feature norms from weighted mixtures based on textual similarity .', '']","['Many approaches mult research have succeeded by abstracting away raw perceptual information and using high-level representations instead', '', '', '', '', '', ' #TAUTHOR_TAG take an entirely different approach by showing that one can successfully infer held out feature norms from weighted mixtures based on textual similarity .', '']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', '', '', '', '', '', ' #TAUTHOR_TAG take an entirely different approach by showing that one can successfully infer held out feature norms from weighted mixtures based on textual similarity .', '']",0
"['as this', 'Following #TAUTHOR_TAG , we measure association norm prediction as an average of percentile ranks .', 'For all possible of words in our voc compute negative symmetric', '', '']","['as this', 'Following #TAUTHOR_TAG , we measure association norm prediction as an average of percentile ranks .', 'For all possible of words in our compute negative symmetric', '', '']","['as this evaluation', 'Following #TAUTHOR_TAG , we measure association norm prediction as an average of percentile ranks .', 'For all possible pairs of words in our voc we compute', '', '']","['', 'Following #TAUTHOR_TAG , we measure association norm prediction as an average of percentile ranks .', '', '', '']",5
"['In this paper , we evaluated the role of low-level image features , SURF and GIST , for their compatibility with the multimodal Latent Dirichlet Allocation model of #TAUTHOR_TAG .', 'We found both fea- ture sets were directly compatible with multimodal LDA and provided significant gains in to predict association norms over traditional text-only L.', 'UR']","['In this paper , we evaluated the role of low-level image features , SURF and GIST , for their compatibility with the multimodal Latent Dirichlet Allocation model of #TAUTHOR_TAG .', 'We found both fea- ture sets were directly compatible with multimodal LDA and provided significant gains in to predict association norms over traditional text-only LDA.', '']","['In this paper , we evaluated the role of low-level image features , SURF and GIST , for their compatibility with the multimodal Latent Dirichlet Allocation model of #TAUTHOR_TAG .', 'We found both fea- ture sets were directly compatible with multimodal LDA and provided significant gains in to predict association norms over traditional text-only LDA.', 'UR']","['In this paper , we evaluated the role of low-level image features , SURF and GIST , for their compatibility with the multimodal Latent Dirichlet Allocation model of #TAUTHOR_TAG .', 'We found both fea- ture sets were directly compatible with multimodal LDA and provided significant gains in their ability to predict association norms over traditional text-only LDA.', '']",5
"['We also compute GIST vectors #TAUTHOR_TAG for every image using LearGIST #AUTHOR_TAG .', 'Unlike SURF descriptors, GIST produces a single vector representation for an image', '', 'It is frequently used #AUTHOR_TAG', 'ual word is represented as the GIST all its, forming the GIST modality.']","['We also compute GIST vectors #TAUTHOR_TAG for every image using LearGIST #AUTHOR_TAG .', 'Unlike SURF descriptors, GIST produces a single vector representation for an image.', '', 'It is frequently used #AUTHOR_TAG', 'textual word is represented as the GIST all its images, forming the GIST modality.']","['We also compute GIST vectors #TAUTHOR_TAG for every image using LearGIST #AUTHOR_TAG .', 'Unlike SURF descriptors, GIST produces a single vector representation for an image.', '', 'It is frequently used #AUTHOR_TAG shows', 'each textual word is represented as the centroid GIST vector all its, forming the GIST modality.']","['We also compute GIST vectors #TAUTHOR_TAG for every image using LearGIST #AUTHOR_TAG .', 'Unlike SURF descriptors, GIST produces a single vector representation for an image.', '', '', 'After computing the GIST vectors, each textual word is represented as the centroid GIST vector of all its images, forming the GIST modality.']",5
"['The language grounding', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #TAUTHOR_TAG .']","['The language grounding', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #TAUTHOR_TAG .']","['The language grounding problem', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #TAUTHOR_TAG .']","['', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #AUTHOR_TAG , or automatic location identification of Twitter users #TAUTHOR_TAG .']",0
"['ingual information andlevel representations instead', 'itedition', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) associated words that come to mind (e.g., #AUTHOR_TAG ), and feature norms, where subjects are given a cue word and asked to describe typical properties of the cue concept (e.g., Mc #AUTHOR_TAG ).', ' #TAUTHOR_TAG helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis #AUTHOR_TAG in the prediction of association norms .', '', '', '', '']","['abstracting information and representations instead.', 'cognition', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) associated words that come to mind (e.g., #AUTHOR_TAG ), and feature norms, where subjects are given a cue word and asked to describe typical properties of the cue concept (e.g., Mc #AUTHOR_TAG ).', ' #TAUTHOR_TAG helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis #AUTHOR_TAG in the prediction of association norms .', '', '', '', '']","['and instead', 'ited', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) associated words that come to mind (e.g., #AUTHOR_TAG ), and feature norms, where subjects are given a cue word and asked to describe typical properties of the cue concept (e.g., Mc #AUTHOR_TAG ).', ' #TAUTHOR_TAG helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis #AUTHOR_TAG in the prediction of association norms .', '', '', '', '']","['', '', 'Within the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) associated words that come to mind (e.g., #AUTHOR_TAG ), and feature norms, where subjects are given a cue word and asked to describe typical properties of the cue concept (e.g., Mc #AUTHOR_TAG ).', ' #TAUTHOR_TAG helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis #AUTHOR_TAG in the prediction of association norms .', '', '', '', '']",0
"['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #AUTHOR_TAG and #TAUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #AUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #AUTHOR_TAG and #TAUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #AUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #AUTHOR_TAG and #TAUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #AUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #AUTHOR_TAG and #TAUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #AUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']",0
"['BilderNetle (""little ImageNet"" in Swabian German) is our new data set of German noun-to-ImageNet synset mappings.', 'ImageNet is a large-scale and widely used image database , built on top of WordNet , which maps words into groups of images , called synsets #TAUTHOR_TAG .', 'Multiple synsets exist for each meaning of a word.', 'example, Im-ageNet contains two different synsets for the word mouse: one contains images of the animal, the other contains images of the computer peripheral', 'This BilderNetle set mappings from German noun']","['BilderNetle (""little ImageNet"" in Swabian German) is our new data set of German noun-to-ImageNet synset mappings.', 'ImageNet is a large-scale and widely used image database , built on top of WordNet , which maps words into groups of images , called synsets #TAUTHOR_TAG .', 'Multiple synsets exist for each meaning of a word.', 'example, Im-ageNet contains two different synsets for the word mouse: one contains images of the animal, the other contains images of the computer peripheral.', 'This BilderNetle set mappings from German noun']","['BilderNetle (""little ImageNet"" in Swabian German) is our new data set of German noun-to-ImageNet synset mappings.', 'ImageNet is a large-scale and widely used image database , built on top of WordNet , which maps words into groups of images , called synsets #TAUTHOR_TAG .', 'Multiple synsets exist for each meaning of a word.', 'example, Im-ageNet contains two different synsets for the word mouse: one contains images of the animal, the other contains images of the computer peripheral.', 'This BilderNetle data set mappings from German noun types']","['BilderNetle (""little ImageNet"" in Swabian German) is our new data set of German noun-to-ImageNet synset mappings.', 'ImageNet is a large-scale and widely used image database , built on top of WordNet , which maps words into groups of images , called synsets #TAUTHOR_TAG .', 'Multiple synsets exist for each meaning of a word.', 'For example, Im-ageNet contains two different synsets for the word mouse: one contains images of the animal, while the other contains images of the computer peripheral.', '']",5
"['', '', '', 'an successfully weighted mi based', ' #TAUTHOR_TAG introduce a new method of multimodal integration based on Canonical Correlation Analysis , and performs a systematic comparison between their CCA-based model and others on association norm prediction , held out feature prediction , and word similarity .']","['', '', '', 'an successfully weighted mixtures based', ' #TAUTHOR_TAG introduce a new method of multimodal integration based on Canonical Correlation Analysis , and performs a systematic comparison between their CCA-based model and others on association norm prediction , held out feature prediction , and word similarity .']","['', '', '', 'successfully weighted mi based', ' #TAUTHOR_TAG introduce a new method of multimodal integration based on Canonical Correlation Analysis , and performs a systematic comparison between their CCA-based model and others on association norm prediction , held out feature prediction , and word similarity .']","['', '', '', '', ' #TAUTHOR_TAG introduce a new method of multimodal integration based on Canonical Correlation Analysis , and performs a systematic comparison between their CCA-based model and others on association norm prediction , held out feature prediction , and word similarity .']",0
"['computer have improved other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is', '', '', '', '', 'recently , #TAUTHOR_TAG show that visual attribute classifiers , which have been immensely successful in object recognition #AUTHOR_TAG , act as excellent substitutes for feature', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #AUTHOR_TAG']","['computer have improved other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is', '', '', '', '', 'recently , #TAUTHOR_TAG show that visual attribute classifiers , which have been immensely successful in object recognition #AUTHOR_TAG , act as excellent substitutes for feature', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #AUTHOR_TAG']","['have improved other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is', '', '', '', '', 'recently , #TAUTHOR_TAG show that visual attribute classifiers , which have been immensely successful in object recognition #AUTHOR_TAG , act as excellent substitutes for feature', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #AUTHOR_TAG .']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', '', '', '', '', 'More recently , #TAUTHOR_TAG show that visual attribute classifiers , which have been immensely successful in object recognition #AUTHOR_TAG , act as excellent substitutes for feature', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #AUTHOR_TAG .']",0
"['Dirich at  atch', '.', 'The high Dirichlet priors are chosen to prevent sparsity in topic distributions , while the other parameters are selected as the best from #TAUTHOR_TAG .']","['Dirichlet at', 'time.', 'The high Dirichlet priors are chosen to prevent sparsity in topic distributions , while the other parameters are selected as the best from #TAUTHOR_TAG .']","['at atch sizes', '.', 'The high Dirichlet priors are chosen to prevent sparsity in topic distributions , while the other parameters are selected as the best from #TAUTHOR_TAG .']","['', '', 'The high Dirichlet priors are chosen to prevent sparsity in topic distributions , while the other parameters are selected as the best from #TAUTHOR_TAG .']",5
"['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning with information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning with information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning withual information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', '']",0
"['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']",0
"['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #AUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #TAUTHOR_TAG .', 'It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers #AUTHOR_TAG .', 'al Lafter', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #AUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #TAUTHOR_TAG .', 'It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers #AUTHOR_TAG .', 'LDA', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #AUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #TAUTHOR_TAG .', 'It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers #AUTHOR_TAG .', 'after', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #AUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #TAUTHOR_TAG .', 'It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers #AUTHOR_TAG .', '', '', '']",0
"['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'these approaches have differed in model definition enhance']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'these approaches have differed in model definition, enhance']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'these approaches have differed in model definition enhance']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', '']",0
"['computer techniques have improved the, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b', '', '', '', '', 'features', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #TAUTHOR_TAG .']","['computer techniques have improved the decade, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b).', '', '', '', '', 'feature', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #TAUTHOR_TAG .']","['computer vision techniques have improved the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to this with topic models is #AUTHOR_TAG b).', '', '', '', '', 'feature norms.', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #TAUTHOR_TAG .']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #AUTHOR_TAG b).', '', '', '', '', '', 'Other work on modeling the meanings of verbs using video recognition has also begun showing great promise #TAUTHOR_TAG .']",0
"['Association Norms ( AN ) is a collection of association norms collected by Schulte im #TAUTHOR_TAG .', 'In association norm experiments, subjects are presented with a cue word and asked to list the first few words that come to mind.', 'With enough subjects and responses, association norms can provide a common and detailed view of the meaning components of cue words.', 'only the data set a total 95 cue-response pairs noun 56 response']","['Association Norms ( AN ) is a collection of association norms collected by Schulte im #TAUTHOR_TAG .', 'In association norm experiments, subjects are presented with a cue word and asked to list the first few words that come to mind.', 'With enough subjects and responses, association norms can provide a common and detailed view of the meaning components of cue words.', 'only the data set a total cue-response pairs nouns 5,716 response']","['Association Norms ( AN ) is a collection of association norms collected by Schulte im #TAUTHOR_TAG .', 'In association norm experiments, subjects are presented with a cue word and asked to list the first few words that come to mind.', 'With enough subjects and responses, association norms can provide a common and detailed view of the meaning components of cue words.', 'the data set a total 954 cue-response pairs2 nouns 56 response types.']","['Association Norms ( AN ) is a collection of association norms collected by Schulte im #TAUTHOR_TAG .', 'In association norm experiments, subjects are presented with a cue word and asked to list the first few words that come to mind.', 'With enough subjects and responses, association norms can provide a common and detailed view of the meaning components of cue words.', '']",5
"['Latent Dirichlet Allocation #TAUTHOR_TAG , or LDA , is an unsupervised Bayesian probabilistic model of text documents .', 'It assumes that all documents are probabilistically generated from a shared set of K common topics, where each topic is a multinomial distribution over the vocabulary (notated as β), and documents are modeled as mixtures of these shared topics (notated as θ).', 'LDA assumes every document in the cor is generated foling process']","['Latent Dirichlet Allocation #TAUTHOR_TAG , or LDA , is an unsupervised Bayesian probabilistic model of text documents .', 'It assumes that all documents are probabilistically generated from a shared set of K common topics, where each topic is a multinomial distribution over the vocabulary (notated as β), and documents are modeled as mixtures of these shared topics (notated as θ).', 'LDA assumes every document in the corpus is generated fol-lowing process:']","['Latent Dirichlet Allocation #TAUTHOR_TAG , or LDA , is an unsupervised Bayesian probabilistic model of text documents .', 'It assumes that all documents are probabilistically generated from a shared set of K common topics, where each topic is a multinomial distribution over the vocabulary (notated as β), and documents are modeled as mixtures of these shared topics (notated as θ).', 'LDA assumes every document in the corpus is generated using']","['Latent Dirichlet Allocation #TAUTHOR_TAG , or LDA , is an unsupervised Bayesian probabilistic model of text documents .', 'It assumes that all documents are probabilistically generated from a shared set of K common topics, where each topic is a multinomial distribution over the vocabulary (notated as β), and documents are modeled as mixtures of these shared topics (notated as θ).', 'LDA assumes every document in the corpus is generated using the fol-lowing generative process:']",0
"['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephen./research/ emnlp13 cue word and name the first (or) words that come mind.,', '', '', '', '', '']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) words that come mind', '', '', '', '', '']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) words that come mind.,', '', '', '', '', '']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'Within the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) associated words that come to mind (e.g., #AUTHOR_TAG ), and feature norms, where subjects are given a cue word and asked to describe typical properties of the cue concept (e.g., Mc #AUTHOR_TAG ).', '', '', '', '', '']",0
"['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #TAUTHOR_TAG and #AUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #AUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #TAUTHOR_TAG and #AUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #AUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #TAUTHOR_TAG and #AUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #AUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']","['The Computer Vision community has also benefited greatly from efforts to unify the two modalities.', 'To name a few examples , #TAUTHOR_TAG and #AUTHOR_TAG show how semantic information from text can be used to improve zero-shot classification ( i.e. , classifying never-before-seen objects ) , and #AUTHOR_TAG show that verb clusters can be used to improve activity recognition in videos .']",0
"['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephen./research/ emnlp13 cue word and name the first (or) words that come mind.,', '', '', '', '', '']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) words that come mind', '', '', '', '', '']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) words that come mind.,', '', '', '', '', '']","['Many approaches to multimodal research have succeeded by abstracting away raw perceptual information and using high-level representations instead.', 'Some works abstract perception via the usage of symbolic logic representations #TAUTHOR_TAG , while others choose to employ concepts elicited from psycholinguistic and cognition studies .', 'Within the latter category, the two most common representations have been association norms, where subjects are given a 1 http://stephenroller.com/research/ emnlp13 cue word and name the first (or several) associated words that come to mind (e.g., #AUTHOR_TAG ), and feature norms, where subjects are given a cue word and asked to describe typical properties of the cue concept (e.g., Mc #AUTHOR_TAG ).', '', '', '', '', '']",0
"['informationlevel representations', '', 'representations', 'Dir Allper Latent Semantic Analysis #AUTHOR_TAG in the prediction of association norms', ' #TAUTHOR_TAG furthered this work by showing that a bimodal topic model , consisting of both text and feature norms , outperformed models using only one modality on the prediction of association norms , word substitution errors , and semantic interference tasks .', '', '', '']","['information representations', '', 'representations', 'Allocation Latent Semantic Analysis #AUTHOR_TAG in the prediction of association norms.', ' #TAUTHOR_TAG furthered this work by showing that a bimodal topic model , consisting of both text and feature norms , outperformed models using only one modality on the prediction of association norms , word substitution errors , and semantic interference tasks .', '', '', '']","['', '', '', 'per Latent Semantic Analysis #AUTHOR_TAG in the prediction of association norms.', ' #TAUTHOR_TAG furthered this work by showing that a bimodal topic model , consisting of both text and feature norms , outperformed models using only one modality on the prediction of association norms , word substitution errors , and semantic interference tasks .', '', '', '']","['', '', '', '', ' #TAUTHOR_TAG furthered this work by showing that a bimodal topic model , consisting of both text and feature norms , outperformed models using only one modality on the prediction of association norms , word substitution errors , and semantic interference tasks .', '', '', '']",0
"['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning with information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning with information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning withual information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', '']",0
"['Our experiments are based on the multimodal extension of Latent Dirich Allocation developed by #AUTHOR_TAG', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #AUTHOR_TAG .', 'It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers #TAUTHOR_TAG .', 'These multimodal LDA models (hereafter, mLDA) have toitatively', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #AUTHOR_TAG', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #AUTHOR_TAG .', 'It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers #TAUTHOR_TAG .', 'These multimodal LDA models (hereafter, mLDA) have to qualitatively', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #AUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #AUTHOR_TAG .', 'It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers #TAUTHOR_TAG .', 'These multimodal LDA models (hereafter, mLDA) to be qualitatively', '', '']","['Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by #AUTHOR_TAG .', 'Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together #AUTHOR_TAG .', 'It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers #TAUTHOR_TAG .', 'These multimodal LDA models (hereafter, mLDA) have been shown to be qualitatively sensible and highly predictive of several psycholinguistic tasks #AUTHOR_TAG .', '', '']",0
"['The languageing', '', 'Others provide automatic mappings of language instructions to execut actions, such as interpre navigation directions #AUTHOR_TAG or #AUTHOR_TAG', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #TAUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['The language grounding', '', 'Others provide automatic mappings of language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or #AUTHOR_TAG', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #TAUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['The language grounding problem', '', 'Others provide automatic mappings of natural language instructions to execut actions, such as interpreting navigation directions #AUTHOR_TAG or #AUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #TAUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']","['', '', 'Others provide automatic mappings of natural language instructions to executable actions, such as interpreting navigation directions #AUTHOR_TAG or robot commands #AUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation #AUTHOR_TAG a ; #AUTHOR_TAG , text illustration #TAUTHOR_TAG , or automatic location identification of Twitter users #AUTHOR_TAG .']",0
"['The language grounding problem has come in many different flavors with as different.', 'Some approaches apply semantic parsing, where words and sentences are mapped to logical structure meaning #AUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions , such as interpreting navigation directions #AUTHOR_TAG or robot commands #TAUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation a;']","['The language grounding problem has come in many different flavors with as different approaches.', 'Some approaches apply semantic parsing, where words and sentences are mapped to logical structure meaning #AUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions , such as interpreting navigation directions #AUTHOR_TAG or robot commands #TAUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation a; #AUTHOR_TAG']","['The language grounding problem has come in many different flavors with as many different approaches.', 'Some approaches apply semantic parsing, where words and sentences are mapped to logical structure meaning #AUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions , such as interpreting navigation directions #AUTHOR_TAG or robot commands #TAUTHOR_TAG .', 'Some efforts have tackled tasks such as automatic image caption generation a;']","['The language grounding problem has come in many different flavors with just as many different approaches.', 'Some approaches apply semantic parsing, where words and sentences are mapped to logical structure meaning #AUTHOR_TAG .', 'Others provide automatic mappings of natural language instructions to executable actions , such as interpreting navigation directions #AUTHOR_TAG or robot commands #TAUTHOR_TAG .', '']",0
"['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #AUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #TAUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #AUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #TAUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #AUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #TAUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #AUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #TAUTHOR_TAG .']",0
"['To solve these scaling issues , we implement Online Variational Bayesian Inference #TAUTHOR_TAG for our models .', 'esianferenceBI one approximates the true posterior', '', '', '', '']","['To solve these scaling issues , we implement Online Variational Bayesian Inference #TAUTHOR_TAG for our models .', 'Bayesian Inference one approximates the true posterior', '', '', '', '']","['To solve these scaling issues , we implement Online Variational Bayesian Inference #TAUTHOR_TAG for our models .', 'BI), one approximates the true posterior using', '', '', '', '']","['To solve these scaling issues , we implement Online Variational Bayesian Inference #TAUTHOR_TAG for our models .', '', '', '', '', '']",5
"['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning with information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning with information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning withual information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', '']",0
"['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning with information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning with information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', 'Although these approaches have differed in model definition, to enhance word meaning withual information in']","['Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information #AUTHOR_TAG b ; #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG .', '']",0
"['Table 1 shows our results for each of our selected models with our compositionality evaluation.', 'The 2D models employing feature norms and association norms do significantly better than the text-only model (two-tailed t-test).', 'This result is consistent with other works using this model with these features #TAUTHOR_TAG .']","['Table 1 shows our results for each of our selected models with our compositionality evaluation.', 'The 2D models employing feature norms and association norms do significantly better than the text-only model (two-tailed t-test).', 'This result is consistent with other works using this model with these features #TAUTHOR_TAG .']","['Table 1 shows our results for each of our selected models with our compositionality evaluation.', 'The 2D models employing feature norms and association norms do significantly better than the text-only model (two-tailed t-test).', 'This result is consistent with other works using this model with these features #TAUTHOR_TAG .']","['Table 1 shows our results for each of our selected models with our compositionality evaluation.', 'The 2D models employing feature norms and association norms do significantly better than the text-only model (two-tailed t-test).', 'This result is consistent with other works using this model with these features #TAUTHOR_TAG .']",1
"['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']",0
"['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']","['The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , #AUTHOR_TAG ) , computing power , improved computer vision models #TAUTHOR_TAG and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm Â¨ uller et al. , 2005 ; #AUTHOR_TAG Aziz- #AUTHOR_TAG .']",0
"['informationlevel representations instead', '', '', ' #AUTHOR_TAG helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis #TAUTHOR_TAG in the prediction of association norms .', '', '', '', '']","['information representations instead.', '', '', ' #AUTHOR_TAG helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis #TAUTHOR_TAG in the prediction of association norms .', '', '', '', '']","['instead', '', '', ' #AUTHOR_TAG helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis #TAUTHOR_TAG in the prediction of association norms .', '', '', '', '']","['', '', '', ' #AUTHOR_TAG helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis #TAUTHOR_TAG in the prediction of association norms .', '', '', '', '']",0
"['To solve these scaling issues , we implement Online Variational Bayesian Inference #TAUTHOR_TAG for our models .', 'esianferenceBI one approximates the true posterior', '', '', '', '']","['To solve these scaling issues , we implement Online Variational Bayesian Inference #TAUTHOR_TAG for our models .', 'Bayesian Inference one approximates the true posterior', '', '', '', '']","['To solve these scaling issues , we implement Online Variational Bayesian Inference #TAUTHOR_TAG for our models .', 'BI), one approximates the true posterior using', '', '', '', '']","['To solve these scaling issues , we implement Online Variational Bayesian Inference #TAUTHOR_TAG for our models .', '', '', '', '', '']",5
"['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #TAUTHOR_TAG b ) .', 'They use a Bag of Visual Words (BoVW) model #AUTHOR_TAG to create a bimodal vocabulary describing documents.', 'The topic model using the bimodal vocabulary outperforms a purely textual based model in word association and word similarity prediction.', '', '', '', '']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #TAUTHOR_TAG b ) .', 'They use a Bag of Visual Words (BoVW) model #AUTHOR_TAG to create a bimodal vocabulary describing documents.', 'The topic model using the bimodal vocabulary outperforms a purely textual based model in word association and word similarity prediction.', '', '', '', '']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #TAUTHOR_TAG b ) .', 'They use a Bag of Visual Words (BoVW) model #AUTHOR_TAG to create a bimodal vocabulary describing documents.', 'The topic model using the bimodal vocabulary outperforms a purely textual based model in word association and word similarity prediction.', '', '', '', '']","['As computer vision techniques have improved over the past decade, other research has begun directly using visual information in place of feature norms.', 'The first work to do this with topic models is #TAUTHOR_TAG b ) .', 'They use a Bag of Visual Words (BoVW) model #AUTHOR_TAG to create a bimodal vocabulary describing documents.', 'The topic model using the bimodal vocabulary outperforms a purely textual based model in word association and word similarity prediction.', '', '', '', '']",0
"['', 'model we rely on was originally developed by #AUTHOR_TAG and is based on a generalization of Latent Dirichlet Allocation.', 'This model has previously been shown to provide excellent performance on multiple tasks , including prediction of association norms , word substitution errors , semantic inferences , and word similarity #TAUTHOR_TAG .', '', '', '', '', '']","['', 'model we rely on was originally developed by #AUTHOR_TAG and is based on a generalization of Latent Dirichlet Allocation.', 'This model has previously been shown to provide excellent performance on multiple tasks , including prediction of association norms , word substitution errors , semantic inferences , and word similarity #TAUTHOR_TAG .', '', '', '', '', '']","['', 'The model we rely on was originally developed by #AUTHOR_TAG and is based on a generalization of Latent Dirichlet Allocation.', 'This model has previously been shown to provide excellent performance on multiple tasks , including prediction of association norms , word substitution errors , semantic inferences , and word similarity #TAUTHOR_TAG .', '', '', '', '', '']","['', 'The model we rely on was originally developed by #AUTHOR_TAG and is based on a generalization of Latent Dirichlet Allocation.', 'This model has previously been shown to provide excellent performance on multiple tasks , including prediction of association norms , word substitution errors , semantic inferences , and word similarity #TAUTHOR_TAG .', '', '', '', '', '']",2
"['a labeling', '', 'choice is motivated by an observation we made previously #TAUTHOR_TAG preced']","['a labeling', '', 'choice is motivated by an observation we made previously #TAUTHOR_TAG preceding']","['', '', 'This choice is motivated by an observation we made previously #TAUTHOR_TAG']","['', '', '']",2
"['Frame-semantic features.', 'While dependencybased features capture the syntactic dependencies, frame-semantic features encode the semantic representation of the concepts in a.', 'Following our previous work on stance classification #TAUTHOR_TAG c ) , we employ three types of features computed based on the frame-semantic parse of each sentence in a post obtained from SEMAFOR #AUTHOR_TAG .', '', '']","['Frame-semantic features.', 'While dependencybased features capture the syntactic dependencies, frame-semantic features encode the semantic representation of the concepts in a sentence.', 'Following our previous work on stance classification #TAUTHOR_TAG c ) , we employ three types of features computed based on the frame-semantic parse of each sentence in a post obtained from SEMAFOR #AUTHOR_TAG .', '', '']","['Frame-semantic features.', 'While dependencybased features capture the syntactic dependencies, frame-semantic features encode the semantic representation of the concepts in a sentence.', 'Following our previous work on stance classification #TAUTHOR_TAG c ) , we employ three types of features computed based on the frame-semantic parse of each sentence in a post obtained from SEMAFOR #AUTHOR_TAG .', '', '']","['Frame-semantic features.', 'While dependencybased features capture the syntactic dependencies, frame-semantic features encode the semantic representation of the concepts in a sentence.', 'Following our previous work on stance classification #TAUTHOR_TAG c ) , we employ three types of features computed based on the frame-semantic parse of each sentence in a post obtained from SEMAFOR #AUTHOR_TAG .', '', '']",2
"['', '', 'Our experimental design with professional bilingual translators follows our previous work #TAUTHOR_TAG a ) comparing scratch translation to post-edit .', '', '']","['', '', 'Our experimental design with professional bilingual translators follows our previous work #TAUTHOR_TAG a ) comparing scratch translation to post-edit .', '', '']","['', '', 'Our experimental design with professional bilingual translators follows our previous work #TAUTHOR_TAG a ) comparing scratch translation to post-edit .', '', '']","['', '', 'Our experimental design with professional bilingual translators follows our previous work #TAUTHOR_TAG a ) comparing scratch translation to post-edit .', '', '']",2
"[""Table1 shows theson's product correlation between each topical feature and candidate's power."", '', 'inencies is significantlyrelated', '', 'This is in line with our previous findings from #TAUTHOR_TAG that candidates with higher power attempt to shift topics less often than others when responding to moderators', '', '']","[""Table 1 shows the Pearson's product correlation between each topical feature and candidate's power."", '', 'in tendencies is significantly correlated', '', 'This is in line with our previous findings from #TAUTHOR_TAG that candidates with higher power attempt to shift topics less often than others when responding to moderators', '', '']","[""Table1 shows the Pearson's product correlation between each topical feature and candidate's power."", '', 'inencies is significantlyrelated', '', 'This is in line with our previous findings from #TAUTHOR_TAG that candidates with higher power attempt to shift topics less often than others when responding to moderators .', '', '']","[""Table 1 shows the Pearson's product correlation between each topical feature and candidate's power."", '', '', '', 'This is in line with our previous findings from #TAUTHOR_TAG that candidates with higher power attempt to shift topics less often than others when responding to moderators .', '', '']",1
"['Bridging orative widely', '', 'We follow our previous work #TAUTHOR_TAG b ) and restrict bridging to non-coreferential cases .', 'We']","['Bridging or associative widely', '', 'We follow our previous work #TAUTHOR_TAG b ) and restrict bridging to non-coreferential cases .', 'We']","['Bridging or', '', 'We follow our previous work #TAUTHOR_TAG b ) and restrict bridging to non-coreferential cases .', 'We']","['', '', 'We follow our previous work #TAUTHOR_TAG b ) and restrict bridging to non-coreferential cases .', '']",2
"['', '', '', 'resources', '', 'We augment mlSystem ruleFeats with more features from our previous work #TAUTHOR_TAG a ; #AUTHOR_TAG b ) on bridging anaphora recognition and antecedent selection .', '']","['', '', '', 'resources', '', 'We augment mlSystem ruleFeats with more features from our previous work #TAUTHOR_TAG a ; #AUTHOR_TAG b ) on bridging anaphora recognition and antecedent selection .', '']","['', '', '', '', '', 'We augment mlSystem ruleFeats with more features from our previous work #TAUTHOR_TAG a ; #AUTHOR_TAG b ) on bridging anaphora recognition and antecedent selection .', '']","['', '', '', '', '', 'mlSystem ruleFeats + atomFeats We augment mlSystem ruleFeats with more features from our previous work #TAUTHOR_TAG a ; #AUTHOR_TAG b ) on bridging anaphora recognition and antecedent selection .', '']",2
"['', '', '', '', '', '', 'in history-based models #TAUTHOR_TAG , the probability estimate for each derivation decision di is conditioned on the previous derivation decisions d1 , ... , d , _ 1 , which is called the derivation history at step i .', 'This allows us to use the chain rule for conditional probabilities to derive the probability of the entire derivation as the multiplication of the probabilities for each of its decisions.']","['', '', '', '', '', '', 'in history-based models #TAUTHOR_TAG , the probability estimate for each derivation decision di is conditioned on the previous derivation decisions d1 , ... , d , _ 1 , which is called the derivation history at step i .', 'This allows us to use the chain rule for conditional probabilities to derive the probability of the entire derivation as the multiplication of the probabilities for each of its decisions.']","['', '', '', '', '', '', 'in history-based models #TAUTHOR_TAG , the probability estimate for each derivation decision di is conditioned on the previous derivation decisions d1 , ... , d , _ 1 , which is called the derivation history at step i .', 'This allows us to use the chain rule for conditional probabilities to derive the probability of the entire derivation as the multiplication of the probabilities for each of its decisions.']","['', '', '', '', '', '', 'in history-based models #TAUTHOR_TAG , the probability estimate for each derivation decision di is conditioned on the previous derivation decisions d1 , ... , d , _ 1 , which is called the derivation history at step i .', 'This allows us to use the chain rule for conditional probabilities to derive the probability of the entire derivation as the multiplication of the probabilities for each of its decisions.']",5
"['The most important step in designing a statistical parser with a-based probability model is choosing a method for estimating the parameters d,_1).', 'The main difficulty with this estimation is that the d 1 ,..., di _ 1 is of unbounded length.', 'Most probability estimation methods require that there be a finite set of features on which the probability is conditioned.', 'The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history #TAUTHOR_TAG .']","['The most important step in designing a statistical parser with a history-based probability model is choosing a method for estimating the parameters d,_1).', 'The main difficulty with this estimation is that the d 1 ,..., di _ 1 is of unbounded length.', 'Most probability estimation methods require that there be a finite set of features on which the probability is conditioned.', 'The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history #TAUTHOR_TAG .']","['The most important step in designing a statistical parser with a history-based probability model is choosing a method for estimating the parameters d,_1).', 'The main difficulty with this estimation is that the history d 1 ,..., di _ 1 is of unbounded length.', 'Most probability estimation methods require that there be a finite set of features on which the probability is conditioned.', 'The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history #TAUTHOR_TAG .']","['The most important step in designing a statistical parser with a history-based probability model is choosing a method for estimating the parameters d,_1).', 'The main difficulty with this estimation is that the history d 1 ,..., di _ 1 is of unbounded length.', 'Most probability estimation methods require that there be a finite set of features on which the probability is conditioned.', 'The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history #TAUTHOR_TAG .']",1
['7A11 our results are computed with the evalb program following the now-standard criteria in #TAUTHOR_TAG .'],['7A11 our results are computed with the evalb program following the now-standard criteria in #TAUTHOR_TAG .'],['7A11 our results are computed with the evalb program following the now-standard criteria in #TAUTHOR_TAG .'],['7A11 our results are computed with the evalb program following the now-standard criteria in #TAUTHOR_TAG .'],5
"['Many statistical parsers #AUTHOR_TAG are based on a history-based probability model #TAUTHOR_TAG , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .', 'A major challenge in this approach is choosing a representation of the parse history from which the probability for the next parser decision can be accurately estimated.', 'a hand-crafted set', '', '', '', '']","['Many statistical parsers #AUTHOR_TAG are based on a history-based probability model #TAUTHOR_TAG , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .', 'A major challenge in this approach is choosing a representation of the parse history from which the probability for the next parser decision can be accurately estimated.', 'a hand-crafted set', '', '', '', '']","['Many statistical parsers #AUTHOR_TAG are based on a history-based probability model #TAUTHOR_TAG , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .', 'A major challenge in this approach is choosing a representation of the parse history from which the probability for the next parser decision can be accurately estimated.', 'a hand-crafted finite set', '', '', '', '']","['Many statistical parsers #AUTHOR_TAG are based on a history-based probability model #TAUTHOR_TAG , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .', 'A major challenge in this approach is choosing a representation of the parse history from which the probability for the next parser decision can be accurately estimated.', '', '', '', '', '']",0
"['The most important step in designing a statistical parser with a-based probability model is choosing a method for estimating the parameters d,_1).', 'The main difficulty with this estimation is that the d 1 ,..., di _ 1 is of unbounded length.', 'Most probability estimation methods require that there be a finite set of features on which the probability is conditioned.', 'The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history #TAUTHOR_TAG .']","['The most important step in designing a statistical parser with a history-based probability model is choosing a method for estimating the parameters d,_1).', 'The main difficulty with this estimation is that the d 1 ,..., di _ 1 is of unbounded length.', 'Most probability estimation methods require that there be a finite set of features on which the probability is conditioned.', 'The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history #TAUTHOR_TAG .']","['The most important step in designing a statistical parser with a history-based probability model is choosing a method for estimating the parameters d,_1).', 'The main difficulty with this estimation is that the history d 1 ,..., di _ 1 is of unbounded length.', 'Most probability estimation methods require that there be a finite set of features on which the probability is conditioned.', 'The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history #TAUTHOR_TAG .']","['The most important step in designing a statistical parser with a history-based probability model is choosing a method for estimating the parameters d,_1).', 'The main difficulty with this estimation is that the history d 1 ,..., di _ 1 is of unbounded length.', 'Most probability estimation methods require that there be a finite set of features on which the probability is conditioned.', 'The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history #TAUTHOR_TAG .']",1
"['about', 'difficulty is the of a on performance, is feas', 'features use', '', '', '', '', '', '', ""re-ranking a parser but the to compute the kernel efficiently and the results are not as good as Collins ' previous work on re-ranking using a finite set of features #TAUTHOR_TAG .""]","['about', 'difficulty is the of a on performance system, is feasible', 'features use', '', '', '', '', '', '', ""re-ranking a parser but the to compute the kernel efficiently and the results are not as good as Collins ' previous work on re-ranking using a finite set of features #TAUTHOR_TAG .""]","['about', 'The difficulty is the choice of on the performance feas', 'features use', '', '', '', '', '', '', ""re-rank a parser but the need to compute the kernel efficiently and the results are not as good as Collins ' previous work on re-ranking using a finite set of features #TAUTHOR_TAG .""]","['', '', '', '', '', '', '', '', '', "" #AUTHOR_TAG define a kernel over parse trees and apply it to re-ranking the output of a parser , but the resulting feature space is restricted by the need to compute the kernel efficiently , and the results are not as good as Collins ' previous work on re-ranking using a finite set of features #TAUTHOR_TAG .""]",0
"['in', ', D) includes nodes which are structally local to top', ""These nodes are the- and 's most recent child (which  any)."", 'For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial #TAUTHOR_TAG , as has conditioning on the left-corner child #AUTHOR_TAG .', 'a step always has access information', '']","['', 'reason, D(top) includes nodes which are structurally local to top,.', ""These nodes are the and 's most recent child (which 1 any)."", 'For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial #TAUTHOR_TAG , as has conditioning on the left-corner child #AUTHOR_TAG .', 'a step always has access information', '']","['', 'D) includes nodes which are structurally local to top', ""These nodes are and 's most recent child (which  any)."", 'For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial #TAUTHOR_TAG , as has conditioning on the left-corner child #AUTHOR_TAG .', 'always has access any information', '']","['', 'For this reason, D(top) includes nodes which are structurally local to top,.', '', 'For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial #TAUTHOR_TAG , as has conditioning on the left-corner child #AUTHOR_TAG .', '', '']",0
"['about', 'a performance', '', '', '', '', '', '', ', but then efficiency becomes a problem.', "" #TAUTHOR_TAG define a kernel over parse trees and apply it to re-ranking the output of a parser , but the resulting feature space is restricted by the need to compute the kernel efficiently , and the results are not as good as Collins ' previous work on re-ranking using a finite set of features #AUTHOR_TAG .""]","['about', 'a performance', '', '', '', '', '', '', 'sets, but then efficiency becomes a problem.', "" #TAUTHOR_TAG define a kernel over parse trees and apply it to re-ranking the output of a parser , but the resulting feature space is restricted by the need to compute the kernel efficiently , and the results are not as good as Collins ' previous work on re-ranking using a finite set of features #AUTHOR_TAG .""]","['about', 'the performance', '', '', '', '', '', '', 'but then efficiency becomes a problem.', "" #TAUTHOR_TAG define a kernel over parse trees and apply it to re-ranking the output of a parser , but the resulting feature space is restricted by the need to compute the kernel efficiently , and the results are not as good as Collins ' previous work on re-ranking using a finite set of features #AUTHOR_TAG .""]","['', '', '', '', '', '', '', '', 'feature sets, but then efficiency becomes a problem.', "" #TAUTHOR_TAG define a kernel over parse trees and apply it to re-ranking the output of a parser , but the resulting feature space is restricted by the need to compute the kernel efficiently , and the results are not as good as Collins ' previous work on re-ranking using a finite set of features #AUTHOR_TAG .""]",0
"['', 'We used a publicly available tagger #TAUTHOR_TAG to tag the words and then used these in the input to the system .']","['', 'We used a publicly available tagger #TAUTHOR_TAG to tag the words and then used these in the input to the system .']","['', 'We used a publicly available tagger #TAUTHOR_TAG to tag the words and then used these in the input to the system .']","['', 'We used a publicly available tagger #TAUTHOR_TAG to tag the words and then used these in the input to the system .']",5
"['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6 precision error and only lex.', 'The SSN parser achieves this using much lessxical,', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% precision error and only lexicalized model.', 'The SSN parser achieves this using much less lexical approaches,', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% less precision error and', 'The SSN parser achieves this result using much lessxical knowledge', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% less precision error and only 11% less recall error than the lexicalized model.', '', '']",1
"['Many statistical parsers #TAUTHOR_TAG are based on a history-based probability model #AUTHOR_TAG , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .', 'A major challenge in this approach is choosing a representation of the parse history from which the probability for the next parser decision can be accurately estimated.', 'Previous have used a hand-crafted finite set of toed', '', '', '', '']","['Many statistical parsers #TAUTHOR_TAG are based on a history-based probability model #AUTHOR_TAG , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .', 'A major challenge in this approach is choosing a representation of the parse history from which the probability for the next parser decision can be accurately estimated.', 'Previous have used a hand-crafted finite set of to', '', '', '', '']","['Many statistical parsers #TAUTHOR_TAG are based on a history-based probability model #AUTHOR_TAG , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .', 'A major challenge in this approach is choosing a representation of the parse history from which the probability for the next parser decision can be accurately estimated.', 'Previous approaches have used a hand-crafted finite set of to', '', '', '', '']","['Many statistical parsers #TAUTHOR_TAG are based on a history-based probability model #AUTHOR_TAG , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .', 'A major challenge in this approach is choosing a representation of the parse history from which the probability for the next parser decision can be accurately estimated.', 'Previous approaches have used a hand-crafted finite set of features to represent the unbounded parse history #AUTHOR_TAG .', '', '', '', '']",0
"['in', ',) includes nodes which are structally local to top', 'nodes are the most', 'For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial #AUTHOR_TAG , as has conditioning on the left-corner child #TAUTHOR_TAG .', 'featurescoror and the most recent child, a derivation step i always has access to the history features from the previous derivation step i - and ( induction) any information from the history could in stored', '']","['', 'reason, includes nodes which are structurally local to top,.', 'nodes are the most', 'For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial #AUTHOR_TAG , as has conditioning on the left-corner child #TAUTHOR_TAG .', 'features ancestor and the most recent child, a derivation step i always has access to the history features from the previous derivation step i and (by induction) any information from the history could in stored', '']","['', ') includes nodes which are structurally local to top', 'These nodes are', 'For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial #AUTHOR_TAG , as has conditioning on the left-corner child #TAUTHOR_TAG .', 'and the most recent child, a derivation step i always has access to the history features from the previous derivation step i -1, and ( induction) any information from could in be stored', '']","['', 'For this reason, D(top) includes nodes which are structurally local to top,.', '', 'For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial #AUTHOR_TAG , as has conditioning on the left-corner child #TAUTHOR_TAG .', 'Because these inputs include the history features of both the leftcorner ancestor and the most recent child, a derivation step i always has access to the history features from the previous derivation step i -1, and thus (by induction) any information from the entire previous derivation history could in principle be stored in the history features.', '']",0
"['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6 precision error and only lex.', 'The SSN parser achieves this using much lessxical,', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% precision error and only lexicalized model.', 'The SSN parser achieves this using much less lexical approaches,', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% less precision error and', 'The SSN parser achieves this result using much lessxical knowledge', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% less precision error and only 11% less recall error than the lexicalized model.', '', '']",1
"['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6 precision error and only lex.', 'The SSN parser achieves this using much lessxical,', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% precision error and only lexicalized model.', 'The SSN parser achieves this using much less lexical approaches,', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% less precision error and', 'The SSN parser achieves this result using much lessxical knowledge', '']","['The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers #TAUTHOR_TAG .', 'The performance of the lexicalized model falls in the middle of this range, only being beaten by the three best current parsers, which all achieve equivalent performance.', 'The best current model #AUTHOR_TAG has only 6% less precision error and only 11% less recall error than the lexicalized model.', '', '']",1
"['In this work we use a method for automatically inducing a finite set of features for representing the derivation history.', 'method is a form of multi-layered artificial neural network called Simple Synchrony Networks #AUTHOR_TAG', 'The outputs of this network are probability estimates computed with a log-linear model (also known as a maximum entropy model), as is done in #AUTHOR_TAG .', 'Log-linear models have proved successful in a wide variety of applications , and are the inspiration behind one of the best current statistical parsers #TAUTHOR_TAG .', 'The difference from previous approaches is in the nature of the input to the log-linear model.', '', '', '']","['In this work we use a method for automatically inducing a finite set of features for representing the derivation history.', 'method is a form of multi-layered artificial neural network called Simple Synchrony Networks #AUTHOR_TAG', 'The outputs of this network are probability estimates computed with a log-linear model (also known as a maximum entropy model), as is done in #AUTHOR_TAG .', 'Log-linear models have proved successful in a wide variety of applications , and are the inspiration behind one of the best current statistical parsers #TAUTHOR_TAG .', 'The difference from previous approaches is in the nature of the input to the log-linear model.', '', '', '']","['In this work we use a method for automatically inducing a finite set of features for representing the derivation history.', 'The method is a form of multi-layered artificial neural network called Simple Synchrony Networks #AUTHOR_TAG .', 'The outputs of this network are probability estimates computed with a log-linear model (also known as a maximum entropy model), as is done in #AUTHOR_TAG .', 'Log-linear models have proved successful in a wide variety of applications , and are the inspiration behind one of the best current statistical parsers #TAUTHOR_TAG .', 'The difference from previous approaches is in the nature of the input to the log-linear model.', '', '', '']","['In this work we use a method for automatically inducing a finite set of features for representing the derivation history.', 'The method is a form of multi-layered artificial neural network called Simple Synchrony Networks #AUTHOR_TAG .', 'The outputs of this network are probability estimates computed with a log-linear model (also known as a maximum entropy model), as is done in #AUTHOR_TAG .', 'Log-linear models have proved successful in a wide variety of applications , and are the inspiration behind one of the best current statistical parsers #TAUTHOR_TAG .', 'The difference from previous approaches is in the nature of the input to the log-linear model.', '', '', '']",1
"['', 'decreases after n4 conver and conver L', 'The highest accuracy is obtained by SL-DOP at 12 n 14: an LP of 90.8% and an LR of 90.7%.', 'This is roughly an 11 % relative reduction in error rate over #TAUTHOR_TAG and Bods PCFG-reduction reported in Table 1 .', '', 'in']","['', 'decreases after n=14 converges and converges', 'The highest accuracy is obtained by SL-DOP at 12 n 14: an LP of 90.8% and an LR of 90.7%.', 'This is roughly an 11 % relative reduction in error rate over #TAUTHOR_TAG and Bods PCFG-reduction reported in Table 1 .', '', 'in']","['', 'OP decreases after n4 conver and conver L', 'The highest accuracy is obtained by SL-DOP at 12 n 14: an LP of 90.8% and an LR of 90.7%.', 'This is roughly an 11 % relative reduction in error rate over #TAUTHOR_TAG and Bods PCFG-reduction reported in Table 1 .', '', 'in']","['', '', 'The highest accuracy is obtained by SL-DOP at 12 n 14: an LP of 90.8% and an LR of 90.7%.', 'This is roughly an 11 % relative reduction in error rate over #TAUTHOR_TAG and Bods PCFG-reduction reported in Table 1 .', '', '']",1
"['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG showed how the perceptron algorithm can', ""be used to efficiently compute the best parse with DOP1 's sub"", 'trees , reporting a 5.1 % relative reduction in error rate over the model in #AUTHOR_TAG on the WSJ .', '', '']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG showed how the perceptron algorithm can', ""be used to efficiently compute the best parse with DOP1 's sub"", 'trees , reporting a 5.1 % relative reduction in error rate over the model in #AUTHOR_TAG on the WSJ .', '', '']","['', '', '', '', '', '', '', '', '', 'showed how the perceptron algorithm can', ""be used to efficiently compute the best parse with DOP1 's sub"", 'trees , reporting a 5.1 % relative reduction in error rate over the model in #AUTHOR_TAG on the WSJ', '', '']","['', '', '', '', '', '', '', '', '', '', ""be used to efficiently compute the best parse with DOP1 's sub"", 'trees , reporting a 5.1 % relative reduction in error rate over the model in #AUTHOR_TAG on the WSJ . #AUTHOR_TAG furthermore showed', '', '']",0
"[""This paper presents the first published results with Goodman's PCFG-reductions of both Bonnema et al.'s () and."", 'We that these PCFG-reductions in 60 times speedup in processing time.', ', 2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #AUTHOR_TAG and #AUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #TAUTHOR_TAG .""]","[""This paper presents the first published results with Goodman's PCFG-reductions of both Bonnema et al.'s and"", 'We that these PCFG-reductions in 60 times speedup in processing time', ', 2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #AUTHOR_TAG and #AUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #TAUTHOR_TAG .""]","[""This paper presents the first published results with Goodman's PCFG-reductions of both Bonnema et al.'s () and"", 'We show that these PCFG-reductions result in a 60 times speedup in', ', 2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #AUTHOR_TAG and #AUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #TAUTHOR_TAG .""]","[""This paper presents the first published results with Goodman's PCFG-reductions of both Bonnema et al.'s (1999) and #AUTHOR_TAG estimators on the WSJ."", 'We show that these PCFG-reductions result in a 60 times speedup in processing time w.r.t.', ' #AUTHOR_TAG Bod ( , 2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #AUTHOR_TAG and #AUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #TAUTHOR_TAG .""]",0
"['', 'decre n conver L and conver LOP', 'The highest accuracy is obtained by SLOP at 12 n 4: LP L', 'Table 1', 'Compared to the reranking technique in #TAUTHOR_TAG , who obtained an LP of 89.9 % and an LR of 89.6 % , our results show a 9 % relative error rate reduction .', 'While SL-DOP and LS-DOP have been compared before in']","['', 'decreases converges and converges', 'The highest accuracy is obtained by SL-DOP at 12 n 14: LP LR', 'Table 1.', 'Compared to the reranking technique in #TAUTHOR_TAG , who obtained an LP of 89.9 % and an LR of 89.6 % , our results show a 9 % relative error rate reduction .', 'While SL-DOP and LS-DOP have been compared before in']","['', 'n conver L and conver LOP', 'The highest accuracy is obtained by SLOP at 12 n 14: an LP', 'Table 1.', 'Compared to the reranking technique in #TAUTHOR_TAG , who obtained an LP of 89.9 % and an LR of 89.6 % , our results show a 9 % relative error rate reduction .', 'While SL-DOP and LS-DOP have been compared before in']","['', '', '', '', 'Compared to the reranking technique in #TAUTHOR_TAG , who obtained an LP of 89.9 % and an LR of 89.6 % , our results show a 9 % relative error rate reduction .', 'While SL-DOP and LS-DOP have been compared before in']",1
"[""This paper presents the first published results with Goodmans P-reductions of both Bonnema et al.'s"", 'We that these PCFG-reductions result in a 60 times speedup in processing time w.', 'Bod , 2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #AUTHOR_TAG and #TAUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #AUTHOR_TAG .""]","[""This paper presents the first published results with Goodman's PCFG-reductions of both Bonnema et al.'s"", 'We that these PCFG-reductions result in a 60 times speedup in processing time', 'Bod , 2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #AUTHOR_TAG and #TAUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #AUTHOR_TAG .""]","[""This paper presents the first published results with Goodmans PCFG-reductions of both Bonnema et al.'s"", 'We show that these PCFG-reductions result in a 60 times speedup in processing time w.r.t.', ' #AUTHOR_TAG Bod , 2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #AUTHOR_TAG and #TAUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #AUTHOR_TAG .""]","[""This paper presents the first published results with Goodman's PCFG-reductions of both Bonnema et al.'s (1999) and #AUTHOR_TAG estimators on the WSJ."", 'We show that these PCFG-reductions result in a 60 times speedup in processing time w.r.t.', ' #AUTHOR_TAG Bod ( , 2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #AUTHOR_TAG and #TAUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #AUTHOR_TAG .""]",0
"['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e.', 'most probable) tree as a candidate for the best tree of a sentence.', 'We will refer to these models as Likelihood-DOP models, but will ""Likelihood-DOP']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e.', 'most probable) tree as a candidate for the best tree of a sentence.', 'We will refer to these models as Likelihood-DOP models, but will ""Likelihood-DOP""']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e.', 'most probable) tree as a candidate for the best tree of a sentence.', 'We will refer to these models as Likelihood-DOP models, but will ""Likelihood-DOP']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e.', 'most probable) tree as a candidate for the best tree of a sentence.', 'We will refer to these models as Likelihood-DOP models, but in this paper we will specifically mean by ""Likelihood-DOP"" the PCFG-reduction of #AUTHOR_TAG given in Section 2.2.']",0
"['u', 'Our first experimental goal was to the two PCFG-reductions in we', 'and Bon', 'Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.', 'Collins 1996 , Charniak 1997 , Collins 1999 and #TAUTHOR_TAG .', '', '', '', '', '']","['', 'Our first experimental goal was to the two PCFG-reductions in we', 'and', 'Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.', 'Collins 1996 , Charniak 1997 , Collins 1999 and #TAUTHOR_TAG .', '', '', '', '', '']","['', 'Our first experimental goal was to the two PCFG-reductions in', 'and Bon', 'Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.', 'Collins 1996 , Charniak 1997 , Collins 1999 and #TAUTHOR_TAG .', '', '', '', '', '']","['', 'Our first experimental goal was to compare the two PCFG-reductions in Section 2.2, which we will refer to resp.', '', 'Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.', 'Collins 1996 , Charniak 1997 , Collins 1999 and #TAUTHOR_TAG .', '', '', '', '', '']",1
"['For our experiments we used the standard division of the WSJ #TAUTHOR_TAG , with sections 2 through 21 for training ( approx .', '40,000 sentences) and section 23 for testing (2416 sentences 100 words); section 22 was used as development set.', 'As, all trees were off their semantic tags, co-reference information and quotation marks.', 'ofality to binary branch (', '', '', '']","['For our experiments we used the standard division of the WSJ #TAUTHOR_TAG , with sections 2 through 21 for training ( approx .', '40,000 sentences) and section 23 for testing (2416 sentences 100 words); section 22 was used as development set.', 'As usual, all trees were off their semantic tags, co-reference information and quotation marks.', 'of to binary branching (and', '', '', '']","['For our experiments we used the standard division of the WSJ #TAUTHOR_TAG , with sections 2 through 21 for training ( approx .', '40,000 sentences) and section 23 for testing (2416 sentences 100 words); section 22 was used as development set.', 'As, all trees were stripped off their semantic tags, co-reference information and quotation marks.', 'ofality to binary branching (', '', '', '']","['For our experiments we used the standard division of the WSJ #TAUTHOR_TAG , with sections 2 through 21 for training ( approx .', '40,000 sentences) and section 23 for testing (2416 sentences 100 words); section 22 was used as development set.', 'As usual, all trees were stripped off their semantic tags, co-reference information and quotation marks.', '', '', '', '']",5
"['nyu', 'Our first experimental goal was to compare the two PCFG-reductions in Section2. we will to', 'as Bod01 and Bon99.', 'Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.', ' #TAUTHOR_TAG , Charniak 1997 , Collins 1999 and Charniak 2000 ) .', '(1996).', '', '', '', '', '']","['', 'Our first experimental goal was to compare the two PCFG-reductions in Section we will to', 'as Bod01 and Bon99.', 'Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.', ' #TAUTHOR_TAG , Charniak 1997 , Collins 1999 and Charniak 2000 ) .', '(1996).', '', '', '', '', '']","['', 'Our first experimental goal was to compare the two PCFG-reductions in Section 2.2, we will refer to', 'as Bod01 and Bon99.', 'Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.', ' #TAUTHOR_TAG , Charniak 1997 , Collins 1999 and Charniak 2000 ) .', '(1996).', '', '', '', '', '']","['', 'Our first experimental goal was to compare the two PCFG-reductions in Section 2.2, which we will refer to resp.', 'as Bod01 and Bon99.', 'Table 1 gives the results of these experiments and compares them with some other statistical parsers (resp.', ' #TAUTHOR_TAG , Charniak 1997 , Collins 1999 and Charniak 2000 ) .', '(1996).', '', '', '', '', '']",1
"[""This paper presents the first published results withmans P-reductions of bothn et al.'"", 'that these P-reductions result in a 60 times speedup in processing time', '2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #TAUTHOR_TAG and #AUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #AUTHOR_TAG .""]","[""This paper presents the first published results with Goodman's PCFG-reductions of both et al.'s"", 'that these PCFG-reductions result in a 60 times speedup in processing time', '2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #TAUTHOR_TAG and #AUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #AUTHOR_TAG .""]","[""This paper presents the first published results withmans PCFG-reductions of both Bonnema et al.'"", 'that these PCFG-reductions result in a 60 times speedup in', '2003.', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #TAUTHOR_TAG and #AUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #AUTHOR_TAG .""]","['', 'We show that these PCFG-reductions result in a 60 times speedup in processing time w.r.t.', '', ""But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to #TAUTHOR_TAG and #AUTHOR_TAG , Bonnema et al. 's estimator performs worse and is comparable to #AUTHOR_TAG .""]",0
"['', '', '', '', '', 'i ; 1998).', ""And #TAUTHOR_TAG argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in #AUTHOR_TAG who use exactly the same set of ( all ) tree fragments as proposed in #AUTHOR_TAG .""]","['', '', '', '', '', '1998).', ""And #TAUTHOR_TAG argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in #AUTHOR_TAG who use exactly the same set of ( all ) tree fragments as proposed in #AUTHOR_TAG .""]","['', '', '', '', '', '', ""And #TAUTHOR_TAG argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in #AUTHOR_TAG who use exactly the same set of ( all ) tree fragments as proposed in #AUTHOR_TAG .""]","['', '', '', '', '', '', ""And #TAUTHOR_TAG argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in #AUTHOR_TAG who use exactly the same set of ( all ) tree fragments as proposed in #AUTHOR_TAG .""]",0
"['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .', 'We will refer to these models as Likelihood- DOP models, but we will by ""Likelihood-DOP']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .', 'We will refer to these models as Likelihood- DOP models, but we will by ""Likelihood-DOP""']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .', 'We will refer to these models as Likelihood- DOP models, but we will by ""Likelihood-DOP']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .', 'We will refer to these models as Likelihood- DOP models, but in this paper we will specifically mean by ""Likelihood-DOP"" the PCFG-reduction of #AUTHOR_TAG given in Section 2.2.']",0
"['Most DOP models , such as in #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e.', 'most probable) tree as a candidate for the best tree of a sentence.', 'We will refer to these models as Likelihood-DOP models, but will by ""Likelihood-DOP']","['Most DOP models , such as in #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e.', 'most probable) tree as a candidate for the best tree of a sentence.', 'We will refer to these models as Likelihood-DOP models, but will by ""Likelihood-DOP""']","['Most DOP models , such as in #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e.', 'most probable) tree as a candidate for the best tree of a sentence.', 'We will refer to these models as Likelihood-DOP models, but will by ""Likelihood-DOP']","['Most DOP models , such as in #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e.', 'most probable) tree as a candidate for the best tree of a sentence.', 'We will refer to these models as Likelihood-DOP models, but in this paper we will specifically mean by ""Likelihood-DOP"" the PCFG-reduction of #AUTHOR_TAG given in Section 2.2.']",0
"['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .', 'We will refer to these models as Likelihood-DOP models, but will ""Likelihood-DOP']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .', 'We will refer to these models as Likelihood-DOP models, but will ""Likelihood-DOP""']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .', 'We will refer to these models as Likelihood-DOP models, but will ""Likelihood-DOP']","['Most DOP models , such as in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .', 'We will refer to these models as Likelihood-DOP models, but in this paper we will specifically mean by ""Likelihood-DOP"" the PCFG-reduction of #AUTHOR_TAG given in Section 2.2.']",0
"['Thus DOP1 considers counts of subtrees of a wide of sizes in computing the probability of a tree: everything from counts of single-level rules to of entire trees.', 'A disadvantage this is an extremely large number of subtrees (and derivations) must be taken into account.', 'Fortunately , there exists a compact PCFG-reduction of DOP1 that generates the same trees with the same probabilities , as shown by #TAUTHOR_TAG , 2002 ) .', 'Here we will only sketch this PCFG-reduction, which is heavily based on #AUTHOR_TAG .']","['Thus DOP1 considers counts of subtrees of a wide of sizes in computing the probability of a tree: everything from counts of single-level rules to of entire trees.', 'A disadvantage this is an extremely large number of subtrees (and derivations) must be taken into account.', 'Fortunately , there exists a compact PCFG-reduction of DOP1 that generates the same trees with the same probabilities , as shown by #TAUTHOR_TAG , 2002 ) .', 'Here we will only sketch this PCFG-reduction, which is heavily based on #AUTHOR_TAG .']","['Thus DOP1 considers counts of subtrees of a wide range of sizes in computing the probability of a tree: everything from counts of single-level rules to of entire trees.', 'A disadvantage this model is an extremely large number of subtrees (and derivations) must be taken into account.', 'Fortunately , there exists a compact PCFG-reduction of DOP1 that generates the same trees with the same probabilities , as shown by #TAUTHOR_TAG , 2002 ) .', 'Here we will only sketch this PCFG-reduction, which is heavily based on #AUTHOR_TAG .']","['Thus DOP1 considers counts of subtrees of a wide range of sizes in computing the probability of a tree: everything from counts of single-level rules to counts of entire trees.', 'A disadvantage of this model is that an extremely large number of subtrees (and derivations) must be taken into account.', 'Fortunately , there exists a compact PCFG-reduction of DOP1 that generates the same trees with the same probabilities , as shown by #TAUTHOR_TAG , 2002 ) .', 'Here we will only sketch this PCFG-reduction, which is heavily based on #AUTHOR_TAG .']",0
"['Waegner 1992; Pereira and Schabes 1992).', 'The DOP model on the other hand, was the first model (to the best of our knowledge) that proposed not to train a predefined grammar on a corpus, but to directly use corpus fragments as a grammar.', 'This approach has now gained wide usage , as exemplified by the work of #TAUTHOR_TAG , 1999 ) , #AUTHOR_TAG , 1997 ) , #AUTHOR_TAG , #AUTHOR_TAG , and many others .']","['Waegner 1992; Pereira and Schabes 1992).', 'The DOP model, on the other hand, was the first model (to the best of our knowledge) that proposed not to train a predefined grammar on a corpus, but to directly use corpus fragments as a grammar.', 'This approach has now gained wide usage , as exemplified by the work of #TAUTHOR_TAG , 1999 ) , #AUTHOR_TAG , 1997 ) , #AUTHOR_TAG , #AUTHOR_TAG , and many others .']","['Waegner 1992; Pereira and Schabes 1992).', 'The DOP model, on the other hand, was the first model (to the best of our knowledge) that proposed not to train a predefined grammar on a corpus, but to directly use corpus fragments as a grammar.', 'This approach has now gained wide usage , as exemplified by the work of #TAUTHOR_TAG , 1999 ) , #AUTHOR_TAG , 1997 ) , #AUTHOR_TAG , #AUTHOR_TAG , and many others .']","['Waegner 1992; Pereira and Schabes 1992).', 'The DOP model, on the other hand, was the first model (to the best of our knowledge) that proposed not to train a predefined grammar on a corpus, but to directly use corpus fragments as a grammar.', 'This approach has now gained wide usage , as exemplified by the work of #TAUTHOR_TAG , 1999 ) , #AUTHOR_TAG , 1997 ) , #AUTHOR_TAG , #AUTHOR_TAG , and many others .']",4
"['', '', '', ').', 'The importance of including nonheadwords has become uncontroversial ( e.g. Collins 1999 ; #TAUTHOR_TAG ; Goodman 1998 ) .', '']","['', '', '', '', 'The importance of including nonheadwords has become uncontroversial ( e.g. Collins 1999 ; #TAUTHOR_TAG ; Goodman 1998 ) .', '']","['', '', '', '', 'The importance of including nonheadwords has become uncontroversial ( e.g. Collins 1999 ; #TAUTHOR_TAG ; Goodman 1998 ) .', '']","['', '', '', '', 'The importance of including nonheadwords has become uncontroversial ( e.g. Collins 1999 ; #TAUTHOR_TAG ; Goodman 1998 ) .', '']",0
"['', '', '', '', 'becomeeg.', '1999;Chiak 2000;Good 1998).', "" #AUTHOR_TAG argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in #TAUTHOR_TAG who use exactly the same set of ( all ) tree fragments as proposed in #AUTHOR_TAG .""]","['', '', '', '', 'become (e.g.', '1999;Charniak 2000;Goodman 1998).', "" #AUTHOR_TAG argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in #TAUTHOR_TAG who use exactly the same set of ( all ) tree fragments as proposed in #AUTHOR_TAG .""]","['', '', '', '', 'has becomeeg.', 'Collins 1999;Charniak 2000;Goodman 1998).', "" #AUTHOR_TAG argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in #TAUTHOR_TAG who use exactly the same set of ( all ) tree fragments as proposed in #AUTHOR_TAG .""]","['', '', '', '', '', 'Collins 1999;Charniak 2000;Goodman 1998).', "" #AUTHOR_TAG argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in #TAUTHOR_TAG who use exactly the same set of ( all ) tree fragments as proposed in #AUTHOR_TAG .""]",4
"['Goodman then shows by simple induction that subderivations headed by A with external nonterminals at the roots and leaves, internal nonterminals elsewhere have probability 1/a.', 'And subderivations headed by A1 with external nonterminals only at the leaves , internal nonterminals elsewhere , have probability 1/a1 #TAUTHOR_TAG .', 'Goodmans main theorem is that this construction produces PCFG derivations isomorphic to DOP derivations with equal probability.', 'This means that summing up over derivations of a tree in DOP yields the same probability as summing over all the isomorphic derivations in the', '', '', '', '']","['Goodman then shows by simple induction that subderivations headed by A with external nonterminals at the roots and leaves, internal nonterminals elsewhere have probability 1/a.', 'And subderivations headed by A1 with external nonterminals only at the leaves , internal nonterminals elsewhere , have probability 1/a1 #TAUTHOR_TAG .', ""Goodman's main theorem is that this construction produces PCFG derivations isomorphic to DOP derivations with equal probability."", 'This means that summing up over derivations of a tree in DOP yields the same probability as summing over all the isomorphic derivations in the', '', '', '', '']","['Goodman then shows by simple induction that subderivations headed by A with external nonterminals at the roots and leaves, internal nonterminals elsewhere have probability 1/a.', 'And subderivations headed by A1 with external nonterminals only at the leaves , internal nonterminals elsewhere , have probability 1/a1 #TAUTHOR_TAG .', 'Goodmans main theorem is that this construction produces PCFG derivations isomorphic to DOP derivations with equal probability.', 'This means that summing up over derivations of a tree in DOP yields the same probability as summing over all the isomorphic derivations in', '', '', '', '']","['Goodman then shows by simple induction that subderivations headed by A with external nonterminals at the roots and leaves, internal nonterminals elsewhere have probability 1/a.', 'And subderivations headed by A1 with external nonterminals only at the leaves , internal nonterminals elsewhere , have probability 1/a1 #TAUTHOR_TAG .', ""Goodman's main theorem is that this construction produces PCFG derivations isomorphic to DOP derivations with equal probability."", 'This means that summing up over derivations of a tree in DOP yields the same probability as summing over all the isomorphic derivations in the PCFG.', '', '', '', '']",0
"['One instant of DOP has received considerable is the model known as DOP1  ', 'DOP1 combines subtrees from a treebank by means of node-substitution and computes the probability of a tree from the normalized frequencies of the subtrees (see', '', '', '', ' #AUTHOR_TAG gave an efficient algorithm for computing the parse tree generated by the most probable derivation, which in some is a reasonable approximation of the most probable parse.', ' #TAUTHOR_TAG , 1998 ) developed a polynomial time PCFG-reduction of DOP1 whose size is linear in the size of the training set , thus converting the exponential number of subtrees to a compact grammar .', 'Goods method does still not for an efficient most, does the ""maximum', '', '', '', '', '', '']","['One instantiation of DOP has received considerable is the model known as DOP1 2', 'DOP1 combines subtrees from a treebank by means of node-substitution and computes the probability of a tree from the normalized frequencies of the subtrees (see', '', '', '', ' #AUTHOR_TAG gave an efficient algorithm for computing the parse tree generated by the most probable derivation, which in some is a reasonable approximation of the most probable parse.', ' #TAUTHOR_TAG , 1998 ) developed a polynomial time PCFG-reduction of DOP1 whose size is linear in the size of the training set , thus converting the exponential number of subtrees to a compact grammar .', 'Goodman\'s method does still not for an efficient most does the ""maximum', '', '', '', '', '', '']","['One instantiation of DOP has received considerable interest is the model known as DOP1 2 ', 'DOP1 combines subtrees from a treebank by means of node-substitution and computes the probability of a tree from the normalized frequencies of the subtrees (see', '', '', '', ' #AUTHOR_TAG gave an efficient algorithm for computing the parse tree generated by the most probable derivation, which in some cases is a reasonable approximation of the most probable parse.', ' #TAUTHOR_TAG , 1998 ) developed a polynomial time PCFG-reduction of DOP1 whose size is linear in the size of the training set , thus converting the exponential number of subtrees to a compact grammar .', 'Goods method does still not for an efficient computation most, the ""maximum constituents', '', '', '', '', '', '']","['One instantiation of DOP which has received considerable interest is the model known as DOP1 2 (Bod 1992).', 'DOP1 combines subtrees from a treebank by means of node-substitution and computes the probability of a tree from the normalized frequencies of the subtrees (see Section 2 for a full definition).', '', '', '', ' #AUTHOR_TAG gave an efficient algorithm for computing the parse tree generated by the most probable derivation, which in some cases is a reasonable approximation of the most probable parse.', ' #TAUTHOR_TAG , 1998 ) developed a polynomial time PCFG-reduction of DOP1 whose size is linear in the size of the training set , thus converting the exponential number of subtrees to a compact grammar .', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', 'Our Moses systems use default settings.', 'The LM uses the monolingual data and is trained as a five-gram9 using the SRILM-Toolkit #TAUTHOR_TAG .', 'We run MERT separately for each system.', 'recaser used is the', 'is the supplied training', '', '']","['', '', '', '', '', '', 'Our Moses systems use default settings.', 'The LM uses the monolingual data and is trained as a five-gram9 using the SRILM-Toolkit #TAUTHOR_TAG .', 'We run MERT separately for each system.', 'recaser used is the', 'is the supplied training', '', '']","['', '', '', '', '', '', 'Our Moses systems use default settings.', 'The LM uses the monolingual data and is trained as a five-gram9 using the SRILM-Toolkit #TAUTHOR_TAG .', 'We run MERT separately for each system.', 'The recaser used is the', 'It is supplied', '', '']","['', '', '', '', '', '', 'Our Moses systems use default settings.', 'The LM uses the monolingual data and is trained as a five-gram9 using the SRILM-Toolkit #TAUTHOR_TAG .', 'We run MERT separately for each system.', '', '', '', '']",5
"['After translation, compound parts have to be resynthesized into compounds before inflection.', 'Two decisions have to be taken: i) where to merge and ii) how to merge.', 'Following the work of #TAUTHOR_TAG , we implement a linear-chain CRF merging system using the following features : stemmed ( separated ) surface form , part-of-speech14 and frequencies from the training corpus for bigrams/merging of word and word +1 , word as true prefix , word +1 as true suffix , plus frequency comparisons of these .', 'The CRF is trained on the split monolingual data', 'It merging']","['After translation, compound parts have to be resynthesized into compounds before inflection.', 'Two decisions have to be taken: i) where to merge and ii) how to merge.', 'Following the work of #TAUTHOR_TAG , we implement a linear-chain CRF merging system using the following features : stemmed ( separated ) surface form , part-of-speech14 and frequencies from the training corpus for bigrams/merging of word and word +1 , word as true prefix , word +1 as true suffix , plus frequency comparisons of these .', 'The CRF is trained on the split monolingual data.', 'It merging']","['After translation, compound parts have to be resynthesized into compounds before inflection.', 'Two decisions have to be taken: i) where to merge and ii) how to merge.', 'Following the work of #TAUTHOR_TAG , we implement a linear-chain CRF merging system using the following features : stemmed ( separated ) surface form , part-of-speech14 and frequencies from the training corpus for bigrams/merging of word and word +1 , word as true prefix , word +1 as true suffix , plus frequency comparisons of these .', 'The CRF is trained on the split monolingual data.', 'It']","['After translation, compound parts have to be resynthesized into compounds before inflection.', 'Two decisions have to be taken: i) where to merge and ii) how to merge.', 'Following the work of #TAUTHOR_TAG , we implement a linear-chain CRF merging system using the following features : stemmed ( separated ) surface form , part-of-speech14 and frequencies from the training corpus for bigrams/merging of word and word +1 , word as true prefix , word +1 as true suffix , plus frequency comparisons of these .', 'The CRF is trained on the split monolingual data.', '']",5
"['For compound splitting , we follow #TAUTHOR_TAG , using linguistic knowledge encoded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies .', 'Other approaches use less deep linguistic resources (e.g., PO #AUTHOR_TAG ) or are (almost) knowledge-free (e.g., #AUTHOR_TAG ).', '.', '', '', '', '']","['For compound splitting , we follow #TAUTHOR_TAG , using linguistic knowledge encoded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies .', 'Other approaches use less deep linguistic resources (e.g., PO #AUTHOR_TAG ) or are (almost) knowledge-free (e.g., #AUTHOR_TAG ).', 'studied.', '', '', '', '']","['For compound splitting , we follow #TAUTHOR_TAG , using linguistic knowledge encoded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies .', 'Other approaches use less deep linguistic resources (e.g., PO #AUTHOR_TAG ) or are (almost) knowledge-free (e.g., #AUTHOR_TAG ).', '.', '', '', '', '']","['For compound splitting , we follow #TAUTHOR_TAG , using linguistic knowledge encoded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies .', 'Other approaches use less deep linguistic resources (e.g., PO #AUTHOR_TAG ) or are (almost) knowledge-free (e.g., #AUTHOR_TAG ).', '', '', '', '', '']",5
"['We use an additional target factor to obtain the coarse POS for each stem, applying a 7-gram POS model.', ' #TAUTHOR_TAG showed that the use of a POS factor only results in negligible BLEU improvements , but we need access to the POS in our inflection prediction models .']","['We use an additional target factor to obtain the coarse POS for each stem, applying a 7-gram POS model.', ' #TAUTHOR_TAG showed that the use of a POS factor only results in negligible BLEU improvements , but we need access to the POS in our inflection prediction models .']","['We use an additional target factor to obtain the coarse POS for each stem, applying a 7-gram POS model.', ' #TAUTHOR_TAG showed that the use of a POS factor only results in negligible BLEU improvements , but we need access to the POS in our inflection prediction models .']","['We use an additional target factor to obtain the coarse POS for each stem, applying a 7-gram POS model.', ' #TAUTHOR_TAG showed that the use of a POS factor only results in negligible BLEU improvements , but we need access to the POS in our inflection prediction models .']",0
"['', '', '', '', 'We follow #TAUTHOR_TAG , for compound merging .', 'We trained a CRF using (nearly all) of the features used found their approach to be effective (when combined with inflection and portmanteau merg- ing) on one of our two test sets.']","['', '', '', '', 'We follow #TAUTHOR_TAG , for compound merging .', 'We trained a CRF using (nearly all) of the features used found their approach to be effective (when combined with inflection and portmanteau merg- ing) on one of our two test sets.']","['', '', '', '', 'We follow #TAUTHOR_TAG , for compound merging .', 'We trained a CRF using (nearly all) of the features they used found their approach to be effective (when combined with inflection and portmanteau merg- ing) on one of our two test sets.']","['', '', '', '', 'We follow #TAUTHOR_TAG , for compound merging .', 'We trained a CRF using (nearly all) of the features they used and found their approach to be effective (when combined with inflection and portmanteau merg- ing) on one of our two test sets.']",5
"['', '', '', '', '', '', '', '', 'deals de G and Mariño (2008), deals with verbal morphology and attached pronouns', 'solving', '', '', 'to solve the inflection by simply building an SMT system for translating from stems to inflected forms.', ' #TAUTHOR_TAG improved on this by marking prepositions with the case they mark ( one of the most important markups in our system ) .', 'in data sets', '', '']","['', '', '', '', '', '', '', '', 'deals de and Mariño (2008), deals with verbal morphology and attached pronouns.', 'solving', '', '', 'to solve the inflection by simply building an SMT system for translating from stems to inflected forms.', ' #TAUTHOR_TAG improved on this by marking prepositions with the case they mark ( one of the most important markups in our system ) .', 'ineffective data sets.', '', '']","['', '', '', '', '', '', '', '', 'deals de G and Mariño (2008), deals with verbal morphology and attached pronouns', '', '', '', 'to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms.', ' #TAUTHOR_TAG improved on this by marking prepositions with the case they mark ( one of the most important markups in our system ) .', 'in large data sets.', '', '']","['', '', '', '', '', '', '', '', 'The only work that we are aware of which deals with both issues is the work of de Gispert and Mariño (2008), which deals with verbal morphology and attached pronouns.', '', '', '', ' #AUTHOR_TAG tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms.', ' #TAUTHOR_TAG improved on this by marking prepositions with the case they mark ( one of the most important markups in our system ) .', '', '', '']",1
"['For compound follow #AUTHOR_TAG using linguistic en-coded in abasedological analyser and then selecting the analysis the mean word frequencies.', 'Other approaches use less deep linguistic resources ( e.g. , PO #AUTHOR_TAG ) or are ( almost ) knowledge-free ( e.g. , #TAUTHOR_TAG .', 'Compound merging is less.', '', '', '', '']","['For compound follow #AUTHOR_TAG using linguistic en-coded in a morphological analyser and then selecting the analysis the mean word frequencies.', 'Other approaches use less deep linguistic resources ( e.g. , PO #AUTHOR_TAG ) or are ( almost ) knowledge-free ( e.g. , #TAUTHOR_TAG .', 'Compound merging is less studied.', '', '', '', '']","['For we follow #AUTHOR_TAG using linguistic knowledge en-coded in a rule-based morphological analyser and then selecting the best analysis the geometric mean word part frequencies.', 'Other approaches use less deep linguistic resources ( e.g. , PO #AUTHOR_TAG ) or are ( almost ) knowledge-free ( e.g. , #TAUTHOR_TAG .', 'Compound merging is less well.', '', '', '', '']","['For compound splitting, we follow #AUTHOR_TAG , using linguistic knowledge en-coded in a rule-based morphological analyser and then selecting the best analysis based on the geometric mean of word part frequencies.', 'Other approaches use less deep linguistic resources ( e.g. , PO #AUTHOR_TAG ) or are ( almost ) knowledge-free ( e.g. , #TAUTHOR_TAG .', 'Compound merging is less well studied.', '', '', '', '']",1
"['', '', '', '', '', '', 'deals de G and Marin__ (200 deals with verbal morphology and attached pronouns', '', '', '', '', '', 'in on large data sets', ' #TAUTHOR_TAG used unification in an SMT system to model some of the agreement phenomena that we model.', 'Our CR to use more- text']","['', '', '', '', '', '', 'deals de and Marin__o (2008), deals with verbal morphology and attached pronouns.', '', '', '', '', '', 'ineffective on large data sets.', ' #TAUTHOR_TAG used unification in an SMT system to model some of the agreement phenomena that we model.', 'Our CRF to use more con- text']","['', '', '', '', '', '', 'deals de G and Marin__ (200 deals with verbal morphology and attached pronouns', '', '', '', '', '', 'in on large data sets.', ' #TAUTHOR_TAG used unification in an SMT system to model some of the agreement phenomena that we model.', 'Our CR to use']","['', '', '', '', '', '', '', '', '', '', '', '', 'Both efforts were ineffective on large data sets.', ' #TAUTHOR_TAG used unification in an SMT system to model some of the agreement phenomena that we model.', '']",1
"['The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR , a morphological analyzer/generator of German #AUTHOR_TAG and the BitPar parser , which is a state-of-the-art parser of German #TAUTHOR_TAG .']","['The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR , a morphological analyzer/generator of German #AUTHOR_TAG and the BitPar parser , which is a state-of-the-art parser of German #TAUTHOR_TAG .']","['The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR , a morphological analyzer/generator of German #AUTHOR_TAG and the BitPar parser , which is a state-of-the-art parser of German #TAUTHOR_TAG .']","['The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR , a morphological analyzer/generator of German #AUTHOR_TAG and the BitPar parser , which is a state-of-the-art parser of German #TAUTHOR_TAG .']",5
"['We prepare the training data by splitting compounds in two steps , following the technique of #TAUTHOR_TAG .', 'First, possible split points are extracted using SMOR, and second, the best split points are selected using the geometric mean of word part frequencies.', 'Training .', 'modifying words the to right)', '']","['We prepare the training data by splitting compounds in two steps , following the technique of #TAUTHOR_TAG .', 'First, possible split points are extracted using SMOR, and second, the best split points are selected using the geometric mean of word part frequencies.', 'Training', 'modifying words the to rightmost word)', '']","['We prepare the training data by splitting compounds in two steps , following the technique of #TAUTHOR_TAG .', 'First, possible split points are extracted using SMOR, and second, the best split points are selected using the geometric mean of word part frequencies.', 'Training data', 'The formerly modifying words the words to', '']","['We prepare the training data by splitting compounds in two steps , following the technique of #TAUTHOR_TAG .', 'First, possible split points are extracted using SMOR, and second, the best split points are selected using the geometric mean of word part frequencies.', '', '', '']",5
"['', '', '', '', '', 'As improves, the performance of linguistic-feature-based approaches will increase.', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and others are primarily concerned with using morpheme segmentation in SMT , which is a useful approach for dealing with issues of word-formation .', ', this not deal with marked.', '', '']","['', '', '', '', '', 'As improves, the performance of linguistic-feature-based approaches will increase.', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and others are primarily concerned with using morpheme segmentation in SMT , which is a useful approach for dealing with issues of word-formation .', 'However, this not deal with marked', '', '']","['', '', '', '', '', 'As improves, the performance of linguistic-feature-based approaches will increase.', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and others are primarily concerned with using morpheme segmentation in SMT , which is a useful approach for dealing with issues of word-formation .', ', this does not deal directly with marked.', '', '']","['', '', '', '', '', 'As parsing performance improves, the performance of linguistic-feature-based approaches will increase.', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and others are primarily concerned with using morpheme segmentation in SMT , which is a useful approach for dealing with issues of word-formation .', '', '', '']",1
"['', '', '', '', '', '', '', '', 'deals de G and Mariño (2008), deals with verbal morphology and attached pronouns', 'other on solving inflection.', '', 'We use more complex context features.', ' #TAUTHOR_TAG tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms .', 'ing prepos with the case theyone of the most importantups in our system', '', '', '']","['', '', '', '', '', '', '', '', 'deals de and Mariño (2008), deals with verbal morphology and attached pronouns.', 'other on solving inflection.', '', 'We use more complex context features.', ' #TAUTHOR_TAG tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms .', 'marking prepositions with the case they (one of the most important markups in our system).', '', '', '']","['', '', '', '', '', '', '', '', 'deals de G and Mariño (2008), deals with verbal morphology and attached pronouns', 'other work on solving inflection.', '', 'We use more complex context features.', ' #TAUTHOR_TAG tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms .', 'ing prepositions with the case they markone of the most important markups in our system', '', '', '']","['', '', '', '', '', '', '', '', 'The only work that we are aware of which deals with both issues is the work of de Gispert and Mariño (2008), which deals with verbal morphology and attached pronouns.', 'There has been other work on solving inflection.', '', 'We use more complex context features.', ' #TAUTHOR_TAG tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms .', ' #AUTHOR_TAG improved on this by marking prepositions with the case they mark (one of the most important markups in our system).', '', '', '']",1
"['', '', '', '', '', '', 'that we are aware of which deals with both issues is the work of de Gispert and Marin__o (2008), which deals with verbal morphology and attached pronouns.', 'There has been other work on solving inflection.', ' #TAUTHOR_TAG introduced factored SMT .', 'We use more complex context features.', ' #AUTHOR_TAG to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms.', '', '', '', '']","['', '', '', '', '', '', 'that we are aware of which deals with both issues is the work of de Gispert and Marin__o (2008), which deals with verbal morphology and attached pronouns.', 'There has been other work on solving inflection.', ' #TAUTHOR_TAG introduced factored SMT .', 'We use more complex context features.', ' #AUTHOR_TAG to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms.', '', '', '', '']","['', '', '', '', '', '', 'that we are aware of which deals with both issues is the work of de Gispert and Marin__o (2008), which deals with verbal morphology and attached pronouns.', 'There has been other work on solving inflection.', ' #TAUTHOR_TAG introduced factored SMT .', 'We use more complex context features.', ' #AUTHOR_TAG to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms.', '', '', '', '']","['', '', '', '', '', '', 'The only work that we are aware of which deals with both issues is the work of de Gispert and Marin__o (2008), which deals with verbal morphology and attached pronouns.', 'There has been other work on solving inflection.', ' #TAUTHOR_TAG introduced factored SMT .', 'We use more complex context features.', ' #AUTHOR_TAG tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms.', '', '', '', '']",1
"['Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of #AUTHOR_TAG , #TAUTHOR_TAG and others .', 'Toutanova et.', 'als work showed that is to co', '']","['Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of #AUTHOR_TAG , #TAUTHOR_TAG and others .', 'Toutanova et.', ""al.'s work showed that is to"", '']","['Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of #AUTHOR_TAG , #TAUTHOR_TAG and others .', 'Toutanova et.', 'als work showed that to', '']","['Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of #AUTHOR_TAG , #TAUTHOR_TAG and others .', 'Toutanova et.', '', '']",1
"['Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of #TAUTHOR_TAG , #AUTHOR_TAG and others .', 'Toutanova et.', ""al.'s work showed that it is to target co"", 'source information markup']","['Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of #TAUTHOR_TAG , #AUTHOR_TAG and others .', 'Toutanova et.', ""al.'s work showed that it is to target"", 'source information markup']","['Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of #TAUTHOR_TAG , #AUTHOR_TAG and others .', 'Toutanova et.', ""al.'s work showed that it is most to model target"", 'the markup']","['Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of #TAUTHOR_TAG , #AUTHOR_TAG and others .', 'Toutanova et.', '', '']",1
"['For compound #AUTHOR_TAG using linguistic-oded aological analyser and then selecting the word frequencies.', 'Other approaches use less deep linguistic resources ( e.g. , POS-tags #TAUTHOR_TAG or are ( almost ) knowledge-free ( e.g. , #AUTHOR_TAG ) .', '', '', '', '', '']","['For compound #AUTHOR_TAG using linguistic en-coded a morphological analyser and then selecting the word frequencies.', 'Other approaches use less deep linguistic resources ( e.g. , POS-tags #TAUTHOR_TAG or are ( almost ) knowledge-free ( e.g. , #AUTHOR_TAG ) .', '', '', '', '', '']","['For #AUTHOR_TAG using linguistic knowledge-oded a rule-based morphological analyser and word part frequencies.', 'Other approaches use less deep linguistic resources ( e.g. , POS-tags #TAUTHOR_TAG or are ( almost ) knowledge-free ( e.g. , #AUTHOR_TAG ) .', '', '', '', '', '']","['', 'Other approaches use less deep linguistic resources ( e.g. , POS-tags #TAUTHOR_TAG or are ( almost ) knowledge-free ( e.g. , #AUTHOR_TAG ) .', '', '', '', '', '']",1
"['Our approach to extract and classify social events builds on our previous work #TAUTHOR_TAG , which in turn builds on work from the relation extraction community #AUTHOR_TAG .', 'Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper.', '', '', '', '', '']","['Our approach to extract and classify social events builds on our previous work #TAUTHOR_TAG , which in turn builds on work from the relation extraction community #AUTHOR_TAG .', 'Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper.', '', '', '', '', '']","['Our approach to extract and classify social events builds on our previous work #TAUTHOR_TAG , which in turn builds on work from the relation extraction community #AUTHOR_TAG .', 'Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper.', '', '', '', '', '']","['Our approach to extract and classify social events builds on our previous work #TAUTHOR_TAG , which in turn builds on work from the relation extraction community #AUTHOR_TAG .', 'Therefore, the task of relation extraction is most closely related to the tasks addressed in this paper.', '', '', '', '', '']",2
"['2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in #TAUTHOR_TAG .', ""Typed feature structures as normal form ir~'~Eterms are merely syntactic objects.""]","['2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in #TAUTHOR_TAG .', ""Typed feature structures as normal form ir~'~Eterms are merely syntactic objects.""]","['2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in #TAUTHOR_TAG .', ""Typed feature structures as normal form ir~'~Eterms are merely syntactic objects.""]","['2This view of typed feature structures differs from the perspective on typed feature structures as modeling partial information as in #TAUTHOR_TAG .', ""Typed feature structures as normal form ir~'~Eterms are merely syntactic objects.""]",0
['I A more detailed discussion of various aspects of the proposed parser can be found in #TAUTHOR_TAG .'],['I A more detailed discussion of various aspects of the proposed parser can be found in #TAUTHOR_TAG .'],['I A more detailed discussion of various aspects of the proposed parser can be found in #TAUTHOR_TAG .'],['I A more detailed discussion of various aspects of the proposed parser can be found in #TAUTHOR_TAG .'],0
"['Combining control strategies depends on a way to differentiate between types of constraints.', ""Proceedings of EACL '99 example , the ALE parser #TAUTHOR_TAG presupposes a phrase structure backbone which can be used to determine whether a constraint is to be interpreted bottom-up or topdown ."", '', '', '', '', '', 'an important gu and are best interpreted- given', '', '']","['Combining control strategies depends on a way to differentiate between types of constraints.', ""Proceedings of EACL '99 example , the ALE parser #TAUTHOR_TAG presupposes a phrase structure backbone which can be used to determine whether a constraint is to be interpreted bottom-up or topdown ."", '', '', '', '', '', 'an important guiding and are best interpreted given', '', '']","['Combining control strategies depends on a way to differentiate between types of constraints.', ""Proceedings of EACL '99 example , the ALE parser #TAUTHOR_TAG presupposes a phrase structure backbone which can be used to determine whether a constraint is to be interpreted bottom-up or topdown ."", '', '', '', '', '', 'an important guiding role and are best interpreted- given', '', '']","['Combining control strategies depends on a way to differentiate between types of constraints.', ""Proceedings of EACL '99 example , the ALE parser #TAUTHOR_TAG presupposes a phrase structure backbone which can be used to determine whether a constraint is to be interpreted bottom-up or topdown ."", '', '', '', '', '', '', '', '']",0
"['originally', 'among, (Ramakrishnan et al.1).', 'As shown in #TAUTHOR_TAG â\x80¢ The presented research was carried out at the University of Tubingen , Germany , as part of the Sonderforschungsbereich 340 .']","['originally', 'among others, (Ramakrishnan et al.', 'As shown in #TAUTHOR_TAG â\x80¢ The presented research was carried out at the University of Tubingen , Germany , as part of the Sonderforschungsbereich 340 .']","['originally', 'among, (Ramakrishnan et al.1).', 'As shown in #TAUTHOR_TAG â\x80¢ The presented research was carried out at the University of Tubingen , Germany , as part of the Sonderforschungsbereich 340 .']","['', 'See, among others, (Ramakrishnan et al. 1992).', 'As shown in #TAUTHOR_TAG â\x80¢ The presented research was carried out at the University of Tubingen , Germany , as part of the Sonderforschungsbereich 340 .']",0
"['Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; #TAUTHOR_TAG', '3 #AUTHOR_TAG propose a compilation of lexical rules into T~r/: definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modehng partial information as in #AUTHOR_TAG .', 'Typed feature structures as normal form ir~~E terms are merely syntactic objects.']","['Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; #TAUTHOR_TAG', '3 #AUTHOR_TAG propose a compilation of lexical rules into T~r/: definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modehng partial information as in #AUTHOR_TAG .', ""Typed feature structures as normal form ir~'~E terms are merely syntactic objects.""]","['Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; #TAUTHOR_TAG', '3 #AUTHOR_TAG propose a compilation of lexical rules into T~r/: definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modehng partial information as in #AUTHOR_TAG .', ""Typed feature structures as normal form ir~'~E terms are merely syntactic objects.""]","['Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; #TAUTHOR_TAG', '3 #AUTHOR_TAG propose a compilation of lexical rules into T~r/: definite clauses 2This view of typed feature structures differs from the perspective on typed feature structures as modehng partial information as in #AUTHOR_TAG .', ""Typed feature structures as normal form ir~'~E terms are merely syntactic objects.""]",0
"['Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar #TAUTHOR_TAG .', '3 #AUTHOR_TAG a ofxical rules into clauses.', '', '', '']","['Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar #TAUTHOR_TAG .', '3 #AUTHOR_TAG a of lexical rules into clauses entries.', '', '', '']","['Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar #TAUTHOR_TAG .', '3 #AUTHOR_TAG a compilation ofxical rules into', '', '', '']","['Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar #TAUTHOR_TAG .', '', '', '', '']",0
"['Magic is a compilation technique originally developed for goal-directed bottom-up processing of logic programs.', 'See , among others , #TAUTHOR_TAG .', 'is an interesting with respect to natural language processing as it', '', '', '']","['Magic is a compilation technique originally developed for goal-directed bottom-up processing of logic programs.', 'See , among others , #TAUTHOR_TAG .', 'is an interesting with respect to natural language processing as it', '', '', '']","['Magic is a compilation technique originally developed for goal-directed bottom-up processing of logic programs.', 'See , among others , #TAUTHOR_TAG .', 'is an interesting technique with respect to natural language processing as', '', '', '']","['Magic is a compilation technique originally developed for goal-directed bottom-up processing of logic programs.', 'See , among others , #TAUTHOR_TAG .', '', '', '', '']",0
"['', '', ' #AUTHOR_TAG b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.', 'have to refrain from an example.', 'The ConTroll grammar development system as described in #TAUTHOR_TAG b ) implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars .']","['', '', ' #AUTHOR_TAG b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.', 'have to refrain from an example.', 'The ConTroll grammar development system as described in #TAUTHOR_TAG b ) implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars .']","['', '', ' #AUTHOR_TAG b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.', 'we have to refrain from an example.', 'The ConTroll grammar development system as described in #TAUTHOR_TAG b ) implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars .']","['', '', ' #AUTHOR_TAG b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.', '4 Because of space limitations we have to refrain from an example.', 'The ConTroll grammar development system as described in #TAUTHOR_TAG b ) implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars .']",0
"['Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freezing, and blocking.', 'See also #TAUTHOR_TAG .']","['Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freezing, and blocking.', 'See also #TAUTHOR_TAG .']","['Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freezing, and blocking.', 'See also #TAUTHOR_TAG .']","['Coroutining appears under many different guises, like for example, suspension, residuation, (goal) freezing, and blocking.', 'See also #TAUTHOR_TAG .']",0
"['ded', ""In contrast to Johnson and DSrre's deduction system, though, the selective magic parsing approach combines top-down and bottom-up control strategies."", 'As such it resembles the parser of the grammar development system Attribute Language Engine ( ALE ) of #TAUTHOR_TAG .', 'Unlike the ALE parser, though, the selective magic parser not presuppose a phrase structure backbone more flexible sub-computations tabled/filtered', '']","['deduction', ""In contrast to Johnson and DSrre's deduction system, though, the selective magic parsing approach combines top-down and bottom-up control strategies."", 'As such it resembles the parser of the grammar development system Attribute Language Engine ( ALE ) of #TAUTHOR_TAG .', 'Unlike the ALE parser, though, the selective magic parser not presuppose a phrase structure backbone more flexible sub-computations tabled/filtered.', '']","['', ""In contrast to Johnson and DSrre's deduction system, though, the selective magic parsing approach combines top-down and bottom-up control strategies."", 'As such it resembles the parser of the grammar development system Attribute Language Engine ( ALE ) of #TAUTHOR_TAG .', 'Unlike the ALE parser, though, the selective magic parser does not presuppose a phrase structure backbone is more flexible sub-computations tabled/filtered', '']","['', ""In contrast to Johnson and DSrre's deduction system, though, the selective magic parsing approach combines top-down and bottom-up control strategies."", 'As such it resembles the parser of the grammar development system Attribute Language Engine ( ALE ) of #TAUTHOR_TAG .', 'Unlike the ALE parser, though, the selective magic parser does not presuppose a phrase structure backbone and is more flexible as to which sub-computations are tabled/filtered.', '']",1
"['with', 'this we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based Feature', 'Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; #AUTHOR_TAG as discussed in #TAUTHOR_TAG a ) and #AUTHOR_TAG .', 'dealt']","['with', 'this we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based Feature', 'Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; #AUTHOR_TAG as discussed in #TAUTHOR_TAG a ) and #AUTHOR_TAG .', 'dealt']","['with', 'this paper we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based', 'Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; #AUTHOR_TAG as discussed in #TAUTHOR_TAG a ) and #AUTHOR_TAG .', '']","['', 'In this paper we investigate the selective application of magic to typed feature grammars a type of constraint-logic grammar based on Typed Feature Logic (Tgv£:;G #AUTHOR_TAG .', 'Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; #AUTHOR_TAG as discussed in #TAUTHOR_TAG a ) and #AUTHOR_TAG .', '']",2
"['` See #TAUTHOR_TAG for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG .', 'append ([~,[~,[~).', ' #AUTHOR_TAG b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.', 'refr', 'gram']","['` See #TAUTHOR_TAG for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG .', 'append ([~,[~,[~).', ' #AUTHOR_TAG b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.', 'refrain', 'grammar']","['` See #TAUTHOR_TAG for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG .', 'append ([~,[~,[~).', ' #AUTHOR_TAG b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.', 'refr', '']","['` See #TAUTHOR_TAG for a discussion of the appropriateness of TIG for HPSG and a comparison with other feature logic approaches designed for HPSG .', 'append ([~,[~,[~).', ' #AUTHOR_TAG b) describe a method for compiling implicational constraints into typed feature grammars and interleaving them with relational constraints.', '', '']",0
"['', '', 'headwords in both languages are chosen to force a synchronized alignment (for better or worse) in order to simplify cases involving so-called head-ing.', 'This contrasts with one of the traditional approaches ( e.g. , #TAUTHOR_TAG ; Watanabe 1995 ) to posing the translation problem , i.e. , the approach in which translation problems are seen in terms of bridging the gap between the most natural monolingual representations underlying the sentences of each language .']","['', '', 'headwords in both languages are chosen to force a synchronized alignment (for better or worse) in order to simplify cases involving so-called head-switching.', 'This contrasts with one of the traditional approaches ( e.g. , #TAUTHOR_TAG ; Watanabe 1995 ) to posing the translation problem , i.e. , the approach in which translation problems are seen in terms of bridging the gap between the most natural monolingual representations underlying the sentences of each language .']","['', '', ', headwords in both languages are chosen to force a synchronized alignment (for better or worse) in order to simplify cases involving so-called head-switching.', 'This contrasts with one of the traditional approaches ( e.g. , #TAUTHOR_TAG ; Watanabe 1995 ) to posing the translation problem , i.e. , the approach in which translation problems are seen in terms of bridging the gap between the most natural monolingual representations underlying the sentences of each language .']","['', '', 'For example, headwords in both languages are chosen to force a synchronized alignment (for better or worse) in order to simplify cases involving so-called head-switching.', 'This contrasts with one of the traditional approaches ( e.g. , #TAUTHOR_TAG ; Watanabe 1995 ) to posing the translation problem , i.e. , the approach in which translation problems are seen in terms of bridging the gap between the most natural monolingual representations underlying the sentences of each language .']",1
"['In the transducers produced by the training method described in this paper , the source and target positions are in the set -LCB- -1 , 0,1 -RCB- , though we have also used handcoded transducers #TAUTHOR_TAG and automatically trained transducers ( Alshawi and Douglas 2000 ) with a larger range of positions .']","['In the transducers produced by the training method described in this paper , the source and target positions are in the set -LCB- -1 , 0,1 -RCB- , though we have also used handcoded transducers #TAUTHOR_TAG and automatically trained transducers ( Alshawi and Douglas 2000 ) with a larger range of positions .']","['In the transducers produced by the training method described in this paper , the source and target positions are in the set -LCB- -1 , 0,1 -RCB- , though we have also used handcoded transducers #TAUTHOR_TAG and automatically trained transducers ( Alshawi and Douglas 2000 ) with a larger range of positions .']","['In the transducers produced by the training method described in this paper , the source and target positions are in the set -LCB- -1 , 0,1 -RCB- , though we have also used handcoded transducers #TAUTHOR_TAG and automatically trained transducers ( Alshawi and Douglas 2000 ) with a larger range of positions .']",5
"['At the same time , we believe our method has advantages over the approach developed initially at IBM #TAUTHOR_TAG ; Brown et al. 1993 ) for training translation systems automatically .', 'One is that our method attempts to model the natural decomposition of sentences into phrases.', '', '']","['At the same time , we believe our method has advantages over the approach developed initially at IBM #TAUTHOR_TAG ; Brown et al. 1993 ) for training translation systems automatically .', 'One is that our method attempts to model the natural decomposition of sentences into phrases.', '', '']","['At the same time , we believe our method has advantages over the approach developed initially at IBM #TAUTHOR_TAG ; Brown et al. 1993 ) for training translation systems automatically .', 'One advantage is that our method attempts to model the natural decomposition of sentences into phrases.', '', '']","['At the same time , we believe our method has advantages over the approach developed initially at IBM #TAUTHOR_TAG ; Brown et al. 1993 ) for training translation systems automatically .', 'One advantage is that our method attempts to model the natural decomposition of sentences into phrases.', '', '']",1
"['GEN constructs itssson', '', '', ""9 Moore and Paris also note that `` a generation system must maintain the kinds of information outlined by Grosz and Sidner '' #TAUTHOR_TAG , 203 ) ."", ""Their planner uses plan structures similar to IGEN's, except that the plan operators they use are generally instantiations of rhetorical relations drawn from Rhetorical StructureM"", '']","['IGEN constructs its', '', '', ""9 Moore and Paris also note that `` a generation system must maintain the kinds of information outlined by Grosz and Sidner '' #TAUTHOR_TAG , 203 ) ."", ""Their planner uses plan structures similar to IGEN's, except that the plan operators they use are generally instantiations of rhetorical relations drawn from Rhetorical Structure"", '']","['GEN constructs its', '', '', ""Moore and Paris also note that `` a generation system must maintain the kinds of information outlined by Grosz and Sidner '' #TAUTHOR_TAG , 203 ) ."", ""Their planner uses plan structures similar to IGEN's, except that the plan operators they use are generally instantiations of rhetorical relations drawn from Rhetorical Structure TheoryM"", '']","['', '', '', ""1 Â° The body of a plan can be an action or sequence of actions , a goal or sequence 9 Moore and Paris also note that `` a generation system must maintain the kinds of information outlined by Grosz and Sidner '' #TAUTHOR_TAG , 203 ) ."", ""Their planner uses plan structures similar to IGEN's, except that the plan operators they use are generally instantiations of rhetorical relations drawn from Rhetorical Structure Theory (Mann and Thompson 1987)."", '']",0
"['generally separated the task into distinct text', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component ( Meteer 1994 ; Panaget 1994 ; #TAUTHOR_TAG .', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation (Reiter 1994).']","['generally separated the task into distinct text', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component ( Meteer 1994 ; Panaget 1994 ; #TAUTHOR_TAG .', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation (Reiter 1994).']","['has generally separated the task into distinct text planning', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component ( Meteer 1994 ; Panaget 1994 ; #TAUTHOR_TAG .', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation (Reiter 1994).']","['', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component ( Meteer 1994 ; Panaget 1994 ; #TAUTHOR_TAG .', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation (Reiter 1994).']",0
"['The opposite approach is to simply ignore the limitations of a modular design and proceed as if there need be no interactions between the components.', 'Whatever problems result will be handled as best they can, on a case-by-case basis.', 'This approach is the one taken (implicitly or explicitly) in the majority of generators.', 'In fact , Reiter has even argued in favor of this approach , claiming that the interactions are sufficiently minor to be ignored ( or at least handled on an ad hoc basis ) #TAUTHOR_TAG .', 'While this certainly has appeal as a design methodology, it seems reckless to assume that problems will never appear.', ""Certainly an approach to generation that handle these interactions be an improvement'""]","['The opposite approach is to simply ignore the limitations of a modular design and proceed as if there need be no interactions between the components.', 'Whatever problems result will be handled as best they can, on a case-by-case basis.', 'This approach is the one taken (implicitly or explicitly) in the majority of generators.', 'In fact , Reiter has even argued in favor of this approach , claiming that the interactions are sufficiently minor to be ignored ( or at least handled on an ad hoc basis ) #TAUTHOR_TAG .', 'While this certainly has appeal as a design methodology, it seems reckless to assume that problems will never appear.', 'Certainly an approach to generation that handle these interactions be an improvement,']","['The opposite approach is to simply ignore the limitations of a modular design and proceed as if there need be no interactions between the components.', 'Whatever problems result will be handled as best they can, on a case-by-case basis.', 'This approach is the one taken (implicitly or explicitly) in the majority of generators.', 'In fact , Reiter has even argued in favor of this approach , claiming that the interactions are sufficiently minor to be ignored ( or at least handled on an ad hoc basis ) #TAUTHOR_TAG .', 'While this certainly has appeal as a design methodology, it seems reckless to assume that problems will never appear.', 'Certainly an approach to generation that does handle these interactions would be an improvement,']","['The opposite approach is to simply ignore the limitations of a modular design and proceed as if there need be no interactions between the components.', 'Whatever problems result will be handled as best they can, on a case-by-case basis.', 'This approach is the one taken (implicitly or explicitly) in the majority of generators.', 'In fact , Reiter has even argued in favor of this approach , claiming that the interactions are sufficiently minor to be ignored ( or at least handled on an ad hoc basis ) #TAUTHOR_TAG .', 'While this certainly has appeal as a design methodology, it seems reckless to assume that problems will never appear.', '']",0
"['generally the task into distinct', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component #TAUTHOR_TAG ; Panaget 1994 ; Wanner 1994 ) .', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation (Reiter 1994).']","['generally the task into distinct', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component #TAUTHOR_TAG ; Panaget 1994 ; Wanner 1994 ) .', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation (Reiter 1994).']","['has generally the task into', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component #TAUTHOR_TAG ; Panaget 1994 ; Wanner 1994 ) .', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation (Reiter 1994).']","['', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component #TAUTHOR_TAG ; Panaget 1994 ; Wanner 1994 ) .', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation (Reiter 1994).']",0
"['produce differentxical real a', 'the only goal we could dispense with the feedback mechanism and simply design some sort of discrimination (or similar device to information being expressed', '', 'Something like this approach is in fact used in some systems ( e.g. , Elhadad and Robin 1992 ; PenMan 1989 ; #TAUTHOR_TAG a ) .']","['produce different lexical realizations a', 'the only goal, we could dispense with the feedback mechanism and simply design some sort of discrimination (or similar device) to information being expressed.', '', 'Something like this approach is in fact used in some systems ( e.g. , Elhadad and Robin 1992 ; PenMan 1989 ; #TAUTHOR_TAG a ) .']","['can produce different lexical realizations', 'the only goal, we could dispense with the feedback mechanism and simply design some sort of discrimination network (or similar device) to the information being expressed', '', 'Something like this approach is in fact used in some systems ( e.g. , Elhadad and Robin 1992 ; PenMan 1989 ; #TAUTHOR_TAG a ) .']","['', 'If that were the only goal, we could dispense with the feedback mechanism and simply design some sort of discrimination network (or similar device) to test various features of the information being expressed.', '', 'Something like this approach is in fact used in some systems ( e.g. , Elhadad and Robin 1992 ; PenMan 1989 ; #TAUTHOR_TAG a ) .']",0
"['There have in fact been attempts to develop modified modular designs that allow generators to handle interactions between the components.', ""These include devices such as interleaving the components ( McDonald 1983 ; Appelt 1983 ) , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner #TAUTHOR_TAG ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 1988a , 1988c )"", '', '', '']","['There have in fact been attempts to develop modified modular designs that allow generators to handle interactions between the components.', ""These include devices such as interleaving the components ( McDonald 1983 ; Appelt 1983 ) , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner #TAUTHOR_TAG ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 1988a , 1988c )"", '', '', '']","['There have in fact been attempts to develop modified modular designs that allow generators to handle interactions between the components.', ""These include devices such as interleaving the components ( McDonald 1983 ; Appelt 1983 ) , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner #TAUTHOR_TAG ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 1988a , 1988c )"", '', '', '']","['There have in fact been attempts to develop modified modular designs that allow generators to handle interactions between the components.', ""These include devices such as interleaving the components ( McDonald 1983 ; Appelt 1983 ) , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner #TAUTHOR_TAG ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 1988a , 1988c ) ."", '', '', '']",0
"['There have in fact been attempts to develop modified modular designs that allow generators to handle interactions between the components.', ""These include devices such as interleaving the components ( McDonald 1983 ; #TAUTHOR_TAG , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner ( Mann 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 8a , "", '', '']","['There have in fact been attempts to develop modified modular designs that allow generators to handle interactions between the components.', ""These include devices such as interleaving the components ( McDonald 1983 ; #TAUTHOR_TAG , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner ( Mann 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 1988a ,"", '', '']","['There have in fact been attempts to develop modified modular designs that allow generators to handle interactions between the components.', ""These include devices such as interleaving the components ( McDonald 1983 ; #TAUTHOR_TAG , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner ( Mann 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 1988a , "", '', '']","['There have in fact been attempts to develop modified modular designs that allow generators to handle interactions between the components.', ""These include devices such as interleaving the components ( McDonald 1983 ; #TAUTHOR_TAG , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner ( Mann 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 1988a , 1988c ) ."", '', '']",0
"['One possible response would be to abandon the separation the could be a single component that handles all of the work.', 'This approach has occasionally been taken , as in #AUTHOR_TAG and #AUTHOR_TAG and , at least implicitly , in #TAUTHOR_TAG and #AUTHOR_TAG ; this approach all of the and simplicity of mod design is lost']","['One possible response would be to abandon the separation; the could be a single component that handles all of the work.', 'This approach has occasionally been taken , as in #AUTHOR_TAG and #AUTHOR_TAG and , at least implicitly , in #TAUTHOR_TAG and #AUTHOR_TAG ; this approach all of the and simplicity of modular design is lost']","['One possible response would be to abandon the separation; the generator could be a single component that handles all of the work.', 'This approach has occasionally been taken , as in #AUTHOR_TAG and #AUTHOR_TAG and , at least implicitly , in #TAUTHOR_TAG and #AUTHOR_TAG ; this approach all of the flexibility and simplicity of modular design is lost .']","['One possible response would be to abandon the separation; the generator could be a single component that handles all of the work.', 'This approach has occasionally been taken , as in #AUTHOR_TAG and #AUTHOR_TAG and , at least implicitly , in #TAUTHOR_TAG and #AUTHOR_TAG ; however , under this approach , all of the flexibility and simplicity of modular design is lost .']",0
"['in to develop modified modular designsators handle components.', ""These include devices such as inter ( 3 ; Appelt 83 , backtracking on failure ( Appelt 1985 ; Nogier 89 ) , allowing the linguistic component to interrogate the planner ( 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning #TAUTHOR_TAG a , 1988c ) ."", 'these approaches', '', '']","['in to develop modified modular designs generators handle components.', ""These include devices such as ( ; Appelt 1983 , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner ( 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning #TAUTHOR_TAG a , 1988c ) ."", 'these approaches,', '', '']","['in to develop modified modular designsators handle the components.', ""These include devices such as inter ( ; Appelt 1983 , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner ( Mann 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning #TAUTHOR_TAG a , 1988c ) ."", '', '', '']","['', ""These include devices such as interleaving the components ( McDonald 1983 ; Appelt 1983 ) , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner ( Mann 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning #TAUTHOR_TAG a , 1988c ) ."", '', '', '']",0
"['Hovy has described another text planner that builds similar plans #TAUTHOR_TAG b ) .', 'pattern', '', '', '']","['Hovy has described another text planner that builds similar plans #TAUTHOR_TAG b ) .', 'pattern;', '', '', '']","['Hovy has described another text planner that builds similar plans #TAUTHOR_TAG b ) .', '', '', '', '']","['Hovy has described another text planner that builds similar plans #TAUTHOR_TAG b ) .', '', '', '', '']",0
"['Research in natural language generation has generally separated the task into distinct text planning and linguistic', 'The information linguistic, information', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components (McDonald 1988), and several systems have indeed added an additional component between the planner and the linguistic component (Meteer 1994;Panaget 1994;Wanner 1994).', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation #TAUTHOR_TAG .']","['Research in natural language generation has generally separated the task into distinct text planning and linguistic', 'The information linguistic component, information', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components (McDonald 1988), and several systems have indeed added an additional component between the planner and the linguistic component (Meteer 1994;Panaget 1994;Wanner 1994).', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation #TAUTHOR_TAG .']","['Research in natural language generation has generally separated the task into distinct text planning and lingu', 'the information the linguistic component, the information', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components (McDonald 1988), and several systems have indeed added an additional component between the planner and the linguistic component (Meteer 1994;Panaget 1994;Wanner 1994).', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation #TAUTHOR_TAG .']","['Research in natural language generation has generally separated the task into distinct text planning and linguistic components.', '', '', '', '', '', 'McDonald has even argued for extending the model to a large number of components (McDonald 1988), and several systems have indeed added an additional component between the planner and the linguistic component (Meteer 1994;Panaget 1994;Wanner 1994).', 'Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation #TAUTHOR_TAG .']",0
"['Research natural generation has generally separated the task into distinct text planning and linguistic', 'The,', '""strategic ""tactical"" ( e.g. , McKeown 1985 ; Thompson 1977 ; Danlos 1987 ) 1 , ""planning"" and ""realization"" ( e.g. , McDonald 1983 ; #TAUTHOR_TAG a ) , or simply ""what to say"" versus ""how to say it"" ( e.g. , Danlos 1987 ; Reithinger 1990 ) .', '', '', '', 'pip a consensus underlying most recent in']","['Research natural generation has generally separated the task into distinct text planning and linguistic', 'The component,', '""strategic"" ""tactical"" ( e.g. , McKeown 1985 ; Thompson 1977 ; Danlos 1987 ) 1 , ""planning"" and ""realization"" ( e.g. , McDonald 1983 ; #TAUTHOR_TAG a ) , or simply ""what to say"" versus ""how to say it"" ( e.g. , Danlos 1987 ; Reithinger 1990 ) .', '', '', '', 'a consensus underlying most recent in']","['Research natural language generation has generally separated the task into distinct text planning and lingu', '', '""strategic ""tactical"" components ( e.g. , McKeown 1985 ; Thompson 1977 ; Danlos 1987 ) 1 , ""planning"" and ""realization"" ( e.g. , McDonald 1983 ; #TAUTHOR_TAG a ) , or simply ""what to say"" versus ""how to say it"" ( e.g. , Danlos 1987 ; Reithinger 1990 ) .', '', '', '', 'a consensus architecture underlying most recent work in']","['Research in natural language generation has generally separated the task into distinct text planning and linguistic components.', '', 'The names given to the components vary ; they have been called ""strategic"" and ""tactical"" components ( e.g. , McKeown 1985 ; Thompson 1977 ; Danlos 1987 ) 1 , ""planning"" and ""realization"" ( e.g. , McDonald 1983 ; #TAUTHOR_TAG a ) , or simply ""what to say"" versus ""how to say it"" ( e.g. , Danlos 1987 ; Reithinger 1990 ) .', '', '', '', '']",0
"['Surveys and articles on the topic include #AUTHOR_TAG , de #AUTHOR_TAG , and #TAUTHOR_TAG .', 'of proceed a pace, we aim nonetheless to include here enough details to make the present paper self-contained.']","['Surveys and articles on the topic include #AUTHOR_TAG , de #AUTHOR_TAG , and #TAUTHOR_TAG .', 'of proceeding a pace, we aim nonetheless to include here enough details to make the present paper self-contained.']","['Surveys and articles on the topic include #AUTHOR_TAG , de #AUTHOR_TAG , and #TAUTHOR_TAG .', 'of proceed a slightly slower pace, we aim nonetheless to include here enough details to make the present paper self-contained.']","['Surveys and articles on the topic include #AUTHOR_TAG , de #AUTHOR_TAG , and #TAUTHOR_TAG .', 'Still, at the risk of proceeding at a slightly slower pace, we aim nonetheless to include here enough details to make the present paper self-contained.']",0
"['', 'atory categ itself all (or only) conc', 'An approach ( also based on regulation of the succession of rule application ) to the associated problem of spurious ambiguity is given in #TAUTHOR_TAG but again , to our knowledge , there is no predictive relation between incremental combinatory processing and the kind of processing phenomena cited in the introduction .']","['', 'categorial itself all (or only)', 'An approach ( also based on regulation of the succession of rule application ) to the associated problem of spurious ambiguity is given in #TAUTHOR_TAG but again , to our knowledge , there is no predictive relation between incremental combinatory processing and the kind of processing phenomena cited in the introduction .']","['', 'atory categ itself all (or only)', 'An approach ( also based on regulation of the succession of rule application ) to the associated problem of spurious ambiguity is given in #TAUTHOR_TAG but again , to our knowledge , there is no predictive relation between incremental combinatory processing and the kind of processing phenomena cited in the introduction .']","['', '', 'An approach ( also based on regulation of the succession of rule application ) to the associated problem of spurious ambiguity is given in #TAUTHOR_TAG but again , to our knowledge , there is no predictive relation between incremental combinatory processing and the kind of processing phenomena cited in the introduction .']",0
"['One approach to this problem consists in defining , within the Cut-free atomic-id space , normal form derivations in which the succession of rule application is regulated #TAUTHOR_TAG , Hepple 1990 , Hendriks 1993 ) .', 'Each sequent has a distinguished category formula (underlined) on which rule applications are keyed: In the regulated calculus there is no spurious ambiguity, and provided there is no explicit or implicit antecedent product, i.e., provided .L is not needed, F ~ A is a theorem of the calculus if F ~ A is a theorem of the regulated calculus.', '', '']","['One approach to this problem consists in defining , within the Cut-free atomic-id space , normal form derivations in which the succession of rule application is regulated #TAUTHOR_TAG , Hepple 1990 , Hendriks 1993 ) .', 'Each sequent has a distinguished category formula (underlined) on which rule applications are keyed: In the regulated calculus there is no spurious ambiguity, and provided there is no explicit or implicit antecedent product, i.e., provided .L is not needed, F ~ A is a theorem of the calculus iff F ~ A is a theorem of the regulated calculus.', '', '']","['One approach to this problem consists in defining , within the Cut-free atomic-id space , normal form derivations in which the succession of rule application is regulated #TAUTHOR_TAG , Hepple 1990 , Hendriks 1993 ) .', 'Each sequent has a distinguished category formula (underlined) on which rule applications are keyed: In the regulated calculus there is no spurious ambiguity, and provided there is no explicit or implicit antecedent product, i.e., provided .L is not needed, F ~ A is a theorem of the Lambek calculus iff F ~ A is a theorem of the regulated calculus.', '', '']","['One approach to this problem consists in defining , within the Cut-free atomic-id space , normal form derivations in which the succession of rule application is regulated #TAUTHOR_TAG , Hepple 1990 , Hendriks 1993 ) .', 'Each sequent has a distinguished category formula (underlined) on which rule applications are keyed: In the regulated calculus there is no spurious ambiguity, and provided there is no explicit or implicit antecedent product, i.e., provided .L is not needed, F ~ A is a theorem of the Lambek calculus iff F ~ A is a theorem of the regulated calculus.', '', '']",0
"['DA classification using words is based on the observation that different DAs use distinctive word strings.', 'It is known that certain cue words and phrases #TAUTHOR_TAG can serve as explicit indicators of discourse structure .', 'Similarly find and', '', '', '', '', '', '']","['DA classification using words is based on the observation that different DAs use distinctive word strings.', 'It is known that certain cue words and phrases #TAUTHOR_TAG can serve as explicit indicators of discourse structure .', 'Similarly, find and', '', '', '', '', '', '']","['DA classification using words is based on the observation that different DAs use distinctive word strings.', 'It is known that certain cue words and phrases #TAUTHOR_TAG can serve as explicit indicators of discourse structure .', 'Similarly we find and', '', '', '', '', '', '']","['DA classification using words is based on the observation that different DAs use distinctive word strings.', 'It is known that certain cue words and phrases #TAUTHOR_TAG can serve as explicit indicators of discourse structure .', '', '', '', '', '', '', '']",4
"['', '', 'many other classifier architectures are applicable to the tasks discussed, in particular to DA classification.', 'A nonprobabilistic approach for DA labeling proposed by Samuel , Carberry , and Vijay- #AUTHOR_TAG is transformation-based learning #TAUTHOR_TAG .', 'tasks']","['', '', 'many other classifier architectures are applicable to the tasks discussed, in particular to DA classification.', 'A nonprobabilistic approach for DA labeling proposed by Samuel , Carberry , and Vijay- #AUTHOR_TAG is transformation-based learning #TAUTHOR_TAG .', 'tasks']","['', '', 'many other classifier architectures are applicable to the tasks discussed, in particular to DA classification.', 'A nonprobabilistic approach for DA labeling proposed by Samuel , Carberry , and Vijay- #AUTHOR_TAG is transformation-based learning #TAUTHOR_TAG .', '']","['', '', 'However, many other classifier architectures are applicable to the tasks discussed, in particular to DA classification.', 'A nonprobabilistic approach for DA labeling proposed by Samuel , Carberry , and Vijay- #AUTHOR_TAG is transformation-based learning #TAUTHOR_TAG .', '']",1
"['The combination of likelihood and prior modeling , HMMs , and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition ( Bahl , Jelinek , and Mercer 1983 ) and tagging #TAUTHOR_TAG .', 'It maximizes the probability of getting the entire DA sequence correct, but it does not necessarily find the DA sequence that has the most DA labels correct (Dermatas and Kokkinakis 1995).', '', '']","['The combination of likelihood and prior modeling , HMMs , and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition ( Bahl , Jelinek , and Mercer 1983 ) and tagging #TAUTHOR_TAG .', 'It maximizes the probability of getting the entire DA sequence correct, but it does not necessarily find the DA sequence that has the most DA labels correct (Dermatas and Kokkinakis 1995).', '', '']","['The combination of likelihood and prior modeling , HMMs , and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition ( Bahl , Jelinek , and Mercer 1983 ) and tagging #TAUTHOR_TAG .', 'It maximizes the probability of getting the entire DA sequence correct, but it does not necessarily find the DA sequence that has the most DA labels correct (Dermatas and Kokkinakis 1995).', '', '']","['The combination of likelihood and prior modeling , HMMs , and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition ( Bahl , Jelinek , and Mercer 1983 ) and tagging #TAUTHOR_TAG .', 'It maximizes the probability of getting the entire DA sequence correct, but it does not necessarily find the DA sequence that has the most DA labels correct (Dermatas and Kokkinakis 1995).', '', '']",1
"['The combination of likelihood and prior modeling, Hs, and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition (Bahl, Jelinek, and Mercer 1983) and tagging (Church 1988).', 'It maximizes the probability of getting the entire DA sequence correct , but it does not necessarily find the DA sequence that has the most DA labels correct #TAUTHOR_TAG .', '', '']","['The combination of likelihood and prior modeling, HMMs, and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition (Bahl, Jelinek, and Mercer 1983) and tagging (Church 1988).', 'It maximizes the probability of getting the entire DA sequence correct , but it does not necessarily find the DA sequence that has the most DA labels correct #TAUTHOR_TAG .', '', '']","['The combination of likelihood and prior modeling, HMMs, and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition (Bahl, Jelinek, and Mercer 1983) and tagging (Church 1988).', 'It maximizes the probability of getting the entire DA sequence correct , but it does not necessarily find the DA sequence that has the most DA labels correct #TAUTHOR_TAG .', '', '']","['The combination of likelihood and prior modeling, HMMs, and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition (Bahl, Jelinek, and Mercer 1983) and tagging (Church 1988).', 'It maximizes the probability of getting the entire DA sequence correct , but it does not necessarily find the DA sequence that has the most DA labels correct #TAUTHOR_TAG .', '', '']",0
"[""This equivalence is doing essentially the same job as Pereira 's pronoun abstraction schema in #TAUTHOR_TAG ."", 'It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations.']","[""This equivalence is doing essentially the same job as Pereira 's pronoun abstraction schema in #TAUTHOR_TAG ."", 'It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations.']","[""This equivalence is doing essentially the same job as Pereira 's pronoun abstraction schema in #TAUTHOR_TAG ."", 'It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations.']","[""This equivalence is doing essentially the same job as Pereira 's pronoun abstraction schema in #TAUTHOR_TAG ."", 'It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations.']",1
"['s here a typed logic, augmented with constructs representing the interpretation of context-dependent elements (pronouns, ellipsis, etc.).', 'These constructs correspond as directly as possible to properties of the linguistic structure that express them and are , to as small an extent as possible , dependent on the requirements of contextual resolution ( unlike , say , the metavariables of standard QLFs [ #TAUTHOR_TAG ] , or the labels of UDRS [ Reyle 1996 ] , which are motivated entirely by the mechanisms that operate on them after grammatical processing )', '', '']","['here, a typed logic, augmented with constructs representing the interpretation of context-dependent elements (pronouns, ellipsis, etc.).', 'These constructs correspond as directly as possible to properties of the linguistic structure that express them and are , to as small an extent as possible , dependent on the requirements of contextual resolution ( unlike , say , the metavariables of standard QLFs [ #TAUTHOR_TAG ] , or the labels of UDRS [ Reyle 1996 ] , which are motivated entirely by the mechanisms that operate on them after grammatical processing )', '', '']","['s here a typed higher-order logic, augmented with constructs representing the interpretation of context-dependent elements (pronouns, ellipsis,, etc.).', 'These constructs correspond as directly as possible to properties of the linguistic structure that express them and are , to as small an extent as possible , dependent on the requirements of contextual resolution ( unlike , say , the metavariables of standard QLFs [ #TAUTHOR_TAG ] , or the labels of UDRS [ Reyle 1996 ] , which are motivated entirely by the mechanisms that operate on them after grammatical processing )', '', '']","['What is required is that QLFs are, as here, expressed in a typed higher-order logic, augmented with constructs representing the interpretation of context-dependent elements (pronouns, ellipsis, focus, etc.).', 'These constructs correspond as directly as possible to properties of the linguistic structure that express them and are , to as small an extent as possible , dependent on the requirements of contextual resolution ( unlike , say , the metavariables of standard QLFs [ #TAUTHOR_TAG ] , or the labels of UDRS [ Reyle 1996 ] , which are motivated entirely by the mechanisms that operate on them after grammatical processing ) .', '', '']",0
"['a dissaction with certain quasiCLE', 'In the CLE-QLF approach, as rationally reconstructed by #TAUTHOR_TAG and #AUTHOR_TAG , the context-independent meaning of a sentence is given by one or more QLFs that are built directly from syntactic and semantic rules.', 'Just as here, these QLFs repre- sent the basic predicate argument structure of the sentence, and contain constructs which represent those aspects of the meaning of the sentence that are dependent on context.']","['a dissatisfaction with certain', 'In the CLE-QLF approach, as rationally reconstructed by #TAUTHOR_TAG and #AUTHOR_TAG , the context-independent meaning of a sentence is given by one or more QLFs that are built directly from syntactic and semantic rules.', 'Just as here, these QLFs repre- sent the basic predicate argument structure of the sentence, and contain constructs which represent those aspects of the meaning of the sentence that are dependent on context.']","['a dissatisfaction with certain aspects quasiCLE', 'In the CLE-QLF approach, as rationally reconstructed by #TAUTHOR_TAG and #AUTHOR_TAG , the context-independent meaning of a sentence is given by one or more QLFs that are built directly from syntactic and semantic rules.', 'Just as here, these QLFs repre- sent the basic predicate argument structure of the sentence, and contain constructs which represent those aspects of the meaning of the sentence that are dependent on context.']","['', 'In the CLE-QLF approach, as rationally reconstructed by #TAUTHOR_TAG and #AUTHOR_TAG , the context-independent meaning of a sentence is given by one or more QLFs that are built directly from syntactic and semantic rules.', 'Just as here, these QLFs repre- sent the basic predicate argument structure of the sentence, and contain constructs which represent those aspects of the meaning of the sentence that are dependent on context.']",1
"['A third problem arises with the approach to the semantics of QLFs that this notion of the relationship between QLF and RQLF encourages one to adopt : it is that taken by #TAUTHOR_TAG .', 'This describes the semantics of QLFs via a supervaluation over the semantics of the RQLFs that they subsume.', 'Although the problem does not arise for the simple fragment they illustrate there, if their approach were extended to cover a wider range of constructions, it would be found that many QLFs subsumed RQLFs that are not actually permitted by the resolution: for example, those that can only arise via a violation of scoping or binding constraints', 'resolution (', '', '', '', '', '', '']","['A third problem arises with the approach to the semantics of QLFs that this notion of the relationship between QLF and RQLF encourages one to adopt : it is that taken by #TAUTHOR_TAG .', 'This describes the semantics of QLFs via a supervaluation over the semantics of the RQLFs that they subsume.', 'Although the problem does not arise for the simple fragment they illustrate there, if their approach were extended to cover a wider range of constructions, it would be found that many QLFs subsumed RQLFs that are not actually permitted by the resolution rules: for example, those that can only arise via a violation of scoping or binding constraints.', 'resolution (for', '', '', '', '', '', '']","['A third problem arises with the approach to the semantics of QLFs that this notion of the relationship between QLF and RQLF encourages one to adopt : it is that taken by #TAUTHOR_TAG .', 'This describes the semantics of QLFs via a supervaluation over the semantics of the RQLFs that they subsume.', 'Although the problem does not arise for the simple fragment they illustrate there, if their approach were extended to cover a wider range of constructions, it would be found that many QLFs subsumed RQLFs that are not actually permitted by the resolution rules: for example, those that can only arise via a violation of scoping or binding constraints.', 'resolution rules (', '', '', '', '', '', '']","['A third problem arises with the approach to the semantics of QLFs that this notion of the relationship between QLF and RQLF encourages one to adopt : it is that taken by #TAUTHOR_TAG .', 'This describes the semantics of QLFs via a supervaluation over the semantics of the RQLFs that they subsume.', 'Although the problem does not arise for the simple fragment they illustrate there, if their approach were extended to cover a wider range of constructions, it would be found that many QLFs subsumed RQLFs that are not actually permitted by the resolution rules: for example, those that can only arise via a violation of scoping or binding constraints.', '', '', '', '', '', '', '']",1
"['We then go on to compare the current approach with that of some other theories with similar aims : the `` standard version of quasi-logical form implemented in the Core Language Engine , as rationally reconstructed by #TAUTHOR_TAG and #AUTHOR_TAG ; underspecified Discourse Representation Theory ( Reyle 1993 ) ; and the ``ue language approach .']","['We then go on to compare the current approach with that of some other theories with similar aims : the `` standard version of quasi-logical form implemented in the Core Language Engine , as rationally reconstructed by #TAUTHOR_TAG and #AUTHOR_TAG ; underspecified Discourse Representation Theory ( Reyle 1993 ) ; and the `` glue language approach .']","['We then go on to compare the current approach with that of some other theories with similar aims : the `` standard version of quasi-logical form implemented in the Core Language Engine , as rationally reconstructed by #TAUTHOR_TAG and #AUTHOR_TAG ; underspecified Discourse Representation Theory ( Reyle 1993 ) ; and the ``ue language approach #AUTHOR_TAG .']","['We then go on to compare the current approach with that of some other theories with similar aims : the `` standard version of quasi-logical form implemented in the Core Language Engine , as rationally reconstructed by #TAUTHOR_TAG and #AUTHOR_TAG ; underspecified Discourse Representation Theory ( Reyle 1993 ) ; and the `` glue language approach of #AUTHOR_TAG .']",1
"[""The starting point for the approach followed here was a dissatisfaction with certain aspects of the theory of quasi-logical form as described in #TAUTHOR_TAG , 1992 ) , and implemented in SRI 's Core Language Engine ( CLE ) ."", '', '']","[""The starting point for the approach followed here was a dissatisfaction with certain aspects of the theory of quasi-logical form as described in #TAUTHOR_TAG , 1992 ) , and implemented in SRI 's Core Language Engine ( CLE ) ."", '', '']","[""The starting point for the approach followed here was a dissatisfaction with certain aspects of the theory of quasi-logical form as described in #TAUTHOR_TAG , 1992 ) , and implemented in SRI 's Core Language Engine ( CLE ) ."", '', '']","[""The starting point for the approach followed here was a dissatisfaction with certain aspects of the theory of quasi-logical form as described in #TAUTHOR_TAG , 1992 ) , and implemented in SRI 's Core Language Engine ( CLE ) ."", '', '']",1
"['We assume that every determiner has its own equivalence , which resolves it as a quantifier : sometimes this can be quite a complicated matter , as with any #TAUTHOR_TAG , which will resolve in different ways depending on its linguistic context , but here we avoid this complexity.']","['We assume that every determiner has its own equivalence , which resolves it as a quantifier : sometimes this can be quite a complicated matter , as with any #TAUTHOR_TAG , which will resolve in different ways depending on its linguistic context , but here we avoid this complexity.']","['We assume that every determiner has its own equivalence , which resolves it as a quantifier : sometimes this can be quite a complicated matter , as with any #TAUTHOR_TAG , which will resolve in different ways depending on its linguistic context , but here we avoid this complexity.']","['We assume that every determiner has its own equivalence , which resolves it as a quantifier : sometimes this can be quite a complicated matter , as with any #TAUTHOR_TAG , which will resolve in different ways depending on its linguistic context , but here we avoid this complexity.']",0
"['several stateg might be pursued.', 'One is to adopt Pinkal\'s ""radical underspecification"" (Pinkal 1995) and use underspecified representations of ambig', ""The more conservative approach is to try to integrate existing statistical disambiguation schemes for QLFs , either individually or in a `` packed '' structure #TAUTHOR_TAG , with the resolution process as described here ."", '']","['several stategies might be pursued.', 'One is to adopt Pinkal\'s ""radical underspecification"" (Pinkal 1995) and use underspecified representations of', ""The more conservative approach is to try to integrate existing statistical disambiguation schemes for QLFs , either individually or in a `` packed '' structure #TAUTHOR_TAG , with the resolution process as described here ."", '']","['several stategies might be pursued.', 'One is to adopt Pinkal\'s ""radical underspecification"" approach (Pinkal 1995) and use underspecified representations of ambig', ""The more conservative approach is to try to integrate existing statistical disambiguation schemes for QLFs , either individually or in a `` packed '' structure #TAUTHOR_TAG , with the resolution process as described here ."", '']","['There are several stategies that might be pursued.', 'One is to adopt Pinkal\'s ""radical underspecification"" approach (Pinkal 1995) and use underspecified representations for all types of ambiguity, even syntactic ambiguity.', ""The more conservative approach is to try to integrate existing statistical disambiguation schemes for QLFs , either individually or in a `` packed '' structure #TAUTHOR_TAG , with the resolution process as described here ."", '']",3
"['implement a deduct theoryifier scope using the conditional equival mechanism.', 'The version proposed here combines a basic insight from #AUTHOR_TAG with higher-order unification to give an analysis that has a strong resemblance to that proposed in #TAUTHOR_TAG , 1991 ) , with some differences that are commented on below .', '', '', '']","['implement a deductive theory quantifier scope using the conditional equivalence mechanism.', 'The version proposed here combines a basic insight from #AUTHOR_TAG with higher-order unification to give an analysis that has a strong resemblance to that proposed in #TAUTHOR_TAG , 1991 ) , with some differences that are commented on below .', '', '', '']","['a deductive theoryifier scope using the conditional equivalence mechanism.', 'The version proposed here combines a basic insight from #AUTHOR_TAG with higher-order unification to give an analysis that has a strong resemblance to that proposed in #TAUTHOR_TAG , 1991 ) , with some differences that are commented on below .', '', '', '']","['We can implement a deductive theory of quantifier scope using the conditional equivalence mechanism.', 'The version proposed here combines a basic insight from #AUTHOR_TAG with higher-order unification to give an analysis that has a strong resemblance to that proposed in #TAUTHOR_TAG , 1991 ) , with some differences that are commented on below .', '', '', '']",1
"['It is interesting to compare this analysis with that described in Dalrymple , Shieber , and #AUTHOR_TAG and #TAUTHOR_TAG , 1991 ) .', 'that in their treatment, quantified noun phrases are treated in two', '', '']","['It is interesting to compare this analysis with that described in Dalrymple , Shieber , and #AUTHOR_TAG and #TAUTHOR_TAG , 1991 ) .', 'that in their treatment, quantified noun phrases are treated in two', '', '']","['It is interesting to compare this analysis with that described in Dalrymple , Shieber , and #AUTHOR_TAG and #TAUTHOR_TAG , 1991 ) .', 'that in their treatment, quantified noun phrases are treated in', '', '']","['It is interesting to compare this analysis with that described in Dalrymple , Shieber , and #AUTHOR_TAG and #TAUTHOR_TAG , 1991 ) .', '', '', '']",1
"['only the available five relative scopings of the quantifiers are produced #TAUTHOR_TAG , 47 ) , but without the need for a free variable constraint -- the HOU algorithm will not produce any solutions in which a previously bound variable becomes free ;¢ the equivalences are reversible , and thus the sentences cart be generatedoped forms']","['only the available five relative scopings of the quantifiers are produced #TAUTHOR_TAG , 47 ) , but without the need for a free variable constraint -- the HOU algorithm will not produce any solutions in which a previously bound variable becomes free ; the equivalences are reversible , and thus the sentences cart be generated scoped forms']","['only the available five relative scopings of the quantifiers are produced #TAUTHOR_TAG , 47 ) , but without the need for a free variable constraint -- the HOU algorithm will not produce any solutions in which a previously bound variable becomes free ;¢ the equivalences are reversible , and thus the above sentences cart be generatedoped logical forms']",[''],0
"['Developing a calculus for reasoning with QLFs is too large a task to be undertaken here.', 'But the general outlines are reasonably clear , and we can adapt some of the UDRS #TAUTHOR_TAG work to our own framework .', '', '']","['Developing a calculus for reasoning with QLFs is too large a task to be undertaken here.', 'But the general outlines are reasonably clear , and we can adapt some of the UDRS #TAUTHOR_TAG work to our own framework .', '', '']","['Developing a calculus for reasoning with QLFs is too large a task to be undertaken here.', 'But the general outlines are reasonably clear , and we can adapt some of the UDRS #TAUTHOR_TAG work to our own framework .', '', '']","['Developing a calculus for reasoning with QLFs is too large a task to be undertaken here.', 'But the general outlines are reasonably clear , and we can adapt some of the UDRS #TAUTHOR_TAG work to our own framework .', '', '']",5
"[' #TAUTHOR_TAG present an illustrative first-order fragment along these lines and are able to supply a coherent formal semantics for the CLF-QLFs themselves , using a technique essentially equivalent to supervaluations : a QLF is true iff all its possible RQLFs are , false iff they are all false , and undefined otherwise']","[' #TAUTHOR_TAG present an illustrative first-order fragment along these lines and are able to supply a coherent formal semantics for the CLF-QLFs themselves , using a technique essentially equivalent to supervaluations : a QLF is true iff all its possible RQLFs are , false iff they are all false , and undefined otherwise']","[' #TAUTHOR_TAG present an illustrative first-order fragment along these lines and are able to supply a coherent formal semantics for the CLF-QLFs themselves , using a technique essentially equivalent to supervaluations : a QLF is true iff all its possible RQLFs are , false iff they are all false , and undefined otherwise .']","[' #TAUTHOR_TAG present an illustrative first-order fragment along these lines and are able to supply a coherent formal semantics for the CLF-QLFs themselves , using a technique essentially equivalent to supervaluations : a QLF is true iff all its possible RQLFs are , false iff they are all false , and undefined otherwise .']",0
"['heavily exploitedistic', 'encouraged many researchers to move away from extensive domain andistic knowledge and to embark instead upon knowledge-or anhora resolution', 'ev  ; Williams , Harvey , and Preston 1996 ; #TAUTHOR_TAG ; Mitkov 1996 , 1998b ) .']","['heavily exploited linguistic', 'encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution', '; Williams , Harvey , and Preston 1996 ; #TAUTHOR_TAG ; Mitkov 1996 , 1998b ) .']","['heavily exploitedistic knowledge', 'encouraged many researchers to move away from extensive domain andistic knowledge and to embark instead upon knowledge-or anaphora resolution strategies.', '; Williams , Harvey , and Preston 1996 ; #TAUTHOR_TAG ; Mitkov 1996 , 1998b ) .']","['', '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impetus to core', '', '', 'the continuing interest in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; Strube and Hahn 1996 ; #TAUTHOR_TAG ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 998a , ', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impetus to coreference', '', '', 'the continuing interest in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; Strube and Hahn 1996 ; #TAUTHOR_TAG ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a ,', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task a considerable impetus to core', '', '', 'the continuing interest in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; Strube and Hahn 1996 ; #TAUTHOR_TAG ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a , ', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', '', '', '']",0
"[""Tetreault 's contribution features comparative evaluation involving the author 's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm ( LRC ) as well as three other pronoun resolution methods : Hobbs 's naive algorithm ( Hobbs 1978 ) , BFP ( Brennan , Friedman , and Pollard 1987 ) , and Strube 's 5list approach #TAUTHOR_TAG ."", '', '']","[""Tetreault 's contribution features comparative evaluation involving the author 's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm ( LRC ) as well as three other pronoun resolution methods : Hobbs 's naive algorithm ( Hobbs 1978 ) , BFP ( Brennan , Friedman , and Pollard 1987 ) , and Strube 's 5list approach #TAUTHOR_TAG ."", '', '']","[""Tetreault 's contribution features comparative evaluation involving the author 's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm ( LRC ) as well as three other pronoun resolution methods : Hobbs 's naive algorithm ( Hobbs 1978 ) , BFP ( Brennan , Friedman , and Pollard 1987 ) , and Strube 's 5list approach #TAUTHOR_TAG ."", '', '']","[""Tetreault 's contribution features comparative evaluation involving the author 's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm ( LRC ) as well as three other pronoun resolution methods : Hobbs 's naive algorithm ( Hobbs 1978 ) , BFP ( Brennan , Friedman , and Pollard 1987 ) , and Strube 's 5list approach #TAUTHOR_TAG ."", '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impus core', '', '', 'form Abracos and Lopes  ; Strube and Hahn 1996 ; Hahn and Strube 1997 ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution #TAUTHOR_TAG a , 2001b ) .', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impetus coreference', '', '', 'form Abracos and Lopes ; Strube and Hahn 1996 ; Hahn and Strube 1997 ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution #TAUTHOR_TAG a , 2001b ) .', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task a considerable impetus core', '', '', 'ised form Abracos and L ; Strube and Hahn 1996 ; Hahn and Strube 1997 ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution #TAUTHOR_TAG a , 2001b ) .', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', '', '', '']",0
"['of the in anap heavily exploited domain andistic knowledgener 9oyell', 'robust encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution', 'istic and reported promising in-or operational environments ( Dagan and Itai 1990 , 99 ; Lappin and Leass 1994 ; Nasukawa 1994 ; #TAUTHOR_TAG ; Williams , Harvey , and Preston 1996 ;win 1997 ; Mit 6 , b']","['of the in anaphora heavily exploited domain and guistic knowledge', 'robust encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution', 'linguistic and reported promising in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; Nasukawa 1994 ; #TAUTHOR_TAG ; Williams , Harvey , and Preston 1996 ; Baldwin 1997 ; Mitkov ,']","['of in anap heavily exploited domain and- guistic knowledgeell', 'robust encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies.', 'and reported promising results in-or operational environments ( Dagan and Itai 1990 , 99 ; Lappin and Leass 1994 ; Nasukawa 1994 ; #TAUTHOR_TAG ; Williams , Harvey , and Preston 1996 ;win 1997 ; Mit , b']","['', 'However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies.', 'A number of proposals in the 1990s deliberately limited the extent to which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; Nasukawa 1994 ; #TAUTHOR_TAG ; Williams , Harvey , and Preston 1996 ; Baldwin 1997 ; Mitkov 1996 , 1998b ) .']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impus core', '', '', 'andstaff the continuing interest in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; #TAUTHOR_TAG ; Hahn and Strube 1997 ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998 , .']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impetus coreference', '', '', 'and the continuing interest in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; #TAUTHOR_TAG ; Hahn and Strube 1997 ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a , .']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task a considerable impetus core', '', '', 'and the continuing interest in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; #TAUTHOR_TAG ; Hahn and Strube 1997 ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a , .']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impus core', '', '', 'Other milestones of recent research include the deployment of probabilistic and machine learning techniques ( Aone and Bennett 1995 ; #TAUTHOR_TAG ; Ge , Hale , and Charniak 1998 ; Cardie and Wagstaff 1999 ; the continuing interest in , used rev form ( Abrac and', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impetus coreference', '', '', 'Other milestones of recent research include the deployment of probabilistic and machine learning techniques ( Aone and Bennett 1995 ; #TAUTHOR_TAG ; Ge , Hale , and Charniak 1998 ; Cardie and Wagstaff 1999 ; the continuing interest in , used revised form ( Abracos and', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task a considerable impetus core', '', '', 'Other milestones of recent research include the deployment of probabilistic and machine learning techniques ( Aone and Bennett 1995 ; #TAUTHOR_TAG ; Ge , Hale , and Charniak 1998 ; Cardie and Wagstaff 1999 ; the continuing interest in , used either revised form ( Abrac and', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', '', '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task) gave a considerable impetus to the development of coreference resolution algorithms and, such as in', 'decade a of Japanese', 'mult McKee Azzam , Hys , and Gaizausas 199 ;abagiu and Maiorano  ; Mitkov and Barbu 2000 ; #TAUTHOR_TAG ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task gave a considerable impetus to the development of coreference resolution algorithms and systems, such as in', 'decade a of Japanese,', 'McKee Azzam , Humphreys , and Gaizauskas 1998 ; Harabagiu and Maiorano ; Mitkov and Barbu 2000 ; #TAUTHOR_TAG ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task) gave a considerable impetus to the development of coreference resolution algorithms and, such as in', 'a number of', 'mult McK Azzam , Hys , and Gaizausas 1998 ;abagiu and Maior ; Mitkov and Barbu 2000 ; #TAUTHOR_TAG ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', 'Against the background of a growing interest in multilingual NLP , multilingual anaphora / coreference resolution has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; Harabagiu and Maiorano 2000 ; Mitkov and Barbu 2000 ; #TAUTHOR_TAG ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']",0
"['of the in anap heavily exploitedistic knowledge', 'robustLP systems encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution', 'istic knowledge and reported promising results in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; #TAUTHOR_TAG ; Kennedy and Boguraev 1996 ; Williams , Harvey , and Preston 1996 ;win 1997 ; ,']","['of the in anaphora heavily exploited guistic knowledge', 'robust NLP systems encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution', 'linguistic knowledge and reported promising results in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; #TAUTHOR_TAG ; Kennedy and Boguraev 1996 ; Williams , Harvey , and Preston 1996 ; Baldwin 1997 ; ,']","['of in anap heavily exploited- guistic knowledge', 'robust practical NLP systems encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies.', 'or linguistic knowledge and reported promising results in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; #TAUTHOR_TAG ; Kennedy and Boguraev 1996 ; Williams , Harvey , and Preston 1996 ;win 1997 ; ,']","['', 'However, the pressing need for the development of robust and inexpensive solutions to meet the demands of practical NLP systems encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor anaphora resolution strategies.', 'A number of proposals in the 1990s deliberately limited the extent to which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; #TAUTHOR_TAG ; Kennedy and Boguraev 1996 ; Williams , Harvey , and Preston 1996 ; Baldwin 1997 ; Mitkov 1996 , 1998b ) .']",0
"['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; Carter 1987 ; #TAUTHOR_TAG ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input', 'encouraged many researchers to move away fromistic knowledge embark', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; Carter 1987 ; #TAUTHOR_TAG ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input', 'encouraged many researchers to move away from linguistic knowledge embark', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; Carter 1987 ; #TAUTHOR_TAG ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input .', 'encouraged many researchers to move away fromistic knowledge embark instead', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; Carter 1987 ; #TAUTHOR_TAG ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input .', '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task the) gave a considerable impetus to the development of coreference resolution algorithms and, such as in', 'decade 2 saw a of anap resolution projects for Japanese', 'mult , multual /ference has gained considerable momentum in recent ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; Harabagiu and Maiorano 2000 ; #TAUTHOR_TAG ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task the gave a considerable impetus to the development of coreference resolution algorithms and systems, such as in', 'decade 20th saw a of anaphora resolution projects for Japanese,', ', multilingual / coreference has gained considerable momentum in recent ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; Harabagiu and Maiorano 2000 ; #TAUTHOR_TAG ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task) gave a considerable impetus to the development of coreference resolution algorithms and, such as in', 'saw a number of anaphora resolution projects for', 'mult , mult has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; Harabagiu and Maiorano 2000 ; #TAUTHOR_TAG ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', 'Against the background of a growing interest in multilingual NLP , multilingual anaphora / coreference resolution has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; Harabagiu and Maiorano 2000 ; #TAUTHOR_TAG ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']",0
"['The last years have seen considerable advances in the field of anaphora resolution , but a number of outstanding issues either remain unsolved or need more attention and , as a consequence , represent major challenges to the further development of the field #TAUTHOR_TAG a ) .', 'needs further investigation is how far the performance of anaphora algorithms can go and what the ofpoor methods are', '', '', '', '']","['The last years have seen considerable advances in the field of anaphora resolution , but a number of outstanding issues either remain unsolved or need more attention and , as a consequence , represent major challenges to the further development of the field #TAUTHOR_TAG a ) .', 'needs further investigation is how far the performance of anaphora algorithms can go and what the of knowledge-poor methods are.', '', '', '', '']","['The last years have seen considerable advances in the field of anaphora resolution , but a number of outstanding issues either remain unsolved or need more attention and , as a consequence , represent major challenges to the further development of the field #TAUTHOR_TAG a ) .', 'needs further investigation is how far the performance of anaphora resolution algorithms can go and what the limitations ofpoor methods are.', '', '', '', '']","['The last years have seen considerable advances in the field of anaphora resolution , but a number of outstanding issues either remain unsolved or need more attention and , as a consequence , represent major challenges to the further development of the field #TAUTHOR_TAG a ) .', 'A fundamental question that needs further investigation is how far the performance of anaphora resolution algorithms can go and what the limitations of knowledge-poor methods are.', '', '', '', '']",3
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impetus to core', '', '', 'the continuing inering , used either in original or in revised form ( Abracos and Lopes 1994 ; Strube and Hahn 1996 ; Hahn and Strube 1997 ; #TAUTHOR_TAG ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a , 2001b ) .', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'inclusion of coreference task a considerable impetus to coreference', '', '', 'the continuing in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; Strube and Hahn 1996 ; Hahn and Strube 1997 ; #TAUTHOR_TAG ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a , 2001b ) .', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task a considerable impetus to core', '', '', 'the continuing interest inering , used either in original or in revised form ( Abracos and Lopes 1994 ; Strube and Hahn 1996 ; Hahn and Strube 1997 ; #TAUTHOR_TAG ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a , 2001b ) .', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', '', 'Other milestones of recent research include the deployment of probabilistic and machine learning techniques ( Aone and Bennett 1995 ; Kehler 1997 ; Ge , Hale , and Charniak 1998 ; Cardie and Wagstaff 1999 ; the continuing interest in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; Strube and Hahn 1996 ; Hahn and Strube 1997 ; #TAUTHOR_TAG ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a , 2001b ) .', '']",0
"['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; 1987 ; Rich and LuperFoy 1988 ; #TAUTHOR_TAG , which was difficult both to represent and to process , and which required considerable human input .', 'encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-or an resolution', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; 1987 ; Rich and LuperFoy 1988 ; #TAUTHOR_TAG , which was difficult both to represent and to process , and which required considerable human input .', 'encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-poor resolution', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; Carter 1987 ; Rich and LuperFoy 1988 ; #TAUTHOR_TAG , which was difficult both to represent and to process , and which required considerable human input .', 'encouraged many researchers to move away from extensive domain and linguistic knowledge and to embark instead upon knowledge-', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; Carter 1987 ; Rich and LuperFoy 1988 ; #TAUTHOR_TAG , which was difficult both to represent and to process , and which required considerable human input .', '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'The last decade of the 2 century saw a of anaphora resolution for Japanese', '', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'The last decade of the 20th century saw a of anaphora resolution for Japanese,', '', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'The last decade of the 20th century saw a number of anaphora resolution projects for', '', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', '', '', '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task) gave a considerable impetus to the development of coreference resolution algorithms and, such as in', 'decade 2 a ofap resolution for Japanese', 'Against the background of a growing in multual NLP , multilingual anaphora / coreference resolution has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; #TAUTHOR_TAG ; Mitkov and Barbu 2000 ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task gave a considerable impetus to the development of coreference resolution algorithms and systems, such as in', 'decade 20th a of resolution for Japanese,', 'Against the background of a growing in multilingual NLP , multilingual anaphora / coreference resolution has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; #TAUTHOR_TAG ; Mitkov and Barbu 2000 ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task) gave a considerable impetus to the development of coreference resolution algorithms and, such as in', 'a number ofap for', 'Against the background of a growing interest in multual NLP , multilingual anaphora / coreference resolution has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; #TAUTHOR_TAG ; Mitkov and Barbu 2000 ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', 'Against the background of a growing interest in multilingual NLP , multilingual anaphora / coreference resolution has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; #TAUTHOR_TAG ; Mitkov and Barbu 2000 ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .', '', '']",0
"['of heavily exploitedistic', 'many researchers to move away from domainistic knowledge and to embark instead upon knowledge-', ', Harvey , and Preston 996 ;win 1997 ; #TAUTHOR_TAG , 1998b ) .']","['of heavily exploited linguistic', 'many researchers to move away from domain linguistic knowledge and to embark instead upon knowledge-poor', ', Harvey , and Preston 1996 ; Baldwin 1997 ; #TAUTHOR_TAG , 1998b ) .']","['of heavily exploitedistic knowledge', 'many researchers to move away from extensive domainistic knowledge and to embark instead upon knowledge-', ', Harvey , and Preston 1996 ;win 1997 ; #TAUTHOR_TAG , 1998b ) .']","['', '', '']",0
"[""Tetreault 's contribution features comparative evaluation involving the author 's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm ( LRC ) as well as three other pronoun resolution methods : Hobbs 's naive algorithm #TAUTHOR_TAG , BFP ( Brennan , Friedman , and Pollard 1987 ) , and Strube 's 5list approach ( Strube 1998 ) ."", '', '']","[""Tetreault 's contribution features comparative evaluation involving the author 's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm ( LRC ) as well as three other pronoun resolution methods : Hobbs 's naive algorithm #TAUTHOR_TAG , BFP ( Brennan , Friedman , and Pollard 1987 ) , and Strube 's 5list approach ( Strube 1998 ) ."", '', '']","[""Tetreault 's contribution features comparative evaluation involving the author 's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm ( LRC ) as well as three other pronoun resolution methods : Hobbs 's naive algorithm #TAUTHOR_TAG , BFP ( Brennan , Friedman , and Pollard 1987 ) , and Strube 's 5list approach ( Strube 1998 ) ."", '', '']","[""Tetreault 's contribution features comparative evaluation involving the author 's own centering-based pronoun resolution algorithm called the Left-Right Centering algorithm ( LRC ) as well as three other pronoun resolution methods : Hobbs 's naive algorithm #TAUTHOR_TAG , BFP ( Brennan , Friedman , and Pollard 1987 ) , and Strube 's 5list approach ( Strube 1998 ) ."", '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task) gave a considerable impetus to coreference resolution algorithms and', 'decade', 'andbu  ; Mitkov 1999 ; #TAUTHOR_TAG ; Mitkov , Belguith , and Stys 1998', 'abil', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task gave a considerable impetus to coreference resolution algorithms and', 'decade', 'and Barbu ; Mitkov 1999 ; #TAUTHOR_TAG ; Mitkov , Belguith , and Stys 1998', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task) gave a considerable impetus to coreference resolution algorithms and', '', 'and ; Mitkov 1999 ; #TAUTHOR_TAG ; Mitkov , Belguith , and Stys 1998', 'abil', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', '', '', '', '', '']",0
"['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', 'The last decade of the 2 century saw a number of anaphora resolution projects for Japanese', '', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', 'The last decade of the 20th century saw a number of anaphora resolution projects for Japanese,', '', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', 'The last decade of the 20th century saw a number of anaphora resolution projects for', '', '', '']","['While the shift toward knowledge-poor strategies and the use of corpora represented the main trends of anaphora resolution in the 1990s, there are other significant highlights in recent anaphora resolution research.', 'The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', '', '', '', '']",0
"['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge #TAUTHOR_TAG ; Carter 1987 ; Rich and LuperFoy 1988 ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input', 'encouraged many researchers to move away from extensive domain andistic knowledge and embark instead upon knowledgeor resolution', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge #TAUTHOR_TAG ; Carter 1987 ; Rich and LuperFoy 1988 ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input', 'encouraged many researchers to move away from extensive domain and linguistic knowledge and embark instead upon knowledge-poor resolution', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge #TAUTHOR_TAG ; Carter 1987 ; Rich and LuperFoy 1988 ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input .', 'encouraged many researchers to move away from extensive domain andistic knowledge and embark instead upon knowledge', '']","['Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge #TAUTHOR_TAG ; Carter 1987 ; Rich and LuperFoy 1988 ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input .', '', '']",0
"['Proper names are the main concern of the named-entity recognition subtask #TAUTHOR_TAG 1998) of information extraction.', 'The main objective of this subtask is the identification of proper names and also their classification into semantic categories (person, organization, location, etc.).1', 'There theambiguation of the in a sentence ( other ambig of the central 2% of', 'surn', '', '', '']","['Proper names are the main concern of the named-entity recognition subtask #TAUTHOR_TAG 1998) of information extraction.', 'The main objective of this subtask is the identification of proper names and also their classification into semantic categories (person, organization, location, etc.).1', 'There the disambiguation of the in a sentence (and other ambiguous of the central 20% of', 'surname', '', '', '']","['Proper names are the main concern of the named-entity recognition subtask #TAUTHOR_TAG 1998) of information extraction.', 'The main objective of this subtask is the identification of proper names and also their classification into semantic categories (person, organization, location, etc.).1', 'There the disambiguation of in a sentence ( of the central problems: 2% of', '', '', '', '']","['Proper names are the main concern of the named-entity recognition subtask #TAUTHOR_TAG 1998) of information extraction.', 'The main objective of this subtask is the identification of proper names and also their classification into semantic categories (person, organization, location, etc.).1', '', '', '', '', '']",0
"['', '', '', '', '', ""We see no good reason , however , why such text spans should necessarily be sentences , since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ #TAUTHOR_TAG ] , Brill 's [ Brill 1995a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']","['', '', '', '', '', ""We see no good reason , however , why such text spans should necessarily be sentences , since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ #TAUTHOR_TAG ] , Brill 's [ Brill 1995a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']","['', '', '', '', '', ""We see no good reason , however , why such text spans should necessarily be sentences , since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ #TAUTHOR_TAG ] , Brill 's [ Brill 1995a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']","['', '', '', '', '', ""We see no good reason , however , why such text spans should necessarily be sentences , since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ #TAUTHOR_TAG ] , Brill 's [ Brill 1995a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']",1
"['punct', 'text information about or is a common word is crucial for the, document-cent fly ambigu entire.', 'This is implemented as a cascade of simple strategies , which were briefly described in #TAUTHOR_TAG .']","['punctuation', 'text information about or is a common word is crucial for the task, document-centered fly ambiguously entire document.', 'This is implemented as a cascade of simple strategies , which were briefly described in #TAUTHOR_TAG .']","['', 'about or is a common word is crucial for a document-centered approach the fly ambigu the entire document.', 'This is implemented as a cascade of simple strategies , which were briefly described in #TAUTHOR_TAG .']","['', '', 'This is implemented as a cascade of simple strategies , which were briefly described in #TAUTHOR_TAG .']",5
"['There are two corpora normally used for evaluation in a number of text-processing tasks : the Brown corpus #TAUTHOR_TAG and the Wall Street Journal ( WSJ ) corpus , both part of the Penn Treebank ( Marcus , Marcinkiewicz , and Santorini 1993 ) .', 'The Brown corpus represents general English.', 'It contains over one million word tokens and is composed from 15 subcorpora that belong to different genres and domains, ranging from news wire texts and scientific papers to fiction and transcribed speech.', 'The Brown corpus is rich in out-of-vocabulary (unknown) words, spelling errors, and ungrammatical sentences with complex internal structure.', 'Alt there are about 500 documents in the Brown, with length .']","['There are two corpora normally used for evaluation in a number of text-processing tasks : the Brown corpus #TAUTHOR_TAG and the Wall Street Journal ( WSJ ) corpus , both part of the Penn Treebank ( Marcus , Marcinkiewicz , and Santorini 1993 ) .', 'The Brown corpus represents general English.', 'It contains over one million word tokens and is composed from 15 subcorpora that belong to different genres and domains, ranging from news wire texts and scientific papers to fiction and transcribed speech.', 'The Brown corpus is rich in out-of-vocabulary (unknown) words, spelling errors, and ungrammatical sentences with complex internal structure.', 'Altogether there are about 500 documents in the Brown with length tokens.']","['There are two corpora normally used for evaluation in a number of text-processing tasks : the Brown corpus #TAUTHOR_TAG and the Wall Street Journal ( WSJ ) corpus , both part of the Penn Treebank ( Marcus , Marcinkiewicz , and Santorini 1993 ) .', 'The Brown corpus represents general English.', 'It contains over one million word tokens and is composed from 15 subcorpora that belong to different genres and domains, ranging from news wire texts and scientific papers to fiction and transcribed speech.', 'The Brown corpus is rich in out-of-vocabulary (unknown) words, spelling errors, and ungrammatical sentences with complex internal structure.', 'Alt there are about 500 documents in the Brown corpus, with ']","['There are two corpora normally used for evaluation in a number of text-processing tasks : the Brown corpus #TAUTHOR_TAG and the Wall Street Journal ( WSJ ) corpus , both part of the Penn Treebank ( Marcus , Marcinkiewicz , and Santorini 1993 ) .', 'The Brown corpus represents general English.', 'It contains over one million word tokens and is composed from 15 subcorpora that belong to different genres and domains, ranging from news wire texts and scientific papers to fiction and transcribed speech.', 'The Brown corpus is rich in out-of-vocabulary (unknown) words, spelling errors, and ungrammatical sentences with complex internal structure.', 'Altogether there are about 500 documents in the Brown corpus, with an average length of 2,300 word tokens.']",5
"['', '', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG showed that words strongly tend to exhibit only one sense in a document or discourse (""one sense per discourse"").', 'Since then this idea has been applied to several tasks , including word sense disambiguation ( Yarowsky 1995 ) and named-entity recognition #TAUTHOR_TAG .', 'Gale, Church, and Yarowskys observation is also used in our DCA, especially for the identification of abbreviations.', 'ation']","['', '', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG showed that words strongly tend to exhibit only one sense in a document or discourse (""one sense per discourse"").', 'Since then this idea has been applied to several tasks , including word sense disambiguation ( Yarowsky 1995 ) and named-entity recognition #TAUTHOR_TAG .', ""Gale, Church, and Yarowsky's observation is also used in our DCA, especially for the identification of abbreviations."", '']","['', '', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG showed that words strongly tend to exhibit only one sense in a document or discourse (""one sense per discourse"").', 'Since then this idea has been applied to several tasks , including word sense disambiguation ( Yarowsky 1995 ) and named-entity recognition #TAUTHOR_TAG .', 'Gale, Church, and Yarowskys observation is also used in our DCA, especially for the identification of abbreviations.', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG showed that words strongly tend to exhibit only one sense in a document or discourse (""one sense per discourse"").', 'Since then this idea has been applied to several tasks , including word sense disambiguation ( Yarowsky 1995 ) and named-entity recognition #TAUTHOR_TAG .', ""Gale, Church, and Yarowsky's observation is also used in our DCA, especially for the identification of abbreviations."", '']",0
"['atically trainable software is generally seen way producing sys tems are quickly retrain for a a or for.', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers #TAUTHOR_TAG , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .', 'Ma- chine learning systems treat theBD task as a', '', '']","['Automatically trainable software is generally seen way producing sys- tems are quickly retrainable for a a or for language.', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers #TAUTHOR_TAG , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .', 'Ma- chine learning systems treat the SBD task as a', '', '']","['atically trainable software is generally seen a way producing sys- tems are quickly retrain for or for', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers #TAUTHOR_TAG , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .', 'Ma- chine learning systems treat the SBD task as', '', '']","['Automatically trainable software is generally seen as a way of producing sys- tems that are quickly retrainable for a new corpus, for a new domain, or even for another language.', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers #TAUTHOR_TAG , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .', '', '', '']",0
"['atically trainable software is generally seen way producing sys tems are quickly retrain a a for.', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks #TAUTHOR_TAG , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .', 'Ma- chine learning systems treat the SBD task as a', '', '']","['Automatically trainable software is generally seen way producing sys- tems are quickly retrainable a a for language.', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks #TAUTHOR_TAG , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .', 'Ma- chine learning systems treat the SBD task as a', '', '']","['atically trainable software is generally seen a way producing sys- tems are quickly retrain for', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks #TAUTHOR_TAG , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .', 'Ma- chine learning systems treat the SBD task as', '', '']","['Automatically trainable software is generally seen as a way of producing sys- tems that are quickly retrainable for a new corpus, for a new domain, or even for another language.', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks #TAUTHOR_TAG , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .', '', '', '']",0
"['', '', '', '', '', ""since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ Kupiec 1992 ] , Brill 's [ #TAUTHOR_TAG a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']","['', '', '', '', '', ""since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ Kupiec 1992 ] , Brill 's [ #TAUTHOR_TAG a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']","['', '', '', '', '', ""since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ Kupiec 1992 ] , Brill 's [ #TAUTHOR_TAG a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']","['', '', '', '', '', ""We see no good reason , however , why such text spans should necessarily be sentences , since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ Kupiec 1992 ] , Brill 's [ #TAUTHOR_TAG a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']",1
"['', '', '', '', '', 'ms ( , Brillsill1995a ] , and MaxEnt [ #TAUTHOR_TAG ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens .', '', '', '', '', '']","['', '', '', '', '', ""( , Brill 's Brill 1995a ] , and MaxEnt [ #TAUTHOR_TAG ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens ."", '', '', '', '', '']","['', '', '', '', '', '( , Brills [ Brill 1995a ] , and MaxEnt [ #TAUTHOR_TAG ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens .', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '']",1
"['Row C of Table4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system #TAUTHOR_TAG with the Alembic system ( Aberdeen et al. 1995 ) : a 0.5 % error rate .', '', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system #TAUTHOR_TAG with the Alembic system ( Aberdeen et al. 1995 ) : a 0.5 % error rate .', '', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system #TAUTHOR_TAG with the Alembic system ( Aberdeen et al. 1995 ) : a 0.5 % error rate .', '', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system #TAUTHOR_TAG with the Alembic system ( Aberdeen et al. 1995 ) : a 0.5 % error rate .', '', '', '']",1
"['There exist two large classes of SBD systems: rule based and machine learning.', 'The rule-', 'To a is and to a-based system with good performance is quite a-consuming enterprise.', 'For instance , the Alembic workbench #TAUTHOR_TAG contains a sentence-splitting module that employs over 100 regular-expression rules written in Flex .', 'ged short rulebased such systems are usually closely tailored to a corpus sub and not easily.']","['There exist two large classes of SBD systems: rule based and machine learning.', 'The rule-based', 'To a is and to a rule-based system with good performance is quite a labor-consuming enterprise.', 'For instance , the Alembic workbench #TAUTHOR_TAG contains a sentence-splitting module that employs over 100 regular-expression rules written in Flex .', 'shortcoming rule-based such systems are usually closely tailored to a corpus sublanguage and not easily domains.']","['There exist two large classes of SBD systems: rule based and machine learning.', 'The rule-based systems', 'To is and to a rule-based system with good performance is quite a labor-consuming enterprise.', 'For instance , the Alembic workbench #TAUTHOR_TAG contains a sentence-splitting module that employs over 100 regular-expression rules written in Flex .', 'rulebased systems such systems are usually closely tailored to a particular corpus sub and are not easily.']","['There exist two large classes of SBD systems: rule based and machine learning.', '', 'To put together a few rules is fast and easy, but to develop a rule-based system with good performance is quite a labor-consuming enterprise.', 'For instance , the Alembic workbench #TAUTHOR_TAG contains a sentence-splitting module that employs over 100 regular-expression rules written in Flex .', '']",0
"['performance reported', '(iley 19 0 error rate).', 'On the WSJ corpus our system performed slightly better than the combination of the Alembic and SATZ systems described in #TAUTHOR_TAG ( 0.44 % vs. 0.5 % error rate ) .', 'error rates to very, they', '', '', '']","['performance reported', '(Riley 1989: error rate).', 'On the WSJ corpus our system performed slightly better than the combination of the Alembic and SATZ systems described in #TAUTHOR_TAG ( 0.44 % vs. 0.5 % error rate ) .', 'error rates to very small, they', '', '', '']","['the performance reported', '(% error rate).', 'On the WSJ corpus our system performed slightly better than the combination of the Alembic and SATZ systems described in #TAUTHOR_TAG ( 0.44 % vs. 0.5 % error rate ) .', 'these error rates to be very,', '', '', '']","['', '', 'On the WSJ corpus our system performed slightly better than the combination of the Alembic and SATZ systems described in #TAUTHOR_TAG ( 0.44 % vs. 0.5 % error rate ) .', '', '', '', '']",1
"['', '', '', ""This done purely unsupervised techniques ( e.g. , Baum-Welch [ Baum and Petrie 1966 ] or Brill 's [ #TAUTHOR_TAG b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns ."", 'OS patterns the right combinations the', '']","['', '', '', ""This done purely unsupervised techniques ( e.g. , Baum-Welch [ Baum and Petrie 1966 ] or Brill 's [ #TAUTHOR_TAG b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns ."", 'POS patterns the right combinations the', '']","['', '', '', ""This was done because purely unsupervised techniques ( e.g. , Baum-Welch [ Baum and Petrie 1966 ] or Brill 's [ #TAUTHOR_TAG b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns ."", 'patterns over the right combinations the', '']","['', '', '', ""This was done because purely unsupervised techniques ( e.g. , Baum-Welch [ Baum and Petrie 1966 ] or Brill 's [ #TAUTHOR_TAG b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns ."", '', '']",1
"['Row C of Table4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1% measured on the and thepus.', 'The best performance on the WSJpus Ale', '', 'In the disambiguation of capitalized words , the most widespread method is POS tagging , which achieves about a 3 % error rate on the Brown corpus and a 5 % error rate on the WSJ corpus , as reported in #TAUTHOR_TAG .', 'of abbreviations with comprehensive on the or']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the and the corpus.', 'The best performance on the WSJ corpus', '', 'In the disambiguation of capitalized words , the most widespread method is POS tagging , which achieves about a 3 % error rate on the Brown corpus and a 5 % error rate on the WSJ corpus , as reported in #TAUTHOR_TAG .', 'of abbreviations with comprehensive on the or']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1% measured on and', 'The best performance on the WSJ corpus', '', 'In the disambiguation of capitalized words , the most widespread method is POS tagging , which achieves about a 3 % error rate on the Brown corpus and a 5 % error rate on the WSJ corpus , as reported in #TAUTHOR_TAG .', 'of abbreviations with comprehensive evaluation on or']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', '', '', 'In the disambiguation of capitalized words , the most widespread method is POS tagging , which achieves about a 3 % error rate on the Brown corpus and a 5 % error rate on the WSJ corpus , as reported in #TAUTHOR_TAG .', '']",1
"['ation is usually handled', 'As #TAUTHOR_TAG rightly pointed out , however , `` Proper nouns and capitalized words are particularly problematic : some capitalized words are proper nouns and some are not .', 'Estimates from the Brown Corpus can be misleading.', 'For example, the capital wordActs is in the Brown Corpus, both as a proper noun (in a title).', 'It']","['is usually handled', 'As #TAUTHOR_TAG rightly pointed out , however , `` Proper nouns and capitalized words are particularly problematic : some capitalized words are proper nouns and some are not .', 'Estimates from the Brown Corpus can be misleading.', ""For example, the capitalized word 'Acts' is in the Brown Corpus, both as a proper noun (in a title)."", 'It']","['ation is usually handled', 'As #TAUTHOR_TAG rightly pointed out , however , `` Proper nouns and capitalized words are particularly problematic : some capitalized words are proper nouns and some are not .', 'Estimates from the Brown Corpus can be misleading.', ""For example, the capitalized word 'Acts' in the Brown Corpus, both times as a proper noun (in a title)."", '']","['', 'As #TAUTHOR_TAG rightly pointed out , however , `` Proper nouns and capitalized words are particularly problematic : some capitalized words are proper nouns and some are not .', 'Estimates from the Brown Corpus can be misleading.', ""For example, the capitalized word 'Acts' is found twice in the Brown Corpus, both times as a proper noun (in a title)."", '']",1
"['', '', '', ""This was done because purely unsupervised techniques ( e.g. , Baum-Welch [ #TAUTHOR_TAG ] or Brill 's [ Brill 1995b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns ."", '', '']","['', '', '', ""This was done because purely unsupervised techniques ( e.g. , Baum-Welch [ #TAUTHOR_TAG ] or Brill 's [ Brill 1995b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns ."", '', '']","['', '', '', ""This was done because purely unsupervised techniques ( e.g. , Baum-Welch [ #TAUTHOR_TAG ] or Brill 's [ Brill 1995b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns ."", '', '']","['', '', '', ""This was done because purely unsupervised techniques ( e.g. , Baum-Welch [ #TAUTHOR_TAG ] or Brill 's [ Brill 1995b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns ."", '', '']",1
"['to with the normalization issue', 'Before using the DCA method , we applied a Russian morphological processor #TAUTHOR_TAG to convert each word in the text to its main form : nominative case singular for nouns and adjectives , infinitive for verbs , etc. .', 'to ( we', '', '']","['to with the normalization issue.', 'Before using the DCA method , we applied a Russian morphological processor #TAUTHOR_TAG to convert each word in the text to its main form : nominative case singular for nouns and adjectives , infinitive for verbs , etc. .', 'to we', '', '']","['to with the case normalization issue.', 'Before using the DCA method , we applied a Russian morphological processor #TAUTHOR_TAG to convert each word in the text to its main form : nominative case singular for nouns and adjectives , infinitive for verbs , etc. .', 'to ( we retained', '', '']","['', 'Before using the DCA method , we applied a Russian morphological processor #TAUTHOR_TAG to convert each word in the text to its main form : nominative case singular for nouns and adjectives , infinitive for verbs , etc. .', '', '', '']",5
"['', '', '', '', '', '', '', '', '', '', '', '', 'applied tasks wordation5)', '', 'we use this assumption with caution and first apply strategies that rely not just on', 'single words but on words together with their local contexts (n-grams). This is similar to ""one sense per collocation"" idea of #TAUTHOR_TAG', '.']","['', '', '', '', '', '', '', '', '', '', '', '', 'applied several tasks word95', '', 'however, we use this assumption with caution and first apply strategies that rely not just on', 'single words but on words together with their local contexts (n-grams). This is similar to ""one sense per collocation"" idea of #TAUTHOR_TAG', '.']","['', '', '', '', '', '', '', '', '', '', '', '', 'applied wordation', '', 'we use this assumption with caution and first apply strategies that rely not just on', 'single words but on words together with their local contexts (n-grams). This is similar to ""one sense per collocation"" idea of #TAUTHOR_TAG', '.']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'single words but on words together with their local contexts (n-grams). This is similar to ""one sense per collocation"" idea of #TAUTHOR_TAG', '.']",1
"['rel a list of words', 'This list includes common words for a, but no supplementary information such as POS or morphological information is required to be present in this list.', 'A variety of such lists for many languages are already available ( e.g. , #TAUTHOR_TAG .', 'Words in such lists are usually supplemented with morphological and POS information (which is not required by our method', 'pre', '', '', '', '']","['relies a list of words.', 'This list includes common words for a language, but no supplementary information such as POS or morphological information is required to be present in this list.', 'A variety of such lists for many languages are already available ( e.g. , #TAUTHOR_TAG .', 'Words in such lists are usually supplemented with morphological and POS information (which is not required by our method).', '', '', '', '', '']","['a list of', 'This list includes common words for a, but no supplementary information such as POS or morphological information is required to be present in this list.', 'A variety of such lists for many languages are already available ( e.g. , #TAUTHOR_TAG .', 'Words in such lists are usually supplemented with morphological and POS information (which is not required by our method', 'pre', '', '', '', '']","['', 'This list includes common words for a given language, but no supplementary information such as POS or morphological information is required to be present in this list.', 'A variety of such lists for many languages are already available ( e.g. , #TAUTHOR_TAG .', 'Words in such lists are usually supplemented with morphological and POS information (which is not required by our method).', '', '', '', '', '']",0
"['Despite its simplicity, the performance of our approach was on the level with the previously highest reported results on the same test collections.', 'The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before #TAUTHOR_TAG : 0.28 % vs. 0.20 % error rate ) .', '', '', '', '', '']","['Despite its simplicity, the performance of our approach was on the level with the previously highest reported results on the same test collections.', 'The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before #TAUTHOR_TAG : 0.28 % vs. 0.20 % error rate ) .', '', '', '', '', '']","['Despite its simplicity, the performance of our approach was on the level with the previously highest reported results on the same test collections.', 'The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before #TAUTHOR_TAG : 0.28 % vs. 0.20 % error rate ) .', '', '', '', '', '']","['Despite its simplicity, the performance of our approach was on the level with the previously highest reported results on the same test collections.', 'The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before #TAUTHOR_TAG : 0.28 % vs. 0.20 % error rate ) .', '', '', '', '', '']",1
"['In the information extraction field, the disambiguation of ambiguous capitalized words has always been tightly linked to the classification of proper names into semantic classes such as person name, location, and company name.', 'Named-entity recognition usually use sets of complex hand-crafted rules that employ a gazetteer and a local context (Krupa and Hausman 199).', 'In some systems such dependencies are learned from labeled examples #TAUTHOR_TAG .', 'The the namedentity approach is only', '', '']","['In the information extraction field, the disambiguation of ambiguous capitalized words has always been tightly linked to the classification of proper names into semantic classes such as person name, location, and company name.', 'Named-entity recognition usually use sets of complex hand-crafted rules that employ a gazetteer and a local context (Krupa and Hausman 1998).', 'In some systems such dependencies are learned from labeled examples #TAUTHOR_TAG .', 'The the namedentity approach is only', '', '']","['In the information extraction field, the disambiguation of ambiguous capitalized words has always been tightly linked to the classification of proper names into semantic classes such as person name, location, and company name.', 'Named-entity recognition systems usually use sets of complex hand-crafted rules that employ a gazetteer and a local context (Krupa and Hausman 1998).', 'In some systems such dependencies are learned from labeled examples #TAUTHOR_TAG .', 'The advantage the namedentity approach is only', '', '']","['In the information extraction field, the disambiguation of ambiguous capitalized words has always been tightly linked to the classification of proper names into semantic classes such as person name, location, and company name.', 'Named-entity recognition systems usually use sets of complex hand-crafted rules that employ a gazetteer and a local context (Krupa and Hausman 1998).', 'In some systems such dependencies are learned from labeled examples #TAUTHOR_TAG .', '', '', '']",0
"['abbreviation (as opposed word) These four lists can be acquired completely automatically from raw (unlabeled', 'For the development of these lists we used a collection of texts of about 300,000 words derived from the New York Times ( NYT ) corpus that was supplied as training data for the 7th Message Understanding Conference ( MUC-7 ) #TAUTHOR_TAG .', 'We used these texts because the approach described in this article was initially designed to be part of a named-entity recognition system (Mikheev, Grover, and Moens 1998) developed for MUC-7.', '']","['abbreviation (as opposed word) These four lists can be acquired completely automatically from raw (unlabeled)', 'For the development of these lists we used a collection of texts of about 300,000 words derived from the New York Times ( NYT ) corpus that was supplied as training data for the 7th Message Understanding Conference ( MUC-7 ) #TAUTHOR_TAG .', 'We used these texts because the approach described in this article was initially designed to be part of a named-entity recognition system (Mikheev, Grover, and Moens 1998) developed for MUC-7.', '']","['abbreviation (as opposed word) These four lists can be acquired completely automatically from raw (unlabeled', 'For the development of these lists we used a collection of texts of about 300,000 words derived from the New York Times ( NYT ) corpus that was supplied as training data for the 7th Message Understanding Conference ( MUC-7 ) #TAUTHOR_TAG .', 'We used these texts because the approach described in this article was initially designed to be part of a named-entity recognition system (Mikheev, Grover, and Moens 1998) developed for MUC-7.', '']","['• abbreviation (as opposed to regular word) These four lists can be acquired completely automatically from raw (unlabeled) texts.', 'For the development of these lists we used a collection of texts of about 300,000 words derived from the New York Times ( NYT ) corpus that was supplied as training data for the 7th Message Understanding Conference ( MUC-7 ) #TAUTHOR_TAG .', 'We used these texts because the approach described in this article was initially designed to be part of a named-entity recognition system (Mikheev, Grover, and Moens 1998) developed for MUC-7.', '']",5
"['Row C of Table4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the cor and theJ corpus.', 'The best performance on the WSJ corpus was achieved by a of the SATZ system (Palmer and Hearst 1997) with the Ale system (Aberdeen et al. 1995): a 0.% error rate.', 'The best performance on the Brown corpus , a 0.2 % error rate , was reported by #TAUTHOR_TAG , who trained a decision tree classifier on a 25-million-word corpus .', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the corpus and the corpus.', 'The best performance on the WSJ corpus was achieved by a of the SATZ system (Palmer and Hearst 1997) with the system (Aberdeen et al. 1995): a 0.5% error rate.', 'The best performance on the Brown corpus , a 0.2 % error rate , was reported by #TAUTHOR_TAG , who trained a decision tree classifier on a 25-million-word corpus .', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system (Palmer and Hearst 1997) with the Alembic system (Aberdeen et al. 1995): a 0.5% error rate.', 'The best performance on the Brown corpus , a 0.2 % error rate , was reported by #TAUTHOR_TAG , who trained a decision tree classifier on a 25-million-word corpus .', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system (Palmer and Hearst 1997) with the Alembic system (Aberdeen et al. 1995): a 0.5% error rate.', 'The best performance on the Brown corpus , a 0.2 % error rate , was reported by #TAUTHOR_TAG , who trained a decision tree classifier on a 25-million-word corpus .', '', '']",1
"['Not much information has been published on abbreviation identification.', 'One of the better-known approaches is described in #TAUTHOR_TAG , which suggested that abbreviations first be extracted from a corpus using abbreviation-guessing heuristics akin to those described in Section 6 and then reused in further processing .', 'This is similar to', '', '', '', '', '', '', '', '', '']","['Not much information has been published on abbreviation identification.', 'One of the better-known approaches is described in #TAUTHOR_TAG , which suggested that abbreviations first be extracted from a corpus using abbreviation-guessing heuristics akin to those described in Section 6 and then reused in further processing .', 'This is similar to', '', '', '', '', '', '', '', '', '']","['Not much information has been published on abbreviation identification.', 'One of the better-known approaches is described in #TAUTHOR_TAG , which suggested that abbreviations first be extracted from a corpus using abbreviation-guessing heuristics akin to those described in Section 6 and then reused in further processing .', 'This is similar to', '', '', '', '', '', '', '', '', '']","['Not much information has been published on abbreviation identification.', 'One of the better-known approaches is described in #TAUTHOR_TAG , which suggested that abbreviations first be extracted from a corpus using abbreviation-guessing heuristics akin to those described in Section 6 and then reused in further processing .', '', '', '', '', '', '', '', '', '', '']",0
"['in speech', '', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG showed that words strongly tend to exhibit only one sense in a document or discourse (""one sense per discourse"").', 'Since then this idea has been applied to several tasks , including word sense disambiguation #TAUTHOR_TAG and named-entity recognition ( Cucerzan and Yarowsky 1999 ) .', 'Gale, Church, and Yarowskys observation is also used in DCA, especially for the of abvi.', 'capitalized-word disambiguation, however']","['in speech', '', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG showed that words strongly tend to exhibit only one sense in a document or discourse (""one sense per discourse"").', 'Since then this idea has been applied to several tasks , including word sense disambiguation #TAUTHOR_TAG and named-entity recognition ( Cucerzan and Yarowsky 1999 ) .', ""Gale, Church, and Yarowsky's observation is also used in DCA, especially for the of abbreviations."", 'capitalized-word disambiguation, however']","['in', '', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG showed that words strongly tend to exhibit only one sense in a document or discourse (""one sense per discourse"").', 'Since then this idea has been applied to several tasks , including word sense disambiguation #TAUTHOR_TAG and named-entity recognition ( Cucerzan and Yarowsky 1999 ) .', 'Gale, Church, and Yarowskys observation is also used in DCA, especially for the identification of abvi.', 'capitalized-word disambiguation, however']","['', '', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG showed that words strongly tend to exhibit only one sense in a document or discourse (""one sense per discourse"").', 'Since then this idea has been applied to several tasks , including word sense disambiguation #TAUTHOR_TAG and named-entity recognition ( Cucerzan and Yarowsky 1999 ) .', ""Gale, Church, and Yarowsky's observation is also used in our DCA, especially for the identification of abbreviations."", 'In capitalized-word disambiguation, however']",0
"['Another important task of text normalization is sentence boundary disambiguation ( or sentence', '', '', ').', 'A detailed introduction to the SBD problem can be found in #TAUTHOR_TAG .']","['Another important task of text normalization is sentence boundary disambiguation or sentence', '', '', '', 'A detailed introduction to the SBD problem can be found in #TAUTHOR_TAG .']","['Another important task of text normalization is sentence boundary disambiguation ( or', '', '', ').', 'A detailed introduction to the SBD problem can be found in #TAUTHOR_TAG .']","['Another important task of text normalization is sentence boundary disambiguation (SBD) or sentence splitting.', '', '', '', 'A detailed introduction to the SBD problem can be found in #TAUTHOR_TAG .']",0
"['', '', '', ' very short documents of one to three sentences also present a difficulty for our approach', 'This is where robust syntactic systems like SATZ ( Palmer and Hearst 1997 ) or the POS tagger reported in #TAUTHOR_TAG , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .']","['', '', '', '8 very short documents of one to three sentences also present a difficulty for our approach.', 'This is where robust syntactic systems like SATZ ( Palmer and Hearst 1997 ) or the POS tagger reported in #TAUTHOR_TAG , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .']","['', '', '', 'very short documents of one to three sentences also present a difficulty for our approach', 'This is where robust syntactic systems like SATZ ( Palmer and Hearst 1997 ) or the POS tagger reported in #TAUTHOR_TAG , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .']","['', '', '', 'We noted in Section 8 that very short documents of one to three sentences also present a difficulty for our approach.', 'This is where robust syntactic systems like SATZ ( Palmer and Hearst 1997 ) or the POS tagger reported in #TAUTHOR_TAG , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .']",1
"['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG pointed out that little attention had been paid in the named-entity recognition field to the discourse properties of proper names .', 'They proposed that proper names be viewed as linguistic expressions whose interpretation often depends on the discourse context, advocating text-driven processing rather than reliance on pre-existing lists', 'TheCA outlined in this article also uses nonlocal discourse context and does not heavily rely on pre-existing word lists.', 'has been applied not only to the identification of proper names, as described in this article, but to their (Mikheev, Gro, and Moens ', '', '', '', '']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG pointed out that little attention had been paid in the named-entity recognition field to the discourse properties of proper names .', 'They proposed that proper names be viewed as linguistic expressions whose interpretation often depends on the discourse context, advocating text-driven processing rather than reliance on pre-existing lists.', 'The DCA outlined in this article also uses nonlocal discourse context and does not heavily rely on pre-existing word lists.', 'has been applied not only to the identification of proper names, as described in this article, but to their (Mikheev, Grover, and Moens', '', '', '', '']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG pointed out that little attention had been paid in the named-entity recognition field to the discourse properties of proper names .', 'They proposed that proper names be viewed as linguistic expressions whose interpretation often depends on the discourse context, advocating text-driven processing rather than reliance on pre-existing lists.', 'The DCA outlined in this article also uses nonlocal discourse context and does not heavily rely on pre-existing word lists.', 'It has been applied not only to the identification of proper names, as described in this article, but to their (Mikheev, Gro, and Mo', '', '', '', '']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG pointed out that little attention had been paid in the named-entity recognition field to the discourse properties of proper names .', 'They proposed that proper names be viewed as linguistic expressions whose interpretation often depends on the discourse context, advocating text-driven processing rather than reliance on pre-existing lists.', 'The DCA outlined in this article also uses nonlocal discourse context and does not heavily rely on pre-existing word lists.', 'It has been applied not only to the identification of proper names, as described in this article, but also to their classification (Mikheev, Grover, and Moens 1998).', '', '', '', '']",5
"['we combined our main (evaluated in row D of Table4) POS.', 'Unlike other POS taggers , this POS tagger #TAUTHOR_TAG was also trained to disambiguate sentence boundaries .']","['we combined our main (evaluated in row D of Table 4) POS', 'Unlike other POS taggers , this POS tagger #TAUTHOR_TAG was also trained to disambiguate sentence boundaries .']","['we combined our main configuration (evaluated in row D of Table 4)', 'Unlike other POS taggers , this POS tagger #TAUTHOR_TAG was also trained to disambiguate sentence boundaries .']","['', 'Unlike other POS taggers , this POS tagger #TAUTHOR_TAG was also trained to disambiguate sentence boundaries .']",5
"['Row C of Table4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system ( Palmer and Hearst 1997 ) with the Alembic system #TAUTHOR_TAG : a 0.5 % error rate .', '', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system ( Palmer and Hearst 1997 ) with the Alembic system #TAUTHOR_TAG : a 0.5 % error rate .', '', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system ( Palmer and Hearst 1997 ) with the Alembic system #TAUTHOR_TAG : a 0.5 % error rate .', '', '', '']","['Row C of Table 4 summarizes the highest results known to us (for all three tasks) produced by automatic systems on the Brown corpus and the WSJ corpus.', 'State-of-theart machine learning and rule-based SBD systems achieve an error rate of 0.8-1.5% measured on the Brown corpus and the WSJ corpus.', 'The best performance on the WSJ corpus was achieved by a combination of the SATZ system ( Palmer and Hearst 1997 ) with the Alembic system #TAUTHOR_TAG : a 0.5 % error rate .', '', '', '']",1
"['', '', '', 'in Section 8 that very short documents of one to three sentences also present a difficulty for our approach', 'This is where robust syntactic systems like SATZ #TAUTHOR_TAG or the POS tagger reported in #AUTHOR_TAG , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .']","['', '', '', 'in Section 8 that very short documents of one to three sentences also present a difficulty for our approach.', 'This is where robust syntactic systems like SATZ #TAUTHOR_TAG or the POS tagger reported in #AUTHOR_TAG , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .']","['', '', '', 'in Section 8 that very short documents of one to three sentences also present a difficulty for our approach', 'This is where robust syntactic systems like SATZ #TAUTHOR_TAG or the POS tagger reported in #AUTHOR_TAG , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .']","['', '', '', 'We noted in Section 8 that very short documents of one to three sentences also present a difficulty for our approach.', 'This is where robust syntactic systems like SATZ #TAUTHOR_TAG or the POS tagger reported in #AUTHOR_TAG , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .']",1
"['speech', '', '', '', 'unlike multipass', "" #TAUTHOR_TAG developed a way of incorporating standard n-grams into the cache model , using mixtures of language models and also exponentially decaying the weight for the cache prediction depending on the recency of the word 's last"", 'DCA a', '', '', '', '', '', '', '', '', '', '']","['speech', '', '', '', 'unlike multipass', "" #TAUTHOR_TAG developed a way of incorporating standard n-grams into the cache model , using mixtures of language models and also exponentially decaying the weight for the cache prediction depending on the recency of the word 's last"", 'DCA a', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'unlike', "" #TAUTHOR_TAG developed a way of incorporating standard n-grams into the cache model , using mixtures of language models and also exponentially decaying the weight for the cache prediction depending on the recency of the word 's last"", 'the DCA system', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', "" #TAUTHOR_TAG developed a way of incorporating standard n-grams into the cache model , using mixtures of language models and also exponentially decaying the weight for the cache prediction depending on the recency of the word 's last"", '', '', '', '', '', '', '', '', '', '', '']",2
"['The description of the EAGLE workbench for linguistic engineering #TAUTHOR_TAG mentions a case normalization module that uses a heuristic in which a capitalized word in an ambiguous position should be rewritten without capitalization if it is found lower-cased in the same document .', 'This heuristic also employs a database of bigrams and unigrams of lower-cased and capitalized words found in unambiguous positions.', 'It is quite similar to our method for capitalized-word disambiguation.', 'AG. performance details']","['The description of the EAGLE workbench for linguistic engineering #TAUTHOR_TAG mentions a case normalization module that uses a heuristic in which a capitalized word in an ambiguous position should be rewritten without capitalization if it is found lower-cased in the same document .', 'This heuristic also employs a database of bigrams and unigrams of lower-cased and capitalized words found in unambiguous positions.', 'It is quite similar to our method for capitalized-word disambiguation.', 'al. performance details.']","['The description of the EAGLE workbench for linguistic engineering #TAUTHOR_TAG mentions a case normalization module that uses a heuristic in which a capitalized word in an ambiguous position should be rewritten without capitalization if it is found lower-cased in the same document .', 'This heuristic also employs a database of bigrams and unigrams of lower-cased and capitalized words found in unambiguous positions.', 'It is quite similar to our method for capitalized-word disambiguation.', '']","['The description of the EAGLE workbench for linguistic engineering #TAUTHOR_TAG mentions a case normalization module that uses a heuristic in which a capitalized word in an ambiguous position should be rewritten without capitalization if it is found lower-cased in the same document .', 'This heuristic also employs a database of bigrams and unigrams of lower-cased and capitalized words found in unambiguous positions.', 'It is quite similar to our method for capitalized-word disambiguation.', '']",1
"['is generally seen re', ', the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling #TAUTHOR_TAG .', 'Machine learning systems treat the SBD task as a classification problem, using features such as word spelling, capitalization, suffix, and word class found in the local context of a potential sentence-terminating punctuation sign.', '', '']","['is generally seen', ', the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling #TAUTHOR_TAG .', 'Machine learning systems treat the SBD task as a classification problem, using features such as word spelling, capitalization, suffix, and word class found in the local context of a potential sentence-terminating punctuation sign.', '', '']","['is generally seen re', ', the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling #TAUTHOR_TAG .', 'Machine learning systems treat the SBD task as a classification problem, using features such as word spelling, capitalization, suffix, and word class found in the local context of a potential sentence-terminating punctuation sign.', '', '']","['', 'Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling #TAUTHOR_TAG .', 'Machine learning systems treat the SBD task as a classification problem, using features such as word spelling, capitalization, suffix, and word class found in the local context of a potential sentence-terminating punctuation sign.', '', '']",0
"['received it plays an important in many.', '', 'open', '', '', 'The disambiguation of capitalized words in ambiguous positions leads to the identification of proper names (or their derivatives), and in this article we will use these two terms and the term case normalization interchangeably.', "" #TAUTHOR_TAG , p. 294 ) studied , among other simple text normalization techniques , the effect of case normalization for different words and showed that `` sometimes case variants refer to the same thing ( hurricane and Hurricane ) , sometimes they refer to different things ( continental and Continental ) and sometimes they do nt refer to much of anything ( e.g. , anytime and Anytime ) . ''"", 'Obviously these differences because some capitalized words stand for proper names (such as Contin, the name of an airline) and some']","['received it plays an important in many tasks.', '', 'open', '', '', 'The disambiguation of capitalized words in ambiguous positions leads to the identification of proper names (or their derivatives), and in this article we will use these two terms and the term case normalization interchangeably.', "" #TAUTHOR_TAG , p. 294 ) studied , among other simple text normalization techniques , the effect of case normalization for different words and showed that `` sometimes case variants refer to the same thing ( hurricane and Hurricane ) , sometimes they refer to different things ( continental and Continental ) and sometimes they do n't refer to much of anything ( e.g. , anytime and Anytime ) . ''"", 'Obviously these differences because some capitalized words stand for proper names (such as Continental, the name of an airline) and some']","['has received it plays an important role in many tasks.', '', '', '', '', 'The disambiguation of capitalized words in ambiguous positions leads to the identification of proper names (or their derivatives), and in this article we will use these two terms and the term case normalization interchangeably.', "" #TAUTHOR_TAG , p. 294 ) studied , among other simple text normalization techniques , the effect of case normalization for different words and showed that `` sometimes case variants refer to the same thing ( hurricane and Hurricane ) , sometimes they refer to different things ( continental and Continental ) and sometimes they do n't refer to much of anything ( e.g. , anytime and Anytime ) . ''"", 'Obviously these differences because some capitalized words stand for proper names (such as Contin, the name of an airline) and some']","['', '', '', '', '', 'The disambiguation of capitalized words in ambiguous positions leads to the identification of proper names (or their derivatives), and in this article we will use these two terms and the term case normalization interchangeably.', "" #TAUTHOR_TAG , p. 294 ) studied , among other simple text normalization techniques , the effect of case normalization for different words and showed that `` sometimes case variants refer to the same thing ( hurricane and Hurricane ) , sometimes they refer to different things ( continental and Continental ) and sometimes they do n't refer to much of anything ( e.g. , anytime and Anytime ) . ''"", 'Obviously these differences arise because some capitalized words stand for proper names (such as Continental, the name of an airline) and some do not.']",0
"['', '', '', '', ' #TAUTHOR_TAG recently described a hybrid method for finding abbreviations and their definitions .', 'This method first applies an ""abbreviation recognizer"" that generates a set of ""candidate abbreviations"" for a document.', 'Then for this set of candidates the system tries to find in the text their definitions (e.g., United Kingdom for UK).', 'The abbreviation recognizer for these purposes is allowed to overgenerate significantly.', 'no harm (apart from performance issues) proposing too many abbreviations, because only those that can be linked to their definitions will be retained', 'abviation recognizer two to', 'andid known', '']","['', '', '', '', ' #TAUTHOR_TAG recently described a hybrid method for finding abbreviations and their definitions .', 'This method first applies an ""abbreviation recognizer"" that generates a set of ""candidate abbreviations"" for a document.', 'Then for this set of candidates the system tries to find in the text their definitions (e.g., United Kingdom for UK).', 'The abbreviation recognizer for these purposes is allowed to overgenerate significantly.', 'no harm (apart from performance issues) proposing too many abbreviations, because only those that can be linked to their definitions will be retained.', 'abbreviation recognizer two to', 'known', '']","['', '', '', '', ' #TAUTHOR_TAG recently described a hybrid method for finding abbreviations and their definitions .', 'This method first applies an ""abbreviation recognizer"" that generates a set of ""candidate abbreviations"" for a document.', 'Then for this set of candidates the system tries to find in the text their definitions (e.g., United Kingdom for UK).', 'The abbreviation recognizer for these purposes is allowed to overgenerate significantly.', 'no harm (apart from the performance issues) proposing too many abbreviations, because only those that can be linked to their definitions will be retained', 'Therefore the abbreviation recognizer treats two to', 'andid', '']","['', '', '', '', ' #TAUTHOR_TAG recently described a hybrid method for finding abbreviations and their definitions .', 'This method first applies an ""abbreviation recognizer"" that generates a set of ""candidate abbreviations"" for a document.', 'Then for this set of candidates the system tries to find in the text their definitions (e.g., United Kingdom for UK).', 'The abbreviation recognizer for these purposes is allowed to overgenerate significantly.', 'There is no harm (apart from the performance issues) in proposing too many candidate abbreviations, because only those that can be linked to their definitions will be retained.', '', '', '']",0
"['approach', 'system', 'some SBD systems can be trained on relatively of labeled examples, their performance in cases is somewhat than', 'For instance #TAUTHOR_TAG report that the SATZ system ( decision tree variant ) was trained on a set of about 800 labeled periods , which corresponds to a corpus of about 16,000 words .', 'This is a be manually marked in a', 'But the error rate (1.5%) of the decision tree classifier trained on was about 50 6 examples (']","['approach', 'system', 'some SBD systems can be trained on relatively of labeled examples, their performance in cases is somewhat than', 'For instance #TAUTHOR_TAG report that the SATZ system ( decision tree variant ) was trained on a set of about 800 labeled periods , which corresponds to a corpus of about 16,000 words .', 'This is a be manually marked in a', 'But the error rate (1.5%) of the decision tree classifier trained on was about 50% examples']","['this approach', 'system', 'some SBD systems can be trained on of labeled examples, their performance in such cases is somewhat than', 'For instance #TAUTHOR_TAG report that the SATZ system ( decision tree variant ) was trained on a set of about 800 labeled periods , which corresponds to a corpus of about 16,000 words .', 'This is can be manually marked in', 'But the error rate (1.5%) of the decision tree classifier trained on was about 50 6 (']","['', '', 'Although some SBD systems can be trained on relatively small sets of labeled examples, their performance in such cases is somewhat lower than their optimal performance.', 'For instance , #TAUTHOR_TAG report that the SATZ system ( decision tree variant ) was trained on a set of about 800 labeled periods , which corresponds to a corpus of about 16,000 words .', '', 'But the error rate (1.5%) of the decision tree classifier trained on this small sample was about 50% higher than that when trained on 6,000 labeled examples (1.0%).']",1
"['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', '', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; Veale and Way 1997 ; #TAUTHOR_TAG . an consider the translation into French of the house collapsed .']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', '', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; Veale and Way 1997 ; #TAUTHOR_TAG .7 an consider the translation into French of the house collapsed .']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', '', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; Veale and Way 1997 ; #TAUTHOR_TAG . an example consider the translation into French of the house collapsed .']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', '', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; Veale and Way 1997 ; #TAUTHOR_TAG .7 As an example , consider the translation into French of the house collapsed .']",0
"['These translations gave rise to a number of automatically constructed linguistic resources (  Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['These translations gave rise to a number of automatically constructed linguistic resources ( 1 Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['These translations gave rise to a number of automatically constructed linguistic resources (  are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['These translations gave rise to a number of automatically constructed linguistic resources : ( 1 ) the original ( source , target ) phrasal translation pairs , ( 2 ) the marker lexicon , ( 3 ) the gen11 Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']",1
"['ised', '', 'Kay and Rscheisen (1993) attempt to extract a bilingual dictionary a hybrid method of sentence and word alignment assumption the a', ' #TAUTHOR_TAG attempt to translate technical terms using word relation matrices , although the resource from which such relations are derived is a pair of nonparallel corpora .', 'replicates the work of Fung and McKeown with different language pairs using the simpler metric Levenshtein', '', '', '', '', '']","['premised', '', 'Kay and Röscheisen (1993) attempt to extract a bilingual dictionary a hybrid method of sentence and word alignment assumption the a', ' #TAUTHOR_TAG attempt to translate technical terms using word relation matrices , although the resource from which such relations are derived is a pair of nonparallel corpora .', 'replicates the work of Fung and McKeown with different language pairs using the simpler metric Levenshtein', '', '', '', '', '']","['', '', 'Kay and Rscheisen (1993) attempt to extract a bilingual dictionary using a hybrid method of sentence and word alignment the assumption', ' #TAUTHOR_TAG attempt to translate technical terms using word relation matrices , although the resource from which such relations are derived is a pair of nonparallel corpora .', 'replicates the work of Fung and McKeown with different language pairs using the simpler metric Levenshte', '', '', '', '', '']","['', '', 'Kay and Röscheisen (1993) attempt to extract a bilingual dictionary using a hybrid method of sentence and word alignment on the assumption that the source, target words have a similar distribution.', ' #TAUTHOR_TAG attempt to translate technical terms using word relation matrices , although the resource from which such relations are derived is a pair of nonparallel corpora .', ' #AUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance.', '', '', '', '', '']",0
"['â\x80¢ Learnability #TAUTHOR_TAG â\x80¢ Text generation ( Hovy 1988 ;osljic , Tulloch , and Dale 1996 )¢ Speech generation Ray Localization (¨er']","['â\x80¢ Learnability #TAUTHOR_TAG â\x80¢ Text generation ( Hovy 1988 ; , Tulloch , and Dale 1996 ) Speech generation Rayner Localization ( aler']","['â\x80¢ Learnability #TAUTHOR_TAG â\x80¢ Text generation ( Hovy 1988 ;osljic , Tulloch , and Dale 1996 )¢ Speech generation Ray Localization (er']","['â\x80¢ Learnability #TAUTHOR_TAG â\x80¢ Text generation ( Hovy 1988 ; Milosavljevic , Tulloch , and Dale 1996 ) â\x80¢ Speech generation ( Rayner and Carter 1997 ) â\x80¢ Localization ( Sch Â¨ aler 1996 )']",0
"['', 'are derived from, patterns are computed from the derived chunks means followingfor each pairs Using algorithm described above, the patterns in ( 26) are derived from the chunks in ( 25): Of, many other researchers to general', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , inter alia .']","['', 'are derived from patterns are computed from the derived chunks means following ""for each pairs Using algorithm described above, the patterns in ( 26) are derived from the chunks in ( 25): Of course, many other researchers to generalized', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , inter alia .']","['', 'are derived from are computed from the derived chunks means each pair chunk pairs Using the algorithm described above, the patterns in ( 26) are derived from the chunks in ( 25): Of, many other researchers to general', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , inter alia .']","['', 'Once chunks are derived from source, target alignments, patterns are computed from the derived chunks by means of the following algorithm: ""for each pair of chunk pairs Using the algorithm described above, the patterns in ( 26) are derived from the chunks in ( 25): Of course, many other researchers also try to extract generalized templates.', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , inter alia .']",0
"['â\x80¢ Learnability ( Zernik and Dyer 1987 ) â\x80¢ Text generation #TAUTHOR_TAG ; Milosavljevic , Tulloch , and Dale 1996 ) â¢ Speech generation Localization (¨er ']","['â\x80¢ Learnability ( Zernik and Dyer 1987 ) â\x80¢ Text generation #TAUTHOR_TAG ; Milosavljevic , Tulloch , and Dale 1996 ) â\x80¢ Speech generation Localization ( aler']","['â\x80¢ Learnability ( Zernik and Dyer 1987 ) â\x80¢ Text generation #TAUTHOR_TAG ; Milosavljevic , Tulloch , and Dale 1996 ) â¢ Speech generation Localization (er ']","['â\x80¢ Learnability ( Zernik and Dyer 1987 ) â\x80¢ Text generation #TAUTHOR_TAG ; Milosavljevic , Tulloch , and Dale 1996 ) â\x80¢ Speech generation ( Rayner and Carter 1997 ) â\x80¢ Localization ( Sch Â¨ aler 1996 )']",0
"['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', 'In TL sentence we multiply the weights of each chunk used in its construction.', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX #TAUTHOR_TAG ; Veale and Way 1997 ; Carl 1999 ) .7']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', 'In TL sentence we multiply the weights of each chunk used in its construction.', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX #TAUTHOR_TAG ; Veale and Way 1997 ; Carl 1999 ) .7']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', 'In we multiply the weights of each chunk used in its construction.', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX #TAUTHOR_TAG ; Veale and Way 1997 ; Carl 1999 ) .7']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', 'In order to calculate a ranking for each TL sentence produced, we multiply the weights of each chunk used in its construction.', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX #TAUTHOR_TAG ; Veale and Way 1997 ; Carl 1999 ) .7']",0
"['translation memory (TM systems have become a very useful tool in the translators arm.', 'systems store a set of', 'a new a for (zy', 'From this description , it should be clear that TM systems do not translate : Indeed , some researchers consider them to be little more than a search-and-replace engine , albeit a rather sophisticated one #TAUTHOR_TAG .']","[""translation memory (TM) systems have become a very useful tool in the translator's armory."", 'systems store a set of', 'a new a for (or', 'From this description , it should be clear that TM systems do not translate : Indeed , some researchers consider them to be little more than a search-and-replace engine , albeit a rather sophisticated one #TAUTHOR_TAG .']","["", translation memory (TM) systems have become a very useful tool in the translator's armory."", 'M systems store a set of', 'a new input string a search for (', 'From this description , it should be clear that TM systems do not translate : Indeed , some researchers consider them to be little more than a search-and-replace engine , albeit a rather sophisticated one #TAUTHOR_TAG .']","[""In quite a short space of time, translation memory (TM) systems have become a very useful tool in the translator's armory."", '', '', 'From this description , it should be clear that TM systems do not translate : Indeed , some researchers consider them to be little more than a search-and-replace engine , albeit a rather sophisticated one #TAUTHOR_TAG .']",0
"['', '', '', '', ' #AUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance.', ' #TAUTHOR_TAG use a tagged parallel corpus to extract translationally equivalent English-Greek clauses on the basis of word occurrence and co-occurrence probabilities .', 'lengths of', '', '', '']","['', '', '', '', ' #AUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance.', ' #TAUTHOR_TAG use a tagged parallel corpus to extract translationally equivalent English-Greek clauses on the basis of word occurrence and co-occurrence probabilities .', 'lengths of', '', '', '']","['', '', '', '', ' #AUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance.', ' #TAUTHOR_TAG use a tagged parallel corpus to extract translationally equivalent English-Greek clauses on the basis of word occurrence and co-occurrence probabilities .', 'of', '', '', '']","['', '', '', '', ' #AUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance.', ' #TAUTHOR_TAG use a tagged parallel corpus to extract translationally equivalent English-Greek clauses on the basis of word occurrence and co-occurrence probabilities .', '', '', '', '']",0
"['¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 )¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 )\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; #TAUTHOR_TAG ; Gough , Way , and Hearne 2002 )']","['language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 ) â\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; #TAUTHOR_TAG ; Gough , Way , and Hearne 2002 )']","['¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 )¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 )\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; #TAUTHOR_TAG ; Gough , Way , and Hearne 2002 )']","['â\x80¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 ) â\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; #TAUTHOR_TAG ; Gough , Way , and Hearne 2002 )']",0
"['â\x80¢ language learning #TAUTHOR_TAG ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 )\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Ju 994 )¢ into universal grammar ( Ju']","['â\x80¢ language learning #TAUTHOR_TAG ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 ) into universal grammar ( Juola']","['â\x80¢ language learning #TAUTHOR_TAG ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 )\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 )¢ into universal grammar ( Ju']","['â\x80¢ language learning #TAUTHOR_TAG ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 ) â\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , Way , and Hearne 2002 )']",0
"['Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']",1
"['More recently , #TAUTHOR_TAG have proposed the exploitation of TMs at a subsentential level , while Carl , Way , and Sch Â¨ aler ( 2002 ) and Sch Â¨ aler , Way , and #AUTHOR_TAG , pages 108 -- 109 ) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment .', 'This, they suggest, may result in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are on the whole wary of MT technology, but once subsentential alignment is enabled, translators will become aware of the benefits to be gained from _source, target_ phrasal segments suggest that �it is a reasonably short step to enabling an automated solution via the recombination element of EBMT systems such as those in3']","['More recently , #TAUTHOR_TAG have proposed the exploitation of TMs at a subsentential level , while Carl , Way , and Sch Â¨ aler ( 2002 ) and Sch Â¨ aler , Way , and #AUTHOR_TAG , pages 108 -- 109 ) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment .', 'This, they suggest, may result in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are on the whole wary of MT technology, but once subsentential alignment is enabled, translators will become aware of the benefits to be gained from _source, target_ phrasal segments, suggest that �it is a reasonably short step to enabling an automated solution via the recombination element of EBMT systems such as those in']","['More recently , #TAUTHOR_TAG have proposed the exploitation of TMs at a subsentential level , while Carl , Way , and Sch Â¨ aler ( 2002 ) and Sch Â¨ aler , Way , and #AUTHOR_TAG , pages 108 -- 109 ) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment .', 'This, they suggest, may result in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are on the whole wary of MT technology, but once subsentential alignment is enabled, translators will become aware of the benefits to be gained from _source, target_ phrasal segments, they suggest that �it is a reasonably short step to enabling an automated solution via the recombination element of EBMT systems such as those in']","['More recently , #TAUTHOR_TAG have proposed the exploitation of TMs at a subsentential level , while Carl , Way , and Sch Â¨ aler ( 2002 ) and Sch Â¨ aler , Way , and #AUTHOR_TAG , pages 108 -- 109 ) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment .', 'This, they suggest, may result in a paradigm shift from TM to EBMT via the phrasal lexicon: Translators are on the whole wary of MT technology, but once subsentential alignment is enabled, translators will become aware of the benefits to be gained from _source, target_ phrasal segments, and from there they suggest that �it is a reasonably short step to enabling an automated solution via the recombination element of EBMT systems such as those described in [Carl and Way 2003].�']",0
"['', '', '', 'attempt to relation matrices from such are derived a pair of nonparallel corpora.', ' #TAUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance .', '', '', '', '', '']","['', '', '', 'attempt to relation matrices, from such are derived a pair of nonparallel corpora.', ' #TAUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance .', '', '', '', '', '']","['', '', '', ' #AUTHOR_TAG attempt to word relation matrices, from such relations are derived is a pair of nonparallel corpora.', ' #TAUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance .', '', '', '', '', '']","['', '', '', '', ' #TAUTHOR_TAG replicates the work of Fung and McKeown with different language pairs using the simpler metric of Levenshtein distance .', '', '', '', '', '']",0
"[' #TAUTHOR_TAG , 1997 ) assumes that words ending in - ed are verbs .', 'However, given that verbs are not a closed class, in our approach we do not mark chunks beginning with a verb with any marker category.', 'we take advantage of the fact that the initial phrasal chunks correspond to rule right-hand sides', 'the, a present particip', '', '']","[' #TAUTHOR_TAG , 1997 ) assumes that words ending in - ed are verbs .', 'However, given that verbs are not a closed class, in our approach we do not mark chunks beginning with a verb with any marker category.', 'we take advantage of the fact that the initial phrasal chunks correspond to rule right-hand sides.', 'the is, a present', '', '']","[' #TAUTHOR_TAG , 1997 ) assumes that words ending in - ed are verbs .', 'However, given that verbs are not a closed class, in our approach we do not mark chunks beginning with a verb with any marker category.', 'we take advantage of the fact that the initial phrasal chunks correspond to rule right-hand sides.', ', a present participle.', '', '']","[' #TAUTHOR_TAG , 1997 ) assumes that words ending in - ed are verbs .', 'However, given that verbs are not a closed class, in our approach we do not mark chunks beginning with a verb with any marker category.', 'Instead, we take advantage of the fact that the initial phrasal chunks correspond to rule right-hand sides.', '', '', '']",1
"['', '', '', '', '', '', '', '', '', 'We have yet to import such a constraint into our model , but we plan to do so in the near future using the weighted majority algorithm #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', 'We have yet to import such a constraint into our model , but we plan to do so in the near future using the weighted majority algorithm #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', 'We have yet to import such a constraint into our model , but we plan to do so in the near future using the weighted majority algorithm #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', 'We have yet to import such a constraint into our model , but we plan to do so in the near future using the weighted majority algorithm #TAUTHOR_TAG .']",3
"['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', '', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; #TAUTHOR_TAG ; Carl 1999 ) .7']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', '', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; #TAUTHOR_TAG ; Carl 1999 ) .7']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', '', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; #TAUTHOR_TAG ; Carl 1999 ) .7']","['When translated phrases have been retrieved for each chunk of the input string, they must then be combined to produce an output string.', '', 'Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; #TAUTHOR_TAG ; Carl 1999 ) .7']",0
"['The problem of boundary friction is clearly here We have inserted a feminine singular determiner into a chunk that was generalized from a masculine plural NP.', 'However , rather than output this wrong translation directly , we use a post hoc validation and ( if required ) correction process based on #TAUTHOR_TAG .', 'Grefen the Web can be used', '', '', '', '', '', '', '']","['The problem of boundary friction is clearly here: We have inserted a feminine singular determiner into a chunk that was generalized from a masculine plural NP.', 'However , rather than output this wrong translation directly , we use a post hoc validation and ( if required ) correction process based on #TAUTHOR_TAG .', 'Grefenstette the Web can be used', '', '', '', '', '', '', '']","['The problem of boundary friction is clearly We have inserted a feminine singular determiner into a chunk that was generalized from a masculine plural NP.', 'However , rather than output this wrong translation directly , we use a post hoc validation and ( if required ) correction process based on #TAUTHOR_TAG .', 'Grefen the Web can be used', '', '', '', '', '', '', '']","['The problem of boundary friction is clearly visible here: We have inserted a feminine singular determiner into a chunk that was generalized from a masculine plural NP.', 'However , rather than output this wrong translation directly , we use a post hoc validation and ( if required ) correction process based on #TAUTHOR_TAG .', '', '', '', '', '', '', '', '']",5
"['Given that the marker hypothesis is arguably universal, it is clear that benefits may accrue by using it to facilitate subsentential alignment of source, target chunks.', ' #TAUTHOR_TAG , 1997 ) conducts some small experiments using his METLA system to show the viability of this approach for English â\x88\x92 > French and English â\x88\x92 > Urdu .', '→ language pair, Ju', '', '', '', '']","['Given that the marker hypothesis is arguably universal, it is clear that benefits may accrue by using it to facilitate subsentential alignment of source, target chunks.', ' #TAUTHOR_TAG , 1997 ) conducts some small experiments using his METLA system to show the viability of this approach for English â\x88\x92 > French and English â\x88\x92 > Urdu .', '−→ language pair, Juola', '', '', '', '']","['Given that the marker hypothesis is arguably universal, it is clear that benefits may accrue by using it to facilitate subsentential alignment of source, target chunks.', ' #TAUTHOR_TAG , 1997 ) conducts some small experiments using his METLA system to show the viability of this approach for English â\x88\x92 > French and English â\x88\x92 > Urdu .', 'French language pair, Juola', '', '', '', '']","['Given that the marker hypothesis is arguably universal, it is clear that benefits may accrue by using it to facilitate subsentential alignment of source, target chunks.', ' #TAUTHOR_TAG , 1997 ) conducts some small experiments using his METLA system to show the viability of this approach for English â\x88\x92 > French and English â\x88\x92 > Urdu .', '', '', '', '', '']",0
"['¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization #TAUTHOR_TAG â\x80¢ insights into universal grammar ( Juola 1998 )\x80¢ machine translation ( Juola 1994 , 1997 ; Veale and Way 7 ; Gough , , and Hearne 2 )']","['language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization #TAUTHOR_TAG â\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; Veale and Way ; Gough , , and Hearne )']","['¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization #TAUTHOR_TAG â\x80¢ insights into universal grammar ( Juola 1998 )\x80¢ machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , , and Hearne 2002 )']","['â\x80¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization #TAUTHOR_TAG â\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , Way , and Hearne 2002 )']",0
"['In a final processing stage , we generalize over the marker lexicon following a process found in #TAUTHOR_TAG .', ""In's approach, word alignments are assigned probabilities by means of a statistical word alignment."", 'chunk extracted']","['In a final processing stage , we generalize over the marker lexicon following a process found in #TAUTHOR_TAG .', ""In Block's approach, word alignments are assigned probabilities by means of a statistical word alignment tool."", 'chunk extracted,']","['In a final processing stage , we generalize over the marker lexicon following a process found in #TAUTHOR_TAG .', ""In's approach, word alignments are assigned probabilities by means of a statistical word alignment tool."", 'extracted']","['In a final processing stage , we generalize over the marker lexicon following a process found in #TAUTHOR_TAG .', ""In Block's approach, word alignments are assigned probabilities by means of a statistical word alignment tool."", '']",5
"['', '', '', '', '', '', 'to in the to be', 'Following construction of the marker lexicon , the ( source , target ) chunks are generalized further using a methodology based on #TAUTHOR_TAG to permit a limited form of insertion in the translation process .', 'we a ""- le', '']","['', '', '', '', '', '', 'to in the to be', 'Following construction of the marker lexicon , the ( source , target ) chunks are generalized further using a methodology based on #TAUTHOR_TAG to permit a limited form of insertion in the translation process .', 'we a', '']","['', '', '', '', '', '', 'to in the languages to be', 'Following construction of the marker lexicon , the ( source , target ) chunks are generalized further using a methodology based on #TAUTHOR_TAG to permit a limited form of insertion in the translation process .', 'we', '']","['', '', '', '', '', '', '', 'Following construction of the marker lexicon , the ( source , target ) chunks are generalized further using a methodology based on #TAUTHOR_TAG to permit a limited form of insertion in the translation process .', '', '']",5
"['the isably universal is clear that benefits may accue to facilitate subsential of source, target chunks.', '', '', '', '', '', 'In their Gaijin system , #TAUTHOR_TAG give a result of 63 % accurate translations obtained for English â\x88\x92 > German on a test set of 791 sentences from CorelDRAW manuals .']","['the is universal, is clear that benefits may accrue to facilitate subsentential of source, target chunks.', '', '', '', '', '', 'In their Gaijin system , #TAUTHOR_TAG give a result of 63 % accurate translations obtained for English â\x88\x92 > German on a test set of 791 sentences from CorelDRAW manuals .']","['is arguably universal it is clear that benefits may accrue to facilitate subsential alignment of source, target chunks.', '', '', '', '', '', 'In their Gaijin system , #TAUTHOR_TAG give a result of 63 % accurate translations obtained for English â\x88\x92 > German on a test set of 791 sentences from CorelDRAW manuals .']","['Given that the marker hypothesis is arguably universal, it is clear that benefits may accrue by using it to facilitate subsentential alignment of source, target chunks.', '', '', '', '', '', 'In their Gaijin system , #TAUTHOR_TAG give a result of 63 % accurate translations obtained for English â\x88\x92 > German on a test set of 791 sentences from CorelDRAW manuals .']",1
"['â\x80¢ language learning ( Green 1979 ; #TAUTHOR_TAG ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 )¢ insights into universal grammar ( Ju  )¢']","['â\x80¢ language learning ( Green 1979 ; #TAUTHOR_TAG ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 ) insights into universal grammar ( Juola )']","['â\x80¢ language learning ( Green 1979 ; #TAUTHOR_TAG ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 )¢ insights into universal grammar ( Ju )¢']","['â\x80¢ language learning ( Green 1979 ; #TAUTHOR_TAG ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction ( Juola 1998 ) â\x80¢ grammar optimization ( Juola 1994 ) â\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , Way , and Hearne 2002 )']",0
"['â\x80¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction #TAUTHOR_TAG â\x80¢ grammar optimization ( Juola 1994 ) â\x80¢ insights into universal grammar ( Juola 1998 )¢ machine translation Ju , ; Gough ,']","['â\x80¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction #TAUTHOR_TAG â\x80¢ grammar optimization ( Juola 1994 ) â\x80¢ insights into universal grammar ( Juola 1998 ) machine translation Juola , ; Gough ,']","['â\x80¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction #TAUTHOR_TAG â\x80¢ grammar optimization ( Juola 1994 ) â\x80¢ insights into universal grammar ( Juola 1998 )¢ machine translation Ju , ; Gough ,']","['â\x80¢ language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) â\x80¢ monolingual grammar induction #TAUTHOR_TAG â\x80¢ grammar optimization ( Juola 1994 ) â\x80¢ insights into universal grammar ( Juola 1998 ) â\x80¢ machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , Way , and Hearne 2002 )']",0
"['the is may accue to facilitate subsential _ chunks', '', 'For the English __ French language pair, Ju gives results of61% correct when the system is tested on the training cor, and36% accuracy when it is evaluated with test data.', 'For English â\x88\x92 > Urdu , #TAUTHOR_TAG , page 213 ) notes that ""the system learned the original training corpus ... perfectly and could reproduce it without errors ; that is , it scored 100 % accuracy when tested against the training corpus .', 'On novel test sentences, he gives results of 72% correct translation.', 'Gaij #AUTHOR_TAG6 transl obtained']","['the is may accrue to facilitate subsentential chunks.', '', 'For the English __ French language pair, Juola gives results of 61% correct when the system is tested on the training corpus, and 36% accuracy when it is evaluated with test data.', 'For English â\x88\x92 > Urdu , #TAUTHOR_TAG , page 213 ) notes that ""the system learned the original training corpus ... perfectly and could reproduce it without errors ; that is , it scored 100 % accuracy when tested against the training corpus .', 'On novel test sentences, he gives results of 72% correct translation.', 'Gaijin #AUTHOR_TAG translations obtained']","['it is may accrue to facilitate subsential alignment _', '', 'For the English __ French language pair, Juola gives results of61% correct translation when the system is tested on the training corpus, and36% accuracy when it is evaluated with test data.', 'For English â\x88\x92 > Urdu , #TAUTHOR_TAG , page 213 ) notes that ""the system learned the original training corpus ... perfectly and could reproduce it without errors ; that is , it scored 100 % accuracy when tested against the training corpus .', 'On novel test sentences, he gives results of 72% correct translation.', 'Gaij #AUTHOR_TAG6 obtained']","['', '', 'For the English __ French language pair, Juola gives results of 61% correct translation when the system is tested on the training corpus, and 36% accuracy when it is evaluated with test data.', 'For English â\x88\x92 > Urdu , #TAUTHOR_TAG , page 213 ) notes that ""the system learned the original training corpus ... perfectly and could reproduce it without errors ; that is , it scored 100 % accuracy when tested against the training corpus .', 'On novel test sentences, he gives results of 72% correct translation.', '']",0
"['', 'are derived from, patterns are computed from the derived chunks means following Using described above, the patterns in ( 26) are derived from the chunks in ( 2): Of, researchers to', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , Mc #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG , inter alia .']","['', 'are derived from patterns are computed from the derived chunks means following Using described above, the patterns in ( 26) are derived from the chunks in ( 25): Of course, researchers to', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , Mc #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG , inter alia .']","['', 'are derived from are computed from the derived chunks means described above, the patterns in ( 26) are derived from the chunks in ( 2): Of, to', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , Mc #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG , inter alia .']","['', 'Once chunks are derived from source, target alignments, patterns are computed from the derived chunks by means of the following algorithm: ""for each pair of chunk pairs Using the algorithm described above, the patterns in ( 26) are derived from the chunks in ( 25): Of course, many other researchers also try to extract generalized templates.', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , Mc #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG , inter alia .']",0
"['', '', 'First, the phrasalxicon is segmented using the marker hypothesis to produce a marker lexicon.', 'This is then generalized , following a methodology based on #TAUTHOR_TAG , to generate the `` generalized marker lexicon .', '', '']","['', '', 'First, the phrasal lexicon is segmented using the marker hypothesis to produce a marker lexicon.', 'This is then generalized , following a methodology based on #TAUTHOR_TAG , to generate the `` generalized marker lexicon .', '', '']","['', '', 'First, the phrasal lexicon is segmented using the marker hypothesis to produce a marker lexicon.', 'This is then generalized , following a methodology based on #TAUTHOR_TAG , to generate the `` generalized marker lexicon .', '', '']","['', '', 'First, the phrasal lexicon is segmented using the marker hypothesis to produce a marker lexicon.', ""This is then generalized , following a methodology based on #TAUTHOR_TAG , to generate the `` generalized marker lexicon . ''"", '', '']",5
"['â\x80¢ Learnability ( Zernik and Dyer 1987 ) â\x80¢ Text generation ( Hovy 1988 ;osavljevic , Tulloch , and Dale 1996 ) â\x80¢ Speech generation #TAUTHOR_TAG â\x80¢ Localization ( Sch Â¨ aler 1996 )']","['â\x80¢ Learnability ( Zernik and Dyer 1987 ) â\x80¢ Text generation ( Hovy 1988 ; Milosavljevic , Tulloch , and Dale 1996 ) â\x80¢ Speech generation #TAUTHOR_TAG â\x80¢ Localization ( Sch Â¨ aler 1996 )']","['â\x80¢ Learnability ( Zernik and Dyer 1987 ) â\x80¢ Text generation ( Hovy 1988 ;osavljevic , Tulloch , and Dale 1996 ) â\x80¢ Speech generation #TAUTHOR_TAG â\x80¢ Localization ( Sch Â¨ aler 1996 )']","['â\x80¢ Learnability ( Zernik and Dyer 1987 ) â\x80¢ Text generation ( Hovy 1988 ; Milosavljevic , Tulloch , and Dale 1996 ) â\x80¢ Speech generation #TAUTHOR_TAG â\x80¢ Localization ( Sch Â¨ aler 1996 )']",0
"[""Each set of translations is stored separately , and for each set the `` marker hypothesis '' #TAUTHOR_TAG is used to segment the phrasal lexicon into a `` marker lexicon . ''"", 'The marker hypothesis is a universal psycholinguistic constraint which states that natural languages are ""marked"" for complex syntactic structure at surface form by a closed set of specific lexemes and morphemes', '']","[""Each set of translations is stored separately , and for each set the `` marker hypothesis '' #TAUTHOR_TAG is used to segment the phrasal lexicon into a `` marker lexicon . ''"", 'The marker hypothesis is a universal psycholinguistic constraint which states that natural languages are ""marked"" for complex syntactic structure at surface form by a closed set of specific lexemes and morphemes.', '']","[""Each set of translations is stored separately , and for each set the `` marker hypothesis '' #TAUTHOR_TAG is used to segment the phrasal lexicon into a `` marker lexicon . ''"", 'The marker hypothesis is a universal psycholinguistic constraint which states that natural languages are ""marked"" for complex syntactic structure at surface form by a closed set of specific lexemes and morphemes', '']","[""Each set of translations is stored separately , and for each set the `` marker hypothesis '' #TAUTHOR_TAG is used to segment the phrasal lexicon into a `` marker lexicon . ''"", 'The marker hypothesis is a universal psycholinguistic constraint which states that natural languages are ""marked"" for complex syntactic structure at surface form by a closed set of specific lexemes and morphemes.', '']",5
"['That is, where #TAUTHOR_TAG substitutes variables for various words in his templates, we replace certain lexical items with their marker tag.', 'Given that examples such as ��<DET> a : un� are likely to exist in the word-level lexicon, they may be inserted at the point indicated by the to form the correct translation un bon.', '']","['That is, where #TAUTHOR_TAG substitutes variables for various words in his templates, we replace certain lexical items with their marker tag.', 'Given that examples such as ��<DET> a : un� are likely to exist in the word-level lexicon, they may be inserted at the point indicated by the to form the correct translation un bon homme.', '']","['That is, where #TAUTHOR_TAG substitutes variables for various words in his templates, we replace certain lexical items with their marker tag.', 'Given that examples such as ��<DET> a : un� are likely to exist in the word-level lexicon, they may be inserted at the point indicated by to form the correct translation un bon homme.', '']","['That is, where #TAUTHOR_TAG substitutes variables for various words in his templates, we replace certain lexical items with their marker tag.', 'Given that examples such as ��<DET> a : un� are likely to exist in the word-level lexicon, they may be inserted at the point indicated by the marker tag to form the correct translation un bon homme.', '']",1
"['', '', '', 'Jus ( , 8 work on grammar optimization andction shows that context-free grars can be converted to ""marker-normal form.""', ', marker- grammars cannot capture the of regularities demonstrated for languages that do not have a oneto-one mapping between a terminal symbol and a word.', ""Nevertheless , #TAUTHOR_TAG , page 23 ) observes that `` a slightly more general mapping , where two adjacent terminal symbols can be merged into a single lexical item ( for example , a word and its case-marking ) , can capture this sort of result quite handily . ''"", 'Work using the marker hypothesis for MT adapts this monolingual mapping for pairs of languages: It is straightforward to map an Englishiner-noun onto a Japanese noun- the of marker in the to be', '', '', '']","['', '', '', 'Juola\'s ( , work on grammar optimization and induction shows that context-free grammars can be converted to ""marker-normal form.""', 'However, marker-normal grammars cannot capture the of regularities demonstrated for languages that do not have a oneto-one mapping between a terminal symbol and a word.', ""Nevertheless , #TAUTHOR_TAG , page 23 ) observes that `` a slightly more general mapping , where two adjacent terminal symbols can be merged into a single lexical item ( for example , a word and its case-marking ) , can capture this sort of result quite handily . ''"", 'Work using the marker hypothesis for MT adapts this monolingual mapping for pairs of languages: It is straightforward to map an English determiner-noun onto a Japanese noun-case the of marker in the to be', '', '', '']","['', '', '', '( , 8 work on grammar optimization andction shows that context-free grammars can be converted to ""marker-normal form.""', ', marker-normal form grammars cannot capture the sorts of regularities demonstrated for languages that do not have a oneto-one mapping between a terminal symbol and a word.', ""Nevertheless , #TAUTHOR_TAG , page 23 ) observes that `` a slightly more general mapping , where two adjacent terminal symbols can be merged into a single lexical item ( for example , a word and its case-marking ) , can capture this sort of result quite handily . ''"", 'Work using the marker hypothesis for MT adapts this monolingual mapping for pairs of languages: It is reasonably straightforward to map an English determiner-noun sequence onto a Japanese noun-case marker segment, the sets of marker tags in the languages to be', '', '', '']","['', '', '', ' #AUTHOR_TAG Juola\'s ( , 1998 work on grammar optimization and induction shows that context-free grammars can be converted to ""marker-normal form.""', 'However, marker-normal form grammars cannot capture the sorts of regularities demonstrated for languages that do not have a oneto-one mapping between a terminal symbol and a word.', ""Nevertheless , #TAUTHOR_TAG , page 23 ) observes that `` a slightly more general mapping , where two adjacent terminal symbols can be merged into a single lexical item ( for example , a word and its case-marking ) , can capture this sort of result quite handily . ''"", 'Work using the marker hypothesis for MT adapts this monolingual mapping for pairs of languages: It is reasonably straightforward to map an English determiner-noun sequence onto a Japanese noun-case marker segment, once one has identified the sets of marker tags in the languages to be translated.', '', '', '']",0
"['', 'are derived from, patterns are computed from the derived chunks means following each Using described above, the patterns in ( 26) are derived from the chunks in ( 25): Of, many researchers', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , Mc #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , inter alia .']","['', 'are derived from patterns are computed from the derived chunks means following each Using described above, the patterns in ( 26) are derived from the chunks in ( 25): Of course, many researchers', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , Mc #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , inter alia .']","['', 'are derived from are computed from the derived chunks means each pair described above, the patterns in ( 26) are derived from the chunks in ( 25): Of, many other researchers', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , Mc #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , inter alia .']","['', 'Once chunks are derived from source, target alignments, patterns are computed from the derived chunks by means of the following algorithm: ""for each pair of chunk pairs Using the algorithm described above, the patterns in ( 26) are derived from the chunks in ( 25): Of course, many other researchers also try to extract generalized templates.', '', '', 'Other similar approaches include those of Cicekli and G Â¨ uvenir ( 1996 ) , Mc #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , inter alia .']",0
"['', '', '', '', '', '', '', '', '', 'More specifically , the notion of the phrasal lexicon ( used first by #TAUTHOR_TAG has been used successfully in a number of areas :']","['', '', '', '', '', '', '', '', '', 'More specifically , the notion of the phrasal lexicon ( used first by #TAUTHOR_TAG has been used successfully in a number of areas :']","['', '', '', '', '', '', '', '', '', 'More specifically , the notion of the phrasal lexicon ( used first by #TAUTHOR_TAG has been used successfully in a number of areas :']","['', '', '', '', '', '', '', '', '', 'More specifically , the notion of the phrasal lexicon ( used first by #TAUTHOR_TAG has been used successfully in a number of areas :']",0
"['All EBMT systems , from the initial proposal by #TAUTHOR_TAG to the recent collection of #AUTHOR_TAG , are premised on the availability of subsentential alignments derived from the input bitext .', 'is a of literature on trying to establish subsentential translations bual cor', '', '', '', '', '', '', '', '']","['All EBMT systems , from the initial proposal by #TAUTHOR_TAG to the recent collection of #AUTHOR_TAG , are premised on the availability of subsentential alignments derived from the input bitext .', 'is a of literature on trying to establish subsentential translations bilingual', '', '', '', '', '', '', '', '']","['All EBMT systems , from the initial proposal by #TAUTHOR_TAG to the recent collection of #AUTHOR_TAG , are premised on the availability of subsentential alignments derived from the input bitext .', 'is a wealth of literature on trying to establish subsentential translations', '', '', '', '', '', '', '', '']","['All EBMT systems , from the initial proposal by #TAUTHOR_TAG to the recent collection of #AUTHOR_TAG , are premised on the availability of subsentential alignments derived from the input bitext .', 'There is a wealth of literature on trying to establish subsentential translations from a bilingual corpus. 3', '', '', '', '', '', '', '', '']",0
"['', 'derived are computed derived following each Using described above, the patterns in ( 26) are derived from the chunks in ( 2): Of course, many other researchers to extract generalized templates.', 'suchents with to generate a set of translation patterns.', ' #TAUTHOR_TAG combines lexical and dependency mappings to form his generalizations .', 'Other similar approaches include Cicek and Güven (1996), Mc #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ,']","['', 'derived are computed derived following each Using described above, the patterns in ( 26) are derived from the chunks in ( 25): Of course, many other researchers to extract generalized templates.', 'such equivalents with to generate a set of translation patterns.', ' #TAUTHOR_TAG combines lexical and dependency mappings to form his generalizations .', 'Other similar approaches include Cicekli and Güvenir (1996), Mc #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ,']","['', 'are derived are computed derived each pair described above, the patterns in ( 26) are derived from the chunks in ( 2): Of course, many other researchers to extract generalized templates.', 'such equivalents with to generate a set of translation patterns.', ' #TAUTHOR_TAG combines lexical and dependency mappings to form his generalizations .', 'Other similar approaches include Cicek and Güven (1996), Mc #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ,']","['', 'Once chunks are derived from source, target alignments, patterns are computed from the derived chunks by means of the following algorithm: ""for each pair of chunk pairs Using the algorithm described above, the patterns in ( 26) are derived from the chunks in ( 25): Of course, many other researchers also try to extract generalized templates.', '', ' #TAUTHOR_TAG combines lexical and dependency mappings to form his generalizations .', 'Other similar approaches include those of Cicekli and Güvenir (1996), Mc #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , inter alia.']",0
"['where V is a random variable that can take any possible outcome in set V, and p(v) = Pr(V = v) is the density function.', 'Further details about the properties of entropy can be found in textbooks on information theory ( e.g. , #TAUTHOR_TAG .', 'parse', 'direct application', '', '', '', '', '']","['where V is a random variable that can take any possible outcome in set V, and p(v) = Pr(V = v) is the density function.', 'Further details about the properties of entropy can be found in textbooks on information theory ( e.g. , #TAUTHOR_TAG .', 'parse', 'direct application', '', '', '', '', '']","['where V is a random variable that can take any possible outcome in set V, and p(v) = Pr(V = v) is the density function.', 'Further details about the properties of entropy can be found in textbooks on information theory ( e.g. , #TAUTHOR_TAG .', '', 'a direct application', '', '', '', '', '']","['where V is a random variable that can take any possible outcome in set V, and p(v) = Pr(V = v) is the density function.', 'Further details about the properties of entropy can be found in textbooks on information theory ( e.g. , #TAUTHOR_TAG .', '', '', '', '', '', '', '']",0
"['applied tonotationleneck', '', '', '', '', 'The work of #TAUTHOR_TAG and Steedman , Osborne , et al. ( 2003 ) suggests that co-training can be helpful for statistical parsing .', '', '']","['applied to annotation bottleneck', '', '', '', '', 'The work of #TAUTHOR_TAG and Steedman , Osborne , et al. ( 2003 ) suggests that co-training can be helpful for statistical parsing .', '', '']","['have applied to', '', '', '', '', 'The work of #TAUTHOR_TAG and Steedman , Osborne , et al. ( 2003 ) suggests that co-training can be helpful for statistical parsing .', '', '']","['', '', '', '', '', 'The work of #TAUTHOR_TAG and Steedman , Osborne , et al. ( 2003 ) suggests that co-training can be helpful for statistical parsing .', '', '']",0
"['benefits problems in which the costiring raw data is cheap but thenotating them is high, as is certainly the case for many supervised learning tasks in natural language processing.', 'In addition to PP-attachment, as discussed in this article, sample selection has been successfully applied to other classification applications.', 'Some examples include text categorization #TAUTHOR_TAG , base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill  ) , and word sense disambiguation ( Fii et.1998 ) .']","['benefits problems in which the cost acquiring raw data is cheap but the annotating them is high, as is certainly the case for many supervised learning tasks in natural language processing.', 'In addition to PP-attachment, as discussed in this article, sample selection has been successfully applied to other classification applications.', 'Some examples include text categorization #TAUTHOR_TAG , base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill ) , and word sense disambiguation ( Fujii et al. 1998 ) .']","['Sample selection benefits problems in which the costiring raw data is cheap but the costnotating them is high, as is certainly the case for many supervised learning tasks in natural language processing.', 'In addition to PP-attachment, as discussed in this article, sample selection has been successfully applied to other classification applications.', 'Some examples include text categorization #TAUTHOR_TAG , base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Br ) , and word sense disambiguation ( Fii et.1998 ) .']","['Sample selection benefits problems in which the cost of acquiring raw data is cheap but the cost of annotating them is high, as is certainly the case for many supervised learning tasks in natural language processing.', 'In addition to PP-attachment, as discussed in this article, sample selection has been successfully applied to other classification applications.', 'Some examples include text categorization #TAUTHOR_TAG , base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill 2001 ) , and word sense disambiguation ( Fujii et al. 1998 ) .']",0
"['from active, researchers have applied other learning techniques to combat the annotation bottleneck problem in parsing', '', '', '', 'Another technique for making better use of unlabeled data is cotraining #TAUTHOR_TAG , in which two sufficiently different learners help each other learn by labeling training data for one another .', '', '', '']","['from active learning, researchers have applied other learning techniques to combat the annotation bottleneck problem in parsing.', '', '', '', 'Another technique for making better use of unlabeled data is cotraining #TAUTHOR_TAG , in which two sufficiently different learners help each other learn by labeling training data for one another .', '', '', '']","['from active learning, researchers have applied other learning techniques to combat the annotation bottleneck problem in parsing', '', '', '', 'Another technique for making better use of unlabeled data is cotraining #TAUTHOR_TAG , in which two sufficiently different learners help each other learn by labeling training data for one another .', '', '', '']","['Aside from active learning, researchers have applied other learning techniques to combat the annotation bottleneck problem in parsing.', '', '', '', 'Another technique for making better use of unlabeled data is cotraining #TAUTHOR_TAG , in which two sufficiently different learners help each other learn by labeling training data for one another .', '', '', '']",0
"['', 'shar', '', ""predict domain , we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism #TAUTHOR_TAG ; Hwa 1998 ) , and Collins 's Model 2 parser ( 1997 ) ."", 'Although models arexicalized', '', '']","['', '', '', ""predictive domain , we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism #TAUTHOR_TAG ; Hwa 1998 ) , and Collins 's Model 2 parser ( 1997 ) ."", 'Although models are lexicalized,', '', '']","['', '', '', "", we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism #TAUTHOR_TAG ; Hwa 1998 ) , and Collins 's Model 2 parser ( 1997 ) ."", 'Although both models arexicalized', '', '']","['', '', '', ""Moreover , in order to determine whether the performances of the predictive criteria are consistent across different learning models within the same domain , we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism #TAUTHOR_TAG ; Hwa 1998 ) , and Collins 's Model 2 parser ( 1997 ) ."", '', '', '']",5
"['of structuraluities ar fromactic in which apositional equally theoun.', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models #TAUTHOR_TAG , and a maximumentropy model ( Ratnaparkhi 1998 ) .', '', '']","['of structural ambiguities arises from syntactic in which a prepositional equally the noun it.', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models #TAUTHOR_TAG , and a maximumentropy model ( Ratnaparkhi 1998 ) .', '', '']","['of structural ambiguities ar from in which a prepositional phrase', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models #TAUTHOR_TAG , and a maximumentropy model ( Ratnaparkhi 1998 ) .', '', '']","['', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models #TAUTHOR_TAG , and a maximumentropy model ( Ratnaparkhi 1998 ) .', '', '']",0
"['is cheap is as is certainly the case for many supervised learning tasks in natural processing.', '', 'includeization and Catlett 9 base noun phraseing ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation #TAUTHOR_TAG , and word sense disambiguation ( Fujii et al. 1998 ) .']","['is cheap is as is certainly the case for many supervised learning tasks in natural processing.', '', 'include categorization and Catlett base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation #TAUTHOR_TAG , and word sense disambiguation ( Fujii et al. 1998 ) .']","['is cheap them is as is certainly the case for many supervised learning tasks in natural language processing.', '', 'include and Catlett 1994 base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation #TAUTHOR_TAG , and word sense disambiguation ( Fujii et al. 1998 ) .']","['', '', 'Some examples include text categorization ( Lewis and Catlett 1994 ) , base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation #TAUTHOR_TAG , and word sense disambiguation ( Fujii et al. 1998 ) .']",0
"['Using the bottom-up , dynamic programming technique ( see the appendix for details ) of computing inside probabilities #TAUTHOR_TAG , we can efficiently compute the probability of the sentence , P ( w | G ) .', 'Similarly, the algorithm can be modified to compute the quantity']","['Using the bottom-up , dynamic programming technique ( see the appendix for details ) of computing inside probabilities #TAUTHOR_TAG , we can efficiently compute the probability of the sentence , P ( w | G ) .', 'Similarly, the algorithm can be modified to compute the quantity']","['Using the bottom-up , dynamic programming technique ( see the appendix for details ) of computing inside probabilities #TAUTHOR_TAG , we can efficiently compute the probability of the sentence , P ( w | G ) .', 'Similarly, the algorithm can be modified to compute the quantity']","['Using the bottom-up , dynamic programming technique ( see the appendix for details ) of computing inside probabilities #TAUTHOR_TAG , we can efficiently compute the probability of the sentence , P ( w | G ) .', 'Similarly, the algorithm can be modified to compute the quantity']",5
"['', '', 'vised', '', '', '', 'Our algorithm is similar to the approach taken by #TAUTHOR_TAG for inducing PCFG parsers .']","['', '', '', '', '', '', 'Our algorithm is similar to the approach taken by #TAUTHOR_TAG for inducing PCFG parsers .']","['', '', 'vised', '', '', '', 'Our algorithm is similar to the approach taken by #TAUTHOR_TAG for inducing PCFG parsers .']","['', '', '', '', '', '', 'Our algorithm is similar to the approach taken by #TAUTHOR_TAG for inducing PCFG parsers .']",1
"['Many learning tasks for natural language processing require supervised training; that is, the system successfully learns a concept only if it has been given annotated training data.', 'For example , while it is difficult to induce a grammar with raw text alone , the task is tractable when the syntactic analysis for each sentence is provided as a part of the training data #TAUTHOR_TAG .', 'Current state-of-the-art statistical parsers (Collins 1999;Charniak 2000) are all trained on large annotated corpora such as the Penn Treebank (Marcus, Santor Marcinkicz 3', '', '', '', '']","['Many learning tasks for natural language processing require supervised training; that is, the system successfully learns a concept only if it has been given annotated training data.', 'For example , while it is difficult to induce a grammar with raw text alone , the task is tractable when the syntactic analysis for each sentence is provided as a part of the training data #TAUTHOR_TAG .', 'Current state-of-the-art statistical parsers (Collins 1999;Charniak 2000) are all trained on large annotated corpora such as the Penn Treebank (Marcus, Santorini, Marcinkiewicz', '', '', '', '']","['Many learning tasks for natural language processing require supervised training; that is, the system successfully learns a concept only if it has been given annotated training data.', 'For example , while it is difficult to induce a grammar with raw text alone , the task is tractable when the syntactic analysis for each sentence is provided as a part of the training data #TAUTHOR_TAG .', 'Current state-of-the-art statistical parsers (Collins 1999;Charniak 2000) are all trained on large annotated corpora such as the Penn Treebank (Marcus, Santorini, Marcink', '', '', '', '']","['Many learning tasks for natural language processing require supervised training; that is, the system successfully learns a concept only if it has been given annotated training data.', 'For example , while it is difficult to induce a grammar with raw text alone , the task is tractable when the syntactic analysis for each sentence is provided as a part of the training data #TAUTHOR_TAG .', 'Current state-of-the-art statistical parsers (Collins 1999;Charniak 2000) are all trained on large annotated corpora such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993).', '', '', '', '']",0
"['benefits problems in which the cost of acquiring raw data is cheap but the cost annotating them is high, as is certainly the case for many supervised learning tasks in natural language processing.', 'to-attachment, as in this, sample selection has been successfully applied to other classification applications.', 'Some examples include text categorization ( Lewis and Catlett 1994 ) , base noun phrase chunking #TAUTHOR_TAG , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill 200 ) , and word sense disambiguation ( Fii et.1998 ) .']","['benefits problems in which the cost of acquiring raw data is cheap but the cost annotating them is high, as is certainly the case for many supervised learning tasks in natural language processing.', 'to PP-attachment, as in this article, sample selection has been successfully applied to other classification applications.', 'Some examples include text categorization ( Lewis and Catlett 1994 ) , base noun phrase chunking #TAUTHOR_TAG , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill 2001 ) , and word sense disambiguation ( Fujii et al. 1998 ) .']","['Sample selection benefits problems in which the cost of acquiring raw data is cheap but the cost annotating them is high, as is certainly the case for many supervised learning tasks in natural language processing.', 'to-attachment, as in this article, sample selection has been successfully applied to other classification applications.', 'Some examples include text categorization ( Lewis and Catlett 1994 ) , base noun phrase chunking #TAUTHOR_TAG , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill 2001 ) , and word sense disambiguation ( Fii et.1998 ) .']","['Sample selection benefits problems in which the cost of acquiring raw data is cheap but the cost of annotating them is high, as is certainly the case for many supervised learning tasks in natural language processing.', 'In addition to PP-attachment, as discussed in this article, sample selection has been successfully applied to other classification applications.', 'Some examples include text categorization ( Lewis and Catlett 1994 ) , base noun phrase chunking #TAUTHOR_TAG , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill 2001 ) , and word sense disambiguation ( Fujii et al. 1998 ) .']",0
"['', 'shar', '', ""to domain , we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism ( Schabes and Waters 1993 ; #TAUTHOR_TAG , and Collins 's Model 2 parser ( 1997 ) ."", 'Although both models arexicalized, statisticals, learning algorithms are', '', '']","['', '', '', ""to domain , we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism ( Schabes and Waters 1993 ; #TAUTHOR_TAG , and Collins 's Model 2 parser ( 1997 ) ."", 'Although both models are lexicalized, statistical parsers, learning algorithms are', '', '']","['', '', '', ""to , we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism ( Schabes and Waters 1993 ; #TAUTHOR_TAG , and Collins 's Model 2 parser ( 1997 ) ."", 'Although both models arexicalized, statisticals, learning algorithms are', '', '']","['', '', '', ""Moreover , in order to determine whether the performances of the predictive criteria are consistent across different learning models within the same domain , we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism ( Schabes and Waters 1993 ; #TAUTHOR_TAG , and Collins 's Model 2 parser ( 1997 ) ."", 'Although both models are lexicalized, statistical parsers, their learning algorithms are different.', '', '']",5
"['have applied other techniques to annotation bottleneck in', '', '', '', '', '', ' #TAUTHOR_TAG have shown , in the context of base noun identification , that combining sample selection and cotraining can be an effective learning framework for large-scale training .', '3']","['have applied other techniques to annotation bottleneck in', '', '', '', '', '', ' #TAUTHOR_TAG have shown , in the context of base noun identification , that combining sample selection and cotraining can be an effective learning framework for large-scale training .', '']","['have applied other learning techniques to the annotation bottleneck problem in', '', '', '', '', '', ' #TAUTHOR_TAG have shown , in the context of base noun identification , that combining sample selection and cotraining can be an effective learning framework for large-scale training .', '3']","['', '', '', '', '', '', ' #TAUTHOR_TAG have shown , in the context of base noun identification , that combining sample selection and cotraining can be an effective learning framework for large-scale training .', '']",0
"['Many learning tasks for natural language processing require supervised training; the system successfullys a concept only if it has been given annotated training data.', 'it is difficult to induce a grammar with raw text alone, the task is tractable when the syntactic analysis for each sentence is provided as a part of the training data (Pereira and Schabes 199).', 'Current state-of-the-art statistical parsers #TAUTHOR_TAG ; Charniak 2000 ) are all trained on large annotated corpora such as the Penn Treebank ( Marcus , Santorini , and Marcinkiewicz 1993 ) .', '', '', '', '']","['Many learning tasks for natural language processing require supervised training; the system successfully learns a concept only if it has been given annotated training data.', 'it is difficult to induce a grammar with raw text alone, the task is tractable when the syntactic analysis for each sentence is provided as a part of the training data (Pereira and Schabes 1992).', 'Current state-of-the-art statistical parsers #TAUTHOR_TAG ; Charniak 2000 ) are all trained on large annotated corpora such as the Penn Treebank ( Marcus , Santorini , and Marcinkiewicz 1993 ) .', '', '', '', '']","['Many learning tasks for natural language processing require supervised training; the system successfullys a concept only if it has been given annotated training data.', 'it is difficult to induce a grammar with raw text alone, the task is tractable when the syntactic analysis for each sentence is provided as a part of the training data (Pereira and Schabes 1992).', 'Current state-of-the-art statistical parsers #TAUTHOR_TAG ; Charniak 2000 ) are all trained on large annotated corpora such as the Penn Treebank ( Marcus , Santorini , and Marcinkiewicz 1993 ) .', '', '', '', '']","['Many learning tasks for natural language processing require supervised training; that is, the system successfully learns a concept only if it has been given annotated training data.', 'For example, while it is difficult to induce a grammar with raw text alone, the task is tractable when the syntactic analysis for each sentence is provided as a part of the training data (Pereira and Schabes 1992).', 'Current state-of-the-art statistical parsers #TAUTHOR_TAG ; Charniak 2000 ) are all trained on large annotated corpora such as the Penn Treebank ( Marcus , Santorini , and Marcinkiewicz 1993 ) .', '', '', '', '']",0
"['One source of structural ambiguities arises from syntactic constructs in which apositional phrase be equally to modify the or the noun preceding it.', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models #TAUTHOR_TAG , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model ( Ratnaparkhi 1998 ) .', '', 'use theBrooks model as learning algorithm']","['One source of structural ambiguities arises from syntactic constructs in which a prepositional phrase be equally to modify the or the noun preceding it.', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models #TAUTHOR_TAG , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model ( Ratnaparkhi 1998 ) .', '', 'use the Collins-Brooks model as learning algorithm']","['One common source of structural ambiguities arises from syntactic constructs in which a prepositional phrase might be equally to modify the verb or the noun preceding it.', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models #TAUTHOR_TAG , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model ( Ratnaparkhi 1998 ) .', '', 'We use the Collins-Brooks model as the basic learning algorithm']","['One common source of structural ambiguities arises from syntactic constructs in which a prepositional phrase might be equally likely to modify the verb or the noun preceding it.', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models #TAUTHOR_TAG , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model ( Ratnaparkhi 1998 ) .', '', '']",0
"['In the first experiment , we use an induction algorithm #TAUTHOR_TAG a ) based on the expectation-maximization ( EM ) principle that induces parsers for PLTIGs .', 'The heistic through re procedure to local optima values for the grammarizes the gram generating the training data', 'unvised learning; too', '', '', '', '']","['In the first experiment , we use an induction algorithm #TAUTHOR_TAG a ) based on the expectation-maximization ( EM ) principle that induces parsers for PLTIGs .', 'The heuristic through procedure to local optima: values for the grammar maximizes the generating the training data.', 'unsupervised learning; too', '', '', '', '']","['In the first experiment , we use an induction algorithm #TAUTHOR_TAG a ) based on the expectation-maximization ( EM ) principle that induces parsers for PLTIGs .', 'The algorithm heistic search through to local optima: sets values for the grammar parametersizes generating the training data.', 'unvised learning has too', '', '', '', '']","['In the first experiment , we use an induction algorithm #TAUTHOR_TAG a ) based on the expectation-maximization ( EM ) principle that induces parsers for PLTIGs .', '', '', '', '', '', '']",5
"['Performance of the hypothesis: Testing the candidates on the current working hypothesis shows the type of input data on which the hypothesis may perform weakly.', 'That is , if the current hypothesis is unable to label a candidate or is uncertain about it , then the candidate might be a good training example #TAUTHOR_TAG .', 'The underlying assumption is that an uncertain output is likely to be wrong.']","['Performance of the hypothesis: Testing the candidates on the current working hypothesis shows the type of input data on which the hypothesis may perform weakly.', 'That is , if the current hypothesis is unable to label a candidate or is uncertain about it , then the candidate might be a good training example #TAUTHOR_TAG .', 'The underlying assumption is that an uncertain output is likely to be wrong.']","['Performance of the hypothesis: Testing the candidates on the current working hypothesis shows the type of input data on which the hypothesis may perform weakly.', 'That is , if the current hypothesis is unable to label a candidate or is uncertain about it , then the candidate might be a good training example #TAUTHOR_TAG .', 'The underlying assumption is that an uncertain output is likely to be wrong.']","['Performance of the hypothesis: Testing the candidates on the current working hypothesis shows the type of input data on which the hypothesis may perform weakly.', 'That is , if the current hypothesis is unable to label a candidate or is uncertain about it , then the candidate might be a good training example #TAUTHOR_TAG .', 'The underlying assumption is that an uncertain output is likely to be wrong.']",0
"['have applied other techniques to annotation bottleneck', '', '', '', '', '', '', 'Similar approaches are being explored for parsing ( Steedman , #TAUTHOR_TAG ; Hwa et al. 2003 ) .']","['have applied other techniques to annotation bottleneck', '', '', '', '', '', '', 'Similar approaches are being explored for parsing ( Steedman , #TAUTHOR_TAG ; Hwa et al. 2003 ) .']","['have applied other learning techniques to the annotation bottleneck problem', '', '', '', '', '', '', 'Similar approaches are being explored for parsing ( Steedman , #TAUTHOR_TAG ; Hwa et al. 2003 ) .']","['', '', '', '', '', '', '', 'Similar approaches are being explored for parsing ( Steedman , #TAUTHOR_TAG ; Hwa et al. 2003 ) .']",0
"['The-Brooks PP-attachment classification algorithm.', 'preposition, and the prepositional noun phrase, respectively, and a specifies the attachment classification.', 'For example, (wrote a in three days, attach-verb) would be annotated as (wrote, book, in, days, verb).', 'The head words can be automatically extracted using a heuristic table lookup in the manner described by #TAUTHOR_TAG .', 'bit', 'the builds attachment statistics for', '', '']","['The Collins-Brooks PP-attachment classification algorithm.', 'preposition, and the prepositional noun phrase, respectively, and a specifies the attachment classification.', 'For example, (wrote a in three days, attach-verb) would be annotated as (wrote, book, in, days, verb).', 'The head words can be automatically extracted using a heuristic table lookup in the manner described by #TAUTHOR_TAG .', '', 'the builds attachment statistics for', '', '']","['The Collins-Brooks PP-attachment classification algorithm.', 'preposition, and the prepositional noun phrase, respectively, and a specifies the attachment classification.', 'For example, (wrote a book in three days, attach-verb) would be annotated as (wrote, book, in, days, verb).', 'The head words can be automatically extracted using a heuristic table lookup in the manner described by #TAUTHOR_TAG .', '', 'the system builds attachment statistics for', '', '']","['The Collins-Brooks PP-attachment classification algorithm.', 'preposition, and the prepositional noun phrase, respectively, and a specifies the attachment classification.', 'For example, (wrote a book in three days, attach-verb) would be annotated as (wrote, book, in, days, verb).', 'The head words can be automatically extracted using a heuristic table lookup in the manner described by #TAUTHOR_TAG .', '', '', '', '']",5
"['ities ar fromactic in which apositional equally theoun', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model #TAUTHOR_TAG .', '', 'use theBro']","['arises from syntactic in which a prepositional equally the noun', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model #TAUTHOR_TAG .', '', 'use the']","['ar from in which a prepositional phrase', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model #TAUTHOR_TAG .', '', 'We use']","['', 'Researchers have proposed many computational models for resolving PPattachment ambiguities.', 'Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model #TAUTHOR_TAG .', '', '']",0
"['', '', 'b', 'We follow the notation convention of #TAUTHOR_TAG .']","['', '', '', 'We follow the notation convention of #TAUTHOR_TAG .']","['', '', '', 'We follow the notation convention of #TAUTHOR_TAG .']","['', '', '', 'We follow the notation convention of #TAUTHOR_TAG .']",5
"['Unlike traditional learning systems that receive training examples indiscriminately, a sample selection learning system actively influences its own progress by choosing new examples to incorporate into its training set.', 'There are two types of selection algorithms: committee-based and singlener.', 'A committee-based works with multiple learn maintaining a hypothesis (perhaps pertaining to different aspects of the problem).', 'The candidate examples that lead to the most disagreements among the different learners are considered to have the highest TUV ( Cohn , Atlas , and Ladner 1994 ; #TAUTHOR_TAG .', 'For computationally intensive problems, such as parsing, keeping multiple learners may be impractical.']","['Unlike traditional learning systems that receive training examples indiscriminately, a sample selection learning system actively influences its own progress by choosing new examples to incorporate into its training set.', 'There are two types of selection algorithms: committee-based and single learner.', 'A committee-based works with multiple maintaining a hypothesis (perhaps pertaining to different aspects of the problem).', 'The candidate examples that lead to the most disagreements among the different learners are considered to have the highest TUV ( Cohn , Atlas , and Ladner 1994 ; #TAUTHOR_TAG .', 'For computationally intensive problems, such as parsing, keeping multiple learners may be impractical.']","['Unlike traditional learning systems that receive training examples indiscriminately, a sample selection learning system actively influences its own progress by choosing new examples to incorporate into its training set.', 'There are two types of selection algorithms: committee-based and single learner.', 'A committee-based selection algorithm works with multiple learners, each maintaining a different hypothesis (perhaps pertaining to different aspects of the problem).', 'The candidate examples that lead to the most disagreements among the different learners are considered to have the highest TUV ( Cohn , Atlas , and Ladner 1994 ; #TAUTHOR_TAG .', 'For computationally intensive problems, such as parsing, keeping multiple learners may be impractical.']","['Unlike traditional learning systems that receive training examples indiscriminately, a sample selection learning system actively influences its own progress by choosing new examples to incorporate into its training set.', 'There are two types of selection algorithms: committee-based and single learner.', 'A committee-based selection algorithm works with multiple learners, each maintaining a different hypothesis (perhaps pertaining to different aspects of the problem).', 'The candidate examples that lead to the most disagreements among the different learners are considered to have the highest TUV ( Cohn , Atlas , and Ladner 1994 ; #TAUTHOR_TAG .', 'For computationally intensive problems, such as parsing, keeping multiple learners may be impractical.']",0
"['', '', '', '', 'The largest lexical evaluation we know of is that of Schulte im #AUTHOR_TAG b) for German.', 'She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden #TAUTHOR_TAG .', 'We will refer to this work and the methods and results presented by Schulte im Walde again in Sections 6.2 and 6.3.']","['', '', '', '', 'The largest lexical evaluation we know of is that of Schulte im #AUTHOR_TAG b) for German.', 'She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden #TAUTHOR_TAG .', 'We will refer to this work and the methods and results presented by Schulte im Walde again in Sections 6.2 and 6.3.']","['', '', '', '', 'The largest lexical evaluation we know of is that of Schulte im #AUTHOR_TAG b) for German.', 'She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden #TAUTHOR_TAG .', 'We will refer to this work and the methods and results presented by Schulte im Walde again in Sections 6.2 and 6.3.']","['', '', '', '', 'The largest lexical evaluation we know of is that of Schulte im #AUTHOR_TAG b) for German.', 'She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden #TAUTHOR_TAG .', 'We will refer to this work and the methods and results presented by Schulte im Walde again in Sections 6.2 and 6.3.']",0
"['drawback to using an existing external gold standard such', '', '', '', '', '', '', '', ' #TAUTHOR_TAG report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX .', '(95%), (84%).', 'on recall of against COM', '', '', '']","['drawback to using an existing external gold standard such', '', '', '', '', '', '', '', ' #TAUTHOR_TAG report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX .', '(95%), (84%).', 'on recall of against', '', '', '']","['Another drawback to using an existing external gold standard such', '', '', '', '', '', '', '', ' #TAUTHOR_TAG report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX .', '(95%), (84%).', 'on recall scores of against COM', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX .', 'Precision was quite high (95%), but recall was low (84%).', '', '', '', '']",1
"['', '', '', '', '', '', '', 'extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #TAUTHOR_TAG and #AUTHOR_TAG', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', 'extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #TAUTHOR_TAG and #AUTHOR_TAG', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', 'The extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #TAUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', 'The extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #TAUTHOR_TAG and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']",0
"['In syntactic ( exical-functional grammar [ LFG ] [ Kaplan and Bresnan2 ; Bresnan  ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ #TAUTHOR_TAG ] , and combinatory categorial grammar [ CCG ] [ Ades and 8 the central']","['In syntactic ( lexical-functional grammar [ LFG ] [ Kaplan and Bresnan ; Bresnan ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ #TAUTHOR_TAG ] , and combinatory categorial grammar [ CCG ] [ Ades and the central']","['In modern syntactic theories ( exical-functional grammar [ LFG ] [ Kaplan and Bres ; Bres ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ #TAUTHOR_TAG ] , and combinatory categorial grammar [ CCG ] [ Ades and']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ #TAUTHOR_TAG ] , and combinatory categorial grammar [ CCG ] [ Ades and Steedman 1982 ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information .']",0
"['While many linguistic theories state subcategorization requirements in terms of phrase structure ( CFG categories ) , #TAUTHOR_TAG questions the viability and universality of such an approach because of the variety of ways in which grammatical functions may be realized at the language-specific constituent structure level .', 'L that subcategorization requirements are stated at thestructure level, in functional rather than phal terms.', 'This because of the assumption that abstract grammatical functions are primitive concepts as opposed to of position.', '']","['While many linguistic theories state subcategorization requirements in terms of phrase structure ( CFG categories ) , #TAUTHOR_TAG questions the viability and universality of such an approach because of the variety of ways in which grammatical functions may be realized at the language-specific constituent structure level .', 'that subcategorization requirements are stated at the level, in functional rather than phrasal terms.', 'This because of the assumption that abstract grammatical functions are primitive concepts as opposed to of position.', '']","['While many linguistic theories state subcategorization requirements in terms of phrase structure ( CFG categories ) , #TAUTHOR_TAG questions the viability and universality of such an approach because of the variety of ways in which grammatical functions may be realized at the language-specific constituent structure level .', 'L that subcategorization requirements are best stated at the f-structure level, in functional rather than phal terms.', 'This because of the assumption that abstract grammatical functions are primitive concepts as opposed to of phrase structural position.', '']","['While many linguistic theories state subcategorization requirements in terms of phrase structure ( CFG categories ) , #TAUTHOR_TAG questions the viability and universality of such an approach because of the variety of ways in which grammatical functions may be realized at the language-specific constituent structure level .', 'LFG argues that subcategorization requirements are best stated at the f-structure level, in functional rather than phrasal terms.', 'This is because of the assumption that abstract grammatical functions are primitive concepts as opposed to derivatives of phrase structural position.', '']",0
"['approaches', '', '', '', '', '', 'adj', 'frames', ' #TAUTHOR_TAG attempts to improve on the approach of #AUTHOR_TAG by passing raw text through a stochastic tagger and a finite-state parser ( which includes a set of simple rules for subcategorization frame recognition ) in order to extract verbs and the constituents with which they co-occur .', 'He assumes 19 different subcategorization frame definitions, and the extracted frames include details of specific prepositions.', 'The extracted', '', '', '']","['approaches', '', '', '', '', '', '', 'frames.', ' #TAUTHOR_TAG attempts to improve on the approach of #AUTHOR_TAG by passing raw text through a stochastic tagger and a finite-state parser ( which includes a set of simple rules for subcategorization frame recognition ) in order to extract verbs and the constituents with which they co-occur .', 'He assumes 19 different subcategorization frame definitions, and the extracted frames include details of specific prepositions.', 'The extracted', '', '', '']","['general approaches', '', '', '', '', '', 'adj', '', ' #TAUTHOR_TAG attempts to improve on the approach of #AUTHOR_TAG by passing raw text through a stochastic tagger and a finite-state parser ( which includes a set of simple rules for subcategorization frame recognition ) in order to extract verbs and the constituents with which they co-occur .', 'He assumes 19 different subcategorization frame definitions, and the extracted frames include details of specific prepositions.', 'The extracted', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG attempts to improve on the approach of #AUTHOR_TAG by passing raw text through a stochastic tagger and a finite-state parser ( which includes a set of simple rules for subcategorization frame recognition ) in order to extract verbs and the constituents with which they co-occur .', 'He assumes 19 different subcategorization frame definitions, and the extracted frames include details of specific prepositions.', '', '', '', '']",0
"['Applying an absolute threshold of five occurrences, we still generate 162 frame types from Penn-II and 221 from Penn-III.', ' #TAUTHOR_TAG , by comparison , employ 163 distinct predefined frames .']","['Applying an absolute threshold of five occurrences, we still generate 162 frame types from Penn-II and 221 from Penn-III.', ' #TAUTHOR_TAG , by comparison , employ 163 distinct predefined frames .']","['Applying an absolute threshold of five occurrences, we still generate 162 frame types from Penn-II and 221 from Penn-III.', ' #TAUTHOR_TAG , by comparison , employ 163 distinct predefined frames .']","['Applying an absolute threshold of five occurrences, we still generate 162 frame types from Penn-II and 221 from Penn-III.', ' #TAUTHOR_TAG , by comparison , employ 163 distinct predefined frames .']",0
"['-', 'extr essentially to a', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Unlike our approach , those of #TAUTHOR_TAG and Hockenmaier , Bierner , and #AUTHOR_TAG include a substantial initial correction and clean-up of the Penn-II trees .', ' #AUTHOR_TAG']","['', 'extraction essentially to a', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Unlike our approach , those of #TAUTHOR_TAG and Hockenmaier , Bierner , and #AUTHOR_TAG include a substantial initial correction and clean-up of the Penn-II trees .', ' #AUTHOR_TAG']","['-', 'essentially to', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Unlike our approach , those of #TAUTHOR_TAG and Hockenmaier , Bierner , and #AUTHOR_TAG include a substantial initial correction and clean-up of the Penn-II trees .', ' #AUTHOR_TAG']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Unlike our approach , those of #TAUTHOR_TAG and Hockenmaier , Bierner , and #AUTHOR_TAG include a substantial initial correction and clean-up of the Penn-II trees .', ' #AUTHOR_TAG']",1
"['Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG #TAUTHOR_TAG ; Xia 1999 ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .', 'In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems).', 'our approach generalizes to CFG category-based approaches.', '', '', '', '', '', '', '', '']","['Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG #TAUTHOR_TAG ; Xia 1999 ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .', 'In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems).', 'our approach generalizes to CFG category-based approaches.', '', '', '', '', '', '', '', '']","['Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG #TAUTHOR_TAG ; Xia 1999 ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .', 'In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems).', 'our approach generalizes to CFG category-based approaches.', '', '', '', '', '', '', '', '']","['Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG #TAUTHOR_TAG ; Xia 1999 ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .', 'In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems).', 'However, our approach also generalizes to CFG category-based approaches.', '', '', '', '', '', '', '', '']",0
"['will divide-general approaches toization frame acquisition into two', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG predefine 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT ( Boguraev et al. 1987 ) dictionaries and adding around 30 frames found by manual inspection .', 'The frames incorporate']","['will divide more-general approaches to frame acquisition into two', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG predefine 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT ( Boguraev et al. 1987 ) dictionaries and adding around 30 frames found by manual inspection .', 'The frames incorporate']","['We will divide-general approaches toization frame acquisition into', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG predefine 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT ( Boguraev et al. 1987 ) dictionaries and adding around 30 frames found by manual inspection .', 'The frames incorporate']","['', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG predefine 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT ( Boguraev et al. 1987 ) dictionaries and adding around 30 frames found by manual inspection .', 'The frames incorporate']",0
"['We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank #TAUTHOR_TAG and Penn Chinese Treebank (Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar approximations and lexical resources for German (Cahill et al. 2003) and Chinese (Burke, Lam, et al. 2004).', 'Thex']","['We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank #TAUTHOR_TAG and Penn Chinese Treebank (Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar approximations and lexical resources for German (Cahill et al. 2003) and Chinese (Burke, Lam, et al. 2004).', 'The']","['We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank #TAUTHOR_TAG and Penn Chinese Treebank (Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar approximations and lexical resources for German (Cahill et al. 2003) and Chinese (Burke, Lam, et al. 2004).', '']","['We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank #TAUTHOR_TAG and Penn Chinese Treebank (Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar approximations and lexical resources for German (Cahill et al. 2003) and Chinese (Burke, Lam, et al. 2004).', '']",5
['The subcategorization requirements expressed by semantic forms are enforced at f-structure level through completeness and coherence well-formedness conditions on f-structure #TAUTHOR_TAG : An f-structure is locally complete iff it contains all the governable grammatical functions that its predicate governs .'],['The subcategorization requirements expressed by semantic forms are enforced at f-structure level through completeness and coherence well-formedness conditions on f-structure #TAUTHOR_TAG : An f-structure is locally complete iff it contains all the governable grammatical functions that its predicate governs .'],['The subcategorization requirements expressed by semantic forms are enforced at f-structure level through completeness and coherence well-formedness conditions on f-structure #TAUTHOR_TAG : An f-structure is locally complete iff it contains all the governable grammatical functions that its predicate governs .'],['The subcategorization requirements expressed by semantic forms are enforced at f-structure level through completeness and coherence well-formedness conditions on f-structure #TAUTHOR_TAG : An f-structure is locally complete iff it contains all the governable grammatical functions that its predicate governs .'],0
"['Lexical functional grammar ( Kaplan and Bresnan 1982 ; Bresnan 2001 ; #TAUTHOR_TAG is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', 'C', 'produced functional nodes', 'judge (']","['Lexical functional grammar ( Kaplan and Bresnan 1982 ; Bresnan 2001 ; #TAUTHOR_TAG is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', '', 'produced functional nodes', 'judge']","['Lexical functional grammar ( Kaplan and Bresnan 1982 ; Bresnan 2001 ; #TAUTHOR_TAG is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', 'C', 'is produced the nodes', 'the judge (']","['Lexical functional grammar ( Kaplan and Bresnan 1982 ; Bresnan 2001 ; #TAUTHOR_TAG is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', '', '', '']",0
"['Lexical functional grammar ( Kaplan and Bresnan 1982 ; #TAUTHOR_TAG ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .', 'It positsally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', 'C', 'produced functional', 'judge (']","['Lexical functional grammar ( Kaplan and Bresnan 1982 ; #TAUTHOR_TAG ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', '', 'produced functional', 'judge']","['Lexical functional grammar ( Kaplan and Bresnan 1982 ; #TAUTHOR_TAG ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', 'C', 'is produced', 'the judge (']","['Lexical functional grammar ( Kaplan and Bresnan 1982 ; #TAUTHOR_TAG ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', '', '', '']",0
"['RED', '', '', '', 'verbUS object introduced', 'judge', 'According to #TAUTHOR_TAG , LFG assumes the following universally available inventory of grammatical functions : SUBJ ( ect ) , OBJ ( ect ) , OBJe , COMP , XCOMP , OBL ( ique ) e , ADJ ( unct ) , XADJ .', 'OBJ θ and OBL θ represent families of grammatical functions indexed by their semantic role, represented by the theta subscript.', 'This list grammat functions is), summar in Table1.']","['PRED', '', '', '', 'verb object introduced', 'judge', 'According to #TAUTHOR_TAG , LFG assumes the following universally available inventory of grammatical functions : SUBJ ( ect ) , OBJ ( ect ) , OBJe , COMP , XCOMP , OBL ( ique ) e , ADJ ( unct ) , XADJ .', 'OBJ θ and OBL θ represent families of grammatical functions indexed by their semantic role, represented by the theta subscript.', 'This list grammatical functions is summarized in Table 1.']","['', '', '', '', 'introduced', 'judge', 'According to #TAUTHOR_TAG , LFG assumes the following universally available inventory of grammatical functions : SUBJ ( ect ) , OBJ ( ect ) , OBJe , COMP , XCOMP , OBL ( ique ) e , ADJ ( unct ) , XADJ .', 'OBJ θ and OBL θ represent families of grammatical functions indexed by their semantic role, represented by the theta subscript.', 'This list grammatical functions is divided), summar in Table1.']","['', '', '', '', '', '', 'According to #TAUTHOR_TAG , LFG assumes the following universally available inventory of grammatical functions : SUBJ ( ect ) , OBJ ( ect ) , OBJe , COMP , XCOMP , OBL ( ique ) e , ADJ ( unct ) , XADJ .', 'OBJ θ and OBL θ represent families of grammatical functions indexed by their semantic role, represented by the theta subscript.', '']",0
"['', '', ', to date this is the largest number of verbs used in any of the evaluations of the systems for English described in .', ' #TAUTHOR_TAG evaluate 914 Czech verbs against a custom-made gold standard and record a token recall of 88 % .', 'their evaluation does not examine the extracted subcatego- rization frames but rather the argument�adjunct distinctions posited by their sys- tem.', 'The largest lexical evaluation we know of is that ofte im #AUTHOR_TAG b) for German.', 'She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden (Dudenredaktion 201', 'We will refer to this work and the methods and results presented by im Wal']","['', '', 'Still, to date this is the largest number of verbs used in any of the evaluations of the systems for English described in 3.', ' #TAUTHOR_TAG evaluate 914 Czech verbs against a custom-made gold standard and record a token recall of 88 % .', 'their evaluation does not examine the extracted subcatego- rization frames but rather the argument�adjunct distinctions posited by their sys- tem.', 'The largest lexical evaluation we know of is that of Schulte im #AUTHOR_TAG b) for German.', 'She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden (Dudenredaktion 2001).', 'We will refer to this work and the methods and results presented by im Walde']","['', '', ', to date this is the largest number of verbs used in any of the evaluations of the systems for English described in', ' #TAUTHOR_TAG evaluate 914 Czech verbs against a custom-made gold standard and record a token recall of 88 % .', 'their evaluation does not examine the extracted subcatego- rization frames but rather the argument�adjunct distinctions posited by their sys- tem.', 'The largest lexical evaluation we know of is that ofte im #AUTHOR_TAG b) for German.', 'She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden (Dudenredaktion 2001).', 'We will refer to this work and the methods and results presented byte im Walde']","['', '', 'Still, to date this is the largest number of verbs used in any of the evaluations of the systems for English described in Section 3.', ' #TAUTHOR_TAG evaluate 914 Czech verbs against a custom-made gold standard and record a token recall of 88 % .', 'However, their evaluation does not examine the extracted subcatego- rization frames but rather the argument�adjunct distinctions posited by their sys- tem.', 'The largest lexical evaluation we know of is that of Schulte im #AUTHOR_TAG b) for German.', 'She evaluates 3,000 German verbs with a token frequency between 10 and 2,000 against the Duden (Dudenredaktion 2001).', '']",1
"['syntactic functionsCOMP refer to clausal complements with predicate control as in 2. neither of these functions betrays anything about the syntactic nature of the constructs in question.', 'Many lexicons , both automatically acquired and manually created , are more fine grained in their approaches to subcategorized clausal arguments , differentiating , for example , between a that-clause and a to + infinitive clause #TAUTHOR_TAG .', 'extract', '']","['syntactic functions XCOMP refer to clausal complements with predicate control as in 2. neither of these functions betrays anything about the syntactic nature of the constructs in question.', 'Many lexicons , both automatically acquired and manually created , are more fine grained in their approaches to subcategorized clausal arguments , differentiating , for example , between a that-clause and a to + infinitive clause #TAUTHOR_TAG .', 'extract', '']","['The syntactic functions COMPCOMP refer to clausal complements with different predicate control patterns as in Section 2. neither of these functions betrays anything about the syntactic nature of the constructs in question.', 'Many lexicons , both automatically acquired and manually created , are more fine grained in their approaches to subcategorized clausal arguments , differentiating , for example , between a that-clause and a to + infinitive clause #TAUTHOR_TAG .', 'extract', '']","['The syntactic functions COMP and XCOMP refer to clausal complements with different predicate control patterns as described in Section 2. However, as it stands, neither of these functions betrays anything about the syntactic nature of the constructs in question.', 'Many lexicons , both automatically acquired and manually created , are more fine grained in their approaches to subcategorized clausal arguments , differentiating , for example , between a that-clause and a to + infinitive clause #TAUTHOR_TAG .', '', '']",0
"['', 'x to ofmar', 'number of related approaches extrx.', ""The extraction procedure utilizes a head percolation table as introduced by #TAUTHOR_TAG in combination with a variation of Collins 's ( 1997 ) approach to the differentiation between complement and adjunct ."", 'This results in the construction of a of lex anch elementary', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'to of', 'number of related approaches extraction', ""The extraction procedure utilizes a head percolation table as introduced by #TAUTHOR_TAG in combination with a variation of Collins 's ( 1997 ) approach to the differentiation between complement and adjunct ."", 'This results in the construction of a of lexically anchored elementary', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'to of', 'a number of related approaches.', ""The extraction procedure utilizes a head percolation table as introduced by #TAUTHOR_TAG in combination with a variation of Collins 's ( 1997 ) approach to the differentiation between complement and adjunct ."", 'This results in the construction of a set of lex anch elementary trees', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', '', ""The extraction procedure utilizes a head percolation table as introduced by #TAUTHOR_TAG in combination with a variation of Collins 's ( 1997 ) approach to the differentiation between complement and adjunct ."", '', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['approaches toization frame acquisition two', '', '', '', '', '', '', '', 'och a finite-state constituents', 'frame extracted frames detailspos', 'The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theory ( BHT ) , following #TAUTHOR_TAG .', '', '', '']","['approaches to frame acquisition two', '', '', '', '', '', '', '', 'a finite-state constituents', 'frame extracted frames details', 'The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theory ( BHT ) , following #TAUTHOR_TAG .', '', '', '']","['general approaches toization frame acquisition', '', '', '', '', '', '', '', 'a finite-state parser the constituents', 'the extracted frames details', 'The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theory ( BHT ) , following #TAUTHOR_TAG .', '', '', '']","['', '', '', '', '', '', '', '', '', '', 'The extracted frames are noisy as a result of parser errors and so are filtered using the binomial hypothesis theory ( BHT ) , following #TAUTHOR_TAG .', '', '', '']",0
"['We applied lexical-redundancy rules #TAUTHOR_TAG to automatically convert the active COMLEX frames to their passive counterparts:lique and objects become', 'resulting precision (7 to .']","['We applied lexical-redundancy rules #TAUTHOR_TAG to automatically convert the active COMLEX frames to their passive counterparts: oblique and objects become', 'resulting precision (from to']","['We applied lexical-redundancy rules #TAUTHOR_TAG to automatically convert the active COMLEX frames to their passive counterparts: and direct objects become', 'The resulting precision ( to .']","['We applied lexical-redundancy rules #TAUTHOR_TAG to automatically convert the active COMLEX frames to their passive counterparts: For example, subjects are demoted to optional by oblique agents, and direct objects become subjects.', '']",5
"['to ensure the of the forms our we must first ensure the quality of the f-structure annotations.', 'The results of two different evaluations of the automatically generated f-structures are presented in Table 2.', 'Both use the evaluation software and triple encoding presented in #TAUTHOR_TAG .', 'The first of these is against the DCU 105, a gold-standard set of 105 hand-coded f-structures']","['to ensure the of the forms our we must first ensure the quality of the f-structure annotations.', 'The results of two different evaluations of the automatically generated f-structures are presented in Table 2.', 'Both use the evaluation software and triple encoding presented in #TAUTHOR_TAG .', 'The first of these is against the DCU 105, a gold-standard set of 105 hand-coded f-structures']","['to ensure the quality of the semantic forms our we must first ensure the quality of the f-structure annotations.', 'The results of two different evaluations of the automatically generated f-structures are presented in Table 2.', 'Both use the evaluation software and triple encoding presented in #TAUTHOR_TAG .', 'The first of these is against the DCU 105, a gold-standard set of 105 hand-coded f-structures']","['In order to ensure the quality of the semantic forms extracted by our method, we must first ensure the quality of the f-structure annotations.', 'The results of two different evaluations of the automatically generated f-structures are presented in Table 2.', 'Both use the evaluation software and triple encoding presented in #TAUTHOR_TAG .', 'The first of these is against the DCU 105, a gold-standard set of 105 hand-coded f-structures']",5
"['', '', '', 'More recently , Burke , Cahill , et al. ( 2004a ) carried out an evaluation of the automatic annotation algorithm against the publicly available PARC 700 Dependency Bank #TAUTHOR_TAG , a set of 700 randomly selected sentences from Section23 which have been parsed , converted to dependency format , and manually corrected and extended by human validators .', 'They report precision of over 88.5% and recall of over 86% (Table 2).', 'The PARC 700 Dependency Bank differs substantially from both the DCU 105 f-structure bank and the automatically generated f-structures in regard to the style of linguistic analysis, feature nomenclature feature geometry', 'all these differences are captured automatic conversion software', '', '', '']","['', '', '', 'More recently , Burke , Cahill , et al. ( 2004a ) carried out an evaluation of the automatic annotation algorithm against the publicly available PARC 700 Dependency Bank #TAUTHOR_TAG , a set of 700 randomly selected sentences from Section 23 which have been parsed , converted to dependency format , and manually corrected and extended by human validators .', 'They report precision of over 88.5% and recall of over 86% (Table 2).', 'The PARC 700 Dependency Bank differs substantially from both the DCU 105 f-structure bank and the automatically generated f-structures in regard to the style of linguistic analysis, feature nomenclature, feature geometry.', 'all, these differences are captured automatic conversion software.', '', '', '']","['', '', '', 'More recently , Burke , Cahill , et al. ( 2004a ) carried out an evaluation of the automatic annotation algorithm against the publicly available PARC 700 Dependency Bank #TAUTHOR_TAG , a set of 700 randomly selected sentences from Section 23 which have been parsed , converted to dependency format , and manually corrected and extended by human validators .', 'They report precision of over 88.5% and recall of over 86% (Table 2).', 'The PARC 700 Dependency Bank differs substantially from both the DCU 105 f-structure bank and the automatically generated f-structures in regard to the style of linguistic analysis, feature nomenclature, feature geometry.', 'these differences are captured automatic conversion software.', '', '', '']","['', '', '', 'More recently , Burke , Cahill , et al. ( 2004a ) carried out an evaluation of the automatic annotation algorithm against the publicly available PARC 700 Dependency Bank #TAUTHOR_TAG , a set of 700 randomly selected sentences from Section 23 which have been parsed , converted to dependency format , and manually corrected and extended by human validators .', 'They report precision of over 88.5% and recall of over 86% (Table 2).', 'The PARC 700 Dependency Bank differs substantially from both the DCU 105 f-structure bank and the automatically generated f-structures in regard to the style of linguistic analysis, feature nomenclature, and feature geometry.', 'Some, but not all, of these differences are captured by automatic conversion software.', '', '', '']",0
"['', 'definedur are used to automatically annotate each tree in the treebank with specified HPSG derivation trees : Head/argument/modifier distinctions are made for each node in the tree based on #TAUTHOR_TAG and #AUTHOR_TAG ; the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct errors in', '']","['', 'defined are used to automatically annotate each tree in the treebank with specified HPSG derivation trees : Head/argument/modifier distinctions are made for each node in the tree based on #TAUTHOR_TAG and #AUTHOR_TAG ; the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct errors in', '']","['', 'definedur are used to automatically annotate each tree in the treebank with specified HPSG derivation trees : Head/argument/modifier distinctions are made for each node in the tree based on #TAUTHOR_TAG and #AUTHOR_TAG ; the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in', '']","['', 'Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees : Head/argument/modifier distinctions are made for each node in the tree based on #TAUTHOR_TAG and #AUTHOR_TAG ; the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the tree- bank, and finally an HPSG category is assigned to each node in the tree in accordance with its CFG category.', '']",5
"['acticfunctional Kapresnan Dal head-driven phrase structure and , tree-ing gram [AG ] [ Joshi 1 , and combinatory categorial grammar [ CCG ] [ #TAUTHOR_TAG ] ) , thexicon is the central for much morphological , syntactic , and semantic information']","['syntactic Kaplan Bresnan head-driven phrase structure and , tree-adjoining grammar [ TAG ] [ Joshi , and combinatory categorial grammar [ CCG ] [ #TAUTHOR_TAG ] ) , the lexicon is the central for much morphological , syntactic , and semantic information']","['functionres Dal head- and , tree-ing grammar [ TAG ] [ Joshi 1988 , and combinatory categorial grammar [ CCG ] [ #TAUTHOR_TAG ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information .']",[''],0
"['', '', 'Most of the early work on automatic f-structure annotation ( e.g. , van Genabith , Way , and Sadler 1999 ; #TAUTHOR_TAG ; Sadler , van Genabith , and Way 2000 ) was applied only to small data sets ( fewer than 200 sentences ) and was largely proof of concept .', '']","['', '', 'Most of the early work on automatic f-structure annotation ( e.g. , van Genabith , Way , and Sadler 1999 ; #TAUTHOR_TAG ; Sadler , van Genabith , and Way 2000 ) was applied only to small data sets ( fewer than 200 sentences ) and was largely proof of concept .', '']","['', '', 'Most of the early work on automatic f-structure annotation ( e.g. , van Genabith , Way , and Sadler 1999 ; #TAUTHOR_TAG ; Sadler , van Genabith , and Way 2000 ) was applied only to small data sets ( fewer than 200 sentences ) and was largely proof of concept .', '']","['', '', 'Most of the early work on automatic f-structure annotation ( e.g. , van Genabith , Way , and Sadler 1999 ; #TAUTHOR_TAG ; Sadler , van Genabith , and Way 2000 ) was applied only to small data sets ( fewer than 200 sentences ) and was largely proof of concept .', '']",0
"['pus sixpositional are treated as adjuncts', '', '', '', '', '', '', '', '', '', 'induced', 'Recent work by #TAUTHOR_TAG on the filtering phase of this approach uses linguistic verb classes ( based on Levin [ 1993 ] ) for obtaining more accurate back-off estimates for hypothesis selection .', '', '']","['sixpositional phrases are treated as adjuncts', '', '', '', '', '', '', '', '', '', 'induced', '. Recent work by #TAUTHOR_TAG on the filtering phase of this approach uses linguistic verb classes ( based on Levin [ 1993 ] ) for obtaining more accurate back-off estimates for hypothesis selection . #AUTHOR_TAG', '', '']","['pus to sixpositional are treated as adjuncts', '', '', '', '', '', '', '', '', '', 'induced frames', 'Recent work by #TAUTHOR_TAG on the filtering phase of this approach uses linguistic verb classes ( based on Levin [ 1993 ] ) for obtaining more accurate back-off estimates for hypothesis selection . #AUTHOR_TAG', '', '']","['', '', '', '', '', '', '', '', '', '', '', '. Recent work by #TAUTHOR_TAG on the filtering phase of this approach uses linguistic verb classes ( based on Levin [ 1993 ] ) for obtaining more accurate back-off estimates for hypothesis selection . #AUTHOR_TAG use a handwritten head-lexicalized, context', '', '']",0
"['The rate of accession may also be represented graphically.', ' #AUTHOR_TAG and #TAUTHOR_TAG , it was observed that treebank grammars ( CFGs extracted from treebanks ) are very large and grow with the size of the treebank .', 'We were interested in discovering whether the acquisition ofxical material from the data displayed a similar prop', 'Figurection sem CF combined', '', '']","['The rate of accession may also be represented graphically.', ' #AUTHOR_TAG and #TAUTHOR_TAG , it was observed that treebank grammars ( CFGs extracted from treebanks ) are very large and grow with the size of the treebank .', 'We were interested in discovering whether the acquisition of lexical material from the data displayed a similar', 'Figure induction semantic CFG combined).', '', '']","['The rate of accession may also be represented graphically.', ' #AUTHOR_TAG and #TAUTHOR_TAG , it was observed that treebank grammars ( CFGs extracted from treebanks ) are very large and grow with the size of the treebank .', 'We were interested in discovering whether the acquisition ofxical material from the same data displayed a similar propensity.', 'ction sem CF', '', '']","['The rate of accession may also be represented graphically.', ' #AUTHOR_TAG and #TAUTHOR_TAG , it was observed that treebank grammars ( CFGs extracted from treebanks ) are very large and grow with the size of the treebank .', 'We were interested in discovering whether the acquisition of lexical material from the same data displayed a similar propensity.', '', '', '']",0
"['describe a methodology for acquiring an English HPS the-', 'ually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees : Head/argument/modifier distinctions are made for each node in the tree based on #AUTHOR_TAG and #TAUTHOR_TAG ; the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the tree- bank, and an H to', '']","['describe a methodology for acquiring an English HPSG the', 'Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees : Head/argument/modifier distinctions are made for each node in the tree based on #AUTHOR_TAG and #TAUTHOR_TAG ; the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the tree- bank, and an to', '']","['describe a methodology for acquiring an English HPSG', 'ually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees : Head/argument/modifier distinctions are made for each node in the tree based on #AUTHOR_TAG and #TAUTHOR_TAG ; the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the tree- bank, and to', '']","[' #AUTHOR_TAG and #AUTHOR_TAG describe a methodology for acquiring an English HPSG from the Penn-II Treebank.', 'Manually defined heuristics are used to automatically annotate each tree in the treebank with partially specified HPSG derivation trees : Head/argument/modifier distinctions are made for each node in the tree based on #AUTHOR_TAG and #TAUTHOR_TAG ; the whole tree is then converted to a binary tree; heuristics are applied to deal with phenomena such as LDDs and coordination and to correct some errors in the tree- bank, and finally an HPSG category is assigned to each node in the tree in accordance with its CFG category.', '']",5
"['', ' #TAUTHOR_TAG describe a simple tool which uses fine-grained rules to identify the arguments of verb occurrences in the Penn-II Treebank .', 'This is made possible by manual examination of more than 150 different sequences of syntactic and functional tags in the treebank.', 'Each of these sequences was categorized as a modifier or argument.', 'Arg were mapped to syntactic functions.', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', ' #TAUTHOR_TAG describe a simple tool which uses fine-grained rules to identify the arguments of verb occurrences in the Penn-II Treebank .', 'This is made possible by manual examination of more than 150 different sequences of syntactic and functional tags in the treebank.', 'Each of these sequences was categorized as a modifier or argument.', 'Arguments were mapped to syntactic functions.', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', ' #TAUTHOR_TAG describe a simple tool which uses fine-grained rules to identify the arguments of verb occurrences in the Penn-II Treebank .', 'This is made possible by manual examination of more than 150 different sequences of syntactic and functional tags in the treebank.', 'Each of these sequences was categorized as a modifier or argument.', 'Arg were then mapped to traditional syntactic functions.', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', ' #TAUTHOR_TAG describe a simple tool which uses fine-grained rules to identify the arguments of verb occurrences in the Penn-II Treebank .', 'This is made possible by manual examination of more than 150 different sequences of syntactic and functional tags in the treebank.', 'Each of these sequences was categorized as a modifier or argument.', 'Arguments were then mapped to traditional syntactic functions.', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', '', '', '', '', '', '', 'verbs or more).', ' #TAUTHOR_TAG present preliminary work on the automatic extraction of subcategorization frames for Bulgarian from the BulTreeBank ( Simov , Popova , and Osenova 2002 ) .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'verbs or more).', ' #TAUTHOR_TAG present preliminary work on the automatic extraction of subcategorization frames for Bulgarian from the BulTreeBank ( Simov , Popova , and Osenova 2002 ) .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', '4 verbs or more).', ' #TAUTHOR_TAG present preliminary work on the automatic extraction of subcategorization frames for Bulgarian from the BulTreeBank ( Simov , Popova , and Osenova 2002 ) .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG present preliminary work on the automatic extraction of subcategorization frames for Bulgarian from the BulTreeBank ( Simov , Popova , and Osenova 2002 ) .', '', '', '', '']",0
"['', '', '', '', '', '', ' #TAUTHOR_TAG also presents a similar method for the extraction of a TAG from the Penn Treebank .', 'The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #AUTHOR_TAG and #AUTHOR_TAG .', 'the elementary are read in a.', 'any invalid produced as a of annotation in the tree are out using linguistic', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', ' #TAUTHOR_TAG also presents a similar method for the extraction of a TAG from the Penn Treebank .', 'The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #AUTHOR_TAG and #AUTHOR_TAG .', 'the elementary are read in a manner.', 'any invalid produced as a of annotation in the treebank are out using linguistic', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', ' #TAUTHOR_TAG also presents a similar method for the extraction of a TAG from the Penn Treebank .', 'The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #AUTHOR_TAG and #AUTHOR_TAG .', 'Then the elementary trees are read off in', 'produced as a result of annotation errors in the treebank are filtered out', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', ' #TAUTHOR_TAG also presents a similar method for the extraction of a TAG from the Penn Treebank .', 'The extraction procedure consists of three steps: First, the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #AUTHOR_TAG and #AUTHOR_TAG .', 'Then the elementary trees are read off in a quite straightforward manner.', 'Finally any invalid elementary trees produced as a result of annotation errors in the treebank are filtered out using linguistic heuristics.', '', '', '', '', '', '', '', '']",0
"['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ #TAUTHOR_TAG ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CC [ Ad and  central']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ #TAUTHOR_TAG ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG [ Ades and central']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ #TAUTHOR_TAG ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades and']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ #TAUTHOR_TAG ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades and Steedman 1982 ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information .']",0
"['', '', 'science fiction, mystery and.', 'It has been shown #TAUTHOR_TAG that the subcategorization tendencies of verbs vary across linguistic domains .', 'le', '', '', '', '', 'functional -)']","['', '', 'science fiction, mystery and humor.', 'It has been shown #TAUTHOR_TAG that the subcategorization tendencies of verbs vary across linguistic domains .', '', '', '', '', '', 'functional -TMP']","['', '', 'fiction, mystery and.', 'It has been shown #TAUTHOR_TAG that the subcategorization tendencies of verbs vary across linguistic domains .', '', '', '', '', '', '-)']","['', '', '', 'It has been shown #TAUTHOR_TAG that the subcategorization tendencies of verbs vary across linguistic domains .', '', '', '', '', '', '']",4
"['Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG ( Chen and Vijay-Shanker 2000 ; #TAUTHOR_TAG ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .', 'In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems).', 'our approach to CFG category-based approaches', '', '', '', '', '', '', '', '']","['Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG ( Chen and Vijay-Shanker 2000 ; #TAUTHOR_TAG ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .', 'In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems).', 'our approach to CFG category-based approaches.', '', '', '', '', '', '', '', '']","['Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG ( Chen and Vijay-Shanker 2000 ; #TAUTHOR_TAG ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .', 'In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems).', 'our approach to CFG category-based approaches.', '', '', '', '', '', '', '', '']","['Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG ( Chen and Vijay-Shanker 2000 ; #TAUTHOR_TAG ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .', 'In this article we present an approach to automating the process of lexical acquisition for LFG (i.e., grammatical-function-based systems).', 'However, our approach also generalizes to CFG category-based approaches.', '', '', '', '', '', '', '', '']",0
"['will divide-general approaches toization frame acquisition into two', '', '', '', '', '', '', '', '', '', '', '', 'pre 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT #TAUTHOR_TAG dictionaries and adding around 30 frames found by manual inspection .', 'The frames', '']","['will divide more-general approaches to frame acquisition into two', '', '', '', '', '', '', '', '', '', '', '', 'predefine 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT #TAUTHOR_TAG dictionaries and adding around 30 frames found by manual inspection .', 'The frames', '']","['We will divide-general approaches toization frame acquisition into', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG predefine 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT #TAUTHOR_TAG dictionaries and adding around 30 frames found by manual inspection .', 'The frames', '']","['', '', '', '', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG predefine 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT #TAUTHOR_TAG dictionaries and adding around 30 frames found by manual inspection .', '', '']",0
"['We utilize the automatic annotation algorithm of #AUTHOR_TAG and Cahill, Mc #AUTHOR_TAG to derive a version of Penn-II in which node is annot with LFG functional annotations in the form of-value structure.', '', 'The annotation procedure is dependent on locating the head daughter , for which an amended version of #TAUTHOR_TAG is used .', 'head is annotated with the LG equation ↑↓', '', '', '']","['We utilize the automatic annotation algorithm of #AUTHOR_TAG and Cahill, Mc #AUTHOR_TAG to derive a version of Penn-II in which node is annotated with LFG functional annotations in the form of attribute-value structure equations.', '', 'The annotation procedure is dependent on locating the head daughter , for which an amended version of #TAUTHOR_TAG is used .', 'head is annotated with the LFG equation ↑=↓.', '', '', '']","['We utilize the automatic annotation algorithm of #AUTHOR_TAG and Cahill, Mc #AUTHOR_TAG to derive a version of Penn-II in which each node is annotated with LFG functional annotations in the form of-value structure equations.', '', 'The annotation procedure is dependent on locating the head daughter , for which an amended version of #TAUTHOR_TAG is used .', 'The head is annotated with the LFG equation ↑=↓.', '', '', '']","['We utilize the automatic annotation algorithm of #AUTHOR_TAG and Cahill, Mc #AUTHOR_TAG to derive a version of Penn-II in which each node in each tree is annotated with LFG functional annotations in the form of attribute-value structure equations.', '', 'The annotation procedure is dependent on locating the head daughter , for which an amended version of #TAUTHOR_TAG is used .', 'The head is annotated with the LFG equation ↑=↓.', '', '', '']",5
"['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; #TAUTHOR_TAG ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combatory categ gram']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; #TAUTHOR_TAG ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; #TAUTHOR_TAG ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and comb']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; #TAUTHOR_TAG ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades and Steedman 1982 ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information .']",0
"['', '', '', 'more recent work ( Cahill et al. 2002 ; Cahill , McCarthy , et al. 2004 ) has presented efforts in evolving and scaling up annotation techniques to the Penn-II Treebank #TAUTHOR_TAG , containing more than 1,000,000 words and 49,000 sentences .']","['', '', '', 'more recent work ( Cahill et al. 2002 ; Cahill , McCarthy , et al. 2004 ) has presented efforts in evolving and scaling up annotation techniques to the Penn-II Treebank #TAUTHOR_TAG , containing more than 1,000,000 words and 49,000 sentences .']","['', '', '', 'more recent work ( Cahill et al. 2002 ; Cahill , McCarthy , et al. 2004 ) has presented efforts in evolving and scaling up annotation techniques to the Penn-II Treebank #TAUTHOR_TAG , containing more than 1,000,000 words and 49,000 sentences .']","['', '', '', 'However , more recent work ( Cahill et al. 2002 ; Cahill , McCarthy , et al. 2004 ) has presented efforts in evolving and scaling up annotation techniques to the Penn-II Treebank #TAUTHOR_TAG , containing more than 1,000,000 words and 49,000 sentences .']",0
"['In modern syntactic theories ( e.. ,xical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ #TAUTHOR_TAG ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CC central']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ #TAUTHOR_TAG ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG central']","['In modern syntactic theories ( e.. ,xical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ #TAUTHOR_TAG ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ #TAUTHOR_TAG ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades and Steedman 1982 ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information .']",0
"['to the of our extracted sem we also examined at induced', 'This of the induced lexicon on new data.', 'Following Hockenmaier , Bierner , and #AUTHOR_TAG , #TAUTHOR_TAG , and Miyao , Ninomiya , and #AUTHOR_TAG , we extract a reference lexicon from Sections 02 -- 21 of the WSJ .', 'We then compare this to a test lex', '', '', '', '', '', '']","['to the of our extracted semantic we also examined at induced.', 'This of the induced lexicon on new data.', 'Following Hockenmaier , Bierner , and #AUTHOR_TAG , #TAUTHOR_TAG , and Miyao , Ninomiya , and #AUTHOR_TAG , we extract a reference lexicon from Sections 02 -- 21 of the WSJ .', 'We then compare this to a test lexicon', '', '', '', '', '', '']","['to of our we also examined at induced', 'This of the induced lexicon on new data.', 'Following Hockenmaier , Bierner , and #AUTHOR_TAG , #TAUTHOR_TAG , and Miyao , Ninomiya , and #AUTHOR_TAG , we extract a reference lexicon from Sections 02 -- 21 of the WSJ .', 'We then compare this to a test lexicon', '', '', '', '', '', '']","['', 'This can be expressed as a measure of the coverage of the induced lexicon on new data.', 'Following Hockenmaier , Bierner , and #AUTHOR_TAG , #TAUTHOR_TAG , and Miyao , Ninomiya , and #AUTHOR_TAG , we extract a reference lexicon from Sections 02 -- 21 of the WSJ .', 'We then compare this to a test lexicon from Section 23.', '', '', '', '', '', '']",5
"['will divide-general approaches to subcization frame acquisition into two groups', '', ' #TAUTHOR_TAG relies on morphosyntactic cues in the untagged Brown corpus as indicators of six predefined subcategorization frames .', 'The frames do not include details of specific prepositions.', 'Brent used hypothesis testing on binomial frequency data to statistically filter the induced frames.', 'sixategorization verb', 'pos treated as adj', '', '', '', '', '', '', '']","['will divide more-general approaches to subcategorization frame acquisition into two groups:', '', ' #TAUTHOR_TAG relies on morphosyntactic cues in the untagged Brown corpus as indicators of six predefined subcategorization frames .', 'The frames do not include details of specific prepositions.', 'Brent used hypothesis testing on binomial frequency data to statistically filter the induced frames.', 'six subcategorization verb', 'treated as', '', '', '', '', '', '', '']","['We will divide-general approaches to subcization frame acquisition into two groups:', '', ' #TAUTHOR_TAG relies on morphosyntactic cues in the untagged Brown corpus as indicators of six predefined subcategorization frames .', 'The frames do not include details of specific prepositions.', 'Brent used hypothesis testing on binomial frequency data to statistically filter the induced frames.', '', 'are treated as adj', '', '', '', '', '', '', '']","['', '', ' #TAUTHOR_TAG relies on morphosyntactic cues in the untagged Brown corpus as indicators of six predefined subcategorization frames .', 'The frames do not include details of specific prepositions.', 'Brent used hypothesis testing on binomial frequency data to statistically filter the induced frames.', '', '', '', '', '', '', '', '', '']",0
"['Lexical functional grammar #TAUTHOR_TAG ; Bresnan 2001 ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .', 'It positsally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', 'C', 'is produced from functionalnotations on the nodes', 'judge']","['Lexical functional grammar #TAUTHOR_TAG ; Bresnan 2001 ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', '', 'is produced from functional annotations on the nodes', 'judge']","['Lexical functional grammar #TAUTHOR_TAG ; Bresnan 2001 ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', 'C', 'is produced from functional annotations on the nodes', 'the judge']","['Lexical functional grammar #TAUTHOR_TAG ; Bresnan 2001 ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .', 'It posits minimally two levels of syntactic representation: 2 c(onstituent)-structure encodes details of surface syntactic constituency, whereas f(unctional)-structure expresses abstract syntactic information about predicate-argument-modifier relations and certain morphosyntactic properties such as tense, aspect, and case.', '', '', '']",0
"['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG present an approach to learn previously unknown frames for Czech from the Prague Dependency Bank ( Hajic', 'Czech is a language with a freer word order than English and so configurational information cannot be relied upon.', 'In a dependency tree, the set of all dependents of the verb make up a so-called observed frame, whereas a subcategorization frame contains a subset of the dependents in the observed frame.', 'Finding subcategorization frames involves filtering adjuncts from the observed frame', 'elihood t', 'The system learns 137 subcategorization frames from 19,126 sentences for 914 verbs ( or', '', '', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG present an approach to learn previously unknown frames for Czech from the Prague Dependency Bank ( Hajic', 'Czech is a language with a freer word order than English and so configurational information cannot be relied upon.', 'In a dependency tree, the set of all dependents of the verb make up a so-called observed frame, whereas a subcategorization frame contains a subset of the dependents in the observed frame.', 'Finding subcategorization frames involves filtering adjuncts from the observed frame.', '', 'The system learns 137 subcategorization frames from 19,126 sentences for 914 verbs or', '', '', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG present an approach to learn previously unknown frames for Czech from the Prague Dependency Bank ( Hajic', 'Czech is a language with a freer word order than English and so configurational information cannot be relied upon.', 'In a dependency tree, the set of all dependents of the verb make up a so-called observed frame, whereas a subcategorization frame contains a subset of the dependents in the observed frame.', 'Finding subcategorization frames involves filtering adjuncts from the observed frame.', 't', 'The system learns 137 subcategorization frames from 19,126 sentences for 914 verbs ( or', '', '', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG present an approach to learn previously unknown frames for Czech from the Prague Dependency Bank ( Hajic', 'Czech is a language with a freer word order than English and so configurational information cannot be relied upon.', 'In a dependency tree, the set of all dependents of the verb make up a so-called observed frame, whereas a subcategorization frame contains a subset of the dependents in the observed frame.', 'Finding subcategorization frames involves filtering adjuncts from the observed frame.', '', 'The system learns 137 subcategorization frames from 19,126 sentences for 914 verbs (those which occurred five times or more).', '', '', '', '', '']",0
"['', '', '', '', '', '', 'extr Treebank', 'The extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #AUTHOR_TAG and #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', 'extraction Treebank.', 'The extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #AUTHOR_TAG and #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', 'The extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #AUTHOR_TAG and #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', 'The extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of #AUTHOR_TAG and #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']",0
"['order to capture CF- categorial information, we add a CAT feature to the f-structures automatically generated from the Penn-II and Penn- Treebanks', '', '', '', '', 'details', ' #TAUTHOR_TAG argues that there are cases , albeit exceptional ones , in which constraints on syntactic category are an issue in subcategorization .', '']","['order to capture CFG-based categorial information, we add a CAT feature to the f-structures automatically generated from the Penn-II and Penn-III Treebanks.', '', '', '', '', 'details.', ' #TAUTHOR_TAG argues that there are cases , albeit exceptional ones , in which constraints on syntactic category are an issue in subcategorization .', '']","['order to capture CF-based categorial information, we add a CAT feature to the f-structures automatically generated from the Penn-II and Penn-III Treebanks.', '', '', '', '', '', ' #TAUTHOR_TAG argues that there are cases , albeit exceptional ones , in which constraints on syntactic category are an issue in subcategorization .', '']","['In order to capture CFG-based categorial information, we add a CAT feature to the f-structures automatically generated from the Penn-II and Penn-III Treebanks.', '', '', '', '', '', ' #TAUTHOR_TAG argues that there are cases , albeit exceptional ones , in which constraints on syntactic category are an issue in subcategorization .', '']",4
"['banks, annot with Lstruct', '', '', '', '', '', '', '', '', '', '', '', '', '', 'analysis revealed interesting issues associated with using an external standard such as', 'In the future , we hope to evaluate the automatic annotations and extracted lexicon against Propbank #TAUTHOR_TAG .']","['Treebanks, annotated with', '', '', '', '', '', '', '', '', '', '', '', '', '', 'analysis revealed interesting issues associated with using an external standard such as', 'In the future , we hope to evaluate the automatic annotations and extracted lexicon against Propbank #TAUTHOR_TAG .']","['III Treebanks, annot with L', '', '', '', '', '', '', '', '', '', '', '', '', '', 'error analysis revealed some interesting issues associated with using an external standard such as', 'In the future , we hope to evaluate the automatic annotations and extracted lexicon against Propbank #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Our error analysis also revealed some interesting issues associated with using an external standard such as COMLEX.', 'In the future , we hope to evaluate the automatic annotations and extracted lexicon against Propbank #TAUTHOR_TAG .']",3
"['Another drawback to using an existing external gold standard such as COMLEX to evaluate an automatically induced subcategorization lexicon is that the resources are not necessarily constructed from the same source data.', 'As noted above , it is well documented #TAUTHOR_TAG that subcategorization frames ( and their frequencies ) vary across domains .', 'We have extracted frames from two sources (the WSJ and the Brown corpus), whereas COMLEX using examples', '', '', '', '', '', '', '', '', '', '', '']","['Another drawback to using an existing external gold standard such as COMLEX to evaluate an automatically induced subcategorization lexicon is that the resources are not necessarily constructed from the same source data.', 'As noted above , it is well documented #TAUTHOR_TAG that subcategorization frames ( and their frequencies ) vary across domains .', 'We have extracted frames from two sources (the WSJ and the Brown corpus), whereas COMLEX using examples', '', '', '', '', '', '', '', '', '', '', '']","['Another drawback to using an existing external gold standard such as COMLEX to evaluate an automatically induced subcategorization lexicon is that the resources are not necessarily constructed from the same source data.', 'As noted above , it is well documented #TAUTHOR_TAG that subcategorization frames ( and their frequencies ) vary across domains .', 'We have extracted frames from two sources (the WSJ and the Brown corpus), whereas COMLEX examples', '', '', '', '', '', '', '', '', '', '', '']","['Another drawback to using an existing external gold standard such as COMLEX to evaluate an automatically induced subcategorization lexicon is that the resources are not necessarily constructed from the same source data.', 'As noted above , it is well documented #TAUTHOR_TAG that subcategorization frames ( and their frequencies ) vary across domains .', '', '', '', '', '', '', '', '', '', '', '', '']",4
"['been carried extractionxical resources frombank', 'fullyxical with an ( CCHPS the extraction of axicon essentially amounts to the creation of a grammar', ' #TAUTHOR_TAG explore a number of related approaches to the extraction of a lexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical model for parsing .', 'The extraction procedure utilizes a head percolation table as introduced by in combination with a variation of #AUTHOR_TAG approach to the differentiation between complement and adjunct.', 'a le', 'le', '', '', '', '', '', '', '', '', '', '', '', '']","['been carried extraction lexical resources from', 'fully lexicalized with an the extraction of a lexicon essentially amounts to the creation of a grammar.', ' #TAUTHOR_TAG explore a number of related approaches to the extraction of a lexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical model for parsing .', 'The extraction procedure utilizes a head percolation table as introduced by in combination with a variation of #AUTHOR_TAG approach to the differentiation between complement and adjunct.', 'a', '', '', '', '', '', '', '', '', '', '', '', '', '']","['has been carried out the extractionspecific lexical resources from', 'are fullyxical with an invariant ( CCHPS the extraction of a lexicon essentially amounts to the creation of a grammar.', ' #TAUTHOR_TAG explore a number of related approaches to the extraction of a lexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical model for parsing .', 'The extraction procedure utilizes a head percolation table as introduced by in combination with a variation of #AUTHOR_TAG approach to the differentiation between complement and adjunct.', 'a set le', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', ' #TAUTHOR_TAG explore a number of related approaches to the extraction of a lexicalized TAG from the Penn-II Treebank with the aim of constructing a statistical model for parsing .', 'The extraction procedure utilizes a head percolation table as introduced by #AUTHOR_TAG in combination with a variation of #AUTHOR_TAG approach to the differentiation between complement and adjunct.', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['The rate of accession may also be represented graphically.', 'In #TAUTHOR_TAG and #AUTHOR_TAG , it was observed that treebank grammars ( CFGs extracted from treebanks ) are very large and grow with the size of the treebank .', 'We were discoverxical a similar', '', '', '']","['The rate of accession may also be represented graphically.', 'In #TAUTHOR_TAG and #AUTHOR_TAG , it was observed that treebank grammars ( CFGs extracted from treebanks ) are very large and grow with the size of the treebank .', 'We were discovering lexical a similar', '', '', '']","['The rate of accession may also be represented graphically.', 'In #TAUTHOR_TAG and #AUTHOR_TAG , it was observed that treebank grammars ( CFGs extracted from treebanks ) are very large and grow with the size of the treebank .', 'We were discoverxical material', '', '', '']","['The rate of accession may also be represented graphically.', 'In #TAUTHOR_TAG and #AUTHOR_TAG , it was observed that treebank grammars ( CFGs extracted from treebanks ) are very large and grow with the size of the treebank .', '', '', '', '']",0
"['information is theization of entry the a pred take in form a', 'Lex includingategorization details,ally produced hand', 'bott', 'ization may genre (roll and Rooth 199', ' #TAUTHOR_TAG argues that , aside from missing domain-specific complementation trends , dictionaries produced by hand will tend to lag behind real language use because of their static nature .', 'Given these facts, research on automating acquisition of dictionaries for lexically based NLP systems is a particularly important issue.']","['information is the of entry the a predicate take in form a', 'including subcategorization details, traditionally produced hand.', '', 'may genre (Carroll and Rooth 1998).', ' #TAUTHOR_TAG argues that , aside from missing domain-specific complementation trends , dictionaries produced by hand will tend to lag behind real language use because of their static nature .', 'Given these facts, research on automating acquisition of dictionaries for lexically based NLP systems is a particularly important issue.']","['ical information is of an entry the arguments a predicate must take in form', 'Lex, includingategorization details, produced hand', 'bott', 'may vary genre (roll and Rooth 1998).', ' #TAUTHOR_TAG argues that , aside from missing domain-specific complementation trends , dictionaries produced by hand will tend to lag behind real language use because of their static nature .', 'Given these facts, research on automating acquisition of dictionaries for lexically based NLP systems is a particularly important issue.']","['', 'Lexicons, including subcategorization details, were traditionally produced by hand.', '', '', ' #TAUTHOR_TAG argues that , aside from missing domain-specific complementation trends , dictionaries produced by hand will tend to lag behind real language use because of their static nature .', 'Given these facts, research on automating acquisition of dictionaries for lexically based NLP systems is a particularly important issue.']",4
"['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; #TAUTHOR_TAG ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ central']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; #TAUTHOR_TAG ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ central']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; #TAUTHOR_TAG ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades']","['In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; #TAUTHOR_TAG ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades and Steedman 1982 ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information .']",0
"['approaches to frame', '', '', '', '', ' #TAUTHOR_TAG run a finite-state NP parser on a POS-tagged corpus to calculate the relative frequency of the same six subcategorization verb classes .', 'positional treated as adjuncts', '', '', '', '', '', '', '']","['approaches to frame', '', '', '', '', ' #TAUTHOR_TAG run a finite-state NP parser on a POS-tagged corpus to calculate the relative frequency of the same six subcategorization verb classes .', 'prepositional treated as adjuncts.', '', '', '', '', '', '', '']","['general approaches to frame acquisition', '', '', '', '', ' #TAUTHOR_TAG run a finite-state NP parser on a POS-tagged corpus to calculate the relative frequency of the same six subcategorization verb classes .', 'are treated as adjuncts', '', '', '', '', '', '', '']","['', '', '', '', '', ' #TAUTHOR_TAG run a finite-state NP parser on a POS-tagged corpus to calculate the relative frequency of the same six subcategorization verb classes .', '', '', '', '', '', '', '', '']",0
"['drawback to using an existing external gold standard such', '', '', '', '', '', '', 'As a generalization , #TAUTHOR_TAG notes that lexicons such as COMLEX tend to demonstrate high precision but low recall .', '', '', '', '', '', '']","['drawback to using an existing external gold standard such', '', '', '', '', '', '', 'As a generalization , #TAUTHOR_TAG notes that lexicons such as COMLEX tend to demonstrate high precision but low recall .', '', '', '', '', '', '']","['Another drawback to using an existing external gold standard such', '', '', '', '', '', '', 'As a generalization , #TAUTHOR_TAG notes that lexicons such as COMLEX tend to demonstrate high precision but low recall .', '', '', '', '', '', '']","['', '', '', '', '', '', '', 'As a generalization , #TAUTHOR_TAG notes that lexicons such as COMLEX tend to demonstrate high precision but low recall .', '', '', '', '', '', '']",0
"['We believe that the identification of OOV words should not be treated as a problem separate from word segmentation.', 'We propose a unified approach that solves both problems simultaneously.', 'A previous work along this line is #TAUTHOR_TAG , which is based on weighted finite-state transducers ( FSTs ) .', '', 'le', '', '', '', '']","['We believe that the identification of OOV words should not be treated as a problem separate from word segmentation.', 'We propose a unified approach that solves both problems simultaneously.', 'A previous work along this line is #TAUTHOR_TAG , which is based on weighted finite-state transducers ( FSTs ) .', '', '', '', '', '', '']","['We believe that the identification of OOV words should not be treated as a problem separate from word segmentation.', 'We propose a unified approach that solves both problems simultaneously.', 'A previous work along this line is #TAUTHOR_TAG , which is based on weighted finite-state transducers ( FSTs ) .', '', 'le', '', '', '', '']","['We believe that the identification of OOV words should not be treated as a problem separate from word segmentation.', 'We propose a unified approach that solves both problems simultaneously.', 'A previous work along this line is #TAUTHOR_TAG , which is based on weighted finite-state transducers ( FSTs ) .', '', '', '', '', '', '']",1
"['Common sense (as well as the Gricean maxims; Grice 1975) suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication.', 'aware of any empirical validation of this idea, but the fact that vague descriptions are frequent is fairly well documented.', ' #TAUTHOR_TAG , for example , discussed the transcripts of a dialogue between people who assemble a piece of garden furniture ( originally recorded by Candy Sidner ) .', 'They found that, while instructional texts tended to use numerical descriptions like the 3 1 4 "" bolt, human assemblers ""unless they were reading or discussing the written instructions, in all cases used relative modifiers, such as the long bolt"" (Dale and Reiter 1995).', '', '', '', '', '']","['Common sense (as well as the Gricean maxims; Grice 1975) suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication.', 'aware of any empirical validation of this idea, but the fact that vague descriptions are frequent is fairly well documented.', ' #TAUTHOR_TAG , for example , discussed the transcripts of a dialogue between people who assemble a piece of garden furniture ( originally recorded by Candy Sidner ) .', 'They found that, while instructional texts tended to use numerical descriptions like the 3 1 4 "" bolt, human assemblers ""unless they were reading or discussing the written instructions, in all cases used relative modifiers, such as the long bolt"" (Dale and Reiter 1995).', '', '', '', '', '']","['Common sense (as well as the Gricean maxims; Grice 1975) suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication.', 'aware of any empirical validation of this idea, but the fact that vague descriptions are frequent is fairly well documented.', ' #TAUTHOR_TAG , for example , discussed the transcripts of a dialogue between people who assemble a piece of garden furniture ( originally recorded by Candy Sidner ) .', 'They found that, while instructional texts tended to use numerical descriptions like the 3 1 4 "" bolt, human assemblers ""unless they were reading or discussing the written instructions, in all cases used relative modifiers, such as the long bolt"" (Dale and Reiter 1995). 6', '', '', '', '', '']","['Common sense (as well as the Gricean maxims; Grice 1975) suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication.', 'We are not aware of any empirical validation of this idea, but the fact that vague descriptions are frequent is fairly well documented.', ' #TAUTHOR_TAG , for example , discussed the transcripts of a dialogue between people who assemble a piece of garden furniture ( originally recorded by Candy Sidner ) .', 'They found that, while instructional texts tended to use numerical descriptions like the 3 1 4 "" bolt, human assemblers ""unless they were reading or discussing the written instructions, in all cases used relative modifiers, such as the long bolt"" (Dale and Reiter 1995). 6 Our own experiments (van Deemter 2004) point in the same direction.', '', '', '', '', '']",0
"['Viewed in this way , gradable adjectives are an extreme example of the ""efficiency of language"" #TAUTHOR_TAG : Far from meaning something concrete like ""larger than 8 cm"" -- a concept that would have very limited applicability -- or even something more general like ""larger than the average N , ""a word like large is applicable across a wide range of different situations .']","['Viewed in this way , gradable adjectives are an extreme example of the ""efficiency of language"" #TAUTHOR_TAG : Far from meaning something concrete like ""larger than 8 cm"" -- a concept that would have very limited applicability -- or even something more general like ""larger than the average N , ""a word like large is applicable across a wide range of different situations .']","['Viewed in this way , gradable adjectives are an extreme example of the ""efficiency of language"" #TAUTHOR_TAG : Far from meaning something concrete like ""larger than 8 cm"" -- a concept that would have very limited applicability -- or even something more general like ""larger than the average N , ""a word like large is applicable across a wide range of different situations .']","['Viewed in this way , gradable adjectives are an extreme example of the ""efficiency of language"" #TAUTHOR_TAG : Far from meaning something concrete like ""larger than 8 cm"" -- a concept that would have very limited applicability -- or even something more general like ""larger than the average N , ""a word like large is applicable across a wide range of different situations .']",1
"['Clearly , what it takes for the adjective to be applicable has not been cast in , but is open to fiat : the speaker may decide that 8 cm is enough , or the speaker may set the standards higher ( cfXXX , #TAUTHOR_TAG .', 'The numeral (whether it is implicit, as in (3), or explicit) can be construed as allowing the reader to draw inferences about standards employed (Kyburg and Morreau 2000;DeVault and 2004): (3),  cm and', '', '', '']","['Clearly , what it takes for the adjective to be applicable has not been cast in , but is open to fiat : the speaker may decide that 8 cm is enough , or the speaker may set the standards higher ( cfXXX , #TAUTHOR_TAG .', 'The numeral (whether it is implicit, as in (3), or explicit) can be construed as allowing the reader to draw inferences about standards employed (Kyburg and Morreau 2000;DeVault and 2004): (3), cm and', '', '', '']","['Clearly , what it takes for the adjective to be applicable has not been cast in , but is open to fiat : the speaker may decide that 8 cm is enough , or the speaker may set the standards higher ( cfXXX , #TAUTHOR_TAG .', 'The numeral (whether it is implicit, as in (3), or explicit) can be construed as allowing the reader to draw inferences about the standards employed (Kyburg and Morreau 2000;DeVault and Stone 2004): (3), 0 cm and', '', '', '']","['Clearly , what it takes for the adjective to be applicable has not been cast in stone , but is open to fiat : the speaker may decide that 8 cm is enough , or the speaker may set the standards higher ( cfXXX , #TAUTHOR_TAG .', 'The numeral (whether it is implicit, as in (3), or explicit) can be construed as allowing the reader to draw inferences about the standards employed (Kyburg and Morreau 2000;DeVault and Stone 2004): (3), for example, implies a standard that counts 10 cm as large and 8 cm as not large.', '', '', '']",0
"['Cases like this would be covered if the decision-theoretic property of Pareto optimality ( e.g. , #TAUTHOR_TAG was used as the sole criterion : Formally , an object r E C has a Pareto-optimal combination of Values V iff there is no other x E C such that']","['Cases like this would be covered if the decision-theoretic property of Pareto optimality ( e.g. , #TAUTHOR_TAG was used as the sole criterion : Formally , an object r E C has a Pareto-optimal combination of Values V iff there is no other x E C such that']","['Cases like this would be covered if the decision-theoretic property of Pareto optimality ( e.g. , #TAUTHOR_TAG was used as the sole criterion : Formally , an object r E C has a Pareto-optimal combination of Values V iff there is no other x E C such that']","['Cases like this would be covered if the decision-theoretic property of Pareto optimality ( e.g. , #TAUTHOR_TAG was used as the sole criterion : Formally , an object r E C has a Pareto-optimal combination of Values V iff there is no other x E C such that']",0
"['One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , #TAUTHOR_TAG ; Malouf 2000 ) .', ""Work in this area is often based on assigning adjectives to a small number of categories (e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives' relative position."", 'Interestingly, vague properties tend to be realized before others.', '', '', '', '', '', '', '']","['One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , #TAUTHOR_TAG ; Malouf 2000 ) .', ""Work in this area is often based on assigning adjectives to a small number of categories (e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives' relative position."", 'Interestingly, vague properties tend to be realized before others.', '', '', '', '', '', '', '']","['One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , #TAUTHOR_TAG ; Malouf 2000 ) .', ""Work in this area is often based on assigning adjectives to a small number of categories (e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives' relative position."", 'Interestingly, vague properties tend to be realized before others.', '', '', '', '', '', '', '']","['One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , #TAUTHOR_TAG ; Malouf 2000 ) .', ""Work in this area is often based on assigning adjectives to a small number of categories (e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives' relative position."", 'Interestingly, vague properties tend to be realized before others.', '', '', '', '', '', '', '']",0
"['3 The degree of precision of the measurement #TAUTHOR_TAG , Section 1.5 ) determines which objects can be described by the GRE algorithm , since it determines which objects count as having the same size .']","['3 The degree of precision of the measurement #TAUTHOR_TAG , Section 1.5 ) determines which objects can be described by the GRE algorithm , since it determines which objects count as having the same size .']","['3 The degree of precision of the measurement #TAUTHOR_TAG , Section 1.5 ) determines which objects can be described by the GRE algorithm , since it determines which objects count as having the same size .']","['3 The degree of precision of the measurement #TAUTHOR_TAG , Section 1.5 ) determines which objects can be described by the GRE algorithm , since it determines which objects count as having the same size .']",0
"['Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead ( Stone and Webber 1998 ; #TAUTHOR_TAG .', 'We have separated the two phases because, in the case of vague descriptions, interleaving would tend to be difficult.', '', '', '']","['Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead ( Stone and Webber 1998 ; #TAUTHOR_TAG .', 'We have separated the two phases because, in the case of vague descriptions, interleaving would tend to be difficult.', '', '', '']","['Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead ( Stone and Webber 1998 ; #TAUTHOR_TAG .', 'We have separated the two phases because, in the case of vague descriptions, interleaving would tend to be difficult.', '', '', '']","['Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead ( Stone and Webber 1998 ; #TAUTHOR_TAG .', 'We have separated the two phases because, in the case of vague descriptions, interleaving would tend to be difficult.', '', '', '']",1
"['more', 'observ', 'a answer prohibit binary are and objects that are not, given that one can always construct objects x and y, one of which falls just below the divide while the other falls just above it.', 'This is the strongest version of the sorites paradox ( e.g. , #TAUTHOR_TAG .']","['more', '', 'a answer prohibit binary are and objects that are not, given that one can always construct objects x and y, one of which falls just below the divide while the other falls just above it.', 'This is the strongest version of the sorites paradox ( e.g. , #TAUTHOR_TAG .']","['more', 'observ', 'a negative answer would prohibit are and objects that are not, given that one can always construct objects x and y, one of which falls just below the divide while the other falls just above it.', 'This is the strongest version of the sorites paradox ( e.g. , #TAUTHOR_TAG .']","['', '', '', 'This is the strongest version of the sorites paradox ( e.g. , #TAUTHOR_TAG .']",0
"['We will examine the worst-case complexity of interpretation as well as generation to shed some light on the hypothesis that vague descriptions are more difficult to process than others because they involve a comparison between objects ( Beun and Cremers 1998 , #TAUTHOR_TAG .', 'this tract', '', '', 'the we on the2 4, and.']","['We will examine the worst-case complexity of interpretation as well as generation to shed some light on the hypothesis that vague descriptions are more difficult to process than others because they involve a comparison between objects ( Beun and Cremers 1998 , #TAUTHOR_TAG .', 'this, tractability', '', '', 'the we on the 4, and']","['We will examine the worst-case complexity of interpretation as well as generation to shed some light on the hypothesis that vague descriptions are more difficult to process than others because they involve a comparison between objects ( Beun and Cremers 1998 , #TAUTHOR_TAG .', '', '', '', 'we focus on the2 4, and.']","['We will examine the worst-case complexity of interpretation as well as generation to shed some light on the hypothesis that vague descriptions are more difficult to process than others because they involve a comparison between objects ( Beun and Cremers 1998 , #TAUTHOR_TAG .', '', '', '', '']",0
"['', '', 'We shall focus on more challenging case where output less, as is the case in FOG and DYD.', 'This can be a hazardous affair , since vague expressions tend to be interpreted in different ways by different people #TAUTHOR_TAG , sometimes in stark contrast with the intention of the speaker/writer ( Berry , Knapp , and Raynor 2002 ) .', '', '', '', '', '', '', '']","['', '', 'We shall focus on more challenging case where output less input, as is the case in FOG and DYD.', 'This can be a hazardous affair , since vague expressions tend to be interpreted in different ways by different people #TAUTHOR_TAG , sometimes in stark contrast with the intention of the speaker/writer ( Berry , Knapp , and Raynor 2002 ) .', '', '', '', '', '', '', '']","['', '', 'We shall focus on more challenging case where the output is less as is the case in FOG and DYD.', 'This can be a hazardous affair , since vague expressions tend to be interpreted in different ways by different people #TAUTHOR_TAG , sometimes in stark contrast with the intention of the speaker/writer ( Berry , Knapp , and Raynor 2002 ) .', '', '', '', '', '', '', '']","['', '', 'We shall focus on the more challenging case where the output of the generator is less precise than the input, as is the case in FOG and DYD.', 'This can be a hazardous affair , since vague expressions tend to be interpreted in different ways by different people #TAUTHOR_TAG , sometimes in stark contrast with the intention of the speaker/writer ( Berry , Knapp , and Raynor 2002 ) .', '', '', '', '', '', '', '']",0
"['compar properties at the, while the fixed', 'the KB contains () height > < x,c) width >, and () width < x.', 'Which of these should come first?', ' #TAUTHOR_TAG ; also reported in Levelt 1989 ) show that greater differences are most likely to be chosen , presumably because they are more striking .', 'refer tallended', '', '', '', '', '']","['comparative properties at the order, while the fixed', 'the KB contains (a) height > < x, (c) width > x, and (d) width < x.', 'Which of these should come first?', ' #TAUTHOR_TAG ; also reported in Levelt 1989 ) show that greater differences are most likely to be chosen , presumably because they are more striking .', 'referent tallest tended', '', '', '', '', '']","['comparative properties at the bottom while the order fixed', 'the KB contains () height > x, < x,c) width > x, and () width < x.', 'Which of these should come first?', ' #TAUTHOR_TAG ; also reported in Levelt 1989 ) show that greater differences are most likely to be chosen , presumably because they are more striking .', 'ended', '', '', '', '', '']","['', '', 'Which of these should come first?', ' #TAUTHOR_TAG ; also reported in Levelt 1989 ) show that greater differences are most likely to be chosen , presumably because they are more striking .', '', '', '', '', '', '']",0
"['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; Pechmann 1989 ; #TAUTHOR_TAG , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '(W redu', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; Pechmann 1989 ; #TAUTHOR_TAG , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '(Wildly', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; Pechmann 1989 ; #TAUTHOR_TAG , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '(W', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; Pechmann 1989 ; #TAUTHOR_TAG , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '', '', '', '', '', '', '', '', '']",0
"[""FindBestValue selects the 'best value' from among the Values of a given Attribute, assuming that these are linearly ordered in terms of specificity."", 'The function selects the Value that removes most distractors , but in case of a tie , the least specific contestant is chosen , as long as it is not less specific than the basic-level Value ( i.e. , the most commonly occurring and psychologically most fundamental level , #TAUTHOR_TAG .', 'IA Pl refer to target']","[""FindBestValue selects the 'best value' from among the Values of a given Attribute, assuming that these are linearly ordered in terms of specificity."", 'The function selects the Value that removes most distractors , but in case of a tie , the least specific contestant is chosen , as long as it is not less specific than the basic-level Value ( i.e. , the most commonly occurring and psychologically most fundamental level , #TAUTHOR_TAG .', 'IA Plur refer to target']","[""FindBestValue selects the 'best value' from among the Values of a given Attribute, assuming that these are linearly ordered in terms of specificity."", 'The function selects the Value that removes most distractors , but in case of a tie , the least specific contestant is chosen , as long as it is not less specific than the basic-level Value ( i.e. , the most commonly occurring and psychologically most fundamental level , #TAUTHOR_TAG .', 'IA Plur can refer to a target']","[""FindBestValue selects the 'best value' from among the Values of a given Attribute, assuming that these are linearly ordered in terms of specificity."", 'The function selects the Value that removes most distractors , but in case of a tie , the least specific contestant is chosen , as long as it is not less specific than the basic-level Value ( i.e. , the most commonly occurring and psychologically most fundamental level , #TAUTHOR_TAG .', '']",0
"['', 'will will', 'A New Perspective on Salience.', "" #TAUTHOR_TAG have argued that Dale and Reiter 's ( 1995 ) dichotomy between salient and nonsalient objects ( where the objects in the domain are the salient ones ) should be replaced by an account that takes degrees of salience into account : No object can be too unsalient to be referred to , as long as the right properties are available ."", 'effect this proposal (which measured salience numerically) analyzes the black mouse as denoting the unique most salient object in the domain that is both black and a mouse.', '', '', '', '', '', '', '']","['', 'will will', 'A New Perspective on Salience.', "" #TAUTHOR_TAG have argued that Dale and Reiter 's ( 1995 ) dichotomy between salient and nonsalient objects ( where the objects in the domain are the salient ones ) should be replaced by an account that takes degrees of salience into account : No object can be too unsalient to be referred to , as long as the right properties are available ."", 'effect, this proposal (which measured salience numerically) analyzes the black mouse as denoting the unique most salient object in the domain that is both black and a mouse.', '', '', '', '', '', '', '']","['', 'will allow', '1 A New Perspective on Salience.', "" #TAUTHOR_TAG have argued that Dale and Reiter 's ( 1995 ) dichotomy between salient and nonsalient objects ( where the objects in the domain are the salient ones ) should be replaced by an account that takes degrees of salience into account : No object can be too unsalient to be referred to , as long as the right properties are available ."", 'effect this proposal (which measured salience numerically) analyzes the black mouse as denoting the unique most salient object in the domain that is both black and a mouse.', '', '', '', '', '', '', '']","['', '', '9.4.1 A New Perspective on Salience.', "" #TAUTHOR_TAG have argued that Dale and Reiter 's ( 1995 ) dichotomy between salient and nonsalient objects ( where the objects in the domain are the salient ones ) should be replaced by an account that takes degrees of salience into account : No object can be too unsalient to be referred to , as long as the right properties are available ."", 'In effect, this proposal (which measured salience numerically) analyzes the black mouse as denoting the unique most salient object in the domain that is both black and a mouse.', '', '', '', '', '', '', '']",0
"['Gradability is especially widespread in adjectives.', 'British Cor), ten most adjectives (', 'Children use vague adjectives among their first dozens of words ( Peccei 1994 ) and understand some of their intricacies as early as their 24th month #TAUTHOR_TAG .', 'These intricacies include what Ebeling and Gelman call perceptual context dependence, as when a set of objects is perceptually available and the adjective is applied to an element or subset of the set (e.g., Is this hat big or is it little?, when hats of different sizes are']","['Gradability is especially widespread in adjectives.', 'British Corpus ten most adjectives', 'Children use vague adjectives among their first dozens of words ( Peccei 1994 ) and understand some of their intricacies as early as their 24th month #TAUTHOR_TAG .', 'These intricacies include what Ebeling and Gelman call perceptual context dependence, as when a set of objects is perceptually available and the adjective is applied to an element or subset of the set (e.g., Is this hat big or is it little?, when hats of different sizes are']","['Gradability is especially widespread in adjectives.', '), the ten most frequent adjectives (', 'Children use vague adjectives among their first dozens of words ( Peccei 1994 ) and understand some of their intricacies as early as their 24th month #TAUTHOR_TAG .', 'These intricacies include what Ebeling and Gelman call perceptual context dependence, as when a set of objects is perceptually available and the adjective is applied to an element or subset of the set (e.g., Is this hat big or is it little?, when two hats of different sizes are']","['Gradability is especially widespread in adjectives.', '', 'Children use vague adjectives among their first dozens of words ( Peccei 1994 ) and understand some of their intricacies as early as their 24th month #TAUTHOR_TAG .', 'These intricacies include what Ebeling and Gelman call perceptual context dependence, as when a set of objects is perceptually available and the adjective is applied to an element or subset of the set (e.g., Is this hat big or is it little?, when two hats of different sizes are visible).']",0
"['for the adject to be applicable has not been cast open fiat decide 8 enough, or (cf., Kennedy 1999).', 'The numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed #TAUTHOR_TAG ; DeVault and Stone 2004 ) : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .', '', '', '']","['for the adjective to be applicable has not been cast open fiat: decide 8 enough, or (cf., Kennedy 1999).', 'The numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed #TAUTHOR_TAG ; DeVault and Stone 2004 ) : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .', '', '', '']","['for the adject to be applicable has not been cast open fiat may decide 8 cm enough, or (cf., Kennedy 1999).', 'The numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed #TAUTHOR_TAG ; DeVault and Stone 2004 ) : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .', '', '', '']","['Clearly, what it takes for the adjective to be applicable has not been cast in stone, but is open to fiat: the speaker may decide that 8 cm is enough, or the speaker may set the standards higher (cf., Kennedy 1999).', 'The numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed #TAUTHOR_TAG ; DeVault and Stone 2004 ) : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .', '', '', '']",0
"['We will examine the worst-case complexity of interpretation as well as generation to shed some light on the hypothesis that vague descriptions are more difficult to process than others because they involve a comparison between objects #TAUTHOR_TAG , Krahmer and Theune 2002 ) .', 'we do this, consider tract', '', '', 'we on the2  and']","['We will examine the worst-case complexity of interpretation as well as generation to shed some light on the hypothesis that vague descriptions are more difficult to process than others because they involve a comparison between objects #TAUTHOR_TAG , Krahmer and Theune 2002 ) .', 'we do this, consider tractability', '', '', 'we on the and']","['We will examine the worst-case complexity of interpretation as well as generation to shed some light on the hypothesis that vague descriptions are more difficult to process than others because they involve a comparison between objects #TAUTHOR_TAG , Krahmer and Theune 2002 ) .', 'we do this, consider', '', '', 'we focus on the2  and']","['We will examine the worst-case complexity of interpretation as well as generation to shed some light on the hypothesis that vague descriptions are more difficult to process than others because they involve a comparison between objects #TAUTHOR_TAG , Krahmer and Theune 2002 ) .', '', '', '', '']",0
"['', '', '', '; also reported in #TAUTHOR_TAG show that greater differences are most likely to be chosen , presumably because they are more striking .', 'ights width the refer the tall and theended tall', '', '', '', '', '']","['', '', '', '; also reported in #TAUTHOR_TAG show that greater differences are most likely to be chosen , presumably because they are more striking .', 'heights the referent the tallest and the tended tall', '', '', '', '', '']","['', '', '', '; also reported in #TAUTHOR_TAG show that greater differences are most likely to be chosen , presumably because they are more striking .', 'width the referent both the tallest andended', '', '', '', '', '']","['', '', '', ' #AUTHOR_TAG ; also reported in #TAUTHOR_TAG show that greater differences are most likely to be chosen , presumably because they are more striking .', '', '', '', '', '', '']",0
"['The account sketched in Section 4 was superimposed on an incremental GRE algorithm , partly because incrementality is well established in this area ( Appelt 1985 ; #TAUTHOR_TAG .', '', '']","['The account sketched in Section 4 was superimposed on an incremental GRE algorithm , partly because incrementality is well established in this area ( Appelt 1985 ; #TAUTHOR_TAG .', '', '']","['The account sketched in Section 4 was superimposed on an incremental GRE algorithm , partly because incrementality is well established in this area ( Appelt 1985 ; #TAUTHOR_TAG .', '', '']","['The account sketched in Section 4 was superimposed on an incremental GRE algorithm , partly because incrementality is well established in this area ( Appelt 1985 ; #TAUTHOR_TAG .', '', '']",0
"['Vague or gradable expressions pose problems to models of language, caused by their context dependence, and by the fact that they are applicable to different degrees.', 'degree we shall explore how referring expressions containing gradable adjectives can be produced by a Natural Language Generation (NLG) program.', 'Following #TAUTHOR_TAG , such expressions will be called vague descriptions even though , as we shall see , the vagueness of the adjective does not extend to the description as a whole .', 'It will be useful to generalize over different forms of the adjective, covering the superlative form (e.g., largest) and the comparative form (larger), as or form (large)', '', '']","['Vague or gradable expressions pose problems to models of language, caused by their context dependence, and by the fact that they are applicable to different degrees.', 'degree we shall explore how referring expressions containing gradable adjectives can be produced by a Natural Language Generation (NLG) program.', 'Following #TAUTHOR_TAG , such expressions will be called vague descriptions even though , as we shall see , the vagueness of the adjective does not extend to the description as a whole .', 'It will be useful to generalize over different forms of the adjective, covering the superlative form (e.g., largest) and the comparative form (larger), as or form (large)', '', '']","['Vague or gradable expressions pose problems to models of language, caused by their context dependence, and by the fact that they are applicable to different degrees.', 'we shall explore how referring expressions containing gradable adjectives can be produced by a Natural Language Generation (NLG) program.', 'Following #TAUTHOR_TAG , such expressions will be called vague descriptions even though , as we shall see , the vagueness of the adjective does not extend to the description as a whole .', 'It will be useful to generalize over different forms of the adjective, covering the superlative form (e.g., largest) and the comparative form (larger), as or base form (large)', '', '']","['Vague or gradable expressions pose problems to models of language, caused by their context dependence, and by the fact that they are applicable to different degrees.', '', 'Following #TAUTHOR_TAG , such expressions will be called vague descriptions even though , as we shall see , the vagueness of the adjective does not extend to the description as a whole .', 'It will be useful to generalize over different forms of the adjective, covering the superlative form (e.g., largest) and the comparative form (larger), as well as the positive or base form (large) of the adjective.', '', '']",5
"['', '', '', '', '', '', '', 'A similar problem is discussed in the psycholinguistics of interpretation #TAUTHOR_TAG : Interpretation is widely assumed to proceed incrementally , but vague strict incrementality , since an adjective in a vague description can only be fully interpreted when its comparison set is known', '', '']","['', '', '', '', '', '', '', 'A similar problem is discussed in the psycholinguistics of interpretation #TAUTHOR_TAG : Interpretation is widely assumed to proceed incrementally , but vague strict incrementality , since an adjective in a vague description can only be fully interpreted when its comparison set is known', '', '']","['', '', '', '', '', '', '', 'A similar problem is discussed in the psycholinguistics of interpretation #TAUTHOR_TAG : Interpretation is widely assumed to proceed incrementally , but vague descriptions strict incrementality , since an adjective in a vague description can only be fully interpreted when its comparison set is known .', '', '']","['', '', '', '', '', '', '', 'A similar problem is discussed in the psycholinguistics of interpretation #TAUTHOR_TAG : Interpretation is widely assumed to proceed incrementally , but vague descriptions resist strict incrementality , since an adjective in a vague description can only be fully interpreted when its comparison set is known .', '', '']",1
"['', 'the property added to the is context', 'the set with a form size ( involvesing the distractors as size may amount to O ( n2d ) or O ( nd log nd ) calculations ( depending on the sorting algorithm : cfXXX [ #TAUTHOR_TAG ] Chapter8 ) .', 'Once again, the most time-consuming part of the calculation can be performed off-line, since is the for all referring']","['', 'the property added to the is context', 'the set with a form size ( involves sorting the distractors as size may amount to O ( n2d ) or O ( nd log nd ) calculations ( depending on the sorting algorithm : cfXXX [ #TAUTHOR_TAG ] Chapter 8 ) .', 'Once again, the most time-consuming part of the calculation can be performed off-line, since is the for all referring']","['', 'the property added to the description is', 'with the form size ( involves sorting the distractors as size may amount to O ( n2d ) or O ( nd log nd ) calculations ( depending on the sorting algorithm : cfXXX [ #TAUTHOR_TAG ] Chapter 8 ) .', 'Once again, the most time-consuming part of the calculation can be performed off-line, since it is the for all referring expressions.']","['', '', '', 'Once again, the most time-consuming part of the calculation can be performed off-line, since it is the same for all referring expressions.']",0
"['Common sense ( as well as the Gricean maxims ; #TAUTHOR_TAG suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication .', 'the fact that vague descriptions are frequent is fairly well documented.', '', '', '', '', '', '', '']","['Common sense ( as well as the Gricean maxims ; #TAUTHOR_TAG suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication .', 'the fact that vague descriptions are frequent is fairly well documented.', '', '', '', '', '', '', '']","['Common sense ( as well as the Gricean maxims ; #TAUTHOR_TAG suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication .', 'the fact that vague descriptions are frequent is fairly well documented.', '', '', '', '', '', '', '']","['Common sense ( as well as the Gricean maxims ; #TAUTHOR_TAG suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication .', '', '', '', '', '', '', '', '']",0
"['ity the', 'shapes', 'there exists a formula for mapping three into (g height the dimension (over-size), and the of 4 can be applied verbatim.', 'But if big is applied to a person then it is far from clear that there is one canonical formula for mapping the different dimensions of your body into one overall dimension, and this complicates the situation.', 'Similar things hold for multifaceted properties like intelligence #TAUTHOR_TAG .']","['the', 'shapes.', 'there exists a formula for mapping three into height) the dimension (overall-size), and the of 4 can be applied verbatim.', 'But if big is applied to a person then it is far from clear that there is one canonical formula for mapping the different dimensions of your body into one overall dimension, and this complicates the situation.', 'Similar things hold for multifaceted properties like intelligence #TAUTHOR_TAG .']","['ity', '', 'there exists a formula for mapping three dimensions into (g one dimension (over-size), and the algorithm of Section 4 can be applied verbatim.', 'But if big is applied to a person then it is far from clear that there is one canonical formula for mapping the different dimensions of your body into one overall dimension, and this complicates the situation.', 'Similar things hold for multifaceted properties like intelligence #TAUTHOR_TAG .']","['', '', 'If there exists a formula for mapping three dimensions into one (e.g., length × width × height) then the result is one dimension (overall-size), and the algorithm of Section 4 can be applied verbatim.', 'But if big is applied to a person then it is far from clear that there is one canonical formula for mapping the different dimensions of your body into one overall dimension, and this complicates the situation.', 'Similar things hold for multifaceted properties like intelligence #TAUTHOR_TAG .']",0
"['of the ""global', 'For some adjectives , including the ones that #TAUTHOR_TAG called evaluative ( as opposed to dimensional ) , this is clearly inadequate .', 'He argued that evaluative adjectives (such as beautiful and its antonym ugly; smart and its antonym stupid, etc.) can be recognized by the way in which they compare with antonyms.', 'For example (after Bierwisch 1989),']","['of the ""global""', 'For some adjectives , including the ones that #TAUTHOR_TAG called evaluative ( as opposed to dimensional ) , this is clearly inadequate .', 'He argued that evaluative adjectives (such as beautiful and its antonym ugly; smart and its antonym stupid, etc.) can be recognized by the way in which they compare with antonyms.', 'For example (after Bierwisch 1989),']","['of the ""global""', 'For some adjectives , including the ones that #TAUTHOR_TAG called evaluative ( as opposed to dimensional ) , this is clearly inadequate .', 'He argued that evaluative adjectives (such as beautiful and its antonym ugly; smart and its antonym stupid, etc.) can be recognized by the way in which they compare with antonyms.', 'For example (after Bierwisch 1989),']","['', 'For some adjectives , including the ones that #TAUTHOR_TAG called evaluative ( as opposed to dimensional ) , this is clearly inadequate .', 'He argued that evaluative adjectives (such as beautiful and its antonym ugly; smart and its antonym stupid, etc.) can be recognized by the way in which they compare with antonyms.', 'For example (after Bierwisch 1989),']",0
"['Minimality.', 'Unless Small Gaps and Dichotomy forbid it, we expected that preference should be given to the base form.', 'In English , where the base form is morphologically simpler than the other two , this rule could be argued to follow from Gricean principles #TAUTHOR_TAG .']","['Minimality.', 'Unless Small Gaps and Dichotomy forbid it, we expected that preference should be given to the base form.', 'In English , where the base form is morphologically simpler than the other two , this rule could be argued to follow from Gricean principles #TAUTHOR_TAG .']","['Minimality.', 'Unless Small Gaps and Dichotomy forbid it, we expected that preference should be given to the base form.', 'In English , where the base form is morphologically simpler than the other two , this rule could be argued to follow from Gricean principles #TAUTHOR_TAG .']","['Minimality.', 'Unless Small Gaps and Dichotomy forbid it, we expected that preference should be given to the base form.', 'In English , where the base form is morphologically simpler than the other two , this rule could be argued to follow from Gricean principles #TAUTHOR_TAG .']",0
"['If the usefulness ofG resides in its ability to present data in human-accessible form, then vagueness must surely be one of its central instruments, because it allows the suppression of irrelevant detail.', 'In principle , this might be done by providing the generator with vague input -- in which case no special algorithms are needed -- but suitably contextualized vague input is often not available #TAUTHOR_TAG .', 'hook', '', '', '']","['If the usefulness of NLG resides in its ability to present data in human-accessible form, then vagueness must surely be one of its central instruments, because it allows the suppression of irrelevant detail.', 'In principle , this might be done by providing the generator with vague input -- in which case no special algorithms are needed -- but suitably contextualized vague input is often not available #TAUTHOR_TAG .', 'hooked', '', '', '']","['If the usefulness ofG resides in its ability to present data in human-accessible form, then vagueness must surely be one of its central instruments, because it allows the suppression of irrelevant detail.', 'In principle , this might be done by providing the generator with vague input -- in which case no special algorithms are needed -- but suitably contextualized vague input is often not available #TAUTHOR_TAG .', '', '', '', '']","['If the usefulness of NLG resides in its ability to present data in human-accessible form, then vagueness must surely be one of its central instruments, because it allows the suppression of irrelevant detail.', 'In principle , this might be done by providing the generator with vague input -- in which case no special algorithms are needed -- but suitably contextualized vague input is often not available #TAUTHOR_TAG .', '', '', '', '']",4
"['description (., Daleock', 'CD for this type of descriptions along the lines of Section 4 is not difficult once relational descriptions are integrated with a standard GRE algorithm #TAUTHOR_TAG , Section 8.6.2 )', '']","['description (cf., Dale', 'CD for this type of descriptions along the lines of Section 4 is not difficult once relational descriptions are integrated with a standard GRE algorithm #TAUTHOR_TAG , Section 8.6.2 )', '']","['(., Dale', 'CD for this type of descriptions along the lines of Section 4 is not difficult once relational descriptions are integrated with a standard GRE algorithm #TAUTHOR_TAG , Section 8.6.2 )', '']","['', '', '']",0
"['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; #TAUTHOR_TAG ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates', '(', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; #TAUTHOR_TAG ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates', '', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; #TAUTHOR_TAG ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '(', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; #TAUTHOR_TAG ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '', '', '', '', '', '', '', '', '']",0
"['to complex Boolean involving neg andunction ( 2 to marked', 'For the have to decide whether to say the patients that are old or the patients that are not young.', '9.3 Multidimensionality 9.3.1 Combinations of Adjectives.', 'When objects are compared in terms of several dimensions , these dimensions can be weighed in different ways ( e.g. , #TAUTHOR_TAG .', 'on to refer', '']","['to complex Boolean involving negation and (van to', 'For the have to decide whether to say the patients that are old or the patients that are not young.', '9.3 Multidimensionality 9.3.1 Combinations of Adjectives.', 'When objects are compared in terms of several dimensions , these dimensions can be weighed in different ways ( e.g. , #TAUTHOR_TAG .', 'on to referent', '']","['to complex Boolean descriptions involving neg andunction ( to marked', 'For will have to decide whether to say the patients that are old or the patients that are not young.', '9.3 Multidimensionality 9.3.1 Combinations of Adjectives.', 'When objects are compared in terms of several dimensions , these dimensions can be weighed in different ways ( e.g. , #TAUTHOR_TAG .', 'on to', '']","['', 'For example, the generator will have to decide whether to say the patients that are old or the patients that are not young.', '9.3 Multidimensionality 9.3.1 Combinations of Adjectives.', 'When objects are compared in terms of several dimensions , these dimensions can be weighed in different ways ( e.g. , #TAUTHOR_TAG .', '', '']",0
"['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; #TAUTHOR_TAG ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it', '', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; #TAUTHOR_TAG ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it', '', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; #TAUTHOR_TAG ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which', '', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; #TAUTHOR_TAG ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '', '', '', '', '', '', '', '', '']",0
"['', 'Fritz to be the stupid man, it is not enough for him to be the least male in the local context; he also has to be a specimen in his own right.) If this is done, it is not evident that dimensional adjectives should be treated differently: If Hans�s and Fritz�s heights are 210 and 205 cm, respectively, then it seems questionable to describe Fritz as the short man, even if Hans is the only other man in the local context (but see #TAUTHOR_TAG 1999, discussed in Section 7.2).', '']","['', 'Fritz to be the stupid man, it is not enough for him to be the least male in the local context; he also has to be a specimen in his own right.) If this is done, it is not evident that dimensional adjectives should be treated differently: If Hans�s and Fritz�s heights are 210 and 205 cm, respectively, then it seems questionable to describe Fritz as the short man, even if Hans is the only other man in the local context (but see #TAUTHOR_TAG 1999, discussed in Section 7.2).', '']","['', 'For Fritz to be the stupid man, it is not enough for him to be the least intelligent male in the local context; he also has to be a fairly stupid specimen in his own right.) If this is done, it is not evident that dimensional adjectives should be treated differently: If Hans�s and Fritz�s heights are 210 and 205 cm, respectively, then it seems questionable to describe Fritz as the short man, even if Hans is the only other man in the local context (but see #TAUTHOR_TAG 1999, discussed in Section 7.2).', '']","['', '(For Fritz to be the stupid man, it is not enough for him to be the least intelligent male in the local context; he also has to be a fairly stupid specimen in his own right.) If this is done, it is not evident that dimensional adjectives should be treated differently: If Hans�s and Fritz�s heights are 210 and 205 cm, respectively, then it seems questionable to describe Fritz as the short man, even if Hans is the only other man in the local context (but see #TAUTHOR_TAG 1999, discussed in Section 7.2).', '']",0
"['NLG has to do more than select a distinguishing description ( i.e. , one that unambiguously denotes its referent ; #TAUTHOR_TAG : The selected expression should also be felicitous .', 'observ', '', '']","['NLG has to do more than select a distinguishing description ( i.e. , one that unambiguously denotes its referent ; #TAUTHOR_TAG : The selected expression should also be felicitous .', '', '', '']","['NLG has to do more than select a distinguishing description ( i.e. , one that unambiguously denotes its referent ; #TAUTHOR_TAG : The selected expression should also be felicitous .', 'observ', '', '']","['NLG has to do more than select a distinguishing description ( i.e. , one that unambiguously denotes its referent ; #TAUTHOR_TAG : The selected expression should also be felicitous .', '', '', '']",0
"['One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , Shaw and Hatzivassiloglou 1999 ; #TAUTHOR_TAG .', ""Work in this area is often based on assigning adjectives to a small number of categories (e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives' relative position."", 'Interestingly, vague properties tend to be realized before others', '', '', '', '', '', '', '']","['One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , Shaw and Hatzivassiloglou 1999 ; #TAUTHOR_TAG .', ""Work in this area is often based on assigning adjectives to a small number of categories (e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives' relative position."", 'Interestingly, vague properties tend to be realized before others.', '', '', '', '', '', '', '']","['One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , Shaw and Hatzivassiloglou 1999 ; #TAUTHOR_TAG .', ""Work in this area is often based on assigning adjectives to a small number of categories (e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives' relative position."", 'Interestingly, vague properties tend to be realized before others', '', '', '', '', '', '', '']","['One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , Shaw and Hatzivassiloglou 1999 ; #TAUTHOR_TAG .', ""Work in this area is often based on assigning adjectives to a small number of categories (e.g., Precentral, Central, Postcentral, and Prehead), which predict adjectives' relative position."", 'Interestingly, vague properties tend to be realized before others.', '', '', '', '', '', '', '']",0
"['4 To turn this likelihood into a certainty , one can add a test at the end of the algorithm , which adds a type-related property if none is present yet ( cfXXX , #TAUTHOR_TAG .', 'VAGUE uses both of these devices.']","['4 To turn this likelihood into a certainty , one can add a test at the end of the algorithm , which adds a type-related property if none is present yet ( cfXXX , #TAUTHOR_TAG .', 'VAGUE uses both of these devices.']","['4 To turn this likelihood into a certainty , one can add a test at the end of the algorithm , which adds a type-related property if none is present yet ( cfXXX , #TAUTHOR_TAG .', 'VAGUE uses both of these devices.']","['4 To turn this likelihood into a certainty , one can add a test at the end of the algorithm , which adds a type-related property if none is present yet ( cfXXX , #TAUTHOR_TAG .', 'VAGUE uses both of these devices.']",0
"[', is the only object that has a Pareto-optimal combination of Values, predicting correctly can be called the tall giraffe', '', '', 'alternative', 'The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors ( Nash 1950 ; cfXXX #TAUTHOR_TAG ; Thorisson 1994 , for other plans ) .']","['example, is the only object that has a Pareto-optimal combination of Values, predicting correctly can be called the tall giraffe.', '', '', 'alternative', 'The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors ( Nash 1950 ; cfXXX #TAUTHOR_TAG ; Thorisson 1994 , for other plans ) .']","[', b is the only object that has a Pareto-optimal combination of Values, predicting correctly can be called the tall fat giraffe.', '', '', '', 'The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors ( Nash 1950 ; cfXXX #TAUTHOR_TAG ; Thorisson 1994 , for other plans ) .']","['In our example, b is the only object that has a Pareto-optimal combination of Values, predicting correctly that b can be called the tall fat giraffe.', '', '', '', 'The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors ( Nash 1950 ; cfXXX #TAUTHOR_TAG ; Thorisson 1994 , for other plans ) .']",0
"['for cast9', 'numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed ( Kyburg and Morreau 2000 ; #TAUTHOR_TAG : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .', '', '', '']","['for cast', 'numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed ( Kyburg and Morreau 2000 ; #TAUTHOR_TAG : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .', '', '', '']","['for been cast', 'numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed ( Kyburg and Morreau 2000 ; #TAUTHOR_TAG : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .', '', '', '']","['', 'The numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed ( Kyburg and Morreau 2000 ; #TAUTHOR_TAG : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .', '', '', '']",0
"['', '', '', 'Each of these Values has equal status , so the notion of a basic-level Value can not play a role ( cfXXX , #TAUTHOR_TAG .', ""If we abstract away from the role of basic-level Values, then Dale and Reiter's FindBestValue chooses the most general Value that removes the maximal number of distractors, as we have seen."", '', '']","['', '', '', 'Each of these Values has equal status , so the notion of a basic-level Value can not play a role ( cfXXX , #TAUTHOR_TAG .', ""If we abstract away from the role of basic-level Values, then Dale and Reiter's FindBestValue chooses the most general Value that removes the maximal number of distractors, as we have seen."", '', '']","['', '', '', 'Each of these Values has equal status , so the notion of a basic-level Value can not play a role ( cfXXX , #TAUTHOR_TAG .', ""If we abstract away from the role of basic-level Values, then Dale and Reiter's FindBestValue chooses the most general Value that removes the maximal number of distractors, as we have seen."", '', '']","['', '', '', 'Each of these Values has equal status , so the notion of a basic-level Value can not play a role ( cfXXX , #TAUTHOR_TAG .', ""If we abstract away from the role of basic-level Values, then Dale and Reiter's FindBestValue chooses the most general Value that removes the maximal number of distractors, as we have seen."", '', '']",0
"['Some generalizations of our method are fairly straightforward.', 'For example , consider a relational description ( cfXXX , #TAUTHOR_TAG involving a gradable adjective , as in the dog in the large shed .', 'of of4 difficult relational are integrated with a standard GRE algorithm (Krahmer and Theune , Section', '', '', '']","['Some generalizations of our method are fairly straightforward.', 'For example , consider a relational description ( cfXXX , #TAUTHOR_TAG involving a gradable adjective , as in the dog in the large shed .', 'of of 4 difficult relational are integrated with a standard GRE algorithm (Krahmer and Theune Section', '', '', '']","['Some generalizations of our method are fairly straightforward.', 'For example , consider a relational description ( cfXXX , #TAUTHOR_TAG involving a gradable adjective , as in the dog in the large shed .', 'of of difficult once relational descriptions are integrated with a standard GRE algorithm (Krahmer and The', '', '', '']","['Some generalizations of our method are fairly straightforward.', 'For example , consider a relational description ( cfXXX , #TAUTHOR_TAG involving a gradable adjective , as in the dog in the large shed .', '', '', '', '']",0
"[', is the only object that has a Pareto-optimal combination of Values, predicting correctly b can be called the tall giraffe', '', '', '', 'The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors #TAUTHOR_TAG ; cfXXX Gorniak and Roy 2003 ; Thorisson 1994 , for other plans ) .']","['example, is the only object that has a Pareto-optimal combination of Values, predicting correctly b can be called the tall giraffe.', '', '', '', 'The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors #TAUTHOR_TAG ; cfXXX Gorniak and Roy 2003 ; Thorisson 1994 , for other plans ) .']","[', b is the only object that has a Pareto-optimal combination of Values, predicting correctly b can be called the tall fat giraffe.', '', '', '', 'The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors #TAUTHOR_TAG ; cfXXX Gorniak and Roy 2003 ; Thorisson 1994 , for other plans ) .']","['In our example, b is the only object that has a Pareto-optimal combination of Values, predicting correctly that b can be called the tall fat giraffe.', '', '', '', 'The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors #TAUTHOR_TAG ; cfXXX Gorniak and Roy 2003 ; Thorisson 1994 , for other plans ) .']",0
"['The inference rules that were necessary to convert one list of properties into another do not sit comfortably within the received NLG pipeline model ( e.g. , #TAUTHOR_TAG .', 'An example of such an inference rule is the one that transforms a list of the form >0 cm into one of the', '']","['The inference rules that were necessary to convert one list of properties into another do not sit comfortably within the received NLG pipeline model ( e.g. , #TAUTHOR_TAG .', 'An example of such an inference rule is the one that transforms a list of the form >10 cm into one of the', '']","['The inference rules that were necessary to convert one list of properties into another do not sit comfortably within the received NLG pipeline model ( e.g. , #TAUTHOR_TAG .', 'An example of such an inference rule is the one that transforms a list of the form mouse, >10 cm into one of', '']","['The inference rules that were necessary to convert one list of properties into another do not sit comfortably within the received NLG pipeline model ( e.g. , #TAUTHOR_TAG .', '', '']",0
"['systems produce gradable adjectives TheG weather-fore, for, uses numerical input (Rain[Tuesday] = 45 mm) to generate vague output (Heavy rain fell on Tuesday, Goldberg, Driedger, and Kitteridge 1994).', 'FOG not to have generic rules governing the of not: it does not compute the meaning of a term on the context, but fixed boundary values instead', 'A more flexible approach is used by #TAUTHOR_TAG , where users can specify boundary values for attributes like rainfall , specifying , for example , rain counts as moderate above 7 mm/h , as heavy above 20 mm/h , and so on .', '', '', '']","['systems produce gradable adjectives. The FOG weather-forecast system, for example, uses numerical input (Rain[Tuesday] = 45 mm) to generate vague output (Heavy rain fell on Tuesday, Goldberg, Driedger, and Kitteridge 1994).', 'FOG not to have generic rules governing the of notions: it does not compute the meaning of a term on the context, but fixed boundary values instead.', 'A more flexible approach is used by #TAUTHOR_TAG , where users can specify boundary values for attributes like rainfall , specifying , for example , rain counts as moderate above 7 mm/h , as heavy above 20 mm/h , and so on .', '', '', '']","['produce gradable adjectives The FOG weather-fore for, uses numerical input (Rain[Tuesday] = 45 mm) to generate vague output (Heavy rain fell on Tuesday, Goldberg, Driedger, and Kitteridge 1994).', 'FOG does not to have generic rules governing the use ofable notions: it does not compute the meaning of a vague term on the context, but fixed boundary values instead', 'A more flexible approach is used by #TAUTHOR_TAG , where users can specify boundary values for attributes like rainfall , specifying , for example , rain counts as moderate above 7 mm/h , as heavy above 20 mm/h , and so on .', '', '', '']","['Some NLG systems produce gradable adjectives. The FOG weather-forecast system, for example, uses numerical input (Rain[Tuesday] = 45 mm) to generate vague output (Heavy rain fell on Tuesday, Goldberg, Driedger, and Kitteridge 1994).', 'FOG does not appear to have generic rules governing the use of gradable notions: it does not compute the meaning of a vague term based on the context, but uses fixed boundary values instead.', 'A more flexible approach is used by #TAUTHOR_TAG , where users can specify boundary values for attributes like rainfall , specifying , for example , rain counts as moderate above 7 mm/h , as heavy above 20 mm/h , and so on .', '', '', '']",0
"['Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead #TAUTHOR_TAG ; Krahmer and Theune 2002 ) .', 'We have separated the two phases because, in the case of vague descriptions, interleaving would tend to be difficult.', '', '', '']","['Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead #TAUTHOR_TAG ; Krahmer and Theune 2002 ) .', 'We have separated the two phases because, in the case of vague descriptions, interleaving would tend to be difficult.', '', '', '']","['Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead #TAUTHOR_TAG ; Krahmer and Theune 2002 ) .', 'We have separated the two phases because, in the case of vague descriptions, interleaving would tend to be difficult.', '', '', '']","['Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead #TAUTHOR_TAG ; Krahmer and Theune 2002 ) .', 'We have separated the two phases because, in the case of vague descriptions, interleaving would tend to be difficult.', '', '', '']",1
"['While IA is generally thought to be consistent with findings on human language production #TAUTHOR_TAG ; Levelt 1989 ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates', '', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production #TAUTHOR_TAG ; Levelt 1989 ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates', '', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production #TAUTHOR_TAG ; Levelt 1989 ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '', '', '', '', '', '', '', '', '']","['While IA is generally thought to be consistent with findings on human language production #TAUTHOR_TAG ; Levelt 1989 ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .', '', '', '', '', '', '', '', '', '']",0
"['', 'modeled in saturation', '', 'chair chairs refer', 'A further complication is that different speakers can regard very different values as prototypical , making it difficult to assess which of two objects is greener even on one dimension #TAUTHOR_TAG , pages 10 -- 12 ) .', '( G', '', '', '', '', '', '', '', '']","['', 'modeled in saturation,', '', 'chair, chairs, refer', 'A further complication is that different speakers can regard very different values as prototypical , making it difficult to assess which of two objects is greener even on one dimension #TAUTHOR_TAG , pages 10 -- 12 ) .', 'GRE', '', '', '', '', '', '', '', '']","['', 'is modeled in saturation', '', 'would refer', 'A further complication is that different speakers can regard very different values as prototypical , making it difficult to assess which of two objects is greener even on one dimension #TAUTHOR_TAG , pages 10 -- 12 ) .', '(', '', '', '', '', '', '', '', '']","['', '', '', '', 'A further complication is that different speakers can regard very different values as prototypical , making it difficult to assess which of two objects is greener even on one dimension #TAUTHOR_TAG , pages 10 -- 12 ) .', '', '', '', '', '', '', '', '', '']",0
"['', 'it is worth noting that the inequalities computed as step  the of4 might be psychologically more plausible, they are essentially no more than compar between.', ' #TAUTHOR_TAG asked subjects to identify the target of a vague description in a visual scene .', 'Consider the tall cup.', 'The relevant scene contain three distractors: () a less tall object of the height a to ad', 'object', '', '']","['', 'it is worth noting that the inequalities computed as step 2 the of 4 might be psychologically more plausible, they are essentially no more than comparisons between objects.', ' #TAUTHOR_TAG asked subjects to identify the target of a vague description in a visual scene .', 'Consider the tall cup.', 'The relevant scene contain three distractors: (1) a less tall object of the height a to', 'object', '', '']","['', 'it is worth noting that the inequalities computed as step 2 the algorithm of might be psychologically more plausible, they are essentially no more than compar between.', ' #TAUTHOR_TAG asked subjects to identify the target of a vague description in a visual scene .', 'Consider the tall cup.', 'The relevant scene would contain three distractors: () a less tall object of the target height to', 'object', '', '']","['', '', ' #TAUTHOR_TAG asked subjects to identify the target of a vague description in a visual scene .', 'Consider the tall cup.', '', '', '', '']",0
"['It has been argued that , in an incremental approach , gradable properties should be given a low preference ranking because they are difficult to process #TAUTHOR_TAG .', '4 interpretation vague descriptions a', 'grad properties a low might cause the algorithm to underuse them to', '', '']","['It has been argued that , in an incremental approach , gradable properties should be given a low preference ranking because they are difficult to process #TAUTHOR_TAG .', '4.3 interpretation vague descriptions a', 'gradable properties a low might cause the algorithm to underuse them, to', '', '']","['It has been argued that , in an incremental approach , gradable properties should be given a low preference ranking because they are difficult to process #TAUTHOR_TAG .', 'interpretation vague descriptions', 'giving gradable properties a low ranking, we might cause the algorithm to underuse them to', '', '']","['It has been argued that , in an incremental approach , gradable properties should be given a low preference ranking because they are difficult to process #TAUTHOR_TAG .', '', '', '', '']",1
"['2 The reader is asked to focus on any reasonable size measurement , for example , the maximal horizontal or vertical distance , or some combination of dimensions #TAUTHOR_TAG ; also Section 8.1 of the present article ) .']","['2 The reader is asked to focus on any reasonable size measurement , for example , the maximal horizontal or vertical distance , or some combination of dimensions #TAUTHOR_TAG ; also Section 8.1 of the present article ) .']","['2 The reader is asked to focus on any reasonable size measurement , for example , the maximal horizontal or vertical distance , or some combination of dimensions #TAUTHOR_TAG ; also Section 8.1 of the present article ) .']","['2 The reader is asked to focus on any reasonable size measurement , for example , the maximal horizontal or vertical distance , or some combination of dimensions #TAUTHOR_TAG ; also Section 8.1 of the present article ) .']",0
"['treated regardless', '', '', '', '', ""In other words , existing treatments of gradables in GRE fail to take the `` efficiency of language '' into account #TAUTHOR_TAG ; see our Section 2 ) .""]","['treated regardless', '', '', '', '', ""In other words , existing treatments of gradables in GRE fail to take the `` efficiency of language '' into account #TAUTHOR_TAG ; see our Section 2 ) .""]","['are treated', '', '', '', '', ""In other words , existing treatments of gradables in GRE fail to take the `` efficiency of language '' into account #TAUTHOR_TAG ; see our Section 2 ) .""]","['', '', '', '', '', ""In other words , existing treatments of gradables in GRE fail to take the `` efficiency of language '' into account #TAUTHOR_TAG ; see our Section 2 ) .""]",0
"['The second facet is independent of the clinical task and pertains to the structure of a well-built clinical question.', 'The following four components have been identified as the key elements of a question related to patient care #TAUTHOR_TAG :']","['The second facet is independent of the clinical task and pertains to the structure of a well-built clinical question.', 'The following four components have been identified as the key elements of a question related to patient care #TAUTHOR_TAG :']","['The second facet is independent of the clinical task and pertains to the structure of a well-built clinical question.', 'The following four components have been identified as the key elements of a question related to patient care #TAUTHOR_TAG :']","['The second facet is independent of the clinical task and pertains to the structure of a well-built clinical question.', 'The following four components have been identified as the key elements of a question related to patient care #TAUTHOR_TAG :']",0
"['Mean Average Precision (MAP) is the average of precision values after each relevant document is retrieved #TAUTHOR_TAG .', 'It is the most widely accepted single-value metric in information retrieval, and is seen to balance the need for both precision and recall.']","['Mean Average Precision (MAP) is the average of precision values after each relevant document is retrieved #TAUTHOR_TAG .', 'It is the most widely accepted single-value metric in information retrieval, and is seen to balance the need for both precision and recall.']","['Mean Average Precision (MAP) is the average of precision values after each relevant document is retrieved #TAUTHOR_TAG .', 'It is the most widely accepted single-value metric in information retrieval, and is seen to balance the need for both precision and recall.']","['Mean Average Precision (MAP) is the average of precision values after each relevant document is retrieved #TAUTHOR_TAG .', 'It is the most widely accepted single-value metric in information retrieval, and is seen to balance the need for both precision and recall.']",5
"['be sensitive to is not new', 'Mend have studiedSH associated basic clinical tasks therapyosisology', 'cit', '', 'Although originally developed as a tool to assist in query formulation , #TAUTHOR_TAG pointed out that PICO frames can be employed to structure IR results for improving precision .', 'ICObased querying in information retriev', '']","['be sensitive to is not new.', 'have studied MeSH associated basic clinical tasks therapy,', 'citations', '', 'Although originally developed as a tool to assist in query formulation , #TAUTHOR_TAG pointed out that PICO frames can be employed to structure IR results for improving precision .', 'PICO-based querying in information retrieval', '']","['should be sensitive to is not new', 'have studiedSH terms associated the four basic clinical tasks therapyology', 'cit', '', 'Although originally developed as a tool to assist in query formulation , #TAUTHOR_TAG pointed out that PICO frames can be employed to structure IR results for improving precision .', 'ICObased querying in information retrieval', '']","['', '', '', '', 'Although originally developed as a tool to assist in query formulation , #TAUTHOR_TAG pointed out that PICO frames can be employed to structure IR results for improving precision .', '', '']",0
"['- is na Bayes class it.', 'We first identified the most informative unigrams and bigrams using the information gain measure #TAUTHOR_TAG , and then selected only the positive outcome predictors using odds ratio ( Mladenic and Grobelnik 1999 ) .', '', '', '']","['is naive Bayes it features.', 'We first identified the most informative unigrams and bigrams using the information gain measure #TAUTHOR_TAG , and then selected only the positive outcome predictors using odds ratio ( Mladenic and Grobelnik 1999 ) .', '', '', '']","['- is also a naive Bayes classifier, it operates.', 'We first identified the most informative unigrams and bigrams using the information gain measure #TAUTHOR_TAG , and then selected only the positive outcome predictors using odds ratio ( Mladenic and Grobelnik 1999 ) .', '', '', '']","['', 'We first identified the most informative unigrams and bigrams using the information gain measure #TAUTHOR_TAG , and then selected only the positive outcome predictors using odds ratio ( Mladenic and Grobelnik 1999 ) .', '', '', '']",5
"['In addition to question answering, multi-document summarization provides a complementary approach to addressing clinical information needs.', ""The PERSIVAL project , the most comprehensive study of such techniques applied on medical texts to date , leverages patient records to generate personalized summaries in response to physicians ' queries ( McKeown , Elhadad , and Hatzivassiloglou 2003 ; #TAUTHOR_TAG ."", 'Although the system incorporates both a user and a task model, it does not explicitly capture the of evidence-based medicine.', 'doubt']","['In addition to question answering, multi-document summarization provides a complementary approach to addressing clinical information needs.', ""The PERSIVAL project , the most comprehensive study of such techniques applied on medical texts to date , leverages patient records to generate personalized summaries in response to physicians ' queries ( McKeown , Elhadad , and Hatzivassiloglou 2003 ; #TAUTHOR_TAG ."", 'Although the system incorporates both a user and a task model, it does not explicitly capture the of evidence-based medicine.', 'doubt']","['In addition to question answering, multi-document summarization provides a complementary approach to addressing clinical information needs.', ""The PERSIVAL project , the most comprehensive study of such techniques applied on medical texts to date , leverages patient records to generate personalized summaries in response to physicians ' queries ( McKeown , Elhadad , and Hatzivassiloglou 2003 ; #TAUTHOR_TAG ."", 'Although the system incorporates both a user and a task model, it does not explicitly capture the principles of evidence-based medicine.', 'no doubt']","['In addition to question answering, multi-document summarization provides a complementary approach to addressing clinical information needs.', ""The PERSIVAL project , the most comprehensive study of such techniques applied on medical texts to date , leverages patient records to generate personalized summaries in response to physicians ' queries ( McKeown , Elhadad , and Hatzivassiloglou 2003 ; #TAUTHOR_TAG ."", 'Although the system incorporates both a user and a task model, it does not explicitly capture the principles of evidence-based medicine.', '']",1
"['The literature also contains work on sentence-level classification of MEDLINE abstracts for non-clinical purposes.', 'For example , Mc #AUTHOR_TAG describe a machine learning approach to automatically label sentences as belonging to introduction , methods , results , or conclusion using structured abstracts as training data ( see also #TAUTHOR_TAG .', '', '', '']","['The literature also contains work on sentence-level classification of MEDLINE abstracts for non-clinical purposes.', 'For example , Mc #AUTHOR_TAG describe a machine learning approach to automatically label sentences as belonging to introduction , methods , results , or conclusion using structured abstracts as training data ( see also #TAUTHOR_TAG .', '', '', '']","['The literature also contains work on sentence-level classification of MEDLINE abstracts for non-clinical purposes.', 'For example , Mc #AUTHOR_TAG describe a machine learning approach to automatically label sentences as belonging to introduction , methods , results , or conclusion using structured abstracts as training data ( see also #TAUTHOR_TAG .', '', '', '']","['The literature also contains work on sentence-level classification of MEDLINE abstracts for non-clinical purposes.', 'For example , Mc #AUTHOR_TAG describe a machine learning approach to automatically label sentences as belonging to introduction , methods , results , or conclusion using structured abstracts as training data ( see also #TAUTHOR_TAG .', '', '', '']",0
"['most important phys', '', '', 'We have noted that many of these desiderata make complex question answering quite similar to multi-document summarization #TAUTHOR_TAG b ) , but these features are also beyond the capabilities of current summarization systems .']","['most important', '', '', 'We have noted that many of these desiderata make complex question answering quite similar to multi-document summarization #TAUTHOR_TAG b ) , but these features are also beyond the capabilities of current summarization systems .']","['most important characteristic', '', '', 'We have noted that many of these desiderata make complex question answering quite similar to multi-document summarization #TAUTHOR_TAG b ) , but these features are also beyond the capabilities of current summarization systems .']","['', '', '', 'We have noted that many of these desiderata make complex question answering quite similar to multi-document summarization #TAUTHOR_TAG b ) , but these features are also beyond the capabilities of current summarization systems .']",1
"['The literature contains work on sentence-level classification ofEDLINE abstracts', '', ' #TAUTHOR_TAG have demonstrated that differential weighting of automatically labeled sections can lead to improved retrieval performance .', '', '']","['The literature contains work on sentence-level classification of MEDLINE abstracts', '', ' #TAUTHOR_TAG have demonstrated that differential weighting of automatically labeled sections can lead to improved retrieval performance .', '', '']","['The literature contains work on sentence-level classification ofEDLINE abstracts', '', ' #TAUTHOR_TAG have demonstrated that differential weighting of automatically labeled sections can lead to improved retrieval performance .', '', '']","['The literature also contains work on sentence-level classification of MEDLINE abstracts for non-clinical purposes.', '', ' #TAUTHOR_TAG have demonstrated that differential weighting of automatically labeled sections can lead to improved retrieval performance .', '', '']",0
"['', 'Dorsch', 'have shown that existing systems for searching MEDLINE ( such as , the search service provided by the National Library of Medicine ) are often inadequate and unable to supply clinically relevant answers in a timely manner ( Gorman , Ash , and Wykoff 1994 ; #TAUTHOR_TAG .', 'ins', '']","['', 'Dorsch', 'have shown that existing systems for searching MEDLINE ( such as , the search service provided by the National Library of Medicine ) are often inadequate and unable to supply clinically relevant answers in a timely manner ( Gorman , Ash , and Wykoff 1994 ; #TAUTHOR_TAG .', 'insufficient', '']","['', 'D', 'have shown that existing systems for searching MEDLINE ( such as , the search service provided by the National Library of Medicine ) are often inadequate and unable to supply clinically relevant answers in a timely manner ( Gorman , Ash , and Wykoff 1994 ; #TAUTHOR_TAG .', 'ins', '']","['', '', 'However , studies have shown that existing systems for searching MEDLINE ( such as PubMed , the search service provided by the National Library of Medicine ) are often inadequate and unable to supply clinically relevant answers in a timely manner ( Gorman , Ash , and Wykoff 1994 ; #TAUTHOR_TAG .', '', '']",0
"['Additional are associated with eachED citation.', 'The most important of these is the controlled vocabulary terms assigned by human indexers.', 'NLMSH', '.', 'Since mid-2002 , the Library has been employing software that automatically suggests MeSH headings based on content #TAUTHOR_TAG .', ', the indexing process remains firmly human-centered.']","['Additional are associated with each citation.', 'The most important of these is the controlled vocabulary terms assigned by human indexers.', ""NLM's"", '', 'Since mid-2002 , the Library has been employing software that automatically suggests MeSH headings based on content #TAUTHOR_TAG .', 'Nevertheless, the indexing process remains firmly human-centered.']","['Additional metadata are associated with each MEDLINE citation.', 'The most important of these is the controlled vocabulary terms assigned by human indexers.', 'NLMSH', '.', 'Since mid-2002 , the Library has been employing software that automatically suggests MeSH headings based on content #TAUTHOR_TAG .', ', the indexing process remains firmly human-centered.']","['Additional metadata are associated with each MEDLINE citation.', 'The most important of these is the controlled vocabulary terms assigned by human indexers.', '', '', 'Since mid-2002 , the Library has been employing software that automatically suggests MeSH headings based on content #TAUTHOR_TAG .', 'Nevertheless, the indexing process remains firmly human-centered.']",0
"['', 'Previously , a user study #TAUTHOR_TAG has shown that people are reluctant to type full natural language questions , even after being told that they were using a questionanswering system and that typing complete questions would result in better performance .', '', '', '', '', '']","['', 'Previously , a user study #TAUTHOR_TAG has shown that people are reluctant to type full natural language questions , even after being told that they were using a questionanswering system and that typing complete questions would result in better performance .', '', '', '', '', '']","['', 'Previously , a user study #TAUTHOR_TAG has shown that people are reluctant to type full natural language questions , even after being told that they were using a questionanswering system and that typing complete questions would result in better performance .', '', '', '', '', '']","['', 'Previously , a user study #TAUTHOR_TAG has shown that people are reluctant to type full natural language questions , even after being told that they were using a questionanswering system and that typing complete questions would result in better performance .', '', '', '', '', '']",1
"['The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , #TAUTHOR_TAG , Rinaldi et al. 2004 ) , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .', '']","['The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , #TAUTHOR_TAG , Rinaldi et al. 2004 ) , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .', '']","['The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , #TAUTHOR_TAG , Rinaldi et al. 2004 ) , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .', '']","['The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , #TAUTHOR_TAG , Rinaldi et al. 2004 ) , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .', '']",0
"['', '', 'cod', ', software for utilizing this ontology already exists : MetaMap ( Aronson 2001 ) identifies concepts in free text , and SemRep #TAUTHOR_TAG extracts relations between the concepts .', 'Both systems utilize and propagate semantic information from UMLS knowledge sources: the Metathesaurus, the Semantic Network, and the SPECIALISTxicon.', '', '', '', '', '']","['', '', 'codified', ', software for utilizing this ontology already exists : MetaMap ( Aronson 2001 ) identifies concepts in free text , and SemRep #TAUTHOR_TAG extracts relations between the concepts .', 'Both systems utilize and propagate semantic information from UMLS knowledge sources: the Metathesaurus, the Semantic Network, and the SPECIALIST lexicon.', '', '', '', '', '']","['', '', '', ', software for utilizing this ontology already exists : MetaMap ( Aronson 2001 ) identifies concepts in free text , and SemRep #TAUTHOR_TAG extracts relations between the concepts .', 'Both systems utilize and propagate semantic information from UMLS knowledge sources: the Metathesaurus, the Semantic Network, and the SPECIALIST lexicon.', '', '', '', '', '']","['', '', '', 'Second , software for utilizing this ontology already exists : MetaMap ( Aronson 2001 ) identifies concepts in free text , and SemRep #TAUTHOR_TAG extracts relations between the concepts .', 'Both systems utilize and propagate semantic information from UMLS knowledge sources: the Metathesaurus, the Semantic Network, and the SPECIALIST lexicon.', '', '', '', '', '']",0
"['We attempted two approaches for assigning these weights. The first method rel ad hoc weight selection based on intuition.', 'The second involved a more principled method using confidence values generated by the base classifiers and least squares linear regression adapted for classification #TAUTHOR_TAG , which can be described by the following equation:']","['We attempted two approaches for assigning these weights. The first method relied ad hoc weight selection based on intuition.', 'The second involved a more principled method using confidence values generated by the base classifiers and least squares linear regression adapted for classification #TAUTHOR_TAG , which can be described by the following equation:']","['We attempted two approaches for assigning these weights. The first method rel ad hoc weight selection based on intuition.', 'The second involved a more principled method using confidence values generated by the base classifiers and least squares linear regression adapted for classification #TAUTHOR_TAG , which can be described by the following equation:']","['We attempted two approaches for assigning these weights. The first method relied on ad hoc weight selection based on intuition.', 'The second involved a more principled method using confidence values generated by the base classifiers and least squares linear regression adapted for classification #TAUTHOR_TAG , which can be described by the following equation:']",5
"['The feasibility of automatically identifying outcome statements in secondary sources has been demonstrated by #TAUTHOR_TAG .', 'Their study also illustrates the importance of semantic classes and relations.', 'However, extraction of outcome statements from secondary sources (meta-analyses, in this case) differs from extraction of outcomes from MEDLINE citations because secondary sources represent knowledge that has already been distilled by humans (which may limit its scope', '', '']","['The feasibility of automatically identifying outcome statements in secondary sources has been demonstrated by #TAUTHOR_TAG .', 'Their study also illustrates the importance of semantic classes and relations.', 'However, extraction of outcome statements from secondary sources (meta-analyses, in this case) differs from extraction of outcomes from MEDLINE citations because secondary sources represent knowledge that has already been distilled by humans (which may limit its scope).', '', '']","['The feasibility of automatically identifying outcome statements in secondary sources has been demonstrated by #TAUTHOR_TAG .', 'Their study also illustrates the importance of semantic classes and relations.', 'However, extraction of outcome statements from secondary sources (meta-analyses, in this case) differs from extraction of outcomes from MEDLINE citations because secondary sources represent knowledge that has already been distilled by humans (which may limit its scope', '', '']","['The feasibility of automatically identifying outcome statements in secondary sources has been demonstrated by #TAUTHOR_TAG .', 'Their study also illustrates the importance of semantic classes and relations.', 'However, extraction of outcome statements from secondary sources (meta-analyses, in this case) differs from extraction of outcomes from MEDLINE citations because secondary sources represent knowledge that has already been distilled by humans (which may limit its scope).', '', '']",1
"['', '', 'cod H', 'Second , software for utilizing this ontology already exists : MetaMap #TAUTHOR_TAG identifies concepts in free text , and SemRep ( Rindflesch and Fiszman 2003 ) extracts relations between the concepts .', 'Both systems utilize and propagate semantic information from UMLS knowledge sources: the Metathesaurus, the Semantic Network, and the SPECIALISTxicon.', '', '', '', '', '']","['', '', 'codified', 'Second , software for utilizing this ontology already exists : MetaMap #TAUTHOR_TAG identifies concepts in free text , and SemRep ( Rindflesch and Fiszman 2003 ) extracts relations between the concepts .', 'Both systems utilize and propagate semantic information from UMLS knowledge sources: the Metathesaurus, the Semantic Network, and the SPECIALIST lexicon.', '', '', '', '', '']","['', '', '', 'Second , software for utilizing this ontology already exists : MetaMap #TAUTHOR_TAG identifies concepts in free text , and SemRep ( Rindflesch and Fiszman 2003 ) extracts relations between the concepts .', 'Both systems utilize and propagate semantic information from UMLS knowledge sources: the Metathesaurus, the Semantic Network, and the SPECIALIST lexicon.', '', '', '', '', '']","['', '', '', 'Second , software for utilizing this ontology already exists : MetaMap #TAUTHOR_TAG identifies concepts in free text , and SemRep ( Rindflesch and Fiszman 2003 ) extracts relations between the concepts .', 'Both systems utilize and propagate semantic information from UMLS knowledge sources: the Metathesaurus, the Semantic Network, and the SPECIALIST lexicon.', '', '', '', '', '']",0
"['to not', 'Mend have studiedSH clinical tasks therapyosisology', 'cit', '', '', '', 'The work of #TAUTHOR_TAG demonstrates that faceted queries can be converted into simple filtering constraints to boost precision .']","['to not', 'have studied MeSH clinical tasks therapy,', 'citations', '', '', '', 'The work of #TAUTHOR_TAG demonstrates that faceted queries can be converted into simple filtering constraints to boost precision .']","['to is not', 'have studiedSH terms therapyology', 'cit', '', '', '', 'The work of #TAUTHOR_TAG demonstrates that faceted queries can be converted into simple filtering constraints to boost precision .']","['', '', '', '', '', '', 'The work of #TAUTHOR_TAG demonstrates that faceted queries can be converted into simple filtering constraints to boost precision .']",0
"['The extraction of each PICO element relies to a different extent on an annotated corpus of MEDLINE abstracts , created through an effort led by the first author at the National Library of Medicine #TAUTHOR_TAG .', 'is implemented as an ensemble of class trained using supervised machine learning', '', '', '', '', '', '', '', '']","['The extraction of each PICO element relies to a different extent on an annotated corpus of MEDLINE abstracts , created through an effort led by the first author at the National Library of Medicine #TAUTHOR_TAG .', 'is implemented as an ensemble of classifiers trained using supervised machine learning', '', '', '', '', '', '', '', '']","['The extraction of each PICO element relies to a different extent on an annotated corpus of MEDLINE abstracts , created through an effort led by the first author at the National Library of Medicine #TAUTHOR_TAG .', 'is implemented as an ensemble of class trained using supervised machine learning', '', '', '', '', '', '', '', '']","['The extraction of each PICO element relies to a different extent on an annotated corpus of MEDLINE abstracts , created through an effort led by the first author at the National Library of Medicine #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']",5
"['Gan , Ash , Wykoff 994 ; #TAUTHOR_TAG , 2005', '', '', '', '']","['Gorman , Ash , Wykoff 1994 ; #TAUTHOR_TAG , 2005', '', '', '', '']","['Gan , Ash , Wykoff 1994 ; #TAUTHOR_TAG , 2005', '', '', '', '']","['', '', '', '', '']",0
"['further have to first define what a answer should be.', 'We have empirically verified that an extractive approach based on outcome sentences is actually quite satisfactory, but our algorithm does not currently integrate evidence from multiple abstracts; although see #TAUTHOR_TAG and #AUTHOR_TAG', '', '']","['further have to first define what a answer should be.', 'We have empirically verified that an extractive approach based on outcome sentences is actually quite satisfactory, but our algorithm does not currently integrate evidence from multiple abstracts; although see #TAUTHOR_TAG and #AUTHOR_TAG', '', '']","['s further to first define what a good answer should be.', 'We have empirically verified that an extractive approach based on outcome sentences is actually quite satisfactory, but our algorithm does not currently integrate evidence from multiple abstracts; although see #TAUTHOR_TAG and #AUTHOR_TAG .', '', '']","['', 'We have empirically verified that an extractive approach based on outcome sentences is actually quite satisfactory, but our algorithm does not currently integrate evidence from multiple abstracts; although see #TAUTHOR_TAG and #AUTHOR_TAG .', '', '']",0
"['After much exploration , #TAUTHOR_TAG discovered that it was not practical to annotate PICO entities at the phrase level due to significant unresolvable disagreement and interannotator reliability issues .', 'Consider the following segment:']","['After much exploration , #TAUTHOR_TAG discovered that it was not practical to annotate PICO entities at the phrase level due to significant unresolvable disagreement and interannotator reliability issues .', 'Consider the following segment:']","['After much exploration , #TAUTHOR_TAG discovered that it was not practical to annotate PICO entities at the phrase level due to significant unresolvable disagreement and interannotator reliability issues .', 'Consider the following segment:']","['After much exploration , #TAUTHOR_TAG discovered that it was not practical to annotate PICO entities at the phrase level due to significant unresolvable disagreement and interannotator reliability issues .', 'Consider the following segment:']",0
"['', 'We first identified the most informative unigrams and bigrams using the information gain measure ( Yang and Pedersen 1997 ) , and then selected only the positive outcome predictors using odds ratio #TAUTHOR_TAG .', 'ases such as rhe', '', '']","['', 'We first identified the most informative unigrams and bigrams using the information gain measure ( Yang and Pedersen 1997 ) , and then selected only the positive outcome predictors using odds ratio #TAUTHOR_TAG .', 'such as', '', '']","['', 'We first identified the most informative unigrams and bigrams using the information gain measure ( Yang and Pedersen 1997 ) , and then selected only the positive outcome predictors using odds ratio #TAUTHOR_TAG .', 'ases such as rhe', '', '']","['', 'We first identified the most informative unigrams and bigrams using the information gain measure ( Yang and Pedersen 1997 ) , and then selected only the positive outcome predictors using odds ratio #TAUTHOR_TAG .', '', '', '']",5
"['', '', '', 'present more effectively the; for example #AUTHOR_TAG', 'multilevelleted lists , appropri integrated with interface elements for expanding and items , might provide physicians a better overview of the information landscape ; see , for example , #TAUTHOR_TAG .']","['', '', '', 'present more effectively the information; for example, #AUTHOR_TAG', 'multi-level bulleted lists , appropriately integrated with interface elements for expanding and items , might provide physicians a better overview of the information landscape ; see , for example , #TAUTHOR_TAG .']","['', '', '', 'present more effectively for example #AUTHOR_TAG .', 'multilevelleted lists , appropri integrated with interface elements for expanding and hiding items , might provide physicians a better overview of the information landscape ; see , for example , #TAUTHOR_TAG .']","['', '', '', '', 'Perhaps some variation of multi-level bulleted lists , appropriately integrated with interface elements for expanding and hiding items , might provide physicians a better overview of the information landscape ; see , for example , #TAUTHOR_TAG .']",3
"['the evaluation of answers to complex questions remains an open research problem.', 'are not agreed methodology comparisons results', '', 'Recently, there is a growing consensus that an evaluation methodology based on the notion of ""information nuggets"" may provide an appropriate framework for assessing the quality of answers to complex questions.', ""Nugget F-score has been employed as a metric in the TREC question-answering track since 2003 , to evaluate so-called definition and `` other '' questions #TAUTHOR_TAG ."", 'A of (eg., Hildet, Katz, 2004) have pointed out shortcom nug number these have been Dem', '']","['the evaluation of answers to complex questions remains an open research problem.', 'are not agreed methodology comparisons results', '', 'Recently, there is a growing consensus that an evaluation methodology based on the notion of ""information nuggets"" may provide an appropriate framework for assessing the quality of answers to complex questions.', ""Nugget F-score has been employed as a metric in the TREC question-answering track since 2003 , to evaluate so-called definition and `` other '' questions #TAUTHOR_TAG ."", 'A of (e.g., Hildebrandt, Katz, 2004) have pointed out shortcomings nugget number these have been', '']","['the evaluation of answers to complex questions remains an open research problem.', 'are not agreed a methodology meaningful comparisons results', '', 'Recently, there is a growing consensus that an evaluation methodology based on the notion of ""information nuggets"" may provide an appropriate framework for assessing the quality of answers to complex questions.', ""Nugget F-score has been employed as a metric in the TREC question-answering track since 2003 , to evaluate so-called definition and `` other '' questions #TAUTHOR_TAG ."", 'A number of (eg., Hildebrandt, Katz, Lin 2004) have pointed out shortcom a number these issues have been recently Dem', '']","['Finally, the evaluation of answers to complex questions remains an open research problem.', '', '', 'Recently, there is a growing consensus that an evaluation methodology based on the notion of ""information nuggets"" may provide an appropriate framework for assessing the quality of answers to complex questions.', ""Nugget F-score has been employed as a metric in the TREC question-answering track since 2003 , to evaluate so-called definition and `` other '' questions #TAUTHOR_TAG ."", '', '']",0
"['', '', '', '', 'In addition , there has been much work on the application of linguistic and semantic knowledge to information retrieval ; see #TAUTHOR_TAG a ) for a brief overview .']","['', '', '', '', 'In addition , there has been much work on the application of linguistic and semantic knowledge to information retrieval ; see #TAUTHOR_TAG a ) for a brief overview .']","['', '', '', '', 'In addition , there has been much work on the application of linguistic and semantic knowledge to information retrieval ; see #TAUTHOR_TAG a ) for a brief overview .']","['', '', '', '', 'In addition , there has been much work on the application of linguistic and semantic knowledge to information retrieval ; see #TAUTHOR_TAG a ) for a brief overview .']",0
"['the evaluation of answers to remains an open', '', '', 'method', '', 'A of studies ( e.g. , Hildebrandt , Katz , and Lin 2004 ) have pointed out shortcomings of the original nugget scoring model , although a number of these issues have been recently addressed #TAUTHOR_TAG a , 2006b ) .', 'ende']","['the evaluation of answers to remains an open', '', '', 'methodology', '', 'A of studies ( e.g. , Hildebrandt , Katz , and Lin 2004 ) have pointed out shortcomings of the original nugget scoring model , although a number of these issues have been recently addressed #TAUTHOR_TAG a , 2006b ) .', 'endeavor']","['the evaluation of answers to remains', '', '', '', '', 'A number of studies ( e.g. , Hildebrandt , Katz , and Lin 2004 ) have pointed out shortcomings of the original nugget scoring model , although a number of these issues have been recently addressed #TAUTHOR_TAG a , 2006b ) .', '']","['Finally, the evaluation of answers to complex questions remains an open research problem.', '', '', '', '', 'A number of studies ( e.g. , Hildebrandt , Katz , and Lin 2004 ) have pointed out shortcomings of the original nugget scoring model , although a number of these issues have been recently addressed #TAUTHOR_TAG a , 2006b ) .', '']",0
"['The potential highest level of the strength of evidence for a given citation can be identified using the Publication Type (a metadata field) and MeSH terms pertaining to the type of the clinical study.', 'Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy #TAUTHOR_TAG .']","['The potential highest level of the strength of evidence for a given citation can be identified using the Publication Type (a metadata field) and MeSH terms pertaining to the type of the clinical study.', 'Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy #TAUTHOR_TAG .']","['The potential highest level of the strength of evidence for a given citation can be identified using the Publication Type (a metadata field) and MeSH terms pertaining to the type of the clinical study.', 'Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy #TAUTHOR_TAG .']","['The potential highest level of the strength of evidence for a given citation can be identified using the Publication Type (a metadata field) and MeSH terms pertaining to the type of the clinical study.', 'Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy #TAUTHOR_TAG .']",5
"['', ""MEDLINE , the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine , provides the clinically relevant sources for answering physicians ' questions , and is commonly used in that capacity #TAUTHOR_TAG ; Groote and Dorsch 2003 ) ."", '', '', '']","['', ""MEDLINE , the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine , provides the clinically relevant sources for answering physicians ' questions , and is commonly used in that capacity #TAUTHOR_TAG ; Groote and Dorsch 2003 ) ."", '', '', '']","['', ""MEDLINE , the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine , provides the clinically relevant sources for answering physicians ' questions , and is commonly used in that capacity #TAUTHOR_TAG ; De Groote and Dorsch 2003 ) ."", '', '', '']","['', ""MEDLINE , the authoritative repository of abstracts from the medical and biomedical primary literature maintained by the National Library of Medicine , provides the clinically relevant sources for answering physicians ' questions , and is commonly used in that capacity #TAUTHOR_TAG ; De Groote and Dorsch 2003 ) ."", '', '', '']",0
"['', '', '-', 'For an overview of systems designed to answer open-domain factoid questions , the TREC QA track overview papers are a good place to start #TAUTHOR_TAG .', 'In addition, there has been much work on the application of linguistic and semantic knowledge to information retrieval; see Lin and Demner- #AUTHOR_TAG a) for a brief overview.']","['', '', '', 'For an overview of systems designed to answer open-domain factoid questions , the TREC QA track overview papers are a good place to start #TAUTHOR_TAG .', 'In addition, there has been much work on the application of linguistic and semantic knowledge to information retrieval; see Lin and Demner- #AUTHOR_TAG a) for a brief overview.']","['', '', '', 'For an overview of systems designed to answer open-domain factoid questions , the TREC QA track overview papers are a good place to start #TAUTHOR_TAG .', 'In addition, there has been much work on the application of linguistic and semantic knowledge to information retrieval; see Lin and Demner- #AUTHOR_TAG a) for a brief overview.']","['', '', '', 'For an overview of systems designed to answer open-domain factoid questions , the TREC QA track overview papers are a good place to start #TAUTHOR_TAG .', 'In addition, there has been much work on the application of linguistic and semantic knowledge to information retrieval; see Lin and Demner- #AUTHOR_TAG a) for a brief overview.']",0
"['', '', '', '', '', '', 'The Semantic Network a consistent categorization of all concepts represented in the UMLS Metathesaurus', 'Third the paradigm of evidence-based medicine #TAUTHOR_TAG provides a task-based model of the clinical information-seeking process .', 'The PRichardson. 95 well- queries that br the needsical', '']","['', '', '', '', '', '', 'The Semantic Network a consistent categorization of all concepts represented in the UMLS Metathesaurus.', 'Third the paradigm of evidence-based medicine #TAUTHOR_TAG provides a task-based model of the clinical information-seeking process .', 'The (Richardson al. well-formulated queries that bridges the needs analytical', '']","['', '', '', '', '', '', 'The Semantic Network a consistent categorization of all concepts represented in the UMLS Metathesaurus.', 'Third the paradigm of evidence-based medicine #TAUTHOR_TAG provides a task-based model of the clinical information-seeking process .', 'Richardson. 95 that br the needsical capabilities', '']","['', '', '', '', '', '', 'The Semantic Network provides a consistent categorization of all concepts represented in the UMLS Metathesaurus.', 'Third , the paradigm of evidence-based medicine #TAUTHOR_TAG provides a task-based model of the clinical information-seeking process .', '', '']",0
"['structured M cittakinglevant', '', 'As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems ( Voorhees and Tice 1999 ; #TAUTHOR_TAG .']","['structured citations (taking', '', 'As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems ( Voorhees and Tice 1999 ; #TAUTHOR_TAG .']","['structured representations Mtaking', '', 'As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems ( Voorhees and Tice 1999 ; #TAUTHOR_TAG .']","['', '', 'As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems ( Voorhees and Tice 1999 ; #TAUTHOR_TAG .']",1
"['citlevant', '', 'As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems #TAUTHOR_TAG ; Hirschman and Gaizauskas 2001 ) .']","['citations', '', 'As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems #TAUTHOR_TAG ; Hirschman and Gaizauskas 2001 ) .']","['', '', 'As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems #TAUTHOR_TAG ; Hirschman and Gaizauskas 2001 ) .']","['', '', 'As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems #TAUTHOR_TAG ; Hirschman and Gaizauskas 2001 ) .']",1
"['clinical', ""SH head of the human indexers' tasks assigning terms is mainsometimes a"", 'For this evaluation , we randomly selected 50 abstracts with disorders indexed as the main topic from abstracts retrieved using PubMed on the five clinical questions described in #TAUTHOR_TAG .']","['clinical', ""MeSH headings of the human indexers' tasks assigning terms is main (sometimes a"", 'For this evaluation , we randomly selected 50 abstracts with disorders indexed as the main topic from abstracts retrieved using PubMed on the five clinical questions described in #TAUTHOR_TAG .']","['', ""of the human indexers' tasks assigning terms issometimes"", 'For this evaluation , we randomly selected 50 abstracts with disorders indexed as the main topic from abstracts retrieved using PubMed on the five clinical questions described in #TAUTHOR_TAG .']","['', '', 'For this evaluation , we randomly selected 50 abstracts with disorders indexed as the main topic from abstracts retrieved using PubMed on the five clinical questions described in #TAUTHOR_TAG .']",5
"['The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , Jacquemart and Zweigenbaum 2003 , #TAUTHOR_TAG , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .', '']","['The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , Jacquemart and Zweigenbaum 2003 , #TAUTHOR_TAG , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .', '']","['The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , Jacquemart and Zweigenbaum 2003 , #TAUTHOR_TAG , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .', '']","['The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , Jacquemart and Zweigenbaum 2003 , #TAUTHOR_TAG , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .', '']",0
"['Our knowledge extractors rely extensively on MetaMap #TAUTHOR_TAG , a system for identifying segments of text that correspond to concepts in the UMLS Metathesaurus .', 'algorithmssergrantic types Semanticray Burg', '', '', '', '', '', '', '']","['Our knowledge extractors rely extensively on MetaMap #TAUTHOR_TAG , a system for identifying segments of text that correspond to concepts in the UMLS Metathesaurus .', 'algorithms semantic types Semantic', '', '', '', '', '', '', '']","['Our knowledge extractors rely extensively on MetaMap #TAUTHOR_TAG , a system for identifying segments of text that correspond to concepts in the UMLS Metathesaurus .', 'algorithms operatesergrained semantic types Semray', '', '', '', '', '', '', '']","['Our knowledge extractors rely extensively on MetaMap #TAUTHOR_TAG , a system for identifying segments of text that correspond to concepts in the UMLS Metathesaurus .', '', '', '', '', '', '', '', '']",5
"['The automatic extraction of PICO elements from MEDLINE citations represents a key capability integral to clinical question answering.', 'This section , which elaborates on preliminary results reported in #TAUTHOR_TAG , describes extraction algorithms for population , problems , interventions , outcomes , and the strength of evidence .', 'For an completely annotated, see Figure .', '']","['The automatic extraction of PICO elements from MEDLINE citations represents a key capability integral to clinical question answering.', 'This section , which elaborates on preliminary results reported in #TAUTHOR_TAG , describes extraction algorithms for population , problems , interventions , outcomes , and the strength of evidence .', 'For an completely annotated abstract, see Figure 2.', '']","['The automatic extraction of PICO elements from MEDLINE citations represents a key capability integral to clinical question answering.', 'This section , which elaborates on preliminary results reported in #TAUTHOR_TAG , describes extraction algorithms for population , problems , interventions , outcomes , and the strength of evidence .', 'For an example a completely annotated abstract, see Figure .', '']","['The automatic extraction of PICO elements from MEDLINE citations represents a key capability integral to clinical question answering.', 'This section , which elaborates on preliminary results reported in #TAUTHOR_TAG , describes extraction algorithms for population , problems , interventions , outcomes , and the strength of evidence .', 'For an example of a completely annotated abstract, see Figure 2.', '']",2
"['The function  maps a MeSH term to a positive score if the term is a positive indicator for that task a score if the term is a clinical task', 'Note that although our current system uses MeSH headings assigned by human indexers , manually assigned terms can be replaced with automatic processing if needed #TAUTHOR_TAG .']","['The function maps a MeSH term to a positive score if the term is a positive indicator for that task a score if the term is a clinical task.', 'Note that although our current system uses MeSH headings assigned by human indexers , manually assigned terms can be replaced with automatic processing if needed #TAUTHOR_TAG .']","['The function  maps a MeSH term to a positive score if the term is a positive indicator for a negative score if the term is the clinical task.', 'Note that although our current system uses MeSH headings assigned by human indexers , manually assigned terms can be replaced with automatic processing if needed #TAUTHOR_TAG .']","['The function α(t) maps a MeSH term to a positive score if the term is a positive indicator for that particular task type, or a negative score if the term is a negative indicator for the clinical task.', 'Note that although our current system uses MeSH headings assigned by human indexers , manually assigned terms can be replaced with automatic processing if needed #TAUTHOR_TAG .']",3
"['', '', '', '', '', '', '', '', 'The PICO framework #TAUTHOR_TAG for capturing well-formulated clinical queries ( described in Section2 ) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system .', '']","['', '', '', '', '', '', '', '', 'The PICO framework #TAUTHOR_TAG for capturing well-formulated clinical queries ( described in Section 2 ) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system .', '']","['', '', '', '', '', '', '', '', 'The PICO framework #TAUTHOR_TAG for capturing well-formulated clinical queries ( described in Section 2 ) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system .', '']","['', '', '', '', '', '', '', '', 'The PICO framework #TAUTHOR_TAG for capturing well-formulated clinical queries ( described in Section 2 ) can serve as the basis of a knowledge representation that bridges the needs of clinicians and analytical capabilities of a system .', '']",0
"['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al.2003 ; Preiss 2003 ; #TAUTHOR_TAG ; Miyao and Tsujii 2004 ) .', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al. 2003 ; Preiss 2003 ; #TAUTHOR_TAG ; Miyao and Tsujii 2004 ) .', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al.2003 ; Preiss 2003 ; #TAUTHOR_TAG ; Miyao and Tsujii 2004 ) .', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al. 2003 ; Preiss 2003 ; #TAUTHOR_TAG ; Miyao and Tsujii 2004 ) .', '']",4
"['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; #TAUTHOR_TAG ; Preiss 2003 ; Kaplan et al.004 ; M4', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; #TAUTHOR_TAG ; Preiss 2003 ; Kaplan et al. 2004 ;', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; #TAUTHOR_TAG ; Preiss 2003 ; Kaplan et al.004 ; M', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; #TAUTHOR_TAG ; Preiss 2003 ; Kaplan et al. 2004 ; Miyao and Tsujii 2004 ) .', '']",4
"['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al.2003 ; #TAUTHOR_TAG ; Kaplan et al.2004 ; M and 4', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al. 2003 ; #TAUTHOR_TAG ; Kaplan et al. 2004 ; and', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al.2003 ; #TAUTHOR_TAG ; Kaplan et al.2004 ; M and', '']","['Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al. 2003 ; #TAUTHOR_TAG ; Kaplan et al. 2004 ; Miyao and Tsujii 2004 ) .', '']",4
"['graph dependencies-one is that the computational of training the model and searching for the most likely labeling given the tree can be prohibitive, and', '', 'efficiency adopt re-ranking algorithms', '', 'Our re-ranking approach , like the approach to parse re-ranking of #TAUTHOR_TAG , employs a simpler model -- a local semantic role labeling algorithm -- as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes .', '']","['graphical dependencies dangers-one is that the computational of training the model and searching for the most likely labeling given the tree can be prohibitive, and', '', 'efficiency adopt re-ranking algorithms.', '', 'Our re-ranking approach , like the approach to parse re-ranking of #TAUTHOR_TAG , employs a simpler model -- a local semantic role labeling algorithm -- as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes .', '']","['many dependencies is that the computational complexity of training the model and searching for the most likely labeling given the tree can be prohibitive, and', '', 'we adopt re-ranking algorithms.', '', 'Our re-ranking approach , like the approach to parse re-ranking of #TAUTHOR_TAG , employs a simpler model -- a local semantic role labeling algorithm -- as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes .', '']","['', '', '', '', 'Our re-ranking approach , like the approach to parse re-ranking of #TAUTHOR_TAG , employs a simpler model -- a local semantic role labeling algorithm -- as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes .', '']",1
"['', '', '', '', 'classes due strong independence assumptions', 'in order to be able to incorporate long-range dependencies in our models , we chose to adopt a re-ranking approach #TAUTHOR_TAG , which selects from likely assignments generated by a model which makes stronger independence assumptions .', 'We utilize the top n of local semantic role label S to', 'our re-ranking approach does not present a serious bottleneck to performance', '= ', '', '', '']","['', '', '', '', 'classes due strong independence assumptions.', 'in order to be able to incorporate long-range dependencies in our models , we chose to adopt a re-ranking approach #TAUTHOR_TAG , which selects from likely assignments generated by a model which makes stronger independence assumptions .', 'We utilize the top n of local semantic role labeling SRL to', 'our re-ranking approach does not present a serious bottleneck to performance.', '=', '', '', '']","['', '', '', '', 'classes due strong independence assumptions.', 'in order to be able to incorporate long-range dependencies in our models , we chose to adopt a re-ranking approach #TAUTHOR_TAG , which selects from likely assignments generated by a model which makes stronger independence assumptions .', 'We utilize the top n assignments of local semantic role labeling to', 'our re-ranking approach does not present a serious bottleneck to performance', '= ', '', '', '']","['', '', '', '', '', 'Therefore , in order to be able to incorporate long-range dependencies in our models , we chose to adopt a re-ranking approach #TAUTHOR_TAG , which selects from likely assignments generated by a model which makes stronger independence assumptions .', 'We utilize the top n assignments of our local semantic role labeling model P SRL to generate likely assignments.', '', '', '', '', '']",5
"['Following our previous work #TAUTHOR_TAG ; Althaus , Karamanis , and Koller 2004 ) , the to information an un of represented lists', '', '', '', '', '', '', '', '']","['Following our previous work #TAUTHOR_TAG ; Althaus , Karamanis , and Koller 2004 ) , the to information an unordered of represented lists', '', '', '', '', '', '', '', '']","['Following our previous work #TAUTHOR_TAG ; Althaus , Karamanis , and Koller 2004 ) , the input to information ordering an unordered set of represented', '', '', '', '', '', '', '', '']","['Following our previous work #TAUTHOR_TAG ; Althaus , Karamanis , and Koller 2004 ) , the input to information ordering is an unordered set of informationbearing items represented as CF lists .', '', '', '', '', '', '', '', '']",2
"['Specifically , we examine the strength of association between the verb and the noun constituent of a combination ( the target expression or its lexical variants ) as an indirect cue to its idiomaticity , an approach inspired by #TAUTHOR_TAG .', 'We use the words to', '', '']","['Specifically , we examine the strength of association between the verb and the noun constituent of a combination ( the target expression or its lexical variants ) as an indirect cue to its idiomaticity , an approach inspired by #TAUTHOR_TAG .', 'We use the words to', '', '']","['Specifically , we examine the strength of association between the verb and the noun constituent of a combination ( the target expression or its lexical variants ) as an indirect cue to its idiomaticity , an approach inspired by #TAUTHOR_TAG .', 'We use the words to', '', '']","['Specifically , we examine the strength of association between the verb and the noun constituent of a combination ( the target expression or its lexical variants ) as an indirect cue to its idiomaticity , an approach inspired by #TAUTHOR_TAG .', '', '', '']",4
"['a classification method to predict clusters from the values of the.', 'We posit that this would not have a significant effect on the results , in particular for MML-based classification techniques , such as Decision Graphs #TAUTHOR_TAG .']","['a classification method to predict clusters from the values of the cases.', 'We posit that this would not have a significant effect on the results , in particular for MML-based classification techniques , such as Decision Graphs #TAUTHOR_TAG .']","['a classification method to predict clusters from the values of', 'We posit that this would not have a significant effect on the results , in particular for MML-based classification techniques , such as Decision Graphs #TAUTHOR_TAG .']","['', 'We posit that this would not have a significant effect on the results , in particular for MML-based classification techniques , such as Decision Graphs #TAUTHOR_TAG .']",0
"['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms, such as expert systems (Barr and Tessler 1995) and case-based reasoning (Watson 1997).', 'Such technologies require significant human input , and are difficult to create and maintain #TAUTHOR_TAG .', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms, such as expert systems (Barr and Tessler 1995) and case-based reasoning (Watson 1997).', 'Such technologies require significant human input , and are difficult to create and maintain #TAUTHOR_TAG .', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms, such as expert systems (Barr and Tessler 1995) and case-based reasoning (Watson 1997).', 'Such technologies require significant human input , and are difficult to create and maintain #TAUTHOR_TAG .', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms, such as expert systems (Barr and Tessler 1995) and case-based reasoning (Watson 1997).', 'Such technologies require significant human input , and are difficult to create and maintain #TAUTHOR_TAG .', '', '']",0
"['â\x80¢ Only an automatic evaluation was performed , which relied on having model responses ( Berger and Mittal 2000 ; #TAUTHOR_TAG .']","['â\x80¢ Only an automatic evaluation was performed , which relied on having model responses ( Berger and Mittal 2000 ; #TAUTHOR_TAG .']","['â\x80¢ Only an automatic evaluation was performed , which relied on having model responses ( Berger and Mittal 2000 ; #TAUTHOR_TAG .']","['â\x80¢ Only an automatic evaluation was performed , which relied on having model responses ( Berger and Mittal 2000 ; #TAUTHOR_TAG .']",1
"['As stated herein, we studied two document-based methods: Document Retrieval and Document Prediction.', '(Doc-Ret).', 'This method follows a traditional Information Retrieval paradigm #TAUTHOR_TAG , where a query is represented by the content terms it contains , and the system retrieves from the corpus a set of documents that best match this query .', '']","['As stated herein, we studied two document-based methods: Document Retrieval and Document Prediction.', '(Doc-Ret).', 'This method follows a traditional Information Retrieval paradigm #TAUTHOR_TAG , where a query is represented by the content terms it contains , and the system retrieves from the corpus a set of documents that best match this query .', '']","['As stated herein, we studied two document-based methods: Document Retrieval and Document Prediction.', '(Doc-Ret).', 'This method follows a traditional Information Retrieval paradigm #TAUTHOR_TAG , where a query is represented by the content terms it contains , and the system retrieves from the corpus a set of documents that best match this query .', '']","['As stated herein, we studied two document-based methods: Document Retrieval and Document Prediction.', '(Doc-Ret).', 'This method follows a traditional Information Retrieval paradigm #TAUTHOR_TAG , where a query is represented by the content terms it contains , and the system retrieves from the corpus a set of documents that best match this query .', '']",5
"['', '', '', '', '', '', 'For the cases where retrieval took place , we used F-score ( van Rijsbergen 1979 ; #TAUTHOR_TAG to determine the similarity between the response from the top-ranked document and the real response ( the formulas for F-score and its contributing factors , recall and precision , appear in Section 4.2', '', '', '', '']","['', '', '', '', '', '', 'For the cases where retrieval took place , we used F-score ( van Rijsbergen 1979 ; #TAUTHOR_TAG to determine the similarity between the response from the top-ranked document and the real response ( the formulas for F-score and its contributing factors , recall and precision , appear in Section 4.2', '', '', '', '']","['', '', '', '', '', '', 'For the cases where retrieval took place , we used F-score ( van Rijsbergen 1979 ; #TAUTHOR_TAG to determine the similarity between the response from the top-ranked document and the real response ( the formulas for F-score and its contributing factors , recall and precision , appear in Section 4.2', '', '', '', '']","['', '', '', '', '', '', 'For the cases where retrieval took place , we used F-score ( van Rijsbergen 1979 ; #TAUTHOR_TAG to determine the similarity between the response from the top-ranked document and the real response ( the formulas for F-score and its contributing factors , recall and precision , appear in Section 4.2 ) .', '', '', '', '']",5
"['The example in Figure 1(b) illustrates a situation where specific words in the request (docking station and install) are also mentioned in the response.', 'This situation suggests a response-automation approach that follows the document retrieval paradigm #TAUTHOR_TAG , where a new request is matched with existing response documents ( e-mails ) .', 'specific words in the do match a, and sometimes do not match a as the examples in Figures 1(a) and 1(c),.']","['The example in Figure 1(b) illustrates a situation where specific words in the request (docking station and install) are also mentioned in the response.', 'This situation suggests a response-automation approach that follows the document retrieval paradigm #TAUTHOR_TAG , where a new request is matched with existing response documents ( e-mails ) .', 'specific words in the do match a well, and sometimes do not match a as the examples in Figures 1(a) and 1(c), respectively.']","['The example in Figure 1(b) illustrates a situation where specific words in the request (docking station and install) are also mentioned in the response.', 'This situation suggests a response-automation approach that follows the document retrieval paradigm #TAUTHOR_TAG , where a new request is matched with existing response documents ( e-mails ) .', 'specific words in the request match a response well, and sometimes do not match a response as the examples in Figures 1(a) and 1(c), respectively.']","['The example in Figure 1(b) illustrates a situation where specific words in the request (docking station and install) are also mentioned in the response.', 'This situation suggests a response-automation approach that follows the document retrieval paradigm #TAUTHOR_TAG , where a new request is matched with existing response documents ( e-mails ) .', 'However, specific words in the request do not always match a response well, and sometimes do not match a response at all, as demonstrated by the examples in Figures 1(a) and 1(c), respectively.']",0
"['even the automation of responses to the ""easy"" problems is a difficult task.', 'Although such inquiries revolve around a relatively small set of issues, specific circumstances can make each inquiry unique and hence care must be taken to compose a response that does not confuse, irritate, or mislead the.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven #TAUTHOR_TAG ; Watson 1997 ; Delic and Lahaix 1998 ) .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['even the automation of responses to the ""easy"" problems is a difficult task.', 'Although such inquiries revolve around a relatively small set of issues, specific circumstances can make each inquiry unique, and hence care must be taken to compose a response that does not confuse, irritate, or mislead the customer.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven #TAUTHOR_TAG ; Watson 1997 ; Delic and Lahaix 1998 ) .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['even the automation of responses to the ""easy"" problems is a difficult task.', 'Although such inquiries revolve around a relatively small set of issues, specific circumstances can make each inquiry unique, and hence care must be taken to compose a response that does not confuse, irritate, or mislead the customer.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven #TAUTHOR_TAG ; Watson 1997 ; Delic and Lahaix 1998 ) .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['However, even the automation of responses to the ""easy"" problems is a difficult task.', 'Although such inquiries revolve around a relatively small set of issues, specific circumstances can make each inquiry unique, and hence care must be taken to compose a response that does not confuse, irritate, or mislead the customer.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven #TAUTHOR_TAG ; Watson 1997 ; Delic and Lahaix 1998 ) .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']",0
"['of (ations (  and ', 'We then use the program Snob ( Wallace and Boulton 1968 ; #TAUTHOR_TAG to cluster these experiences .', 'Figure 8(a)ids clusters produced Snob into three most Pr Analysis (', 'project', '']","['of (Equations ( and', 'We then use the program Snob ( Wallace and Boulton 1968 ; #TAUTHOR_TAG to cluster these experiences .', 'Figure 8(a) centroids clusters produced Snob into three most Principal Analysis', '', '']","['of (ations (  and ', 'We then use the program Snob ( Wallace and Boulton 1968 ; #TAUTHOR_TAG to cluster these experiences .', 'Figure 8(a) the clusters produced Snob into three most Pr (', 'project', '']","['', 'We then use the program Snob ( Wallace and Boulton 1968 ; #TAUTHOR_TAG to cluster these experiences .', '', '', '']",5
"['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems #TAUTHOR_TAG and case-based reasoning ( Watson 1997 ) .', 'Such require significant human difficult to create and maintainDel', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems #TAUTHOR_TAG and case-based reasoning ( Watson 1997 ) .', 'Such require significant human difficult to create and maintain', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems #TAUTHOR_TAG and case-based reasoning ( Watson 1997 ) .', 'Such technologies require significant human input, difficult to create and maintainDel', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems #TAUTHOR_TAG and case-based reasoning ( Watson 1997 ) .', '', '', '']",1
"['is Function kernel', 'trainedas as', 'binary bag--lemed results.', 'We employed the LIBSVM package #TAUTHOR_TAG .', 'the SVMs predict zero or more SCs for each, as shown in Figure 3.', 'following steps']","['Basis Function kernel', 'trained as', 'binary bag-of-lemmas yielded results.', 'We employed the LIBSVM package #TAUTHOR_TAG .', 'the SVMs predict zero or more SCs for each request, as shown in Figure 3.', 'following steps.']","['', 'is trained as', 'the simple binary bag-of-lemmas representationed similar results.', 'We employed the LIBSVM package #TAUTHOR_TAG .', 'the SVMs predict zero or more SCs for each request, as shown in Figure 3.', 'the following steps.']","['', '', '', '7 We employed the LIBSVM package #TAUTHOR_TAG .', 'prediction stage, the SVMs predict zero or more SCs for each request, as shown in Figure 3.', '']",5
"['', 'our case , the clustering is performed by the program Snob , which implements mixture modeling combined with model selection based on the Minimum Message Length ( MML ) criterion ( Wallace and Boulton 1968 ; #TAUTHOR_TAG .', 'We this the in and aabilistic for its', '', '', '', '', '', '', 'Table']","['', 'our case , the clustering is performed by the program Snob , which implements mixture modeling combined with model selection based on the Minimum Message Length ( MML ) criterion ( Wallace and Boulton 1968 ; #TAUTHOR_TAG .', 'We this the in and a probabilistic for its', '', '', '', '', '', '', '(Table']","['', 'our case , the clustering is performed by the program Snob , which implements mixture modeling combined with model selection based on the Minimum Message Length ( MML ) criterion ( Wallace and Boulton 1968 ; #TAUTHOR_TAG .', 'We chose this program the number in and a probabilistic interpretation for its', '', '', '', '', '', '', 'Table']","['', 'In our case , the clustering is performed by the program Snob , which implements mixture modeling combined with model selection based on the Minimum Message Length ( MML ) criterion ( Wallace and Boulton 1968 ; #TAUTHOR_TAG .', '', '', '', '', '', '', '', '']",5
"['We use two measures from Information Retrieval to determine the quality of an automatically generated response : precision and F-score ( van Rijsbergen 1979 ; #TAUTHOR_TAG .', 'Prec measures how much of the information in an automatically generated response is correct (i.e., appears in the model response), and F-score measures the overallity between the automatically generated response and the model response.', 'harm precision', '', '', '']","['We use two measures from Information Retrieval to determine the quality of an automatically generated response : precision and F-score ( van Rijsbergen 1979 ; #TAUTHOR_TAG .', 'Precision measures how much of the information in an automatically generated response is correct (i.e., appears in the model response), and F-score measures the overall similarity between the automatically generated response and the model response.', 'harmonic precision', '', '', '']","['We use two measures from Information Retrieval to determine the quality of an automatically generated response : precision and F-score ( van Rijsbergen 1979 ; #TAUTHOR_TAG .', 'Prec measures how much of the information in an automatically generated response is correct (i.e., appears in the model response), and F-score measures the overall similarity between the automatically generated response and the model response.', 'precision', '', '', '']","['We use two measures from Information Retrieval to determine the quality of an automatically generated response : precision and F-score ( van Rijsbergen 1979 ; #TAUTHOR_TAG .', 'Precision measures how much of the information in an automatically generated response is correct (i.e., appears in the model response), and F-score measures the overall similarity between the automatically generated response and the model response.', '', '', '', '']",5
"['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems ( Barr and Tessler 1995 ) and case-based reasoning #TAUTHOR_TAG .', 'Such technologies require significant human input, and are difficult to create and maintain (Delic and Lahaix 199).', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems ( Barr and Tessler 1995 ) and case-based reasoning #TAUTHOR_TAG .', 'Such technologies require significant human input, and are difficult to create and maintain (Delic and Lahaix 1998).', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems ( Barr and Tessler 1995 ) and case-based reasoning #TAUTHOR_TAG .', 'Such technologies require significant human input, and are difficult to create and maintain (Delic and Lahaix 1998).', '', '']","['The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems ( Barr and Tessler 1995 ) and case-based reasoning #TAUTHOR_TAG .', 'Such technologies require significant human input, and are difficult to create and maintain (Delic and Lahaix 1998).', '', '']",1
"['', '', '', '', '', '', '', '', '', '', '', '', '', '.', ' #TAUTHOR_TAG investigated three approaches to the automatic generation of response e-mails : text classification , case-based reasoning , and question answering .', 'Text classification was used to group request e-mails']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'templates.', ' #TAUTHOR_TAG investigated three approaches to the automatic generation of response e-mails : text classification , case-based reasoning , and question answering .', 'Text classification was used to group request e-mails']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG investigated three approaches to the automatic generation of response e-mails : text classification , case-based reasoning , and question answering .', 'Text classification was used to group request e-mails']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG investigated three approaches to the automatic generation of response e-mails : text classification , case-based reasoning , and question answering .', 'Text classification was used to group request e-mails']",1
"['5 Significant bigrams are obtained using the n-gram statistics package NSP #TAUTHOR_TAG , which offers statistical tests to decide whether to accept or reject the null hypothesis regarding a bigram ( that it is not a collocation ) .']","['5 Significant bigrams are obtained using the n-gram statistics package NSP #TAUTHOR_TAG , which offers statistical tests to decide whether to accept or reject the null hypothesis regarding a bigram ( that it is not a collocation ) .']","['5 Significant bigrams are obtained using the n-gram statistics package NSP #TAUTHOR_TAG , which offers statistical tests to decide whether to accept or reject the null hypothesis regarding a bigram ( that it is not a collocation ) .']","['5 Significant bigrams are obtained using the n-gram statistics package NSP #TAUTHOR_TAG , which offers statistical tests to decide whether to accept or reject the null hypothesis regarding a bigram ( that it is not a collocation ) .']",5
"['In recent times, such knowledge-intensive approaches to content delivery have been largely superseded by data-intensive, statistical approaches.', '', '', 'been little on corpus-based approaches to help-desk response automation ( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; #TAUTHOR_TAG ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .', 'de of corpor-help-', '', '', '', '', '']","['In recent times, such knowledge-intensive approaches to content delivery have been largely superseded by data-intensive, statistical approaches.', '', '', 'been little on corpus-based approaches to help-desk response automation ( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; #TAUTHOR_TAG ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .', 'dearth of corpora-help-desk', '', '', '', '', '']","['In recent times, such knowledge-intensive approaches to content delivery have been largely superseded by data-intensive, statistical approaches.', '', '', 'has been little work on corpus-based approaches to help-desk response automation ( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; #TAUTHOR_TAG ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .', 'of corpor-help-', '', '', '', '', '']","['In recent times, such knowledge-intensive approaches to content delivery have been largely superseded by data-intensive, statistical approaches.', '', '', 'Despite this , to date , there has been little work on corpus-based approaches to help-desk response automation ( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; #TAUTHOR_TAG ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '']",0
"['Two applications that, like help-desk, deal with question�answer pairs are: sum- marization of e-mail threads (Dalli, Xia, and Wilks 2004; Shrestha and McKeown 2004), and answer extraction in FAQs (Frequently Asked Questions) (Berger and Mittal 2000; Berger et al. 2000; Jijkoun and de Rijke 2005; #TAUTHOR_TAG .', '', '', '']","['Two applications that, like help-desk, deal with question�answer pairs are: sum- marization of e-mail threads (Dalli, Xia, and Wilks 2004; Shrestha and McKeown 2004), and answer extraction in FAQs (Frequently Asked Questions) (Berger and Mittal 2000; Berger et al. 2000; Jijkoun and de Rijke 2005; #TAUTHOR_TAG .', '', '', '']","['Two applications that, like help-desk, deal with question�answer pairs are: sum- marization of e-mail threads (Dalli, Xia, and Wilks 2004; Shrestha and McKeown 2004), and answer extraction in FAQs (Frequently Asked Questions) (Berger and Mittal 2000; Berger et al. 2000; Jijkoun and de Rijke 2005; #TAUTHOR_TAG .', '', '', '']","['Two applications that, like help-desk, deal with question�answer pairs are: sum- marization of e-mail threads (Dalli, Xia, and Wilks 2004; Shrestha and McKeown 2004), and answer extraction in FAQs (Frequently Asked Questions) (Berger and Mittal 2000; Berger et al. 2000; Jijkoun and de Rijke 2005; #TAUTHOR_TAG .', '', '', '']",1
['â\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) #TAUTHOR_TAG ; Roy and Subramaniam 2006 ) .'],['â\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) #TAUTHOR_TAG ; Roy and Subramaniam 2006 ) .'],['â\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) #TAUTHOR_TAG ; Roy and Subramaniam 2006 ) .'],['â\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) #TAUTHOR_TAG ; Roy and Subramaniam 2006 ) .'],1
"['', '', '', ""we tried to ensure that the sets of cases shown to the judges were of quality, so that the judges' assessments would be."", 'Because the judges do not evaluate the same cases , we could not employ standard inter-annotator agreement measures #TAUTHOR_TAG .', '']","['', '', '', ""we tried to ensure that the sets of cases shown to the judges were of quality, so that the judges' assessments would be comparable."", 'Because the judges do not evaluate the same cases , we could not employ standard inter-annotator agreement measures #TAUTHOR_TAG .', '']","['', '', '', ""we tried to ensure that the sets of cases shown to the judges were of similar quality, so that the judges' assessments would be."", 'Because the judges do not evaluate the same cases , we could not employ standard inter-annotator agreement measures #TAUTHOR_TAG .', '']","['', '', '', ""In addition, we tried to ensure that the sets of cases shown to the judges were of similar quality, so that the judges' assessments would be comparable."", 'Because the judges do not evaluate the same cases , we could not employ standard inter-annotator agreement measures #TAUTHOR_TAG .', '']",5
"['are be a requests only or match portions of', '', '', '', 'In our work , we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization #TAUTHOR_TAG ; Barzilay , Elhadad , and McKeown 2001 ; Barzilay and McKeown 2005 ) .']","['are be a requests only or match portions of', '', '', '', 'In our work , we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization #TAUTHOR_TAG ; Barzilay , Elhadad , and McKeown 2001 ; Barzilay and McKeown 2005 ) .']","['are be addressed requests only or match portions of', '', '', '', 'In our work , we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization #TAUTHOR_TAG ; Barzilay , Elhadad , and McKeown 2001 ; Barzilay and McKeown 2005 ) .']","['', '', '', '', 'In our work , we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization #TAUTHOR_TAG ; Barzilay , Elhadad , and McKeown 2001 ; Barzilay and McKeown 2005 ) .']",0
"['A common way to combine different models consists of selecting the model that is most confident regarding its decision #TAUTHOR_TAG .', '', 'selecting method', '', '', '']","['A common way to combine different models consists of selecting the model that is most confident regarding its decision #TAUTHOR_TAG .', '', 'selecting method,', '', '', '']","['A common way to combine different models consists of selecting the model that is most confident regarding its decision #TAUTHOR_TAG .', '', 'selecting', '', '', '']","['A common way to combine different models consists of selecting the model that is most confident regarding its decision #TAUTHOR_TAG .', '', '', '', '', '']",1
"['Two applications that, like help-desk, deal with question-answer pairs are: summarization of e-mail threads (Dalli, Xia, and Wilks 2004;Shrestha and McKeown 2004), and answer extraction in FAQs (Frequently Asked Questions) #TAUTHOR_TAG ; Soricut and Brill 2006).', '', '', '']","['Two applications that, like help-desk, deal with question-answer pairs are: summarization of e-mail threads (Dalli, Xia, and Wilks 2004;Shrestha and McKeown 2004), and answer extraction in FAQs (Frequently Asked Questions) #TAUTHOR_TAG ; Soricut and Brill 2006).', '', '', '']","['Two applications that, like help-desk, deal with question-answer pairs are: summarization of e-mail threads (Dalli, Xia, and Wilks 2004;Shrestha and McKeown 2004), and answer extraction in FAQs (Frequently Asked Questions) #TAUTHOR_TAG ; Soricut and Brill 2006).', '', '', '']","['Two applications that, like help-desk, deal with question-answer pairs are: summarization of e-mail threads (Dalli, Xia, and Wilks 2004;Shrestha and McKeown 2004), and answer extraction in FAQs (Frequently Asked Questions) #TAUTHOR_TAG ; Soricut and Brill 2006).', '', '', '']",1
"['â\x80¢ A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours ( Feng et al. 2006 ; #TAUTHOR_TAG .', 'The representativeness of the sample size was not discussed in any of these studies.']","['â\x80¢ A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours ( Feng et al. 2006 ; #TAUTHOR_TAG .', 'The representativeness of the sample size was not discussed in any of these studies.']","['â\x80¢ A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours ( Feng et al. 2006 ; #TAUTHOR_TAG .', 'The representativeness of the sample size was not discussed in any of these studies.']","['â\x80¢ A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours ( Feng et al. 2006 ; #TAUTHOR_TAG .', 'The representativeness of the sample size was not discussed in any of these studies.']",1
"[' #AUTHOR_TAG a) we identified several systems that resemble ours in that they provide answers to queries.', 'These systems addressed the evaluation issue as follows.', 'â\x80¢ Only an automatic evaluation was performed , which relied on having model responses #TAUTHOR_TAG ; Berger et al. 2000 ) .']","[' #AUTHOR_TAG a) we identified several systems that resemble ours in that they provide answers to queries.', 'These systems addressed the evaluation issue as follows.', 'â\x80¢ Only an automatic evaluation was performed , which relied on having model responses #TAUTHOR_TAG ; Berger et al. 2000 ) .']","[' #AUTHOR_TAG a) we identified several systems that resemble ours in that they provide answers to queries.', 'These systems addressed the evaluation issue as follows.', 'â\x80¢ Only an automatic evaluation was performed , which relied on having model responses #TAUTHOR_TAG ; Berger et al. 2000 ) .']","[' #AUTHOR_TAG a) we identified several systems that resemble ours in that they provide answers to queries.', 'These systems addressed the evaluation issue as follows.', 'â\x80¢ Only an automatic evaluation was performed , which relied on having model responses #TAUTHOR_TAG ; Berger et al. 2000 ) .']",1
"['In #TAUTHOR_TAG a ) we identified several systems that resemble ours in that they provide answers to queries .', 'These systems addressed the evaluation issue as follows.', 'r Only an automatic evaluation was performed, which relied on having model responses .']","['In #TAUTHOR_TAG a ) we identified several systems that resemble ours in that they provide answers to queries .', 'These systems addressed the evaluation issue as follows.', 'r Only an automatic evaluation was performed, which relied on having model responses .']","['In #TAUTHOR_TAG a ) we identified several systems that resemble ours in that they provide answers to queries .', 'These systems addressed the evaluation issue as follows.', 'r Only an automatic evaluation was performed, which relied on having model responses .']","['In #TAUTHOR_TAG a ) we identified several systems that resemble ours in that they provide answers to queries .', 'These systems addressed the evaluation issue as follows.', 'r Only an automatic evaluation was performed, which relied on having model responses .']",0
"['clusters basis', 'In our case , the clustering is performed by the program Snob , which implements mixture modeling combined with model selection based on the Minimum Message Length ( MML ) criterion #TAUTHOR_TAG ; Wallace 2005 ) .', '', '', '', '', '', '', '', 'Table']","['clusters, basis', 'In our case , the clustering is performed by the program Snob , which implements mixture modeling combined with model selection based on the Minimum Message Length ( MML ) criterion #TAUTHOR_TAG ; Wallace 2005 ) .', '', '', '', '', '', '', '', '(Table']","['clusters the basis', 'In our case , the clustering is performed by the program Snob , which implements mixture modeling combined with model selection based on the Minimum Message Length ( MML ) criterion #TAUTHOR_TAG ; Wallace 2005 ) .', '', '', '', '', '', '', '', 'Table']","['', 'In our case , the clustering is performed by the program Snob , which implements mixture modeling combined with model selection based on the Minimum Message Length ( MML ) criterion #TAUTHOR_TAG ; Wallace 2005 ) .', '', '', '', '', '', '', '', '']",5
"['In FAQs , #TAUTHOR_TAG employed a sentence retrieval approach based on a language model where the entire response to an FAQ is considered a sentence , and the questions and answers are embedded in an FAQ document .', 'They complemented this approach with machine learning techniques that automatically learn the weights of different retrieval models.', 'compared two retrieval approaches (TF.IDF and query expansion) and two predictive approaches (statistical translation and latent variable models).', 'Jijk', '', 'the.']","['In FAQs , #TAUTHOR_TAG employed a sentence retrieval approach based on a language model where the entire response to an FAQ is considered a sentence , and the questions and answers are embedded in an FAQ document .', 'They complemented this approach with machine learning techniques that automatically learn the weights of different retrieval models.', 'compared two retrieval approaches (TF.IDF and query expansion) and two predictive approaches (statistical translation and latent variable models).', 'Jijkoun', '', 'the following.']","['In FAQs , #TAUTHOR_TAG employed a sentence retrieval approach based on a language model where the entire response to an FAQ is considered a sentence , and the questions and answers are embedded in an FAQ document .', 'They complemented this approach with machine learning techniques that automatically learn the weights of different retrieval models.', 'compared two retrieval approaches (TF.IDF and query expansion) and two predictive approaches (statistical translation and latent variable models).', 'Jijk', '', 'the following.']","['In FAQs , #TAUTHOR_TAG employed a sentence retrieval approach based on a language model where the entire response to an FAQ is considered a sentence , and the questions and answers are embedded in an FAQ document .', 'They complemented this approach with machine learning techniques that automatically learn the weights of different retrieval models.', 'compared two retrieval approaches (TF.IDF and query expansion) and two predictive approaches (statistical translation and latent variable models).', '', '', '']",0
"['â\x80¢ A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours #TAUTHOR_TAG ; Leuski et al. 2006 )', 'The representat of the sample size was not discussed in any of these studies.']","['â\x80¢ A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours #TAUTHOR_TAG ; Leuski et al. 2006 )', 'The representativeness of the sample size was not discussed in any of these studies.']","['â\x80¢ A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours #TAUTHOR_TAG ; Leuski et al. 2006 )', 'The representativeness of the sample size was not discussed in any of these studies.']","['â\x80¢ A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours #TAUTHOR_TAG ; Leuski et al. 2006 ) .', 'The representativeness of the sample size was not discussed in any of these studies.']",1
"['In recent times, such knowledge-intensive approaches to content delivery have been largely superseded by data-intensive, statistical approaches.', '', '', '( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; #TAUTHOR_TAG ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '']","['In recent times, such knowledge-intensive approaches to content delivery have been largely superseded by data-intensive, statistical approaches.', '', '', '( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; #TAUTHOR_TAG ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '']","['In recent times, such knowledge-intensive approaches to content delivery have been largely superseded by data-intensive, statistical approaches.', '', '', '( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; #TAUTHOR_TAG ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '']","['In recent times, such knowledge-intensive approaches to content delivery have been largely superseded by data-intensive, statistical approaches.', '', '', 'Despite this , to date , there has been little work on corpus-based approaches to help-desk response automation ( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; #TAUTHOR_TAG ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '']",0
"['performance', '', 'Specifically , we used Decision Graphs ( Oliver 1993 ) for Doc-Pred , and SVMs #TAUTHOR_TAG for Sent-Pred .', '', '']","['performance', '', 'Specifically , we used Decision Graphs ( Oliver 1993 ) for Doc-Pred , and SVMs #TAUTHOR_TAG for Sent-Pred', '', '']","['', '', 'Specifically , we used Decision Graphs ( Oliver 1993 ) for Doc-Pred , and SVMs #TAUTHOR_TAG for Sent-', '', '']","['', '', '', '', '']",5
"['.', 'After calculating the raw score of each sentence , we use a modified version of the Adaptive Greedy Algorithm by #TAUTHOR_TAG to penalize redundant sentences in cohesive clusters .', 'This is done by decrementing the score of a sentence that belongs to an SC for which there is a higher or equal scoring sentence (if there are several highest-scoring sentences, we retain one sentence as a reference sentence-i.e its is not decrement', '', '']","['sentences.', 'After calculating the raw score of each sentence , we use a modified version of the Adaptive Greedy Algorithm by #TAUTHOR_TAG to penalize redundant sentences in cohesive clusters .', 'This is done by decrementing the score of a sentence that belongs to an SC for which there is a higher or equal scoring sentence (if there are several highest-scoring sentences, we retain one sentence as a reference sentence-i.e., its is not decremented).', '', '']","['', 'After calculating the raw score of each sentence , we use a modified version of the Adaptive Greedy Algorithm by #TAUTHOR_TAG to penalize redundant sentences in cohesive clusters .', 'This is done by decrementing the score of a sentence that belongs to an SC for which there is a higher or equal scoring sentence (if there are several highest-scoring sentences, we retain one sentence as a reference sentence-i.e., its is not decrement', '', '']","['', 'After calculating the raw score of each sentence , we use a modified version of the Adaptive Greedy Algorithm by #TAUTHOR_TAG to penalize redundant sentences in cohesive clusters .', 'This is done by decrementing the score of a sentence that belongs to an SC for which there is a higher or equal scoring sentence (if there are several highest-scoring sentences, we retain one sentence as a reference sentence-i.e., its score is not decremented).', '', '']",5
"['', '', '', '', '', 'The predictive model is a Decision Graph #TAUTHOR_TAG , which , like Snob , is based on the MML principle', 'mm input the identifier of the response cluster that contains the actual response for the request as the target feature', 'predicts which response is most for a re- quest and returns the this prediction is correct', '', 'Table']","['', '', '', '', '', 'The predictive model is a Decision Graph #TAUTHOR_TAG , which , like Snob , is based on the MML principle', 'input the identifier of the response cluster that contains the actual response for the request as the target feature.', 'predicts which response is most for a re- quest, and returns the this prediction is correct.', '', '(Table']","['', '', '', '', '', 'The predictive model is a Decision Graph #TAUTHOR_TAG , which , like Snob , is based on the MML principle .', 'the identifier of the response cluster that contains the actual response for the request as the target feature.', 'predicts which response cluster is most for a re- quest, and returns the probability this prediction is correct', '', 'Table']","['', '', '', '', '', 'The predictive model is a Decision Graph #TAUTHOR_TAG , which , like Snob , is based on the MML principle .', '', 'The model predicts which response cluster is most suitable for a given re- quest, and returns the probability that this prediction is correct.', '', '']",5
"['even the automation of responses to the ""easy"" problems is a difficult task.', 'such inquiries revolve around a relatively small set of issues specific circumstancesquiry unique and hence care be taken compose a response notuse.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; Watson 1997 ; #TAUTHOR_TAG .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['even the automation of responses to the ""easy"" problems is a difficult task.', 'such inquiries revolve around a relatively small set of issues, specific circumstances inquiry unique, and hence care be taken compose a response not customer.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; Watson 1997 ; #TAUTHOR_TAG .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['even the automation of responses to the ""easy"" problems is a difficult task.', 'such inquiries revolve around a relatively small set of issues specific circumstances and hence care must be taken compose a response does notuse', 'It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; Watson 1997 ; #TAUTHOR_TAG .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['However, even the automation of responses to the ""easy"" problems is a difficult task.', 'Although such inquiries revolve around a relatively small set of issues, specific circumstances can make each inquiry unique, and hence care must be taken to compose a response that does not confuse, irritate, or mislead the customer.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; Watson 1997 ; #TAUTHOR_TAG .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']",0
"['There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; #TAUTHOR_TAG ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; #TAUTHOR_TAG ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; #TAUTHOR_TAG ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; #TAUTHOR_TAG ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",1
"['There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; #TAUTHOR_TAG ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; #TAUTHOR_TAG ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; #TAUTHOR_TAG ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; #TAUTHOR_TAG ; Malik , Subramaniam , and Kaushik 2007 ) .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",1
"['', '', '', '', ' #TAUTHOR_TAG compared a predictive approach ( statistical translation ) , a retrieval approach based on a language-model , and a hybrid approach which combines statistical chunking and traditional retrieval .', 'Two the.']","['', '', '', '', ' #TAUTHOR_TAG compared a predictive approach ( statistical translation ) , a retrieval approach based on a language-model , and a hybrid approach which combines statistical chunking and traditional retrieval .', 'Two the following.']","['', '', '', '', ' #TAUTHOR_TAG compared a predictive approach ( statistical translation ) , a retrieval approach based on a language-model , and a hybrid approach which combines statistical chunking and traditional retrieval .', 'the following.']","['', '', '', '', ' #TAUTHOR_TAG compared a predictive approach ( statistical translation ) , a retrieval approach based on a language-model , and a hybrid approach which combines statistical chunking and traditional retrieval .', '']",1
"['with kernel', 'trainedas as a target feature', 'For Sent-Pred we also experimented with grammatical and sentence-based syntactic features , such as number of syntactic phrases , grammatical mood , and grammatical person #TAUTHOR_TAG , but the simple binary bag-of-lemmas representation yielded similar results .', '', '', '']","['with kernel', 'trained as a target feature', 'For Sent-Pred we also experimented with grammatical and sentence-based syntactic features , such as number of syntactic phrases , grammatical mood , and grammatical person #TAUTHOR_TAG , but the simple binary bag-of-lemmas representation yielded similar results .', '7', '', '']","['with', 'is trained as a binary target feature specifying', 'For Sent-Pred we also experimented with grammatical and sentence-based syntactic features , such as number of syntactic phrases , grammatical mood , and grammatical person #TAUTHOR_TAG , but the simple binary bag-of-lemmas representation yielded similar results .', '', '', '']","['', '', '6 For Sent-Pred we also experimented with grammatical and sentence-based syntactic features , such as number of syntactic phrases , grammatical mood , and grammatical person #TAUTHOR_TAG , but the simple binary bag-of-lemmas representation yielded similar results .', '', '', '']",5
"['', '', '', 'proposed two major categories of meta-learning approaches for recommender systems , merging and ensemble , each subdivided into the more specific subclasses suggested by #TAUTHOR_TAG as follows .', 'merging category to techniques where the individual methods affect each other in ways (this category encompasses Burs feature', 'prediction']","['', '', '', 'proposed two major categories of meta-learning approaches for recommender systems , merging and ensemble , each subdivided into the more specific subclasses suggested by #TAUTHOR_TAG as follows .', ""merging category to techniques where the individual methods affect each other in ways (this category encompasses Burke's feature"", 'prediction']","['', '', '', 'proposed two major categories of meta-learning approaches for recommender systems , merging and ensemble , each subdivided into the more specific subclasses suggested by #TAUTHOR_TAG as follows .', 'The merging category corresponds to techniques where the individual methods affect each other in different ways (this', '']","['', '', '', 'They also proposed two major categories of meta-learning approaches for recommender systems , merging and ensemble , each subdivided into the more specific subclasses suggested by #TAUTHOR_TAG as follows .', ""The merging category corresponds to techniques where the individual methods affect each other in different ways (this category encompasses Burke's feature combination, cascade, feature augmentation, and meta-level sub-categories)."", '']",0
"['', '', '', '', 'we discuss the difficulties associated with such user studies , and describe a human-based evaluation we conducted for a small subset of the responses generated by our system #TAUTHOR_TAG b ) .', '']","['', '', '', '', 'we discuss the difficulties associated with such user studies , and describe a human-based evaluation we conducted for a small subset of the responses generated by our system #TAUTHOR_TAG b ) .', '']","['', '', '', '', 'we discuss the difficulties associated with such user studies , and describe a human-based evaluation we conducted for a small subset of the responses generated by our system #TAUTHOR_TAG b ) .', '']","['', '', '', '', 'In Section 5 , we discuss the difficulties associated with such user studies , and describe a human-based evaluation we conducted for a small subset of the responses generated by our system #TAUTHOR_TAG b ) .', '']",5
"['even the automation of responses to the ""easy"" problems is a difficult task.', 'such inquiries revolve around a relatively small set of issues specific circumstancesquiry hence care taken comp response notuse.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; #TAUTHOR_TAG ; Delic and Lahaix 1998 ) .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['even the automation of responses to the ""easy"" problems is a difficult task.', 'such inquiries revolve around a relatively small set of issues, specific circumstances inquiry hence care taken compose response not customer.', 'It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; #TAUTHOR_TAG ; Delic and Lahaix 1998 ) .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['even the automation of responses to the ""easy"" problems is a difficult task.', 'such inquiries revolve around a relatively small set of issues specific circumstances hence care comp a response does notuse', 'It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; #TAUTHOR_TAG ; Delic and Lahaix 1998 ) .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']","['However, even the automation of responses to the ""easy"" problems is a difficult task.', '', 'It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; #TAUTHOR_TAG ; Delic and Lahaix 1998 ) .', 'These systems were carefully designed to produce relevant and correct responses, but required significant human input and maintenance (Delic and Lahaix 1998).']",0
"['', '', ' #TAUTHOR_TAG two retrieval approaches ( TF.IDF and query expansion ) and two predictive approaches ( statistical translation and latent variable models )', 'ijk', '', '']","['', '', ' #TAUTHOR_TAG two retrieval approaches ( TF.IDF and query expansion ) and two predictive approaches ( statistical translation and latent variable models )', '', '', '']","['', '', ' #TAUTHOR_TAG two retrieval approaches ( TF.IDF and query expansion ) and two predictive approaches ( statistical translation and latent variable models )', 'ijk', '', '']","['', '', ' #TAUTHOR_TAG compared two retrieval approaches ( TF.IDF and query expansion ) and two predictive approaches ( statistical translation and latent variable models ) .', '', '', '']",0
"['Following #TAUTHOR_TAG , one approach for achieving this objective consists of applying supervised learning , where a winning method is selected for each case in the training set , all the training cases are labeled accordingly , and then the system is trained to predict a winner for unseen cases .', '', 'an', '', '', '']","['Following #TAUTHOR_TAG , one approach for achieving this objective consists of applying supervised learning , where a winning method is selected for each case in the training set , all the training cases are labeled accordingly , and then the system is trained to predict a winner for unseen cases .', '', 'an', '', '', '']","['Following #TAUTHOR_TAG , one approach for achieving this objective consists of applying supervised learning , where a winning method is selected for each case in the training set , all the training cases are labeled accordingly , and then the system is trained to predict a winner for unseen cases .', '', '', '', '', '']","['Following #TAUTHOR_TAG , one approach for achieving this objective consists of applying supervised learning , where a winning method is selected for each case in the training set , all the training cases are labeled accordingly , and then the system is trained to predict a winner for unseen cases .', '', '', '', '', '']",1
['â\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) ( Lapalme and Kosseim 2003 ; #TAUTHOR_TAG .'],['â\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) ( Lapalme and Kosseim 2003 ; #TAUTHOR_TAG .'],['â\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) ( Lapalme and Kosseim 2003 ; #TAUTHOR_TAG .'],['â\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) ( Lapalme and Kosseim 2003 ; #TAUTHOR_TAG .'],1
"['are a requests or match portions of', '', '', '', 'our we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization ( Goldstein et al. 2000 ; Barzilay , Elhadad , and McKeown 2001 ; #TAUTHOR_TAG .']","['are a requests or match portions of', '', '', '', 'our we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization ( Goldstein et al. 2000 ; Barzilay , Elhadad , and McKeown 2001 ; #TAUTHOR_TAG .']","['are requests or match portions of', '', '', '', 'our we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization ( Goldstein et al. 2000 ; Barzilay , Elhadad , and McKeown 2001 ; #TAUTHOR_TAG .']","['', '', '', '', 'In our work , we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization ( Goldstein et al. 2000 ; Barzilay , Elhadad , and McKeown 2001 ; #TAUTHOR_TAG .']",0
"['Two applications that , like help-desk , deal with question -- answer pairs are : summarization of e-mail threads ( Dalli , Xia , and Wilks 2004 ; #TAUTHOR_TAG , and answer extraction in FAQs ( Frequently Asked Questions ) ( Berger and Mittal 2000;Soricut and Brill 2006).', '', '', '']","['Two applications that , like help-desk , deal with question -- answer pairs are : summarization of e-mail threads ( Dalli , Xia , and Wilks 2004 ; #TAUTHOR_TAG , and answer extraction in FAQs ( Frequently Asked Questions ) ( Berger and Mittal 2000;Soricut and Brill 2006).', '', '', '']","['Two applications that , like help-desk , deal with question -- answer pairs are : summarization of e-mail threads ( Dalli , Xia , and Wilks 2004 ; #TAUTHOR_TAG , and answer extraction in FAQs ( Frequently Asked Questions ) ( Berger and Mittal 2000;Soricut and Brill 2006).', '', '', '']","['Two applications that , like help-desk , deal with question -- answer pairs are : summarization of e-mail threads ( Dalli , Xia , and Wilks 2004 ; #TAUTHOR_TAG , and answer extraction in FAQs ( Frequently Asked Questions ) ( Berger and Mittal 2000;Soricut and Brill 2006).', '', '', '']",1
"['performance techniques', '', 'Specifically , we used Decision Graphs #TAUTHOR_TAG for Doc-Pred , and SVMs ( Vapnik 1998 ) for Sent-Pred .', '', '']","['performance techniques.', '', 'Specifically , we used Decision Graphs #TAUTHOR_TAG for Doc-Pred , and SVMs ( Vapnik 1998 ) for Sent-Pred', '', '']","['', '', 'Specifically , we used Decision Graphs #TAUTHOR_TAG for Doc-Pred , and SVMs ( Vapnik 1998 ) for Sent-', '', '']","['', '', '', '', '']",5
"[' We also employed sequence-based measures using the ROUGE tool set #TAUTHOR_TAG , with similar results to those obtained with the word-by-word measures .']","['We also employed sequence-based measures using the ROUGE tool set #TAUTHOR_TAG , with similar results to those obtained with the word-by-word measures .']","[' We also employed sequence-based measures using the ROUGE tool set #TAUTHOR_TAG , with similar results to those obtained with the word-by-word measures .']","['13 We also employed sequence-based measures using the ROUGE tool set #TAUTHOR_TAG , with similar results to those obtained with the word-by-word measures .']",5
"['of (ations (  and', 'We then use the program Snob #TAUTHOR_TAG ; Wallace 2005 ) to cluster these experiences .', 'Figure 8a)ids clusters produced by Snob into the three most significant dimensions discovered by Pr Component Analysis (', 'project', '']","['of (Equations ( and', 'We then use the program Snob #TAUTHOR_TAG ; Wallace 2005 ) to cluster these experiences .', 'Figure 8(a) centroids clusters produced by Snob into the three most significant dimensions discovered by Principal Component Analysis', '', '']","['of (ations (  and', 'We then use the program Snob #TAUTHOR_TAG ; Wallace 2005 ) to cluster these experiences .', 'Figure 8a) the clusters produced by Snob into the three most significant dimensions discovered by Principal Component Analysis (', 'project', '']","['', 'We then use the program Snob #TAUTHOR_TAG ; Wallace 2005 ) to cluster these experiences .', '', '', '']",5
"['In order to address these limitations in a practical way , we conducted a small user study where we asked four judges ( graduate students from the Faculty of Information Technology at Monash University ) to assess the responses generated by our system #TAUTHOR_TAG a ) .', '', '']","['In order to address these limitations in a practical way , we conducted a small user study where we asked four judges ( graduate students from the Faculty of Information Technology at Monash University ) to assess the responses generated by our system #TAUTHOR_TAG a ) .', '', '']","['In order to address these limitations in a practical way , we conducted a small user study where we asked four judges ( graduate students from the Faculty of Information Technology at Monash University ) to assess the responses generated by our system #TAUTHOR_TAG a ) .', '', '']","['In order to address these limitations in a practical way , we conducted a small user study where we asked four judges ( graduate students from the Faculty of Information Technology at Monash University ) to assess the responses generated by our system #TAUTHOR_TAG a ) .', '', '']",5
"['a', '', '', '', ""The question answering system developed by #TAUTHOR_TAG belongs to the merging category of approaches , where the output of an individual method can be used as input to a different method ( this corresponds to Burke 's cascade sub-category ) ."", '', 'twoys methods that not use', '']","['a', '', '', '', ""The question answering system developed by #TAUTHOR_TAG belongs to the merging category of approaches , where the output of an individual method can be used as input to a different method ( this corresponds to Burke 's cascade sub-category ) ."", '', 'two methods that not use', '']","['', '', '', '', ""The question answering system developed by #TAUTHOR_TAG belongs to the merging category of approaches , where the output of an individual method can be used as input to a different method ( this corresponds to Burke 's cascade sub-category ) ."", '', 'twoys methods that are not they use', '']","['', '', '', '', ""The question answering system developed by #TAUTHOR_TAG belongs to the merging category of approaches , where the output of an individual method can be used as input to a different method ( this corresponds to Burke 's cascade sub-category ) ."", '', '', '']",1
"['M', '', '', 'has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al.005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases #TAUTHOR_TAG ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .']","['', '', '', 'has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases #TAUTHOR_TAG ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .']","['M', '', '', 'has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases #TAUTHOR_TAG ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .']","['', '', '', 'But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases #TAUTHOR_TAG ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .']",4
"['the projection step uses the same inference algorithm (forward-backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of λ.', 'We optimize the dual objective using the gradient based methods shown in Al', ""η precision  step chosen with strongfe'sNocedal and Wright 99)."", 'PV ( A ) represents an ascent direction chosen as follows : For inequality constraints , it is the projected gradient #TAUTHOR_TAG ; for equality constraints with slack , we use conjugate gradient ( Nocedal and Wright 1999 ) , noting that when A = 0 , the objective is not differentiable .', '']","['the projection step uses the same inference algorithm (forward-backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of λ.', 'We optimize the dual objective using the gradient based methods shown in Algorithm', ""η precision, α step chosen with strong Wolfe's (Nocedal and Wright 1999)."", 'PV ( A ) represents an ascent direction chosen as follows : For inequality constraints , it is the projected gradient #TAUTHOR_TAG ; for equality constraints with slack , we use conjugate gradient ( Nocedal and Wright 1999 ) , noting that when A = 0 , the objective is not differentiable .', '']","['Hence the projection step uses the same inference algorithm (forward-backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of λ.', 'We optimize the dual objective using the gradient based methods shown in Al', ""Here η chosen with the strong Wolfe's ruleNocedal and Wright 1999)."", 'PV ( A ) represents an ascent direction chosen as follows : For inequality constraints , it is the projected gradient #TAUTHOR_TAG ; for equality constraints with slack , we use conjugate gradient ( Nocedal and Wright 1999 ) , noting that when A = 0 , the objective is not differentiable .', '']","['Hence the projection step uses the same inference algorithm (forward-backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of λ.', 'We optimize the dual objective using the gradient based methods shown in Algorithm 1.', ""Here η is an optimization precision, α is a step size chosen with the strong Wolfe's rule (Nocedal and Wright 1999)."", 'Here , PV ( A ) represents an ascent direction chosen as follows : For inequality constraints , it is the projected gradient #TAUTHOR_TAG ; for equality constraints with slack , we use conjugate gradient ( Nocedal and Wright 1999 ) , noting that when A = 0 , the objective is not differentiable .', '']",5
"['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'abilities See #TAUTHOR_TAG for further discussion .']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'abilities See #TAUTHOR_TAG for further discussion .']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'phrase probabilities. See #TAUTHOR_TAG for further discussion .']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['', '3 4 and 5 attempt to (the tendency each word generate several target), resulting in probabilistically deficient, intractable models that heuristic search and are difficult to implement and extend.', 'Many researchers use the GIZA + + software package #TAUTHOR_TAG as a black box , selecting IBM Model 4 as a compromise between alignment quality and efficiency', '', '', '']","['', '3, 4, and 5 attempt to (the tendency each word generate several target words), resulting in probabilistically deficient, intractable models that heuristic search and are difficult to implement and extend.', 'Many researchers use the GIZA + + software package #TAUTHOR_TAG as a black box , selecting IBM Model 4 as a compromise between alignment quality and efficiency', '', '', '']","['', 'and 5 attempt to (the tendency each source word generate several target), resulting in probabilistically deficient, intractable models that local heuristic search and are difficult to implement and extend.', 'Many researchers use the GIZA + + software package #TAUTHOR_TAG as a black box , selecting IBM Model 4 as a compromise between alignment quality and efficiency .', '', '', '']","['', 'IBM Models 3, 4, and 5 attempt to capture fertility (the tendency of each source word to generate several target words), resulting in probabilistically deficient, intractable models that require local heuristic search and are difficult to implement and extend.', 'Many researchers use the GIZA + + software package #TAUTHOR_TAG as a black box , selecting IBM Model 4 as a compromise between alignment quality and efficiency .', '', '', '']",0
"['Hence the projection step uses the same inference algorithm (forward-backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of λ.', 'We optimize the dual objective using the gradient based methods shown in Algorithm 1.', ""Here 11 is an optimization precision , oc is a step size chosen with the strong Wolfe 's rule #TAUTHOR_TAG ."", 'Here, λ) represents an as direction chosen as: gradient', '']","['Hence the projection step uses the same inference algorithm (forward-backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of λ.', 'We optimize the dual objective using the gradient based methods shown in Algorithm 1.', ""Here 11 is an optimization precision , oc is a step size chosen with the strong Wolfe 's rule #TAUTHOR_TAG ."", 'Here, represents an ascent direction chosen as follows: gradient', '']","['Hence the projection step uses the same inference algorithm (forward-backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of λ.', 'We optimize the dual objective using the gradient based methods shown in Algorithm 1.', ""Here 11 is an optimization precision , oc is a step size chosen with the strong Wolfe 's rule #TAUTHOR_TAG ."", 'Here, λ) represents an ascent direction chosen as:', '']","['Hence the projection step uses the same inference algorithm (forward-backward for HMMs) to compute the gradient, only modifying the local factors using the current setting of λ.', 'We optimize the dual objective using the gradient based methods shown in Algorithm 1.', ""Here 11 is an optimization precision , oc is a step size chosen with the strong Wolfe 's rule #TAUTHOR_TAG ."", '', '']",5
"['alignment models in general in grossimpl of and the optimal likelihood parameters learned often do not correspond to alignments', 'One solution to this problem is to add more complexity to the model to better reflect the translation process.', 'This is the approach taken by IBM Models 4 + ( Brown et al. 1993b ; Och and Ney 2003 ) , and more recently by the LEAF model #TAUTHOR_TAG .', 'Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors.', '', '', '', '', '', '', '', '', '']","['alignment models in general in gross of and the optimal likelihood parameters learned often do not correspond to alignments.', 'One solution to this problem is to add more complexity to the model to better reflect the translation process.', 'This is the approach taken by IBM Models 4 + ( Brown et al. 1993b ; Och and Ney 2003 ) , and more recently by the LEAF model #TAUTHOR_TAG .', 'Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors.', '', '', '', '', '', '', '', '', '']","['Word alignment models in general in of and the optimal likelihood parameters learned often do not correspond to alignments', 'One solution to this problem is to add more complexity to the model to better reflect the translation process.', 'This is the approach taken by IBM Models 4 + ( Brown et al. 1993b ; Och and Ney 2003 ) , and more recently by the LEAF model #TAUTHOR_TAG .', 'Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors.', '', '', '', '', '', '', '', '', '']","['Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments.', 'One solution to this problem is to add more complexity to the model to better reflect the translation process.', 'This is the approach taken by IBM Models 4 + ( Brown et al. 1993b ; Och and Ney 2003 ) , and more recently by the LEAF model #TAUTHOR_TAG .', 'Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors.', '', '', '', '', '', '', '', '', '']",1
['5 The open source Moses #TAUTHOR_TAG toolkit from www.statmt.org/moses/ .'],['5 The open source Moses #TAUTHOR_TAG toolkit from www.statmt.org/moses/ .'],['5 The open source Moses #TAUTHOR_TAG toolkit from www.statmt.org/moses/ .'],['5 The open source Moses #TAUTHOR_TAG toolkit from www.statmt.org/moses/ .'],5
"['', '', '', '', '', '', '', '', 'bank and parses forian', 'Figure 10 shows our results for transferring from English to Bulgarian (En→Bg) and from English to Spanish (En→Es).', 'results are based on a corpus of movie subtitles #TAUTHOR_TAG , and are consequently shorter sentences , whereas the En â\x86\x92 Es results are based on a corpus of parliamentary proceedings ( Koehn 2005 ) .', '']","['', '', '', '', '', '', '', '', 'Treebank and parses for Bulgarian', 'Figure 10 shows our results for transferring from English to Bulgarian (En→Bg) and from English to Spanish (En→Es).', 'results are based on a corpus of movie subtitles #TAUTHOR_TAG , and are consequently shorter sentences , whereas the En â\x86\x92 Es results are based on a corpus of parliamentary proceedings ( Koehn 2005 ) .', '']","['', '', '', '', '', '', '', '', 'and parses forian', 'shows our results for transferring from English to Bulgarian (En→Bg) and from English to Spanish (En→Es).', 'results are based on a corpus of movie subtitles #TAUTHOR_TAG , and are consequently shorter sentences , whereas the En â\x86\x92 Es results are based on a corpus of parliamentary proceedings ( Koehn 2005 ) .', '']","['', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG , we filter alignment links between words with incompatible POS tags. Figure 10 shows our results for transferring from English to Bulgarian (En→Bg) and from English to Spanish (En→Es).', 'results are based on a corpus of movie subtitles #TAUTHOR_TAG , and are consequently shorter sentences , whereas the En â\x86\x92 Es results are based on a corpus of parliamentary proceedings ( Koehn 2005 ) .', '']",5
"['M', '', ', [ K , andcu 3 ] and rules [ Galley et al.04 ; #TAUTHOR_TAG ] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006).', 'importance machine translation transferring annotations betweensky and Ng1;5;Gancheasesny']","['', '', ', [ , and Marcu ] and rules [ Galley et al. ; #TAUTHOR_TAG ] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006).', 'importance machine translation: transferring annotations between and Ngai']","['M', '', ', [ Koehn , andcu 2003 ] and rules [ Galley et al.04 ; #TAUTHOR_TAG ] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006).', 'importance machine translation:, transferring annotations betweensky and Ngasesny']","['', '', '', '']",0
"['Another possibility that often works better is to use Minimum Bayes-Risk ( MBR ) decoding #TAUTHOR_TAG ; Liang , Taskar , and Klein 2006 ; Ganchev , and Taskar 2007 ) .', 'this we include an alignment link i − j if the posterior probability that word i aligns to word j is above some threshold.', 'accumulation of probability from several low-scoring align that agree on one alignment link', '', '', '', '', '', '', '']","['Another possibility that often works better is to use Minimum Bayes-Risk ( MBR ) decoding #TAUTHOR_TAG ; Liang , Taskar , and Klein 2006 ; Ganchev , and Taskar 2007 ) .', 'this we include an alignment link i − j if the posterior probability that word i aligns to word j is above some threshold.', 'accumulation of probability from several low-scoring alignments that agree on one alignment link.', '', '', '', '', '', '', '']","['Another possibility that often works better is to use Minimum Bayes-Risk ( MBR ) decoding #TAUTHOR_TAG ; Liang , Taskar , and Klein 2006 ; Ganchev , and Taskar 2007 ) .', 'we include an alignment link i − j if the posterior probability that word i aligns to word j is above some threshold.', 'the accumulation of probability from several low-scoring alignments that agree on one alignment link.', '', '', '', '', '', '', '']","['Another possibility that often works better is to use Minimum Bayes-Risk ( MBR ) decoding #TAUTHOR_TAG ; Liang , Taskar , and Klein 2006 ; Ganchev , and Taskar 2007 ) .', 'Using this decoding we include an alignment link i − j if the posterior probability that word i aligns to word j is above some threshold.', 'This allows the accumulation of probability from several low-scoring alignments that agree on one alignment link.', '', '', '', '', '', '', '']",5
"['', '', '', '', 'We used a standard implementation of IBM Model 4 #TAUTHOR_TAG and the existing code is not we could not use the same stopping criterion to avoid overfitting and we not to produce precision/recall curves', '']","['', '', '', '', 'We used a standard implementation of IBM Model 4 #TAUTHOR_TAG and the existing code is not we could not use the same stopping criterion to avoid overfitting and we not to produce precision/recall curves', '']","['', '', '', '', 'We used a standard implementation of IBM Model 4 #TAUTHOR_TAG and changing the existing code is not we could not use the same stopping criterion to avoid overfitting and we are not to produce precision/recall curves .', '']","['', '', '', '', 'We used a standard implementation of IBM Model 4 #TAUTHOR_TAG and because changing the existing code is not trivial , we could not use the same stopping criterion to avoid overfitting and we are not able to produce precision/recall curves .', '']",5
"['M', '', '', '; ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages #TAUTHOR_TAG .']","['', '', '', '; ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages #TAUTHOR_TAG .']","['M', '', '', '; ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages #TAUTHOR_TAG .']","['', '', '', 'But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages #TAUTHOR_TAG .']",4
"['al nature of the gener models used to recover word alignments conflicts with interpretation', '', 'The standard approach is to train two models independently and then intersect their predictions #TAUTHOR_TAG .', 'that much better to train two directional models concurrently, coupling their posterior distributions over alignments to approximately agree.', 'Let the directional models be defined as: − → p ( − → z ) (source-target) and ← − p ( ← − z ) (target-source', '', '', '']","['directional nature of the generative models used to recover word alignments conflicts with interpretation', '', 'The standard approach is to train two models independently and then intersect their predictions #TAUTHOR_TAG .', 'that much better to train two directional models concurrently, coupling their posterior distributions over alignments to approximately agree.', 'Let the directional models be defined as: − → p ( − → z ) (source-target) and ← − p ( ← − z ) (target-source).', '', '←', '']","['The directional nature of the generative models used to recover word alignments conflicts with interpretation', '', 'The standard approach is to train two models independently and then intersect their predictions #TAUTHOR_TAG .', 'that better to train two directional models concurrently, coupling their posterior distributions over alignments to approximately agree.', 'Let the directional models be defined as: − → p ( − → z ) (source-target) and ← − p ( ← − z ) (target-source', '', '', '']","['The directional nature of the generative models used to recover word alignments conflicts with their interpretation as translations.', '', 'The standard approach is to train two models independently and then intersect their predictions #TAUTHOR_TAG .', 'However, we show that it is much better to train two directional models concurrently, coupling their posterior distributions over alignments to approximately agree.', 'Let the directional models be defined as: − → p ( − → z ) (source-target) and ← − p ( ← − z ) (target-source).', '', '', '']",1
"['Because of the latent alignment variables z, the log-likelihood function for the HMM model is not concave, and the model is fit using the Expectation Maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).', 'EM maximizes G ( 0 ) via block-coordinate ascent on a lower bound F ( q , 0 ) using an auxiliary distribution over the latent variables q ( z | x , y ) #TAUTHOR_TAG :']","['Because of the latent alignment variables z, the log-likelihood function for the HMM model is not concave, and the model is fit using the Expectation Maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).', 'EM maximizes G ( 0 ) via block-coordinate ascent on a lower bound F ( q , 0 ) using an auxiliary distribution over the latent variables q ( z | x , y ) #TAUTHOR_TAG :']","['Because of the latent alignment variables z, the log-likelihood function for the HMM model is not concave, and the model is fit using the Expectation Maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).', 'EM maximizes G ( 0 ) via block-coordinate ascent on a lower bound F ( q , 0 ) using an auxiliary distribution over the latent variables q ( z | x , y ) #TAUTHOR_TAG :']","['Because of the latent alignment variables z, the log-likelihood function for the HMM model is not concave, and the model is fit using the Expectation Maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).', 'EM maximizes G ( 0 ) via block-coordinate ascent on a lower bound F ( q , 0 ) using an auxiliary distribution over the latent variables q ( z | x , y ) #TAUTHOR_TAG :']",5
"['alignment models in general and the in grossimpl of and the optimal likelihood parameters learned often do not correspond to alignments', 'One solution to this problem is to add more complexity to the model to better reflect the translation process.', 'This is the approach taken by IBM Models 4 + ( Brown et al. 1993b ; #TAUTHOR_TAG , and more recently by the LEAF model ( Fraser and Marcu 2007 ) .', 'these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors', '', '', '', '', '', '', '', '', '']","['alignment models in general and the in gross of and the optimal likelihood parameters learned often do not correspond to alignments.', 'One solution to this problem is to add more complexity to the model to better reflect the translation process.', 'This is the approach taken by IBM Models 4 + ( Brown et al. 1993b ; #TAUTHOR_TAG , and more recently by the LEAF model ( Fraser and Marcu 2007 ) .', 'these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors.', '', '', '', '', '', '', '', '', '']","['Word alignment models in general and in of and the optimal likelihood parameters learned often do not correspond to alignments', 'One solution to this problem is to add more complexity to the model to better reflect the translation process.', 'This is the approach taken by IBM Models 4 + ( Brown et al. 1993b ; #TAUTHOR_TAG , and more recently by the LEAF model ( Fraser and Marcu 2007 ) .', 'these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors', '', '', '', '', '', '', '', '', '']","['Word alignment models in general and the HMM in particular are very gross oversimplifications of the translation process and the optimal likelihood parameters learned often do not correspond to sensible alignments.', 'One solution to this problem is to add more complexity to the model to better reflect the translation process.', 'This is the approach taken by IBM Models 4 + ( Brown et al. 1993b ; #TAUTHOR_TAG , and more recently by the LEAF model ( Fraser and Marcu 2007 ) .', 'Unfortunately, these changes make the models probabilistically deficient and intractable, requiring approximations and heuristic learning and inference prone to search errors.', '', '', '', '', '', '', '', '', '']",1
"['The idea of introducing constraints over a model to better guide the learning process has appeared before.', 'In the context of word alignment , #TAUTHOR_TAG use a state-duration HMM in order to model word-to-phrase translations .', 'The fertility of each source word is implicitly encoded in the durations of the HMM states.', 'Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control this behavior by multiplying every probability η > 1', 'transitions', '', '', '', '', '', '', '', '', '']","['The idea of introducing constraints over a model to better guide the learning process has appeared before.', 'In the context of word alignment , #TAUTHOR_TAG use a state-duration HMM in order to model word-to-phrase translations .', 'The fertility of each source word is implicitly encoded in the durations of the HMM states.', 'Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control this behavior by multiplying every probability η > 1.', 'transitions', '', '', '', '', '', '', '', '', '']","['The idea of introducing constraints over a model to better guide the learning process has appeared before.', 'In the context of word alignment , #TAUTHOR_TAG use a state-duration HMM in order to model word-to-phrase translations .', 'The fertility of each source word is implicitly encoded in the durations of the HMM states.', 'Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control this behavior by multiplying every transition probability a constant η > 1', 'more transitions', '', '', '', '', '', '', '', '', '']","['The idea of introducing constraints over a model to better guide the learning process has appeared before.', 'In the context of word alignment , #TAUTHOR_TAG use a state-duration HMM in order to model word-to-phrase translations .', 'The fertility of each source word is implicitly encoded in the durations of the HMM states.', 'Without any restrictions, likelihood prefers to always use longer phrases and the authors try to control this behavior by multiplying every transition probability by a constant η > 1.', '', '', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', '', 'and', 'Figure 10 shows our results for transferring from Englishian (En→Bg) and English Spanish (En→).', 'results are based on a corpus of movie subtitles ( Tiedemann 2007 ) , and are consequently shorter sentences , whereas the En â\x86\x92 Es results are based on a corpus of parliamentary proceedings #TAUTHOR_TAG .', 'in Figure  models trained using posterior']","['', '', '', '', '', '', '', '', 'and', 'Figure 10 shows our results for transferring from English Bulgarian (En→Bg) and English Spanish (En→Es).', 'results are based on a corpus of movie subtitles ( Tiedemann 2007 ) , and are consequently shorter sentences , whereas the En â\x86\x92 Es results are based on a corpus of parliamentary proceedings #TAUTHOR_TAG .', 'in Figure models trained using posterior']","['', '', '', '', '', '', '', '', 'and', 'shows our results for transferring from Englishian (En→Bg) and English Spanish (En→).', 'results are based on a corpus of movie subtitles ( Tiedemann 2007 ) , and are consequently shorter sentences , whereas the En â\x86\x92 Es results are based on a corpus of parliamentary proceedings #TAUTHOR_TAG .', 'in Figure 10 the models trained using']","['', '', '', '', '', '', '', '', '', ' #AUTHOR_TAG , we filter alignment links between words with incompatible POS tags. Figure 10 shows our results for transferring from English to Bulgarian (En→Bg) and from English to Spanish (En→Es).', 'results are based on a corpus of movie subtitles ( Tiedemann 2007 ) , and are consequently shorter sentences , whereas the En â\x86\x92 Es results are based on a corpus of parliamentary proceedings #TAUTHOR_TAG .', '']",5
"['are whereas applications a', '', '', '', '', '', '', '', 'this work we followed a more principled approach that uses the knowledge about the posterior distributions of each directional model.', 'We include a point in the final alignment if the average of the posteriors under the two models for that point is above a threshold.', 'This heuristic is called soft union #TAUTHOR_TAG .', 'Figure 8 shows the Precision/Recall curves after symmetrization for the En-Fr corpus.', 'The posterior regularization-trained models still performed better, the', '', '']","['are whereas applications a', '', '', '', '', '', '', '', 'this work we followed a more principled approach that uses the knowledge about the posterior distributions of each directional model.', 'We include a point in the final alignment if the average of the posteriors under the two models for that point is above a threshold.', 'This heuristic is called soft union #TAUTHOR_TAG .', 'Figure 8 shows the Precision/Recall curves after symmetrization for the En-Fr corpus.', 'The posterior regularization-trained models still performed better, the', '', '']","['are whereas most applications', '', '', '', '', '', '', '', 'this work we followed a more principled approach that uses the knowledge about the posterior distributions of each directional model.', 'We include a point in the final alignment if the average of the posteriors under the two models for that point is above a threshold.', 'This heuristic is called soft union #TAUTHOR_TAG .', 'Figure 8 shows the Precision/Recall curves after symmetrization for the En-Fr corpus.', 'The posterior regularization-trained models still performed better, the differences', '', '']","['', '', '', '', '', '', '', '', 'In this work we followed a more principled approach that uses the knowledge about the posterior distributions of each directional model.', 'We include a point in the final alignment if the average of the posteriors under the two models for that point is above a threshold.', 'This heuristic is called soft union #TAUTHOR_TAG .', 'Figure 8 shows the Precision/Recall curves after symmetrization for the En-Fr corpus.', 'The posterior regularization-trained models still performed better, but the differences get smaller after doing the symmetrization.', '', '']",5
"['M', '', '', 'their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; #TAUTHOR_TAG ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 8 )']","['', '', '', 'their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; #TAUTHOR_TAG ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay )']","['M', '', '', 'their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; #TAUTHOR_TAG ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 )']","['', '', '', 'But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; #TAUTHOR_TAG ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .']",4
"['for a pair the between words in a and a (.3', 'ato-word (to-) correspondence is not every aux in., English He walked and French Il est allé), in), English German Massenichtungen), and expressions indirectly.', 'Due to this inherent ambiguity , manual annotations usually distinguish between sure correspondences for unambiguous translations , and possible , for ambiguous translations #TAUTHOR_TAG .', 'The top row of Figure 1 shows two word alignments between an English-French sentence pair.', '', '', '']","['for a pair the between words in a and a al.', 'a word-to-word (1-to-1) correspondence is not every auxiliary in English He walked and French Il est allé), in English German Massenvernichtungswaffen), and expressions indirectly.', 'Due to this inherent ambiguity , manual annotations usually distinguish between sure correspondences for unambiguous translations , and possible , for ambiguous translations #TAUTHOR_TAG .', 'The top row of Figure 1 shows two word alignments between an English-French sentence pair.', '', '', '']","['for a parallel sentence pair the correspondence between words in and (.3', 'a simple word-to-word (to-) correspondence is not in., English He walked and French Il est allé), articles in English weapons German Massenvernichtungswaffen), and expressions indirectly.', 'Due to this inherent ambiguity , manual annotations usually distinguish between sure correspondences for unambiguous translations , and possible , for ambiguous translations #TAUTHOR_TAG .', 'The top row of Figure 1 shows two word alignments between an English-French sentence pair.', '', '', '']","['', '', 'Due to this inherent ambiguity , manual annotations usually distinguish between sure correspondences for unambiguous translations , and possible , for ambiguous translations #TAUTHOR_TAG .', 'The top row of Figure 1 shows two word alignments between an English-French sentence pair.', '', '', '']",0
"['As discussed earlier, the word alignment models are asymmetric, whereas most applications require a single alignment for each sentence pair.', 'Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a single alignment.', 'For MT the most commonly used heuristic is called grow diagonal final #TAUTHOR_TAG .', 'This starts with the intersection of the sets of aligned points and adds points around the diagonal that are in the union of the two sets of aligned points.', 'The alignment produced has high recall relative to the intersection and only slightly lower recall than the union.', 'theuristic is used, to to transfer', '', '', '', '', '', '', '', '', '']","['As discussed earlier, the word alignment models are asymmetric, whereas most applications require a single alignment for each sentence pair.', 'Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a single alignment.', 'For MT the most commonly used heuristic is called grow diagonal final #TAUTHOR_TAG .', 'This starts with the intersection of the sets of aligned points and adds points around the diagonal that are in the union of the two sets of aligned points.', 'The alignment produced has high recall relative to the intersection and only slightly lower recall than the union.', 'the heuristic is used, to to transfer', '', '', '', '', '', '', '', '', '']","['As discussed earlier, the word alignment models are asymmetric, whereas most applications require a single alignment for each sentence pair.', 'Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a single alignment.', 'For MT the most commonly used heuristic is called grow diagonal final #TAUTHOR_TAG .', 'This starts with the intersection of the sets of aligned points and adds points around the diagonal that are in the union of the two sets of aligned points.', 'The alignment produced has high recall relative to the intersection and only slightly lower recall than the union.', 'the intersection heuristic is normally used, to to transfer', '', '', '', '', '', '', '', '', '']","['As discussed earlier, the word alignment models are asymmetric, whereas most applications require a single alignment for each sentence pair.', 'Typically this is achieved by a symmetrization heuristic that takes two directional alignments and produces a single alignment.', 'For MT the most commonly used heuristic is called grow diagonal final #TAUTHOR_TAG .', 'This starts with the intersection of the sets of aligned points and adds points around the diagonal that are in the union of the two sets of aligned points.', 'The alignment produced has high recall relative to the intersection and only slightly lower recall than the union.', '', '', '', '', '', '', '', '', '', '']",1
"['PR is closely related to the work of #TAUTHOR_TAG , 2008 ) , who concurrently developed the idea of using penalties based on posterior expectations of features to guide semi-supervised learning .', 'They call their method generalized expectation (GE) constraints or alternatively expectation regularization.', ', the posteriors of the model on unlabeled data are regular directly', 'data and an ""expectation regularization"" penalty term on the unlabeled data']","['PR is closely related to the work of #TAUTHOR_TAG , 2008 ) , who concurrently developed the idea of using penalties based on posterior expectations of features to guide semi-supervised learning .', 'They call their method generalized expectation (GE) constraints or alternatively expectation regularization.', 'framework, the posteriors of the model on unlabeled data are regularized directly.', 'data and an ""expectation regularization"" penalty term on the unlabeled data:']","['PR is closely related to the work of #TAUTHOR_TAG , 2008 ) , who concurrently developed the idea of using penalties based on posterior expectations of features to guide semi-supervised learning .', 'They call their method generalized expectation (GE) constraints or alternatively expectation regularization.', ', the posteriors of the model on unlabeled data are regularized directly', 'data and an ""expectation regularization"" penalty term on the unlabeled data:']","['PR is closely related to the work of #TAUTHOR_TAG , 2008 ) , who concurrently developed the idea of using penalties based on posterior expectations of features to guide semi-supervised learning .', 'They call their method generalized expectation (GE) constraints or alternatively expectation regularization.', 'In the original GE framework, the posteriors of the model on unlabeled data are regularized directly.', 'They train a discriminative model, using conditional likelihood on labeled data and an ""expectation regularization"" penalty term on the unlabeled data:']",0
"['M', '', '', 'But their importance has grown far beyond machine translation : for instance , transferring annotations between languages #TAUTHOR_TAG ; Hwa et al. 005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay']","['', '', '', 'But their importance has grown far beyond machine translation : for instance , transferring annotations between languages #TAUTHOR_TAG ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay']","['M', '', '', 'But their importance has grown far beyond machine translation : for instance , transferring annotations between languages #TAUTHOR_TAG ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzil']","['', '', '', 'But their importance has grown far beyond machine translation : for instance , transferring annotations between languages #TAUTHOR_TAG ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .']",4
"['sem work b) introduced a seriesabilistic modelsM ) machine', '', 'Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ #TAUTHOR_TAG ; Chiang et al.2005 ] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006).', 'transferasesny']","['seminal work b) introduced a series probabilistic models machine', '', 'Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ #TAUTHOR_TAG ; Chiang et al. 2005 ] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006).', 'transferring']","['The seminal work #AUTHOR_TAG b) introduced a seriesabilistic modelsM', '', 'Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ #TAUTHOR_TAG ; Chiang et al. 2005 ] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006).', 'asesny']","['', '', 'Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ #TAUTHOR_TAG ; Chiang et al. 2005 ] ) as well as for MT system combination (Matusov, Ueffing, and Ney 2006).', '']",0
"['of introducing constraints over a model to better guide the learning process has appeared before.', '', '', '', '', ""For the task of unsupervised dependency parsing , #TAUTHOR_TAG add a constraint of the form `` the average length of dependencies should be X '' to capture the locality of syntax ( at least half of the dependencies are between adjacent words ) , using a scheme they call structural annealing ."", ""They modify the model's distribution over trees p θ (y) by a penalty term as: p θ (y) ∝ p θ (y)e (δ e∈y length(e)) , where length(e) is the surface length of edge e."", '', 'two the of controlling un and', '', '', '', '', '']","['of introducing constraints over a model to better guide the learning process has appeared before.', '', '', '', '', ""For the task of unsupervised dependency parsing , #TAUTHOR_TAG add a constraint of the form `` the average length of dependencies should be X '' to capture the locality of syntax ( at least half of the dependencies are between adjacent words ) , using a scheme they call structural annealing ."", ""They modify the model's distribution over trees p θ (y) by a penalty term as: p θ (y) ∝ p θ (y)e (δ e∈y length(e)) , where length(e) is the surface length of edge e."", 'δ', 'two the of controlling and', '', '', '', '', '']","['of introducing constraints over a model to better guide the learning process has appeared before.', '', '', '', '', ""For the task of unsupervised dependency parsing , #TAUTHOR_TAG add a constraint of the form `` the average length of dependencies should be X '' to capture the locality of syntax ( at least half of the dependencies are between adjacent words ) , using a scheme they call structural annealing ."", ""They modify the model's distribution over trees p θ (y) by a penalty term as: p θ (y) ∝ p θ (y)e (δ e∈y length(e)) , where length(e) is the surface length of edge e."", '', 'the goal of and', '', '', '', '', '']","['The idea of introducing constraints over a model to better guide the learning process has appeared before.', '', '', '', '', ""For the task of unsupervised dependency parsing , #TAUTHOR_TAG add a constraint of the form `` the average length of dependencies should be X '' to capture the locality of syntax ( at least half of the dependencies are between adjacent words ) , using a scheme they call structural annealing ."", ""They modify the model's distribution over trees p θ (y) by a penalty term as: p θ (y) ∝ p θ (y)e (δ e∈y length(e)) , where length(e) is the surface length of edge e."", '', '', '', '', '', '', '']",0
"['', '', 'We use the agreement checker code developed by #TAUTHOR_TAG and evaluate our baseline ( MaltParser using only CORE12 ) , best performing model ( Easy-ser using', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', 'We use the agreement checker code developed by #TAUTHOR_TAG and evaluate our baseline ( MaltParser using only CORE12 ) , best performing model ( Easy-First Parser using', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', 'We use the agreement checker code developed by #TAUTHOR_TAG and evaluate our baseline ( MaltParser using only CORE12 ) , best performing model ( Easy-First Parser using', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', 'We use the agreement checker code developed by #TAUTHOR_TAG and evaluate our baseline ( MaltParser using only CORE12 ) , best performing model ( Easy-First Parser using CORE12 + DET+LMM+PERSON+FN * NGR g + p ) , and the gold reference .', '', '', '', '', '', '', '', '', '', '', '', '']",5
"['', '', 'In comparison, the tag set of the Buckwalter Morphological Analyzer #TAUTHOR_TAG used in the PATB has a core POS set of 44 tags (CORE44) before mor- phological extension.8', 'Cross-linguistically, a core set containing around 12 tags is often assumed as a �universal tag set� (Rambow et al. 2006;, Das, and McDonald 2', '', '', '']","['', '', 'In comparison, the tag set of the Buckwalter Morphological Analyzer #TAUTHOR_TAG used in the PATB has a core POS set of 44 tags (CORE44) before mor- phological extension.8', 'Cross-linguistically, a core set containing around 12 tags is often assumed as a �universal tag set� (Rambow et al. 2006; Das, and McDonald', '', '', '']","['', '', 'In comparison, the tag set of the Buckwalter Morphological Analyzer #TAUTHOR_TAG used in the PATB has a core POS set of 44 tags (CORE44) before mor- phological extension.8', 'Cross-linguistically, a core set containing around 12 tags is often assumed as a �universal tag set� (Rambow et al. 2006; Petrov, Das, and', '', '', '']","['', '', 'In comparison, the tag set of the Buckwalter Morphological Analyzer #TAUTHOR_TAG used in the PATB has a core POS set of 44 tags (CORE44) before mor- phological extension.8', 'Cross-linguistically, a core set containing around 12 tags is often assumed as a �universal tag set� (Rambow et al. 2006; Petrov, Das, and McDonald 2012).', '', '', '']",1
"['For better comparison with work of others , we adopt the suggestion made by #TAUTHOR_TAG to evaluate the parsing quality on sentences up to 70 tokens long .', 'in Table 14', '', '', '', '']","['For better comparison with work of others , we adopt the suggestion made by #TAUTHOR_TAG to evaluate the parsing quality on sentences up to 70 tokens long .', 'in Table 14.', '', '', '', '']","['For better comparison with work of others , we adopt the suggestion made by #TAUTHOR_TAG to evaluate the parsing quality on sentences up to 70 tokens long .', 'in Table 14', '', '', '', '']","['For better comparison with work of others , we adopt the suggestion made by #TAUTHOR_TAG to evaluate the parsing quality on sentences up to 70 tokens long .', '', '', '', '', '']",5
"['As for work onic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and M 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; #TAUTHOR_TAG and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; #TAUTHOR_TAG and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work onic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; #TAUTHOR_TAG and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; #TAUTHOR_TAG and the CATiB ( Habash and Roth 2009 ) .', '', '', '']",0
"['We use the Columbia Arabic Treebank ( CATiB ) #TAUTHOR_TAG .', 'use the portion converted from Part 3 of the PATB to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information.', ""CATiB's dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations."", 'It has a reduced POS tag set consisting of six tags only (henceforth CATIB6).', 'The tags are: NOM (non-proper nominals including nouns, pronouns, adjectives, and adverbs), PROP (proper noun), VRB (active-), VRB-PASSpass- ver prepos or conj', 'CATiB a standard set of eight dependency relations: SBJ and OBJ for subject and (direct or indirect) object pre); for', '']","['We use the Columbia Arabic Treebank ( CATiB ) #TAUTHOR_TAG .', 'use the portion converted from Part 3 of the PATB to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information.', ""CATiB's dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations."", 'It has a reduced POS tag set consisting of six tags only (henceforth CATIB6).', 'The tags are: NOM (non-proper nominals including nouns, pronouns, adjectives, and adverbs), PROP (proper nouns), VRB (active-voice VRB-PASS prepositions or', 'CATiB a standard set of eight dependency relations: SBJ and OBJ for subject and (direct or indirect) object, for', '']","['We use the Columbia Arabic Treebank ( CATiB ) #TAUTHOR_TAG .', 'we use the portion converted from Part 3 of the PATB to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information.', ""CATiB's dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations."", 'It has a reduced POS tag set consisting of six tags only (henceforth CATIB6).', 'The tags are: NOM (non-proper nominals including nouns, pronouns, adjectives, and adverbs), PROP (proper noun), VRB (active-voice verbs), VRB-PASSpass- prepos or conj', 'CATiB a standard set of eight dependency relations: SBJ and OBJ for subject and (direct or indirect) object, pre for', '']","['We use the Columbia Arabic Treebank ( CATiB ) #TAUTHOR_TAG .', 'Specifically, we use the portion converted from Part 3 of the PATB to the CATiB format, which enriches the CATiB dependency trees with full PATB morphological information.', ""CATiB's dependency representation is based on traditional Arabic grammar and emphasizes syntactic case relations."", 'It has a reduced POS tag set consisting of six tags only (henceforth CATIB6).', 'The tags are: NOM (non-proper nominals including nouns, pronouns, adjectives, and adverbs), PROP (proper nouns), VRB (active-voice verbs), VRB-PASS (passive-voice verbs), PRT (particles such as prepositions or conjunctions), and PNX (punctuation).', '', '']",5
"['Different languages vary with respect to which features may be most helpful given various among three.', 'In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy.', 'For example , modeling CASE in Czech improves Czech parsing #TAUTHOR_TAG : CASE is relevant , not redundant , and can be predicted with sufficient accuracy .', 'It has been more difficult showing that agreement morphology helps parsing, however, with negative results for dependency parsing in several languages (Eryigit, Nivre, and Oflazer 2008;Nivuslavsky Idin']","['Different languages vary with respect to which features may be most helpful given various among three factors.', 'In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy.', 'For example , modeling CASE in Czech improves Czech parsing #TAUTHOR_TAG : CASE is relevant , not redundant , and can be predicted with sufficient accuracy .', 'It has been more difficult showing that agreement morphology helps parsing, however, with negative results for dependency parsing in several languages (Eryigit, Nivre, and Oflazer 2008;Nivre, Boguslavsky, Iomdin']","['Different languages vary with respect to which features may be most helpful given among these three factors.', 'In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy.', 'For example , modeling CASE in Czech improves Czech parsing #TAUTHOR_TAG : CASE is relevant , not redundant , and can be predicted with sufficient accuracy .', 'It has been more difficult showing that agreement morphology helps parsing, however, with negative results for dependency parsing in several languages (Eryigit, Nivre, and Oflazer 2008;Nivre,uslavsky Id']","['Different languages vary with respect to which features may be most helpful given various tradeoffs among these three factors.', 'In the past, it has been shown that if we can recognize the relevant morphological features in assignment configurations well enough, then they contribute to parsing accuracy.', 'For example , modeling CASE in Czech improves Czech parsing #TAUTHOR_TAG : CASE is relevant , not redundant , and can be predicted with sufficient accuracy .', 'It has been more difficult showing that agreement morphology helps parsing, however, with negative results for dependency parsing in several languages (Eryigit, Nivre, and Oflazer 2008;Nivre, Boguslavsky, and Iomdin 2008;.']",4
"['For all the experiments reported in this article , we used the training portion of PATB Part 3 v3 .1 #TAUTHOR_TAG , converted to the CATiB Treebank format , as mentioned in Section 2.5 .', '', '', '']","['For all the experiments reported in this article , we used the training portion of PATB Part 3 v3 .1 #TAUTHOR_TAG , converted to the CATiB Treebank format , as mentioned in Section 2.5 .', '', '', '']","['For all the experiments reported in this article , we used the training portion of PATB Part 3 v3 .1 #TAUTHOR_TAG , converted to the CATiB Treebank format , as mentioned in Section 2.5 .', '', '', '']","['For all the experiments reported in this article , we used the training portion of PATB Part 3 v3 .1 #TAUTHOR_TAG , converted to the CATiB Treebank format , as mentioned in Section 2.5 .', '', '', '']",5
"['18 In this article , we use a newer version of the corpus by #TAUTHOR_TAG than the one we used in Marton , Habash , and #AUTHOR_TAG .']","['18 In this article , we use a newer version of the corpus by #TAUTHOR_TAG than the one we used in Marton , Habash , and #AUTHOR_TAG .']","['18 In this article , we use a newer version of the corpus by #TAUTHOR_TAG than the one we used in Marton , Habash , and #AUTHOR_TAG .']","['18 In this article , we use a newer version of the corpus by #TAUTHOR_TAG than the one we used in Marton , Habash , and #AUTHOR_TAG .']",5
"['', '', '', '', '', '', '', '', '', '', 'functional In this article , we use an in-house system which provides functional gender , number , and rationality features #TAUTHOR_TAG . ']","['', '', '', '', '', '', '', '', '', '', 'the functional In this article , we use an in-house system which provides functional gender , number , and rationality features #TAUTHOR_TAG . See Section']","['', '', '', '', '', '', '', '', '', '', 'functional inf In this article , we use an in-house system which provides functional gender , number , and rationality features #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', '']",5
"['As for work onic ( MSA , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 26 ; Diab 2 ; Green and M 20 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB #TAUTHOR_TAG .', 'the PATB for annotation consistency an enhanced- gram for', '', '']","['As for work on Arabic ( MSA , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB #TAUTHOR_TAG .', 'the PATB for annotation consistency, an enhanced for', '', '']","['As for work onic ( MSA , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB #TAUTHOR_TAG .', 'the PATB for annotation consistency, for', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB #TAUTHOR_TAG .', '', '', '']",0
"['', '', '', 'the to use functional', 'Furthermore , we demonstrate that our results carry over successfully to another parser , the Easy-First Parser #TAUTHOR_TAG ( Section 6 ) .', '21 certain attributes equal node', '', '']","['', '', '', 'the to use functional', 'Furthermore , we demonstrate that our results carry over successfully to another parser , the Easy-First Parser #TAUTHOR_TAG ( Section 6 ) .', '21 certain attributes equal node', '', '']","['', '', '', 'the to use functional features', 'Furthermore , we demonstrate that our results carry over successfully to another parser , the Easy-First Parser #TAUTHOR_TAG ( Section 6 ) .', '2 certain attributes equal a node', '', '']","['', '', '', '', 'Furthermore , we demonstrate that our results carry over successfully to another parser , the Easy-First Parser #TAUTHOR_TAG ( Section 6 ) .', '', '', '']",5
"['The Elixirxical resource used previously provided functionalBER feature values but no functional GENDER values, nor RAT (rationality, or humanness) values.', 'To address this issue , we use a version of the PATB3 training and dev sets manually annotated with functional gender , number , and rationality #TAUTHOR_TAG . This the resource providing all three features ( ElixirFm only provides functional number , and to some extent functional gender )', '', '', '', '', '', '', '']","['The ElixirFM lexical resource used previously provided functional feature values but no functional GENDER values, nor RAT (rationality, or humanness) values.', 'To address this issue , we use a version of the PATB3 training and dev sets manually annotated with functional gender , number , and rationality #TAUTHOR_TAG This the resource providing all three features ( ElixirFm only provides functional number , and to some extent functional gender )', '', '', '', '', '', '', '']","['The ElixirFMxical resource used previously provided functional NUMBER feature values but no functional GENDER values, nor RAT (rationality, or humanness) values.', 'To address this issue , we use a version of the PATB3 training and dev sets manually annotated with functional gender , number , and rationality #TAUTHOR_TAG . This the first resource providing all three features ( ElixirFm only provides functional number , and to some extent functional gender )', '', '', '', '', '', '', '']","['The ElixirFM lexical resource used previously provided functional NUMBER feature values but no functional GENDER values, nor RAT (rationality, or humanness) values.', 'To address this issue , we use a version of the PATB3 training and dev sets manually annotated with functional gender , number , and rationality #TAUTHOR_TAG .18 This is the first resource providing all three features ( ElixirFm only provides functional number , and to some extent functional gender ) .', '', '', '', '', '', '', '']",5
"['', '', '', 'the trade between relevance and accu- r.Therefore, we repeated the experiments with POS tags predicted by the MADA toolkit #TAUTHOR_TAG ; Habash, Rambow, and Roth 2012)15 (see Table 2, columns 5�7).', 'It B', '', '', '']","['', '', '', 'the tradeoff between relevance and accu- racy.Therefore, we repeated the experiments with POS tags predicted by the MADA toolkit #TAUTHOR_TAG ; Habash, Rambow, and Roth 2012)15 (see Table 2, columns 5�7).', 'It', '', '', '']","['', '', '', 'the tradeoff between relevance and accu- racy.Therefore, we repeated the experiments with POS tags predicted by the MADA toolkit #TAUTHOR_TAG ; Habash, Rambow, and Roth 2012)15 (see Table 2, columns 5�7).', 'B', '', '', '']","['', '', '', 'Put differently, we are interested in the tradeoff between relevance and accu- racy.Therefore, we repeated the experiments with POS tags predicted by the MADA toolkit #TAUTHOR_TAG ; Habash, Rambow, and Roth 2012)15 (see Table 2, columns 5�7).', '', '', '', '']",5
"['All results are reported mainly in terms of labeled attachment accuracy (the parent word and the type of dependency relation to it, abbreviated as LAS), is also used for greedy (hill-climbing) decisions for feature combination', 'ed attachment accuracyAS) and label accuracy (dependency relation regardless) also given', ""For statistical significance , we use McNemar 's test on non-gold LAS , as implemented by Nilsson and #TAUTHOR_TAG ."", 'We p < 0.05 and p < 0.01 with + ++ respectively.']","['All results are reported mainly in terms of labeled attachment accuracy (the parent word and the type of dependency relation to it, abbreviated as LAS), is also used for greedy (hill-climbing) decisions for feature combination.', 'attachment accuracy (UAS) and label accuracy (dependency relation regardless also given.', ""For statistical significance , we use McNemar 's test on non-gold LAS , as implemented by Nilsson and #TAUTHOR_TAG ."", 'We p < 0.05 and p < 0.01 with + ++ respectively.']","['All results are reported mainly in terms of labeled attachment accuracy (the parent word and the type of dependency relation to it, abbreviated as LAS), is also used for greedy (hill-climbing) decisions for feature combination.', 'ed attachment accuracy scoreAS) and label accuracy (dependency relation regardless are also given', ""For statistical significance , we use McNemar 's test on non-gold LAS , as implemented by Nilsson and #TAUTHOR_TAG ."", 'We denote p < 0.05 and p < 0.01 with + ++ respectively.']","['All results are reported mainly in terms of labeled attachment accuracy score (the parent word and the type of dependency relation to it, abbreviated as LAS), which is also used for greedy (hill-climbing) decisions for feature combination.', 'Unlabeled attachment accuracy score (UAS) and label accuracy (dependency relation regardless of parent, LS) are also given.', ""For statistical significance , we use McNemar 's test on non-gold LAS , as implemented by Nilsson and #TAUTHOR_TAG ."", 'We denote p < 0.05 and p < 0.01 with + and ++ , respectively.']",5
"['For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 ( Nivre 2003 , 2008 ; KÃ¼bler , McDonald , and #TAUTHOR_TAG , a transition-based parser with an input buffer and a stack , which uses SVM classifiers We use ""dev set', '', '', '', '', '', '', '', '', '', '', '']","['For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 ( Nivre 2003 , 2008 ; KÃ¼bler , McDonald , and #TAUTHOR_TAG , a transition-based parser with an input buffer and a stack , which uses SVM classifiers We use ""dev set""', '', '', '', '', '', '', '', '', '', '', '']","['For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 ( Nivre 2003 , 2008 ; KÃ¼bler , McDonald , and #TAUTHOR_TAG , a transition-based parser with an input buffer and a stack , which uses SVM classifiers We use the term ""dev set""', '', '', '', '', '', '', '', '', '', '', '']","['For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 ( Nivre 2003 , 2008 ; KÃ¼bler , McDonald , and #TAUTHOR_TAG , a transition-based parser with an input buffer and a stack , which uses SVM classifiers We use the term ""dev set"" to denote a non-blind test set, used for model development (feature selection and feature engineering).', '', '', '', '', '', '', '', '', '', '', '']",5
"['ixir used functional GENDationality', '', 'the resource providing all three features (ElixirFm only provides functional number, and to some extent functional gender).', 'We conducted experiments with gold features to assess the potential of these features , and with predicted features , obtained from training a simple maximum likelihood estimation classifier on this resource #TAUTHOR_TAG .', 'Table', '', '', '', '', '']","['ElixirFM used functional GENDER', '', 'the resource providing all three features (ElixirFm only provides functional number, and to some extent functional gender).', 'We conducted experiments with gold features to assess the potential of these features , and with predicted features , obtained from training a simple maximum likelihood estimation classifier on this resource #TAUTHOR_TAG', 'Table', '', '', '', '', '']","['used previouslyationality', '', 'the first resource providing all three features (ElixirFm only provides functional number, and to some extent functional gender).', 'We conducted experiments with gold features to assess the potential of these features , and with predicted features , obtained from training a simple maximum likelihood estimation classifier on this resource #TAUTHOR_TAG .', '', '', '', '', '', '']","['', '', 'This is the first resource providing all three features (ElixirFm only provides functional number, and to some extent functional gender).', 'We conducted experiments with gold features to assess the potential of these features , and with predicted features , obtained from training a simple maximum likelihood estimation classifier on this resource #TAUTHOR_TAG .19', '', '', '', '', '', '']",5
"['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) #TAUTHOR_TAG , the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012).', 'The Elixir', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) #TAUTHOR_TAG , the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012).', 'The Elixir-FM', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) #TAUTHOR_TAG , the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012).', 'The Elixir-FM analyzer', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) #TAUTHOR_TAG , the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012).', '', '', '']",1
"['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional, and not mark rational; this includes the Pennic TreebankPATB) (), the Buckter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit #TAUTHOR_TAG ; Habash, Rambow, and Roth 2012).', 'The Elixir', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and not mark rationality; this includes the Penn Arabic Treebank (PATB) the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit #TAUTHOR_TAG ; Habash, Rambow, and Roth 2012).', 'The Elixir-FM', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rational; this includes the Penn Arabic TreebankPATB) (), the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit #TAUTHOR_TAG ; Habash, Rambow, and Roth 2012).', 'The Elixir-FM analyzer', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) (Maamouri et al. 2004), the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit #TAUTHOR_TAG ; Habash, Rambow, and Roth 2012).', '', '', '']",1
"[""The following are the various tag sets we use in this article : ( a ) the core POS tag sets CORE44 and the newly introduced CORE12 ; ( b ) CATiB Treebank tag set ( CATIB6 ) #TAUTHOR_TAG and its newly introduced extension of CATIBEX created using simple regular expressions on word form , indicating particular morphemes such as the prefix JI Al + or the suffix v ' + wn ; this tag set is the-performing tag set for Arabic on predicted in Section4 ; ( c Buck""]","[""The following are the various tag sets we use in this article : ( a ) the core POS tag sets CORE44 and the newly introduced CORE12 ; ( b ) CATiB Treebank tag set ( CATIB6 ) #TAUTHOR_TAG and its newly introduced extension of CATIBEX created using simple regular expressions on word form , indicating particular morphemes such as the prefix JI Al + or the suffix v ' + wn ; this tag set is the best-performing tag set for Arabic on predicted in Section 4 ; ( c""]","[""The following are the various tag sets we use in this article : ( a ) the core POS tag sets CORE44 and the newly introduced CORE12 ; ( b ) CATiB Treebank tag set ( CATIB6 ) #TAUTHOR_TAG and its newly introduced extension of CATIBEX created using simple regular expressions on word form , indicating particular morphemes such as the prefix JI Al + or the suffix v ' + wn ; this tag set is the best-performing tag set for Arabic on predicted values in Section 4 ; ( c Buck""]",[''],5
"['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) (Maamouri et al. 2004), the Buckwalter morphological analyzer #TAUTHOR_TAG , and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012).', 'The Elixir', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) (Maamouri et al. 2004), the Buckwalter morphological analyzer #TAUTHOR_TAG , and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012).', 'The Elixir-FM', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) (Maamouri et al. 2004), the Buckwalter morphological analyzer #TAUTHOR_TAG , and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012).', 'The Elixir-FM analyzer', '', '']","['Most available Arabic NLP tools and resources model morphology using form- based (�surface�) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) (Maamouri et al. 2004), the Buckwalter morphological analyzer #TAUTHOR_TAG , and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012).', '', '', '']",1
"['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) #TAUTHOR_TAG ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) #TAUTHOR_TAG ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) #TAUTHOR_TAG ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) #TAUTHOR_TAG ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']",0
"['most', '', '', 'It has been more difficult showing that agreement morphology helps parsing , however , with negative results for dependency parsing in several languages ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; #TAUTHOR_TAG .']","['most', '', '', 'It has been more difficult showing that agreement morphology helps parsing , however , with negative results for dependency parsing in several languages ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; #TAUTHOR_TAG .']","['', '', '', 'It has been more difficult showing that agreement morphology helps parsing , however , with negative results for dependency parsing in several languages ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; #TAUTHOR_TAG .']","['', '', '', 'It has been more difficult showing that agreement morphology helps parsing , however , with negative results for dependency parsing in several languages ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; #TAUTHOR_TAG .']",4
"['', '', 'SA having a rich agreement system both verb-subject and noun-adject relations', 'The result holds for both the MaltParser #TAUTHOR_TAG and the Easy-First Parser ( Goldberg and Elhadad 2010 ) .']","['', '', 'MSA having a rich agreement system, both verb-subject and noun-adjective relations.', 'The result holds for both the MaltParser #TAUTHOR_TAG and the Easy-First Parser ( Goldberg and Elhadad 2010 ) .']","['', '', 'SA having a rich agreement system, covering both verb-subject and noun-adject', 'The result holds for both the MaltParser #TAUTHOR_TAG and the Easy-First Parser ( Goldberg and Elhadad 2010 ) .']","['', '', 'This is likely a result of MSA having a rich agreement system, covering both verb-subject and noun-adjective relations.', 'The result holds for both the MaltParser #TAUTHOR_TAG and the Easy-First Parser ( Goldberg and Elhadad 2010 ) .']",5
"[""OS setsRE and the b ) CATiB Treebank tag set ( CATIB6 ) ( Hab and Roth 2009 ) and its newly introduced of CATIBEX created using on form indicating morhe the suffix v ' + wn ; this tag set is the best-performing tag set for Arabic on predicted values as reported in Section 4 ; ( c ) the PATB full tag set with complete morphological tag ( BW ) #TAUTHOR_TAG ; and two extensions of the PATB reduced tag set ( PENN POS , a.k.a. RTS , size 24 [ Diab , Hacioglu , and Jurafsky 2004 ] ) , both""]","[""POS sets and the b ) CATiB Treebank tag set ( CATIB6 ) ( Habash and Roth 2009 ) and its newly introduced of CATIBEX created using on form indicating morphemes the suffix v ' + wn ; this tag set is the best-performing tag set for Arabic on predicted values as reported in Section 4 ; ( c ) the PATB full tag set with complete morphological tag ( BW ) #TAUTHOR_TAG ; and two extensions of the PATB reduced tag set ( PENN POS , a.k.a. RTS , size 24 [ Diab , Hacioglu , and Jurafsky 2004 ] ) , both""]","[""and the b ) CATiB Treebank tag set ( CATIB6 ) ( Hab and Roth 2009 ) and its newly introduced of CATIBEX created using on word form indicating particular morphemes the suffix v ' + wn ; this tag set is the best-performing tag set for Arabic on predicted values as reported in Section 4 ; ( c ) the PATB full tag set with complete morphological tag ( BW ) #TAUTHOR_TAG ; and two extensions of the PATB reduced tag set ( PENN POS , a.k.a. RTS , size 24 [ Diab , Hacioglu , and Jurafsky 2004 ] ) , both""]",[''],5
"['Much work has been done on the use of morphological features for parsing of morphologically rich languages.', ' #TAUTHOR_TAG report that an optimal tag set for parsing Czech consists of a basic POS tag plus a CASE feature ( when applicable ) .', 'This tag set (size 58) outperforms the basic Czech POS tag set (size 13) and the complete tag set (size ≈3000+).', 'They also report that the use of gender, number, and person features did not yield any improvements.', 'results for', '', '', '', '', '', '']","['Much work has been done on the use of morphological features for parsing of morphologically rich languages.', ' #TAUTHOR_TAG report that an optimal tag set for parsing Czech consists of a basic POS tag plus a CASE feature ( when applicable ) .', 'This tag set (size 58) outperforms the basic Czech POS tag set (size 13) and the complete tag set (size ≈3000+).', 'They also report that the use of gender, number, and person features did not yield any improvements.', 'results for', '', '', '', '', '', '']","['Much work has been done on the use of morphological features for parsing of morphologically rich languages.', ' #TAUTHOR_TAG report that an optimal tag set for parsing Czech consists of a basic POS tag plus a CASE feature ( when applicable ) .', 'This tag set (size 58) outperforms the basic Czech POS tag set (size 13) and the complete tag set (size ≈3000+).', 'They also report that the use of gender, number, and person features did not yield any improvements.', 'The results for', '', '', '', '', '', '']","['Much work has been done on the use of morphological features for parsing of morphologically rich languages.', ' #TAUTHOR_TAG report that an optimal tag set for parsing Czech consists of a basic POS tag plus a CASE feature ( when applicable ) .', 'This tag set (size 58) outperforms the basic Czech POS tag set (size 13) and the complete tag set (size ≈3000+).', 'They also report that the use of gender, number, and person features did not yield any improvements.', '', '', '', '', '', '', '']",0
"['9 We do not relate to specific results in their study because it has been brought to our attention that #TAUTHOR_TAG are in the process of rechecking their code for errors , and rerunning their experiments ( personal communication ) .']","['9 We do not relate to specific results in their study because it has been brought to our attention that #TAUTHOR_TAG are in the process of rechecking their code for errors , and rerunning their experiments ( personal communication ) .']","['9 We do not relate to specific results in their study because it has been brought to our attention that #TAUTHOR_TAG are in the process of rechecking their code for errors , and rerunning their experiments ( personal communication ) .']","['9 We do not relate to specific results in their study because it has been brought to our attention that #TAUTHOR_TAG are in the process of rechecking their code for errors , and rerunning their experiments ( personal communication ) .']",1
"['', '', 'SA having a rich agreement system, both verb-subject and noun-adjective relations.', 'The result holds for both the MaltParser ( Nivre 2008 ) and the Easy-First Parser #TAUTHOR_TAG .']","['', '', 'MSA having a rich agreement system, both verb-subject and noun-adjective relations.', 'The result holds for both the MaltParser ( Nivre 2008 ) and the Easy-First Parser #TAUTHOR_TAG .']","['', '', 'SA having a rich agreement system, covering both verb-subject and noun-adjective relations.', 'The result holds for both the MaltParser ( Nivre 2008 ) and the Easy-First Parser #TAUTHOR_TAG .']","['', '', 'This is likely a result of MSA having a rich agreement system, covering both verb-subject and noun-adjective relations.', 'The result holds for both the MaltParser ( Nivre 2008 ) and the Easy-First Parser #TAUTHOR_TAG .']",5
"['', '', '', '', 'select P tag with only certain', 'A more detailed discussion of the various available Arabic tag sets can be found in #TAUTHOR_TAG .']","['', '', '', '', 'selectively POS tag with only certain', 'A more detailed discussion of the various available Arabic tag sets can be found in #TAUTHOR_TAG .']","['', '', '', '', 'select with', 'A more detailed discussion of the various available Arabic tag sets can be found in #TAUTHOR_TAG .']","['', '', '', '', '', 'A more detailed discussion of the various available Arabic tag sets can be found in #TAUTHOR_TAG .']",0
"['', '', '', '', 'An example CATiB dependency tree is shown in Figure 1.', 'For the corpus statistics, see Table 1.', 'For more information on CATiB , see #TAUTHOR_TAG and Habash , Faraj , and #AUTHOR_TAG .']","['', '', '', '', 'An example CATiB dependency tree is shown in Figure 1.', 'For the corpus statistics, see Table 1.', 'For more information on CATiB , see #TAUTHOR_TAG and Habash , Faraj , and #AUTHOR_TAG .']","['', '', '', '', 'An example CATiB dependency tree is shown in Figure 1.', 'For the corpus statistics, see Table 1.', 'For more information on CATiB , see #TAUTHOR_TAG and Habash , Faraj , and #AUTHOR_TAG .']","['', '', '', '', 'An example CATiB dependency tree is shown in Figure 1.', 'For the corpus statistics, see Table 1.', 'For more information on CATiB , see #TAUTHOR_TAG and Habash , Faraj , and #AUTHOR_TAG .']",0
"['So far, we have only evaluated models trained on gold POS tag set and morphological feature values.', 'Some researchers , however , including #TAUTHOR_TAG , train on predicted feature values instead .', 'It makes sense that training on predicted features yields better scores for evaluation on predicted features, since the training better resembles the test.', '', '']","['So far, we have only evaluated models trained on gold POS tag set and morphological feature values.', 'Some researchers , however , including #TAUTHOR_TAG , train on predicted feature values instead .', 'It makes sense that training on predicted features yields better scores for evaluation on predicted features, since the training better resembles the test.', '', '']","['So far, we have only evaluated models trained on gold POS tag set and morphological feature values.', 'Some researchers , however , including #TAUTHOR_TAG , train on predicted feature values instead .', 'It makes sense that training on predicted features yields better scores for evaluation on predicted features, since the training better resembles the test.', '', '']","['So far, we have only evaluated models trained on gold POS tag set and morphological feature values.', 'Some researchers , however , including #TAUTHOR_TAG , train on predicted feature values instead .', 'It makes sense that training on predicted features yields better scores for evaluation on predicted features, since the training better resembles the test.', '', '']",1
"['19 The paper by #TAUTHOR_TAG presents additional , more sophisticated models that we do not use in this article .']","['19 The paper by #TAUTHOR_TAG presents additional , more sophisticated models that we do not use in this article .']","['19 The paper by #TAUTHOR_TAG presents additional , more sophisticated models that we do not use in this article .']","['19 The paper by #TAUTHOR_TAG presents additional , more sophisticated models that we do not use in this article .']",1
"['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; #TAUTHOR_TAG ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; #TAUTHOR_TAG ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; #TAUTHOR_TAG ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; #TAUTHOR_TAG ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']",0
"['11 #TAUTHOR_TAG reports that non-projective and pseudo-projective algorithms outperform the `` eager projective algorithm in MaltParser , but our training data did not contain any non-projective dependencies .', 'The Niv �standard� algorithm is also reported there to do better on Arabic']","['11 #TAUTHOR_TAG reports that non-projective and pseudo-projective algorithms outperform the `` eager projective algorithm in MaltParser , but our training data did not contain any non-projective dependencies .', 'The Nivre �standard� algorithm is also reported there to do better on Arabic,']","['11 #TAUTHOR_TAG reports that non-projective and pseudo-projective algorithms outperform the `` eager projective algorithm in MaltParser , but our training data did not contain any non-projective dependencies .', 'The Nivre �standard� algorithm is also reported there to do better on Arabic']","['11 #TAUTHOR_TAG reports that non-projective and pseudo-projective algorithms outperform the `` eager projective algorithm in MaltParser , but our training data did not contain any non-projective dependencies .', '']",1
"['', '', '', 'alt definedk at buf[0], and so on K�bler, McDonald, and #TAUTHOR_TAG describe a �typical� MaltParser model configuration of attributes and features.', '', '', '', '', '', '']","['', '', '', 'defined at buf[0], and so on. K�bler, McDonald, and #TAUTHOR_TAG describe a �typical� MaltParser model configuration of attributes and features.13', '', '', '', '', '', '']","['', '', '', 'are definedk at buf[0], and so on. K�bler, McDonald, and #TAUTHOR_TAG describe a �typical� MaltParser model configuration of attributes and features.', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '']",5
"['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; #TAUTHOR_TAG , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; #TAUTHOR_TAG , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; #TAUTHOR_TAG , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']","['As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; #TAUTHOR_TAG , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .', '', '', '']",0
"['For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 #TAUTHOR_TAG , 2008 ; KÃ¼bler , McDonald , Nivre  , buffer', '', '', '', '', '', '', '', '', '', '', '']","['For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 #TAUTHOR_TAG , 2008 ; KÃ¼bler , McDonald , Nivre , buffer', '', '', '', '', '', '', '', '', '', '', '']","['For all experiments reported in this section we used the syntactic dependency parser MaltParser v1 .3 #TAUTHOR_TAG , 2008 ; KÃ¼bler , McDonald , Niv ,', '', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '']",5
"['Greenend Mars', ' #AUTHOR_TAG analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses.', ' #AUTHOR_TAG reports experiments on Arabic parsing using his MaltParser #TAUTHOR_TAG , trained on the PADT .', 'His results are not directly comparable to ours because of the different treebank representations, even though all the experiments reported here were performed using the MaltParser.']","['Marsi', ' #AUTHOR_TAG analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses.', ' #AUTHOR_TAG reports experiments on Arabic parsing using his MaltParser #TAUTHOR_TAG , trained on the PADT .', 'His results are not directly comparable to ours because of the different treebank representations, even though all the experiments reported here were performed using the MaltParser.']","['Mars', ' #AUTHOR_TAG analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses.', ' #AUTHOR_TAG reports experiments on Arabic parsing using his MaltParser #TAUTHOR_TAG , trained on the PADT .', 'His results are not directly comparable to ours because of the different treebank representations, even though all the experiments reported here were performed using the MaltParser.']","['', ' #AUTHOR_TAG analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses.', ' #AUTHOR_TAG reports experiments on Arabic parsing using his MaltParser #TAUTHOR_TAG , trained on the PADT .', 'His results are not directly comparable to ours because of the different treebank representations, even though all the experiments reported here were performed using the MaltParser.']",0
"['Much work has been done on the use of morphological features for parsing of morphologically rich languages.', '', '', '', '', 'Table3', 'Similarly , #TAUTHOR_TAG report that the use of a subset of Spanish morphological features ( number for adjectives , determiners , nouns , pronouns , and verbs ; and mode for verbs ) outperforms other combinations .', 'Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features.', 'We', '']","['Much work has been done on the use of morphological features for parsing of morphologically rich languages.', '', '', '', '', 'Table', 'Similarly , #TAUTHOR_TAG report that the use of a subset of Spanish morphological features ( number for adjectives , determiners , nouns , pronouns , and verbs ; and mode for verbs ) outperforms other combinations .', 'Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features.', 'We', '']","['Much work has been done on the use of morphological features for parsing of morphologically rich languages.', '', '', '', '', 'Table3', 'Similarly , #TAUTHOR_TAG report that the use of a subset of Spanish morphological features ( number for adjectives , determiners , nouns , pronouns , and verbs ; and mode for verbs ) outperforms other combinations .', 'Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features.', 'We', '']","['Much work has been done on the use of morphological features for parsing of morphologically rich languages.', '', '', '', '', '', 'Similarly , #TAUTHOR_TAG report that the use of a subset of Spanish morphological features ( number for adjectives , determiners , nouns , pronouns , and verbs ; and mode for verbs ) outperforms other combinations .', 'Our approach is comparable to their work in terms of its systematic exploration of the space of morphological features.', '', '']",0
"['7 We ignore the rare ""false idafa"" construction #TAUTHOR_TAG , p. 102 ) .']","['7 We ignore the rare ""false idafa"" construction #TAUTHOR_TAG , p. 102 ) .']","['7 We ignore the rare ""false idafa"" construction #TAUTHOR_TAG , p. 102 ) .']","['7 We ignore the rare ""false idafa"" construction #TAUTHOR_TAG , p. 102 ) .']",0
"['In this section , we validate the contribution of key tag sets and morphological features -- and combinations thereof -- using a different parser : the Easy-First Parser #TAUTHOR_TAG .', 'Section 4 all models evaluated on nongoldmachine-icted feature values', 'Easy-First Parser is a shift-reduce parser MaltParser', '', '', '']","['In this section , we validate the contribution of key tag sets and morphological features -- and combinations thereof -- using a different parser : the Easy-First Parser #TAUTHOR_TAG .', 'Section 4, all models evaluated on non-gold (machine-predicted) feature values.', 'Easy-First Parser is a shift-reduce parser MaltParser).', '', '', '']","['In this section , we validate the contribution of key tag sets and morphological features -- and combinations thereof -- using a different parser : the Easy-First Parser #TAUTHOR_TAG .', 'Section 4, all models are evaluated on nongoldmachine-icted) feature values.', 'The Easy-First Parser is a shift-reduce parser MaltParser', '', '', '']","['In this section , we validate the contribution of key tag sets and morphological features -- and combinations thereof -- using a different parser : the Easy-First Parser #TAUTHOR_TAG .', 'As in Section 4, all models are evaluated on both gold and non-gold (machine-predicted) feature values.', 'The Easy-First Parser is a shift-reduce parser (as is MaltParser).', '', '', '']",5
"['Our with on and in the definite is for', '', 'Previous work with MaltParser in , Turkish , and Hindi showed gains with CASE but not with agreement features ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; #TAUTHOR_TAG .', 'Our work is the first to usingalt and in Arab the', '', '', '', '']","['Our with on and in the definite is for', '', 'Previous work with MaltParser in , Turkish , and Hindi showed gains with CASE but not with agreement features ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; #TAUTHOR_TAG .', 'Our work is the first to using and in Arabic the', '', '', '', '']","['Our with on and in is for', '', 'Previous work with MaltParser in , Turkish , and Hindi showed gains with CASE but not with agreement features ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; #TAUTHOR_TAG .', 'Our work is the first to gains usingalt and in Arab the', '', '', '', '']","['', '', 'Previous work with MaltParser in Russian , Turkish , and Hindi showed gains with CASE but not with agreement features ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; #TAUTHOR_TAG .', '', '', '', '', '']",1
"['', '', '', '', 'Gold 6', ' #TAUTHOR_TAG have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor .', 'These features are potentially powerful, because they generalize to the very notion of agreement, away from the specific values of the attributes on which agreement occurs', 'We expect this kind of feature to yield lower gains for Arabic r one functional feature values']","['', '', '', '', '6).', ' #TAUTHOR_TAG have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor .', 'These features are potentially powerful, because they generalize to the very notion of agreement, away from the specific values of the attributes on which agreement occurs.', 'We expect this kind of feature to yield lower gains for Arabic, r one functional feature values']","['', '', '', '', 'GoldSection 6).', ' #TAUTHOR_TAG have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor .', 'These features are potentially powerful, because they generalize to the very notion of agreement, away from the specific values of the attributes on which agreement occurs.', 'We expect this kind of feature to yield lower gains for Arabic: r one functional feature values']","['', '', '', '', '', ' #TAUTHOR_TAG have conducted a study on dependency parsing for 21 languages using features that encode whether the values for certain attributes are equal or not for a node and its governor .', 'These features are potentially powerful, because they generalize to the very notion of agreement, away from the specific values of the attributes on which agreement occurs.', '']",0
"['This article represents an extension of our previous work on unsupervised event coreference resolution ( Bejan et al. 2009 ; #TAUTHOR_TAG .', 'In this work, we present more details on the problem of solving both within-and cross-document event coreference as well as describe a generic framework for solving this type of problem in un way.', '', '', '', '', '']","['This article represents an extension of our previous work on unsupervised event coreference resolution ( Bejan et al. 2009 ; #TAUTHOR_TAG .', 'In this work, we present more details on the problem of solving both within-and cross-document event coreference as well as describe a generic framework for solving this type of problem in way.', '', '', '', '', '']","['This article represents an extension of our previous work on unsupervised event coreference resolution ( Bejan et al. 2009 ; #TAUTHOR_TAG .', 'In this work, we present more details on the problem of solving both within-and cross-document event coreference as well as describe a generic framework for solving this type of problem in an unsupervised way.', '', '', '', '', '']","['This article represents an extension of our previous work on unsupervised event coreference resolution ( Bejan et al. 2009 ; #TAUTHOR_TAG .', 'In this work, we present more details on the problem of solving both within-and cross-document event coreference as well as describe a generic framework for solving this type of problem in an unsupervised way.', '', '', '', '', '']",2
"['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et. 1980 , Dixon and 1979 , Erman et al.1980 , Haton and Pierrel 1976 , Lea 1980 , #TAUTHOR_TAG , Medress 1980 , Reddy 1976 , 1978 , and ', 'these', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , #TAUTHOR_TAG , Medress 1980 , Reddy 1976 , 1978 , and', 'these', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et. 1980 , Dixon and Martin 1979 , Erman et al.1980 , Haton and Pierrel 1976 , Lea 1980 , #TAUTHOR_TAG , Medress 1980 , Reddy 1976 , Walker 1978 , and', 'these efforts', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , #TAUTHOR_TAG , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .', '', '', '']",1
"['Though the implemented system is limited to matrix-oriented problems, the theoretical system is capable of learning a wide range of problem types.', 'The only requirement on the problem or situation is that it can be entered into the expectation system in the form of examples.', ""Thus , for example , it can acquire a `` script '' such as the one for going to a restaurant as defined in #TAUTHOR_TAG .""]","['Though the implemented system is limited to matrix-oriented problems, the theoretical system is capable of learning a wide range of problem types.', 'The only requirement on the problem or situation is that it can be entered into the expectation system in the form of examples.', ""Thus , for example , it can acquire a `` script '' such as the one for going to a restaurant as defined in #TAUTHOR_TAG .""]","['Though the implemented system is limited to matrix-oriented problems, the theoretical system is capable of learning a wide range of problem types.', 'The only requirement on the problem or situation is that it can be entered into the expectation system in the form of examples.', ""Thus , for example , it can acquire a `` script '' such as the one for going to a restaurant as defined in #TAUTHOR_TAG .""]","['Though the implemented system is limited to matrix-oriented problems, the theoretical system is capable of learning a wide range of problem types.', 'The only requirement on the problem or situation is that it can be entered into the expectation system in the form of examples.', ""Thus , for example , it can acquire a `` script '' such as the one for going to a restaurant as defined in #TAUTHOR_TAG .""]",0
"['', '', '.', 'There is some literature on procedure acquisition such as the LISP synthesis work described in #AUTHOR_TAG and the PROLOG synthesis method of #TAUTHOR_TAG .']","['', '', 'structures.', 'There is some literature on procedure acquisition such as the LISP synthesis work described in #AUTHOR_TAG and the PROLOG synthesis method of #TAUTHOR_TAG .']","['', '', '', 'There is some literature on procedure acquisition such as the LISP synthesis work described in #AUTHOR_TAG and the PROLOG synthesis method of #TAUTHOR_TAG .']","['', '', '', 'There is some literature on procedure acquisition such as the LISP synthesis work described in #AUTHOR_TAG and the PROLOG synthesis method of #TAUTHOR_TAG .']",1
"[""¢ use of low level knowledge from the speech recognition phase ,¢ use of high level knowledge about the domain in particular and the dialogue task in general , â\x80¢ a `` continue '' facility and an `` auto-loop '' facility as described by #AUTHOR_TAG ,\x80¢ a `` conditioning '' facility as described by #TAUTHOR_TAG , â¢ implementation of new""]","[""use of low level knowledge from the speech recognition phase , use of high level knowledge about the domain in particular and the dialogue task in general , â\x80¢ a `` continue '' facility and an `` auto-loop '' facility as described by #AUTHOR_TAG , â\x80¢ a `` conditioning '' facility as described by #TAUTHOR_TAG , â\x80¢ implementation of new""]","[""¢ use of low level knowledge from the speech recognition phase ,¢ use of high level knowledge about the domain in particular and the dialogue task in general , â\x80¢ a `` continue '' facility and an `` auto-loop '' facility as described by #AUTHOR_TAG ,\x80¢ a `` conditioning '' facility as described by #TAUTHOR_TAG , â¢ implementation of new types""]","[""â\x80¢ use of low level knowledge from the speech recognition phase , â\x80¢ use of high level knowledge about the domain in particular and the dialogue task in general , â\x80¢ a `` continue '' facility and an `` auto-loop '' facility as described by #AUTHOR_TAG , â\x80¢ a `` conditioning '' facility as described by #TAUTHOR_TAG , â\x80¢ implementation of new types of paraphrasing , â\x80¢ checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen , and â\x80¢ examining inter-speaker dialogue patterns .""]",3
"['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']",1
"['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']",1
"['overview approach', 'details', '', 'useful method', 'An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) ( Ballard 1979 , #TAUTHOR_TAG .', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCEink 983).', '']","['overview approach', 'details', '', 'usefulness methodology', 'An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) ( Ballard 1979 , #TAUTHOR_TAG .', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983).', '']","['an overview the approach', 'The details', '', '', 'An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) ( Ballard 1979 , #TAUTHOR_TAG .', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983).', '']","['', '', '', '', 'An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) ( Ballard 1979 , #TAUTHOR_TAG .', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983).', '']",0
"['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #AUTHOR_TAG , assertional statements as in #AUTHOR_TAG , or semantic nets as in #TAUTHOR_TAG .', '.', 'is PRO']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #AUTHOR_TAG , assertional statements as in #AUTHOR_TAG , or semantic nets as in #TAUTHOR_TAG .', 'structures.', 'is PROLOG']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #AUTHOR_TAG , assertional statements as in #AUTHOR_TAG , or semantic nets as in #TAUTHOR_TAG .', '', 'is']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #AUTHOR_TAG , assertional statements as in #AUTHOR_TAG , or semantic nets as in #TAUTHOR_TAG .', '', '']",1
"['', '', '', '', '', '', '', '', 'the ""flowcharts in the current project are probabilistic in nature and the problems sentences nodes', 'Another dialogue acquisition system has been developed by #TAUTHOR_TAG .', 'that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction.', 'The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user', 'It self activates to bias toward historically observed patterns but is not otherwise observable.']","['', '', '', '', '', '', '', '', 'the ""flowcharts"" in the current project are probabilistic in nature and the problems sentences nodes', 'Another dialogue acquisition system has been developed by #TAUTHOR_TAG .', 'that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction.', 'The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user.', 'It self activates to bias toward historically observed patterns but is not otherwise observable.']","['', '', '', '', '', '', '', '', 'the ""flowcharts"" in the current project are probabilistic in nature and the problems existing nodes', 'Another dialogue acquisition system has been developed by #TAUTHOR_TAG .', 'that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction.', 'The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user.', 'It self activates to bias toward historically observed patterns but is not otherwise observable.']","['', '', '', '', '', '', '', '', 'However, the ""flowcharts"" in the current project are probabilistic in nature and the problems associated with matching incoming sentences to existing nodes has not been previously addressed.', 'Another dialogue acquisition system has been developed by #TAUTHOR_TAG .', 'However, that system has different goals: to enable the user to consciously design a dialogue to embody a particular human-machine interaction.', 'The acquisition system described here is aimed at dealing with ill-formed input and is completely automatic and invisible to the user.', 'It self activates to bias recognition toward historically observed patterns but is not otherwise observable.']",1
"['of speech understanding systems have been developed during fifteen years ( Barnett.ixon Er et.  Haton and Pierrel 1976 , Le  , Lower anddy 980 ,ress 80 ,dy 976 , Walker 1978 , and #TAUTHOR_TAG .', 'Most of these efforts concentrated on a', '', '']","['of speech understanding systems have been developed during fifteen years ( Barnett al. Dixon Erman et al. Haton and Pierrel 1976 , Lea , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and #TAUTHOR_TAG .', 'Most of these efforts concentrated on a', '', '']","['of speech understanding systems have been developed during the past fifteen years ( Barnett.ixon Er et.  Haton and Pierrel 1976 , Le , Lower anddy 1980 ,ress 1980 ,dy 1976 , Walker 1978 , and #TAUTHOR_TAG .', 'Most of these efforts concentrated on', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and #TAUTHOR_TAG .', '', '', '']",1
"['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']",1
"['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #AUTHOR_TAG , assertional statements as in #TAUTHOR_TAG , or semantic nets as in #AUTHOR_TAG .', '.', 'is']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #AUTHOR_TAG , assertional statements as in #TAUTHOR_TAG , or semantic nets as in #AUTHOR_TAG .', 'structures.', 'is']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #AUTHOR_TAG , assertional statements as in #TAUTHOR_TAG , or semantic nets as in #AUTHOR_TAG .', '', 'is']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #AUTHOR_TAG , assertional statements as in #TAUTHOR_TAG , or semantic nets as in #AUTHOR_TAG .', '', '']",1
"['', '', '', '', '', '', '', 'The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by #TAUTHOR_TAG where program flowcharts were constructed from traces of their behaviors .', '', '', '', '', '']","['', '', '', '', '', '', '', 'The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by #TAUTHOR_TAG where program flowcharts were constructed from traces of their behaviors .', '', '', '', '', '']","['', '', '', '', '', '', '', 'The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by #TAUTHOR_TAG where program flowcharts were constructed from traces of their behaviors .', '', '', '', '', '']","['', '', '', '', '', '', '', 'The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by #TAUTHOR_TAG where program flowcharts were constructed from traces of their behaviors .', '', '', '', '', '']",1
"['We denote the meaning of each sentence Si with the notation M(Si).', 'The exact form of M ( Si ) need not be discussed at this point ; it could be a conceptual dependence graph #TAUTHOR_TAG , a deep parse of Si , or some other representation .', 'A user behavior represented a directed', '']","['We denote the meaning of each sentence Si with the notation M(Si).', 'The exact form of M ( Si ) need not be discussed at this point ; it could be a conceptual dependence graph #TAUTHOR_TAG , a deep parse of Si , or some other representation .', 'A user behavior represented a directed', '']","['We denote the meaning of each sentence Si with the notation M(Si).', 'The exact form of M ( Si ) need not be discussed at this point ; it could be a conceptual dependence graph #TAUTHOR_TAG , a deep parse of Si , or some other representation .', 'A user behavior is represented directed', '']","['We denote the meaning of each sentence Si with the notation M(Si).', 'The exact form of M ( Si ) need not be discussed at this point ; it could be a conceptual dependence graph #TAUTHOR_TAG , a deep parse of Si , or some other representation .', '', '']",0
"['A of speech understanding systems have been developed during the past fifteen years ( Barnett et.9 ,ixon 19 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 198 , Lower and Reddy 1980 , #TAUTHOR_TAG , Reddy 1976 , Walker 978 , and and ', '', '', '']","['A of speech understanding systems have been developed during the past fifteen years ( Barnett et al. , Dixon 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , #TAUTHOR_TAG , Reddy 1976 , Walker 1978 , and and', '', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et.9 ,ixon Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lower and Reddy 1980 , #TAUTHOR_TAG , Reddy 1976 , Walker 1978 , and and', '', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , #TAUTHOR_TAG , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .', '', '', '']",1
"['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , #TAUTHOR_TAG , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 980 ,ress ,6 ,', '', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , #TAUTHOR_TAG , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress , ,', '', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , #TAUTHOR_TAG , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , , ,', '', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , #TAUTHOR_TAG , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .', '', '', '']",1
"['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']",1
"['', '', '', '', '', '', '', 'current system should be distinguished from an earlier voice system ( VNLC , #TAUTHOR_TAG , which had no expectation and which handled discrete speech where a 300 millisecond pause must follow each word . ]']","['', '', '', '', '', '', '', 'current system should be distinguished from an earlier voice system ( VNLC , #TAUTHOR_TAG , which had no expectation and which handled discrete speech where a 300 millisecond pause must follow each word . ]']","['', '', '', '', '', '', '', 'The current system should be distinguished from an earlier voice system ( VNLC , #TAUTHOR_TAG , which had no expectation and which handled discrete speech where a 300 millisecond pause must follow each word . ]']","['', '', '', '', '', '', '', '[ The current system should be distinguished from an earlier voice system ( VNLC , #TAUTHOR_TAG , which had no expectation and which handled discrete speech where a 300 millisecond pause must follow each word . ]']",1
"['The expectation parser uses an ATN-like representation for its grammar #TAUTHOR_TAG .', 'Its strategy is top-down.', 'The types of sentences accepted are essentially those accepted by the original NLC grammar, imperative sentences with nested noun groups and conjctions (Bard 9).', '', 'tasks', '']","['The expectation parser uses an ATN-like representation for its grammar #TAUTHOR_TAG .', 'Its strategy is top-down.', 'The types of sentences accepted are essentially those accepted by the original NLC grammar, imperative sentences with nested noun groups and conjunctions (Ballard 1979).', '', 'tasks', '']","['The expectation parser uses an ATN-like representation for its grammar #TAUTHOR_TAG .', 'Its strategy is top-down.', 'The types of sentences accepted are essentially those accepted by the original NLC grammar, imperative sentences with nested noun groups and conjctions (Bard 9).', '', '', '']","['The expectation parser uses an ATN-like representation for its grammar #TAUTHOR_TAG .', 'Its strategy is top-down.', 'The types of sentences accepted are essentially those accepted by the original NLC grammar, imperative sentences with nested noun groups and conjunctions (Ballard 1979).', '', '', '']",5
"['', 'details', '', '', '-the- speech recognition device a Electric Corporation DP-200, was added to an existing natural language processing system, the Natural Language Computer (NLC) (Ballard 1979, B andBallard 19).', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation ( VNLCE , #TAUTHOR_TAG .', '']","['', 'details', '', '', 'speech recognition device, a Electric Corporation DP-200, was added to an existing natural language processing system, the Natural Language Computer (NLC) (Ballard 1979, andBallard 1980).', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation ( VNLCE , #TAUTHOR_TAG .', '']","['', 'The details', '', '', 'An off-the-shelf speech recognition device a Nippon Electric Corporation DP-200, was added to an existing natural language processing system, the Natural Language Computer (NLC) (Ballard 1979, B andBallard 19).', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation ( VNLCE , #TAUTHOR_TAG .', '']","['', '', '', '', 'An off-the-shelf speech recognition device, a Nippon Electric Corporation DP-200, was added to an existing natural language processing system, the Natural Language Computer (NLC) (Ballard 1979, Biermann andBallard 1980).', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation ( VNLCE , #TAUTHOR_TAG .', '']",0
"['A number of speech understanding systems have been developed during the past fifteen years #TAUTHOR_TAG , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 ,ress 980 , 976 , Walker 78 , and and 98 )', 'Most of these efforts concentrated on the level from a a', '', '']","['A number of speech understanding systems have been developed during the past fifteen years #TAUTHOR_TAG , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , 1976 , Walker 1978 , and and 1980 )', 'Most of these efforts concentrated on the level from a a', '', '']","['A number of speech understanding systems have been developed during the past fifteen years #TAUTHOR_TAG , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 ,ress 1980 ,dy 1976 , Walker 1978 , and and )', 'Most of these efforts concentrated on the interaction from', '', '']","['A number of speech understanding systems have been developed during the past fifteen years #TAUTHOR_TAG , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .', '', '', '']",1
"['', '', 'some of these systems did exhibit expectation capabilities at the sentence level described here for the sake level expectation and error correction.', 'A detailed description of the kinds of expectation mechanisms appearing in these systems appears in #TAUTHOR_TAG .']","['', '', 'some of these systems did exhibit expectation capabilities at the sentence level, described here for the sake level expectation and error correction.', 'A detailed description of the kinds of expectation mechanisms appearing in these systems appears in #TAUTHOR_TAG .']","['', '', 'some of these systems did exhibit expectation capabilities at the sentence level, none described here for the sake dialogue level expectation and error correction.', 'A detailed description of the kinds of expectation mechanisms appearing in these systems appears in #TAUTHOR_TAG .']","['', '', 'While some of these systems did exhibit expectation capabilities at the sentence level, none acquired dialogues of the kind described here for the sake of dialogue level expectation and error correction.', 'A detailed description of the kinds of expectation mechanisms appearing in these systems appears in #TAUTHOR_TAG .']",0
"[""â\x80¢ use of low level knowledge from the speech recognition phase , â\x80¢ use of high level knowledge about the domain in particular and the dialogue task in general , â\x80¢ a `` continue '' facility and an `` auto-loop '' facility as described by #TAUTHOR_TAG , â\x80¢ a `` conditioning '' facility as described by #AUTHOR_TAG , â¢ implementation of new""]","[""â\x80¢ use of low level knowledge from the speech recognition phase , â\x80¢ use of high level knowledge about the domain in particular and the dialogue task in general , â\x80¢ a `` continue '' facility and an `` auto-loop '' facility as described by #TAUTHOR_TAG , â\x80¢ a `` conditioning '' facility as described by #AUTHOR_TAG , â\x80¢ implementation of new""]","[""â\x80¢ use of low level knowledge from the speech recognition phase , â\x80¢ use of high level knowledge about the domain in particular and the dialogue task in general , â\x80¢ a `` continue '' facility and an `` auto-loop '' facility as described by #TAUTHOR_TAG , â\x80¢ a `` conditioning '' facility as described by #AUTHOR_TAG , â¢ implementation of new types""]","[""â\x80¢ use of low level knowledge from the speech recognition phase , â\x80¢ use of high level knowledge about the domain in particular and the dialogue task in general , â\x80¢ a `` continue '' facility and an `` auto-loop '' facility as described by #TAUTHOR_TAG , â\x80¢ a `` conditioning '' facility as described by #AUTHOR_TAG , â\x80¢ implementation of new types of paraphrasing , â\x80¢ checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen , and â\x80¢ examining inter-speaker dialogue patterns .""]",3
"['The problem of handling ill-formed input has been studied by #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', 'used', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', 'used', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', 'used', '', '', '', '', '', '', '', '', '', '']","['The problem of handling ill-formed input has been studied by #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', 'A wide variety of techniques have been developed for addressing problems at the word, phrase, sentence, and in some cases, dialogue level.', '', '', '', '', '', '', '', '', '', '', '']",1
"['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #TAUTHOR_TAG , assertional statements as in #AUTHOR_TAG , or semantic nets as in #AUTHOR_TAG .', '.', '']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #TAUTHOR_TAG , assertional statements as in #AUTHOR_TAG , or semantic nets as in #AUTHOR_TAG .', 'structures.', '']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #TAUTHOR_TAG , assertional statements as in #AUTHOR_TAG , or semantic nets as in #AUTHOR_TAG .', '', '']","['The VNLCE processor may be considered to be a learning system of the tradition described, for example, in #AUTHOR_TAG .', 'The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in #TAUTHOR_TAG , assertional statements as in #AUTHOR_TAG , or semantic nets as in #AUTHOR_TAG .', '', '']",1
"['approach', 'details', '', 'usefulness of the methodology described above was the of a connected.', 'An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) #TAUTHOR_TAG , Biermann and Ballard 1980 ) .', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (NLCEink 93', '']","['approach', 'details', '', 'usefulness of the methodology described above was the of a connected system.', 'An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) #TAUTHOR_TAG , Biermann and Ballard 1980 ) .', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983).', '']","['the approach', 'The details', '', 'The usefulness of the methodology described above was tested the implementation of a connected speech understanding.', 'An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) #TAUTHOR_TAG , Biermann and Ballard 1980 ) .', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (NLCE', '']","['', '', '', 'The usefulness of the methodology described above was tested in the implementation of a connected speech understanding system.', 'An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) #TAUTHOR_TAG , Biermann and Ballard 1980 ) .', 'The expectation system provided the intermediate processing between the errorful output of the speech recognizer and the deep semantics of NLC.', 'The resulting speech understanding system is called the Voice Natural Language Computer with Expectation (VNLCE, Fink 1983).', '']",0
"['of speech understanding systems have been developed during fifteen ( Barnett.ixon Er et. Haton and Pierrel 1976 , Le  , anddy 9ress980 , #TAUTHOR_TAG , Walker 1978 , and and 9', '', '', '']","['of speech understanding systems have been developed during fifteen ( Barnett al. Dixon Erman et al. Haton and Pierrel 1976 , Lea , and Reddy Medress 1980 , #TAUTHOR_TAG , Walker 1978 , and and', '', '', '']","['of speech understanding systems have been developed during ( Barnett.ixon Er et. Haton and Pierrel 1976 , Le , anddy 1980ress 1980 , #TAUTHOR_TAG , Walker 1978 , and and', '', '', '']","['', '', '', '']",1
"['The expectation parser uses an ATN-like representation for its grammar (Woods 1970).', 'Its strategy is top-down.', 'The types of sentences accepted are essentially those accepted by the original NLC grammar , imperative sentences with nested noun groups and conjunctions #TAUTHOR_TAG .', 'An attempt has been made to build as deep a parse as that sentences with the meaning identical.', '""meaningresult in identical tasks being performed', '']","['The expectation parser uses an ATN-like representation for its grammar (Woods 1970).', 'Its strategy is top-down.', 'The types of sentences accepted are essentially those accepted by the original NLC grammar , imperative sentences with nested noun groups and conjunctions #TAUTHOR_TAG .', 'An attempt has been made to build as deep a parse as that sentences with the meaning identical', '""meaning"" ""result in identical tasks being performed.', '']","['The expectation parser uses an ATN-like representation for its grammar (Woods 1970).', 'Its strategy is top-down.', 'The types of sentences accepted are essentially those accepted by the original NLC grammar , imperative sentences with nested noun groups and conjunctions #TAUTHOR_TAG .', 'An attempt has been made to build as deep a parse as that sentences with the same meaning result identical parses.', 'the same ""meaning"" in identical tasks being performed', '']","['The expectation parser uses an ATN-like representation for its grammar (Woods 1970).', 'Its strategy is top-down.', 'The types of sentences accepted are essentially those accepted by the original NLC grammar , imperative sentences with nested noun groups and conjunctions #TAUTHOR_TAG .', 'An attempt has been made to build as deep a parse as possible so that sentences with the same meaning result in identical parses.', '', '']",0
"['reflected', '', 'unable', 'backs', 'should the the expectation', '', 'that be made to determine which option is better in a given situation is how often the first will error correct incorrectly as opposed to how much error correcting power we will by using the.', 'How it is done is beyond the scope of this paper but is explained in detail in #TAUTHOR_TAG .']","['reflected', '', 'unable', '', 'should the the expectation', '', 'that be made to determine which option is better in a given situation is how often the first will error correct incorrectly as opposed to how much error correcting power we will by using the second.', 'How it is done is beyond the scope of this paper but is explained in detail in #TAUTHOR_TAG .']","['', '', 'unable', 'backs', 'should the expectation parser', '', 'that must be made to determine which option is better in a given situation is how often the first will error correct incorrectly as opposed to how much error correcting power we will lose by using the second.', 'How it is done is beyond the scope of this paper but is explained in detail in #TAUTHOR_TAG .']","['', '', '', '', '', '', 'The comparison that must be made to determine which option is better in a given situation is how often the first will error correct incorrectly as opposed to how much error correcting power we will lose by using the second.', 'How it is done is beyond the scope of this paper but is explained in detail in #TAUTHOR_TAG .']",0
"['', '', '.', 'There is some literature on procedure acquisition such as the LISP synthesis work described in #TAUTHOR_TAG and the PROLOG synthesis method of #AUTHOR_TAG .']","['', '', 'structures.', 'There is some literature on procedure acquisition such as the LISP synthesis work described in #TAUTHOR_TAG and the PROLOG synthesis method of #AUTHOR_TAG .']","['', '', '', 'There is some literature on procedure acquisition such as the LISP synthesis work described in #TAUTHOR_TAG and the PROLOG synthesis method of #AUTHOR_TAG .']","['', '', '', 'There is some literature on procedure acquisition such as the LISP synthesis work described in #TAUTHOR_TAG and the PROLOG synthesis method of #AUTHOR_TAG .']",1
"['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al.1980 , #TAUTHOR_TAG , Lea 1980 , Lower and Reddy 980 ,ress 8 , 96 ,', '', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , #TAUTHOR_TAG , Lea 1980 , Lowerre and Reddy 1980 , Medress , 1976 ,', '', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al.1980 , #TAUTHOR_TAG , Lea 1980 , Lower and Reddy 1980 ,ress 1980 ,dy 1976 ,', '', '', '']","['A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , #TAUTHOR_TAG , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .', '', '', '']",1
"['We to employ LDO as the machine readable source to aid the development of ax this dictionary several properties which make it uniquely appropriate for use as the knowledge base of a natural language processing system.', ""amount of information concerningras, noun compounds and idioms, the individual, collocational and semantic codes for the entries and the consistent of a 'core' voc in the words."", '( #AUTHOR_TAG contains further description and of L', 'In this paper we focus on the exploitation of the LDOCE grammar coding system ; #AUTHOR_TAG and #TAUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE .']","['We to employ LDOCE as the machine readable source to aid the development of a this dictionary several properties which make it uniquely appropriate for use as the knowledge base of a natural language processing system.', ""amount of information concerning noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent of a 'core' vocabulary in the words dictionary."", '( #AUTHOR_TAG contains further description and of', 'In this paper we focus on the exploitation of the LDOCE grammar coding system ; #AUTHOR_TAG and #TAUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE .']","['We chose to employ LDO as the machine readable source to aid the development of this dictionary several properties which make it uniquely appropriate for use as the core knowledge base of a natural language processing system.', ""of information concerningras, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a 'core' voc in defining the words"", '( #AUTHOR_TAG contains further description and of L', 'In this paper we focus on the exploitation of the LDOCE grammar coding system ; #AUTHOR_TAG and #TAUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE .']","['We chose to employ LDOCE as the machine readable source to aid the development of a substantial lexicon because this dictionary has several properties which make it uniquely appropriate for use as the core knowledge base of a natural language processing system.', ""Most prominent among these are the rich grammatical subcategorisations of the 60,000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", '( #AUTHOR_TAG contains further description and discussion of LDOCE.)', 'In this paper we focus on the exploitation of the LDOCE grammar coding system ; #AUTHOR_TAG and #TAUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE .']",0
"['to relations', '', ' #TAUTHOR_TAG and #AUTHOR_TAG provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .', ' #AUTHOR_TAG comprehensively compares different approaches to complementation grammatical theory a touch against which the L scheme be evaluated.']","['to relations', '', ' #TAUTHOR_TAG and #AUTHOR_TAG provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .', ' #AUTHOR_TAG comprehensively compares different approaches to complementation grammatical theory a touchstone against which the scheme be evaluated.']","['toantic relations', '', ' #TAUTHOR_TAG and #AUTHOR_TAG provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .', ' #AUTHOR_TAG comprehensively compares different approaches to complementation grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated.']","['', '', ' #TAUTHOR_TAG and #AUTHOR_TAG provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .', ' #AUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated.']",0
"['Recent developments in lingu and especially on grammatical theory', '', '', 'research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['Recent developments in and especially on grammatical theory', '', '', 'research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['Recent developments in lingu and especially on grammat', '', '', 'The research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['', '', '', 'The research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']",0
"['lispified L retains the structure the typeset tape', 'each of these fields requires further decoding and restructuring to provide client programs with easy access to the information they require ( see #TAUTHOR_TAG for further discussion ) .', 'the form on the typesetting tape are crucial since they provide clues to the correct structure of this information', 'word are largely defined in terms of word core voc, words ( defined terms this', '', 'the definition of rivet as verb includes the nIVET', 'homograph', '', '', '']","['lispified retains the structure the typesetting tape', 'each of these fields requires further decoding and restructuring to provide client programs with easy access to the information they require ( see #TAUTHOR_TAG for further discussion ) .', 'the formatting on the typesetting tape are crucial since they provide clues to the correct structure of this information.', 'word are largely defined in terms of word core vocabulary, words defined terms this', '', 'the definition of rivet as verb includes the noun ""RIVET', 'homograph;', '', '', '']","['The lispified LDOCE file retains the broad structure the typesetting tape', 'each of these fields requires further decoding and restructuring to provide client programs with easy access to the information they require ( see #TAUTHOR_TAG for further discussion ) .', 'the formatting codes on the typesetting tape are crucial since they provide clues to the correct structure of this information.', 'are largely defined in terms of other words ( defined elsewhere terms', '', 'the definition of rivet as verb includes the noun definitionIVET', 'homograph', '', '', '']","['', 'However , each of these fields requires further decoding and restructuring to provide client programs with easy access to the information they require ( see #TAUTHOR_TAG for further discussion ) .', 'For this purpose the formatting codes on the typesetting tape are crucial since they provide clues to the correct structure of this information.', '', '', '', '', '', '', '']",0
"['capital to sem relations', '', '', ' #TAUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated .']","['capital to semantic relations', '', '', ' #TAUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated .']","['capital letters to semantic relations', '', '', ' #TAUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated .']","['', '', '', ' #TAUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated .']",1
"['Clearly, there are other syntactic and semantic tests for this distinction, (see eg. #TAUTHOR_TAG :472 ), but these are the only ones which are explicit in the LDOCE coding system.']","['Clearly, there are other syntactic and semantic tests for this distinction, (see eg. #TAUTHOR_TAG :472 ), but these are the only ones which are explicit in the LDOCE coding system.']","['Clearly, there are other syntactic and semantic tests for this distinction, (see eg. #TAUTHOR_TAG :472 ), but these are the only ones which are explicit in the LDOCE coding system.']","['Clearly, there are other syntactic and semantic tests for this distinction, (see eg. #TAUTHOR_TAG :472 ), but these are the only ones which are explicit in the LDOCE coding system.']",0
"['occurred wide', '', '', '', '', 'x even those employ very comprehensive grammars.', 'consult relatively smallxicons, typically generated by hand', 'Two exceptions to this generalisation are the Linguistic String Project #AUTHOR_TAG and the IBM CRITIQUE ( formerly EPISTLE ) Project #TAUTHOR_TAG ; the former employs a dictionary of approximately 10,000 words , most of which are specialist medical terms , the latter has well over 100,000 entries , gathered from machine readable sources .', 'to substantialx from machine read', '', '']","['occurred wide', '', '', '', '', 'even those employ very comprehensive grammars', 'consult relatively small lexicons, typically generated by hand.', 'Two exceptions to this generalisation are the Linguistic String Project #AUTHOR_TAG and the IBM CRITIQUE ( formerly EPISTLE ) Project #TAUTHOR_TAG ; the former employs a dictionary of approximately 10,000 words , most of which are specialist medical terms , the latter has well over 100,000 entries , gathered from machine readable sources .', 'to substantial from machine readable', '', '']","['has occurred', '', '', '', '', 'even those employ very comprehensive grammars.', ' #AUTHOR_TAG consult relatively small lexicons, typically generated by hand', 'Two exceptions to this generalisation are the Linguistic String Project #AUTHOR_TAG and the IBM CRITIQUE ( formerly EPISTLE ) Project #TAUTHOR_TAG ; the former employs a dictionary of approximately 10,000 words , most of which are specialist medical terms , the latter has well over 100,000 entries , gathered from machine readable sources .', 'to substantial lexicons from machine read', '', '']","['', '', '', '', '', '', ' #AUTHOR_TAG consult relatively small lexicons, typically generated by hand.', 'Two exceptions to this generalisation are the Linguistic String Project #AUTHOR_TAG and the IBM CRITIQUE ( formerly EPISTLE ) Project #TAUTHOR_TAG ; the former employs a dictionary of approximately 10,000 words , most of which are specialist medical terms , the latter has well over 100,000 entries , gathered from machine readable sources .', '', '', '']",1
"['gram a a relatively theory sense this further a parsing', '', '', '', '', 'No attempt has been made to map any closed class entries from LDOCE , as a 3,000 word lexicon containing most closed class items has been developed independently by one of the groups collaborating with us to develop the general purpose morphological and syntactic analyser ( see the Introduction and #TAUTHOR_TAG .']","['grammar a a relatively theory sense this further a parsing', '', '', '', '', 'No attempt has been made to map any closed class entries from LDOCE , as a 3,000 word lexicon containing most closed class items has been developed independently by one of the groups collaborating with us to develop the general purpose morphological and syntactic analyser ( see the Introduction and #TAUTHOR_TAG .']","['a parser a relatively theory neutral representation the sense this representation a format', '', '', '', '', 'No attempt has been made to map any closed class entries from LDOCE , as a 3,000 word lexicon containing most closed class items has been developed independently by one of the groups collaborating with us to develop the general purpose morphological and syntactic analyser ( see the Introduction and #TAUTHOR_TAG .']","['', '', '', '', '', 'No attempt has been made to map any closed class entries from LDOCE , as a 3,000 word lexicon containing most closed class items has been developed independently by one of the groups collaborating with us to develop the general purpose morphological and syntactic analyser ( see the Introduction and #TAUTHOR_TAG .']",0
"['We to employ LDO as the machine readable to aid the development of ax this properties make it uniquely for use as the base of a natural language processing system', ""the large amount of information concerning phrasalbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", '( #AUTHOR_TAG contains further description and discussion of LDO.)', 'In this paper we focus on the exploitation of the LDOCE grammar coding system ; #TAUTHOR_TAG and #AUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE .']","['We to employ LDOCE as the machine readable to aid the development of a this properties make it uniquely for use as the base of a natural language processing system.', ""the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", '( #AUTHOR_TAG contains further description and discussion of LDOCE.)', 'In this paper we focus on the exploitation of the LDOCE grammar coding system ; #TAUTHOR_TAG and #AUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE .']","['We chose to employ LDO as the machine readable source to aid the development of this dictionary several properties make it uniquely for use as the core knowledge base of a natural language processing system.', ""the large amount of information concerning phrasalbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", '( #AUTHOR_TAG contains further description and discussion of LDO.)', 'In this paper we focus on the exploitation of the LDOCE grammar coding system ; #TAUTHOR_TAG and #AUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE .']","['We chose to employ LDOCE as the machine readable source to aid the development of a substantial lexicon because this dictionary has several properties which make it uniquely appropriate for use as the core knowledge base of a natural language processing system.', ""Most prominent among these are the rich grammatical subcategorisations of the 60,000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", '( #AUTHOR_TAG contains further description and discussion of LDOCE.)', 'In this paper we focus on the exploitation of the LDOCE grammar coding system ; #TAUTHOR_TAG and #AUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE .']",0
"['This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic checking procedure is attempted (see #AUTHOR_TAG for further comment).', 'One approach to this problem is that taken by the ASCOT project #TAUTHOR_TAG .', ', a new lexicon is being manually derived from LDOCE.', 'The for thex a', 'the of codes for problematic or erroneously labelled words is being corrected tox', '']","['This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic checking procedure is attempted (see #AUTHOR_TAG for further comment).', 'One approach to this problem is that taken by the ASCOT project #TAUTHOR_TAG .', 'project, a new lexicon is being manually derived from LDOCE.', 'The for the a', 'the of codes for problematic or erroneously labelled words is being corrected to', '']","['This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic checking procedure is attempted (see #AUTHOR_TAG for further comment).', 'One approach to this problem is that taken by the ASCOT project #TAUTHOR_TAG .', 'a new lexicon is being manually derived from LDOCE.', 'for a', 'of codes for problematic or erroneously labelled words is being corrected to', '']","['This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic checking procedure is attempted (see #AUTHOR_TAG for further comment).', 'One approach to this problem is that taken by the ASCOT project #TAUTHOR_TAG .', 'In this project, a new lexicon is being manually derived from LDOCE.', '', 'More importantly, the assignment of codes for problematic or erroneously labelled words is being corrected in an attempt to make the resulting lexicon more appropriate for automated analysis.', '']",0
"['The output of the transformation program can be used to derive entries which are appropriate for particular grammatical formalisms.', 'To demonstrate that this is possible we have implemented a system which constructs dictionary entries for the PATR-II system #TAUTHOR_TAG and references therein ) .', 'PATR-II was chosen because it has been reimplemented in Cambridge and was therefore, available; however, the task would be nearly identical if we were constructing entries for a system based on GPSG, FUG or LFG.', '']","['The output of the transformation program can be used to derive entries which are appropriate for particular grammatical formalisms.', 'To demonstrate that this is possible we have implemented a system which constructs dictionary entries for the PATR-II system #TAUTHOR_TAG and references therein ) .', 'PATR-II was chosen because it has been reimplemented in Cambridge and was therefore, available; however, the task would be nearly identical if we were constructing entries for a system based on GPSG, FUG or LFG.', '']","['The output of the transformation program can be used to derive entries which are appropriate for particular grammatical formalisms.', 'To demonstrate that this is possible we have implemented a system which constructs dictionary entries for the PATR-II system #TAUTHOR_TAG and references therein ) .', 'PATR-II was chosen because it has been reimplemented in Cambridge and was therefore, available; however, the task would be nearly identical if we were constructing entries for a system based on GPSG, FUG or LFG.', '']","['The output of the transformation program can be used to derive entries which are appropriate for particular grammatical formalisms.', 'To demonstrate that this is possible we have implemented a system which constructs dictionary entries for the PATR-II system #TAUTHOR_TAG and references therein ) .', 'PATR-II was chosen because it has been reimplemented in Cambridge and was therefore, available; however, the task would be nearly identical if we were constructing entries for a system based on GPSG, FUG or LFG.', '']",5
"['This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic checking procedure is attempted (see #AUTHOR_TAG for further comment).', 'One approach to this problem is that taken by the ASCOT project #TAUTHOR_TAG .', ', a new lexicon is being manually derived from LDOCE.', 'The for thex a', 'the of codes for problematic or erroneously labelled words is being corrected tox', '']","['This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic checking procedure is attempted (see #AUTHOR_TAG for further comment).', 'One approach to this problem is that taken by the ASCOT project #TAUTHOR_TAG .', 'project, a new lexicon is being manually derived from LDOCE.', 'The for the a', 'the of codes for problematic or erroneously labelled words is being corrected to', '']","['This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic checking procedure is attempted (see #AUTHOR_TAG for further comment).', 'One approach to this problem is that taken by the ASCOT project #TAUTHOR_TAG .', 'a new lexicon is being manually derived from LDOCE.', 'for a', 'of codes for problematic or erroneously labelled words is being corrected to', '']","['This type of error and inconsistency arises because grammatical codes are constructed by hand and no automatic checking procedure is attempted (see #AUTHOR_TAG for further comment).', 'One approach to this problem is that taken by the ASCOT project #TAUTHOR_TAG .', 'In this project, a new lexicon is being manually derived from LDOCE.', '', 'More importantly, the assignment of codes for problematic or erroneously labelled words is being corrected in an attempt to make the resulting lexicon more appropriate for automated analysis.', '']",0
"['occurred wide', '', '', '', '', 'x those employ very comprehensive grammars.', 'consult relatively smallxicons, typically generated hand', 'Two exceptions to this generalisation are the Linguistic String Project #TAUTHOR_TAG and the IBM CRITIQUE ( formerly EPISTLE ) Project #AUTHOR_TAG ; the former emplo a dictionary of 1 , most medical', '', '', '']","['occurred wide', '', '', '', '', 'those employ very comprehensive grammars', 'consult relatively small lexicons, typically generated hand.', 'Two exceptions to this generalisation are the Linguistic String Project #TAUTHOR_TAG and the IBM CRITIQUE ( formerly EPISTLE ) Project #AUTHOR_TAG ; the former employs a dictionary of , most medical', '', '', '']","['has occurred', '', '', '', '', 'those employ very comprehensive grammars.', ' #AUTHOR_TAG consult relatively small lexicons, typically generated hand', 'Two exceptions to this generalisation are the Linguistic String Project #TAUTHOR_TAG and the IBM CRITIQUE ( formerly EPISTLE ) Project #AUTHOR_TAG ; the former emplo a dictionary of , most', '', '', '']","['', '', '', '', '', '', ' #AUTHOR_TAG consult relatively small lexicons, typically generated by hand.', '', '', '', '']",1
"['ational read in of are', '', 'marked', '', '', 'is not particularly well suited for interfacing to complex , structured objects , and it was not our intention to embark on a major effort involving the development of a formal model of a dictionary ( of the style described in , eg. , #TAUTHOR_TAG ;']","['computational readable in of are', '', 'marked', '', '', 'is not particularly well suited for interfacing to complex , structured objects , and it was not our intention to embark on a major effort involving the development of a formal model of a dictionary ( of the style described in , eg. , #TAUTHOR_TAG ;']","['read in of are', '', 'marked', '', '', 'is not particularly well suited for interfacing to complex , structured objects , and it was not our intention to embark on a major effort involving the development of a formal model of a dictionary ( of the style described in , eg. , #TAUTHOR_TAG ;']","['', '', '', '', '', 'Lisp is not particularly well suited for interfacing to complex , structured objects , and it was not our intention to embark on a major effort involving the development of a formal model of a dictionary ( of the style described in , eg. , #TAUTHOR_TAG ; on the other hand a method of access was clearly required , which was flexible enough to support a range of applications intending to make use of the LDOCE tape .']",0
"['The four verbs which are misclassified as Object Equi and which do not have T5 anywhere in their entries are elect, love, represent and require.', 'None of these verbs sents and therefore to beex to our Object Raising', 'In addition , #TAUTHOR_TAG note that our Object Raising rule would assign mean to this category incorrectly .', 'Mean is assigned both a V3 and a T5 category in the code field associated with sense 2 (i.e.', '""intend""), however, when it is used in this sense it must be treated as an Object Equi verb.']","['The four verbs which are misclassified as Object Equi and which do not have T5 anywhere in their entries are elect, love, represent and require.', 'None of these verbs sentential complements and therefore to be to our Object Raising', 'In addition , #TAUTHOR_TAG note that our Object Raising rule would assign mean to this category incorrectly .', 'Mean is assigned both a V3 and a T5 category in the code field associated with sense 2 (i.e.', '""intend""), however, when it is used in this sense it must be treated as an Object Equi verb.']","['The four verbs which are misclassified as Object Equi and which do not have T5 codes anywhere in their entries are elect, love, represent and require.', 'None of these verbs sent and therefore to beex to our Object Raising rule.', 'In addition , #TAUTHOR_TAG note that our Object Raising rule would assign mean to this category incorrectly .', 'Mean is assigned both a V3 and a T5 category in the code field associated with sense 2 (i.e.', '""intend""), however, when it is used in this sense it must be treated as an Object Equi verb.']","['The four verbs which are misclassified as Object Equi and which do not have T5 codes anywhere in their entries are elect, love, represent and require.', 'None of these verbs take sentential complements and therefore they appear to be counterexamples to our Object Raising rule.', 'In addition , #TAUTHOR_TAG note that our Object Raising rule would assign mean to this category incorrectly .', 'Mean is assigned both a V3 and a T5 category in the code field associated with sense 2 (i.e.', '""intend""), however, when it is used in this sense it must be treated as an Object Equi verb.']",1
"['occurred wideaurus', '', '', '', '', '', '', '', 'In addition , there are a number of projects under way to develop substantial lexicons from machine readable sources ( see #TAUTHOR_TAG for details ) .', 'xicons', '']","['occurred wide', '', '', '', '', '', '', '', 'In addition , there are a number of projects under way to develop substantial lexicons from machine readable sources ( see #TAUTHOR_TAG for details ) .', '', '']","['has occurred', '', '', '', '', '', '', '', 'In addition , there are a number of projects under way to develop substantial lexicons from machine readable sources ( see #TAUTHOR_TAG for details ) .', '', '']","['', '', '', '', '', '', '', '', 'In addition , there are a number of projects under way to develop substantial lexicons from machine readable sources ( see #TAUTHOR_TAG for details ) .', '', '']",0
"['Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) #AUTHOR_TAG , Lexical Functional Grammar ( LFG ) #TAUTHOR_TAG -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) #AUTHOR_TAG a ) , PATR-II #AUTHOR_TAG -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .', 'These developments also emphasise that if natural language processing systems are to be able to handle the grammatical and semantic idiosyncracies of individualxical items elegantly and efficiently, then the lexicon must be a central component of the parsing system', '', '', '']","['Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) #AUTHOR_TAG , Lexical Functional Grammar ( LFG ) #TAUTHOR_TAG -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) #AUTHOR_TAG a ) , PATR-II #AUTHOR_TAG -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .', 'These developments also emphasise that if natural language processing systems are to be able to handle the grammatical and semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central component of the parsing system.', '', '', '']","['Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) #AUTHOR_TAG , Lexical Functional Grammar ( LFG ) #TAUTHOR_TAG -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) #AUTHOR_TAG a ) , PATR-II #AUTHOR_TAG -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .', 'These developments also emphasise that if natural language processing systems are to be able to handle the grammatical and semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central component of the parsing system.', '', '', '']","['Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) #AUTHOR_TAG , Lexical Functional Grammar ( LFG ) #TAUTHOR_TAG -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) #AUTHOR_TAG a ) , PATR-II #AUTHOR_TAG -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .', 'These developments also emphasise that if natural language processing systems are to be able to handle the grammatical and semantic idiosyncracies of individual lexical items elegantly and efficiently, then the lexicon must be a central component of the parsing system.', '', '', '']",0
"['contains', 'highlights a deficiency in the LCE coding since prefer occurs much more naturally with a sentential if it collocates with a modal such as ""w', 'This deficiency is rectified in the verb classification system employed by #TAUTHOR_TAG in the Brandeis verb catalogue .']","['contains', 'highlights a deficiency in the LDOCE coding since prefer occurs much more naturally with a sentential if it collocates with a modal such as ""would"".', 'This deficiency is rectified in the verb classification system employed by #TAUTHOR_TAG in the Brandeis verb catalogue .']","['contains', 'highlights a deficiency in the LDOCE coding system since prefer occurs much more naturally with a sentential complement if it collocates with a modal such as ""w', 'This deficiency is rectified in the verb classification system employed by #TAUTHOR_TAG in the Brandeis verb catalogue .']","['', '', 'This deficiency is rectified in the verb classification system employed by #TAUTHOR_TAG in the Brandeis verb catalogue .']",1
"['Recent developments in lingu and especially on grammatical theory', '', '', 'research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['Recent developments in and especially on grammatical theory', '', '', 'research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['Recent developments in lingu and especially on grammat', '', '', 'The research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['', '', '', 'The research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']",0
"['There are many more distinctions which are conveyed by the conjunction of grammar codes and word qualifiers ( see #TAUTHOR_TAG , for further details ) .', 'exploiting this information to the be a non-t task, because it would require accessing the relevant knowledge about the words contained in the qualifier fields from their LDOCE entries.']","['There are many more distinctions which are conveyed by the conjunction of grammar codes and word qualifiers ( see #TAUTHOR_TAG , for further details ) .', 'exploiting this information to the be a non-trivial task, because it would require accessing the relevant knowledge about the words contained in the qualifier fields from their LDOCE entries.']","['There are many more distinctions which are conveyed by the conjunction of grammar codes and word qualifiers ( see #TAUTHOR_TAG , for further details ) .', ', exploiting this information to the would be a non-trivial task, because it would require accessing the relevant knowledge about the words contained in the qualifier fields from their LDOCE entries.']","['There are many more distinctions which are conveyed by the conjunction of grammar codes and word qualifiers ( see #TAUTHOR_TAG , for further details ) .', 'However, exploiting this information to the full would be a non-trivial task, because it would require accessing the relevant knowledge about the words contained in the qualifier fields from their LDOCE entries.']",0
"['', '', '', '', 'In the longer term, therefore, the automatic construction of dictionaries for natural language processing systems may need to be based on techniques for the automatic analysis of large corpora (eg. #TAUTHOR_TAG .', 'in this sophisticated dictionary']","['', '', '', '', 'In the longer term, therefore, the automatic construction of dictionaries for natural language processing systems may need to be based on techniques for the automatic analysis of large corpora (eg. #TAUTHOR_TAG .', 'in this sophisticated dictionary']","['', '', '', '', 'In the longer term, therefore, the automatic construction of dictionaries for natural language processing systems may need to be based on techniques for the automatic analysis of large corpora (eg. #TAUTHOR_TAG .', 'in this paper sophisticated']","['', '', '', '', 'In the longer term, therefore, the automatic construction of dictionaries for natural language processing systems may need to be based on techniques for the automatic analysis of large corpora (eg. #TAUTHOR_TAG .', '']",3
"['occurred wide,', '', '', '', '', 'Few established parsing systems have substantialxicons and even those which employ very comprehensive grammars (eg.', ' #TAUTHOR_TAG consult relatively small lexicons , typically generated by hand .', 'isation', '', '', '']","['occurred wide researchers,', '', '', '', '', 'Few established parsing systems have substantial lexicons and even those which employ very comprehensive grammars (eg.', ' #TAUTHOR_TAG consult relatively small lexicons , typically generated by hand .', 'generalisation', '', '', '']","['has occurred,', '', '', '', '', 'Few established parsing systems have substantial lexicons and even those which employ very comprehensive grammars (eg.', ' #TAUTHOR_TAG consult relatively small lexicons , typically generated by hand .', '', '', '', '']","['', '', '', '', '', 'Few established parsing systems have substantial lexicons and even those which employ very comprehensive grammars (eg.', ' #TAUTHOR_TAG consult relatively small lexicons , typically generated by hand .', '', '', '', '']",1
"['', '', '', '', '', '', 'Michiels proposed rules for doing this for infinitive complement codes ; however there seems to be no principled reason not to extend this approach to computing the underlying relations in other types of VP as well as in cases of NP , AP and PP predication ( see #TAUTHOR_TAG , for further discussion ) .']","['', '', '', '', '', '', 'Michiels proposed rules for doing this for infinitive complement codes ; however there seems to be no principled reason not to extend this approach to computing the underlying relations in other types of VP as well as in cases of NP , AP and PP predication ( see #TAUTHOR_TAG , for further discussion ) .']","['', '', '', '', '', '', 'Michiels proposed rules for doing this for infinitive complement codes ; however there seems to be no principled reason not to extend this approach to computing the underlying relations in other types of VP as well as in cases of NP , AP and PP predication ( see #TAUTHOR_TAG , for further discussion ) .']","['', '', '', '', '', '', 'Michiels proposed rules for doing this for infinitive complement codes ; however there seems to be no principled reason not to extend this approach to computing the underlying relations in other types of VP as well as in cases of NP , AP and PP predication ( see #TAUTHOR_TAG , for further discussion ) .']",0
"['We chose to employ LDO as the machine readable source to aid the development of a substantialxicon because this dictionary has several properties which make it uniquely appropriate for use as the knowledge base of a natural language processing system.', ""prominent these the rich gramical subcategorisations of the 6000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", ' #TAUTHOR_TAG contains further description and discussion of LDOCE .', 'In this paper we focus on the exploitation of the LDOCE grammar coding system; #AUTHOR_TAG in utilising different types of information available in LDO']","['We chose to employ LDOCE as the machine readable source to aid the development of a substantial lexicon because this dictionary has several properties which make it uniquely appropriate for use as the knowledge base of a natural language processing system.', ""prominent these the rich grammatical subcategorisations of the 60,000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", ' #TAUTHOR_TAG contains further description and discussion of LDOCE .', 'In this paper we focus on the exploitation of the LDOCE grammar coding system; #AUTHOR_TAG in utilising different types of information available in LDOCE.']","['We chose to employ LDO as the machine readable source to aid the development of a substantial lexicon because this dictionary has several properties which make it uniquely appropriate for use as the core knowledge base of a natural language processing system.', ""prominent these the rich grammatical subcategorisations of the 6000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", ' #TAUTHOR_TAG contains further description and discussion of LDOCE .', 'In this paper we focus on the exploitation of the LDOCE grammar coding system; #AUTHOR_TAG in utilising different types of information available in LDO']","['We chose to employ LDOCE as the machine readable source to aid the development of a substantial lexicon because this dictionary has several properties which make it uniquely appropriate for use as the core knowledge base of a natural language processing system.', ""Most prominent among these are the rich grammatical subcategorisations of the 60,000 entries, the large amount of information concerning phrasal verbs, noun compounds and idioms, the individual subject, collocational and semantic codes for the entries and the consistent use of a controlled 'core' vocabulary in defining the words throughout the dictionary."", ' #TAUTHOR_TAG contains further description and discussion of LDOCE . )', 'In this paper we focus on the exploitation of the LDOCE grammar coding system; #AUTHOR_TAG and #AUTHOR_TAG describe further research in Cambridge utilising different types of information available in LDOCE.']",0
"['', '', '', 'Expanding on a suggestion of #TAUTHOR_TAG , we classify verbs as Subject Equi , Object Equi , Subject Raising or Object Raising for each sense which has a predicate complement code associated with it .', 'These terms, which derive from Transformational Grammar, are used as convenient labels for what we regard as a semantic distinction', '', '']","['', '', '', 'Expanding on a suggestion of #TAUTHOR_TAG , we classify verbs as Subject Equi , Object Equi , Subject Raising or Object Raising for each sense which has a predicate complement code associated with it .', 'These terms, which derive from Transformational Grammar, are used as convenient labels for what we regard as a semantic distinction;', '', '']","['', '', '', 'Expanding on a suggestion of #TAUTHOR_TAG , we classify verbs as Subject Equi , Object Equi , Subject Raising or Object Raising for each sense which has a predicate complement code associated with it .', 'These terms, which derive from Transformational Grammar, are used as convenient labels for what we regard as a semantic distinction;', '', '']","['', '', '', 'Expanding on a suggestion of #TAUTHOR_TAG , we classify verbs as Subject Equi , Object Equi , Subject Raising or Object Raising for each sense which has a predicate complement code associated with it .', '', '', '']",2
"['From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes.', 'In addition to headwords , dictionary search through the pronunciation field is available ; #TAUTHOR_TAG has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure #AUTHOR_TAG .', '', '']","['From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes.', 'In addition to headwords , dictionary search through the pronunciation field is available ; #TAUTHOR_TAG has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure #AUTHOR_TAG .', '', '']","['From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes.', 'In addition to headwords , dictionary search through the pronunciation field is available ; #TAUTHOR_TAG has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure #AUTHOR_TAG .', '', '']","['From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes.', 'In addition to headwords , dictionary search through the pronunciation field is available ; #TAUTHOR_TAG has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure #AUTHOR_TAG .', '', '']",5
"['Once the grammar codes have been restructured, it still remains to be shown that the information they encode is going to be of some utility for natural language processing.', 'The grammar code system used in LDOCE is based quite closely on the descriptive grammatical framework of #TAUTHOR_TAG , 1985 ) .', 'The are doub artic relations frames', '', '']","['Once the grammar codes have been restructured, it still remains to be shown that the information they encode is going to be of some utility for natural language processing.', 'The grammar code system used in LDOCE is based quite closely on the descriptive grammatical framework of #TAUTHOR_TAG , 1985 ) .', 'The are doubly relations frames', '', '']","['Once the grammar codes have been restructured, it still remains to be shown that the information they encode is going to be of some utility for natural language processing.', 'The grammar code system used in LDOCE is based quite closely on the descriptive grammatical framework of #TAUTHOR_TAG , 1985 ) .', 'The codes are doubly articisation frames', '', '']","['Once the grammar codes have been restructured, it still remains to be shown that the information they encode is going to be of some utility for natural language processing.', 'The grammar code system used in LDOCE is based quite closely on the descriptive grammatical framework of #TAUTHOR_TAG , 1985 ) .', '', '', '']",2
"['we were targeting all envisaged access routes from LDOCE to systems implemented in Lisp', 'Our task was made possible by the fact that while far from being a database in the accepted sense of the word , the LDOCE typesetting tape is the only truly computerised dictionary of English #TAUTHOR_TAG .']","['we were targeting all envisaged access routes from LDOCE to systems implemented in Lisp,', 'Our task was made possible by the fact that while far from being a database in the accepted sense of the word , the LDOCE typesetting tape is the only truly computerised dictionary of English #TAUTHOR_TAG .']","['we were targeting all envisaged access routes from LDOCE to systems implemented in Lisp', 'Our task was made possible by the fact that while far from being a database in the accepted sense of the word , the LDOCE typesetting tape is the only truly computerised dictionary of English #TAUTHOR_TAG .']","['', 'Our task was made possible by the fact that while far from being a database in the accepted sense of the word , the LDOCE typesetting tape is the only truly computerised dictionary of English #TAUTHOR_TAG .']",0
"['', '', ' #AUTHOR_TAG and #TAUTHOR_TAG provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .', ' #AUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the L scheme can be evaluated.']","['', '', ' #AUTHOR_TAG and #TAUTHOR_TAG provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .', ' #AUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the scheme can be evaluated.']","['', '', ' #AUTHOR_TAG and #TAUTHOR_TAG provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .', ' #AUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated.']","['', '', ' #AUTHOR_TAG and #TAUTHOR_TAG provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .', ' #AUTHOR_TAG comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated.']",0
"['Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) #AUTHOR_TAG , Lexical Functional Grammar ( LFG ) #AUTHOR_TAG -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) #AUTHOR_TAG a ) , PATR-II #TAUTHOR_TAG -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .', 'These developments also emphasise that if natural language processing systems are to be able to handle thematical and semantic idyncrac eleg', '', '', '']","['Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) #AUTHOR_TAG , Lexical Functional Grammar ( LFG ) #AUTHOR_TAG -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) #AUTHOR_TAG a ) , PATR-II #TAUTHOR_TAG -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .', 'These developments also emphasise that if natural language processing systems are to be able to handle the grammatical and semantic idiosyncracies elegantly', '', '', '']","['Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) #AUTHOR_TAG , Lexical Functional Grammar ( LFG ) #AUTHOR_TAG -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) #AUTHOR_TAG a ) , PATR-II #TAUTHOR_TAG -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .', 'These developments also emphasise that if natural language processing systems are to be able to handle thematical and semantic idiosyncracies eleg', '', '', '']","['Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) #AUTHOR_TAG , Lexical Functional Grammar ( LFG ) #AUTHOR_TAG -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) #AUTHOR_TAG a ) , PATR-II #TAUTHOR_TAG -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .', '', '', '', '']",0
"['From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes', 'dictionary search through the pronunciation field is available ; #AUTHOR_TAG has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure #TAUTHOR_TAG .', '', '']","['From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes.', 'dictionary search through the pronunciation field is available ; #AUTHOR_TAG has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure #TAUTHOR_TAG .', '', '']","['From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes.', 'dictionary search through the pronunciation field is available ; #AUTHOR_TAG has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure #TAUTHOR_TAG .', '', '']","['From the master LDOCE file, we have computed alternative indexing information, which allows access into the dictionary via different routes.', 'In addition to headwords , dictionary search through the pronunciation field is available ; #AUTHOR_TAG has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure #TAUTHOR_TAG .', '', '']",0
"['', '4 illustrates the grammar code field for the third word sense of the verb believe as it appears in the published dictionary, on the typesetting tape and after restructuring.', 'Figure 4 L provides considerably syntactic.', 'The Longman lexicographers have developed a grammar coding system capable of representing in compact form a nontrivial amount of information , usually to be found only in large descriptive grammars of English ( such as #TAUTHOR_TAG .', 'gram behaviour', '', '']","['', '4 illustrates the grammar code field for the third word sense of the verb believe as it appears in the published dictionary, on the typesetting tape and after restructuring.', 'Figure 4 provides considerably syntactic dictionary.', 'The Longman lexicographers have developed a grammar coding system capable of representing in compact form a nontrivial amount of information , usually to be found only in large descriptive grammars of English ( such as #TAUTHOR_TAG .', 'grammar behaviour', '', '']","['', 'illustrates the grammar code field for the third word sense of the verb believe as it appears in the published dictionary, on the typesetting tape and after restructuring.', 'Figure 4 L provides considerably more syntactic information', 'The Longman lexicographers have developed a grammar coding system capable of representing in compact form a nontrivial amount of information , usually to be found only in large descriptive grammars of English ( such as #TAUTHOR_TAG .', 'behaviour', '', '']","['', 'Figure 4 illustrates the grammar code field for the third word sense of the verb believe as it appears in the published dictionary, on the typesetting tape and after restructuring.', 'Figure 4 LDOCE provides considerably more syntactic information than a traditional dictionary.', 'The Longman lexicographers have developed a grammar coding system capable of representing in compact form a nontrivial amount of information , usually to be found only in large descriptive grammars of English ( such as #TAUTHOR_TAG .', '', '', '']",0
"['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen- #AUTHOR_TAG Grainger , et al. , 1991 ; #TAUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo- cous.', 'for', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen- #AUTHOR_TAG Grainger , et al. , 1991 ; #TAUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', 'for', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen- #AUTHOR_TAG Grainger , et al. , 1991 ; #TAUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-an cousins.', 'for', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen- #AUTHOR_TAG Grainger , et al. , 1991 ; #TAUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '', '', '']",0
"['', '', '', '', '', 'transl equival indirect "" confused coll', 'Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based #TAUTHOR_TAG c ) .', 'The majority of indirect associations can be filtered out by a simple competition heuristic: several word tokens in the co which equivalence', '']","['', '', '', '', '', 'translational equivalence indirect ""a confused', 'Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based #TAUTHOR_TAG c ) .', 'The majority of indirect associations can be filtered out by a simple competition heuristic: several word tokens in the which equivalence', '']","['', '', '', '', '', 'transl indirect associations be confused coll', 'Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based #TAUTHOR_TAG c ) .', 'The majority of indirect associations can be filtered out by a simple competition heuristic: Whenever several word tokens in whichational equivalence', '']","['', '', '', '', '', '', 'Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based #TAUTHOR_TAG c ) .', '', '']",0
"['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', ', the models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', 'However, the models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '', '']",0
"['associ', '', '', '', 'Figure .', ""Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates '' #TAUTHOR_TAG ."", 'Fortunately, indirect are usually not difficult to identify because they tend to be weaker than the direct on which are based #AUTHOR_TAG', 'The of indirect equival', '']","['', '', '', '', 'Figure 1 uk.', ""Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates '' #TAUTHOR_TAG ."", 'Fortunately, indirect are usually not difficult to identify, because they tend to be weaker than the direct on which are based #AUTHOR_TAG', 'The of indirect equivalence', '']","['', '', '', '', 'Figure 1.', ""Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates '' #TAUTHOR_TAG ."", 'Fortunately, indirect associations are usually not difficult to identify because they tend to be weaker than the direct associations on which they are based', 'The majority of indirect associations', '']","['', '', '', '', '', ""Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates '' #TAUTHOR_TAG ."", 'Fortunately, indirect associations are usually not difficult to identify, because they tend to be weaker than the direct associations on which they are based #AUTHOR_TAG c).', '', '']",0
"['researchers at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply', 'Table mult ""ummy"" the WebCh , certain machine-assisted translation tools (e.g. #TAUTHOR_TAG b ) ), concordancing for bilingualxicography #AUTHOR_TAG , computer- assisted language learning, corpus linguistics (Mby.8), and cross (']","['researchers at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', 'Table ""crummy"" the Web , certain machine-assisted translation tools (e.g. #TAUTHOR_TAG b ) ), concordancing for bilingual lexicography #AUTHOR_TAG , computer- assisted language learning, corpus linguistics (Melby. and']","['at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply', '""ummy"" MTCh , certain machine-assisted translation tools (e.g. #TAUTHOR_TAG b ) ), concordancing for bilingual lexicography #AUTHOR_TAG , computer- assisted language learning, corpus linguistics (Mby.8), and cross (']","['Over the past decade, researchers at IBM have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', '']",0
"['some have tried is how to extract such accurate from other published translation models', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be #TAUTHOR_TAG .', 'The likelihoods in the word-to-word model remain un, so they do not.']","['some have tried, is how to extract such accurate from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be #TAUTHOR_TAG .', 'The likelihoods in the word-to-word model remain unnormalized, so they do not compete.']","['some have tried, how to extract from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be #TAUTHOR_TAG .', 'The likelihoods in the word-to-word model remain un, so they do not.']","['Though some have tried, it is not clear how to extract such accurate lexicons from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be #TAUTHOR_TAG .', 'The likelihoods in the word-to-word model remain unnormalized, so they do not compete.']",0
"['at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply', 'Table multummy"" WebCh , certain machine-assisted translation tools (e.g. #AUTHOR_TAG b)), concordancing for bilingual lexicography #TAUTHOR_TAG , computer- assisted language learning, corpus linguistics (Melby. 1981), and cross-lingual information retrieval (Oard & #AUTHOR_TAG .']","['at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', 'Table ""crummy"" Web , certain machine-assisted translation tools (e.g. #AUTHOR_TAG b)), concordancing for bilingual lexicography #TAUTHOR_TAG , computer- assisted language learning, corpus linguistics (Melby. 1981), and cross-lingual information retrieval (Oard & #AUTHOR_TAG .']","['at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply', 'ummy"" MTCh , certain machine-assisted translation tools (e.g. #AUTHOR_TAG b)), concordancing for bilingual lexicography #TAUTHOR_TAG , computer- assisted language learning, corpus linguistics (Melby. 1981), and cross-lingual information retrieval (Oard & #AUTHOR_TAG .']","['Over the past decade, researchers at IBM have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', 'Table look-up using an ex- plicit translation lexicon is sufficient and preferable for many multilingual NLP applications, including ""crummy"" MT on the World Wide Web (Church & I- #AUTHOR_TAG , certain machine-assisted translation tools (e.g. #AUTHOR_TAG b)), concordancing for bilingual lexicography #TAUTHOR_TAG , computer- assisted language learning, corpus linguistics (Melby. 1981), and cross-lingual information retrieval (Oard & #AUTHOR_TAG .']",0
"['researchers at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', 'Table mult ""ummy"" on the WebCh , certain machine-assisted translation tools (e.g. #TAUTHOR_TAG b )), concordancing for bilingualxicography #AUTHOR_TAG , computer- assisted,isticsM and']","['researchers at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', 'Table ""crummy"" on the Web , certain machine-assisted translation tools (e.g. #TAUTHOR_TAG b )), concordancing for bilingual lexicography #AUTHOR_TAG , computer- assisted learning, linguistics and']","['at have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', '""ummy"" MT onCh , certain machine-assisted translation tools (e.g. #TAUTHOR_TAG b )), concordancing for bilingual lexicography #AUTHOR_TAG , computer- assisted language learning, corpus linguisticsM and']","['Over the past decade, researchers at IBM have devel- oped a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computation- ally expensive to apply.', '']",0
"['2We could just as easily use other symmetric ""association"" measures, such as 02 #AUTHOR_TAG or the Dice coefficient #TAUTHOR_TAG .', 'called a', '', '', '', '', '', 'equival', '']","['2We could just as easily use other symmetric ""association"" measures, such as 02 #AUTHOR_TAG or the Dice coefficient #TAUTHOR_TAG .', 'called a', '', '', '', '', '', 'equivalence', '']","['2We could just as easily use other symmetric ""association"" measures, such as 02 #AUTHOR_TAG or the Dice coefficient #TAUTHOR_TAG .', 'is called', '', '', '', '', '', '', '']","['2We could just as easily use other symmetric ""association"" measures, such as 02 #AUTHOR_TAG or the Dice coefficient #TAUTHOR_TAG .', '', '', '', '', '', '', '', '']",1
"['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', ', the models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', 'However, the models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '', '']",0
"['oc the of b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies inxts', '', '', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other #TAUTHOR_TAG a ) .', 'u', '']","['the of b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts', '', '', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other #TAUTHOR_TAG a ) .', '', '']","['oc the exception of b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies inxts', '', '', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other #TAUTHOR_TAG a ) .', 'u', '']","['Co-occurrence With the exception of #AUTHOR_TAG b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #AUTHOR_TAG a; #AUTHOR_TAG .', '', '', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other #TAUTHOR_TAG a ) .', '', '']",0
"['We induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in #TAUTHOR_TAG .']","['We induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in #TAUTHOR_TAG .']","['We induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in #TAUTHOR_TAG .']","['We induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in #TAUTHOR_TAG .']",5
"['. Discard all likelihood scores for word types deemed unlikely to be mutual translations, ie all Lu) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['. Discard all likelihood scores for word types deemed unlikely to be mutual translations, ie all Lu) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']",0
"['The model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', ' #TAUTHOR_TAG reported that the translation lexicon that our model induced from this tiny bitext accounted for 30 % of the word types with precision between 84 % and 90 % .', 'Recall drops when there is tess training data, because the model refuses to make predictions that it cannot make with.', 'is the desired', '', '', '', '', '']","['The model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', ' #TAUTHOR_TAG reported that the translation lexicon that our model induced from this tiny bitext accounted for 30 % of the word types with precision between 84 % and 90 % .', 'Recall drops when there is tess training data, because the model refuses to make predictions that it cannot make with confidence.', 'is the desired', '', '', '', '', '']","['The model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', ' #TAUTHOR_TAG reported that the translation lexicon that our model induced from this tiny bitext accounted for 30 % of the word types with precision between 84 % and 90 % .', 'Recall drops when there is tess training data, because the model refuses to make predictions that it cannot make with.', 'is the desired behavior.', '', '', '', '', '']","['The model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', ' #TAUTHOR_TAG reported that the translation lexicon that our model induced from this tiny bitext accounted for 30 % of the word types with precision between 84 % and 90 % .', 'Recall drops when there is tess training data, because the model refuses to make predictions that it cannot make with confidence.', '', '', '', '', '', '']",0
"['Co-occurrence With the exception of #AUTHOR_TAG b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #TAUTHOR_TAG a; #AUTHOR_TAG .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in ways', 'way to bitext into an equal of segments and to align the segments that each of segments Si and are transl', '', '']","['Co-occurrence With the exception of #AUTHOR_TAG b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #TAUTHOR_TAG a; #AUTHOR_TAG .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in ways.', 'way to bitext into an equal of segments and to align the segments that each of segments Si and are translations', '', '']","['Co-occurrence With the exception of #AUTHOR_TAG b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #TAUTHOR_TAG a; #AUTHOR_TAG .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in', 'common way to the bitext into an equal number of segments and to align the segments that each pair of segments Si and are transl', '', '']","['Co-occurrence With the exception of #AUTHOR_TAG b), previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #TAUTHOR_TAG a; #AUTHOR_TAG .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', 'The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other #AUTHOR_TAG a).', '', '']",0
"['researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', 'Tableupx is prefer mult including ""crummy"" MT on the Wide Web #AUTHOR_TAG , certain machine-assisted translation tools ( e.g. #AUTHOR_TAG b ) ) , concordancing for bilingual lexicography #TAUTHOR_TAG , computerassisted language learning , corpus linguistics ( Melby 198), and cross-lingual information retrieval (Oard & #AUTHOR_TAG .']","['researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', 'Table is preferable including ""crummy"" MT on the Wide Web #AUTHOR_TAG , certain machine-assisted translation tools ( e.g. #AUTHOR_TAG b ) ) , concordancing for bilingual lexicography #TAUTHOR_TAG , computerassisted language learning , corpus linguistics ( Melby 1981), and cross-lingual information retrieval (Oard & #AUTHOR_TAG .']","['at IBM have developed a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', 'is prefer including ""crummy"" MT on the World Wide Web #AUTHOR_TAG , certain machine-assisted translation tools ( e.g. #AUTHOR_TAG b ) ) , concordancing for bilingual lexicography #TAUTHOR_TAG , computerassisted language learning , corpus linguistics ( Melby . 1981), and cross-lingual information retrieval (Oard & #AUTHOR_TAG .']","['Over the past decade, researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #AUTHOR_TAG a).', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', 'Table look-up using an explicit translation lexicon is sufficient and preferable for many multilingual NLP applications , including ""crummy"" MT on the World Wide Web #AUTHOR_TAG , certain machine-assisted translation tools ( e.g. #AUTHOR_TAG b ) ) , concordancing for bilingual lexicography #TAUTHOR_TAG , computerassisted language learning , corpus linguistics ( Melby . 1981), and cross-lingual information retrieval (Oard & #AUTHOR_TAG .']",0
"['Even better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech, frequency of co-occurrence, relative word position, and translational entropy .', ""Another interesting extension is to broaden the definition of a `` word '' to include multi-word lexical units #TAUTHOR_TAG ."", 'If such units can be identified a priori, their translations can be estimated without modifying the word-to-word model.', 'In this manner, the model can account for a wider range of translation phenomena.']","['Even better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech, frequency of co-occurrence, relative word position, and translational entropy .', ""Another interesting extension is to broaden the definition of a `` word '' to include multi-word lexical units #TAUTHOR_TAG ."", 'If such units can be identified a priori, their translations can be estimated without modifying the word-to-word model.', 'In this manner, the model can account for a wider range of translation phenomena.']","['Even better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech, frequency of co-occurrence, relative word position, and translational entropy .', ""Another interesting extension is to broaden the definition of a `` word '' to include multi-word lexical units #TAUTHOR_TAG ."", 'If such units can be identified a priori, their translations can be estimated without modifying the word-to-word model.', 'In this manner, the model can account for a wider range of translation phenomena.']","['Even better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech, frequency of co-occurrence, relative word position, and translational entropy .', ""Another interesting extension is to broaden the definition of a `` word '' to include multi-word lexical units #TAUTHOR_TAG ."", 'If such units can be identified a priori, their translations can be estimated without modifying the word-to-word model.', 'In this manner, the model can account for a wider range of translation phenomena.']",3
"['', '', '', 'For each co-occurring pair of word types u and v , these likelihoods are initially set proportional to their co-occurrence frequency ( â\x80\x9e , v ) and inversely proportional to their marginal frequencies n ( u ) and n ( v ) 1 , following #TAUTHOR_TAG 2 .', ""When the L(u, v) are re-estimated, the model's hidden parameters come into play.""]","['', '', '', 'For each co-occurring pair of word types u and v , these likelihoods are initially set proportional to their co-occurrence frequency ( â\x80\x9e , v ) and inversely proportional to their marginal frequencies n ( u ) and n ( v ) 1 , following #TAUTHOR_TAG 2 .', ""When the L(u, v) are re-estimated, the model's hidden parameters come into play.""]","['', '', '', 'For each co-occurring pair of word types u and v , these likelihoods are initially set proportional to their co-occurrence frequency ( â\x80\x9e , v ) and inversely proportional to their marginal frequencies n ( u ) and n ( v ) 1 , following #TAUTHOR_TAG 2 .', ""When the L(u, v) are re-estimated, the model's hidden parameters come into play.""]","['', '', '', 'For each co-occurring pair of word types u and v , these likelihoods are initially set proportional to their co-occurrence frequency ( â\x80\x9e , v ) and inversely proportional to their marginal frequencies n ( u ) and n ( v ) 1 , following #TAUTHOR_TAG 2 .', ""When the L(u, v) are re-estimated, the model's hidden parameters come into play.""]",5
"['With the exception of #AUTHOR_TAG b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #AUTHOR_TAG a ; #TAUTHOR_TAG .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', 'The most way is to divide each half of the bitext into an equal of and to the segments that and are transl', 'two (u, are to the and', '']","['With the exception of #AUTHOR_TAG b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #AUTHOR_TAG a ; #TAUTHOR_TAG .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', 'The most way is to divide each half of the bitext into an equal of and to the segments that and are translations', 'two (u, are to the and', '']","['With the exception of #AUTHOR_TAG b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #AUTHOR_TAG a ; #TAUTHOR_TAG .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', 'The most common way is to divide each half of the bitext into an equal number of and to the segments that and are transl', ', two (u, are said to and', '']","['With the exception of #AUTHOR_TAG b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts #AUTHOR_TAG a ; #TAUTHOR_TAG .', 'A bitext comprises a pair of texts in two languages, where each text is a translation of the other.', 'Word co-occurrence can be defined in various ways.', '', '', '']",0
"['. Discard all likelihood scores for word types deemed unlikely to be mutual translations, ie all Lu) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['. Discard all likelihood scores for word types deemed unlikely to be mutual translations, ie all Lu) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']",1
"[""One advantage that Brown et al.'s Model i has over our word-to-word model is that their objective function has no local maxima."", 'By using the EM algorithm #TAUTHOR_TAG , they can guarantee convergence towards the globally optimum parameter set .', ', the dynamic nature of the competitive linking algorithm changes the Pr(datalmodel ) in a non-monotonic fashion.', '']","[""One advantage that Brown et al.'s Model i has over our word-to-word model is that their objective function has no local maxima."", 'By using the EM algorithm #TAUTHOR_TAG , they can guarantee convergence towards the globally optimum parameter set .', 'contrast, the dynamic nature of the competitive linking algorithm changes the Pr(datalmodel ) in a non-monotonic fashion.', '']","[""One advantage that Brown et al.'s Model i has over our word-to-word model is that their objective function has no local maxima."", 'By using the EM algorithm #TAUTHOR_TAG , they can guarantee convergence towards the globally optimum parameter set .', ', the dynamic nature of the competitive linking algorithm changes the Pr(datalmodel ) in a non-monotonic fashion.', '']","[""One advantage that Brown et al.'s Model i has over our word-to-word model is that their objective function has no local maxima."", 'By using the EM algorithm #TAUTHOR_TAG , they can guarantee convergence towards the globally optimum parameter set .', 'In contrast, the dynamic nature of the competitive linking algorithm changes the Pr(datalmodel ) in a non-monotonic fashion.', '']",0
"['Even better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy #TAUTHOR_TAG .', 'interesting extension is to broad the a', '', '']","['Even better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy #TAUTHOR_TAG .', 'interesting extension is to broaden the a', '', '']","['Even better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy #TAUTHOR_TAG .', 'Another interesting extension is to broad the definition', '', '']","['Even better accuracy can be achieved with a more fine-grained link class structure.', 'Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy #TAUTHOR_TAG .', '', '', '']",3
"['In the basic word-to-word model, the hidden parameters A + and A-depend only on the distributions of link frequencies generated by the competitive linking algorithm.', 'More accurate models can be induced by taking into account various features of the linked tokens.', 'For example , frequent words are translated less consistently than rare words #TAUTHOR_TAG .']","['In the basic word-to-word model, the hidden parameters A + and A-depend only on the distributions of link frequencies generated by the competitive linking algorithm.', 'More accurate models can be induced by taking into account various features of the linked tokens.', 'For example , frequent words are translated less consistently than rare words #TAUTHOR_TAG .']","['In the basic word-to-word model, the hidden parameters A + and A-depend only on the distributions of link frequencies generated by the competitive linking algorithm.', 'More accurate models can be induced by taking into account various features of the linked tokens.', 'For example , frequent words are translated less consistently than rare words #TAUTHOR_TAG .']","['In the basic word-to-word model, the hidden parameters A + and A-depend only on the distributions of link frequencies generated by the competitive linking algorithm.', 'More accurate models can be induced by taking into account various features of the linked tokens.', 'For example , frequent words are translated less consistently than rare words #TAUTHOR_TAG .']",0
"['. Discard all likelihood scores for word types deemed unlikely to be mutual translations, ie all Lu) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['. Discard all likelihood scores for word types deemed unlikely to be mutual translations, ie all Lu) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']","['1. Discard all likelihood scores for word types deemed unlikely to be mutual translations, i.e. all L(u,v) < 1.', 'This step significantly reduces the computational burden of the algorithm.', 'It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values #TAUTHOR_TAG .', '']",1
"[""2We could just as easily use other symmetric `` association '' measures , such as 02 #TAUTHOR_TAG or the Dice coefficient #AUTHOR_TAG ."", 'called a direct association', '', '', '', '', '', 'equival', '']","[""2We could just as easily use other symmetric `` association '' measures , such as 02 #TAUTHOR_TAG or the Dice coefficient #AUTHOR_TAG ."", 'called a direct association.', '', '', '', '', '', 'equivalence', '']","[""2We could just as easily use other symmetric `` association '' measures , such as 02 #TAUTHOR_TAG or the Dice coefficient #AUTHOR_TAG ."", 'is called a direct association.', '', '', '', '', '', '', '']","[""2We could just as easily use other symmetric `` association '' measures , such as 02 #TAUTHOR_TAG or the Dice coefficient #AUTHOR_TAG ."", '', '', '', '', '', '', '', '']",1
"['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', ', the models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', 'However, the models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', ', the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply', '', '']","['Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation #TAUTHOR_TAG a ) .', 'However, the IBM models, which attempt to capture a broad range of translation phenomena, are computationally expensive to apply.', '', '']",0
"['some have tried is how to extract such accurate from other published translation models', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be #TAUTHOR_TAG .', 'The likelihoods in the word-to-word model remain un, so they do not.']","['some have tried, is how to extract such accurate from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be #TAUTHOR_TAG .', 'The likelihoods in the word-to-word model remain unnormalized, so they do not compete.']","['some have tried, how to extract from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be #TAUTHOR_TAG .', 'The likelihoods in the word-to-word model remain un, so they do not.']","['Though some have tried, it is not clear how to extract such accurate lexicons from other published translation models.', 'Part of the difficulty stems from the implicit assumption in other models that each word has only one sense.', 'Each word is assigned the same unit of probability mass, which the model distributes over all candidate translations.', 'The correct translations of a word that has several correct translations will be assigned a lower probability than the correct translation of a word that has only one correct translation.', 'This imbalance foils thresholding strategies , clever as they might be #TAUTHOR_TAG .', 'The likelihoods in the word-to-word model remain unnormalized, so they do not compete.']",0
"['', '', '', 'a-x', 'This method of incorporating dictionary information seems simpler than the method proposed by Brown et al. for their models #TAUTHOR_TAG b ) .', 'for their models #AUTHOR_TAG b', 'When the hidden parameters are conditioned on different link classes, the estimation method does not change; it is just repeated for each link class.']","['', '', '', 'a', 'This method of incorporating dictionary information seems simpler than the method proposed by Brown et al. for their models #TAUTHOR_TAG b ) .', 'for their models #AUTHOR_TAG b).', 'When the hidden parameters are conditioned on different link classes, the estimation method does not change; it is just repeated for each link class.']","['', '', '', '', 'This method of incorporating dictionary information seems simpler than the method proposed by Brown et al. for their models #TAUTHOR_TAG b ) .', 'for their models #AUTHOR_TAG b', 'When the hidden parameters are conditioned on different link classes, the estimation method does not change; it is just repeated for each link class.']","['', '', '', '', 'This method of incorporating dictionary information seems simpler than the method proposed by Brown et al. for their models #TAUTHOR_TAG b ) .', 'for their models #AUTHOR_TAG b).', 'When the hidden parameters are conditioned on different link classes, the estimation method does not change; it is just repeated for each link class.']",1
"['The model was also used to induce a translationxicon from a 6200-word corpus of French/ weather', '', '', '', ""The most detailed evaluation of link tokens to date was performed by #TAUTHOR_TAG , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."", 'These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set.', 'We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models.', '', '']","['The model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather', '', '', '', ""The most detailed evaluation of link tokens to date was performed by #TAUTHOR_TAG , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."", 'These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set.', 'We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models.', '', '']","['The model was also used to induce a translation lexicon from a 6200-word corpus of French/', '', '', '', ""The most detailed evaluation of link tokens to date was performed by #TAUTHOR_TAG , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."", 'These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set.', 'We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models.', '', '']","['The model was also used to induce a translation lexicon from a 6200-word corpus of French/English weather reports.', '', '', '', ""The most detailed evaluation of link tokens to date was performed by #TAUTHOR_TAG , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards ."", 'These authors kindly provided us with the links generated by that model in 51 aligned sentences from a heldout test set.', 'We generated links in the same 51 sentences using our two-class word-to-word model, and manually evaluated the content-word links from both models.', '', '']",1
"['', '', '', '', '11', '11 From #TAUTHOR_TAG , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .', 'Thus, to be convenient, we only conduct experiments with the SAMT system.']","['', '', '', '', '11', '11 From #TAUTHOR_TAG , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .', 'Thus, to be convenient, we only conduct experiments with the SAMT system.']","['', '', '', '', '11', '11 From #TAUTHOR_TAG , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .', 'Thus, to be convenient, we only conduct experiments with the SAMT system.']","['', '', '', '', '', '11 From #TAUTHOR_TAG , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .', 'Thus, to be convenient, we only conduct experiments with the SAMT system.']",4
"['', '', '', '', 'Differently , #TAUTHOR_TAG designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .', 'We that it is possible to investigate the space of both tree structure and alignment simultaneously.', 'This will of our.']","['', '', '', '', 'Differently , #TAUTHOR_TAG designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .', 'We that it is possible to investigate the space of both tree structure and alignment simultaneously.', 'This will of our topics.']","['', '', '', '', 'Differently , #TAUTHOR_TAG designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .', 'We believe that it is possible to investigate the space of both tree structure and alignment simultaneously.', 'This subject will be of our']","['', '', '', '', 'Differently , #TAUTHOR_TAG designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .', 'We believe that it is possible to investigate the space of both tree structure and alignment simultaneously.', '']",4
"['', '', '', '', 'obtained SCFG is further used in a phrase-based and hierarchical phrase-based system #TAUTHOR_TAG', 'continCFG', 'from', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'obtained SCFG is further used in a phrase-based and hierarchical phrase-based system #TAUTHOR_TAG', 'SCFG', 'from', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'obtained SCFG is further used in a phrase-based and hierarchical phrase-based system #TAUTHOR_TAG .', 'contin', 'from', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'The obtained SCFG is further used in a phrase-based and hierarchical phrase-based system #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '', '']",1
"['', '', '', ' #TAUTHOR_TAG , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .', 'is further used in a phrase-based and hier phrasebased system', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', '', ' #TAUTHOR_TAG , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .', 'is further used in a phrase-based and phrase-based system', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', '', ' #TAUTHOR_TAG , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .', 'is further used in a phrase-based and hierical phrase-based system', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', '', ' #TAUTHOR_TAG , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .', 'The obtained SCFG is further used in a phrase-based and hierarchical phrase-based system #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '', '']",1
"['The translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on #AUTHOR_TAG and #TAUTHOR_TAG .', '']","['The translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on #AUTHOR_TAG and #TAUTHOR_TAG .', '']","['The translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on #AUTHOR_TAG and #TAUTHOR_TAG .', '']","['The translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on #AUTHOR_TAG and #TAUTHOR_TAG .', '']",5
"['', 'Our previous work #TAUTHOR_TAG designed an EMbased method to construct unsupervised trees for tree-based translation models .', 'This work differs from above a novel', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'Our previous work #TAUTHOR_TAG designed an EMbased method to construct unsupervised trees for tree-based translation models .', 'This work differs from above a novel', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'Our previous work #TAUTHOR_TAG designed an EMbased method to construct unsupervised trees for tree-based translation models .', 'This work differs from', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'Our previous work #TAUTHOR_TAG designed an EMbased method to construct unsupervised trees for tree-based translation models .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",1
"['To the2 system, we first use the parse tree, which is generated by parsing the English side of the bilingual data with the Berkeley parser #AUTHOR_TAG', 'Then , we binarize the English parse trees using the head binarization approach #TAUTHOR_TAG and use the resulting binary parse trees to build another s2t system .']","['To the system, we first use the parse tree, which is generated by parsing the English side of the bilingual data with the Berkeley parser #AUTHOR_TAG', 'Then , we binarize the English parse trees using the head binarization approach #TAUTHOR_TAG and use the resulting binary parse trees to build another s2t system .']","['To the above s2t system, we first use the parse tree, which is generated by parsing the English side of the bilingual data with the Berkeley parser #AUTHOR_TAG .', 'Then , we binarize the English parse trees using the head binarization approach #TAUTHOR_TAG and use the resulting binary parse trees to build another s2t system .']","['To build the above s2t system, we first use the parse tree, which is generated by parsing the English side of the bilingual data with the Berkeley parser #AUTHOR_TAG .', 'Then , we binarize the English parse trees using the head binarization approach #TAUTHOR_TAG and use the resulting binary parse trees to build another s2t system .']",5
"['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #AUTHOR_TAG 2006 ; #TAUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #AUTHOR_TAG 2006 ; #TAUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #AUTHOR_TAG 2006 ; #TAUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #AUTHOR_TAG 2006 ; #TAUTHOR_TAG b ) .']",0
"['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #AUTHOR_TAG 2006 ; #TAUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #AUTHOR_TAG 2006 ; #TAUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #AUTHOR_TAG 2006 ; #TAUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #AUTHOR_TAG 2006 ; #TAUTHOR_TAG b ) .']",0
"['', '', '', '', '', '', '', '', '', '', 'adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', 'adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', 'adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees .', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees .', '', '', '', '', '', '']",1
"['The  is designed to assign the', 'each a fragment frag a we follow #TAUTHOR_TAG and decompose the prior probability P0 ( r | N ) into two factors as follows :']","['The 0 is designed to assign the', 'each a fragment frag a we follow #TAUTHOR_TAG and decompose the prior probability P0 ( r | N ) into two factors as follows :']","['is designed to assign', 'a target tree fragment frag we follow #TAUTHOR_TAG and decompose the prior probability P0 ( r | N ) into two factors as follows :']","['', 'Because each rule r consists of a target tree fragment frag and a source string str in the model , we follow #TAUTHOR_TAG and decompose the prior probability P0 ( r | N ) into two factors as follows :']",5
"['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'categories', ' #TAUTHOR_TAG further labeled the SCFG rules with POS tags and unsupervised word classes .', 'ST label']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', 'categories.', ' #TAUTHOR_TAG further labeled the SCFG rules with POS tags and unsupervised word classes .', 'STSG labeling']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG further labeled the SCFG rules with POS tags and unsupervised word classes .', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG further labeled the SCFG rules with POS tags and unsupervised word classes .', '']",1
"['Using the initial target U-trees , source sentences and word alignment , we extract minimal GHKM translation rules7 in terms of frontier nodes #TAUTHOR_TAG .', 'Frontier nodes are the tree nodes that can map onto contiguous substrings on the source side via word alignment.', 'For, the bold italic nodes with shadows in Figure 2 are frontier nodes', '', '', '', '']","['Using the initial target U-trees , source sentences and word alignment , we extract minimal GHKM translation rules7 in terms of frontier nodes #TAUTHOR_TAG .', 'Frontier nodes are the tree nodes that can map onto contiguous substrings on the source side via word alignment.', 'For example, the bold italic nodes with shadows in Figure 2 are frontier nodes.', '', '', '', '']","['Using the initial target U-trees , source sentences and word alignment , we extract minimal GHKM translation rules7 in terms of frontier nodes #TAUTHOR_TAG .', 'Frontier nodes are the tree nodes that can map onto contiguous substrings on the source side via word alignment.', 'For, the bold italic nodes with shadows in Figure 2 are frontier nodes.', '', '', '', '']","['Using the initial target U-trees , source sentences and word alignment , we extract minimal GHKM translation rules7 in terms of frontier nodes #TAUTHOR_TAG .', 'Frontier nodes are the tree nodes that can map onto contiguous substrings on the source side via word alignment.', 'For example, the bold italic nodes with shadows in Figure 2 are frontier nodes.', '', '', '', '']",5
"['', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG re-trained the linguistic parsers bilingually based on word alignment', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG re-trained the linguistic parsers bilingually based on word alignment', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG re-trained the linguistic parsers bilingually based on word alignment .', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG re-trained the linguistic parsers bilingually based on word alignment .', '', '', '', '', '']",1
"['', '', '', '', '', '', '', 'B', 'The statistical significance test is performed by the re-sampling approach #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', 'The statistical significance test is performed by the re-sampling approach #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', 'The statistical significance test is performed by the re-sampling approach #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', 'The statistical significance test is performed by the re-sampling approach #TAUTHOR_TAG .']",5
"['The translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on #TAUTHOR_TAG and ( Marcu et al. 2006 ) .', '']","['The translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on #TAUTHOR_TAG and ( Marcu et al. 2006 ) .', '']","['The translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on #TAUTHOR_TAG and ( Marcu et al. 2006 ) .', '']","['The translation system used for testing the effectiveness of our U-trees is our in-house stringto-tree system (abbreviated as s2t).', 'The system is implemented based on #TAUTHOR_TAG and ( Marcu et al. 2006 ) .', '']",5
"['', '', '', '', '', ' #TAUTHOR_TAG employed a Bayesian method to learn discontinuous SCFG rules', 'This study differs from their work because we concentrate on constructing tree structures for tree-based translation models', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', ' #TAUTHOR_TAG employed a Bayesian method to learn discontinuous SCFG rules', 'This study differs from their work because we concentrate on constructing tree structures for tree-based translation models.', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', ' #TAUTHOR_TAG employed a Bayesian method to learn discontinuous SCFG rules .', 'This study differs from their work because we concentrate on constructing tree structures for tree-based translation models.', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', ' #TAUTHOR_TAG employed a Bayesian method to learn discontinuous SCFG rules .', 'This study differs from their work because we concentrate on constructing tree structures for tree-based translation models.', '', '', '', '', '', '', '', '', '', '']",1
"['', '', '', '', '', '', '', 'STSG more tree-based translation models than SCFG', ' #TAUTHOR_TAG and #AUTHOR_TAG focused on joint parsing and alignment', 'bual Tree-bank to train a joint model for both parsing word alignment', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', 'STSG, more tree-based translation models than SCFG.', ' #TAUTHOR_TAG and #AUTHOR_TAG focused on joint parsing and alignment', 'bilingual Tree-bank to train a joint model for both parsing word alignment.', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', 'STSG is more tree-based translation models than SCFG', ' #TAUTHOR_TAG and #AUTHOR_TAG focused on joint parsing and alignment .', 'the bilingual Tree-bank to train a joint model for both parsing word alignment.', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG and #AUTHOR_TAG focused on joint parsing and alignment .', 'They utilized the bilingual Tree-bank to train a joint model for both parsing and word alignment.', '', '', '', '', '', '', '']",1
"['The sampler might reinforce the alignment errors ( harm the translation (', '', '', '', '', '9 We only use the minimal GHKM rules #TAUTHOR_TAG here to reduce the complexity of the sampler .']","['The sampler might reinforce the alignment errors harm the translation', '', '', '', '', '9 We only use the minimal GHKM rules #TAUTHOR_TAG here to reduce the complexity of the sampler .']","['The sampler might reinforce the frequent alignment errors ( would harm the translation model (', '', '', '', '', '9 We only use the minimal GHKM rules #TAUTHOR_TAG here to reduce the complexity of the sampler .']","['The sampler might reinforce the frequent alignment errors (AE), which would harm the translation model (TM).', '', '', '', '', '9 We only use the minimal GHKM rules #TAUTHOR_TAG here to reduce the complexity of the sampler .']",5
"['effectiveness ourtre', 'implemented on', 'In the system , we extract both the minimal GHKM rules #TAUTHOR_TAG , and the rules of SPMT Model 1 #AUTHOR_TAG with phrases up to length L = 5 on the source side .']","['effectiveness our', 'implemented on', 'In the system , we extract both the minimal GHKM rules #TAUTHOR_TAG , and the rules of SPMT Model 1 #AUTHOR_TAG with phrases up to length L = 5 on the source side .']","['ourtre', 'on', 'In the system , we extract both the minimal GHKM rules #TAUTHOR_TAG , and the rules of SPMT Model 1 #AUTHOR_TAG with phrases up to length L = 5 on the source side .']","['', '', 'In the system , we extract both the minimal GHKM rules #TAUTHOR_TAG , and the rules of SPMT Model 1 #AUTHOR_TAG with phrases up to length L = 5 on the source side .']",5
"['', '', '-tre.', 'Using the GHKM algorithm #TAUTHOR_TAG , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .', 'Each derivation carries a set of STSG rules (i.e., minimal GHKM translation rules) of its.', ""In the two derivations, the STSG rules defined by the two states include the one rooted at the s-node's lowest ancestor frontier node, and the one rooted at the s-node if it is a frontier node."", ', Figure 3),']","['', '', 'U-trees.', 'Using the GHKM algorithm #TAUTHOR_TAG , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .', 'Each derivation carries a set of STSG rules (i.e., minimal GHKM translation rules) of its own.', ""In the two derivations, the STSG rules defined by the two states include the one rooted at the s-node's lowest ancestor frontier node, and the one rooted at the s-node if it is a frontier node."", 'instance, Figure 3(a),']","['', '', '', 'Using the GHKM algorithm #TAUTHOR_TAG , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .', 'Each derivation carries a set of STSG rules (i.e., minimal GHKM translation rules) of its.', ""In the two derivations, the STSG rules defined by the two states include the one rooted at the s-node's lowest ancestor frontier node, and the one rooted at the s-node if it is a frontier node."", ', Figure 3),']","['', '', '', 'Using the GHKM algorithm #TAUTHOR_TAG , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .', 'Each derivation carries a set of STSG rules (i.e., minimal GHKM translation rules) of its own.', ""In the two derivations, the STSG rules defined by the two states include the one rooted at the s-node's lowest ancestor frontier node, and the one rooted at the s-node if it is a frontier node."", '']",5
"['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #TAUTHOR_TAG , 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #TAUTHOR_TAG , 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #TAUTHOR_TAG , 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #TAUTHOR_TAG , 2006 ; #AUTHOR_TAG b ) .']",0
"['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #TAUTHOR_TAG 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #TAUTHOR_TAG 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (MT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #TAUTHOR_TAG 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #AUTHOR_TAG 2009 ; #TAUTHOR_TAG 2006 ; #AUTHOR_TAG b ) .']",0
"['To create the baseline system , we use the opensource Joshua 4.0 system #AUTHOR_TAG to build a hierarchical phrase-based ( HPB ) system , and a syntax-augmented MT ( SAMT ) 11 system #TAUTHOR_TAG respectively .']","['To create the baseline system , we use the opensource Joshua 4.0 system #AUTHOR_TAG to build a hierarchical phrase-based ( HPB ) system , and a syntax-augmented MT ( SAMT ) 11 system #TAUTHOR_TAG respectively .']","['To create the baseline system , we use the opensource Joshua 4.0 system #AUTHOR_TAG to build a hierarchical phrase-based ( HPB ) system , and a syntax-augmented MT ( SAMT ) 11 system #TAUTHOR_TAG respectively .']","['To create the baseline system , we use the opensource Joshua 4.0 system #AUTHOR_TAG to build a hierarchical phrase-based ( HPB ) system , and a syntax-augmented MT ( SAMT ) 11 system #TAUTHOR_TAG respectively .']",5
"['To build the above s2t system , we first use the parse tree , which is generated by parsing the English side of the bilingual data with the Berkeley parser #TAUTHOR_TAG .', 'Then, we binarize the English parse trees resulting binary to build another s2t system']","['To build the above s2t system , we first use the parse tree , which is generated by parsing the English side of the bilingual data with the Berkeley parser #TAUTHOR_TAG .', 'Then, we binarize the English parse trees resulting binary to build another s2t system.']","['To build the above s2t system , we first use the parse tree , which is generated by parsing the English side of the bilingual data with the Berkeley parser #TAUTHOR_TAG .', 'Then, we binarize the English parse trees using to build another s2t system.']","['To build the above s2t system , we first use the parse tree , which is generated by parsing the English side of the bilingual data with the Berkeley parser #TAUTHOR_TAG .', 'Then, we binarize the English parse trees using the head binarization approach #AUTHOR_TAG and use the resulting binary parse trees to build another s2t system.']",5
"['is the probability of producing the target tree fragment frag.', 'To generate frag, used a geometric prior to how many child nodes to assign each node.', 'Differently, we require that each multi-word non-terminal node must have two child nodes.', 'This is because the binary structure has been verified to be very effective for tree-based translation #TAUTHOR_TAG a ) .']","['is the probability of producing the target tree fragment frag.', 'To generate frag, used a geometric prior to how many child nodes to assign each node.', 'Differently, we require that each multi-word non-terminal node must have two child nodes.', 'This is because the binary structure has been verified to be very effective for tree-based translation #TAUTHOR_TAG a ) .']","['is the probability of producing the target tree fragment frag.', 'To generate frag, used a geometric prior to how many child nodes to assign each node.', 'Differently, we require that each multi-word non-terminal node must have two child nodes.', 'This is because the binary structure has been verified to be very effective for tree-based translation #TAUTHOR_TAG a ) .']","['is the probability of producing the target tree fragment frag.', 'To generate frag, used a geometric prior to decide how many child nodes to assign each node.', 'Differently, we require that each multi-word non-terminal node must have two child nodes.', 'This is because the binary structure has been verified to be very effective for tree-based translation #TAUTHOR_TAG a ) .']",4
"['In recent years, tree-based translation models1 are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #TAUTHOR_TAG , 2009 ; #AUTHOR_TAG 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models1 are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #TAUTHOR_TAG , 2009 ; #AUTHOR_TAG 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models1 are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #TAUTHOR_TAG , 2009 ; #AUTHOR_TAG 2006 ; #AUTHOR_TAG b ) .']","['In recent years, tree-based translation models1 are drawing more and more attention in the community of statistical machine translation (SMT).', 'Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality #TAUTHOR_TAG , 2009 ; #AUTHOR_TAG 2006 ; #AUTHOR_TAG b ) .']",0
"['many language pairs, it is difficult to acquire such corresponding linguistic pars due to the lack-bank for training.', '2) Parse trees are actually only used to model and explain the monolingual structure, rather than the bilingual mapping between language pairs.', 'This indicates that parse trees are usually not the optimal choice for training tree-based translation models #TAUTHOR_TAG .']","['many language pairs, it is difficult to acquire such corresponding linguistic parsers due to the lack Tree-bank for training.', '2) Parse trees are actually only used to model and explain the monolingual structure, rather than the bilingual mapping between language pairs.', 'This indicates that parse trees are usually not the optimal choice for training tree-based translation models #TAUTHOR_TAG .']","['many language pairs, it is difficult to acquire such corresponding linguistic parsers due to the lack-bank resources for training.', '2) Parse trees are actually only used to model and explain the monolingual structure, rather than the bilingual mapping between language pairs.', 'This indicates that parse trees are usually not the optimal choice for training tree-based translation models #TAUTHOR_TAG .']","['However, for many language pairs, it is difficult to acquire such corresponding linguistic parsers due to the lack of Tree-bank resources for training.', '2) Parse trees are actually only used to model and explain the monolingual structure, rather than the bilingual mapping between language pairs.', 'This indicates that parse trees are usually not the optimal choice for training tree-based translation models #TAUTHOR_TAG .']",0
"['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG focused on joint parsing and alignment', 'the bilingual Tree-bank to train a joint model for both parsing and word alignment', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG focused on joint parsing and alignment', 'the bilingual Tree-bank to train a joint model for both parsing and word alignment.', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG focused on joint parsing and alignment .', 'the bilingual Tree-bank to train a joint model for both parsing and word alignment.', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', ' #AUTHOR_TAG and #TAUTHOR_TAG focused on joint parsing and alignment .', 'They utilized the bilingual Tree-bank to train a joint model for both parsing and word alignment.', '', '', '', '', '', '', '']",1
"['', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation .', '', '', '', '']",1
"['P(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by #AUTHOR_TAG and #TAUTHOR_TAG , we define P ( str | frag ) as follows : where csw is the number of words in the source string .']","['P(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by #AUTHOR_TAG and #TAUTHOR_TAG , we define P ( str | frag ) as follows : where csw is the number of words in the source string .']","['P(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by #AUTHOR_TAG and #TAUTHOR_TAG , we define P ( str | frag ) as follows : where csw is the number of words in the source string .']","['P(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by #AUTHOR_TAG and #TAUTHOR_TAG , we define P ( str | frag ) as follows : where csw is the number of words in the source string .']",4
"['P(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by #TAUTHOR_TAG and #AUTHOR_TAG , we define P ( str | frag ) as follows : where csw is the number of words in the source string .']","['P(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by #TAUTHOR_TAG and #AUTHOR_TAG , we define P ( str | frag ) as follows : where csw is the number of words in the source string .']","['P(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by #TAUTHOR_TAG and #AUTHOR_TAG , we define P ( str | frag ) as follows : where csw is the number of words in the source string .']","['P(str | frag) in Equation (4) is the probability of generating the source string, which contains several source words and variables.', 'Inspired by #TAUTHOR_TAG and #AUTHOR_TAG , we define P ( str | frag ) as follows : where csw is the number of words in the source string .']",4
"['In addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar #TAUTHOR_TAG 5 .', 'This would indicate that the SCFG-based derivation tree as by-product is also not such good for tree-based translation models.', 'in']","['In addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar #TAUTHOR_TAG 5 .', 'This would indicate that the SCFG-based derivation tree as by-product is also not such good for tree-based translation models.', 'in']","['In addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar #TAUTHOR_TAG 5 .', 'This would indicate that the SCFG-based derivation tree as by-product is also not such good for tree-based translation models.', 'in']","['In addition , we find that the Bayesian SCFG grammar can not even significantly outperform the heuristic SCFG grammar #TAUTHOR_TAG 5 .', 'This would indicate that the SCFG-based derivation tree as by-product is also not such good for tree-based translation models.', '']",1
"['', '', '', '', '', '', '', '', '', '', '', '', '', 'we do not rely on any Tree-bank resources and focus on generating effective unsupervised tree structures for tree-based translation models', ' #TAUTHOR_TAG substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .', 'CFGOS tags and unsupervised word', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'we do not rely on any Tree-bank resources and focus on generating effective unsupervised tree structures for tree-based translation models.', ' #TAUTHOR_TAG substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .', 'SCFG POS tags and unsupervised word', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'we do not rely on any Tree-bank resources and focus on generating effective unsupervised tree structures for tree-based translation models.', ' #TAUTHOR_TAG substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .', 'OS tags and unsuper', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'Compared to their work, we do not rely on any Tree-bank resources and focus on generating effective unsupervised tree structures for tree-based translation models.', ' #TAUTHOR_TAG substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .', '', '']",1
"['word hypotheses', 'fionRex developed by"" or HTK from Entropic Research can be used', 'Acoustic models for HTK is trained with the continuous speech database of the Acoust Society Japan #AUTHOR_TAG', 'This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search #TAUTHOR_TAG using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses', '', '', '', '', '', '', '', '', '', '']","['word hypotheses.', 'recogn/fion VoiceRex, developed by or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society Japan #AUTHOR_TAG', 'This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search #TAUTHOR_TAG using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses', '', '', '', '', '', '', '', '', '', '']","['word hypotheses.', 'Rex developed by"" or HTK from Entropic Research can be used', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society Japan #AUTHOR_TAG .', 'This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search #TAUTHOR_TAG using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses .', '', '', '', '', '', '', '', '', '', '']","['word hypotheses.', 'As the recogn/fion engine, either VoiceRex, developed by NTI"" #AUTHOR_TAG , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan #AUTHOR_TAG .', 'This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search #TAUTHOR_TAG using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses .', '', '', '', '', '', '', '', '', '', '']",0
"['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']",0
"['There have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests #TAUTHOR_TAG .', 'such techniques would deo crease the system developer workload', '', '']","['There have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests #TAUTHOR_TAG .', 'such techniques would deo crease the system developer workload.', '', '']","['There have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests #TAUTHOR_TAG .', 'ating such techniques would deo crease the system developer workload.', '', '']","['There have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests #TAUTHOR_TAG .', 'Incorporating such techniques would deo crease the system developer workload.', '', '']",3
"['Functions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state.', 'They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of #TAUTHOR_TAG .']","['Functions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state.', 'They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of #TAUTHOR_TAG .']","['Functions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state.', 'They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of #TAUTHOR_TAG .']","['Functions defined here decide what string should be spoken and send that string to the speech output module based on the current dialogue state.', 'They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of #TAUTHOR_TAG .']",1
"['word hypotheses.', 'the recogn/fion engine, either VoiceRex, developed by NTI"" #AUTHOR_TAG , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan #TAUTHOR_TAG .', 'word as soonscored', '', '', '', '', '', '', '', '', '', '']","['word hypotheses.', 'the recogn/fion engine, either VoiceRex, developed by NTI"" #AUTHOR_TAG , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan #TAUTHOR_TAG .', 'word as soon best-scored', '', '', '', '', '', '', '', '', '', '']","['word hypotheses.', 'the recogn/fion engine, either VoiceRex, developed by NTI"" #AUTHOR_TAG , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan #TAUTHOR_TAG .', 'wordes as soon', '', '', '', '', '', '', '', '', '', '']","['word hypotheses.', 'As the recogn/fion engine, either VoiceRex, developed by NTI"" #AUTHOR_TAG , or HTK from Entropic Research can be used.', 'Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '']",5
"['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']",0
"['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']",0
"['WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system #TAUTHOR_TAG b ) , a video-recording programming system , a schedule management system #AUTHOR_TAG a ) , and a weather infomiation system #AUTHOR_TAG .', '', '', '', '', '', '']","['WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system #TAUTHOR_TAG b ) , a video-recording programming system , a schedule management system #AUTHOR_TAG a ) , and a weather infomiation system #AUTHOR_TAG .', '', '', '', '', '', '']","['WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system #TAUTHOR_TAG b ) , a video-recording programming system , a schedule management system #AUTHOR_TAG a ) , and a weather infomiation system #AUTHOR_TAG .', '', '', '', '', '', '']","['WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system #TAUTHOR_TAG b ) , a video-recording programming system , a schedule management system #AUTHOR_TAG a ) , and a weather infomiation system #AUTHOR_TAG .', '', '', '', '', '', '']",2
"['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']","['The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems #TAUTHOR_TAG .', 'One of the next research goals is to make these systems task-portable, that is, to simplify the process of porting to another task domain.']",0
"['WIT', '', '', '', 'Since the language understanding module utilizes unification, a wide variety of linguistic phenomena can be covered.', 'For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar #TAUTHOR_TAG .', 'The language generation module features Common Lisp functions, so there is the.', '', '', '']","['WIT', '', '', '', 'Since the language understanding module utilizes unification, a wide variety of linguistic phenomena can be covered.', 'For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar #TAUTHOR_TAG .', 'The language generation module features Common Lisp functions, so there is the description.', '', '', '']","['', '', '', '', 'Since the language understanding module utilizes unification, a wide variety of linguistic phenomena can be covered.', 'For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar #TAUTHOR_TAG .', 'The language generation module features Common Lisp functions, so there is the description.', '', '', '']","['', '', '', '', 'Since the language understanding module utilizes unification, a wide variety of linguistic phenomena can be covered.', 'For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar #TAUTHOR_TAG .', 'The language generation module features Common Lisp functions, so there is no limitation on the description.', '', '', '']",3
"['Since the language generation module works in parallel with the language understanding module , utterance generation is possible even while the system is listening to user utterances and that utterance understanding is possible even while it is speaking #TAUTHOR_TAG a ) .', 'Thus the system can respond immediately after user pauses when the user has the initiative.', '']","['Since the language generation module works in parallel with the language understanding module , utterance generation is possible even while the system is listening to user utterances and that utterance understanding is possible even while it is speaking #TAUTHOR_TAG a ) .', 'Thus the system can respond immediately after user pauses when the user has the initiative.', '']","['Since the language generation module works in parallel with the language understanding module , utterance generation is possible even while the system is listening to user utterances and that utterance understanding is possible even while it is speaking #TAUTHOR_TAG a ) .', 'Thus the system can respond immediately after user pauses when the user has the initiative.', '']","['Since the language generation module works in parallel with the language understanding module , utterance generation is possible even while the system is listening to user utterances and that utterance understanding is possible even while it is speaking #TAUTHOR_TAG a ) .', 'Thus the system can respond immediately after user pauses when the user has the initiative.', '']",0
"['WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system #AUTHOR_TAG b ) , a video-recording programming system , a schedule management system #AUTHOR_TAG a ) , and a weather infomiation system #TAUTHOR_TAG .', '', '', '', '', '', '']","['WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system #AUTHOR_TAG b ) , a video-recording programming system , a schedule management system #AUTHOR_TAG a ) , and a weather infomiation system #TAUTHOR_TAG .', '', '', '', '', '', '']","['WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system #AUTHOR_TAG b ) , a video-recording programming system , a schedule management system #AUTHOR_TAG a ) , and a weather infomiation system #TAUTHOR_TAG .', '', '', '', '', '', '']","['WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system #AUTHOR_TAG b ) , a video-recording programming system , a schedule management system #AUTHOR_TAG a ) , and a weather infomiation system #TAUTHOR_TAG .', '', '', '', '', '', '']",2
"['This paper presents WIT 1 which ac', 'WIT features an incremental understanding method #TAUTHOR_TAG b ) that makes it possible to build a robust and real-time system .', 'WITiles domain-dependent system specifications into internal knowledge sources so that building systems is easier', '', '']","['This paper presents WIT 1, which', 'WIT features an incremental understanding method #TAUTHOR_TAG b ) that makes it possible to build a robust and real-time system .', 'WIT compiles domain-dependent system specifications into internal knowledge sources so that building systems is easier.', '', '']","['This paper presents WIT 1, which', 'WIT features an incremental understanding method #TAUTHOR_TAG b ) that makes it possible to build a robust and real-time system .', ', WITiles domain-dependent system specifications into internal knowledge sources so that building systems is easier', '', '']","['', 'WIT features an incremental understanding method #TAUTHOR_TAG b ) that makes it possible to build a robust and real-time system .', 'In addition, WIT compiles domain-dependent system specifications into internal knowledge sources so that building systems is easier.', '', '']",5
"['The domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules.', 'Disjunctive feature descriptions are also possible ; WIT incorporates an efficient method for handling disjunctions #TAUTHOR_TAG .', 'a phrase boundary is detected, the feature structure for a phrase is computed using some built-in rules from the feature structure rules for the words in', '', '', '']","['The domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules.', 'Disjunctive feature descriptions are also possible ; WIT incorporates an efficient method for handling disjunctions #TAUTHOR_TAG .', 'a phrase boundary is detected, the feature structure for a phrase is computed using some built-in rules from the feature structure rules for the words in', '', '', '']","['The domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules.', 'Disjunctive feature descriptions are also possible ; WIT incorporates an efficient method for handling disjunctions #TAUTHOR_TAG .', 'a phrase boundary is detected, the feature structure for a phrase is computed using some built-in rules from the feature structure rules for the words in', '', '', '']","['The domain-dependent knowledge used in this module consists of a unification-based lexicon and phrase structure rules.', 'Disjunctive feature descriptions are also possible ; WIT incorporates an efficient method for handling disjunctions #TAUTHOR_TAG .', 'When a phrase boundary is detected, the feature structure for a phrase is computed using some built-in rules from the feature structure rules for the words in the phrase.', '', '', '']",5
"['', 'is possible to add to the rules constraints that stipulate relationships that must hold among variables (Nak199), but we do not explain these constraints in detail in this paper.', 'The priorities are used for disambiguating interpretation in the incremental understanding method #TAUTHOR_TAG b ) .', '', '']","['', 'is possible to add to the rules constraints that stipulate relationships that must hold among variables (Nakano,199 I), but we do not explain these constraints in detail in this paper.', 'The priorities are used for disambiguating interpretation in the incremental understanding method #TAUTHOR_TAG b ) .', '', '']","['', 'It is possible to add to the rules constraints that stipulate relationships that must hold among variables (Nak199), but we do not explain these constraints in detail in this paper.', 'The priorities are used for disambiguating interpretation in the incremental understanding method #TAUTHOR_TAG b ) .', '', '']","['', 'It is possible to add to the rules constraints that stipulate relationships that must hold among variables (Nakano,199 I), but we do not explain these constraints in detail in this paper.', 'The priorities are used for disambiguating interpretation in the incremental understanding method #TAUTHOR_TAG b ) .', '', '']",5
"['To this end , several toolkits for building spoken dialogue systems have been developed #TAUTHOR_TAG .', 'One is the CSLUkit rapid prototyping a incorpor a', '', '', '', '', '']","['To this end , several toolkits for building spoken dialogue systems have been developed #TAUTHOR_TAG .', 'One is the CSLU Toolkit rapid prototyping a incorporates a', '', '', '', '', '']","['To this end , several toolkits for building spoken dialogue systems have been developed #TAUTHOR_TAG .', 'One is the CSLU Toolkit rapid prototyping a incorpor', '', '', '', '', '']","['To this end , several toolkits for building spoken dialogue systems have been developed #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['The understanding :module receives wordes module incrementally sequencees update the statelt understanding and discourse information represented frame', 'The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search ) #TAUTHOR_TAG b ) , which is an integrated parsing and discourse processing method .', 'ISSS enables the incremental understanding of user utterances that are not segmented into sentences prior to pars-ing by incrementally finding the most pl sequence (or utterances in the) out of', '']","['The understanding :module receives word hypotheses module incrementally sequence hypotheses update the state, understanding and discourse information represented frame', 'The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search ) #TAUTHOR_TAG b ) , which is an integrated parsing and discourse processing method .', 'ISSS enables the incremental understanding of user utterances that are not segmented into sentences prior to pars-ing by incrementally finding the most sequence (or utterances in the terms) out of', '']","['The language understanding :module receives wordes incrementally the sequencees update the dialogue state, understanding and discourse information are represented a frame', 'The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search ) #TAUTHOR_TAG b ) , which is an integrated parsing and discourse processing method .', 'ISSS enables the incremental understanding of user utterances that are not segmented into sentences prior to pars-ing by incrementally finding the most plible sequence (or significant utterances in) out of', '']","['', 'The understanding module utilizes ISSS ( Incremental Significant-utterance Sequence Search ) #TAUTHOR_TAG b ) , which is an integrated parsing and discourse processing method .', 'ISSS enables the incremental understanding of user utterances that are not segmented into sentences prior to pars-ing by incrementally finding the most plausible sequence of sentences (or significant utterances in the ISSS terms) out of the possible sentence sequences for the input word sequence.', '']",5
"['Another common approach is term translation, e.g., via a bilingual lexicon. #TAUTHOR_TAG .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', '', '']","['Another common approach is term translation, e.g., via a bilingual lexicon. #TAUTHOR_TAG .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', '', '']","['Another common approach is term translation, e.g., via a bilingual lexicon. #TAUTHOR_TAG .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', '', '']","['Another common approach is term translation, e.g., via a bilingual lexicon. #TAUTHOR_TAG .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', '', '']",1
"['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method #TAUTHOR_TAG .', 'One such method is to treat different translations of the same term as synonyms.', 'Ball, for example used the INQUERY #AUTHOR_TAG synonym operator to group translations of different query terms.', '', '', 'ret', '']","['second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method #TAUTHOR_TAG .', 'One such method is to treat different translations of the same term as synonyms.', 'for example, used the INQUERY #AUTHOR_TAG synonym operator to group translations of different query terms.', '', '', '', '']","['A second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method #TAUTHOR_TAG .', 'One such method is to treat different translations of the same term as synonyms.', 'Ball, for example used the INQUERY #AUTHOR_TAG synonym operator to group translations of different query terms.', '', '', 'ret', '']","['A second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method #TAUTHOR_TAG .', 'One such method is to treat different translations of the same term as synonyms.', 'Ballesteros, for example, used the INQUERY #AUTHOR_TAG synonym operator to group translations of different query terms.', '', '', '', '']",1
"['The results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C.', 'Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries.', 'The one-sided t-test #TAUTHOR_TAG at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant .']","['The results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C.', 'Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries.', 'The one-sided t-test #TAUTHOR_TAG at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant .']","['The results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C.', 'Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries.', 'The one-sided t-test #TAUTHOR_TAG at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant .']","['The results in Table 4 show that manual disambiguation improves performance by 17% on Trec5C, 4% on Trec4S, but not at all on Trec6C.', 'Furthermore, the improvement on Trec5C appears to be caused by big improvements for a small number of queries.', 'The one-sided t-test #TAUTHOR_TAG at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant .']",5
"['The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI ) #AUTHOR_TAG , or the General Vector space model ( GVSM ) , #TAUTHOR_TAG .', 'We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in']","['The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI ) #AUTHOR_TAG , or the General Vector space model ( GVSM ) , #TAUTHOR_TAG .', 'We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in']","['The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI ) #AUTHOR_TAG , or the General Vector space model ( GVSM ) , #TAUTHOR_TAG .', 'We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in']","['The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI ) #AUTHOR_TAG , or the General Vector space model ( GVSM ) , #TAUTHOR_TAG .', 'We believe our approach is computationally less costly than (LSI and GVSM) and assumes less resources (WordNet in #AUTHOR_TAG .']",1
['â\x80¢ The transition probability a is 0.7 using the EM algorithm #TAUTHOR_TAG on the TREC4 ad-hoc query set .'],['â\x80¢ The transition probability a is 0.7 using the EM algorithm #TAUTHOR_TAG on the TREC4 ad-hoc query set .'],['â\x80¢ The transition probability a is 0.7 using the EM algorithm #TAUTHOR_TAG on the TREC4 ad-hoc query set .'],['â\x80¢ The transition probability a is 0.7 using the EM algorithm #TAUTHOR_TAG on the TREC4 ad-hoc query set .'],5
"['', '', 'While word sense disambiguation has been a central topic in previous studies for-ual IR on the value of disambiguation for cross-lingual IR include Hiernstra and de #AUTHOR_TAG', ' #TAUTHOR_TAG studied the issue of disambiguation for mono-lingual M.']","['', '', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, on the value of disambiguation for cross-lingual IR include Hiernstra and de #AUTHOR_TAG', ' #TAUTHOR_TAG studied the issue of disambiguation for mono-lingual M.']","['', '', 'While word sense disambiguation has been a central topic in previous studies for-ual IR, on the value of disambiguation for cross-lingual IR include Hiernstra and de #AUTHOR_TAG', ' #TAUTHOR_TAG studied the issue of disambiguation for mono-lingual M.']","['', '', '', ' #TAUTHOR_TAG studied the issue of disambiguation for mono-lingual M.']",0
"['is term a le', '.', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', 'Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de #TAUTHOR_TAG .', ' #AUTHOR_TAG studied the issue of disarnbiguation for mono-lingual IR.']","['is term a', '.', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', 'Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de #TAUTHOR_TAG .', ' #AUTHOR_TAG studied the issue of disarnbiguation for mono-lingual IR.']","['is term', ' #AUTHOR_TAG .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', 'Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de #TAUTHOR_TAG .', ' #AUTHOR_TAG studied the issue of disarnbiguation for mono-lingual IR.']","['', ' #AUTHOR_TAG .', 'While word sense disambiguation has been a central topic in previous studies for cross-lingual IR, our study suggests that using multiple weighted translations and compensating for the incompleteness of the lexicon may be more valuable.', 'Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de #TAUTHOR_TAG .', ' #AUTHOR_TAG studied the issue of disarnbiguation for mono-lingual IR.']",0
"['Many approaches to cross-lingual IR have been published.', 'One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries #TAUTHOR_TAG .', 'For most, there are no MT systems at all.', 'Our']","['Many approaches to cross-lingual IR have been published.', 'One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries #TAUTHOR_TAG .', 'For most languages, there are no MT systems at all.', 'Our']","['Many approaches to cross-lingual IR have been published.', 'One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries #TAUTHOR_TAG .', 'For most languages, there are no MT systems at all.', 'Our']","['Many approaches to cross-lingual IR have been published.', 'One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries #TAUTHOR_TAG .', 'For most languages, there are no MT systems at all.', '']",1
"['A second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method #TAUTHOR_TAG ; Hull 1997 ) .', 'One such method is to treat different translations of the same term as synonyms.', 'Ball INQU #AUTHOR_TAG synonym operator to group terms', '', '', '', '']","['A second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method #TAUTHOR_TAG ; Hull 1997 ) .', 'One such method is to treat different translations of the same term as synonyms.', 'INQUERY #AUTHOR_TAG synonym operator to group terms.', '', '', '', '']","['A second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method #TAUTHOR_TAG ; Hull 1997 ) .', 'One such method is to treat different translations of the same term as synonyms.', 'Ball the INQUERY #AUTHOR_TAG synonym operator to', '', '', '', '']","['A second method is to structure the translated query, separating the translations for one term from translations for other terms.', 'This approach limits how much credit the retrieval algorithm can give to a single term in the original query and prevents the translations of one or a few terms from swamping the whole query.', 'There are several variations of such a method #TAUTHOR_TAG ; Hull 1997 ) .', 'One such method is to treat different translations of the same term as synonyms.', '', '', '', '', '']",1
"['compare our approach with two other approaches', '', '', '', '', '3 may be than a document which contains.', 'the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur #TAUTHOR_TAG .']","['compare our approach with two other approaches.', '', '', '', '', 'a3 may be than a document which contains', 'the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur #TAUTHOR_TAG .']","['we compare our approach with two other approaches.', '', '', '', '', '3 may be ranked than a document which contains.', 'the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur #TAUTHOR_TAG .']","['In this section we compare our approach with two other approaches.', '', '', '', '', '', 'However , the second document is more likely to be relevant since correct translations of the query terms are more likely to co-occur #TAUTHOR_TAG .']",0
"['For Spanish, we download', '', '', 'A cooccurrence based stemmer #TAUTHOR_TAG was used to stem Spanish words .', 'its transl in to its transl in the le.', 'This is useful for translating proper n, spell ininely fromx']","['For Spanish, we downloaded', '', '', 'A cooccurrence based stemmer #TAUTHOR_TAG was used to stem Spanish words .', 'its translations in to its translations in the lexicon.', 'This is useful for translating proper nouns, spellings in routinely from']","['For Spanish, we downloaded', '', '', 'A cooccurrence based stemmer #TAUTHOR_TAG was used to stem Spanish words .', 'its in to its in the lexicon.', 'This is useful for translating proper nouns, in from']","['', '', '', 'A cooccurrence based stemmer #TAUTHOR_TAG was used to stem Spanish words .', '', '']",5
"['Other studies which view lR as a query generation process include #TAUTHOR_TAG .', 'Our work has focused on cross-lingual retrieval.']","['Other studies which view lR as a query generation process include #TAUTHOR_TAG .', 'Our work has focused on cross-lingual retrieval.']","['Other studies which view lR as a query generation process include #TAUTHOR_TAG .', 'Our work has focused on cross-lingual retrieval.']","['Other studies which view lR as a query generation process include #TAUTHOR_TAG .', 'Our work has focused on cross-lingual retrieval.']",1
"['Other studies which view lR as a query generation process include #TAUTHOR_TAG .', 'Our work has focused on cross-lingual retrieval.']","['Other studies which view lR as a query generation process include #TAUTHOR_TAG .', 'Our work has focused on cross-lingual retrieval.']","['Other studies which view lR as a query generation process include #TAUTHOR_TAG .', 'Our work has focused on cross-lingual retrieval.']","['Other studies which view lR as a query generation process include #TAUTHOR_TAG .', 'Our work has focused on cross-lingual retrieval.']",1
"['Another technique is automatic discovery of translations from parallel or non-parallel corpora #TAUTHOR_TAG .', 'Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies.']","['Another technique is automatic discovery of translations from parallel or non-parallel corpora #TAUTHOR_TAG .', 'Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies.']","['Another technique is automatic discovery of translations from parallel or non-parallel corpora #TAUTHOR_TAG .', 'Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies.']","['Another technique is automatic discovery of translations from parallel or non-parallel corpora #TAUTHOR_TAG .', 'Since traditional lexicons are more or less static repositories of knowledge, techniques that discover translation from newly published materials can supplement them with corpus-specific vocabularies.']",0
"['Following #TAUTHOR_TAG , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .', 'Rule PQ) is constant for a query and a a a is', 'The approach therefore estimates the probability that a Q is generated, given the document D is relevant.', '(A glossary of symbols used appears below.)']","['Following #TAUTHOR_TAG , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .', 'Rule, P(Q) is constant for a query, and a a a is', 'The approach therefore estimates the probability that a Q is generated, given the document D is relevant.', '(A glossary of symbols used appears below.)']","['Following #TAUTHOR_TAG , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .', 'PQ) is constant for a query and a uniform a document is', 'The approach therefore estimates the probability that a query Q is generated, given the document D is relevant.', '(A glossary of symbols used appears below.)']","['Following #TAUTHOR_TAG , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .', '', 'The approach therefore estimates the probability that a query Q is generated, given the document D is relevant.', '(A glossary of symbols used appears below.)']",5
"['', '', '', '', 'most of the recent work has been motivated by the observation shallow syntactic information can extracted using local information examining the pattern itself, nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', 'most of the recent work has been motivated by the observation shallow syntactic information can extracted using local information examining the pattern itself, nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', 'most of the recent work has been motivated by the observation shallow syntactic information can be extracted using local information -by examining the pattern itself, nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', 'would be chunked as follows #AUTHOR_TAG : While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information -by examining the pattern itself, its nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']",0
"['The first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim #TAUTHOR_TAG .', 'In this case, a full parse tree is represented in a flat form, producing a representation as in the example above.', 'The goal in this case is therefore to accurately predict a collection of ¢ £ ¢ different types of.', 'The chunk are based on the syntactic category part of the bracket label in the Treebank', '', '', '']","['The first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim #TAUTHOR_TAG .', 'In this case, a full parse tree is represented in a flat form, producing a representation as in the example above.', 'The goal in this case is therefore to accurately predict a collection of ¢ £ ¢ different types of phrases.', 'The chunk are based on the syntactic category part of the bracket label in the Treebank.', '', '', '']","['The first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim #TAUTHOR_TAG .', 'In this case, a full parse tree is represented in a flat form, producing a representation as in the example above.', 'The goal in this case is therefore to accurately predict a collection of ¢ £ ¢ different types of.', 'The chunk types are based on the syntactic category part of the bracket label in the Treebank.', '', '', '']","['The first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim #TAUTHOR_TAG .', 'In this case, a full parse tree is represented in a flat form, producing a representation as in the example above.', 'The goal in this case is therefore to accurately predict a collection of ¢ £ ¢ different types of phrases.', 'The chunk types are based on the syntactic category part of the bracket label in the Treebank.', '', '', '']",5
"['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']",0
"['', '', '', '', 'most of the recent work has been motivated by the observation shallow syntactic information can extracted using local information examining the pattern itself, nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', 'most of the recent work has been motivated by the observation shallow syntactic information can extracted using local information examining the pattern itself, nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', 'most of the recent work has been motivated by the observation shallow syntactic information can be extracted using local information -by examining the pattern itself, nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', 'would be chunked as follows #AUTHOR_TAG : While earlier work in this direction concentrated on manual construction of rules, most of the recent work has been motivated by the observation that shallow syntactic information can be extracted using local information -by examining the pattern itself, its nearby context and the local part-of-speech information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #TAUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']",0
"['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #AUTHOR_TAG b ; #AUTHOR_TAG a ; #TAUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #AUTHOR_TAG b ; #AUTHOR_TAG a ; #TAUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #AUTHOR_TAG b ; #AUTHOR_TAG a ; #TAUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #AUTHOR_TAG b ; #AUTHOR_TAG a ; #TAUTHOR_TAG .']",0
"['We perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins #TAUTHOR_TAG -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After it will choose the candidate parse tree with the highest probability as output', 'version', '']","['We perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins #TAUTHOR_TAG -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After it will choose the candidate parse tree with the highest probability as output.', 'version', '']","['We perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins #TAUTHOR_TAG -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After it will choose the candidate parse tree with the highest probability as output', 'the version', '']","['We perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins #TAUTHOR_TAG -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After that, it will choose the candidate parse tree with the highest probability as output.', '', '']",5
"['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #TAUTHOR_TAG b ; #AUTHOR_TAG a ; #AUTHOR_TAG .']",0
"['The shallow parser used is the SNoW-based CSCL parser #AUTHOR_TAG', 'SNoW #TAUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #AUTHOR_TAG', 'SNoW #TAUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #AUTHOR_TAG .', 'SNoW #TAUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #AUTHOR_TAG .', 'SNoW #TAUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '', '', '']",5
"['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', '', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']",0
"['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', '', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']",0
"['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']",0
"['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']","['Shallow parsing is studied as an alternative to full-sentence parsing.', 'Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text #TAUTHOR_TAG .', '', '', '', '']",0
"['First noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization #TAUTHOR_TAG .', '', '', '', '']","['First noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization #TAUTHOR_TAG .', '', '', '', '']","['First that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization #TAUTHOR_TAG .', '', '', '', '']","['First , it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization #TAUTHOR_TAG .', '', '', '', '']",0
"['NoW used only phrases #AUTHOR_TAG and never we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim #TAUTHOR_TAG to compare it to other shallow parsers .', 'Table 1 shows that it ranks among the top shallow parsers evaluated there 1 .']","['SNoW used only phrases #AUTHOR_TAG and never we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim #TAUTHOR_TAG to compare it to other shallow parsers .', 'Table 1 shows that it ranks among the top shallow parsers evaluated there 1 .']","['the SNoW were used only single phrases #AUTHOR_TAG and never we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim #TAUTHOR_TAG to compare it to other shallow parsers .', 'Table 1 shows that it ranks among the top shallow parsers evaluated there 1 .']","['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #AUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim #TAUTHOR_TAG to compare it to other shallow parsers .', 'Table 1 shows that it ranks among the top shallow parsers evaluated there 1 .']",5
"['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', '', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']",0
"['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #AUTHOR_TAG b ; #AUTHOR_TAG a ; #TAUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #AUTHOR_TAG b ; #AUTHOR_TAG a ; #TAUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #AUTHOR_TAG b ; #AUTHOR_TAG a ; #TAUTHOR_TAG .']","['Overall, the driving force behind the work on learning shallow parsers was the desire to get better performance and higher reliability.', 'However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time #AUTHOR_TAG b ; #AUTHOR_TAG a ; #TAUTHOR_TAG .']",0
"['The shallow parser used is the SNoW-based CSCL parser #TAUTHOR_TAG .', 'SNoW #AUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example', 'works by learning a sparse network of linear functions over a pre-defined or incrementally feature', 'NoW used as a class predicts a winner mechanism target', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #TAUTHOR_TAG .', 'SNoW #AUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'works by learning a sparse network of linear functions over a pre-defined or incrementally feature', 'SNoW used as a predicts a mechanism target', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #TAUTHOR_TAG .', 'SNoW #AUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'It works by learning a sparse network of linear functions over a pre-defined or increment', ', SNoW is used as a classifier, predicts using', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #TAUTHOR_TAG .', 'SNoW #AUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', '', '', '', '']",5
"['We by reporting the results in which we compare the full parser and the shallow parser on the ""clean"" WSJ data.', 'Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim #TAUTHOR_TAG terminology .', 'The results show that for the tasks of identifying phrases, learning directly, as done by the shallow parser outperforms the outcome from the full parser.', 'we compared the performance of the parsers on the task of identifying atomic phrases ', 'its.', 'Table3 shows the results of extracting atomic phrases.']","['We by reporting the results in which we compare the full parser and the shallow parser on the ""clean"" WSJ data.', 'Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim #TAUTHOR_TAG terminology .', 'The results show that for the tasks of identifying phrases, learning directly, as done by the shallow parser outperforms the outcome from the full parser.', 'we compared the performance of the parsers on the task of identifying atomic phrases 2', 'exhibits performance.', 'Table 3 shows the results of extracting atomic phrases.']","['We start by reporting the results in which we compare the full parser and the shallow parser on the ""clean"" WSJ data.', 'Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim #TAUTHOR_TAG terminology .', 'The results show that for the tasks of identifying phrases, learning directly, as done by the shallow parser outperforms the outcome from the full parser.', 'we compared the performance of the parsers on the task of identifying atomic phrases 2', '.', 'Table3 shows the results of extracting atomic phrases.']","['We start by reporting the results in which we compare the full parser and the shallow parser on the ""clean"" WSJ data.', 'Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim #TAUTHOR_TAG terminology .', 'The results show that for the tasks of identifying phrases, learning directly, as done by the shallow parser outperforms the outcome from the full parser.', 'Next, we compared the performance of the parsers on the task of identifying atomic phrases 2 .', '', 'Table 3 shows the results of extracting atomic phrases.']",5
"['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', '', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']",0
"['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #TAUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 #AUTHOR_TAG to compare it to other shallow parsers', 'Table1 ']","['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #TAUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 #AUTHOR_TAG to compare it to other shallow parsers', 'Table 1 1']","['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #TAUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 #AUTHOR_TAG to compare it to other shallow parsers .', 'Table 1 shows ']","['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #TAUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 #AUTHOR_TAG to compare it to other shallow parsers .', '']",2
"['Research on shallow parsing was inspired by psycholinguistics arguments #TAUTHOR_TAG that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint .']","['Research on shallow parsing was inspired by psycholinguistics arguments #TAUTHOR_TAG that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint .']","['Research on shallow parsing was inspired by psycholinguistics arguments #TAUTHOR_TAG that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint .']","['Research on shallow parsing was inspired by psycholinguistics arguments #TAUTHOR_TAG that suggest that in many scenarios ( e.g. , conversational ) full parsing is not a realistic strategy for sentence processing and analysis , and was further motivated by several arguments from a natural language engineering viewpoint .']",0
"['We perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins #TAUTHOR_TAG -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After it will choose the candidate parse tree with the highest probability as output', 'version', '']","['We perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins #TAUTHOR_TAG -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After it will choose the candidate parse tree with the highest probability as output.', 'version', '']","['We perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins #TAUTHOR_TAG -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After it will choose the candidate parse tree with the highest probability as output', 'the version', '']","['We perform our comparison using two state-ofthe-art parsers.', 'For the full parser , we use the one developed by Michael Collins #TAUTHOR_TAG -- one of the most accurate full parsers around .', 'It represents a full parse tree as a set of basic phrases and a set of dependency relationships between them.', 'Statistical learning techniques are used to compute the probabilities of these phrases and of candidate dependency relations occurring in that sentence.', 'After that, it will choose the candidate parse tree with the highest probability as output.', '', '']",5
"['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', '', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']",0
"['The shallow parser used is the SNoW-based CSCL parser #TAUTHOR_TAG .', 'SNoW #AUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example', 'works by learning a sparse network of linear functions over a pre-defined or incrementally feature', 'NoW used as a class predicts a winner mechanism target', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #TAUTHOR_TAG .', 'SNoW #AUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'works by learning a sparse network of linear functions over a pre-defined or incrementally feature', 'SNoW used as a predicts a mechanism target', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #TAUTHOR_TAG .', 'SNoW #AUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'It works by learning a sparse network of linear functions over a pre-defined or increment', ', SNoW is used as a classifier, predicts using', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #TAUTHOR_TAG .', 'SNoW #AUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources (features) taking part in decisions is very large, of which NLP is a principal example.', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', '', '', '', '']",5
"['The shallow parser used is the SNoW-based CSCL parser #AUTHOR_TAG', 'SNoW #TAUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #AUTHOR_TAG', 'SNoW #TAUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #AUTHOR_TAG .', 'SNoW #TAUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '', '', '']","['The shallow parser used is the SNoW-based CSCL parser #AUTHOR_TAG .', 'SNoW #TAUTHOR_TAG is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .', 'It works by learning a sparse network of linear functions over a pre-defined or incrementally learned feature space.', 'Typically, SNoW is used as a classifier, and predicts using a winner-take-all mechanism over the activation value of the target classes.', '', '', '']",5
"['', '', 'of recent work on shallow parsing has been influenced by Abney�s work to �chunk� sentences to base level', 'the �He reckons the current account deficit will narrow to only $ 1.8 billion in September .�', 'would be chunked as follows ( Tjong Kim #TAUTHOR_TAG : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .']","['', '', 'of recent work on shallow parsing has been influenced by Abney�s work to �chunk� sentences to base level', 'the �He reckons the current account deficit will narrow to only $ 1.8 billion in September .�', 'would be chunked as follows ( Tjong Kim #TAUTHOR_TAG : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .']","['', '', 'of recent work on shallow parsing has been influenced by Abney�s work to �chunk� sentences to base', ', the sentence �He reckons the current account deficit will narrow to only $ 1.8 billion in September .�', 'would be chunked as follows ( Tjong Kim #TAUTHOR_TAG : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .']","['', '', 'A lot of recent work on shallow parsing has been influenced by Abney�s work #AUTHOR_TAG , who has suggested to �chunk� sentences to base level phrases.', 'For example, the sentence �He reckons the current account deficit will narrow to only $ 1.8 billion in September .�', 'would be chunked as follows ( Tjong Kim #TAUTHOR_TAG : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP to ] [NP only $ 1.8 billion ] [PP in ] [NP September] .']",0
"['First noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization #TAUTHOR_TAG .', '', '', '', '']","['First noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization #TAUTHOR_TAG .', '', '', '', '']","['First that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization #TAUTHOR_TAG .', '', '', '', '']","['First , it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization #TAUTHOR_TAG .', '', '', '', '']",0
"['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', '', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']",0
"['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', 'of the recent work has been motivated', ', , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']","['', '', '', '', '', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #AUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #TAUTHOR_TAG .']",0
"['', '', '', '', 'most of the recent work has been motivated by information pattern and information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #TAUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', 'most of the recent work has been motivated by information pattern and information.', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #TAUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', 'most of the recent work has been motivated by the pattern and', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #TAUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']","['', '', '', '', '', 'Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers #AUTHOR_TAG a ; #AUTHOR_TAG b ; #TAUTHOR_TAG , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship #AUTHOR_TAG .']",0
"['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #TAUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 #AUTHOR_TAG to compare it to other shallow parsers', 'Table1 ']","['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #TAUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 #AUTHOR_TAG to compare it to other shallow parsers', 'Table 1 1']","['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #TAUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 #AUTHOR_TAG to compare it to other shallow parsers .', 'Table 1 shows ']","['Since earlier versions of the SNoW based CSCL were used only to identify single phrases #TAUTHOR_TAG and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 #AUTHOR_TAG to compare it to other shallow parsers .', '']",2
"['Training was done on the Penn Treebank #TAUTHOR_TAG Wall Street Journal data , sections 02-21 .', '', '']","['Training was done on the Penn Treebank #TAUTHOR_TAG Wall Street Journal data , sections 02-21 .', '', '']","['Training was done on the Penn Treebank #TAUTHOR_TAG Wall Street Journal data , sections 02-21 .', '', '']","['Training was done on the Penn Treebank #TAUTHOR_TAG Wall Street Journal data , sections 02-21 .', '', '']",5
"['Tateisi et al. also translated LTAG into HPSG #TAUTHOR_TAG .', 'However, their method depended on translator�s intuitive analy- sis of the original grammar.', 'Thus the transla- tion was manual and grammar dependent.', 'The manual translation demanded considerable efforts from the translator, and obscures the equiva- lence between the original and obtained gram- mars.', 'Other works convert HPSG grammars into LTAG grammars.', '', '', '']","['Tateisi et al. also translated LTAG into HPSG #TAUTHOR_TAG .', 'However, their method depended on translator�s intuitive analy- sis of the original grammar.', 'Thus the transla- tion was manual and grammar dependent.', 'The manual translation demanded considerable efforts from the translator, and obscures the equiva- lence between the original and obtained gram- mars.', 'Other works convert HPSG grammars into LTAG grammars.', '', '', '']","['Tateisi et al. also translated LTAG into HPSG #TAUTHOR_TAG .', 'However, their method depended on translator�s intuitive analy- sis of the original grammar.', 'Thus the transla- tion was manual and grammar dependent.', 'The manual translation demanded considerable efforts from the translator, and obscures the equiva- lence between the original and obtained gram- mars.', 'Other works #AUTHOR_TAG convert HPSG grammars into LTAG grammars.', '', '', '']","['Tateisi et al. also translated LTAG into HPSG #TAUTHOR_TAG .', 'However, their method depended on translator�s intuitive analy- sis of the original grammar.', 'Thus the transla- tion was manual and grammar dependent.', 'The manual translation demanded considerable efforts from the translator, and obscures the equiva- lence between the original and obtained gram- mars.', 'Other works #AUTHOR_TAG convert HPSG grammars into LTAG grammars.', '', '', '']",1
"['There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #TAUTHOR_TAG , and ones on programming/grammar-development environ - #AUTHOR_TAG .', 'These works are restricted to each closed community, and the relation between them is not discussed.', 'Invest relation apparently for both communities']","['There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #TAUTHOR_TAG , and ones on programming/grammar-development environ - #AUTHOR_TAG .', 'These works are restricted to each closed community, and the relation between them is not discussed.', 'relation apparently for both communities.']","['There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #TAUTHOR_TAG , and ones on programming/grammar-development environ - #AUTHOR_TAG .', 'These works are restricted to each closed community, and the relation between them is not well discussed.', 'Invest for both communities.']","['There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #TAUTHOR_TAG , and ones on programming/grammar-development environ - #AUTHOR_TAG .', 'These works are restricted to each closed community, and the relation between them is not well discussed.', '']",0
"['', 'apply system latest themarThe XTAG #AUTHOR_TAG which is a large-scale FB-LTAG grammar.', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser #TAUTHOR_TAG .', 'This result implies that parsing techniques for HPSG are also beneficial for LTAG parsing.', 'We can say that the grammar conversion enables us to share HPSG parsing techniques in LTAG parsing.']","['', 'apply system latest the grammar (The XTAG #AUTHOR_TAG which is a large-scale FB-LTAG grammar.', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser #TAUTHOR_TAG .', 'This result implies that parsing techniques for HPSG are also beneficial for LTAG parsing.', 'We can say that the grammar conversion enables us to share HPSG parsing techniques in LTAG parsing.']","['', 'We apply systemThe XTAG #AUTHOR_TAG which is a large-scale FB-LTAG grammar.', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser #TAUTHOR_TAG .', 'This result implies that parsing techniques for HPSG are also beneficial for LTAG parsing.', 'We can say that the grammar conversion enables us to share HPSG parsing techniques in LTAG parsing.']","['', 'We apply our system to the latest version of the XTAG English grammar (The XTAG #AUTHOR_TAG , which is a large-scale FB-LTAG grammar.', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser #TAUTHOR_TAG .', 'This result implies that parsing techniques for HPSG are also beneficial for LTAG parsing.', 'We can say that the grammar conversion enables us to share HPSG parsing techniques in LTAG parsing.']",1
"['Table2 shows the average parsing time with the LTAG and HPSG parsers.', 'Table2, lem refers to the LTAG parser , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing (van #AUTHOR_TAG without features (phase 1), and then executes feature unification (phase 2).', 'TNT refers to the HPSG parser #TAUTHOR_TAG , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 )', 'Table shows that the HPSG parser is significantly the LTAG', '', '', '']","['Table 2 shows the average parsing time with the LTAG and HPSG parsers.', 'Table 2, lem refers to the LTAG parser , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing (van #AUTHOR_TAG without features (phase 1), and then executes feature unification (phase 2).', 'TNT refers to the HPSG parser #TAUTHOR_TAG , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 )', 'Table shows that the HPSG parser is significantly the LTAG', '', '', '']","['Table2 shows the average parsing time with the LTAG and HPSG parsers.', 'Table 2, lem refers to the LTAG parser , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing (van #AUTHOR_TAG without features (phase 1), and then executes feature unification (phase 2).', 'TNT refers to the HPSG parser #TAUTHOR_TAG , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 )', 'Table shows that the HPSG parser is significantly faster the LTAG parser.', '', '', '']","['Table 2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2, lem refers to the LTAG parser , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing (van #AUTHOR_TAG without features (phase 1), and then executes feature unification (phase 2).', 'TNT refers to the HPSG parser #TAUTHOR_TAG , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 ) .', 'Table 2 clearly shows that the HPSG parser is significantly faster than the LTAG parser.', '', '', '']",1
"['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay- #AUTHOR_TAG Vijay- #AUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #TAUTHOR_TAG by a method of grammar conversion .', 'The a', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay- #AUTHOR_TAG Vijay- #AUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #TAUTHOR_TAG by a method of grammar conversion .', 'The a', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay- #AUTHOR_TAG Vijay- #AUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #TAUTHOR_TAG by a method of grammar conversion .', '', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay- #AUTHOR_TAG Vijay- #AUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #TAUTHOR_TAG by a method of grammar conversion .', '', '', '']",0
"['', '', '', '', '', '', 'the node labeled onto an internal node of another tree with the symbol (Figure 4).', 'FBLTAG #TAUTHOR_TAG is an extension of the LTAG formalism .', 'mat.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG', '', 'a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', 'the node labeled onto an internal node of another tree with the symbol (Figure 4).', 'FBLTAG #TAUTHOR_TAG is an extension of the LTAG formalism .', 'node.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG', '', 'a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', 'foot node labeled onto an internal node of another tree with the same symbol Ü (Figure 4).', 'FBLTAG #TAUTHOR_TAG is an extension of the LTAG formalism .', 'mat', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG .', '', 'a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', '', 'FBLTAG #TAUTHOR_TAG is an extension of the LTAG formalism .', '', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG .', '', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']",0
"['ment #TAUTHOR_TAG .', 'These works are re- stricted to each closed community, and the rela- tion between them is not well discussed.', 'Investi- gating the relation will be apparently valuable for both communities.']","['ment #TAUTHOR_TAG .', 'These works are re- stricted to each closed community, and the rela- tion between them is not well discussed.', 'Investi- gating the relation will be apparently valuable for both communities.']","['ment #TAUTHOR_TAG .', 'These works are re- stricted to each closed community, and the rela- tion between them is not well discussed.', 'Investi- gating the relation will be apparently valuable for both communities.']","['ment #TAUTHOR_TAG .', 'These works are re- stricted to each closed community, and the rela- tion between them is not well discussed.', 'Investi- gating the relation will be apparently valuable for both communities.']",0
"['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) #TAUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #AUTHOR_TAG by a method of grammar conversion .', 'The RenAL automaticallyts an FB-TAGmar into a strongly equivalent', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) #TAUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #AUTHOR_TAG by a method of grammar conversion .', 'The RenTAL automatically converts an FB-LTAG grammar into a strongly equivalent', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) #TAUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #AUTHOR_TAG by a method of grammar conversion .', 'The RenTAL system automaticallyts an FB-LTAG grammar into', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) #TAUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #AUTHOR_TAG by a method of grammar conversion .', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar .', '', '']",0
['LTAG #TAUTHOR_TAG is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera - Figure 6: Parsing with an HPSG grammar'],['LTAG #TAUTHOR_TAG is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera - Figure 6: Parsing with an HPSG grammar'],['LTAG #TAUTHOR_TAG is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera - Figure 6: Parsing with an HPSG grammar'],['LTAG #TAUTHOR_TAG is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera - Figure 6: Parsing with an HPSG grammar'],0
"['are a of works on efficient parsing with, the ofbased processing in practical application context', 'theGO', 'In practical context , German , English , and Japanese HPSG-based grammars are developed and used in the Verbmobil project #TAUTHOR_TAG .', '']","['are a of works on efficient parsing with the of processing in practical application contexts', 'the', 'In practical context , German , English , and Japanese HPSG-based grammars are developed and used in the Verbmobil project #TAUTHOR_TAG .', '']","['are a variety of works on efficient parsing with, the use ofbased processing in practical application contexts .', 'GO', 'In practical context , German , English , and Japanese HPSG-based grammars are developed and used in the Verbmobil project #TAUTHOR_TAG .', '']","['There are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', '', 'In practical context , German , English , and Japanese HPSG-based grammars are developed and used in the Verbmobil project #TAUTHOR_TAG .', '']",0
"['', '', '', 'Our group has developed a wide-coverage HPSG grammar for Japanese #TAUTHOR_TAG , which is used in a high-accuracy Japanese dependency analyzer #AUTHOR_TAG .']","['', '', '', 'Our group has developed a wide-coverage HPSG grammar for Japanese #TAUTHOR_TAG , which is used in a high-accuracy Japanese dependency analyzer #AUTHOR_TAG .']","['', '', '', 'Our group has developed a wide-coverage HPSG grammar for Japanese #TAUTHOR_TAG , which is used in a high-accuracy Japanese dependency analyzer #AUTHOR_TAG .']","['', '', '', 'Our group has developed a wide-coverage HPSG grammar for Japanese #TAUTHOR_TAG , which is used in a high-accuracy Japanese dependency analyzer #AUTHOR_TAG .']",0
"['Figure 1 depicts a sketch.', 'system consistsor', '', '', '', '', '', '', 'Other works #TAUTHOR_TAG convert HPSG grammars into LTAG grammars .', 'given the greater expressive power of HPS, it is impossible to convert an arbitrary HPSG gram into an LTAG gram', '', '']","['Figure 1 depicts a sketch system.', 'system consists', '', '', '', '', '', '', 'Other works #TAUTHOR_TAG convert HPSG grammars into LTAG grammars .', 'given the greater expressive power of HPSG, it is impossible to convert an arbitrary HPSG grammar into an LTAG', '', '']","['Figure 1 depicts a brief sketch', 'The system consists', '', '', '', '', '', '', 'Other works #TAUTHOR_TAG convert HPSG grammars into LTAG grammars .', 'given the greater expressive power of HPS, it is impossible to convert an arbitrary HPSG grammar into an LTAG grammar.', '', '']","['Figure 1 depicts a brief sketch of the RenTAL system.', '', '', '', '', '', '', '', 'Other works #TAUTHOR_TAG convert HPSG grammars into LTAG grammars .', 'However, given the greater expressive power of HPSG, it is impossible to convert an arbitrary HPSG grammar into an LTAG grammar.', '', '']",1
"['', '', '', 'Our group has developed a wide-coverage HPSG grammar for Japanese #AUTHOR_TAG , which is used in a high-accuracy Japanese dependency analyzer #TAUTHOR_TAG .']","['', '', '', 'Our group has developed a wide-coverage HPSG grammar for Japanese #AUTHOR_TAG , which is used in a high-accuracy Japanese dependency analyzer #TAUTHOR_TAG .']","['', '', '', 'Our group has developed a wide-coverage HPSG grammar for Japanese #AUTHOR_TAG , which is used in a high-accuracy Japanese dependency analyzer #TAUTHOR_TAG .']","['', '', '', 'Our group has developed a wide-coverage HPSG grammar for Japanese #AUTHOR_TAG , which is used in a high-accuracy Japanese dependency analyzer #TAUTHOR_TAG .']",0
"['An HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures #TAUTHOR_TAG .', 'A lexical entry for each word expresses the characteristics of the word, such as the subcategorization frame and the grammatical category.', 'An grammar mother and independent lex', '', '']","['An HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures #TAUTHOR_TAG .', 'A lexical entry for each word expresses the characteristics of the word, such as the subcategorization frame and the grammatical category.', 'An grammar mother and independent lexical', '', '']","['An HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures #TAUTHOR_TAG .', 'A lexical entry for each word expresses the characteristics of the word, such as the subcategorization frame and the grammatical category.', 'An ID grammar rule a mother and independent lex', '', '']","['An HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures #TAUTHOR_TAG .', 'A lexical entry for each word expresses the characteristics of the word, such as the subcategorization frame and the grammatical category.', '', '', '']",0
"['are each comput have', 'We apply our system to the latest version of the XTAG English grammar ( The XTAG Research #TAUTHOR_TAG , which is a large-scale FB-LTAG grammar .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing L', '', '']","['are each computational have', 'We apply our system to the latest version of the XTAG English grammar ( The XTAG Research #TAUTHOR_TAG , which is a large-scale FB-LTAG grammar .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG', '', '']","['are each computational framework have never', 'We apply our system to the latest version of the XTAG English grammar ( The XTAG Research #TAUTHOR_TAG , which is a large-scale FB-LTAG grammar .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser .', '', '']","['', 'We apply our system to the latest version of the XTAG English grammar ( The XTAG Research #TAUTHOR_TAG , which is a large-scale FB-LTAG grammar .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser .', '', '']",5
"['', '', '', '', '', '', '', '', '', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG .', 'The XTAG group #TAUTHOR_TAG at the University of Pennsylvania is also developing Korean , Chinese , and Hindi grammars .', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', '', '', '', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG .', 'The XTAG group #TAUTHOR_TAG at the University of Pennsylvania is also developing Korean , Chinese , and Hindi grammars .', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', '', '', '', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG .', 'The XTAG group #TAUTHOR_TAG at the University of Pennsylvania is also developing Korean , Chinese , and Hindi grammars .', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', '', '', '', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG .', 'The XTAG group #TAUTHOR_TAG at the University of Pennsylvania is also developing Korean , Chinese , and Hindi grammars .', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']",0
"['This paper describes an approach for sharing resources in various grammar formal such as Feature-Based Lexicalized Tree Adjoin-ing Grammar (FB-LTAG 1 ) (Vijay- #AUTHOR_TAG Vijay- #AUTHOR_TAG and Head-Driven Phrase Structure Grammar (HPSG) method', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar #TAUTHOR_TAG .', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoin-ing Grammar (FB-LTAG 1 ) (Vijay- #AUTHOR_TAG Vijay- #AUTHOR_TAG and Head-Driven Phrase Structure Grammar (HPSG) method', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar #TAUTHOR_TAG .', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoin-ing Grammar (FB-LTAG 1 ) (Vijay- #AUTHOR_TAG Vijay- #AUTHOR_TAG and Head-Driven Phrase Structure Grammar (HPSG) a method', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar #TAUTHOR_TAG .', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoin-ing Grammar (FB-LTAG 1 ) (Vijay- #AUTHOR_TAG Vijay- #AUTHOR_TAG and Head-Driven Phrase Structure Grammar (HPSG) #AUTHOR_TAG by a method of grammar conversion.', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar #TAUTHOR_TAG .', '', '']",0
"['Table 2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2 , lem refers to the LTAG parser #TAUTHOR_TAG , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing ( van #AUTHOR_TAG without features ( phase 1 ) , and then executes feature unification ( phase 2 ) .', 'NT refers to the HPSG parser , C++ implementation of the two-phase parsing algorithm that performs filtering with a CF)', '', '', '', '']","['Table 2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2 , lem refers to the LTAG parser #TAUTHOR_TAG , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing ( van #AUTHOR_TAG without features ( phase 1 ) , and then executes feature unification ( phase 2 ) .', 'TNT refers to the HPSG parser , C++ implementation of the two-phase parsing algorithm that performs filtering with a CFG', '', '', '', '']","['Table 2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2 , lem refers to the LTAG parser #TAUTHOR_TAG , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing ( van #AUTHOR_TAG without features ( phase 1 ) , and then executes feature unification ( phase 2 ) .', 'NT refers to the HPSG parser , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG', '', '', '', '']","['Table 2 shows the average parsing time with the LTAG and HPSG parsers.', 'In Table 2 , lem refers to the LTAG parser #TAUTHOR_TAG , ANSI C implementation of the two-phase parsing algorithm that performs the head corner parsing ( van #AUTHOR_TAG without features ( phase 1 ) , and then executes feature unification ( phase 2 ) .', 'TNT refers to the HPSG parser , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG (phase 1) and then executes feature unification (phase 2).', '', '', '', '']",1
"['', '', '', '', '', '', 'the node labeled onto an internal node of another tree with the symbol (Figure 4).', 'FBLTAG #TAUTHOR_TAG is an extension of the LTAG formalism .', 'mat.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG', '', 'a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', 'the node labeled onto an internal node of another tree with the symbol (Figure 4).', 'FBLTAG #TAUTHOR_TAG is an extension of the LTAG formalism .', 'node.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG', '', 'a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', 'foot node labeled onto an internal node of another tree with the same symbol Ü (Figure 4).', 'FBLTAG #TAUTHOR_TAG is an extension of the LTAG formalism .', 'mat', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG .', '', 'a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', '', 'FBLTAG #TAUTHOR_TAG is an extension of the LTAG formalism .', '', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism, including the XTAG English grammar, a large-scale grammar for English (The XTAG #AUTHOR_TAG .', '', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']",0
"['There are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', 'Stanford University is developing the English Resource Grammar , an HPSG grammar for English , as a part of the Linguistic Grammars Online ( LinGO ) project #TAUTHOR_TAG .', '', '']","['There are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', 'Stanford University is developing the English Resource Grammar , an HPSG grammar for English , as a part of the Linguistic Grammars Online ( LinGO ) project #TAUTHOR_TAG .', '', '']","['There are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', 'Stanford University is developing the English Resource Grammar , an HPSG grammar for English , as a part of the Linguistic Grammars Online ( LinGO ) project #TAUTHOR_TAG .', '', '']","['There are a variety of works on efficient parsing with HPSG, which allow the use of HPSGbased processing in practical application contexts .', 'Stanford University is developing the English Resource Grammar , an HPSG grammar for English , as a part of the Linguistic Grammars Online ( LinGO ) project #TAUTHOR_TAG .', '', '']",0
"['Our concern gramm lex', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development environment #TAUTHOR_TAG .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities.']","['Our concern grammars', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development environment #TAUTHOR_TAG .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities.']","['Our gramm lex', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development environment #TAUTHOR_TAG .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities.']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development environment #TAUTHOR_TAG .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities.']",0
"['The RenTAL system is implemented in LiL-FeS #AUTHOR_TAG 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic , and efficient HPSG parsers have already been built on this system #TAUTHOR_TAG .', 'We applied our system to the XTAG English grammar ( #AUTHOR_TAG 3', '', '']","['The RenTAL system is implemented in LiL-FeS #AUTHOR_TAG 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic , and efficient HPSG parsers have already been built on this system #TAUTHOR_TAG .', 'We applied our system to the XTAG English grammar (The #AUTHOR_TAG 3', '', '']","['The RenTAL system is implemented in LiL-FeS #AUTHOR_TAG 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic , and efficient HPSG parsers have already been built on this system #TAUTHOR_TAG .', 'We applied our system to the XTAG English grammar ( #AUTHOR_TAG 3', '', '']","['The RenTAL system is implemented in LiL-FeS #AUTHOR_TAG 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic , and efficient HPSG parsers have already been built on this system #TAUTHOR_TAG .', '', '', '']",0
"['', '', '', '', '', '', 'Another paper #TAUTHOR_TAG describes the detailed analysis on the factor of the difference of parsing performance .']","['', '', '', '', '', '', 'Another paper #TAUTHOR_TAG describes the detailed analysis on the factor of the difference of parsing performance .']","['', '', '', '', '', '', 'Another paper #TAUTHOR_TAG describes the detailed analysis on the factor of the difference of parsing performance .']","['', '', '', '', '', '', 'Another paper #TAUTHOR_TAG describes the detailed analysis on the factor of the difference of parsing performance .']",0
"['The RenAL system is implemented in LiL-FeS #AUTHOR_TAG 2', 'feature', 'system XTAG English grammar ( XTAG #AUTHOR_TAG 3 , a large-scaleB-LTAG grammar for English', 'The original and the obtained grammar generated exactly the same number of derivation trees in the parsing experiment with 457 sentences from the ATIS corpus #TAUTHOR_TAG 6 ( the average length is 6.32 words ) .', 'This result empirically attested the strong equivalence of our algorithm.']","['The RenTAL system is implemented in LiL-FeS #AUTHOR_TAG 2', 'feature', 'system XTAG English grammar (The XTAG #AUTHOR_TAG 3 , a large-scale FB-LTAG grammar for English.', 'The original and the obtained grammar generated exactly the same number of derivation trees in the parsing experiment with 457 sentences from the ATIS corpus #TAUTHOR_TAG 6 ( the average length is 6.32 words ) .', 'This result empirically attested the strong equivalence of our algorithm.']","['The RenTAL system is implemented in LiL-FeS #AUTHOR_TAG 2', '', 'system the XTAG English grammar (The XTAG #AUTHOR_TAG 3 , a large-scale FB-LTAG grammar for English', 'The original and the obtained grammar generated exactly the same number of derivation trees in the parsing experiment with 457 sentences from the ATIS corpus #TAUTHOR_TAG 6 ( the average length is 6.32 words ) .', 'This result empirically attested the strong equivalence of our algorithm.']","['The RenTAL system is implemented in LiL-FeS #AUTHOR_TAG 2 .', '', 'We applied our system to the XTAG English grammar (The XTAG #AUTHOR_TAG 3 , which is a large-scale FB-LTAG grammar for English.', 'The original and the obtained grammar generated exactly the same number of derivation trees in the parsing experiment with 457 sentences from the ATIS corpus #TAUTHOR_TAG 6 ( the average length is 6.32 words ) .', 'This result empirically attested the strong equivalence of our algorithm.']",5
"['The RenTAL system is implemented in LiLFeS #TAUTHOR_TAG 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic, and efficient HPSG parsers have already been built on this system #AUTHOR_TAG .', 'We applied our system to the XTAG English grammar 3', '', '']","['The RenTAL system is implemented in LiLFeS #TAUTHOR_TAG 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic, and efficient HPSG parsers have already been built on this system #AUTHOR_TAG .', 'We applied our system to the XTAG English grammar 3', '', '']","['The RenTAL system is implemented in LiLFeS #TAUTHOR_TAG 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic, and efficient HPSG parsers have already been built on this system #AUTHOR_TAG .', 'We applied our system to the XTAG English grammar #AUTHOR_TAG 3', '', '']","['The RenTAL system is implemented in LiLFeS #TAUTHOR_TAG 2 .', 'LiLFeS is one of the fastest inference engines for processing feature structure logic, and efficient HPSG parsers have already been built on this system #AUTHOR_TAG .', '', '', '']",5
"['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) #TAUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #AUTHOR_TAG by a method of grammar conversion .', 'The RenAL automaticallyts an FB-TAGmar into a strongly equivalent', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) #TAUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #AUTHOR_TAG by a method of grammar conversion .', 'The RenTAL automatically converts an FB-LTAG grammar into a strongly equivalent', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) #TAUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #AUTHOR_TAG by a method of grammar conversion .', 'The RenTAL system automaticallyts an FB-LTAG grammar into', '', '']","['This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) #TAUTHOR_TAG and Head-Driven Phrase Structure Grammar ( HPSG ) #AUTHOR_TAG by a method of grammar conversion .', 'The RenTAL system automatically converts an FB-LTAG grammar into a strongly equivalent HPSG-style grammar .', '', '']",0
"['Our concern gramm and lex', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development #TAUTHOR_TAG .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities.']","['Our concern grammars and', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development #TAUTHOR_TAG .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities.']","['Our gramm and lex', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development #TAUTHOR_TAG .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities.']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #AUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development #TAUTHOR_TAG .', 'These works are re-stricted to each closed community, and the relation between them is not well discussed.', 'Investigating the relation will be apparently valuable for both communities.']",0
"['Our concern gramm and lexicons', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #TAUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development environment #AUTHOR_TAG .', 'These works are restricted to each closed community, and the relation is not discussed.', 'Invest for both communities']","['Our concern grammars and lexicons.', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #TAUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development environment #AUTHOR_TAG .', 'These works are restricted to each closed community, and the relation is not discussed.', 'for both communities.']","['Our gramm and lexicons', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #TAUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development environment #AUTHOR_TAG .', 'These works are restricted to each closed community, and the relation them is not well discussed.', 'Invest for both communities.']","['', 'Strongly equivalent grammars enable the sharing of ideas developed in each formalism.', 'There have been many studies on parsing techniques #TAUTHOR_TAG , ones on disambiguation models #AUTHOR_TAG , and ones on programming/grammar-development environment #AUTHOR_TAG .', 'These works are restricted to each closed community, and the relation between them is not well discussed.', '']",0
['The grammar conversion from LTAG to HPSG #TAUTHOR_TAG is the core portion of the RenTAL system .'],['The grammar conversion from LTAG to HPSG #TAUTHOR_TAG is the core portion of the RenTAL system .'],['The grammar conversion from LTAG to HPSG #TAUTHOR_TAG is the core portion of the RenTAL system .'],['The grammar conversion from LTAG to HPSG #TAUTHOR_TAG is the core portion of the RenTAL system .'],0
"['', '', '', '', '', '', '', 'B-LTAG (V-', 'FB-LTAG each the feature structure containing grammatical on the.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research #TAUTHOR_TAG .', 'The XTAG group #AUTHOR_TAG at the University of Pennsylvania is also developing Korean, Chinese, and Hindi grammars.', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', '', 'FB-LTAG', 'FB-LTAG, each the feature structure, containing grammatical on the node.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research #TAUTHOR_TAG .', 'The XTAG group #AUTHOR_TAG at the University of Pennsylvania is also developing Korean, Chinese, and Hindi grammars.', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', '', 'B-LTAG (V-', 'FB-LTAG each node a feature structure, containing grammatical constraints on the node.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research #TAUTHOR_TAG .', 'The XTAG group #AUTHOR_TAG at the University of Pennsylvania is also developing Korean, Chinese, and Hindi grammars.', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']","['', '', '', '', '', '', '', '', 'In FB-LTAG, each node in the elementary trees has a feature structure, containing grammatical constraints on the node.', 'Figure 5 shows a result of LTAG analysis, which is described not There are several grammars developed in the FB-LTAG formalism , including the XTAG English grammar , a large-scale grammar for English ( The XTAG Research #TAUTHOR_TAG .', 'The XTAG group #AUTHOR_TAG at the University of Pennsylvania is also developing Korean, Chinese, and Hindi grammars.', 'Development of a large-scale French grammar (Abeillé and #AUTHOR_TAG has also started at the University of Pennsylvania and is expanded at University of Paris 7.']",0
"['""ing are dependent each comput have', 'We applied our system to the XTAG English grammar ( The XTAG Research #TAUTHOR_TAG 3 , which is a large-scale FB-LTAG grammar for English .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser', '', '']","['""parsing are dependent each computational have', 'We applied our system to the XTAG English grammar ( The XTAG Research #TAUTHOR_TAG 3 , which is a large-scale FB-LTAG grammar for English .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser', '', '']","['"" are dependent each computational framework have never', 'We applied our system to the XTAG English grammar ( The XTAG Research #TAUTHOR_TAG 3 , which is a large-scale FB-LTAG grammar for English .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser .', '', '']","['', 'We applied our system to the XTAG English grammar ( The XTAG Research #TAUTHOR_TAG 3 , which is a large-scale FB-LTAG grammar for English .', 'A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser .', '', '']",5
"['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Empirical']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', '']",0
"['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']",0
"['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers #TAUTHOR_TAG demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988; #AUTHOR_TAG Ekmekçioglu et al., 1995; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers #TAUTHOR_TAG demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988; #AUTHOR_TAG Ekmekçioglu et al., 1995; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers #TAUTHOR_TAG demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988; #AUTHOR_TAG Ekmekçioglu et al., 1995; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers #TAUTHOR_TAG demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988; #AUTHOR_TAG Ekmekçioglu et al., 1995; #AUTHOR_TAG .', '', '', '']",0
"['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Empirical']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', '']",0
"['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers #TAUTHOR_TAG demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988; #AUTHOR_TAG Ekmekçioglu et al., 1995; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers #TAUTHOR_TAG demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988; #AUTHOR_TAG Ekmekçioglu et al., 1995; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers #TAUTHOR_TAG demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988; #AUTHOR_TAG Ekmekçioglu et al., 1995; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'mers #TAUTHOR_TAG demonstrably improve retrieval performance .', 'This has been reported for other languages, too, dependent on the generality of the chosen approach (Jäppinen and Niemistö, 1988; #AUTHOR_TAG Ekmekçioglu et al., 1995; #AUTHOR_TAG .', '', '', '']",0
"['Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system #AUTHOR_TAG J Â¨ appinen and Niemist Â¨ o , 1988 ; #TAUTHOR_TAG , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '', '']","['Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system #AUTHOR_TAG J Â¨ appinen and Niemist Â¨ o , 1988 ; #TAUTHOR_TAG , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '', '']","['Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system #AUTHOR_TAG J Â¨ appinen and Niemist Â¨ o , 1988 ; #TAUTHOR_TAG , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '', '']","['Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system #AUTHOR_TAG J Â¨ appinen and Niemist Â¨ o , 1988 ; #TAUTHOR_TAG , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '', '']",0
"['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']",0
"['There has been some controversy , at least for simple stemmers #TAUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #AUTHOR_TAG .', 'The key for improvement seems ro in form of', '']","['There has been some controversy , at least for simple stemmers #TAUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #AUTHOR_TAG .', 'The key for improvement seems rooted in form of', '']","['There has been some controversy , at least for simple stemmers #TAUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #AUTHOR_TAG .', 'The key for quality improvement seems in some form of', '']","['There has been some controversy , at least for simple stemmers #TAUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #AUTHOR_TAG .', '', '']",0
"['), but at high ones its precision decreases almost dramatically.', 'Unless very high rates of misspellings are to be expected ( this explains the favorable results for trigram indexing in #TAUTHOR_TAG ) one can not really recommend this method .']","['), but at high ones its precision decreases almost dramatically.', 'Unless very high rates of misspellings are to be expected ( this explains the favorable results for trigram indexing in #TAUTHOR_TAG ) one can not really recommend this method .']","['), but at high ones its precision decreases almost dramatically.', 'Unless very high rates of misspellings are to be expected ( this explains the favorable results for trigram indexing in #TAUTHOR_TAG ) one can not really recommend this method .']","['), but at high ones its precision decreases almost dramatically.', 'Unless very high rates of misspellings are to be expected ( this explains the favorable results for trigram indexing in #TAUTHOR_TAG ) one can not really recommend this method .']",1
"['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']",0
"['some at formers effectiveness of morphological analysis for document retriev', '.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories #TAUTHOR_TAG .']","['some at for stemmers effectiveness of morphological analysis for document retrieval', 'dictionary.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories #TAUTHOR_TAG .']","['at for the effectiveness of morphological analysis for document retrieval', '.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories #TAUTHOR_TAG .']","['', '', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories #TAUTHOR_TAG .']",0
"['', 'sal', 'The retrieval process relies on the vector space model #TAUTHOR_TAG , with the cosine measure expressing the similarity between a query and a document .', '']","['', 'salience', 'The retrieval process relies on the vector space model #TAUTHOR_TAG , with the cosine measure expressing the similarity between a query and a document .', '']","['', '', 'The retrieval process relies on the vector space model #TAUTHOR_TAG , with the cosine measure expressing the similarity between a query and a document .', '']","['', '', 'The retrieval process relies on the vector space model #TAUTHOR_TAG , with the cosine measure expressing the similarity between a query and a document .', '']",5
"['There has been some controversy , at least for simple stemmers #TAUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #AUTHOR_TAG .', 'The key for improvement seems ro in form of', '']","['There has been some controversy , at least for simple stemmers #TAUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #AUTHOR_TAG .', 'The key for improvement seems rooted in form of', '']","['There has been some controversy , at least for simple stemmers #TAUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #AUTHOR_TAG .', 'The key for quality improvement seems in some form of', '']","['There has been some controversy , at least for simple stemmers #TAUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #AUTHOR_TAG .', '', '']",0
"[', medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language (e.g., German), often referred to as neo-classical compounding (Mc- #AUTHOR_TAG', 'While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting #TAUTHOR_TAG .']","['Furthermore, medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language (e.g., German), often referred to as neo-classical compounding (Mc- #AUTHOR_TAG', 'While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting #TAUTHOR_TAG .']","[', medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language (e.g., German), often referred to as neo-classical compounding (Mc- #AUTHOR_TAG .', 'While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting #TAUTHOR_TAG .']","['Furthermore, medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language (e.g., German), often referred to as neo-classical compounding (Mc- #AUTHOR_TAG .', 'While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting #TAUTHOR_TAG .']",0
"['', '', 'terms', '', '', '', '', '', '', '', '', 'It would be interesting to evaluate indexing in cases retriev orword indexes to a complete mismatch between and documents.', 'This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH , #TAUTHOR_TAG ) are incorporated into our system .', '']","['', '', 'terms', '', '', '', '', '', '', '', '', 'It would be interesting to evaluate indexing in cases retrieval or subword indexes to a complete mismatch between and documents.', 'This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH , #TAUTHOR_TAG ) are incorporated into our system .', '']","['', '', 'medical terms', '', '', '', '', '', '', '', '', 'It would be interesting to evaluate in those cases retriev orword indexes fails to a complete mismatch between and documents.', 'This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH , #TAUTHOR_TAG ) are incorporated into our system .', '']","['', '', '', '', '', '', '', '', '', '', '', '', 'This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH , #TAUTHOR_TAG ) are incorporated into our system .', '']",3
"['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Empirical']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', 'Emp']","['There has been some controversy , at least for simple stemmers #AUTHOR_TAG , about the effectiveness of morphological analysis for document retrieval #TAUTHOR_TAG .', 'The key for quality improvement seems to be rooted mainly in the presence or absence of some form of dictionary.', '']",0
"['The efforts required for performing morphologi- cal analysis vary from language to.', 'For English, known for its limited number of inf patterns, lexicon-free general-purposemers #AUTHOR_TAG demonstrably improve retrieval performance.', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ; #TAUTHOR_TAG ; Ekmekc Â¸ ioglu et al. , 1995 ; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphologi- cal analysis vary from language to language.', 'For English, known for its limited number of inflection patterns, lexicon-free general-purpose stemmers #AUTHOR_TAG demonstrably improve retrieval performance.', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ; #TAUTHOR_TAG ; Ekmekc Â¸ ioglu et al. , 1995 ; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphologi- cal analysis vary from language to.', 'For English, known for its limited number of inf patterns, lexicon-free general-purpose stemmers #AUTHOR_TAG demonstrably improve retrieval performance.', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ; #TAUTHOR_TAG ; Ekmekc Â¸ ioglu et al. , 1995 ; #AUTHOR_TAG .', '', '', '']","['The efforts required for performing morphologi- cal analysis vary from language to language.', 'For English, known for its limited number of inflection patterns, lexicon-free general-purpose stemmers #AUTHOR_TAG demonstrably improve retrieval performance.', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ; #TAUTHOR_TAG ; Ekmekc Â¸ ioglu et al. , 1995 ; #AUTHOR_TAG .', '', '', '']",0
"['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']",0
"['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['performing', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']","['', '', '', '', '', '', 'From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition #TAUTHOR_TAG .']",0
"['', '', 'terms', '', '', '', '', '', '', '', '', '', 'Thisappingsonym identifiers to aMeSH)) are incorporated into our system.', 'Alternatively , we may think of user-centered comparative studies #TAUTHOR_TAG .']","['', '', 'terms', '', '', '', '', '', '', '', '', '', 'This mappings synonym identifiers to a are incorporated into our system.', 'Alternatively , we may think of user-centered comparative studies #TAUTHOR_TAG .']","['', '', 'medical terms', '', '', '', '', '', '', '', '', '', 'Thisappingsonym identifiers toMeSH)) are incorporated into our system.', 'Alternatively , we may think of user-centered comparative studies #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'Alternatively , we may think of user-centered comparative studies #TAUTHOR_TAG .']",3
"['some at formers effectiveness of morphological analysis for document retriev', '.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories #TAUTHOR_TAG .']","['some at for stemmers effectiveness of morphological analysis for document retrieval', 'dictionary.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories #TAUTHOR_TAG .']","['at for the effectiveness of morphological analysis for document retrieval', '.', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories #TAUTHOR_TAG .']","['', '', 'Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories #TAUTHOR_TAG .']",0
"['- are quite rare in (', '', 'the a myad of ad hoc comp are formed on the be form a retrieval though documents.', 'Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French #TAUTHOR_TAG , turns out to be infeasible , at least for German and related languages .']","['are quite rare in (which', '', 'the a myriad of ad hoc compounds are formed on the be formulating a retrieval though documents.', 'Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French #TAUTHOR_TAG , turns out to be infeasible , at least for German and related languages .']","['- are quite rare in (', '', 'a myriad of ad hoc compounds are formed on the fly be anticipated formulating a retrieval query though relevant documents.', 'Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French #TAUTHOR_TAG , turns out to be infeasible , at least for German and related languages .']","['', '', '', 'Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French #TAUTHOR_TAG , turns out to be infeasible , at least for German and related languages .']",0
"['The efforts for performing morph vary from', ""known, lexicon-free general-pur '¡ ' denotes the string concatenation."", 'retrieval performance.', 'This has been reported for other , too , dependent on the approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ; #AUTHOR_TAG Ekmekc Â¸ ioglu et al. , 1995 ; #TAUTHOR_TAG .', '', '', '']","['The efforts for performing morphological vary from', ""known patterns, lexicon-free general-purpose '¡ ' denotes the string concatenation operator."", 'retrieval performance.', 'This has been reported for other , too , dependent on the approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ; #AUTHOR_TAG Ekmekc Â¸ ioglu et al. , 1995 ; #TAUTHOR_TAG .', '', '', '']","['The efforts for performing morphological analysis vary from', ""known, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", 'retrieval performance.', 'This has been reported for other languages , too , dependent on ( J Â¨ appinen and Niemist Â¨ o , 1988 ; #AUTHOR_TAG Ekmekc Â¸ ioglu et al. , 1995 ; #TAUTHOR_TAG .', '', '', '']","['The efforts required for performing morphological analysis vary from language to language.', ""For English, known for its limited number of inflection patterns, lexicon-free general-purpose stem-1 '¡ ' denotes the string concatenation operator."", '', 'This has been reported for other languages , too , dependent on the generality of the chosen approach ( J Â¨ appinen and Niemist Â¨ o , 1988 ; #AUTHOR_TAG Ekmekc Â¸ ioglu et al. , 1995 ; #TAUTHOR_TAG .', '', '', '']",0
"['Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system #TAUTHOR_TAG ; J Â¨ appinen and Niemist Â¨ o , 1988 ; #AUTHOR_TAG , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved', '', '']","['Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system #TAUTHOR_TAG ; J Â¨ appinen and Niemist Â¨ o , 1988 ; #AUTHOR_TAG , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved', '', '']","['Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system #TAUTHOR_TAG ; J Â¨ appinen and Niemist Â¨ o , 1988 ; #AUTHOR_TAG , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '', '']","['Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system #TAUTHOR_TAG ; J Â¨ appinen and Niemist Â¨ o , 1988 ; #AUTHOR_TAG , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .', '', '']",0
"['Furthermore , medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding #TAUTHOR_TAG .', 'While this is simply irrelevant for general-purpose morphological analyzers, dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting #AUTHOR_TAG']","['Furthermore , medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding #TAUTHOR_TAG .', 'While this is simply irrelevant for general-purpose morphological analyzers, dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting #AUTHOR_TAG']","['Furthermore , medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding #TAUTHOR_TAG .', 'While this is simply irrelevant for general-purpose morphological analyzers, dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting #AUTHOR_TAG .']","['Furthermore , medical terminology is characterized by a typical mix of Latin and Greek roots with the corresponding host language ( e.g. , German ) , often referred to as neo-classical compounding #TAUTHOR_TAG .', 'While this is simply irrelevant for general-purpose morphological analyzers, dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting #AUTHOR_TAG .']",0
"['schema and flexibility in expressing of', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['schema and flexibility in expressing of', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['and flexibility in express of', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']",0
"['synchron twoars an schema expressing', 'correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG .']","['synchronization two annotation schema expressing', 'correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG .']","['express', 'structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG .']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG .']",0
"['In this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC ) #TAUTHOR_TAG will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .', 'The correspondence between the string and its associated representation tree structure is defined in terms of the sub-correspondence between parts of the string (substrings) and parts of the tree structure (subtrees), which can for both.', 'is defined in a waystandard.', 'project']","['In this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC ) #TAUTHOR_TAG will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .', 'The correspondence between the string and its associated representation tree structure is defined in terms of the sub-correspondence between parts of the string (substrings) and parts of the tree structure (subtrees), which can for both generation.', 'is defined in a way', '']","['In this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC ) #TAUTHOR_TAG will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .', 'The correspondence between the string and its associated representation tree structure is defined in terms of the sub-correspondence between parts of the string (substrings) and parts of the tree structure (subtrees), which for both analysis.', 'is defined in a way.', 'project']","['In this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC ) #TAUTHOR_TAG will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .', 'The correspondence between the string and its associated representation tree structure is defined in terms of the sub-correspondence between parts of the string (substrings) and parts of the tree structure (subtrees), which can be interpreted for both analysis and generation.', '', '']",0
"['The a general structure that can associate an to string annotator to the facility to specify the between the and the tree which be nonproject #AUTHOR_TAG', 'These features are very much desired in the design of an annotation scheme , in particular for the treatment of linguistic phenomena , which are non-standard , e.g. crossed dependencies #TAUTHOR_TAG .', 'crossed dependencies #AUTHOR_TAG .']","['The a general structure that can associate an to string annotator to the facility to specify the between the and the tree which be nonprojective #AUTHOR_TAG', 'These features are very much desired in the design of an annotation scheme , in particular for the treatment of linguistic phenomena , which are non-standard , e.g. crossed dependencies #TAUTHOR_TAG .', 'crossed dependencies #AUTHOR_TAG .']","['a general structure that can associate to string the annotator to the facility to specify the correspondence between the string and the tree which can be nonproject #AUTHOR_TAG .', 'These features are very much desired in the design of an annotation scheme , in particular for the treatment of linguistic phenomena , which are non-standard , e.g. crossed dependencies #TAUTHOR_TAG .', 'crossed dependencies #AUTHOR_TAG .']","['', 'These features are very much desired in the design of an annotation scheme , in particular for the treatment of linguistic phenomena , which are non-standard , e.g. crossed dependencies #TAUTHOR_TAG .', 'crossed dependencies #AUTHOR_TAG .']",0
"['', '', '', '', 'ram serial', '', '', 'Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in #TAUTHOR_TAG to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC .']","['', '', '', '', 'serial', '', '', 'Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in #TAUTHOR_TAG to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC .']","['', '', '', '', 'ram', '', '', 'Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in #TAUTHOR_TAG to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC .']","['', '', '', '', '', '', '', 'Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in #TAUTHOR_TAG to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC .']",0
"['so been lacking is a schema or a framework to annotate and express such extractedical and structural correspond in', '', '', ' #TAUTHOR_TAG presented an approach for constructing a BKB based on the S-SSTC .']","['so been lacking is a schema or a framework to annotate and express such extracted and structural correspondences in', '', '', ' #TAUTHOR_TAG presented an approach for constructing a BKB based on the S-SSTC .']","['been lacking is a schema or a framework to annotate and express such extractedical and structural correspondences in', '', '', ' #TAUTHOR_TAG presented an approach for constructing a BKB based on the S-SSTC .']","['However, what has so far been lacking is a schema or a framework to annotate and express such extracted lexical and structural correspondences in a flexible and powerful manner.', '', '', ' #TAUTHOR_TAG presented an approach for constructing a BKB based on the S-SSTC .']",0
"['schema additional and flexibility in expressing level of', 'For , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['schema additional and flexibility in expressing level of', 'For , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['additional power and flexibility in express the level of', 'For , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']",0
"['The idea of parallel is widely used applied many different ways', 'The use ofous formal is motivated but', ', synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different, for for the purpose of immediate structural translation in machine translation (Abeillé et0), , or for a syntactic and semantic one for the language', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by #AUTHOR_TAG to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL #AUTHOR_TAG , #TAUTHOR_TAG .', ' #AUTHOR_TAG a restricted definition for S-TAG, namely, the IS-TAG for isomorphic S-TAG.', 'only formed each component', '', '']","['The idea of parallelized is widely used applied many different ways.', 'The use of synchronous formalisms is motivated but', 'example, synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different languages, for for the purpose of immediate structural translation in machine translation (Abeillé et , or for a syntactic and semantic one for the language', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by #AUTHOR_TAG to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL #AUTHOR_TAG , #TAUTHOR_TAG .', ' #AUTHOR_TAG a restricted definition for S-TAG, namely, the IS-TAG for isomorphic S-TAG.', 'only formed each component.', '', '']","['The idea of parallel is widely used many different ways.', 'The use ofous formalisms is motivated but', ', synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different languages, for for the purpose of immediate structural translation in machine translation (Abeillé et0), , or for relating a syntactic TAG and semantic one for the same language', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by #AUTHOR_TAG to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL #AUTHOR_TAG , #TAUTHOR_TAG .', ' #AUTHOR_TAG a restricted definition for S-TAG, namely, the IS-TAG for isomorphic S-TAG.', 'each component.', '', '']","['', '', 'For example, synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different languages, for example, for the purpose of immediate structural translation in machine translation (Abeillé et al.,1990), #AUTHOR_TAG , or for relating a syntactic TAG and semantic one for the same language #AUTHOR_TAG .', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by #AUTHOR_TAG to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL #AUTHOR_TAG , #TAUTHOR_TAG .', 'As a result, #AUTHOR_TAG propose a restricted definition for S-TAG, namely, the IS-TAG for isomorphic S-TAG.', '', '', '']",0
"['From the Meaning-Text Theory ( MTT ) 1 point of view , Natural Language ( NL ) is considered as a correspondence between meanings and texts #TAUTHOR_TAG .', 'The MTT point of view, even if it has been introduced in different formulations, is more or less accepted by the whole linguistic community.']","['From the Meaning-Text Theory ( MTT ) 1 point of view , Natural Language ( NL ) is considered as a correspondence between meanings and texts #TAUTHOR_TAG .', 'The MTT point of view, even if it has been introduced in different formulations, is more or less accepted by the whole linguistic community.']","['From the Meaning-Text Theory ( MTT ) 1 point of view , Natural Language ( NL ) is considered as a correspondence between meanings and texts #TAUTHOR_TAG .', 'The MTT point of view, even if it has been introduced in different formulations, is more or less accepted by the whole linguistic community.']","['From the Meaning-Text Theory ( MTT ) 1 point of view , Natural Language ( NL ) is considered as a correspondence between meanings and texts #TAUTHOR_TAG .', 'The MTT point of view, even if it has been introduced in different formulations, is more or less accepted by the whole linguistic community.']",0
"['ars schema', 'schema or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['schema', 'schema or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'such schema or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']",0
"['As mentioned earlier, there are some non-standard phenomena exist between different languages, that cause challenges for synchronized formalisms.', 'In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g. #TAUTHOR_TAG cases ) .', '', '.']","['As mentioned earlier, there are some non-standard phenomena exist between different languages, that cause challenges for synchronized formalisms.', 'In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g. #TAUTHOR_TAG cases ) .', '', 'details.']","['As mentioned earlier, there are some non-standard phenomena exist between different languages, that cause challenges for synchronized formalisms.', 'In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g. #TAUTHOR_TAG cases ) .', '', '']","['As mentioned earlier, there are some non-standard phenomena exist between different languages, that cause challenges for synchronized formalisms.', 'In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g. #TAUTHOR_TAG cases ) .', '', '']",0
"['ars schema additional and flexibility in expressing level of', 'such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['schema additional and flexibility in expressing level of', 'such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['additional power and flexibility in express the level of', 'such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']",0
"['There is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures #TAUTHOR_TAG , such as the relation between syntax and semantic .']","['There is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures #TAUTHOR_TAG , such as the relation between syntax and semantic .']","['There is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures #TAUTHOR_TAG , such as the relation between syntax and semantic .']","['There is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures #TAUTHOR_TAG , such as the relation between syntax and semantic .']",0
"['governed following', '', 'constraints to the lingu meaningful synchronous correspondencesi.e', ""For instance, when building translation units in EBMT approaches #AUTHOR_TAG , #AUTHOR_TAG , ( Al #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences (lexical and structural correspondences) for transferrules' extraction from parallel parsed corpus""]","['governed following', '', 'constraints to the linguistically meaningful synchronous correspondences (i.e.', ""For instance, when building translation units in EBMT approaches #AUTHOR_TAG , #AUTHOR_TAG , ( Al #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences (lexical and structural correspondences) for transferrules' extraction from parallel parsed corpus""]","['are governed', '', 'these constraints to the linguistically meaningful synchronous correspondencesi.e', ""For instance, when building translation units in EBMT approaches #AUTHOR_TAG , #AUTHOR_TAG , ( Al #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences (lexical and structural correspondences) for transferrules' extraction from parallel parsed corpus""]","['', '', '', ""For instance, when building translation units in EBMT approaches #AUTHOR_TAG , #AUTHOR_TAG , ( Al #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences (lexical and structural correspondences) for transferrules' extraction from parallel parsed corpus""]",0
"['schema', 'to realize additional power and flexibility in expressing structural correspondences at the level of language sentence', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['schema', 'to realize additional power and flexibility in expressing structural correspondences at the level of language sentence', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'to realize additional power and flexibility in expressing structural correspondences at the level of language sentence pairs.', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', '', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']",0
"['There is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures #TAUTHOR_TAG .']","['There is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures #TAUTHOR_TAG .']","['There is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures #TAUTHOR_TAG .']","['There is now a consensus about the fact that natural language should be described as correspondences between different levels of representation.', 'Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures #TAUTHOR_TAG .']",0
"[' describes the', 'atur', 'box up"".', 'For more details on the proprieties of SSTC , see #TAUTHOR_TAG .']","['describes the', '', 'box up"".', 'For more details on the proprieties of SSTC , see #TAUTHOR_TAG .']","['describes', '', 'the box up"".', 'For more details on the proprieties of SSTC , see #TAUTHOR_TAG .']","['', '', '', 'For more details on the proprieties of SSTC , see #TAUTHOR_TAG .']",0
"['Figure 2 illustr the ""John picks the box up"" with its corresponding S.', 'It contains a nonprojective.', 'An is assigned to each, ie ( for ""John"", (1 foricksthe and for', 'Astring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in #TAUTHOR_TAG and #AUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree.']","['Figure 2 illustrates the ""John picks the box up"" with its corresponding SSTC.', 'It contains a nonprojective correspondence.', 'An is assigned to each sentence, i.e. for ""John"", for and for', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in #TAUTHOR_TAG and #AUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree.']","['Figure 2 illustr the sentence ""John picks the box up"" with its corresponding SSTC.', 'It contains a nonprojective correspondence.', 'An interval is assigned to each word ( for ""John"", (1 foricksthe and for', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in #TAUTHOR_TAG and #AUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree.']","['Figure 2 illustrates the sentence ""John picks the box up"" with its corresponding SSTC.', 'It contains a nonprojective correspondence.', '', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in #TAUTHOR_TAG and #AUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree.']",5
"['ars schema', 'correspond the purpose of transfer grammar #AUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG , ( kaji et , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['schema', 'correspondences the purpose of transfer grammar #AUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG , ( kaji et , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , ( Al- #AUTHOR_TAG .']",0
"['The idea of parallel is widely used applied many different', 'The use ofous formal is motivated', 'synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different, for for the purpose of immediate structural translation in machine translation (Aé et), , or for a synt and semantic one the', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by #AUTHOR_TAG to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL #TAUTHOR_TAG , #AUTHOR_TAG', 'restricted for S-TAG IS is', '', '', '']","['The idea of parallelized is widely used applied many different', 'The use of synchronous formalisms is motivated', 'synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different languages, for for the purpose of immediate structural translation in machine translation (Abeillé et , or for a syntactic and semantic one the', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by #AUTHOR_TAG to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL #TAUTHOR_TAG , #AUTHOR_TAG', 'restricted for S-TAG, isomorphic', '', '', '']","['The idea of parallel is widely used many different ways.', 'The use ofous formalisms is motivated', ', synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different languages, for for the purpose of immediate structural translation in machine translation (Aé et), , or for and semantic one', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by #AUTHOR_TAG to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL #TAUTHOR_TAG , #AUTHOR_TAG .', 'for S-TAG is', '', '', '']","['', '', 'For example, synchronous Tree Adjoining Grammar (S-TAG) can be used to relate TAGs for two different languages, for example, for the purpose of immediate structural translation in machine translation (Abeillé et al.,1990), #AUTHOR_TAG , or for relating a syntactic TAG and semantic one for the same language #AUTHOR_TAG .', 'S-TAG is a variant of Tree Adjoining Grammar (TAG) introduced by #AUTHOR_TAG to characterize correspondences between tree adjoining languages.', 'Considering the original definition of S-TAGs, one can see that it does not restrict the structures that can be produced in the source and target languages.', 'It allows the construction of a non-TAL #TAUTHOR_TAG , #AUTHOR_TAG .', '', '', '', '']",0
"['ars schema', 'structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['schema', 'structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']","['', 'For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , ( Al- #AUTHOR_TAG .']",0
"['Figure 2 illustr the ""John picks the box up"" with its corresponding SSTC.', 'It contains a nonprojective.', 'An is assigned to each, ie. (0-) for ""John"", (12 for ""picks"",23) forthe"",3-4 for and (4-) for ""up', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in #AUTHOR_TAG and #TAUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree.']","['Figure 2 illustrates the ""John picks the box up"" with its corresponding SSTC.', 'It contains a nonprojective correspondence.', 'An is assigned to each sentence, i.e. (0-1) for ""John"", (1-2) for ""picks"", (2-3) for ""the"", (3-4) for and (4-5) for ""up"".', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in #AUTHOR_TAG and #TAUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree.']","['Figure 2 illustr the sentence ""John picks the box up"" with its corresponding SSTC.', 'It contains a nonprojective correspondence.', 'An interval is assigned to each word the sentence, i.e. (0-) for ""John"", (12 for ""picks"",23) forthe"",3-4 for and (4-) for ""up', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in #AUTHOR_TAG and #TAUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree.']","['Figure 2 illustrates the sentence ""John picks the box up"" with its corresponding SSTC.', 'It contains a nonprojective correspondence.', 'An interval is assigned to each word in the sentence, i.e. (0-1) for ""John"", (1-2) for ""picks"", (2-3) for ""the"", (3-4) for ""box"" and (4-5) for ""up"".', 'A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in #AUTHOR_TAG and #TAUTHOR_TAG .', 'and its dependency tree together with the correspondences between substrings of the sentence and subtrees of the tree.']",5
"['However , the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data #TAUTHOR_TAG .', 'Recent work #AUTHOR_TAG has suggested that some tasks will benefit from using significantly more data.', 'Also, many potential applications of NLP will involve processing very large text databases.', 'biical text-mining involves extracting information from the vast body of biological and medical literature search may apply techniques to the whole web', '', '', '', '']","['However , the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data #TAUTHOR_TAG .', 'Recent work #AUTHOR_TAG has suggested that some tasks will benefit from using significantly more data.', 'Also, many potential applications of NLP will involve processing very large text databases.', 'biomedical text-mining involves extracting information from the vast body of biological and medical literature; search may apply techniques to the whole web.', '', '', '', '']","['However , the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data #TAUTHOR_TAG .', 'Recent work #AUTHOR_TAG has suggested that some tasks will benefit from using significantly more data.', 'Also, many potential applications of NLP will involve processing very large text databases.', ', biomedical text-mining involves extracting information from the vast body of biological and medical literature; search engines may applyLP techniques to the whole web.', '', '', '', '']","['However , the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data #TAUTHOR_TAG .', 'Recent work #AUTHOR_TAG has suggested that some tasks will benefit from using significantly more data.', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '', '', '', '']",0
"['', '', '', 'This of remote is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems #TAUTHOR_TAG and speech recognition #AUTHOR_TAG .', '']","['', '', '', 'This of remote is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems #TAUTHOR_TAG and speech recognition #AUTHOR_TAG .', '']","['', '', '', 'of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems #TAUTHOR_TAG and speech recognition #AUTHOR_TAG .', '']","['', '', '', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems #TAUTHOR_TAG and speech recognition #AUTHOR_TAG .', '']",0
"['As discussed earlier, there are two main requirements of the system that are covered by ""high performance"": speed and state of the art accuracy.', 'Efficiency is required both in training and processing.', 'Efficient training is required because the amount of data available for training will increase significantly.', 'Also , advanced methods often require many training iterations , for example active learning #AUTHOR_TAG and co-training #TAUTHOR_TAG .', 'Processing text needs to be extremely efficient since many new applications will require very large quantities of text to be processed or many of text to be processed very.']","['As discussed earlier, there are two main requirements of the system that are covered by ""high performance"": speed and state of the art accuracy.', 'Efficiency is required both in training and processing.', 'Efficient training is required because the amount of data available for training will increase significantly.', 'Also , advanced methods often require many training iterations , for example active learning #AUTHOR_TAG and co-training #TAUTHOR_TAG .', 'Processing text needs to be extremely efficient since many new applications will require very large quantities of text to be processed or many of text to be processed very quickly.']","['As discussed earlier, there are two main requirements of the system that are covered by ""high performance"": speed and state of the art accuracy.', 'Efficiency is required both in training and processing.', 'Efficient training is required because the amount of data available for training will increase significantly.', 'Also , advanced methods often require many training iterations , for example active learning #AUTHOR_TAG and co-training #TAUTHOR_TAG .', 'Processing text needs to be extremely efficient since many new applications will require very large quantities of text to be processed or of text to be processed very.']","['As discussed earlier, there are two main requirements of the system that are covered by ""high performance"": speed and state of the art accuracy.', 'Efficiency is required both in training and processing.', 'Efficient training is required because the amount of data available for training will increase significantly.', 'Also , advanced methods often require many training iterations , for example active learning #AUTHOR_TAG and co-training #TAUTHOR_TAG .', 'Processing text needs to be extremely efficient since many new applications will require very large quantities of text to be processed or many smaller quantities of text to be processed very quickly.']",0
"['There are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) #TAUTHOR_TAG and the Alembic Workbench #AUTHOR_TAG ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors #AUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', 'ifies the addition of new components to system.']","['There are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) #TAUTHOR_TAG and the Alembic Workbench #AUTHOR_TAG ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors #AUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', 'simplifies the addition of new components to system.']","['There are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) #TAUTHOR_TAG and the Alembic Workbench #AUTHOR_TAG ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors #AUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', 'ifies the addition of new components to the system.']","['There are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) #TAUTHOR_TAG and the Alembic Workbench #AUTHOR_TAG ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors #AUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', '']",0
"['', '', '', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems #AUTHOR_TAG and speech recognition #TAUTHOR_TAG .', 'Web services will researchers in to be composed']","['', '', '', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems #AUTHOR_TAG and speech recognition #TAUTHOR_TAG .', 'Web services will researchers in to be composed']","['', '', '', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems #AUTHOR_TAG and speech recognition #TAUTHOR_TAG .', 'Web services will allow different researchers in to be composed']","['', '', '', 'This standardisation of remote procedures is very exciting from a software engineering viewpoint since it allows systems to be totally distributed.', 'There have already been several attempts to develop distributed NLP systems for dialogue systems #AUTHOR_TAG and speech recognition #TAUTHOR_TAG .', '']",0
"['ming approachLP development will tools such as sentence boundary detectors, POS taggers,ers and named entity recognisers to be rapidly composed elemental components', 'For instance , implementing an efficient version of the MXPOST POS tagger #TAUTHOR_TAG will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component .']","['Programming approach NLP development will tools such as sentence boundary detectors, POS taggers, chunkers and named entity recognisers to be rapidly composed elemental components.', 'For instance , implementing an efficient version of the MXPOST POS tagger #TAUTHOR_TAG will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component .']","['LP infrastructure development will allow tools such as sentence boundary detectors, POS taggers, chunkers and named entity recognisers to be rapidly composed many elemental components.', 'For instance , implementing an efficient version of the MXPOST POS tagger #TAUTHOR_TAG will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component .']","['The Generative Programming approach to NLP infrastructure development will allow tools such as sentence boundary detectors, POS taggers, chunkers and named entity recognisers to be rapidly composed from many elemental components.', 'For instance , implementing an efficient version of the MXPOST POS tagger #TAUTHOR_TAG will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component .']",3
"['The implementation has been inspired by experience in extracting information from very large corpora #AUTHOR_TAG and performing experiments on maximum entropy sequence tagging #TAUTHOR_TAG .', 'We have implemented a POS tagger supertagger and named entity recogniser the infrastructure', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #AUTHOR_TAG and performing experiments on maximum entropy sequence tagging #TAUTHOR_TAG .', 'We have implemented a POS tagger, supertagger and named entity recogniser the infrastructure.', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #AUTHOR_TAG and performing experiments on maximum entropy sequence tagging #TAUTHOR_TAG .', 'We have already implemented a POS tagger, chunker, CCG supertagger and named entity recogniser using the infrastructure.', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #AUTHOR_TAG and performing experiments on maximum entropy sequence tagging #TAUTHOR_TAG .', 'We have already implemented a POS tagger, chunker, CCG supertagger and named entity recogniser using the infrastructure.', '', '', '']",4
"['The implementation has been inspired by experience in extracting information from very large corpora #TAUTHOR_TAG and performing experiments on maximum entropy sequence tagging #AUTHOR_TAG .', 'have a P O S tagger chunk C C G supertagger and named entity recogn the infrastructure', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #TAUTHOR_TAG and performing experiments on maximum entropy sequence tagging #AUTHOR_TAG .', 'have a P O S tagger, C C G supertagger and named entity recogniser the infrastructure.', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #TAUTHOR_TAG and performing experiments on maximum entropy sequence tagging #AUTHOR_TAG .', 'a P O S tagger, chunker, C C G supertagger and named entity recogniser using the infrastructure.', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #TAUTHOR_TAG and performing experiments on maximum entropy sequence tagging #AUTHOR_TAG .', 'We have already implemented a P O S tagger, chunker, C C G supertagger and named entity recogniser using the infrastructure.', '', '', '']",4
"['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by #TAUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly #AUTHOR_TAG .', '', '']","['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by #TAUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly #AUTHOR_TAG .', '', '']","['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by #TAUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly #AUTHOR_TAG .', '', '']","['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by #TAUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly #AUTHOR_TAG .', '', '']",0
"['of stand-alone tools have also been', ', the of tools', '', '', 'Other tools have been designed around particular techniques , such as finite state machines #TAUTHOR_TAG .', ', the source code for these tools is not freely available, so they cannot be extended.']","['of stand-alone tools have also been', 'example, the of tools', '', '', 'Other tools have been designed around particular techniques , such as finite state machines #TAUTHOR_TAG .', 'However, the source code for these tools is not freely available, so they cannot be extended.']","['of stand-alone tools have also been', ', the suite ofT tools', '', '', 'Other tools have been designed around particular techniques , such as finite state machines #TAUTHOR_TAG .', ', the source code for these tools is not freely available, so they cannot be extended.']","['A number of stand-alone tools have also been developed.', '', '', '', 'Other tools have been designed around particular techniques , such as finite state machines #TAUTHOR_TAG .', 'However, the source code for these tools is not freely available, so they cannot be extended.']",0
"['However, the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus #AUTHOR_TAG', 'Recent work #TAUTHOR_TAG has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web', '', '', '', '']","['However, the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus #AUTHOR_TAG', 'Recent work #TAUTHOR_TAG has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '', '', '', '']","['However, the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus #AUTHOR_TAG .', 'Recent work #TAUTHOR_TAG has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '', '', '', '']","['However, the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus #AUTHOR_TAG .', 'Recent work #TAUTHOR_TAG has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '', '', '', '']",0
"['NLP experiencing explosion in the of electronic text', 'Some of this new data will be annot', 'For example , 10 million words of the American National Corpus #AUTHOR_TAG will have manually corrected POS tags , a tenfold increase over the Penn Treebank #TAUTHOR_TAG , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations.']","['NLP experiencing explosion in the of electronic text', 'Some of this new data will be annotated.', 'For example , 10 million words of the American National Corpus #AUTHOR_TAG will have manually corrected POS tags , a tenfold increase over the Penn Treebank #TAUTHOR_TAG , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations.']","['NLP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annot', 'For example , 10 million words of the American National Corpus #AUTHOR_TAG will have manually corrected POS tags , a tenfold increase over the Penn Treebank #TAUTHOR_TAG , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations.']","['NLP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus #AUTHOR_TAG will have manually corrected POS tags , a tenfold increase over the Penn Treebank #TAUTHOR_TAG , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations.']",0
"['C is extremely foruing to', '', '', '', 'already been used to implement a framework for teaching NLP #TAUTHOR_TAG .']","['C++ is extremely for gluing to', '', '', '', 'already been used to implement a framework for teaching NLP #TAUTHOR_TAG .']","['C is extremely for to', '', '', '', 'been used to implement a framework for teaching NLP #TAUTHOR_TAG .']","['', '', '', '', 'It has already been used to implement a framework for teaching NLP #TAUTHOR_TAG .']",2
"['There are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) #AUTHOR_TAG and the Alembic Workbench #TAUTHOR_TAG ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors #AUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure which the G is built on top', '']","['There are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) #AUTHOR_TAG and the Alembic Workbench #TAUTHOR_TAG ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors #AUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure which the GUI is built on top', '']","['There are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) #AUTHOR_TAG and the Alembic Workbench #TAUTHOR_TAG ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors #AUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure which the GUI is built on', '']","['There are a number of generalised NLP systems in the literature.', 'Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) #AUTHOR_TAG and the Alembic Workbench #TAUTHOR_TAG ) as well as NLP tools and resources that can be manipulated from the GUI .', 'For instance, GATE currently provides a POS tagger, named entity recogniser and gazetteer and ontology editors #AUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', '']",0
"['', 'g.', 'Generalure for Text Engineering (GATE) #AUTHOR_TAG and theLP and resources.', 'For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors #TAUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', 'the of to']","['', '', 'General Architecture for Text Engineering (GATE) #AUTHOR_TAG and the NLP and resources', 'For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors #TAUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', 'the of to']","['', 'g.', 'General Architecture for Text Engineering (GATE) #AUTHOR_TAG andLP tools and resources', 'For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors #TAUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', 'the addition of to']","['', '', '', 'For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors #TAUTHOR_TAG .', 'GATE goes beyond earlier systems by using a component-based infrastructure #AUTHOR_TAG which the GUI is built on top of.', '']",0
"['Software engineering research on Generative Programming #TAUTHOR_TAG attempts to solve these problems by focusing on the development of configurable elementary components and knowledge to combine these components into complete systems .', 'Our infrastructure NLP will performance ']","['Software engineering research on Generative Programming #TAUTHOR_TAG attempts to solve these problems by focusing on the development of configurable elementary components and knowledge to combine these components into complete systems .', 'Our infrastructure NLP will performance 1']","['Software engineering research on Generative Programming #TAUTHOR_TAG attempts to solve these problems by focusing on the development of configurable elementary components and knowledge to combine these components into complete systems .', 'Our infrastructure NLP will provide high performance 1']","['Software engineering research on Generative Programming #TAUTHOR_TAG attempts to solve these problems by focusing on the development of configurable elementary components and knowledge to combine these components into complete systems .', '']",0
"['NLP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus #TAUTHOR_TAG will have manually corrected POS tags , a tenfold increase over the Penn Treebank #AUTHOR_TAG , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations.']","['NLP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus #TAUTHOR_TAG will have manually corrected POS tags , a tenfold increase over the Penn Treebank #AUTHOR_TAG , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations.']","['NLP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus #TAUTHOR_TAG will have manually corrected POS tags , a tenfold increase over the Penn Treebank #AUTHOR_TAG , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations.']","['NLP is experiencing an explosion in the quantity of electronic text available.', 'Some of this new data will be manually annotated.', 'For example , 10 million words of the American National Corpus #TAUTHOR_TAG will have manually corrected POS tags , a tenfold increase over the Penn Treebank #AUTHOR_TAG , currently used for training POS taggers .', 'This will require more efficient learning algorithms and implementations.']",0
"['A number of stand-alone tools have also been developed.', 'For example , the suite of LT tools #TAUTHOR_TAG perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files', '', '', '']","['A number of stand-alone tools have also been developed.', 'For example , the suite of LT tools #TAUTHOR_TAG perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '', '', '']","['A number of stand-alone tools have also been developed.', 'For example , the suite of LT tools #TAUTHOR_TAG perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '', '', '']","['A number of stand-alone tools have also been developed.', 'For example , the suite of LT tools #TAUTHOR_TAG perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '', '', '']",0
"['', '', '', 'To provide the required configurability in the static version of the code we will use policy templates #TAUTHOR_TAG , and for the dynamic version we will use configuration classes .']","['', '', '', 'To provide the required configurability in the static version of the code we will use policy templates #TAUTHOR_TAG , and for the dynamic version we will use configuration classes .']","['', '', '', 'To provide the required configurability in the static version of the code we will use policy templates #TAUTHOR_TAG , and for the dynamic version we will use configuration classes .']","['', '', '', 'To provide the required configurability in the static version of the code we will use policy templates #TAUTHOR_TAG , and for the dynamic version we will use configuration classes .']",5
"['However, the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus #AUTHOR_TAG', 'Recent work #TAUTHOR_TAG has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web', '', '', '', '']","['However, the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus #AUTHOR_TAG', 'Recent work #TAUTHOR_TAG has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '', '', '', '']","['However, the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus #AUTHOR_TAG .', 'Recent work #TAUTHOR_TAG has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '', '', '', '']","['However, the greatest increase is in the amount of raw text available to be processed, e.g. the English Gigaword Corpus #AUTHOR_TAG .', 'Recent work #TAUTHOR_TAG has suggested that some tasks will benefit from using significantly more data .', 'Also, many potential applications of NLP will involve processing very large text databases.', 'For instance, biomedical text-mining involves extracting information from the vast body of biological and medical literature; and search engines may eventually apply NLP techniques to the whole web.', '', '', '', '']",0
"['A number of stand-alone tools have also been developed.', 'For example , the suite of LT tools #TAUTHOR_TAG perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files', '', '', '']","['A number of stand-alone tools have also been developed.', 'For example , the suite of LT tools #TAUTHOR_TAG perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '', '', '']","['A number of stand-alone tools have also been developed.', 'For example , the suite of LT tools #TAUTHOR_TAG perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '', '', '']","['A number of stand-alone tools have also been developed.', 'For example , the suite of LT tools #TAUTHOR_TAG perform tokenization , tagging and chunking on XML marked-up text directly .', 'These tools also store their configuration state, e.g. the transduction rules used in LT CHUNK, in XML configuration files.', '', '', '']",0
"['Machine learning methods should be interchangeable : Transformation-based learning ( TBL ) #TAUTHOR_TAG and Memory-based learning ( MBL ) #AUTHOR_TAG have been applied to many different problems , so a single interchangeable component should be used to represent each method .', 'We will these components on the of Weka #AUTHOR_TAG .']","['Machine learning methods should be interchangeable : Transformation-based learning ( TBL ) #TAUTHOR_TAG and Memory-based learning ( MBL ) #AUTHOR_TAG have been applied to many different problems , so a single interchangeable component should be used to represent each method .', 'We will these components on the of Weka #AUTHOR_TAG .']","['Machine learning methods should be interchangeable : Transformation-based learning ( TBL ) #TAUTHOR_TAG and Memory-based learning ( MBL ) #AUTHOR_TAG have been applied to many different problems , so a single interchangeable component should be used to represent each method .', 'We will base these components on the design of Weka #AUTHOR_TAG .']","['Machine learning methods should be interchangeable : Transformation-based learning ( TBL ) #TAUTHOR_TAG and Memory-based learning ( MBL ) #AUTHOR_TAG have been applied to many different problems , so a single interchangeable component should be used to represent each method .', 'We will base these components on the design of Weka #AUTHOR_TAG .']",4
"['Efficiency has not been a for NLP research in general.', 'it will be increasingly important techniques become more complex and corpus sizes grow', 'An example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used by #AUTHOR_TAG converge very slowly to complex techniques from the optimisation more', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit #TAUTHOR_TAG which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging #AUTHOR_TAG .', 'The TOS #AUTHOR_TAG']","['Efficiency has not been a for NLP research in general.', 'it will be increasingly important techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used by #AUTHOR_TAG converge very slowly, to complex techniques from the optimisation more', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit #TAUTHOR_TAG which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging #AUTHOR_TAG .', 'The TNT POS #AUTHOR_TAG']","['Efficiency has not been a focus for NLP research in general.', 'it will be increasingly important techniques become more complex and corpus sizes grow', 'An example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used by #AUTHOR_TAG converge very slowly to complex techniques from the optimisation literature', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit #TAUTHOR_TAG which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging #AUTHOR_TAG .', ' #AUTHOR_TAG']","['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used by #AUTHOR_TAG that converge very slowly, to complex techniques from the optimisation literature that converge much more rapidly #AUTHOR_TAG .', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit #TAUTHOR_TAG which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging #AUTHOR_TAG .', '']",0
"['The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines #TAUTHOR_TAG .', 'An example tag is shown in Figure 1.']","['The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines #TAUTHOR_TAG .', 'An example tagger is shown in Figure 1.']","['The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines #TAUTHOR_TAG .', 'An example is shown in Figure 1.']","['The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines #TAUTHOR_TAG .', 'An example of using the Python tagger interface is shown in Figure 1.']",0
"['', '', 'OS.', 'These tools use a highly optimised GIS implementation and provide sophisticated Gaussian smoothing #TAUTHOR_TAG .', '']","['', '', 'POS', 'These tools use a highly optimised GIS implementation and provide sophisticated Gaussian smoothing #TAUTHOR_TAG .', '']","['', '', '', 'These tools use a highly optimised GIS implementation and provide sophisticated Gaussian smoothing #TAUTHOR_TAG .', '']","['', '', '', 'These tools use a highly optimised GIS implementation and provide sophisticated Gaussian smoothing #TAUTHOR_TAG .', '']",5
"['Efficiency has not been a for NLP research in general.', 'it will be increasingly important techniques become more complex and corpus sizes grow', 'An example of this is the estimation of maximum entropy models, from simple iter estimation algorithms used very slowly', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit #AUTHOR_TAG which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging #TAUTHOR_TAG .', '']","['Efficiency has not been a for NLP research in general.', 'it will be increasingly important techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms used very slowly,', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit #AUTHOR_TAG which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging #TAUTHOR_TAG .', '']","['Efficiency has not been a focus for NLP research in general.', 'it will be increasingly important techniques become more complex and corpus sizes grow', 'An example of this is the estimation of maximum entropy models, from simple iterative estimation algorithms usedge very slowly', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit #AUTHOR_TAG which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging #TAUTHOR_TAG .', '']","['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', '', 'Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit #AUTHOR_TAG which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging #TAUTHOR_TAG .', '']",0
"['Finally , the Natural Language Toolkit ( NLTK ) is a package of NLP components implemented in Python #TAUTHOR_TAG .', 'Python scripting is extremely simple to learn read and write and using the existing components and designing new components is']","['Finally , the Natural Language Toolkit ( NLTK ) is a package of NLP components implemented in Python #TAUTHOR_TAG .', 'Python scripting is extremely simple to learn, read and write, and using the existing components and designing new components is']","['Finally , the Natural Language Toolkit ( NLTK ) is a package of NLP components implemented in Python #TAUTHOR_TAG .', 'Python scripting is extremely simple to learn read and write and so using the existing components and designing new components is']","['Finally , the Natural Language Toolkit ( NLTK ) is a package of NLP components implemented in Python #TAUTHOR_TAG .', 'Python scripting is extremely simple to learn, read and write, and so using the existing components and designing new components is simple.']",0
"['The implementation has been inspired by experience in extracting information from very large corpora #AUTHOR_TAG and performing experiments on maximum entropy sequence tagging #TAUTHOR_TAG .', 'We have implemented a POS tagger supertagger and named entity recogniser the infrastructure', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #AUTHOR_TAG and performing experiments on maximum entropy sequence tagging #TAUTHOR_TAG .', 'We have implemented a POS tagger, supertagger and named entity recogniser the infrastructure.', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #AUTHOR_TAG and performing experiments on maximum entropy sequence tagging #TAUTHOR_TAG .', 'We have already implemented a POS tagger, chunker, CCG supertagger and named entity recogniser using the infrastructure.', '', '', '']","['The implementation has been inspired by experience in extracting information from very large corpora #AUTHOR_TAG and performing experiments on maximum entropy sequence tagging #TAUTHOR_TAG .', 'We have already implemented a POS tagger, chunker, CCG supertagger and named entity recogniser using the infrastructure.', '', '', '']",4
"['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by #AUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly #TAUTHOR_TAG .', '', '']","['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by #AUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly #TAUTHOR_TAG .', '', '']","['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by #AUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly #TAUTHOR_TAG .', '', '']","['Efficiency has not been a focus for NLP research in general.', 'However, it will be increasingly important as techniques become more complex and corpus sizes grow.', 'An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by #AUTHOR_TAG that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly #TAUTHOR_TAG .', '', '']",0
"['The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines #TAUTHOR_TAG .', 'An example tag is shown in Figure 1.']","['The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines #TAUTHOR_TAG .', 'An example tagger is shown in Figure 1.']","['The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines #TAUTHOR_TAG .', 'An example is shown in Figure 1.']","['The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines #TAUTHOR_TAG .', 'An example of using the Python tagger interface is shown in Figure 1.']",0
"['Eff not a for NLP research in general', 'be increasingly more sizes', '', '', 'The TNT POS tagger #TAUTHOR_TAG has also been designed to train and run very quickly , tagging between 30,000 and 60,000 words per second .']","['Efficiency not a for NLP research in general.', 'be increasingly more sizes', '', '', 'The TNT POS tagger #TAUTHOR_TAG has also been designed to train and run very quickly , tagging between 30,000 and 60,000 words per second .']","['Eff has not a focus for NLP research in general', 'it will be increasingly become morepus sizes', '', '', 'The TNT POS tagger #TAUTHOR_TAG has also been designed to train and run very quickly , tagging between 30,000 and 60,000 words per second .']","['Efficiency has not been a focus for NLP research in general.', '', '', '', 'The TNT POS tagger #TAUTHOR_TAG has also been designed to train and run very quickly , tagging between 30,000 and 60,000 words per second .']",0
"['', '', '', 'G POS named entity recogn gazette', 'GATE goes beyond earlier systems by using a component-based infrastructure #TAUTHOR_TAG which the GUI is built on top of .', 'This allows components to be highly configurable and simplifies the addition of new components to the system.']","['', '', '', 'GATE POS named entity recogniser gazetteer', 'GATE goes beyond earlier systems by using a component-based infrastructure #TAUTHOR_TAG which the GUI is built on top of .', 'This allows components to be highly configurable and simplifies the addition of new components to the system.']","['', '', '', 'named entity recogniser gazette', 'GATE goes beyond earlier systems by using a component-based infrastructure #TAUTHOR_TAG which the GUI is built on top of .', 'This allows components to be highly configurable and simplifies the addition of new components to the system.']","['', '', '', '', 'GATE goes beyond earlier systems by using a component-based infrastructure #TAUTHOR_TAG which the GUI is built on top of .', 'This allows components to be highly configurable and simplifies the addition of new components to the system.']",0
"['""Semantic grammars"" already exist which describe not only the syntax but the semantics of natural language', 'for instance , #TAUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #AUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['""Semantic grammars"" already exist which describe not only the syntax but the semantics of natural language.', 'for instance , #TAUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #AUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['""Semantic grammars"" already exist which describe not only the syntax but also the semantics of natural language.', 'for instance , #TAUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #AUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['""Semantic grammars"" already exist which describe not only the syntax but also the semantics of natural language.', 'Thus for instance , #TAUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #AUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']",0
"['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #TAUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', '', '']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #TAUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', '', '']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #TAUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', '', '']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #TAUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', '', '']",0
"['', '', '', ' #AUTHOR_TAG and #TAUTHOR_TAG learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']","['', '', '', ' #AUTHOR_TAG and #TAUTHOR_TAG learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']","['', '', '', ' #AUTHOR_TAG and #TAUTHOR_TAG learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']","['', '', '', 'Similarly , #AUTHOR_TAG and #TAUTHOR_TAG learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']",0
"['', '', '', '', ' #TAUTHOR_TAG use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts .']","['', '', '', '', ' #TAUTHOR_TAG use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts .']","['', '', '', '', ' #TAUTHOR_TAG use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts .']","['', '', '', '', 'And #TAUTHOR_TAG use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts .']",0
"['', 'onym constructs', 'as Figures 34 and 5 show the FTAG trees on by F', 'the is to correspond but syntically to this ageneral.', 'To address this problem , we are currently working on developing a metagrammar in the sense of #TAUTHOR_TAG .', 'This metagrammar allows us to factorise both syntactic and semantic information.', 'Syntactic information is factorised in the usual way.', 'For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur.', 'But additionnally there will be semantic classes such as, ""binary predicate of semantic type X"" which will be associated with the relevant syntactic for instance, NOVN1 (the class of transitive verbs with nominal arguments),ARYPRE (the class of binary pred noun), NO the', '']","['', 'constructs', 'as Figures 3, 4 and 5 show, the FTAG trees on by FTAG', 'the is to correspondances but syntactically to this a', 'To address this problem , we are currently working on developing a metagrammar in the sense of #TAUTHOR_TAG .', 'This metagrammar allows us to factorise both syntactic and semantic information.', 'Syntactic information is factorised in the usual way.', 'For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur.', 'But additionnally there will be semantic classes such as, ""binary predicate of semantic type X"" which will be associated with the relevant syntactic for instance, NOVN1 (the class of transitive verbs with nominal arguments), (the class of binary nouns), the', '']","['', 'actic constructs', 'as Figures 3, 4 and 5 show, the FTAG trees on by', 'the problem to but synt to thisgeneral.', 'To address this problem , we are currently working on developing a metagrammar in the sense of #TAUTHOR_TAG .', 'This metagrammar allows us to factorise both syntactic and semantic information.', 'Syntactic information is factorised in the usual way.', 'For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur.', 'But additionnally there will be semantic classes such as, ""binary predicate of semantic type X"" which will be associated with the relevant syntactic classes for instance, NOVN1 (the class of transitive verbs with nominal arguments), BINARY NPRED (the class of the class', '']","['', '', '', '', 'To address this problem , we are currently working on developing a metagrammar in the sense of #TAUTHOR_TAG .', 'This metagrammar allows us to factorise both syntactic and semantic information.', 'Syntactic information is factorised in the usual way.', 'For instance, there will be a class NOVN1 which groups together all the initial trees representing the possible syntactic configurations in which a transitive verb with two nominal arguments can occur.', 'But additionnally there will be semantic classes such as, ""binary predicate of semantic type X"" which will be associated with the relevant syntactic classes for instance, NOVN1 (the class of transitive verbs with nominal arguments), BINARY NPRED (the class of binary predicative nouns), NOVSUPNN1 , the class of support verb constructions taking two nominal arguments.', '']",3
"['', '', '', 'Similarly , #TAUTHOR_TAG and #AUTHOR_TAG learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', 'And #AUTHOR_TAG']","['', '', '', 'Similarly , #TAUTHOR_TAG and #AUTHOR_TAG learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', 'And #AUTHOR_TAG']","['', '', '', 'Similarly , #TAUTHOR_TAG and #AUTHOR_TAG learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', 'And #AUTHOR_TAG']","['', '', '', 'Similarly , #TAUTHOR_TAG and #AUTHOR_TAG learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .', '']",0
"['To represent the semantics of predicative units , we use FrameNet inventory of frames and frame elements ( C. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'FrameNet is an online lexical resource for English based on the principles of Frame Semantics.', 'In this, a word evokes a frame i.e., a simple or a complex, and each frame is associated with a of frame elements that is a of fulfilling a the frame', 'Finally each frame is associated with a set of target words, the words that evoke that frame']","['To represent the semantics of predicative units , we use FrameNet inventory of frames and frame elements ( C. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'FrameNet is an online lexical resource for English based on the principles of Frame Semantics.', 'In this approach, a word evokes a frame i.e., a simple or a complex event, and each frame is associated with a of frame elements that is, a of fulfilling a the frame.', 'Finally each frame is associated with a set of target words, the words that evoke that frame.']","['To represent the semantics of predicative units , we use FrameNet inventory of frames and frame elements ( C. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'FrameNet is an online lexical resource for English based on the principles of Frame Semantics.', 'In this approach, a word evokes a frame i.e., a simple or a complex event, and each frame is associated with a number of frame elements that is a number of participants fulfilling a the frame.', 'Finally each frame is associated with a set of target words, the words that evoke that frame']","['To represent the semantics of predicative units , we use FrameNet inventory of frames and frame elements ( C. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'FrameNet is an online lexical resource for English based on the principles of Frame Semantics.', 'In this approach, a word evokes a frame i.e., a simple or a complex event, and each frame is associated with a number of frame elements that is, a number of participants fulfilling a given role in the frame.', 'Finally each frame is associated with a set of target words, the words that evoke that frame.']",5
"['', 'aphr', 'For instance , #TAUTHOR_TAG acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .', '', '']","['', 'paraphrases', 'For instance , #TAUTHOR_TAG acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .', '', '']","['', 'aphr', 'For instance , #TAUTHOR_TAG acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .', '', '']","['', '', 'For instance , #TAUTHOR_TAG acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .', '', '']",0
"['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #AUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity #TAUTHOR_TAG .', '.']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #AUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity #TAUTHOR_TAG .', 'techniques.']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #AUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity #TAUTHOR_TAG .', '.']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #AUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity #TAUTHOR_TAG .', 'techniques.']",3
"['', '', '', '', 'the', 'For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena #TAUTHOR_TAG ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information #AUTHOR_TAG', 'these toolsaphrastic power grammar', '', '', '', '', '']","['', '', '', '', 'the', 'For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena #TAUTHOR_TAG ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information #AUTHOR_TAG', 'these tools paraphrastic power grammar.', '', '', '', '', '']","['', '', '', '', '', 'For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena #TAUTHOR_TAG ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information #AUTHOR_TAG .', 'these toolsating the paraphrastic power a grammar.', '', '', '', '', '']","['', '', '', '', '', 'For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena #TAUTHOR_TAG ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information #AUTHOR_TAG .', '', '', '', '', '', '']",1
"['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are focusing on paraphrases than fineainedantic distin unders the description of the relations permittedantics used way of/ relationships', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are focusing on paraphrases than fine grained semantic distinctions, the description of the relations permitted semantics used way of relationships.', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are here focusing on paraphrases than fine grainedantic distinctions, the description of the scope relations permitted flat semantics used of/ relationships', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', '', '', '']",1
"['can aaphrmar', '', 'Whilepus driven efforts along the PARSEVAL lines #TAUTHOR_TAG are good at giving some measure of a grammar coverage , they are not suitable for finer grained analysis and in particular , for progress evaluation , regression testing and comparative report generation .', '', '']","['can a paraphrastic', '', 'While corpus driven efforts along the PARSEVAL lines #TAUTHOR_TAG are good at giving some measure of a grammar coverage , they are not suitable for finer grained analysis and in particular , for progress evaluation , regression testing and comparative report generation .', '', '']","['can', '', 'Whilepus driven efforts along the PARSEVAL lines #TAUTHOR_TAG are good at giving some measure of a grammar coverage , they are not suitable for finer grained analysis and in particular , for progress evaluation , regression testing and comparative report generation .', '', '']","['', '', 'While corpus driven efforts along the PARSEVAL lines #TAUTHOR_TAG are good at giving some measure of a grammar coverage , they are not suitable for finer grained analysis and in particular , for progress evaluation , regression testing and comparative report generation .', '', '']",0
"['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are focusing on paraphrases than fineainedantic distin unders the description of the relations permittedantics used way of/ relationships', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are focusing on paraphrases than fine grained semantic distinctions, the description of the relations permitted semantics used way of relationships.', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are here focusing on paraphrases than fine grainedantic distinctions, the description of the scope relations permitted flat semantics used of/ relationships', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', '', '', '']",1
"['rench altern are described in', '', 'In particular , #TAUTHOR_TAG lists the converses of some 3 500 predicative nouns .']","['french alternations are described in', '', 'In particular , #TAUTHOR_TAG lists the converses of some 3 500 predicative nouns .']","['are partially described in', '', 'In particular , #TAUTHOR_TAG lists the converses of some 3 500 predicative nouns .']","['', '', 'In particular , #TAUTHOR_TAG lists the converses of some 3 500 predicative nouns .']",3
"['As we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar #TAUTHOR_TAG thus ensuring an additional level of abstraction .', 'The metagram is an abstract spec linguistic properties ( structure, val, realisation of grammatical functions etc.) encoded basic', '']","['As we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar #TAUTHOR_TAG thus ensuring an additional level of abstraction .', 'The metagrammar is an abstract specification linguistic properties (phrase structure, valency, realisation of grammatical functions etc.) encoded basic', '']","['As we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar #TAUTHOR_TAG thus ensuring an additional level of abstraction .', 'The metagrammar is an abstract specification the linguistic properties ( structure, valency, realisation of grammatical functions etc.) encoded', '']","['As we shall briefly discuss in section 4, the grammar is developed with the help of a meta-grammar #TAUTHOR_TAG thus ensuring an additional level of abstraction .', 'The metagrammar is an abstract specification of the linguistic properties (phrase structure, valency, realisation of grammatical functions etc.) encoded in the grammar basic units.', '']",5
"['For shuffling paraphrases, french alternations are partially described in (Saint- #AUTHOR_TAG and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs.', 'For complementing this database and for converse constructions , the LADL tables #TAUTHOR_TAG can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .', 'In, #AUTHOR_TAG lists the converses of some 3 0 predicative nouns.']","['For shuffling paraphrases, french alternations are partially described in (Saint- #AUTHOR_TAG and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs.', 'For complementing this database and for converse constructions , the LADL tables #TAUTHOR_TAG can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .', 'In particular, #AUTHOR_TAG lists the converses of some 3 500 predicative nouns.']","['For shuffling paraphrases, french alternations are partially described in (Saint- #AUTHOR_TAG and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs.', 'For complementing this database and for converse constructions , the LADL tables #TAUTHOR_TAG can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .', 'In, #AUTHOR_TAG lists the converses of some 3 500 predicative nouns.']","['For shuffling paraphrases, french alternations are partially described in (Saint- #AUTHOR_TAG and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs.', 'For complementing this database and for converse constructions , the LADL tables #TAUTHOR_TAG can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .', 'In particular, #AUTHOR_TAG lists the converses of some 3 500 predicative nouns.']",3
"['', '', '', '', '', 'engl and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information #TAUTHOR_TAG .', 'Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar.', '', '', '', '', '']","['', '', '', '', '', 'english and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information #TAUTHOR_TAG .', 'Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar.', '', '', '', '', '']","['', '', '', '', '', 'engl and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information #TAUTHOR_TAG .', 'Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar.', '', '', '', '', '']","['', '', '', '', '', '', 'Yet because they do not take into account the semantic dimension, none of these tools are adequate for evaluating the paraphrastic power of a grammar.', '', '', '', '', '']",0
"['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #AUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity #TAUTHOR_TAG .', '.']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #AUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity #TAUTHOR_TAG .', 'techniques.']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #AUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity #TAUTHOR_TAG .', '.']","['Cases of intracategorial synonymy are relatively straigthtforward as several electronic synonym dictionnaries for french are available #AUTHOR_TAG .', 'Multi word expressions however remain a problem as they are often not or only partially included in such dictionnaries.', 'For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity #TAUTHOR_TAG .', 'techniques.']",3
"['""Semantic gramm"" the sem natural', 'for instance , #AUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #TAUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['""Semantic grammars"" the natural', 'for instance , #AUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #TAUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['""Semantic grammars"" the syntax', 'for instance , #AUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #TAUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['', 'Thus for instance , #AUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #TAUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']",0
"['Semantic construction proceeds from the derived tree #TAUTHOR_TAG rather than -- as is more common in TAG -- from the derivation tree', '', '']","['Semantic construction proceeds from the derived tree #TAUTHOR_TAG rather than -- as is more common in TAG -- from the derivation tree', '', '']","['Semantic construction proceeds from the derived tree #TAUTHOR_TAG rather than -- as is more common in TAG -- from the derivation tree .', '', '']","['Semantic construction proceeds from the derived tree #TAUTHOR_TAG rather than -- as is more common in TAG -- from the derivation tree .', '', '']",0
"['""Semantic grammars"" already exist which describe not only the syntax but the semantics of natural language', 'for instance , #TAUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #AUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['""Semantic grammars"" already exist which describe not only the syntax but the semantics of natural language.', 'for instance , #TAUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #AUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['""Semantic grammars"" already exist which describe not only the syntax but also the semantics of natural language.', 'for instance , #TAUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #AUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']","['""Semantic grammars"" already exist which describe not only the syntax but also the semantics of natural language.', 'Thus for instance , #TAUTHOR_TAG describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and #AUTHOR_TAG show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .']",0
"['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are focusing on paraphrases than fineainedantic distin unders the description of the relations permittedantics used way of/ relationships', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are focusing on paraphrases than fine grained semantic distinctions, the description of the relations permitted semantics used way of relationships.', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', 'we are here focusing on paraphrases than fine grainedantic distinctions, the description of the scope relations permitted flat semantics used of/ relationships', '', '']","['The language chosen for semantic representation is a flat semantics along the line of #TAUTHOR_TAG .', '', '', '']",1
"['For shuffling paraphrases , french alternations are partially described in #TAUTHOR_TAG and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs .', '', '']","['For shuffling paraphrases , french alternations are partially described in #TAUTHOR_TAG and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs .', '', '']","['For shuffling paraphrases , french alternations are partially described in #TAUTHOR_TAG and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs .', '', '']","['For shuffling paraphrases , french alternations are partially described in #TAUTHOR_TAG and a resource is available which describes alternation and the mapping verbs/alternations for roughly 1 700 verbs .', '', '']",0
"['', '', 'In this work, we use the Arabic root extraction technique in #AUTHOR_TAG .', 'It compares favorably to other stemming or root extraction algorithms #TAUTHOR_TAG , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', '', 'In this work, we use the Arabic root extraction technique in #AUTHOR_TAG .', 'It compares favorably to other stemming or root extraction algorithms #TAUTHOR_TAG , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', '', 'In this work, we use the Arabic root extraction technique in #AUTHOR_TAG .', 'It compares favorably to other stemming or root extraction algorithms #TAUTHOR_TAG , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', '', 'In this work, we use the Arabic root extraction technique in #AUTHOR_TAG .', 'It compares favorably to other stemming or root extraction algorithms #TAUTHOR_TAG , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']",4
"['', '', 'In this work, we use the Arabic root extraction technique in #AUTHOR_TAG .', 'It compares favorably to other stemming or root extraction algorithms #TAUTHOR_TAG , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', '', 'In this work, we use the Arabic root extraction technique in #AUTHOR_TAG .', 'It compares favorably to other stemming or root extraction algorithms #TAUTHOR_TAG , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', '', 'In this work, we use the Arabic root extraction technique in #AUTHOR_TAG .', 'It compares favorably to other stemming or root extraction algorithms #TAUTHOR_TAG , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']","['', '', 'In this work, we use the Arabic root extraction technique in #AUTHOR_TAG .', 'It compares favorably to other stemming or root extraction algorithms #TAUTHOR_TAG , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .', '']",4
"['selection techniques have been widely used in information retrieval as a means foring with the large number of words in a; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) #TAUTHOR_TAG , minimum description length principal #AUTHOR_TAG , and the X2 statistic .', '', '', '', '', '']","['selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) #TAUTHOR_TAG , minimum description length principal #AUTHOR_TAG , and the X2 statistic .', '', '', '', '', '']","['Feature selection techniques have been widely used in information retrieval as a means foring with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) #TAUTHOR_TAG , minimum description length principal #AUTHOR_TAG , and the X2 statistic .', '', '', '', '', '']","['Feature selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) #TAUTHOR_TAG , minimum description length principal #AUTHOR_TAG , and the X2 statistic .', '', '', '', '', '']",0
"['', '', '', '', '', 'This work is a continuation of that initiated in #TAUTHOR_TAG , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .', 'A 50% overall classification accuracy is reported when testing with a separately evaluation set (3 documents for each of the 2 categories', '']","['', '', '', '', '', 'This work is a continuation of that initiated in #TAUTHOR_TAG , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .', 'A 50% overall classification accuracy is reported when testing with a separately evaluation set (3 documents for each of the 12 categories).', '']","['', '', '', '', '', 'This work is a continuation of that initiated in #TAUTHOR_TAG , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .', 'A 50% overall classification accuracy is also reported when testing with a separately collected evaluation set (3 documents for each of the 12 categories).', '']","['', '', '', '', '', 'This work is a continuation of that initiated in #TAUTHOR_TAG , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .', 'A 50% overall classification accuracy is also reported when testing with a separately collected evaluation set (3 documents for each of the 12 categories).', '']",2
"['To sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in #TAUTHOR_TAG .', '6', '', '', '', '', '']","['To sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in #TAUTHOR_TAG .', '', '', '', '', '', '']","['To sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in #TAUTHOR_TAG .', '6', '', '', '', '', '']","['To sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in #TAUTHOR_TAG .', '', '', '', '', '', '']",1
"['A good study comparing document categorization algorithms can be found in #TAUTHOR_TAG .', 'More recently, #AUTHOR_TAG has performed a good survey of document categorization; recent works can also be found in #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #TAUTHOR_TAG .', 'More recently, #AUTHOR_TAG has performed a good survey of document categorization; recent works can also be found in #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #TAUTHOR_TAG .', 'More recently, #AUTHOR_TAG has performed a good survey of document categorization; recent works can also be found in #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #TAUTHOR_TAG .', 'More recently, #AUTHOR_TAG has performed a good survey of document categorization; recent works can also be found in #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']",0
"['In Arabic, however, the use of stems will not yield satisfactory categorization.', 'This is mainly due to the fact that Arabic is a non-concatenative language #TAUTHOR_TAG , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called the', 'needs further to be', '', '']","['In Arabic, however, the use of stems will not yield satisfactory categorization.', 'This is mainly due to the fact that Arabic is a non-concatenative language #TAUTHOR_TAG , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called the', 'needs further to be', '', '']","['In Arabic, however, the use of stems will not yield satisfactory categorization.', 'This is mainly due to the fact that Arabic is a non-concatenative language #TAUTHOR_TAG , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called', 'needs further to be processed', '', '']","['In Arabic, however, the use of stems will not yield satisfactory categorization.', 'This is mainly due to the fact that Arabic is a non-concatenative language #TAUTHOR_TAG , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called the root .', '', '', '']",0
"['a', 'ious feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) #AUTHOR_TAG , minimum description length principal #AUTHOR_TAG , and the χ 2 statistic.', ' #TAUTHOR_TAG has found strong correlations between DF , IG and the X2 statistic for a term .', 'χ 2 to produce best performance', '', '', '']","['a', 'Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) #AUTHOR_TAG , minimum description length principal #AUTHOR_TAG , and the χ 2 statistic.', ' #TAUTHOR_TAG has found strong correlations between DF , IG and the X2 statistic for a term .', 'χ 2 to produce best performance.', '', '', '']","['a selection', 'ious feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) #AUTHOR_TAG , minimum description length principal #AUTHOR_TAG , and the χ 2 statistic.', ' #TAUTHOR_TAG has found strong correlations between DF , IG and the X2 statistic for a term .', 'χ 2 to produce best performance.', '', '', '']","['', 'Various feature selection techniques have been used in automatic text categorization; they include document frequency (DF), information gain (IG) #AUTHOR_TAG , minimum description length principal #AUTHOR_TAG , and the χ 2 statistic.', ' #TAUTHOR_TAG has found strong correlations between DF , IG and the X2 statistic for a term .', '', '', '', '']",0
"['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #TAUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #TAUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #TAUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #TAUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']",0
"['a', 'text', '', '', 'text the and the retrieval tasks to problems such as information filtering and routing, clustering related documents, and the classification of documents into pre-specified subject themes.', 'Automatic text categorization has been used in search engines , digital library systems , and document management systems #TAUTHOR_TAG .', '', '', '']","['a', 'text', '', '', 'text the and the retrieval tasks to problems, such as information filtering and routing, clustering related documents, and the classification of documents into pre-specified subject themes.', 'Automatic text categorization has been used in search engines , digital library systems , and document management systems #TAUTHOR_TAG .', '', '', '']","['', '', '', '', 'the enhancement and the support information retrieval tasks to problems such as information filtering and routing, clustering related documents, and the classification of documents into pre-specified subject themes.', 'Automatic text categorization has been used in search engines , digital library systems , and document management systems #TAUTHOR_TAG .', '', '', '']","['', '', '', '', 'As such, one of the primary objectives of automatic text categorization has been the enhancement and the support of information retrieval tasks to tackle problems, such as information filtering and routing, clustering of related documents, and the classification of documents into pre-specified subject themes.', 'Automatic text categorization has been used in search engines , digital library systems , and document management systems #TAUTHOR_TAG .', '', '', '']",0
"['', '', '', 'to', 'In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in #TAUTHOR_TAG .', 'TF-IDterm frequency-inverse document frequency', '']","['', '', '', 'to', 'In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in #TAUTHOR_TAG .', 'TF-IDF (term frequency-inverse document frequency)', '']","['', '', '', 'to', 'In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in #TAUTHOR_TAG .', 'TF-IDterm frequency-inverse document frequency)', '']","['', '', '', '', 'In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in #TAUTHOR_TAG .', '', '']",1
"['While the TF measurement concerns the importance of a in a seeks to measure the relative importance of a term in a collection of documents', 'importance assumed invers', ' #TAUTHOR_TAG proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance .', ', the weight of each term/root in a document is given by w D,t TF D,t *F .']","['While the TF measurement concerns the importance of a in a seeks to measure the relative importance of a term in a collection of documents.', 'importance assumed inversely', ' #TAUTHOR_TAG proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance .', 'Thus, the weight of each term/root in a document is given by w D,t TF D,t * IDF .']","['While the TF measurement concerns the importance of a term in a seeks to measure the relative importance of a term in a collection of documents', 'The importance is assumed be inversely', 'proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance .', ', the weight of each term/root in a document is given by w D,t = TF D,t * IDF t .']","['While the TF measurement concerns the importance of a term in a given document, IDF seeks to measure the relative importance of a term in a collection of documents.', '', '', 'Thus, the weight of each term/root in a document is given by w D,t = TF D,t * IDF t .']",4
"['selection have been widely used in information retrieval as a means foring with the large number of words in a; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) #AUTHOR_TAG , minimum description length principal #TAUTHOR_TAG , and the X2 statistic .', '', '', '', '', '']","['selection have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) #AUTHOR_TAG , minimum description length principal #TAUTHOR_TAG , and the X2 statistic .', '', '', '', '', '']","['have been widely used in information retrieval as a means foring with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) #AUTHOR_TAG , minimum description length principal #TAUTHOR_TAG , and the X2 statistic .', '', '', '', '', '']","['Feature selection techniques have been widely used in information retrieval as a means for coping with the large number of words in a document; a selection is made to keep only the more relevant words.', 'Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) #AUTHOR_TAG , minimum description length principal #TAUTHOR_TAG , and the X2 statistic .', '', '', '', '', '']",0
"['Many machine learning algorithms have been applied for many years to text categorization.', 'include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , respectively .']","['Many machine learning algorithms have been applied for many years to text categorization.', 'include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , respectively .']","['Many machine learning algorithms have been applied for many years to text categorization.', 'include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , respectively .']","['Many machine learning algorithms have been applied for many years to text categorization.', 'include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG , respectively .']",0
"['', '', '', '', '', 'TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval #TAUTHOR_TAG .', '.']","['', '', '', '', '', 'TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval #TAUTHOR_TAG .', 'documents.']","['', '', '', '', '', 'TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval #TAUTHOR_TAG .', '.']","['', '', '', '', '', 'TF-IDF ( term frequency-inverse document frequency ) is one of the widely used feature selection techniques in information retrieval #TAUTHOR_TAG .', '']",0
"['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']",0
"['The bulk of the text categorization work has been devoted to with automatic categorization of English and Latin character documents.', 'For , #TAUTHOR_TAG discusses the evaluation of two different text categorization strategies with several variations of their feature spaces .']","['The bulk of the text categorization work has been devoted to with automatic categorization of English and Latin character documents.', 'For , #TAUTHOR_TAG discusses the evaluation of two different text categorization strategies with several variations of their feature spaces .']","['The bulk of the text categorization work has been devoted to with automatic categorization of English and Latin character documents.', 'For , #TAUTHOR_TAG discusses the evaluation of two different text categorization strategies with several variations of their feature spaces .']","['The bulk of the text categorization work has been devoted to cope with automatic categorization of English and Latin character documents.', 'For example , #TAUTHOR_TAG discusses the evaluation of two different text categorization strategies with several variations of their feature spaces .']",0
"['On the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques #AUTHOR_TAG , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist ) #AUTHOR_TAG or , more frequently , on a combination of the two #TAUTHOR_TAG , for example ) .', 'It that these are identify-V on', '']","['On the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques #AUTHOR_TAG , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist ) #AUTHOR_TAG or , more frequently , on a combination of the two #TAUTHOR_TAG , for example ) .', 'It that these are identify N-V on', '']","['On the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques #AUTHOR_TAG , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist ) #AUTHOR_TAG or , more frequently , on a combination of the two #TAUTHOR_TAG , for example ) .', 'It is that these techniques are identify- on', '']","['On the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques #AUTHOR_TAG , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist ) #AUTHOR_TAG or , more frequently , on a combination of the two #TAUTHOR_TAG , for example ) .', '', '']",1
"['ordserver', 'terms been identified as the most specific to corpus by a program and called TermoStat', 'The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles #TAUTHOR_TAG .', '', '']","['(server', 'terms been identified as the most specific to corpus by a program and called TermoStat.', 'The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles #TAUTHOR_TAG .', '', '']","['server ),', 'The terms have been identified as the most specific to corpus by a program and called TermoStat', 'The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles #TAUTHOR_TAG .', '', '']","['', 'The terms have been identified as the most specific to our corpus by a program developed by #AUTHOR_TAG and called TermoStat.', 'The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles #TAUTHOR_TAG .', '', '']",5
"['A number of applications have relied on distributional analysis #AUTHOR_TAG in order to build classes of semantically related terms.', 'This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness #TAUTHOR_TAG , for example ) , does not specify the relationship itself .', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not di\x1berentiated.']","['A number of applications have relied on distributional analysis #AUTHOR_TAG in order to build classes of semantically related terms.', 'This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness #TAUTHOR_TAG , for example ) , does not specify the relationship itself .', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not di\x1berentiated.']","['A number of applications have relied on distributional analysis #AUTHOR_TAG in order to build classes of semantically related terms.', 'This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness #TAUTHOR_TAG , for example ) , does not specify the relationship itself .', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not di\x1berentiated.']","['A number of applications have relied on distributional analysis #AUTHOR_TAG in order to build classes of semantically related terms.', 'This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness #TAUTHOR_TAG , for example ) , does not specify the relationship itself .', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not di\x1berentiated.']",0
"['More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : #TAUTHOR_TAG uses derivational morphology ; #AUTHOR_TAG use , as a point , a number of identical characters .']","['More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : #TAUTHOR_TAG uses derivational morphology ; #AUTHOR_TAG use , as a point , a number of identical characters .']","['More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : #TAUTHOR_TAG uses derivational morphology ; #AUTHOR_TAG use , as a starting point , a number of identical characters .']","['More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : #TAUTHOR_TAG uses derivational morphology ; #AUTHOR_TAG use , as a starting point , a number of identical characters .']",0
"['ten ordserver (), utilisateur (user ).', 'The terms have been identified as the most specific to our corpus by a program developed by #TAUTHOR_TAG and called TER1vloSTAT .', 'The ten most speci c nouns have been produced by comparing our corpus of computing to the French corpus Le', '', '']","['ten (server (system), utilisateur (user ).', 'The terms have been identified as the most specific to our corpus by a program developed by #TAUTHOR_TAG and called TER1vloSTAT .', 'The ten most speci c nouns have been produced by comparing our corpus of computing to the French corpus Le', '', '']","['ordserver ), (), utilisateur (user ).', 'The terms have been identified as the most specific to our corpus by a program developed by #TAUTHOR_TAG and called TER1vloSTAT .', 'The ten most speci c nouns have been produced by comparing our corpus of computing to the French corpus Le Monde,', '', '']","['', 'The terms have been identified as the most specific to our corpus by a program developed by #TAUTHOR_TAG and called TER1vloSTAT .', 'The ten most speci c nouns have been produced by comparing our corpus of computing to the French corpus Le Monde, composed of newspaper articles #AUTHOR_TAG .', '', '']",5
"['More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : #AUTHOR_TAG uses derivational morphology ; #TAUTHOR_TAG use , as a starting point , a number of identical characters .']","['More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : #AUTHOR_TAG uses derivational morphology ; #TAUTHOR_TAG use , as a starting point , a number of identical characters .']","['More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : #AUTHOR_TAG uses derivational morphology ; #TAUTHOR_TAG use , as a starting point , a number of identical characters .']","['More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : #AUTHOR_TAG uses derivational morphology ; #TAUTHOR_TAG use , as a starting point , a number of identical characters .']",0
"['On the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques #AUTHOR_TAG , on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist) #TAUTHOR_TAG or, more frequently, on a combination of the two #AUTHOR_TAG Kilgarri\x1b and #AUTHOR_TAG for example).', 'It noting that these techniques are identify-V', '']","['On the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques #AUTHOR_TAG , on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist) #TAUTHOR_TAG or, more frequently, on a combination of the two #AUTHOR_TAG Kilgarri\x1b and #AUTHOR_TAG for example).', 'It noting that these techniques are identify N-V', '']","['On the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques #AUTHOR_TAG , on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist) #TAUTHOR_TAG or, more frequently, on a combination of the two #AUTHOR_TAG Kilgarri\x1b and #AUTHOR_TAG for example).', 'It is noting that these techniques are identify-', '']","['On the other hand, other work has been carried out in order to acquire collocations.', 'Most of these endeavours have focused on purely statistical acquisition techniques #AUTHOR_TAG , on linguisitic acquisition (by the use of Part-of-Speech filters hand-crafted by a linguist) #TAUTHOR_TAG or, more frequently, on a combination of the two #AUTHOR_TAG Kilgarri\x1b and #AUTHOR_TAG for example).', '', '']",1
"['ASARES is based on a Machine Learning technique , Inductive Logic Programming ( ILP ) #TAUTHOR_TAG , which infers general morpho-syntactic patterns from a set of examples ( this set is noted E + hereafter ) and counter-examples ( E â\x88\x92 ) of the elements one wants to acquire and their context.', 'The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.', 'The acquisition process can be summarized in 3 steps:']","['ASARES is based on a Machine Learning technique , Inductive Logic Programming ( ILP ) #TAUTHOR_TAG , which infers general morpho-syntactic patterns from a set of examples ( this set is noted E + hereafter ) and counter-examples ( E â\x88\x92 ) of the elements one wants to acquire and their context.', 'The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.', 'The acquisition process can be summarized in 3 steps:']","['ASARES is based on a Machine Learning technique , Inductive Logic Programming ( ILP ) #TAUTHOR_TAG , which infers general morpho-syntactic patterns from a set of examples ( this set is noted E + hereafter ) and counter-examples ( E â\x88\x92 ) of the elements one wants to acquire and their context.', 'The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.', 'The acquisition process can be summarized in 3 steps:']","['ASARES is based on a Machine Learning technique , Inductive Logic Programming ( ILP ) #TAUTHOR_TAG , which infers general morpho-syntactic patterns from a set of examples ( this set is noted E + hereafter ) and counter-examples ( E â\x88\x92 ) of the elements one wants to acquire and their context.', 'The contextual patterns produced can then be applied to the corpus in order to retrieve new elements.', 'The acquisition process can be summarized in 3 steps:']",0
"['However , most strategies are based on `` internal or `` external methods #TAUTHOR_TAG , i.e. methods that rely on the form of terms or on the information gathered from contexts .', '(In some cases, an additional resource, such as a dictionary or a thes, is used during the', 'The']","['However , most strategies are based on `` internal or `` external methods #TAUTHOR_TAG , i.e. methods that rely on the form of terms or on the information gathered from contexts .', '(In some cases, an additional resource, such as a dictionary or a thesaurus, is used during the', 'The']","['However , most strategies are based on `` internal or `` external methods #TAUTHOR_TAG , i.e. methods that rely on the form of terms or on the information gathered from contexts .', '(In some cases, an additional resource, such as a dictionary or a thesaurus, is used during', 'The work']","['However , most strategies are based on `` internal or `` external methods #TAUTHOR_TAG , i.e. methods that rely on the form of terms or on the information gathered from contexts .', '(In some cases, an additional resource, such as a dictionary or a thesaurus, is used during the identification process.)', '']",1
"['In this paper, the method is applied to a French corpus on computing to and noun-verb combinations in which verbs convey a meaning of realization.', 'The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information #TAUTHOR_TAG .']","['In this paper, the method is applied to a French corpus on computing to and noun-verb combinations in which verbs convey a meaning of realization.', 'The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information #TAUTHOR_TAG .']","['In this paper, the method is applied to a French corpus on computing to and noun-verb combinations in which verbs convey a meaning of realization.', 'The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information #TAUTHOR_TAG .']","['In this paper, the method is applied to a French corpus on computing to and noun-verb combinations in which verbs convey a meaning of realization.', 'The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information #TAUTHOR_TAG .']",4
"['In addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques #TAUTHOR_TAG .']","['In addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques #TAUTHOR_TAG .']","['In addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques #TAUTHOR_TAG .']","['In addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques #TAUTHOR_TAG .']",4
"['ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework #TAUTHOR_TAG and called qualia relations #AUTHOR_TAG .', 'we to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework #TAUTHOR_TAG and called qualia relations #AUTHOR_TAG .', 'we to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework #TAUTHOR_TAG and called qualia relations #AUTHOR_TAG .', 'we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework #TAUTHOR_TAG and called qualia relations #AUTHOR_TAG .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']",0
"['', 'such rich semantic can be used to extend indices or reformulate queries ( similar to the work by #TAUTHOR_TAG with WoRDNET relations ) .']","['', 'such rich semantic can be used to extend indices or reformulate queries ( similar to the work by #TAUTHOR_TAG with WoRDNET relations ) .']","['', 'such rich semantic links can be used to extend indices or reformulate queries ( similar to the work by #TAUTHOR_TAG with WoRDNET relations ) .']","['', 'Indeed , such rich semantic links can be used to extend indices or reformulate queries ( similar to the work by #TAUTHOR_TAG with WoRDNET relations ) .']",1
"['ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework #AUTHOR_TAG and called qualia relations #TAUTHOR_TAG .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework #AUTHOR_TAG and called qualia relations #TAUTHOR_TAG .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework #AUTHOR_TAG and called qualia relations #TAUTHOR_TAG .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']","['ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework #AUTHOR_TAG and called qualia relations #TAUTHOR_TAG .', 'Here, we propose to use asares in a quite similar way to retrieve our valid N-V pairs.', '']",0
"['The main benefits of this acquisition technique lie in the inferred patterns.', 'Indeed , contrary to the more classical statistical methods ( Mutual Information , Loglike ... , see below ) used for collocation acquisition ( see #TAUTHOR_TAG for a review ) , these patterns allow :']","['The main benefits of this acquisition technique lie in the inferred patterns.', 'Indeed , contrary to the more classical statistical methods ( Mutual Information , Loglike ... , see below ) used for collocation acquisition ( see #TAUTHOR_TAG for a review ) , these patterns allow :']","['The main benefits of this acquisition technique lie in the inferred patterns.', 'Indeed , contrary to the more classical statistical methods ( Mutual Information , Loglike ... , see below ) used for collocation acquisition ( see #TAUTHOR_TAG for a review ) , these patterns allow :']","['The main benefits of this acquisition technique lie in the inferred patterns.', 'Indeed , contrary to the more classical statistical methods ( Mutual Information , Loglike ... , see below ) used for collocation acquisition ( see #TAUTHOR_TAG for a review ) , these patterns allow :']",0
"['The method used for the acquisition of N-V pairs relies mainly on asares, a pattern inference tool.', 'ASARES is presented in detail in #TAUTHOR_TAG .', 'We simply give a short account of its basic principles herein.']","['The method used for the acquisition of N-V pairs relies mainly on asares, a pattern inference tool.', 'ASARES is presented in detail in #TAUTHOR_TAG .', 'We simply give a short account of its basic principles herein.']","['The method used for the acquisition of N-V pairs relies mainly on asares, a pattern inference tool.', 'ASARES is presented in detail in #TAUTHOR_TAG .', 'We simply give a short account of its basic principles herein.']","['The method used for the acquisition of N-V pairs relies mainly on asares, a pattern inference tool.', 'ASARES is presented in detail in #TAUTHOR_TAG .', 'We simply give a short account of its basic principles herein.']",5
"['A number of applications have relied on distributional analysis #TAUTHOR_TAG in order to build classes of semantically related terms .', 'This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness #AUTHOR_TAG for example), does not the itself.', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated.']","['A number of applications have relied on distributional analysis #TAUTHOR_TAG in order to build classes of semantically related terms .', 'This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness #AUTHOR_TAG for example), does not the itself.', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated.']","['A number of applications have relied on distributional analysis #TAUTHOR_TAG in order to build classes of semantically related terms .', 'This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness #AUTHOR_TAG for example), does not the relationship itself.', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated.']","['A number of applications have relied on distributional analysis #TAUTHOR_TAG in order to build classes of semantically related terms .', 'This approach, which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness #AUTHOR_TAG for example), does not specify the relationship itself.', 'Hence, synonyms, co-hyponyms, hyperonyms, etc. are not differentiated.']",0
"['', '', '', 'blank', 'different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging #TAUTHOR_TAG .']","['', '', '', '', 'different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging #TAUTHOR_TAG .']","['', '', '', 'blank', 'the different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging #TAUTHOR_TAG .']","['', '', '', '', 'In addition to the different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging #TAUTHOR_TAG .']",0
"['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in ACE ', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in A', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']",0
"['we focus', 'us', '', 'we will adopt the nomenclature of the Automatic Content Extraction program #TAUTHOR_TAG : we will call the instances of textual references to objects/abstractions mentions , which either named (g. Mayor ) the president )onom she', 'the president', 'An entity the aggregate of all the mentions (of any level) which refer to one conceptual entity', '']","['we focus', '', '', 'we will adopt the nomenclature of the Automatic Content Extraction program #TAUTHOR_TAG : we will call the instances of textual references to objects/abstractions mentions , which either named ( e.g. Mayor ) the president ) she', '(the president)', 'An entity the aggregate of all the mentions (of any level) which refer to one conceptual entity.', '']","['we focus', '', '', 'we will adopt the nomenclature of the Automatic Content Extraction program #TAUTHOR_TAG : we will call the instances of textual references to objects/abstractions mentions , which named (g. John Mayor ) the president )onom she', 'the president)', 'An entity the aggregate of all the mentions (of any level) which refer to one conceptual entity.', '']","['', '', '', 'Instead , we will adopt the nomenclature of the Automatic Content Extraction program #TAUTHOR_TAG : we will call the instances of textual references to objects/abstractions mentions , which can be either named ( e.g. John Mayor ) , nominal ( the president ) or pronominal ( she , it ) .', '', 'An entity is the aggregate of all the mentions (of any level) which refer to one conceptual entity.', '']",5
"['In addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character n-grams , similar to those used for Chinese segmentation #TAUTHOR_TAG .', 'these, aric prefix the ar the state', '', '']","['In addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character n-grams , similar to those used for Chinese segmentation #TAUTHOR_TAG .', 'these models, arabic prefix the arcs the state', '', '']","['In addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character n-grams , similar to those used for Chinese segmentation #TAUTHOR_TAG .', 'these models, the arcs', '', '']","['In addition to the model based upon a dictionary of stems and words , we also experimented with models based upon character n-grams , similar to those used for Chinese segmentation #TAUTHOR_TAG .', '', '', '']",1
"['These types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the #TAUTHOR_TAG Arabic data .', 'The experiments are performed on a clearly specified partition the data', '']","['These types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the #TAUTHOR_TAG Arabic data .', 'The experiments are performed on a clearly specified partition the data,', '']","['These types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the #TAUTHOR_TAG Arabic data .', 'The experiments are performed on a clearly specified partition the data,', '']","['These types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the #TAUTHOR_TAG Arabic data .', '', '']",5
"['2', '', 'Each punctuation symbol is considered a separate token.', 'Character classes , such as punctuation , are defined according to the Unicode Standard #TAUTHOR_TAG .']","['', '', 'Each punctuation symbol is considered a separate token.', 'Character classes , such as punctuation , are defined according to the Unicode Standard #TAUTHOR_TAG .']","['2', '', 'Each punctuation symbol is considered a separate token.', 'Character classes , such as punctuation , are defined according to the Unicode Standard #TAUTHOR_TAG .']","['', '', 'Each punctuation symbol is considered a separate token.', 'Character classes , such as punctuation , are defined according to the Unicode Standard #TAUTHOR_TAG .']",5
"['', '', '', 'blank', 'different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging #TAUTHOR_TAG .']","['', '', '', '', 'different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging #TAUTHOR_TAG .']","['', '', '', 'blank', 'the different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging #TAUTHOR_TAG .']","['', '', '', '', 'In addition to the different forms of the Arabic word that result from the derivational and inflectional process, most prepositions, conjunctions, pronouns, and possessive forms are attached to the Arabic surface word.', 'It is these orthographic variations and complex morphological structure that make Arabic language processing challenging #TAUTHOR_TAG .']",0
['The coreference system system is similar to the Bell tree algorithm as described by #TAUTHOR_TAG .'],['The coreference system system is similar to the Bell tree algorithm as described by #TAUTHOR_TAG .'],['The coreference system system is similar to the Bell tree algorithm as described by #TAUTHOR_TAG .'],['The coreference system system is similar to the Bell tree algorithm as described by #TAUTHOR_TAG .'],1
"['Arabic has two kinds of plurals : broken plurals and sound plurals #TAUTHOR_TAG .', 'The formation of broken plurals is common, more and ir', '', '', '', 'The sound plurals are formed by adding plural suffixes to singular nouns (e.g., meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,']","['Arabic has two kinds of plurals : broken plurals and sound plurals #TAUTHOR_TAG .', 'The formation of broken plurals is common, more and', '', '', '', 'The sound plurals are formed by adding plural suffixes to singular nouns (e.g., meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,']","['Arabic has two kinds of plurals : broken plurals and sound plurals #TAUTHOR_TAG .', 'The formation of broken plurals is common, more and ir', '', '', '', 'The sound plurals are formed by adding plural suffixes to singular nouns (e.g., meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,']","['Arabic has two kinds of plurals : broken plurals and sound plurals #TAUTHOR_TAG .', 'The formation of broken plurals is common, more complex and often irregular.', '', '', '', 'The sound plurals are formed by adding plural suffixes to singular nouns (e.g., meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,']",0
"['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in ACE ', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in A', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']",0
"['classification', '', 'We use a maximum entropy Markov model (MEMM) classifier.', 'The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model ) #TAUTHOR_TAG .', '']","['classification', '', 'We use a maximum entropy Markov model (MEMM) classifier.', 'The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model ) #TAUTHOR_TAG .', '']","['', '', 'We use a maximum entropy Markov model (MEMM) classifier.', 'The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model ) #TAUTHOR_TAG .', '']","['', '', 'We use a maximum entropy Markov model (MEMM) classifier.', 'The principle of maximum entropy states that when one searches among probability distributions that model the observed data ( evidence ) , the preferred one is the one that maximizes the entropy ( a measure of the uncertainty of the model ) #TAUTHOR_TAG .', '']",0
"['the mention sub-type , which is a sub-category of the mention type #TAUTHOR_TAG ( e.g. OrgGovernmental , FacilityPath , etc. ) .']","['the mention sub-type , which is a sub-category of the mention type #TAUTHOR_TAG ( e.g. OrgGovernmental , FacilityPath , etc. ) .']","['the mention sub-type , which is a sub-category of the mention type #TAUTHOR_TAG ( e.g. OrgGovernmental , FacilityPath , etc. ) .']","['the mention sub-type , which is a sub-category of the mention type #TAUTHOR_TAG ( e.g. OrgGovernmental , FacilityPath , etc. ) .']",5
"['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in ACE ', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in A', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']",0
"[' #TAUTHOR_TAG demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .', 'A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules.']","[' #TAUTHOR_TAG demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .', 'A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules.']","[' #TAUTHOR_TAG demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .', 'A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules.']","[' #TAUTHOR_TAG demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .', 'A trigram language model was used to score and select among hypothesized segmentations determined by a set of prefix and suffix expansion rules.']",5
"['Both tasks are performed with a statistical framework the mention detection system is similar to the one presented in #AUTHOR_TAG and the coreference resolution system is similar to the one described in .', 'Both systems are built around from the maximum-entropy technique #TAUTHOR_TAG .', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in #AUTHOR_TAG and the coreference resolution system is similar to the one described in .', 'Both systems are built around from the maximum-entropy technique #TAUTHOR_TAG .', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in #AUTHOR_TAG and the coreference resolution system is similar to the one described in .', 'Both systems are built around from the maximum-entropy technique #TAUTHOR_TAG .', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework: the mention detection system is similar to the one presented in #AUTHOR_TAG and the coreference resolution system is similar to the one described in .', 'Both systems are built around from the maximum-entropy technique #TAUTHOR_TAG .', '', '', '', '', '', '', '']",5
"['Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in #TAUTHOR_TAG and the coreference resolution system is similar to the one described in #AUTHOR_TAG .', 'built around', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in #TAUTHOR_TAG and the coreference resolution system is similar to the one described in #AUTHOR_TAG .', 'built around', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in #TAUTHOR_TAG and the coreference resolution system is similar to the one described in #AUTHOR_TAG .', 'are built around', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in #TAUTHOR_TAG and the coreference resolution system is similar to the one described in #AUTHOR_TAG .', '', '', '', '', '', '', '', '']",1
"['The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not #TAUTHOR_TAG .', 'We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of t i respectively.', 'For a token t i , the backward token n-gram feature will contains the previous n − 1 tokens in the (t−n+', 'and the forward token n-gram feature will contains the next n − 1 tokens (t i+1', '']","['The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not #TAUTHOR_TAG .', 'We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of t i respectively.', 'For a token t i , the backward token n-gram feature will contains the previous n − 1 tokens in the (t i−n+1', 'and the forward token n-gram feature will contains the next n − 1 tokens (t i+1', '']","['The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not #TAUTHOR_TAG .', 'We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of t i respectively.', 'For a token t i , the backward token n-gram feature will contains the previous n − 1 tokens in the history (t i−n+1', 'and the forward token n-gram feature will contains the next n − 1 tokens (t i+1', '']","['The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not #TAUTHOR_TAG .', 'We denote these features as backward token tri-grams and forward token tri-grams for the previous and next context of t i respectively.', 'For a token t i , the backward token n-gram feature will contains the previous n − 1 tokens in the history (t i−n+1 , . . .', 't i−1 ) and the forward token n-gram feature will contains the next n − 1 tokens (t i+1 , . . .', '']",0
"['Features using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution #TAUTHOR_TAG .', 'For Arabic, since words are morphologically derived from a list of (']","['Features using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution #TAUTHOR_TAG .', 'For Arabic, since words are morphologically derived from a list of']","['Features using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution #TAUTHOR_TAG .', 'For Arabic, since words are morphologically derived from a list of (']","['Features using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution #TAUTHOR_TAG .', '']",5
"['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in ACE ', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in A', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']",0
"['an of the the character based is more segmenting words', 'We seeked to exploit this ability to generalize to improve the dictionary based model.', 'As in #TAUTHOR_TAG , we used unsupervised training data which is automatically segmented to discover previously unseen stems .', ', thegram is used Gig', '']","['an of the the character based is more segmenting words', 'We seeked to exploit this ability to generalize to improve the dictionary based model.', 'As in #TAUTHOR_TAG , we used unsupervised training data which is automatically segmented to discover previously unseen stems .', 'case, the is used Gigaword', '']","['an analysis of the errors the character based is more segmenting words', 'We seeked to exploit this ability to generalize to improve the dictionary based model.', 'As in #TAUTHOR_TAG , we used unsupervised training data which is automatically segmented to discover previously unseen stems .', ', the charactergram model is used', '']","['', 'We seeked to exploit this ability to generalize to improve the dictionary based model.', 'As in #TAUTHOR_TAG , we used unsupervised training data which is automatically segmented to discover previously unseen stems .', '', '']",5
"['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in ACE ', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in A', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']",0
"['The trained onicCE ', 'We introduce here a clearly defined and replicable split of the #TAUTHOR_TAG data , so that future investigations can accurately and correctly compare against the results presented here .']","['The trained on Arabic ACE', 'We introduce here a clearly defined and replicable split of the #TAUTHOR_TAG data , so that future investigations can accurately and correctly compare against the results presented here .']","['The system is trained on', 'We introduce here a clearly defined and replicable split of the #TAUTHOR_TAG data , so that future investigations can accurately and correctly compare against the results presented here .']","['', 'We introduce here a clearly defined and replicable split of the #TAUTHOR_TAG data , so that future investigations can accurately and correctly compare against the results presented here .']",5
"['segmentation composition state', ', illustrated in  segment', 'a dictionary', 'The final machine is a trigram language model , specifically a Kneser-Ney #TAUTHOR_TAG based backoff language model .', 'words', '']","['segmentation composition state', 'machine, illustrated in 1', 'a dictionary', 'The final machine is a trigram language model , specifically a Kneser-Ney #TAUTHOR_TAG based backoff language model .', 'words', '']","['this segmentation strategy the composition', 'illustrated in', 'a dictionary', 'The final machine is a trigram language model , specifically a Kneser-Ney #TAUTHOR_TAG based backoff language model .', 'known words', '']","['', '', '', 'The final machine is a trigram language model , specifically a Kneser-Ney #TAUTHOR_TAG based backoff language model .', '', '']",5
"['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in ACE ', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in A', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']",0
"['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in ACE ', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition taskEDR) for Arabic as described in A', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']","['In this paper we focus on the Entity Detection and Recognition task (EDR) for Arabic as described in ACE 2004 framework (ACE, 2004).', ""The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations #TAUTHOR_TAG , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks ."", '', '', '', '', '']",0
"['', '', '', '', 'We report results with two metrics: ECM-F and ACE- Value.', 'ECM-F is an entity-constrained mention Fmeasure ( cfXXX #TAUTHOR_TAG for how ECM-F is computed ) , and A', '']","['', '', '', '', 'We report results with two metrics: ECM-F and ACE- Value.', 'ECM-F is an entity-constrained mention Fmeasure ( cfXXX #TAUTHOR_TAG for how ECM-F is computed ) , and', '']","['', '', '', '', 'We report results with two metrics: ECM-F and ACE- Value.', 'ECM-F is an entity-constrained mention Fmeasure ( cfXXX #TAUTHOR_TAG for how ECM-F is computed ) , and A', '']","['', '', '', '', 'We report results with two metrics: ECM-F and ACE- Value.', 'ECM-F is an entity-constrained mention Fmeasure ( cfXXX #TAUTHOR_TAG for how ECM-F is computed ) , and ACE-Value is the official ACE evaluation metric .', '']",5
"['Arabic has two kinds of plurals : broken plurals and sound plurals #TAUTHOR_TAG .', 'The formation of broken plurals is common, more and ir', '', '', '', 'The sound plurals are formed by adding plural suffixes to singular nouns (e.g., meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,']","['Arabic has two kinds of plurals : broken plurals and sound plurals #TAUTHOR_TAG .', 'The formation of broken plurals is common, more and', '', '', '', 'The sound plurals are formed by adding plural suffixes to singular nouns (e.g., meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,']","['Arabic has two kinds of plurals : broken plurals and sound plurals #TAUTHOR_TAG .', 'The formation of broken plurals is common, more and ir', '', '', '', 'The sound plurals are formed by adding plural suffixes to singular nouns (e.g., meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,']","['Arabic has two kinds of plurals : broken plurals and sound plurals #TAUTHOR_TAG .', 'The formation of broken plurals is common, more complex and often irregular.', '', '', '', 'The sound plurals are formed by adding plural suffixes to singular nouns (e.g., meaning researcher): the plural suffix is for feminine nouns in grammatical cases (e.g.,']",0
"['Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in #AUTHOR_TAG and the coreference resolution system is similar to the one described in #TAUTHOR_TAG .', 'Both systems are built around from the maximum-entropy technique #AUTHOR_TAG', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in #AUTHOR_TAG and the coreference resolution system is similar to the one described in #TAUTHOR_TAG .', 'Both systems are built around from the maximum-entropy technique #AUTHOR_TAG', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in #AUTHOR_TAG and the coreference resolution system is similar to the one described in #TAUTHOR_TAG .', 'Both systems are built around from the maximum-entropy technique #AUTHOR_TAG .', '', '', '', '', '', '', '']","['Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in #AUTHOR_TAG and the coreference resolution system is similar to the one described in #TAUTHOR_TAG .', 'Both systems are built around from the maximum-entropy technique #AUTHOR_TAG .', '', '', '', '', '', '', '']",1
"['We want to investigate the usefulness of stem n- gram features in the mention detection system.', ""As stated before , the experiments are run in the ACE '04 framework #TAUTHOR_TAG where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a sub-type ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) ."", 'Detecting the mention of consecutive and type', '', '', '']","['We want to investigate the usefulness of stem n- gram features in the mention detection system.', ""As stated before , the experiments are run in the ACE '04 framework #TAUTHOR_TAG where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a sub-type ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) ."", 'Detecting the mention of consecutive and type', '', '', '']","['We want to investigate the usefulness of stem n- gram features in the mention detection system.', ""As stated before , the experiments are run in the ACE '04 framework #TAUTHOR_TAG where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a sub-type ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) ."", 'Detecting the mention of and main type', '', '', '']","['We want to investigate the usefulness of stem n- gram features in the mention detection system.', ""As stated before , the experiments are run in the ACE '04 framework #TAUTHOR_TAG where the system will identify mentions and will label them ( cfXXX Section 4 ) with a type ( person , organization , etc ) , a sub-type ( OrgCommercial , OrgGovernmental , etc ) , a mention level ( named , nominal , etc ) , and a class ( specific , generic , etc ) ."", '', '', '', '']",5
"['where mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model #TAUTHOR_TAG .']","['where mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model #TAUTHOR_TAG .']","['where mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model #TAUTHOR_TAG .']","['where mk is one mention in entity e , and the basic model building block PL ( L = 1 | e , mk , m ) is an exponential or maximum entropy model #TAUTHOR_TAG .']",5
"['We web- interface to semantic', '', 'super experiment.', ' #TAUTHOR_TAG observed that some annotators were not familiar with the exact definition of semantic relatedness .', 'Their results differed particularly in cases of antonymy or distributionally related pairs.', 'We with introduction to SR stressing the crucial points.', '', '', '', '']","['We web-based interface to semantic', '', 'supervised experiment.', ' #TAUTHOR_TAG observed that some annotators were not familiar with the exact definition of semantic relatedness .', 'Their results differed particularly in cases of antonymy or distributionally related pairs.', 'We with introduction to SR stressing the crucial points.', '', '', '', '']","['We developed a web-based interface to sem', '', 'super the experiment.', ' #TAUTHOR_TAG observed that some annotators were not familiar with the exact definition of semantic relatedness .', 'Their results differed particularly in cases of antonymy or distributionally related pairs.', 'We created with to SR stressing the crucial points.', '', '', '', '']","['', '', '', ' #TAUTHOR_TAG observed that some annotators were not familiar with the exact definition of semantic relatedness .', 'Their results differed particularly in cases of antonymy or distributionally related pairs.', 'We created a manual with a detailed introduction to SR stressing the crucial points.', '', '', '', '']",4
"['Linguistic plays an important role in many applications like information retrieval, word disambiguation sp correction.', 'It is defined on different kinds of textual units, e.g.', 'documents, parts of a document (e.g.', 'words and their surrounding context), words or concepts #TAUTHOR_TAG .']","['Linguistic plays an important role in many applications like information retrieval, word disambiguation, spelling correction.', 'It is defined on different kinds of textual units, e.g.', 'documents, parts of a document (e.g.', 'words and their surrounding context), words or concepts #TAUTHOR_TAG .']","['Linguistic distance plays an important role in many applications like information retrieval, word sense disambiguation, text summarization spelling correction.', 'It is defined on different kinds of textual units, e.g.', 'documents, parts of a document (e.g.', 'words and their surrounding context), words or concepts #TAUTHOR_TAG .']","['Linguistic distance plays an important role in many applications like information retrieval, word sense disambiguation, text summarization or spelling correction.', 'It is defined on different kinds of textual units, e.g.', 'documents, parts of a document (e.g.', '']",0
"['', '', 'is an concept assignained is felt', '', '', '', '', '', 'In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im #TAUTHOR_TAG . Table 1: Comparison of previous experiments.', 'R/G=Rubenstein and Goodenough, M/C=Miller and Charles, Res=Resnik, Fin=Finkelstein, Gur=Gurevych, Z/G=Zesch and Gurevych similarity from"" to ""synonymous', 'This elaborate domain- quickly', 'we create word pairs using a cor-based approach']","['', '', 'is an concept assign is felt', '', '', '', '', '', 'In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im #TAUTHOR_TAG . Table 1: Comparison of previous experiments.', 'R/G=Rubenstein and Goodenough, M/C=Miller and Charles, Res=Resnik, Fin=Finkelstein, Gur=Gurevych, Z/G=Zesch and Gurevych similarity from similar"" to ""synonymous"".', 'This elaborate domain-specific quickly.', 'we create word pairs using a corpus-based approach.']","['', '', 'is an intuitive concept assign is felt', '', '', '', '', '', 'In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im #TAUTHOR_TAG . Table 1: Comparison of previous experiments.', 'R/G=Rubenstein and Goodenough, M/C=Miller and Charles, Res=Resnik, Fin=Finkelstein, Gur=Gurevych, Z/G=Zesch and Gurevych similarity from to ""synonymous', 'This elaborate process domain- quickly', 'we create word pairs using a corpus-based approach.']","['', '', '', '', '', '', '', '', 'In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im #TAUTHOR_TAG . Table 1: Comparison of previous experiments.', 'R/G=Rubenstein and Goodenough, M/C=Miller and Charles, Res=Resnik, Fin=Finkelstein, Gur=Gurevych, Z/G=Zesch and Gurevych similarity from ""not similar"" to ""synonymous"".', '', 'Therefore, we automatically create word pairs using a corpus-based approach.']",0
"['According to #TAUTHOR_TAG , there are three prevalent approaches for evaluating SR measures : mathematical analysis , applicationspecific evaluation and comparison with human judgments .']","['According to #TAUTHOR_TAG , there are three prevalent approaches for evaluating SR measures : mathematical analysis , applicationspecific evaluation and comparison with human judgments .']","['According to #TAUTHOR_TAG , there are three prevalent approaches for evaluating SR measures : mathematical analysis , applicationspecific evaluation and comparison with human judgments .']","['According to #TAUTHOR_TAG , there are three prevalent approaches for evaluating SR measures : mathematical analysis , applicationspecific evaluation and comparison with human judgments .']",0
"['ofaged humanments on the whole test set (see Figure 3)', 'ing-', 'even with the present setup, automatic extraction of concept pairs performs remarkably well and can be used to quickly create balanced test datasets.', ' #TAUTHOR_TAG pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .', 'This empty band is not observed here', ', Figure 4 shows the distribution of averaged judgments with the highest agreement between annotators (standard deviation < 0.8).', 'The plot clearly shows an empty horizontal band withments.', 'The connection between averagedments and standard deviationotted in Figure 5.']","['of averaged human judgments on the whole test set (see Figure 3)', 'weighting chain-', 'even with the present setup, automatic extraction of concept pairs performs remarkably well and can be used to quickly create balanced test datasets.', ' #TAUTHOR_TAG pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .', 'This empty band is not observed here.', 'However, Figure 4 shows the distribution of averaged judgments with the highest agreement between annotators (standard deviation < 0.8).', 'The plot clearly shows an empty horizontal band with judgments.', 'The connection between averaged judgments and standard deviation plotted in Figure 5.']","['ofaged human judgments on the whole test set (see Figure 3)', '', 'even with the present setup, automatic extraction of concept pairs performs remarkably well and can be used to quickly create balanced test datasets.', ' #TAUTHOR_TAG pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .', 'This empty band is not observed here', ', Figure 4 shows the distribution of averaged judgments with the highest agreement between annotators (standard deviation < 0.8).', 'The plot clearly shows an empty horizontal band with no judgments.', 'The connection between averagedments and standard deviation in Figure 5.']","['', '', 'However, even with the present setup, automatic extraction of concept pairs performs remarkably well and can be used to quickly create balanced test datasets.', ' #TAUTHOR_TAG pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .', 'This empty band is not observed here.', 'However, Figure 4 shows the distribution of averaged judgments with the highest agreement between annotators (standard deviation < 0.8).', 'The plot clearly shows an empty horizontal band with no judgments.', 'The connection between averaged judgments and standard deviation is plotted in Figure 5.']",1
"['requires a number of', '', 'relatedness is an intu concept and being forced to assign fine-grained values is felt to over', ' #AUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in #TAUTHOR_TAG .', 'larger word35', 'used a 0-0 of relatedness', '', '', '', 'we word pairsbased approach']","['requires a number of', '', 'relatedness is an intuitive concept and being forced to assign fine-grained values is felt to', ' #AUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German.', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in #TAUTHOR_TAG .', 'larger word', 'used a 0-10 of relatedness', '', '', '', 'we word pairs approach.']","['measures requires a higher number of', '', 'antic relatedness is an intuitive concept and being forced to assign fine-grained continuous values is felt to over', ' #AUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in #TAUTHOR_TAG .', 'word pairs35', 'They used a 0-10 range of related', '', '', '', 'we word pairs using']","['', '', 'Furthermore, semantic relatedness is an intuitive concept and being forced to assign fine-grained continuous values is felt to overstrain the test subjects.', ' #AUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German.', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['', '', '', 'This experiment was again replicated by #TAUTHOR_TAG with 10 subjects .', 'Table 1']","['', '', '', 'This experiment was again replicated by #TAUTHOR_TAG with 10 subjects .', 'Table 1']","['', '', '', 'This experiment was again replicated by #TAUTHOR_TAG with 10 subjects .', 'Table 1']","['', '', '', 'This experiment was again replicated by #TAUTHOR_TAG with 10 subjects .', 'Table 1']",0
"['We extracted word pairs from three different domain-specific corpora (see Table 2).', 'This is motivated by the aim to enable research in information retrieval incorporating SR measures.', ""In particular , the `` Semantic Information Retrieval '' project ( SIR #TAUTHOR_TAG systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems .""]","['We extracted word pairs from three different domain-specific corpora (see Table 2).', 'This is motivated by the aim to enable research in information retrieval incorporating SR measures.', ""In particular , the `` Semantic Information Retrieval '' project ( SIR #TAUTHOR_TAG systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems .""]","['We extracted word pairs from three different domain-specific corpora (see Table 2).', 'This is motivated by the aim to enable research in information retrieval incorporating SR measures.', ""In particular , the `` Semantic Information Retrieval '' project ( SIR #TAUTHOR_TAG systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems .""]","['We extracted word pairs from three different domain-specific corpora (see Table 2).', 'This is motivated by the aim to enable research in information retrieval incorporating SR measures.', ""In particular , the `` Semantic Information Retrieval '' project ( SIR #TAUTHOR_TAG systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems .""]",4
"['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #AUTHOR_TAG or distributional #TAUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #AUTHOR_TAG or distributional #TAUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #AUTHOR_TAG or distributional #TAUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #AUTHOR_TAG or distributional #TAUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']",0
"['', '', '', '', 'We used the were noun-noun, 15% noun-verb pairs and so on.', 'Word pairs containing polysemous words are expanded to concept pairs using GermaNet #TAUTHOR_TAG , the German equivalent to WordNet , as a sense inventory for each word .', 'It is the most complete resource of this type for German.']","['', '', '', '', 'We used the were noun-noun pairs, 15% noun-verb pairs and so on.', 'Word pairs containing polysemous words are expanded to concept pairs using GermaNet #TAUTHOR_TAG , the German equivalent to WordNet , as a sense inventory for each word .', 'It is the most complete resource of this type for German.']","['', '', '', '', 'We used were noun-noun pairs, 15% noun-verb pairs and so on.', 'Word pairs containing polysemous words are expanded to concept pairs using GermaNet #TAUTHOR_TAG , the German equivalent to WordNet , as a sense inventory for each word .', 'It is the most complete resource of this type for German.']","['', '', '', '', 'We used the following parameters: were noun-noun pairs, 15% noun-verb pairs and so on.', 'Word pairs containing polysemous words are expanded to concept pairs using GermaNet #TAUTHOR_TAG , the German equivalent to WordNet , as a sense inventory for each word .', 'It is the most complete resource of this type for German.']",5
"['Mathematical analysis can assess a measure with respect to some formal properties , e.g. whether a measure is a metric #TAUTHOR_TAG .4', 'However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application.']","['Mathematical analysis can assess a measure with respect to some formal properties , e.g. whether a measure is a metric #TAUTHOR_TAG .4', 'However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application.']","['Mathematical analysis can assess a measure with respect to some formal properties , e.g. whether a measure is a metric #TAUTHOR_TAG .4', 'However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application.']","['Mathematical analysis can assess a measure with respect to some formal properties , e.g. whether a measure is a metric #TAUTHOR_TAG .4', 'However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application.']",0
"['correlation summarsubject correlation of', ' #TAUTHOR_TAG reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .', 'The values may again not be compared directly.', ', we cannot generalize from these results the of participants which repeated too.']","['correlation summarized correlation of', ' #TAUTHOR_TAG reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .', 'The values may again not be compared directly.', 'Furthermore, we cannot generalize from these results, the of participants which repeated too low.']","['of', ' #TAUTHOR_TAG reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .', 'The values may again not be compared directly.', ', we cannot generalize from these results, the number of participants which repeated was too.']","['', ' #TAUTHOR_TAG reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .', 'The values may again not be compared directly.', 'Furthermore, we cannot generalize from these results, because the number of participants which repeated our experiment was too low.']",1
"['our we anated a high of pairs similar in size', 'We used the revised experimental setup #TAUTHOR_TAG , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .', '', '']","['our we annotated a high of pairs similar in size', 'We used the revised experimental setup #TAUTHOR_TAG , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .', '', '']","['our we annotated a high number of pairs similar in size', 'We used the revised experimental setup #TAUTHOR_TAG , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .', '', '']","['', 'We used the revised experimental setup #TAUTHOR_TAG , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .', '', '']",5
"['In our experiment , we annotated a high number of pairs similar in size to the test sets by #AUTHOR_TAG and #TAUTHOR_TAG .', 'We used the rev #AUTHOR_TAG word', '', '']","['In our experiment , we annotated a high number of pairs similar in size to the test sets by #AUTHOR_TAG and #TAUTHOR_TAG .', 'We used the revised #AUTHOR_TAG word', '', '']","['In our experiment , we annotated a high number of pairs similar in size to the test sets by #AUTHOR_TAG and #TAUTHOR_TAG .', 'We used #AUTHOR_TAG word pairs', '', '']","['In our experiment , we annotated a high number of pairs similar in size to the test sets by #AUTHOR_TAG and #TAUTHOR_TAG .', '', '', '']",1
"['Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based #AUTHOR_TAG , ontology-based #TAUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based #AUTHOR_TAG , ontology-based #TAUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based #AUTHOR_TAG , ontology-based #TAUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based #AUTHOR_TAG , ontology-based #TAUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']",0
"['Semanticity is typically defined via the lexical relations of synonymy (automobile -car) and hypernymy (vehicle -car), while semantic relatedness (SR) is defined to cover any kind ofxical or functional association that may exist be-tween two words3', 'Dissimilar words can be semantically related, e.g.', 'via functional relationships (night -dark) or when they are antonyms (high -low).', 'Many NLP applications require knowledge about semantic relatedness rather than just similarity #TAUTHOR_TAG .']","['Semantic similarity is typically defined via the lexical relations of synonymy (automobile -car) and hypernymy (vehicle -car), while semantic relatedness (SR) is defined to cover any kind of lexical or functional association that may exist be-tween two words 3', 'Dissimilar words can be semantically related, e.g.', 'via functional relationships (night -dark) or when they are antonyms (high -low).', 'Many NLP applications require knowledge about semantic relatedness rather than just similarity #TAUTHOR_TAG .']","['Semantic similarity is typically defined via the lexical relations of synonymy (automobile -car) and hypernymy (vehicle -car), while semantic relatedness (SR) is defined to cover any kind ofxical or functional association that may exist be-tween two words3', 'Dissimilar words can be semantically related, e.g.', 'via functional relationships (night -dark) or when they are antonyms (high -low).', 'Many NLP applications require knowledge about semantic relatedness rather than just similarity #TAUTHOR_TAG .']","['Semantic similarity is typically defined via the lexical relations of synonymy (automobile -car) and hypernymy (vehicle -car), while semantic relatedness (SR) is defined to cover any kind of lexical or functional association that may exist be-tween two words #AUTHOR_TAG . 3', 'Dissimilar words can be semantically related, e.g.', 'via functional relationships (night -dark) or when they are antonyms (high -low).', 'Many NLP applications require knowledge about semantic relatedness rather than just similarity #TAUTHOR_TAG .']",0
"['In the seminal work by #TAUTHOR_TAG , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .', 'Test subjects were instructed to order the cards according to the ""similarity of meaning"" and then assign a continuous similarity value (0.0 -4.0) to each card.', 're the experiment with 8 a of 3', '', 'Table1']","['In the seminal work by #TAUTHOR_TAG , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .', 'Test subjects were instructed to order the cards according to the ""similarity of meaning"" and then assign a continuous similarity value (0.0 -4.0) to each card.', 'replicated the experiment with 38 a of 30', '', 'Table 1']","['In the seminal work by #TAUTHOR_TAG , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .', 'Test subjects were instructed to order the cards according to the ""similarity of meaning"" and then assign a continuous similarity value (0.0 -4.0) to each card.', 're the experiment with  a subset of 3', '', 'Table1']","['In the seminal work by #TAUTHOR_TAG , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .', 'Test subjects were instructed to order the cards according to the ""similarity of meaning"" and then assign a continuous similarity value (0.0 -4.0) to each card.', '', '', 'Table 1']",0
"['The latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation #TAUTHOR_TAG or malapropism detection #AUTHOR_TAG . application-specific of similarity measures are always used for some task.', 'as', 'certain measure may work well in application,', '']","['The latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation #TAUTHOR_TAG or malapropism detection #AUTHOR_TAG . application-specific of similarity measures are always used for some task.', 'as', 'certain measure may work well in application,', '']","['The latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation #TAUTHOR_TAG or malapropism detection #AUTHOR_TAG . application-specific evaluation of similar measures are always used for some task.', 'as', 'A certain measure may work well in one application,', '']","['The latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation #TAUTHOR_TAG or malapropism detection #AUTHOR_TAG . #AUTHOR_TAG argue for application-specific evaluation of similarity measures, because measures are always used for some task.', '', 'A certain measure may work well in one application, but not in another.', '']",0
"['The latter question is tackled by applicationspecific evaluation, where a measure is tested within the framework of a certain applicationg.', 'word sense disambiguaprop detection #AUTHOR_TAG', ' #TAUTHOR_TAG argue for application-specific evaluation of similarity measures , because measures are always used for some task .', 'that evaluating a measure as part of a usually complex application only indirectly assesses its quality.', 'measure may work in', '']","['The latter question is tackled by applicationspecific evaluation, where a measure is tested within the framework of a certain application, e.g.', 'word sense disambiguation malapropism detection #AUTHOR_TAG', ' #TAUTHOR_TAG argue for application-specific evaluation of similarity measures , because measures are always used for some task .', 'that evaluating a measure as part of a usually complex application only indirectly assesses its quality.', 'measure may work in', '']","['The latter question is tackled by applicationspecific evaluation, where a measure is tested within the framework of a certain application, e.g.', 'word sense disambiguationapropism detection #AUTHOR_TAG .', ' #TAUTHOR_TAG argue for application-specific evaluation of similarity measures , because measures are always used for some task .', 'that evaluating a measure as part of a usually complex application only indirectly assesses its quality.', 'may work well in', '']","['The latter question is tackled by applicationspecific evaluation, where a measure is tested within the framework of a certain application, e.g.', 'word sense disambiguation #AUTHOR_TAG or malapropism detection #AUTHOR_TAG .', ' #TAUTHOR_TAG argue for application-specific evaluation of similarity measures , because measures are always used for some task .', 'But they also note that evaluating a measure as part of a usually complex application only indirectly assesses its quality.', '', '']",0
"['The three preprocessing steps (tokenization, POS-tagging, lemmatization) are performed using TreeTagger #AUTHOR_TAG', ""The resulting list of POS-tagged lemmas is weighted using the SMART ` ltc ' 8 tf.idf-weighting scheme #TAUTHOR_TAG .""]","['The three preprocessing steps (tokenization, POS-tagging, lemmatization) are performed using TreeTagger #AUTHOR_TAG', ""The resulting list of POS-tagged lemmas is weighted using the SMART ` ltc ' 8 tf.idf-weighting scheme #TAUTHOR_TAG .""]","['The three preprocessing steps (tokenization, POS-tagging, lemmatization) are performed using TreeTagger #AUTHOR_TAG .', ""The resulting list of POS-tagged lemmas is weighted using the SMART ` ltc ' 8 tf.idf-weighting scheme #TAUTHOR_TAG .""]","['The three preprocessing steps (tokenization, POS-tagging, lemmatization) are performed using TreeTagger #AUTHOR_TAG .', ""The resulting list of POS-tagged lemmas is weighted using the SMART ` ltc ' 8 tf.idf-weighting scheme #TAUTHOR_TAG .""]",5
"['', 'of performance for', '', '', '- for their larger dataset.', ' #TAUTHOR_TAG reported a correlation of r = .69 .', 'Test subjects were trained students of computational linguistics, and word pairs were selected analytically.']","['', 'of performance for', '', '', 'for their larger dataset.', ' #TAUTHOR_TAG reported a correlation of r = .69 .', 'Test subjects were trained students of computational linguistics, and word pairs were selected analytically.']","['', 'of performance for', '', '', '- for their larger dataset.', ' #TAUTHOR_TAG reported a correlation of r = .69 .', 'Test subjects were trained students of computational linguistics, and word pairs were selected analytically.']","['', '', '', '', '', ' #TAUTHOR_TAG reported a correlation of r = .69 .', 'Test subjects were trained students of computational linguistics, and word pairs were selected analytically.']",1
"['GermaNet contains only a few conceptual glosses.', 'As they are required to enable test subjects to distinguish between senses , we use artificial glosses composed from synonyms and hypernyms as a surrogate , e.g. for brother : `` brother , male sibling vs. `` brother , comrade , friend #TAUTHOR_TAG .', 'We more than three.']","['GermaNet contains only a few conceptual glosses.', 'As they are required to enable test subjects to distinguish between senses , we use artificial glosses composed from synonyms and hypernyms as a surrogate , e.g. for brother : `` brother , male sibling vs. `` brother , comrade , friend #TAUTHOR_TAG .', 'We more than three senses.']","['GermaNet contains only a few conceptual glosses.', 'As they are required to enable test subjects to distinguish between senses , we use artificial glosses composed from synonyms and hypernyms as a surrogate , e.g. for brother : `` brother , male sibling vs. `` brother , comrade , friend #TAUTHOR_TAG .', 'We removed had more than three senses.']","['GermaNet contains only a few conceptual glosses.', 'As they are required to enable test subjects to distinguish between senses , we use artificial glosses composed from synonyms and hypernyms as a surrogate , e.g. for brother : `` brother , male sibling vs. `` brother , comrade , friend #TAUTHOR_TAG .', 'We removed words which had more than three senses.']",5
"['', 'x-semantic relations', ' #TAUTHOR_TAG pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity .']","['', 'lexical-semantic relations.', ' #TAUTHOR_TAG pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity .']","['', 'x-semantic relations.', ' #TAUTHOR_TAG pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity .']","['', '', ' #TAUTHOR_TAG pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity .']",0
"['of', '', 'is an intu concept being assignained values is felt', '', '', '', ' #TAUTHOR_TAG annotated a larger set of word pairs ( 353 ) , too .', 'They used a 0-10 range of relatedness scores, but did not give further details about their experimental setup.', 'associationSch Table', 'ubennik', '', 'we create word pairs a-based approach']","['of', '', 'is an intuitive concept being assign values is felt', '', '', '', ' #TAUTHOR_TAG annotated a larger set of word pairs ( 353 ) , too .', 'They used a 0-10 range of relatedness scores, but did not give further details about their experimental setup.', 'association Table', '', '', 'we create word pairs a corpus-based approach.']","['of', '', 'is an intuitive concept being forced assignained continuous values is felt', '', '', '', ' #TAUTHOR_TAG annotated a larger set of word pairs ( 353 ) , too .', 'They used a 0-10 range of relatedness scores, but did not give further details about their experimental setup.', 'association testsSch', 'uben', '', 'we create word pairs using a corpus-based approach.']","['', '', '', '', '', '', ' #TAUTHOR_TAG annotated a larger set of word pairs ( 353 ) , too .', 'They used a 0-10 range of relatedness scores, but did not give further details about their experimental setup.', '', '', '', 'Therefore, we automatically create word pairs using a corpus-based approach.']",0
"['The three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger #TAUTHOR_TAG .', ""The resulting list of POS-tagged lemmas is weighted using the SM 'ltc .""]","['The three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger #TAUTHOR_TAG .', ""The resulting list of POS-tagged lemmas is weighted using the SMART 'ltc' 8""]","['The three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger #TAUTHOR_TAG .', ""The resulting list of POS-tagged lemmas is weighted using the SMART 'ltc ""]","['The three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger #TAUTHOR_TAG .', ""The resulting list of POS-tagged lemmas is weighted using the SMART 'ltc' 8 tf.idf-weighting scheme #AUTHOR_TAG .""]",5
"['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #TAUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #TAUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #TAUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #TAUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']",0
"['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #TAUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #TAUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #TAUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #TAUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']",0
"['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #TAUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #TAUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #TAUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed, e.g.', 'dictionary-based #TAUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #AUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']",0
"['If differences in meaning between senses are very fine-grained , distinguishing between them is hard even for humans #TAUTHOR_TAG . 6', 'Pairs containing such words are not suitable for evaluation.', 'limit for the', '']","['If differences in meaning between senses are very fine-grained , distinguishing between them is hard even for humans #TAUTHOR_TAG . 6', 'Pairs containing such words are not suitable for evaluation.', 'limit for the', '']","['If differences in meaning between senses are very fine-grained , distinguishing between them is hard even for humans #TAUTHOR_TAG . 6', 'Pairs containing such words are not suitable for evaluation.', 'limit for', '']","['If differences in meaning between senses are very fine-grained , distinguishing between them is hard even for humans #TAUTHOR_TAG . 6', 'Pairs containing such words are not suitable for evaluation.', '', '']",0
"['', '', 'and therefore produce datasets can be used', '', 'Furthermore , manually selected word pairs are often biased towards highly related pairs #TAUTHOR_TAG , because human annotators tend to select only highly related pairs connected by relations they are aware of .', 'Automatic cor-based selection of word pairs is more, to a balanced dataset with connected by all kinds of lexical-semantic relations', '', '']","['', '', 'and therefore produce datasets can be used', '', 'Furthermore , manually selected word pairs are often biased towards highly related pairs #TAUTHOR_TAG , because human annotators tend to select only highly related pairs connected by relations they are aware of .', 'Automatic corpus-based selection of word pairs is more objective, to a balanced dataset with connected by all kinds of lexical-semantic relations.', '', '']","['', '', 'and therefore produce datasets can be used', '', 'Furthermore , manually selected word pairs are often biased towards highly related pairs #TAUTHOR_TAG , because human annotators tend to select only highly related pairs connected by relations they are aware of .', 'Automatic corpus-based selection of word pairs is more, to a balanced dataset with connected by all kinds of lexical-semantic relations.', '', '']","['', '', '', '', 'Furthermore , manually selected word pairs are often biased towards highly related pairs #TAUTHOR_TAG , because human annotators tend to select only highly related pairs connected by relations they are aware of .', 'Automatic corpus-based selection of word pairs is more objective, leading to a balanced dataset with pairs connected by all kinds of lexical-semantic relations.', '', '']",0
"['', 'upper bound of performance for applied', '', 'of semantic related.', ' #TAUTHOR_TAG did not report inter-subject correlation for their larger dataset .', '', '']","['', 'upper bound of performance for applied', '', 'of semantic relatedness.', ' #TAUTHOR_TAG did not report inter-subject correlation for their larger dataset .', '', '']","['', 'an upper bound of performance for applied', '', 'of semantic relatedness.', ' #TAUTHOR_TAG did not report inter-subject correlation for their larger dataset .', '', '']","['', '', '', '', ' #TAUTHOR_TAG did not report inter-subject correlation for their larger dataset .', '', '']",1
"['The summarized inter-subject correlation between 21 subjects was r=478 (cf. isically at p <05.', 'This correlation coefficient is an upper bound of performance for automatic SR measures applied on the same dataset.', 'reported a correlation of r=902610', ' #TAUTHOR_TAG reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness', '', '', '']","['The summarized inter-subject correlation between 21 subjects was r=.478 (cf. is statistically at p < .05.', 'This correlation coefficient is an upper bound of performance for automatic SR measures applied on the same dataset.', 'reported a correlation of r=.9026. 10', ' #TAUTHOR_TAG reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness', '', '', '']","['The summarized inter-subject correlation between 21 subjects was r=478 (cf. is statistically at p < .05.', 'This correlation coefficient is an upper bound of performance for automatic SR measures applied on the same dataset.', 'reported a correlation of r=9026. 10', ' #TAUTHOR_TAG reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness .', '', '', '']","['The summarized inter-subject correlation between 21 subjects was r=.478 (cf. is statistically significant at p < .05.', 'This correlation coefficient is an upper bound of performance for automatic SR measures applied on the same dataset.', ' #AUTHOR_TAG reported a correlation of r=.9026. 10', ' #TAUTHOR_TAG reported a correlation of r = .9026.10 The results are not directly comparable , because he only used noun-noun pairs , words instead of concepts , a much smaller dataset , and measured semantic similarity instead of semantic relatedness .', '', '', '']",1
"['a number of', '', 'semantic relatedness is an intuitive concept and being forced to assign fine-grained continuous values is felt to overain the subjects', ' #TAUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'setup to a number of word pairs (35', '', 'a 00 range ofness scores', 'Table', '', '', 'we create word pairs using a-based approach']","['a number of', '', 'semantic relatedness is an intuitive concept and being forced to assign fine-grained continuous values is felt to overstrain the subjects.', ' #TAUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'setup to a number of word pairs (350)', '', 'a 0-10 range of relatedness scores,', 'Table', '', '', 'we create word pairs using a corpus-based approach.']","['a higher number of', '', 'semantic relatedness is an intuitive concept and being forced to assign fine-grained continuous values is felt to overain the test subjects.', ' #TAUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', 'This setup to a higher number of word pairs (35', '', 'a 0-10 range ofness scores,', '', '', '', 'we create word pairs using a corpus-based approach.']","['', '', 'Furthermore, semantic relatedness is an intuitive concept and being forced to assign fine-grained continuous values is felt to overstrain the test subjects.', ' #TAUTHOR_TAG replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .', 'She used an adapted experimental setup where test subjects had to assign discrete values {0,1,2,3,4} and word pairs were presented in isolation.', '', '', '', '', '', '', 'Therefore, we automatically create word pairs using a corpus-based approach.']",0
"['expected', '', '', '', 'are highly a - may', 'to the corpusbased approach, many domain-specific concept pairs are introduced into the test set.', 'Therefore inter-subject correlation is lower than the results obtained by #TAUTHOR_TAG .']","['expected', '', '', '', 'are highly a may', 'to the corpusbased approach, many domain-specific concept pairs are introduced into the test set.', 'Therefore inter-subject correlation is lower than the results obtained by #TAUTHOR_TAG .']","['are expected', '', '', '', 'are highly may', 'to the corpusbased approach, many domain-specific concept pairs are introduced into the test set.', 'Therefore inter-subject correlation is lower than the results obtained by #TAUTHOR_TAG .']","['', '', '', '', '', 'Due to the corpusbased approach, many domain-specific concept pairs are introduced into the test set.', 'Therefore , inter-subject correlation is lower than the results obtained by #TAUTHOR_TAG .']",1
"['Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #TAUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #TAUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #TAUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']","['Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based #AUTHOR_TAG , ontology-based #AUTHOR_TAG , information-based #TAUTHOR_TAG or distributional #AUTHOR_TAG .', 'The knowledge sources used for computing relatedness can be as different as dictionaries, ontologies or large corpora.']",0
"['', 'ly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by #TAUTHOR_TAG b ) and shingling techniques described by #AUTHOR_TAG .']","['', 'Secondly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by #TAUTHOR_TAG b ) and shingling techniques described by #AUTHOR_TAG .']","['', 'ly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by #TAUTHOR_TAG b ) and shingling techniques described by #AUTHOR_TAG .']","['', 'Secondly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by #TAUTHOR_TAG b ) and shingling techniques described by #AUTHOR_TAG .']",3
"['majority of previous cor annotation utilised', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a ) and the Linguist 's Search Engine #TAUTHOR_TAG .""]","['majority of previous corpus annotation utilised', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a ) and the Linguist 's Search Engine #TAUTHOR_TAG .""]","['of previous work corpus annotation has utilised either', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a ) and the Linguist 's Search Engine #TAUTHOR_TAG .""]","['', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a ) and the Linguist 's Search Engine #TAUTHOR_TAG .""]",0
"['In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible #AUTHOR_TAG : 56 ) unless the web is used as a corpus #TAUTHOR_TAG .', 'corpus areapping the Web toarse data problem #AUTHOR_TAG', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 24), University of Bologna (January 25 University of (July) and now inrent in April ', '', '', '']","['In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible #AUTHOR_TAG : 56 ) unless the web is used as a corpus #TAUTHOR_TAG .', 'corpus are tapping the Web to sparse data problem #AUTHOR_TAG', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of (July and now in in April', '', '', '']","['In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible #AUTHOR_TAG : 56 ) unless the web is used as a corpus #TAUTHOR_TAG .', ', corpus researchers are tapping the Web to the sparse data problem #AUTHOR_TAG .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of (J and now inrent in', '', '', '']","['In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible #AUTHOR_TAG : 56 ) unless the web is used as a corpus #TAUTHOR_TAG .', 'Increasingly, corpus researchers are tapping the Web to overcome the sparse data problem #AUTHOR_TAG .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', '', '', '']",0
"['In the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience #TAUTHOR_TAG .', 'While an approach promises much in of infrastructure, we wish to exploit computing that more to lingu a P2', '', '', 'andhome']","['In the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience #TAUTHOR_TAG .', 'While an approach promises much in of infrastructure, we wish to exploit computing that more to linguists a P2P', '', '', 'and']","['In the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience #TAUTHOR_TAG .', 'While such an approach promises much in of emerging infrastructure, we wish to exploit existing computing that is more to lingu a P2P approach.', '', '', 'andhome']","['In the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience #TAUTHOR_TAG .', 'While such an approach promises much in terms of emerging infrastructure, we wish to exploit existing computing infrastructure that is more accessible to linguists via a P2P approach.', '', '', '']",0
"['majority of previous cor annotation utilised', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a ) and the Linguist 's Search Engine #TAUTHOR_TAG .""]","['majority of previous corpus annotation utilised', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a ) and the Linguist 's Search Engine #TAUTHOR_TAG .""]","['of previous work corpus annotation has utilised either', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a ) and the Linguist 's Search Engine #TAUTHOR_TAG .""]","['', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a ) and the Linguist 's Search Engine #TAUTHOR_TAG .""]",0
"['majority of previous cor annotation utilised', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #TAUTHOR_TAG a ) and the Linguist 's Search Engine #AUTHOR_TAG .""]","['majority of previous corpus annotation utilised', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #TAUTHOR_TAG a ) and the Linguist 's Search Engine #AUTHOR_TAG .""]","['of previous work corpus annotation has utilised either', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #TAUTHOR_TAG a ) and the Linguist 's Search Engine #AUTHOR_TAG .""]","['', '', '', '', '', '', '', '', '', '', '', '', ""Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp #AUTHOR_TAG , KWiCFinder #TAUTHOR_TAG a ) and the Linguist 's Search Engine #AUTHOR_TAG .""]",0
"['majority of previous cor annotation util', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG , 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['majority of previous corpus annotation utilised', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG , 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['of previous work corpus annotation', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG , 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG , 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']",0
"['A key concern in corpus linguistics and related disciplines is verifiability and replicability of the results of studies.', 'Word frequency counts in internet search engines are inconsistent and unreliable #TAUTHOR_TAG .', 'Tools based on static corpora not suffer from.g.', 'BNCweb 7 , developed at the University ofich, and View 8 (Variation in English W and Phrases, developed at Brigham University) are both based on the Britishpus', '', '', '']","['A key concern in corpus linguistics and related disciplines is verifiability and replicability of the results of studies.', 'Word frequency counts in internet search engines are inconsistent and unreliable #TAUTHOR_TAG .', 'Tools based on static corpora not suffer from e.g.', 'BNCweb 7 , developed at the University of Zurich, and View 8 (Variation in English Words and Phrases, developed at Brigham University) are both based on the British', '', '', '']","['A key concern in corpus linguistics and related disciplines is verifiability and replicability of the results of studies.', 'Word frequency counts in internet search engines are inconsistent and unreliable #TAUTHOR_TAG .', 'Tools based on static corpora do not suffer from', 'BNCweb 7 , developed at the University ofich, and View 8 (Variation in English Words and Phrases, developed at Brigham Young University) are both based on the British National Corpus.', '', '', '']","['A key concern in corpus linguistics and related disciplines is verifiability and replicability of the results of studies.', 'Word frequency counts in internet search engines are inconsistent and unreliable #TAUTHOR_TAG .', 'Tools based on static corpora do not suffer from this problem, e.g.', 'BNCweb 7 , developed at the University of Zurich, and View 8 (Variation in English Words and Phrases, developed at Brigham Young University) are both based on the British National Corpus.', '', '', '']",0
"['majority of previous cor annotation util', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['majority of previous corpus annotation utilised', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['of previous work corpus annotation', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']",0
"['', '', 'generated at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 206', 'In addition , the advantages of using linguistically annotated data over raw data are well documented #TAUTHOR_TAG .', '', 'imp']","['', '', 'generated at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented #TAUTHOR_TAG .', '', '']","['', '', 'generated at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented #TAUTHOR_TAG .', '', 'imp']","['', '', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented #TAUTHOR_TAG .', '', '']",0
"['In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible #TAUTHOR_TAG : 56 ) unless the web is used as a corpus #AUTHOR_TAG .', '', 'oberuary', '', '', '']","['In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible #TAUTHOR_TAG : 56 ) unless the web is used as a corpus #AUTHOR_TAG .', '', '', '', '', '']","['In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible #TAUTHOR_TAG : 56 ) unless the web is used as a corpus #AUTHOR_TAG .', '', '', '', '', '']","['In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible #TAUTHOR_TAG : 56 ) unless the web is used as a corpus #AUTHOR_TAG .', '', '', '', '', '']",0
"['The of will involve im- plementing the framework within a P2P.', 'a of an object-oriented application environment to support P2P system development', 'We have designed this environment so that specific application functionality can be captured within plugins that can then integrate with the environment and utilise its functionality.', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding #TAUTHOR_TAG , distributed virtual worlds #AUTHOR_TAG and digital library management #AUTHOR_TAG .', 'It', '', '']","['The of will involve im- plementing the framework within a P2P environment.', 'a of an object-oriented application environment to support P2P system development', 'We have designed this environment so that specific application functionality can be captured within plugins that can then integrate with the environment and utilise its functionality.', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding #TAUTHOR_TAG , distributed virtual worlds #AUTHOR_TAG and digital library management #AUTHOR_TAG .', 'It', '', '']","['of will involve im- plementing the framework within a P2P environment.', 'a prototype of an object-oriented application environment to support P2P system development using', 'We have designed this environment so that specific application functionality can be captured within plugins that can then integrate with the environment and utilise its functionality.', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding #TAUTHOR_TAG , distributed virtual worlds #AUTHOR_TAG and digital library management #AUTHOR_TAG .', 'It is', '', '']","['The second stage of our work will involve im- plementing the framework within a P2P environment.', '', 'We have designed this environment so that specific application functionality can be captured within plugins that can then integrate with the environment and utilise its functionality.', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding #TAUTHOR_TAG , distributed virtual worlds #AUTHOR_TAG and digital library management #AUTHOR_TAG .', '', '', '']",0
"['Natural ProcessingLP) and computational linguistics, proposals have been made for using the computational Grid for data-intensiveLP and texting', 'we toit to lingu via a P2P approach.', 'In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet #TAUTHOR_TAG .', 'known applications, P2P has increasingly been applied in distributed computational systems.', 'Examples include SETI@home (looking for radio evidence ofrial),imatePrediction.netying climate change), Predictor@home (investigating protein-related diseases) and Einstein@home (searching for gravitational signals).']","['Natural Processing (NLP) and computational linguistics, proposals have been made for using the computational Grid for data-intensive NLP and text-mining', 'we to exploit to linguists via a P2P approach.', 'In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet #TAUTHOR_TAG .', 'known applications, P2P has increasingly been applied in distributed computational systems.', 'Examples include SETI@home (looking for radio evidence of life), ClimatePrediction.net climate change), Predictor@home (investigating protein-related diseases) and Einstein@home (searching for gravitational signals).']","['Natural Language ProcessingLP) and computational linguistics, proposals have been made for using the computational Grid for data-intensive NLP and texting', 'we wish to to lingu via a P2P approach.', 'In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet #TAUTHOR_TAG .', 'knownant Messenger applications, P2P has increasingly been applied in distributed computational systems.', 'Examples include SETI@home (looking for radio evidence ofrial life), ClimatePrediction.netying climate change), Predictor@home (investigating protein-related diseases) and Einstein@home (searching for gravitational signals).']","['In the areas of Natural Language Processing (NLP) and computational linguistics, proposals have been made for using the computational Grid for data-intensive NLP and text-mining for e-Science #AUTHOR_TAG .', '', 'In simple terms , P2P is a technology that takes advantage of the resources and services available at the edge of the Internet #TAUTHOR_TAG .', 'Better known for file-sharing and Instant Messenger applications, P2P has increasingly been applied in distributed computational systems.', 'Examples include SETI@home (looking for radio evidence of extraterrestrial life), ClimatePrediction.net (studying climate change), Predictor@home (investigating protein-related diseases) and Einstein@home (searching for gravitational signals).']",0
"['', 'object- application environment to support P2P development', 'specific can be', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding #AUTHOR_TAG , distributed virtual worlds #AUTHOR_TAG and digital library management #TAUTHOR_TAG .', '', '', '']","['', 'object-oriented application environment to support P2P development', 'specific can be', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding #AUTHOR_TAG , distributed virtual worlds #AUTHOR_TAG and digital library management #TAUTHOR_TAG .', '', '', '']","['', 'an object-oriented application environment to support P2P system development using', 'can be captured', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding #AUTHOR_TAG , distributed virtual worlds #AUTHOR_TAG and digital library management #TAUTHOR_TAG .', '', '', '']","['', '', '', 'This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding #AUTHOR_TAG , distributed virtual worlds #AUTHOR_TAG and digital library management #TAUTHOR_TAG .', '', '', '']",0
"['majority of previous cor annotation util', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['majority of previous corpus annotation utilised', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['of previous work corpus annotation', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']",0
"['majority of previous on corpus annotation utilised', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #AUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #TAUTHOR_TAG .', 'have several different methods mine web', 'prob craw', '', '']","['majority of previous on corpus annotation utilised', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #AUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #TAUTHOR_TAG .', 'have several different methods mine web', 'probabilities', '', '']","['of previous work on corpus annotation has utilised either', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #AUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #TAUTHOR_TAG .', 'have used several different methods mine', '', '', '']","['', '', '', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #AUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #TAUTHOR_TAG .', 'Studies have used several different methods to mine web data.', '', '', '']",0
"['majority previous cor annotation util', '', '', '', '', '', '', '', '', '', 'prob web crawler', ' #TAUTHOR_TAG built a corpus by iteratively searching Google for a small set of seed terms .', 'Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: Webp #AUTHOR_TAG , KWiCF #AUTHOR_TAG a) and the Linguists Search Engine #AUTHOR_TAG .']","['majority previous corpus annotation utilised', '', '', '', '', '', '', '', '', '', 'probabilities web crawler.', ' #TAUTHOR_TAG built a corpus by iteratively searching Google for a small set of seed terms .', ""Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a) and the Linguist's Search Engine #AUTHOR_TAG .""]","['previous work corpus annotation', '', '', '', '', '', '', '', '', '', 'a web crawler.', ' #TAUTHOR_TAG built a corpus by iteratively searching Google for a small set of seed terms .', ""Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: WebCorp #AUTHOR_TAG , KWiCF #AUTHOR_TAG a) and the Linguist's Search Engine #AUTHOR_TAG .""]","['', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG built a corpus by iteratively searching Google for a small set of seed terms .', ""Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a) and the Linguist's Search Engine #AUTHOR_TAG .""]",0
"['A key aspect of our case study research will be to investigate extending corpus collection to new document types.', 'Most web-derived corpora have exploited raw text or HTML pages , so efforts have focussed on boilerplate removal and cleanup of these formats with tools like Hyppia-BTE , Tidy and Parcels3 #TAUTHOR_TAG .']","['A key aspect of our case study research will be to investigate extending corpus collection to new document types.', 'Most web-derived corpora have exploited raw text or HTML pages , so efforts have focussed on boilerplate removal and cleanup of these formats with tools like Hyppia-BTE , Tidy and Parcels3 #TAUTHOR_TAG .']","['A key aspect of our case study research will be to investigate extending corpus collection to new document types.', 'Most web-derived corpora have exploited raw text or HTML pages , so efforts have focussed on boilerplate removal and cleanup of these formats with tools like Hyppia-BTE , Tidy and Parcels3 #TAUTHOR_TAG .']","['A key aspect of our case study research will be to investigate extending corpus collection to new document types.', 'Most web-derived corpora have exploited raw text or HTML pages , so efforts have focussed on boilerplate removal and cleanup of these formats with tools like Hyppia-BTE , Tidy and Parcels3 #TAUTHOR_TAG .']",0
"['In corpus linguistics such megacorpora is beyond the scope of individual researchers, and they not easily accessible :6) unless the web is used as a corpus', 'Increasingly , corpus researchers are tapping the Web to overcome the sparse data problem #TAUTHOR_TAG .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 005) and now in Trento in April 006.', '', '', '']","['In corpus linguistics such megacorpora is beyond the scope of individual researchers, and they not easily accessible : 56) unless the web is used as a corpus', 'Increasingly , corpus researchers are tapping the Web to overcome the sparse data problem #TAUTHOR_TAG .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', '', '', '']","['In corpus linguistics building such megacorpora is beyond the scope of individual researchers, and they are not easily accessible :6) unless the web is used as a corpus', 'Increasingly , corpus researchers are tapping the Web to overcome the sparse data problem #TAUTHOR_TAG .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', '', '', '']","['In corpus linguistics building such megacorpora is beyond the scope of individual researchers, and they are not easily accessible #AUTHOR_TAG : 56) unless the web is used as a corpus #AUTHOR_TAG .', 'Increasingly , corpus researchers are tapping the Web to overcome the sparse data problem #TAUTHOR_TAG .', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', '', '', '']",0
"['', '', '', '', '', 'The Gsearch system #TAUTHOR_TAG also selects sentences by syntactic criteria from large on-line text collections .', 'Gsearch annotates corpora with a fast chart parser to obviate the need for corpora with pre-existing syntactic mark-up', '', '', '', '', '']","['', '', '', '', '', 'The Gsearch system #TAUTHOR_TAG also selects sentences by syntactic criteria from large on-line text collections .', 'Gsearch annotates corpora with a fast chart parser to obviate the need for corpora with pre-existing syntactic mark-up.', '', '', '', '', '']","['', '', '', '', '', 'The Gsearch system #TAUTHOR_TAG also selects sentences by syntactic criteria from large on-line text collections .', 'Gsearch annotates corpora with a fast chart parser to obviate the need for corpora with pre-existing syntactic mark-up.', '', '', '', '', '']","['', '', '', '', '', 'The Gsearch system #TAUTHOR_TAG also selects sentences by syntactic criteria from large on-line text collections .', 'Gsearch annotates corpora with a fast chart parser to obviate the need for corpora with pre-existing syntactic mark-up.', '', '', '', '', '']",0
"['Linguistic annotation of corpora contributes crucially to the study of language at several levels: morphology, syntax, semantics, and discourse.', 'Its significance is reflected both in the growing interest in annotation software for word sense tagging #TAUTHOR_TAG and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages .']","['Linguistic annotation of corpora contributes crucially to the study of language at several levels: morphology, syntax, semantics, and discourse.', 'Its significance is reflected both in the growing interest in annotation software for word sense tagging #TAUTHOR_TAG and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages .']","['Linguistic annotation of corpora contributes crucially to the study of language at several levels: morphology, syntax, semantics, and discourse.', 'Its significance is reflected both in the growing interest in annotation software for word sense tagging #TAUTHOR_TAG and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages .']","['Linguistic annotation of corpora contributes crucially to the study of language at several levels: morphology, syntax, semantics, and discourse.', 'Its significance is reflected both in the growing interest in annotation software for word sense tagging #TAUTHOR_TAG and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages .']",0
"['majority of previous on cor annotation utilised', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['majority of previous on corpus annotation utilised', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['of previous work on corpus annotation has utilised either', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'The use of the web as a corpus for teaching and research on language has been proposed a number of times #TAUTHOR_TAG 2004b ) and received a special issue of the journal Computational Linguistics #AUTHOR_TAG .', '', '', '', '']",0
"['majority of previous on corpus annotation utilised', '', '', '', '', '', '', '', '', 'several methods mine web data', ' #TAUTHOR_TAG extracts word co-occurrence probabilities from unlabelled text collected from a web crawler .', ' #AUTHOR_TAG iter for a small set terms.', 'Prototypes of Internet search engines for linguists, corpus linguists andxicographers have been proposed: and the']","['majority of previous on corpus annotation utilised', '', '', '', '', '', '', '', '', 'several methods mine web data.', ' #TAUTHOR_TAG extracts word co-occurrence probabilities from unlabelled text collected from a web crawler .', ' #AUTHOR_TAG iteratively for a small set terms.', 'Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: and the']","['of previous work on corpus annotation has utilised either', '', '', '', '', '', '', '', '', 'several different methods mine web data.', ' #TAUTHOR_TAG extracts word co-occurrence probabilities from unlabelled text collected from a web crawler .', ' #AUTHOR_TAG iter for a small set seed terms.', 'Prototypes of Internet search engines for linguists, corpus linguists andxicographers have been proposed and']","['', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG extracts word co-occurrence probabilities from unlabelled text collected from a web crawler .', '', ""Prototypes of Internet search engines for linguists, corpus linguists and lexicographers have been proposed: WebCorp #AUTHOR_TAG , KWiCFinder #AUTHOR_TAG a) and the Linguist's Search Engine #AUTHOR_TAG .""]",0
"['', '', '', 'Current practise given the dynamic nature of the web, this is not sufficiently robust.', 'Other solutions such as complete caching of the corpora are not typically adopted due to legal concerns over copyright and redistribution of web data , issues considered at length by #TAUTHOR_TAG a ) .', '']","['', '', '', 'Current practise given the dynamic nature of the web, this is not sufficiently robust.', 'Other solutions such as complete caching of the corpora are not typically adopted due to legal concerns over copyright and redistribution of web data , issues considered at length by #TAUTHOR_TAG a ) .', '']","['', '', '', 'Current practise given the dynamic nature of the web, this is not sufficiently robust.', 'Other solutions such as complete caching of the corpora are not typically adopted due to legal concerns over copyright and redistribution of web data , issues considered at length by #TAUTHOR_TAG a ) .', '']","['', '', '', 'Current practise elsewhere includes the distribution of URL lists, but given the dynamic nature of the web, this is not sufficiently robust.', 'Other solutions such as complete caching of the corpora are not typically adopted due to legal concerns over copyright and redistribution of web data , issues considered at length by #TAUTHOR_TAG a ) .', '']",0
"['', '', 'generated at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 206', 'In addition , the advantages of using linguistically annotated data over raw data are well documented #TAUTHOR_TAG .', '', 'imp']","['', '', 'generated at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented #TAUTHOR_TAG .', '', '']","['', '', 'generated at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented #TAUTHOR_TAG .', '', 'imp']","['', '', 'This topic generated intense interest at workshops held at the University of Heidelberg (October 2004), University of Bologna (January 2005), University of Birmingham (July 2005) and now in Trento in April 2006.', 'In addition , the advantages of using linguistically annotated data over raw data are well documented #TAUTHOR_TAG .', '', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
"['has an important role we not want to force our users to a non-attribut.', 'We consider the Creative Commons model as the most suitable one to let each author choose the rights to reserve #TAUTHOR_TAG .', 'Narrativeings or essays are creative works and they generally treat ownership as authorship, even for the most enthusiastic fellows of free culture #AUTHOR_TAG .']","['has an important role we not want to force our users to a non-attributive work.', 'We consider the Creative Commons model as the most suitable one to let each author choose the rights to reserve #TAUTHOR_TAG .', 'Narrative writings or essays are creative works and they generally treat ownership as authorship, even for the most enthusiastic fellows of free culture #AUTHOR_TAG .']","['has an important role we do not want to force our users to a non-attributive copyright licence.', 'We consider the Creative Commons model as the most suitable one to let each author choose the rights to reserve #TAUTHOR_TAG .', 'Narrative writings or essays are creative works and they generally treat ownership as authorship, even for the most enthusiastic fellows of free culture #AUTHOR_TAG .']","['We believe that ownership has an important role and we do not want to force our users to take a non-attributive copyright licence to their work.', 'We consider the Creative Commons model as the most suitable one to let each author choose the rights to reserve #TAUTHOR_TAG .', 'Narrative writings or essays are creative works and they generally treat ownership as authorship, even for the most enthusiastic fellows of free culture #AUTHOR_TAG .']",5
"['Apart from wikis, blogs, and cognitive mapping, we were also inspired by the experiences of early hypertext writing tools, in particular Intermedia and Storyspace.', 'In fact, they were used expecially in academic writing with some success.', 'Intermedia is no more developed and nobody of us had the opportunity to try it #TAUTHOR_TAG .', 'Story', '', '', '', '']","['Apart from wikis, blogs, and cognitive mapping, we were also inspired by the experiences of early hypertext writing tools, in particular Intermedia and Storyspace.', 'In fact, they were used expecially in academic writing with some success.', 'Intermedia is no more developed and nobody of us had the opportunity to try it #TAUTHOR_TAG .', 'Storyspace', '', '', '', '']","['Apart from wikis, blogs, and cognitive mapping, we were also inspired by the experiences of early hypertext writing tools, in particular Intermedia and Storyspace.', 'In fact, they were used expecially in academic writing with some success.', 'Intermedia is no more developed and nobody of us had the opportunity to try it #TAUTHOR_TAG .', 'Story', '', '', '', '']","['Apart from wikis, blogs, and cognitive mapping, we were also inspired by the experiences of early hypertext writing tools, in particular Intermedia and Storyspace.', 'In fact, they were used expecially in academic writing with some success.', 'Intermedia is no more developed and nobody of us had the opportunity to try it #TAUTHOR_TAG .', '', '', '', '', '']",0
"[""Following the example of #TAUTHOR_TAG , we will call the autonomous units of a hypertext lexias ( from ` lexicon ' ) , a word coined by #AUTHOR_TAG ."", 'hyper lex', 'le navig', '']","[""Following the example of #TAUTHOR_TAG , we will call the autonomous units of a hypertext lexias ( from ` lexicon ' ) , a word coined by #AUTHOR_TAG ."", 'hypertext', '', '']","[""Following the example of #TAUTHOR_TAG , we will call the autonomous units of a hypertext lexias ( from ` lexicon ' ) , a word coined by #AUTHOR_TAG ."", 'lex', 'navig', '']","[""Following the example of #TAUTHOR_TAG , we will call the autonomous units of a hypertext lexias ( from ` lexicon ' ) , a word coined by #AUTHOR_TAG ."", '', '', '']",5
"['', ""'less"", '', '', '', 'use computers for writing has drammatically changed, expecially after their interconnection via the internet, since at least the foundation of the web (B-', ""For example , a ` web page ' is more similar to an infinite canvas than a written page #TAUTHOR_TAG ."", '', '', '', '', '', '', '', '']","['', 'meaningless', '', '', '', 'use computers for writing has drammatically changed, expecially after their interconnection via the internet, since at least the foundation of the web (Berners- #AUTHOR_TAG', ""For example , a ` web page ' is more similar to an infinite canvas than a written page #TAUTHOR_TAG ."", '', '', '', '', '', '', '', '']","['', '', '', '', '', 'computers for writing has drammatically changed, expecially after their interconnection via the internet, since at least the foundation of the web (B-', ""For example , a ` web page ' is more similar to an infinite canvas than a written page #TAUTHOR_TAG ."", '', '', '', '', '', '', '', '']","['', '', '', '', '', 'Nowadays the use of computers for writing has drammatically changed, expecially after their interconnection via the internet, since at least the foundation of the web (Berners- #AUTHOR_TAG .', ""For example , a ` web page ' is more similar to an infinite canvas than a written page #TAUTHOR_TAG ."", '', '', '', '', '', '', '', '']",0
"['want to', 'We consider Commons model to let author', 'Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture #TAUTHOR_TAG .']","['want to', 'We consider Commons model to let author', 'Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture #TAUTHOR_TAG .']","['want to', 'We consider the Creative Commons model to let each author', 'Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture #TAUTHOR_TAG .']","['', '', 'Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture #TAUTHOR_TAG .']",0
"['the of blogs asaries on the still the main interpretation', 'that andis are subjected to the', 'jour', '', 'the other side , wikis started as collective works where each entry is not owned by a single author e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG', '', '']","['the of blogs as diaries on the still the main interpretation', 'that and are subjected to the', '', '', 'the other side , wikis started as collective works where each entry is not owned by a single author e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG', '', '']","['the use of blogs as on is still the main current interpretation', 'that andis are currently subjected to', 'jour', '', 'the other side , wikis started as collective works where each entry is not owned by a single author e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '', '']","['', '', '', '', 'On the other side , wikis started as collective works where each entry is not owned by a single author e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '', '']",0
"['', '', '', '(see Figure 2).', 'Authors may choose this right with the No-Deriv option of the Creative Commons licences #TAUTHOR_TAG .', 'If nobody claims the for himself, it will fall in the public domain', 'le', '', '', '', '', '', '', '', '', '', '']","['', '', '', '(see Figure 2).', 'Authors may choose this right with the No-Deriv option of the Creative Commons licences #TAUTHOR_TAG .', 'If nobody claims the for himself, it will fall in the public domain.', '', '', '', '', '', '', '', '', '', '', '']","['', '', '', '(see Figure 2).', 'Authors may choose this right with the No-Deriv option of the Creative Commons licences #TAUTHOR_TAG .', 'If nobody claims the document for himself, it will fall in the public domain.', 'le', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'Authors may choose this right with the No-Deriv option of the Creative Commons licences #TAUTHOR_TAG .', 'If nobody claims the document for himself, it will fall in the public domain.', '', '', '', '', '', '', '', '', '', '', '']",0
"['The main source of Novelle are wikis and blogs.', 'While wikis have spread from a detailed design #TAUTHOR_TAG , unfortunately blogs have not been designed under a model .', 'So we have tested and compared the most used tools available for blogging']","['The main source of Novelle are wikis and blogs.', 'While wikis have spread from a detailed design #TAUTHOR_TAG , unfortunately blogs have not been designed under a model .', 'So we have tested and compared the most used tools available for blogging:']","['The main source of Novelle are wikis and blogs.', 'While wikis have spread from a detailed design #TAUTHOR_TAG , unfortunately blogs have not been designed under a model .', 'So we have tested and compared the most used tools available for blogging']","['The main source of Novelle are wikis and blogs.', 'While wikis have spread from a detailed design #TAUTHOR_TAG , unfortunately blogs have not been designed under a model .', 'So we have tested and compared the most used tools available for blogging: Bloggers, WordPress, MovableType and LiveJournal.']",0
"['our typ of, we aim to solve the framing problem as defined in Section 1.', 'want to model views of still', 'We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences #TAUTHOR_TAG .']","['our typology of links, we aim to solve the framing problem as defined in Section 1.2.', 'want to model views of still', 'We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences #TAUTHOR_TAG .']","['our typ of, we aim to solve the framing problem as defined in Section 1.2.', 'We want to model views of', 'We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences #TAUTHOR_TAG .']","['With our typology of links, we aim to solve the framing problem as defined in Section 1.2.', '', 'We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences #TAUTHOR_TAG .']",5
"['Generally speaking , we find that the personal public diary metaphor behind blogs #TAUTHOR_TAG may bring to an unsatisfactory representation of the context .', ""way to retrieve information is through a search engine a,e. the of the 'post -xia in the j of bloggers.""]","['Generally speaking , we find that the personal public diary metaphor behind blogs #TAUTHOR_TAG may bring to an unsatisfactory representation of the context .', ""way to retrieve information is through a search engine a calendar, i.e. the of the 'post' -a lexia in the of bloggers.""]","['Generally speaking , we find that the personal public diary metaphor behind blogs #TAUTHOR_TAG may bring to an unsatisfactory representation of the context .', ""to retrieve information is through a search engine a calendar, i.e. the date of the 'post' -a lexia in the jargon of bloggers.""]","['Generally speaking , we find that the personal public diary metaphor behind blogs #TAUTHOR_TAG may bring to an unsatisfactory representation of the context .', ""The only way to retrieve information is through a search engine or a calendar, i.e. the date of the 'post' -a lexia in the jargon of bloggers.""]",0
"['The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre #TAUTHOR_TAG .', 'Furthermore we noticed that blogs and wikis are currently subjected to osmosis, because they have in common the underlying core technology.', 'agen jour', '', '', '', '', '']","['The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre #TAUTHOR_TAG .', 'Furthermore we noticed that blogs and wikis are currently subjected to osmosis, because they have in common the underlying core technology.', '', '', '', '', '', '']","['The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre #TAUTHOR_TAG .', 'Furthermore we noticed that blogs and wikis are currently subjected to osmosis, because they have in common the underlying core technology.', 'jour', '', '', '', '', '']","['The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre #TAUTHOR_TAG .', 'Furthermore we noticed that blogs and wikis are currently subjected to osmosis, because they have in common the underlying core technology.', '', '', '', '', '', '']",0
"['', '� orfoot� simply become meaningless in the texts, or they highly change meaning', '', 'criticism -- unlike in the previous times #TAUTHOR_TAG .', 'computers for writing has drammatically expec after their interconnection via the internet', '', '', '', '', '', '', '']","['', 'or note� simply become meaningless in the texts, or they highly change meaning.', '', 'criticism -- unlike in the previous times #TAUTHOR_TAG .', 'computers for writing has drammatically expecially after their interconnection via the internet,', '', '', '', '', '', '', '']","['', 'orfoot simply become meaningless in the new texts, or they highly change meaning', '', '-- unlike in the previous times #TAUTHOR_TAG .', 'computers for writing has drammatically, expecially after their interconnection via the internet,', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '']",0
"['1 Hypertext as a New Writing Space #TAUTHOR_TAG was the first scholar who stressed the impact of the digital revolution to the medium of writing.', ""Terms as 'chapter 'page' or 'footnote' simply become meaningless in the new texts, or they highly change meaning"", '', '', '', '', '', '', '', '', '', '', '', '', '']","['Hypertext as a New Writing Space #TAUTHOR_TAG was the first scholar who stressed the impact of the digital revolution to the medium of writing.', ""Terms as 'chapter', 'page' or 'footnote' simply become meaningless in the new texts, or they highly change meaning."", '', '', '', '', '', '', '', '', '', '', '', '', '']","['1 Hypertext as a New Writing Space #TAUTHOR_TAG was the first scholar who stressed the impact of the digital revolution to the medium of writing.', ""Terms as 'chapter 'page' or 'footnote' simply become meaningless in the new texts, or they highly change meaning"", '', '', '', '', '', '', '', '', '', '', '', '', '']","['1.1 Hypertext as a New Writing Space #TAUTHOR_TAG was the first scholar who stressed the impact of the digital revolution to the medium of writing.', ""Terms as 'chapter', 'page' or 'footnote' simply become meaningless in the new texts, or they highly change their meaning."", '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['term refers group', 'AX a web development technique for creating interactive web applications a DOM ) , the XMLHTTPRequest object #TAUTHOR_TAG .']","['term refers group', 'a web development technique for creating interactive web applications a DOM ) , the XMLHTTPRequest object #TAUTHOR_TAG .']","['a term refers a group', 'a web development technique for creating interactive web applications using a combination DOM ) , the XMLHTTPRequest object #TAUTHOR_TAG .']","['', '']",0
"[""Concept mapping has been used at least in education for over thirty years, in particular at the Cornell University, where Piaget's ideas gave the roots to the assimilation theory by David Ausubel."", 'Very briefly, concept maps show the relationships between concepts labelling both nodes and arcs.', 'Every arc always has a definite direction , i.e. arcs are arrows #TAUTHOR_TAG .']","[""Concept mapping has been used at least in education for over thirty years, in particular at the Cornell University, where Piaget's ideas gave the roots to the assimilation theory by David Ausubel."", 'Very briefly, concept maps show the relationships between concepts labelling both nodes and arcs.', 'Every arc always has a definite direction , i.e. arcs are arrows #TAUTHOR_TAG .']","[""Concept mapping has been used at least in education for over thirty years, in particular at the Cornell University, where Piaget's ideas gave the roots to the assimilation theory by David Ausubel."", 'Very briefly, concept maps show the relationships between concepts labelling both nodes and arcs.', 'Every arc always has a definite direction , i.e. arcs are arrows #TAUTHOR_TAG .']","[""Concept mapping has been used at least in education for over thirty years, in particular at the Cornell University, where Piaget's ideas gave the roots to the assimilation theory by David Ausubel."", 'Very briefly, concept maps show the relationships between concepts labelling both nodes and arcs.', 'Every arc always has a definite direction , i.e. arcs are arrows #TAUTHOR_TAG .']",0
['The Ruby on #TAUTHOR_TAG framework permits us to quickly develop web applications without rewriting common functions and classes .'],['The Ruby on #TAUTHOR_TAG framework permits us to quickly develop web applications without rewriting common functions and classes .'],['The Ruby on #TAUTHOR_TAG framework permits us to quickly develop web applications without rewriting common functions and classes .'],['The Ruby on #TAUTHOR_TAG framework permits us to quickly develop web applications without rewriting common functions and classes .'],5
"['In wikis every track of to start a a to move move back onto the', ', a sandbox is a temporary view of a document itself i.e. a sandbox can not cause a change in the history #TAUTHOR_TAG .', 'Figure1 shows the model', 'History snapshots', '', 'Nov']","['In wikis every track of to start a a to move move back onto the', ', a sandbox is a temporary view of a document itself i.e. a sandbox can not cause a change in the history #TAUTHOR_TAG .', 'Figure 1 shows the model.', 'History snapshots', '', 'Novelle']","['In wikis every document track of to start a document to move back onto', ', a sandbox is a temporary view of a document itself i.e. a sandbox can not cause a change in the history #TAUTHOR_TAG .', 'Figure 1 shows the model.', 'History snapshots', '', 'Nov']","['', 'Moreover , a sandbox is a temporary view of a document itself i.e. a sandbox can not cause a change in the history #TAUTHOR_TAG .', 'Figure 1 shows the model.', '', '', '']",0
"['', ""'less"", '', '', '', '', '', '', 'open', 'a more pessimistic one, an author may feel to have lost power in this openness.', 'Henceforth the collaborative traits of blogs and wikis #TAUTHOR_TAG emphasize annotation , comment , and strong editing .', 'They give more power to readers, eventually filling the gap -the so-called active readers become authors as well.', 'This could', '', 'Nov']","['', 'meaningless', '', '', '', '', '', '', '(open', 'a more pessimistic one, an author may feel to have lost power in this openness.', 'Henceforth the collaborative traits of blogs and wikis #TAUTHOR_TAG emphasize annotation , comment , and strong editing .', 'They give more power to readers, eventually filling the gap -the so-called active readers become authors as well.', 'This could', '', '']","['', '', '', '', '', '', '', '', '', 'a more pessimistic one, an author may feel to have lost power in this openness.', 'Henceforth the collaborative traits of blogs and wikis #TAUTHOR_TAG emphasize annotation , comment , and strong editing .', 'They give more power to readers, eventually filling the gap -the so-called active readers become authors as well.', 'This situation could make', '', 'Nov']","['', '', '', '', '', '', '', '', '', 'From a more pessimistic one, an author may feel to have lost power in this openness.', 'Henceforth the collaborative traits of blogs and wikis #TAUTHOR_TAG emphasize annotation , comment , and strong editing .', 'They give more power to readers, eventually filling the gap -the so-called active readers become authors as well.', '', '', '']",0
"['inik no lexia is authored and is hierarchy lex', '', 'Gener people avoid prefer to edit each', 'The paradigm is ""write many , read many"" #TAUTHOR_TAG .']","['in no lexia is authored and is hierarchy lexias.', '', 'people avoid preferring to edit each', 'The paradigm is ""write many , read many"" #TAUTHOR_TAG .']","['inikis no lexia is authored and is no hierarchy lex', '', 'Gener, people avoid to edit', 'The paradigm is ""write many , read many"" #TAUTHOR_TAG .']","['On the contrary, in wikis no lexia is authored and there is no hierarchy between lexias.', '', '', 'The paradigm is ""write many , read many"" #TAUTHOR_TAG .']",0
"['We used the Asyncronous J AAX) paradigm to create the graphical user interface.', 'AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML #TAUTHOR_TAG .']","['We used the Asyncronous AJAX) paradigm to create the graphical user interface.', 'AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML #TAUTHOR_TAG .']","['We used the Asyncronous Javascriptor AJAX) paradigm to create the graphical user interface.', 'AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML #TAUTHOR_TAG .']","['We used the Asyncronous Javascript And XML (or AJAX) paradigm to create the graphical user interface.', 'AJAX function lets the communication works asyncronously between a client and a server through a set of messages based on HTTP protocol and XML #TAUTHOR_TAG .']",0
"['A is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #AUTHOR_TAG and Portuguese #TAUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 7 % and 41 % , respectively , and root recall is affected negatively', '', '', '']","['A is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #AUTHOR_TAG and Portuguese #TAUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is affected negatively', '', '', '']","['is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #AUTHOR_TAG and Portuguese #TAUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .', '', '', '']","['A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #AUTHOR_TAG and Portuguese #TAUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .', '', '', '']",1
"['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', 'Graph transformations for recovering nonprojective structures #TAUTHOR_TAG .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', 'Graph transformations for recovering nonprojective structures #TAUTHOR_TAG .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '¢ Graph transformations for recovering nonprojective structures #TAUTHOR_TAG .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', 'â\x80¢ Graph transformations for recovering nonprojective structures #TAUTHOR_TAG .']",5
"['A observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #TAUTHOR_TAG and Portuguese #AUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively', 'accur', '', '']","['A observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #TAUTHOR_TAG and Portuguese #AUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively', '', '', '']","['A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #TAUTHOR_TAG and Portuguese #AUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .', 'accur', '', '']","['A second observation is that a high proportion of non-projective structures leads to fragmentation in the parser output, reflected in lower precision for roots.', 'This is noticeable for German #TAUTHOR_TAG and Portuguese #AUTHOR_TAG , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B Â¨ ohmov Â´ a et al. , 2003 ) , Dutch ( van der #AUTHOR_TAG and Slovene ( DË\x87zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .', '', '', '']",1
['The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by #AUTHOR_TAG and extended to labeled dependency parsing by #TAUTHOR_TAG .'],['The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by #AUTHOR_TAG and extended to labeled dependency parsing by #TAUTHOR_TAG .'],['The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by #AUTHOR_TAG and extended to labeled dependency parsing by #TAUTHOR_TAG .'],['The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by #AUTHOR_TAG and extended to labeled dependency parsing by #TAUTHOR_TAG .'],5
"['specific of feature and learning algorithm parameters can be onalt', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #TAUTHOR_TAG .', 'Japanese #AUTHOR_TAG attachment score drops from 98%']","['specifications of feature and learning algorithm parameters can be on', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #TAUTHOR_TAG .', 'Japanese #AUTHOR_TAG attachment score drops from 98%']","['of and learning algorithm parameters can be found on', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #TAUTHOR_TAG .', 'Japanese #AUTHOR_TAG that attachment score drops from 98%']","['', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #TAUTHOR_TAG .', '']",0
"['of learning algorithm parameters can bealt', '', '.', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of learning algorithm parameters can be', '', '', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of learning algorithm parameters can be found', '', '.', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['', '', '', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']",0
"['general observations specific of the feature models and learning algorithm parameters can be onalt', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #TAUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['general observations specifications of the feature models and learning algorithm parameters can be on', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #TAUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of the feature models and learning algorithm parameters can be found on', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #TAUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['', '', '', 'Typical examples are Bulgarian #AUTHOR_TAG , Chinese #TAUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']",0
"['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', 'â\x80¢ History-based feature models for predicting the next parser action #TAUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '• Graph transformproject structures']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', 'â\x80¢ History-based feature models for predicting the next parser action #TAUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '• Graph transformations structures']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', 'â\x80¢ History-based feature models for predicting the next parser action #TAUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '• Graph transformations']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', 'â\x80¢ History-based feature models for predicting the next parser action #TAUTHOR_TAG .', '• Support vector machines for mapping histories to parser actions #AUTHOR_TAG .', '']",5
"['All experiments have been performed using MaltParser #TAUTHOR_TAG , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1']","['All experiments have been performed using MaltParser #TAUTHOR_TAG , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1']","['All experiments have been performed using MaltParser #TAUTHOR_TAG , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1']","['All experiments have been performed using MaltParser #TAUTHOR_TAG , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1']",5
"['We use support vector machines to predict the next parser action from a feature vector representing the history.', 'More specifically , we use LIBSVM #TAUTHOR_TAG with a quadratic kernel K ( xZ , xj ) = ( - yxT xj + r ) 2 and the built-in one-versus-all strategy for multi-class classification .', '', '', '']","['We use support vector machines to predict the next parser action from a feature vector representing the history.', 'More specifically , we use LIBSVM #TAUTHOR_TAG with a quadratic kernel K ( xZ , xj ) = ( - yxT xj + r ) 2 and the built-in one-versus-all strategy for multi-class classification .', '', '', '']","['We use support vector machines to predict the next parser action from a feature vector representing the history.', 'More specifically , we use LIBSVM #TAUTHOR_TAG with a quadratic kernel K ( xZ , xj ) = ( - yxT xj + r ) 2 and the built-in one-versus-all strategy for multi-class classification .', '', '', '']","['We use support vector machines to predict the next parser action from a feature vector representing the history.', 'More specifically , we use LIBSVM #TAUTHOR_TAG with a quadratic kernel K ( xZ , xj ) = ( - yxT xj + r ) 2 and the built-in one-versus-all strategy for multi-class classification .', '', '', '']",5
['6The analysis is reminiscent of the treatment of coordination in the Collins parser #TAUTHOR_TAG .'],['6The analysis is reminiscent of the treatment of coordination in the Collins parser #TAUTHOR_TAG .'],['6The analysis is reminiscent of the treatment of coordination in the Collins parser #TAUTHOR_TAG .'],['6The analysis is reminiscent of the treatment of coordination in the Collins parser #TAUTHOR_TAG .'],1
"['Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of #TAUTHOR_TAG .']","['Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of #TAUTHOR_TAG .']","['Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of #TAUTHOR_TAG .']","['Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of #TAUTHOR_TAG .']",0
"['For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy #TAUTHOR_TAG .', '']","['For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy #TAUTHOR_TAG .', '']","['For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy #TAUTHOR_TAG .', '']","['For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy #TAUTHOR_TAG .', '']",0
"['of learning algorithm parameters can bealt', '', '.', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of learning algorithm parameters can be', '', '', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['of learning algorithm parameters can be found', '', '.', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']","['', '', '', 'Typical examples are Bulgarian #TAUTHOR_TAG , Chinese #AUTHOR_TAG , Danish #AUTHOR_TAG , and Swedish #AUTHOR_TAG .', '']",0
"['', '', '', 'Dan Swedish', 'Japanese #TAUTHOR_TAG , despite a very high accuracy , is different in that attachment score drops from 98 % to 85 % , as we go from length 1 to 2 , which may have something to do with the data consisting of transcribed speech with very short utterances .']","['', '', '', 'Danish Swedish', 'Japanese #TAUTHOR_TAG , despite a very high accuracy , is different in that attachment score drops from 98 % to 85 % , as we go from length 1 to 2 , which may have something to do with the data consisting of transcribed speech with very short utterances .']","['', '', '', 'Dan Swedish .', 'Japanese #TAUTHOR_TAG , despite a very high accuracy , is different in that attachment score drops from 98 % to 85 % , as we go from length 1 to 2 , which may have something to do with the data consisting of transcribed speech with very short utterances .']","['', '', '', '', 'Japanese #TAUTHOR_TAG , despite a very high accuracy , is different in that attachment score drops from 98 % to 85 % , as we go from length 1 to 2 , which may have something to do with the data consisting of transcribed speech with very short utterances .']",1
"['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', 'Support vector machines for mapping histories to parser actions #TAUTHOR_TAG .', '• Graph transformations foring nonprojective structures .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', 'Support vector machines for mapping histories to parser actions #TAUTHOR_TAG .', '• Graph transformations for recovering nonprojective structures .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', 'Support vector machines for mapping histories to parser actions #TAUTHOR_TAG .', '• Graph transformations foring nonprojective structures .']","['• A deterministic algorithm for building labeled projective dependency graphs #AUTHOR_TAG .', '• History-based feature models for predicting the next parser action #AUTHOR_TAG .', 'Support vector machines for mapping histories to parser actions #TAUTHOR_TAG .', '• Graph transformations for recovering nonprojective structures .']",5
"['results are characterized low accuracy as well as a de of score with arc lengthfrom3 to6', 'By contrast , Turkish #TAUTHOR_TAG exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) .', 'It Turkishtyp']","['results are characterized low accuracy as well as a of score with arc length (from to', 'By contrast , Turkish #TAUTHOR_TAG exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) .', 'It Turkish,']","['The results are characterized low root accuracy as well as of attachment score with arc lengthfrom3 to6', 'By contrast , Turkish #TAUTHOR_TAG exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) .', 'It is Turkishtyp']","['', 'By contrast , Turkish #TAUTHOR_TAG exhibits high root accuracy but consistently low attachment scores ( about 88 % for length 1 and 68 % for length 2 ) .', '']",1
"['', '', '', '', '', '', '', '', '', '', '', 'the availabilityRep a studying the of semantics in various tasks', ' #TAUTHOR_TAG have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability SemRep a studying the of semantics in various tasks.', ' #TAUTHOR_TAG have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availabilityRep studying the role of semantics in various tasks.', ' #TAUTHOR_TAG have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .', '', '', '']",0
"['', '', '', '', 'For example #TAUTHOR_TAG experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4 % improvement in F-score .', 'found a correlation between the quality and strength of conclusions in the full article texts and abstracts.', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'For example #TAUTHOR_TAG experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4 % improvement in F-score .', 'found a correlation between the quality and strength of conclusions in the full article texts and abstracts.', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'For example #TAUTHOR_TAG experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4 % improvement in F-score .', 'found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts.', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', 'For example , #TAUTHOR_TAG experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4 % improvement in F-score .', 'found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts.', '', '', '', '', '', '', '', '', '', '']",0
"['to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vec- tors that maximizes the separation of the Gaussians (corresponding to the HMM states).', ' #TAUTHOR_TAG describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .', 'sentenceMM']","['to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vec- tors that maximizes the separation of the Gaussians (corresponding to the HMM states).', ' #TAUTHOR_TAG describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .', 'HMM']","['to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vec- tors that maximizes the separation of the Gaussians (corresponding to the HMM states).', ' #TAUTHOR_TAG describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .', '']","['In an attempt to further boost performance, we employed Linear Discriminant Analysis (LDA) to find a linear projection of the four-dimensional vec- tors that maximizes the separation of the Gaussians (corresponding to the HMM states).', ' #TAUTHOR_TAG describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .', '']",5
"['information', 'are already appropriately labeled', '', '', 'Such a component would serve as the first stage of a clinical question answering system #TAUTHOR_TAG or summarization system ( Mc #AUTHOR_TAG', 'We chose to controlled bench which all other clinical are measured.']","['information', 'are, already appropriately labeled.', '', '', 'Such a component would serve as the first stage of a clinical question answering system #TAUTHOR_TAG or summarization system ( Mc #AUTHOR_TAG', 'We chose to controlled benchmark which all other clinical are measured.']","['information', 'are already appropriately labeled', '', '', 'Such a component would serve as the first stage of a clinical question answering system #TAUTHOR_TAG or summarization system ( Mc #AUTHOR_TAG .', 'We chose to controlled which all other clinical studies are measured.']","['', '', '', '', 'Such a component would serve as the first stage of a clinical question answering system #TAUTHOR_TAG or summarization system ( Mc #AUTHOR_TAG .', '']",3
"['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']",0
"[' #AUTHOR_TAG and #TAUTHOR_TAG , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .', 'The four states in our H correspond to the information that characterizes each (""introduction"", """",results """")']","[' #AUTHOR_TAG and #TAUTHOR_TAG , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .', 'The four states in our correspond to the information that characterizes each (""introduction"", ""methods"",']","[' #AUTHOR_TAG and #TAUTHOR_TAG , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .', 'The four states in our Hs correspond to the information that characterizes each section (""introduction"", """", ""results"", """")']","[' #AUTHOR_TAG and #TAUTHOR_TAG , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .', '']",5
"['predict', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #TAUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['predictable', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #TAUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #TAUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #TAUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['', 'The transition probability matrix of theMM was initialized with uniform probabilities graph', '', 'Using the section labels , the HMM was trained using the HTK toolkit #TAUTHOR_TAG , which efficiently performs the forward-backward algorithm and BaumWelch estimation .', 'HTK']","['', 'The transition probability matrix of the HMM was initialized with uniform probabilities graph.', '', 'Using the section labels , the HMM was trained using the HTK toolkit #TAUTHOR_TAG , which efficiently performs the forward-backward algorithm and BaumWelch estimation .', 'HTK']","['', 'The transition probability matrix of the HMM was initialized with uniform probabilities graph', '', 'Using the section labels , the HMM was trained using the HTK toolkit #TAUTHOR_TAG , which efficiently performs the forward-backward algorithm and BaumWelch estimation .', '']","['', 'The transition probability matrix of the HMM was initialized with uniform probabilities over a fully connected graph.', '', 'Using the section labels , the HMM was trained using the HTK toolkit #TAUTHOR_TAG , which efficiently performs the forward-backward algorithm and BaumWelch estimation .', '']",5
"['Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.', 'As an, scientific abstracts across many different fields generally follow the pattern of ""introduction"" , ""methods"" , ""results"" , and ""conclusions"" #TAUTHOR_TAG ; OrË\x98asan , 2001 ) .', 'The ability to explicitly identify these sections in un-structured text could play an important role in such as document summarization information retrieval information extr', '', '', '']","['Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"" , ""methods"" , ""results"" , and ""conclusions"" #TAUTHOR_TAG ; OrË\x98asan , 2001 ) .', 'The ability to explicitly identify these sections in un-structured text could play an important role in such as document summarization information retrieval information extraction', '', '', '']","['Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"" , ""methods"" , ""results"" , and ""conclusions"" #TAUTHOR_TAG ; OrË\x98asan , 2001 ) .', 'The ability to explicitly identify these sections in un-structured text could play an important role in such as document summarization information retrieval information extraction', '', '', '']","['Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"" , ""methods"" , ""results"" , and ""conclusions"" #TAUTHOR_TAG ; OrË\x98asan , 2001 ) .', 'The ability to explicitly identify these sections in un-structured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering.', '', '', '']",0
"['An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors ( log probabilities of observing entire sentences based on our language models ) , as opposed to sequences of terms , as done in #TAUTHOR_TAG .', 'This technique provides two important advantages.', 'during trainingorder', '', '']","['An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors ( log probabilities of observing entire sentences based on our language models ) , as opposed to sequences of terms , as done in #TAUTHOR_TAG .', 'This technique provides two important advantages.', 'during training,', '', '']","['An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors ( log probabilities of observing entire sentences based on our language models ) , as opposed to sequences of terms , as done in #TAUTHOR_TAG .', 'This technique provides two important advantages.', 'during training', '', '']","['An interesting aspect of our generative approach is that we model HMM outputs as Gaussian vectors ( log probabilities of observing entire sentences based on our language models ) , as opposed to sequences of terms , as done in #TAUTHOR_TAG .', 'This technique provides two important advantages.', '', '', '']",1
"['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']","['Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , #TAUTHOR_TAG .', 'However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.', '', '', '', '', '']",0
"['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #TAUTHOR_TAG for concept identification and SemRep #AUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #TAUTHOR_TAG for concept identification and SemRep #AUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #TAUTHOR_TAG for concept identification and SemRep #AUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'Furthermore , the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #TAUTHOR_TAG for concept identification and SemRep #AUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks .', '', '', '', '']",0
"['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG , attribut']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG , attribution']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG ,']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', '']",1
"['', '', '', '', '', '', '', 'variety reasons medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev a', 'needsLINE', '', '', '', '', '']","['', '', '', '', '', '', '', 'variety reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retrieval a', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'a variety reasons, medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'For a variety of reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', '', '', '', '', '', '', '']",0
"['Although this study the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (', 'Our task is closer to the work of #TAUTHOR_TAG , who looked at the problem of intellectual attribution in scientific texts .']","['Although this study the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements', 'Our task is closer to the work of #TAUTHOR_TAG , who looked at the problem of intellectual attribution in scientific texts .']","['Although this study the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (', 'Our task is closer to the work of #TAUTHOR_TAG , who looked at the problem of intellectual attribution in scientific texts .']","['Although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (Mc #AUTHOR_TAG .', 'Our task is closer to the work of #TAUTHOR_TAG , who looked at the problem of intellectual attribution in scientific texts .']",1
"['information', 'crossstructured abstracts are after all, already appropriately labeled', '', '', 'Such a component would serve as the first stage of a clinical question answering system ( Demner- #AUTHOR_TAG or summarization system #TAUTHOR_TAG .', 'We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured.']","['information', 'crossvalidation task-structured abstracts are, after all, already appropriately labeled.', '', '', 'Such a component would serve as the first stage of a clinical question answering system ( Demner- #AUTHOR_TAG or summarization system #TAUTHOR_TAG .', 'We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured.']","['information', 'cross are after all, already appropriately labeled', '', '', 'Such a component would serve as the first stage of a clinical question answering system ( Demner- #AUTHOR_TAG or summarization system #TAUTHOR_TAG .', 'We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured.']","['', '', '', '', 'Such a component would serve as the first stage of a clinical question answering system ( Demner- #AUTHOR_TAG or summarization system #TAUTHOR_TAG .', 'We chose to focus on randomized controlled trials because they represent the standard benchmark by which all other clinical studies are measured.']",3
['Table (b) again reproduces the results from #TAUTHOR_TAG (2003) for a comparable task on a different subset of 206 unstructured abstracts.'],['Table (b) again reproduces the results from #TAUTHOR_TAG (2003) for a comparable task on a different subset of 206 unstructured abstracts.'],['Table (b) again reproduces the results from #TAUTHOR_TAG (2003) for a comparable task on a different subset of 206 unstructured abstracts.'],['Table (b) again reproduces the results from #TAUTHOR_TAG (2003) for a comparable task on a different subset of 206 unstructured abstracts.'],1
"['predict', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #TAUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['predictable', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #TAUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #TAUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #AUTHOR_TAG , information extraction #TAUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', 'variety reasons medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev a', 'needsLINE', '', '', '', '', '']","['', '', '', '', '', '', '', 'variety reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retrieval a', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'a variety reasons, medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'For a variety of reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', '', '', '', '', '', '', '']",0
"['predict', ', scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #TAUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['predictable', 'example, scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #TAUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #TAUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', 'As an example, scientific abstracts across many different fields generally follow the pattern of ""introduction"", ""methods"", ""results"", and ""conclusions"" (Salanger- #AUTHOR_TAG Orȃsan, 2001).', 'The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization #AUTHOR_TAG , information retrieval #TAUTHOR_TAG , information extraction #AUTHOR_TAG , and question answering .', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['shown in Tables 2(a) and b). Table2(a) reports the classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance reduces error rate.', 'Table 2(b) reports accuracy, precision, recall, and F- measure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table).', 'The table also presents the closest comparable experimental results reported by #TAUTHOR_TAG .1 McK Sivas ( henceforth', '', '', '']","['shown in Tables 2(a) and 2(b). Table 2(a) reports the classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance, reduces error rate.', 'Table 2(b) reports accuracy, precision, recall, and F- measure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table).', 'The table also presents the closest comparable experimental results reported by #TAUTHOR_TAG .1 McKnight Srinivasan ( henceforth', '', '', '']","['are shown in Tables 2(a) and b). Table2(a) reports the multi-way classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance further reduces error rate.', 'Table 2(b) reports accuracy, precision, recall, and F- measure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table).', 'The table also presents the closest comparable experimental results reported by #TAUTHOR_TAG .1 McKnight Sivas ( henceforth', '', '', '']","['The results of our second set of experiments (with RCTs only) are shown in Tables 2(a) and 2(b). Table 2(a) reports the multi-way classification error rate; once again, applying the Markov assumption to model discourse transitions improves performance, and using LDA further reduces error rate.', 'Table 2(b) reports accuracy, precision, recall, and F- measure for four separate binary classifiers (HMM with LDA) specifically trained for each of the sections (one per row in the table).', '', '', '', '']",1
"['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG , attribut']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG , attribution']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', 'Our task of #AUTHOR_TAG ,']","['Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements #TAUTHOR_TAG .', '']",1
"['', '', '', '', '', '', '', '', '', '', '', '', '', 'the in the same domain , we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models ( HMMs ) ; cfXXX #TAUTHOR_TAG .', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'the in the same domain , we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models ( HMMs ) ; cfXXX #TAUTHOR_TAG .', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'the work in the same domain , we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models ( HMMs ) ; cfXXX #TAUTHOR_TAG .', '', '']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'Building on the work of #AUTHOR_TAG in the same domain , we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models ( HMMs ) ; cfXXX #TAUTHOR_TAG .', '', '']",0
"['', '', '', '', '', '', 'presents experiments generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', 'presents experiments generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', 'presents experiments generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', 'This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', 'variety reasons medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev a', 'needsLINE', '', '', '', '', '']","['', '', '', '', '', '', '', 'variety reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retrieval a', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'a variety reasons, medicine is an interesting domain of research', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', 'Retriev', 'needs', '', '', '', '', '']","['', '', '', '', '', '', '', 'For a variety of reasons, medicine is an interesting domain of research.', 'The need for information systems to support physicians at the point of care has been well studied #TAUTHOR_TAG .', '', '', '', '', '', '', '']",0
"['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #AUTHOR_TAG for concept identification and SemRep #TAUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #AUTHOR_TAG for concept identification and SemRep #TAUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #AUTHOR_TAG for concept identification and SemRep #TAUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'Furthermore , the availability of rich ontological resources , in the form of the Unified Medical Language System ( UMLS ) #AUTHOR_TAG , and the availability of software that leverages this knowledge -- MetaMap #AUTHOR_TAG for concept identification and SemRep #TAUTHOR_TAG for relation extraction -- provide a foundation for studying the role of semantics in various tasks .', '', '', '', '']",0
"['Although not the first to employ a generative approach to directly model content , the seminal work of #TAUTHOR_TAG is a noteworthy point of reference and comparison .', ', our study differs in several important respects.', '', '', 'and', '']","['Although not the first to employ a generative approach to directly model content , the seminal work of #TAUTHOR_TAG is a noteworthy point of reference and comparison .', 'However, our study differs in several important respects.', '', '', 'and', '']","['Although not the first to employ a generative approach to directly model content , the seminal work of #TAUTHOR_TAG is a noteworthy point of reference and comparison .', ', our study differs in several important respects.', '', '', 'and', '']","['Although not the first to employ a generative approach to directly model content , the seminal work of #TAUTHOR_TAG is a noteworthy point of reference and comparison .', 'However, our study differs in several important respects.', '', '', '', '']",1
"['', '', '', '', 'using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition #TAUTHOR_TAG .']","['', '', '', '', 'using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition #TAUTHOR_TAG .']","['', '', '', '', 'using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition #TAUTHOR_TAG .']","['', '', '', '', 'Second , using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition #TAUTHOR_TAG .']",0
"['We work with a semi-technical text on meteorological phenomena #TAUTHOR_TAG , meant for primary school students .', 'The text gradually introduces concepts related to precipitation, and explains them.', 'Its nature makes it appropriate for the semantic analysis task in an incremental approach.', 'The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text.']","['We work with a semi-technical text on meteorological phenomena #TAUTHOR_TAG , meant for primary school students .', 'The text gradually introduces concepts related to precipitation, and explains them.', 'Its nature makes it appropriate for the semantic analysis task in an incremental approach.', 'The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text.']","['We work with a semi-technical text on meteorological phenomena #TAUTHOR_TAG , meant for primary school students .', 'The text gradually introduces concepts related to precipitation, and explains them.', 'Its nature makes it appropriate for the semantic analysis task in an incremental approach.', 'The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text.']","['We work with a semi-technical text on meteorological phenomena #TAUTHOR_TAG , meant for primary school students .', 'The text gradually introduces concepts related to precipitation, and explains them.', 'Its nature makes it appropriate for the semantic analysis task in an incremental approach.', 'The system will mimic the way in which a human reader accumulates knowledge and uses what was written before to process ideas introduced later in the text.']",5
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P .', ""This idea was inspired by #TAUTHOR_TAG , who used a list of arguments surrounding the main verb together with the verb 's subcategorization information and previously processed examples to analyse semantic roles ( case relations ) ."", 'recent approaches, is translated into features Frame']","['To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P .', ""This idea was inspired by #TAUTHOR_TAG , who used a list of arguments surrounding the main verb together with the verb 's subcategorization information and previously processed examples to analyse semantic roles ( case relations ) ."", 'recent approaches, is translated into features']","['To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P .', ""This idea was inspired by #TAUTHOR_TAG , who used a list of arguments surrounding the main verb together with the verb 's subcategorization information and previously processed examples to analyse semantic roles ( case relations ) ."", 'recent approaches, syntactic information is translated into features Frame']","['To process a pair P not encountered previously, the system builds a graph centered on the main element (often the head) of P .', ""This idea was inspired by #TAUTHOR_TAG , who used a list of arguments surrounding the main verb together with the verb 's subcategorization information and previously processed examples to analyse semantic roles ( case relations ) ."", '']",4
"['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #TAUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #AUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #TAUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #AUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #TAUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #AUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #TAUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #AUTHOR_TAG .']",0
"['', '', '', '', '', '', 'The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent #TAUTHOR_TAG a ) .']","['', '', '', '', '', '', 'The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent #TAUTHOR_TAG a ) .']","['', '', '', '', '', '', 'The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent #TAUTHOR_TAG a ) .']","['', '', '', '', '', '', 'The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent #TAUTHOR_TAG a ) .']",4
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #TAUTHOR_TAG or the system #AUTHOR_TAG .', '', 'sem relations designed']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #TAUTHOR_TAG or the system #AUTHOR_TAG .', '', 'semantic relations designed']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #TAUTHOR_TAG or the system #AUTHOR_TAG .', '', 'semantic relations are designed']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #TAUTHOR_TAG or the system #AUTHOR_TAG .', '', '']",0
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts.', 'It helps them build complex knowledge bases by combining components : events , entities and modifiers #TAUTHOR_TAG .', ""The system's interface facilitates the expert's task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary.""]","['In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts.', 'It helps them build complex knowledge bases by combining components : events , entities and modifiers #TAUTHOR_TAG .', ""The system's interface facilitates the expert's task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary.""]","['In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts.', 'It helps them build complex knowledge bases by combining components : events , entities and modifiers #TAUTHOR_TAG .', ""The system's interface facilitates the expert's task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary.""]","['In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts.', 'It helps them build complex knowledge bases by combining components : events , entities and modifiers #TAUTHOR_TAG .', ""The system's interface facilitates the expert's task of creating and manipulating structures which represent domain concepts, and assigning them relations from a relation dictionary.""]",0
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #TAUTHOR_TAG .', 'systemsoun ).', 'Lists of semantic relations are designed to capture salient domain']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #TAUTHOR_TAG .', 'systems noun ).', 'Lists of semantic relations are designed to capture salient domain']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #TAUTHOR_TAG .', 'Such systemsoun phrases #AUTHOR_TAG ).', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods , lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #TAUTHOR_TAG .', '', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['ing is essential to elements meaning inter', 'This an idea', 'The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century BC and the work', 'He was a grammarian who analysed Sanskrit #TAUTHOR_TAG .', 'resur', '']","['analysing is essential to elements meaning', 'This an idea.', 'The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century and the work', 'He was a grammarian who analysed Sanskrit #TAUTHOR_TAG .', 'resurfaced', '']","['it is essential to elements meaning inter', 'This', 'The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work', 'He was a grammarian who analysed Sanskrit #TAUTHOR_TAG .', 'resur', '']","['', '', 'The first chronicled endeavour to connect text elements and organise connections between them goes back to the 5th century B.C. and the work of Panini1 .', 'He was a grammarian who analysed Sanskrit #TAUTHOR_TAG .', '', '']",0
"['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']",0
"['', 'gram notion is the basis for semantic relations #AUTHOR_TAG', 'nière (1959), who proposes grouping verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants -for example, agent or instrument -to such grammatical elements as subject, direct object, indirect object.', 'This idea was expanded to include nouns and their modifiers through verb nominalizations #TAUTHOR_TAG .']","['', 'notion is the basis for semantic relations #AUTHOR_TAG', 'Tesnière (1959), who proposes grouping verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants -for example, agent or instrument -to such grammatical elements as subject, direct object, indirect object.', 'This idea was expanded to include nouns and their modifiers through verb nominalizations #TAUTHOR_TAG .']","['', 'is the basis for semantic relations #AUTHOR_TAG .', 'nière (1959), who proposes a grouping verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants -for example, agent or instrument -to such grammatical elements as subject, direct object, indirect object.', 'This idea was expanded to include nouns and their modifiers through verb nominalizations #TAUTHOR_TAG .']","['', '', 'Tesnière (1959), who proposes a grouping of verb arguments into actants and circumstances, gives a set of rules to connect specific types of actants -for example, agent or instrument -to such grammatical elements as subject, direct object, indirect object.', 'This idea was expanded to include nouns and their modifiers through verb nominalizations #TAUTHOR_TAG .']",0
"['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']","['In current work on semantic relation analysis, the focus is on semantic roles -relations between verbs and their arguments.', 'Most approaches rely on VerbNet #AUTHOR_TAG and FrameNet #AUTHOR_TAG to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions #AUTHOR_TAG and also #TAUTHOR_TAG .']",0
"['The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information , DIPETT #TAUTHOR_TAG .', 'parser Prolog', 'relations', '']","['The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information , DIPETT #TAUTHOR_TAG .', 'parser, Prolog,', 'relations', '']","['The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information , DIPETT #TAUTHOR_TAG .', 'Prolog', 'ical relations', '']","['The syntactic structures of the input data are produced by a parser with good coverage and detailed syntactic information , DIPETT #TAUTHOR_TAG .', '', '', '']",5
"['Some methods of semantic relation analysis rely on predefined templates with information from', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #AUTHOR_TAG ; noun phrases in #TAUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates with information from', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #AUTHOR_TAG ; noun phrases in #TAUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates with information from', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #AUTHOR_TAG ; noun phrases in #TAUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #AUTHOR_TAG ; noun phrases in #TAUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['is to.', '', 'The chronicled endeavour to text elements organise', 'a grammariananskrit #AUTHOR_TAG', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['is to', '', 'The chronicled endeavour to text elements organise', 'a grammarian Sanskrit #AUTHOR_TAG', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['it is to.', '', 'The chronicled endeavour to text elements organise', 'a grammariananskrit #AUTHOR_TAG .', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent research in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['', '', '', 'He was a grammarian who analysed Sanskrit #AUTHOR_TAG .', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic role labelling #AUTHOR_TAG .']",0
"['is to.', '', 'The chronicled endeavour to text elements organise', 'a grammariananskrit #AUTHOR_TAG', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['is to', '', 'The chronicled endeavour to text elements organise', 'a grammarian Sanskrit #AUTHOR_TAG', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['it is to.', '', 'The chronicled endeavour to text elements organise', 'a grammariananskrit #AUTHOR_TAG .', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'many researchers in natural language processing, as shown by recent research in semantic parsing and semantic role labelling #AUTHOR_TAG .']","['', '', '', 'He was a grammarian who analysed Sanskrit #AUTHOR_TAG .', 'The idea resurfaced forcefully at several points in the more recent history of linguistic research #TAUTHOR_TAG .', 'Now it has the attention of many researchers in natural language processing, as shown by recent research in semantic parsing and semantic role labelling #AUTHOR_TAG .']",0
"['Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text.', 'This design idea was adopted from TANKA #TAUTHOR_TAG b ) .', 'encoded marksubpos', '']","['Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text.', 'This design idea was adopted from TANKA #TAUTHOR_TAG b ) .', 'encoded markers', '']","['Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text.', 'This design idea was adopted from TANKA #TAUTHOR_TAG b ) .', 'encoded marksub', '']","['Our system begins operation with a minimum of manually encoded knowledge, and accumulates information as it processes the text.', 'This design idea was adopted from TANKA #TAUTHOR_TAG b ) .', '', '']",5
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #AUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', 'Such systems extract information from some types of syntactic units ( clauses in #TAUTHOR_TAG ; noun phrases in #AUTHOR_TAG ) .', 'Lists of semantic relations are designed to capture salient domain information.']",0
"['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #TAUTHOR_TAG .', ', lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the #AUTHOR_TAG', '', '']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #TAUTHOR_TAG .', 'methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the #AUTHOR_TAG', '', '']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #TAUTHOR_TAG .', 'other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', '', '']","['Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts #TAUTHOR_TAG .', 'In other methods, lexical resources are specifically tailored to meet the requirements of the domain #AUTHOR_TAG or the system #AUTHOR_TAG .', '', '']",0
"['The list of semantic relations with which we work is based on extensive literature study #TAUTHOR_TAG a ) .', 'Three lists of relations for three syntactic levels -inter-clause, intra-clause (case) and nounmodifier relations -were next combined based on syntactic and semantic phenomena.', 'The list is the one used in the experiments', 'relations general ', '', '', '']","['The list of semantic relations with which we work is based on extensive literature study #TAUTHOR_TAG a ) .', 'Three lists of relations for three syntactic levels -inter-clause, intra-clause (case) and nounmodifier relations -were next combined based on syntactic and semantic phenomena.', 'The list is the one used in the experiments', 'relations general 6', '', '', '']","['The list of semantic relations with which we work is based on extensive literature study #TAUTHOR_TAG a ) .', 'Three lists of relations for three syntactic levels -inter-clause, intra-clause (case) and nounmodifier relations -were next combined based on syntactic and semantic phenomena.', 'The resulting list is the one used in the experiments', 'The relations ', '', '', '']","['The list of semantic relations with which we work is based on extensive literature study #TAUTHOR_TAG a ) .', 'Three lists of relations for three syntactic levels -inter-clause, intra-clause (case) and nounmodifier relations -were next combined based on syntactic and semantic phenomena.', 'The resulting list is the one used in the experiments we present in this paper.', '', '', '', '']",5
"['Word reordering between German and English is a complex problem.', 'Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish #TAUTHOR_TAG , we tried to adapt the same approach to the German-English language pair .', 'It turned out that there is a larger variety of long reordering patterns in this case.', 'performed after', '', '', '']","['Word reordering between German and English is a complex problem.', 'Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish #TAUTHOR_TAG , we tried to adapt the same approach to the German-English language pair .', 'It turned out that there is a larger variety of long reordering patterns in this case.', 'performed after', '', '', '']","['Word reordering between German and English is a complex problem.', 'Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish #TAUTHOR_TAG , we tried to adapt the same approach to the German-English language pair .', 'It turned out that there is a larger variety of long reordering patterns in this case.', 'performed after', '', '', '']","['Word reordering between German and English is a complex problem.', 'Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish #TAUTHOR_TAG , we tried to adapt the same approach to the German-English language pair .', 'It turned out that there is a larger variety of long reordering patterns in this case.', '', '', '', '']",4
"['ical phrasebased MT suffers from ambig', '', 'Future research should apply the work of #TAUTHOR_TAG and #AUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['phrase-based MT suffers from', '', 'Future research should apply the work of #TAUTHOR_TAG and #AUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['ical phrase-based MT suffers from', '', 'Future research should apply the work of #TAUTHOR_TAG and #AUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['', '', 'Future research should apply the work of #TAUTHOR_TAG and #AUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']",3
"['Hierarchical phrase-based MT suffers fromurious ambiguity', 'of non', 'Future research should apply the work of #AUTHOR_TAG and #TAUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['Hierarchical phrase-based MT suffers from spurious ambiguity:', 'of', 'Future research should apply the work of #AUTHOR_TAG and #TAUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['Hierarchical phrase-based MT suffers fromurious ambiguity: A', 'of non', 'Future research should apply the work of #AUTHOR_TAG and #TAUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']","['', '', 'Future research should apply the work of #AUTHOR_TAG and #TAUTHOR_TAG , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .']",3
"['In our prior work #TAUTHOR_TAG , we examined whether techniques used for predicting the helpfulness of product reviews #AUTHOR_TAG could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .', 'While previously we used the average of two expert-provided ratings as our gold standard of peerreview helpfulness 1 , there are other types of helpfulness rating', '', '']","['In our prior work #TAUTHOR_TAG , we examined whether techniques used for predicting the helpfulness of product reviews #AUTHOR_TAG could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .', 'While previously we used the average of two expert-provided ratings as our gold standard of peer-review helpfulness 1 , there are other types of helpfulness rating', '', '']","['In our prior work #TAUTHOR_TAG , we examined whether techniques used for predicting the helpfulness of product reviews #AUTHOR_TAG could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .', 'While previously we used the average of two expert-provided ratings as our gold standard of peerreview helpfulness 1 , there are other types of helpfulness rating', '', '']","['In our prior work #TAUTHOR_TAG , we examined whether techniques used for predicting the helpfulness of product reviews #AUTHOR_TAG could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .', 'While previously we used the average of two expert-provided ratings as our gold standard of peer-review helpfulness 1 , there are other types of helpfulness rating (e.g.', '', '']",2
"['We', 'ary pers', '', '', 'this comparing utilities inness predict those', '( Details of how the average-expert model performs can be found in our prior work #TAUTHOR_TAG . )']","['Weka', 'complementary', '', '', 'this comparing utilities in helpfulness predicting those', '( Details of how the average-expert model performs can be found in our prior work #TAUTHOR_TAG . )']","['We', '', '', '', 'this paper is comparing feature utilities in predict', '( Details of how the average-expert model performs can be found in our prior work #TAUTHOR_TAG . )']","['', '', '', '', '', '( Details of how the average-expert model performs can be found in our prior work #TAUTHOR_TAG . )']",2
"['In selecting features for Korean, we have to ac- count for relatively free word order #AUTHOR_TAG', 'We follow our previous work #TAUTHOR_TAG in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also #AUTHOR_TAG .', '', '', '']","['In selecting features for Korean, we have to ac- count for relatively free word order #AUTHOR_TAG', 'We follow our previous work #TAUTHOR_TAG in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also #AUTHOR_TAG .', '', '', '']","['In selecting features for Korean, we have to ac- count for relatively free word order #AUTHOR_TAG .', 'We follow our previous work #TAUTHOR_TAG in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also #AUTHOR_TAG .', '', '', '']","['In selecting features for Korean, we have to ac- count for relatively free word order #AUTHOR_TAG .', 'We follow our previous work #TAUTHOR_TAG in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also #AUTHOR_TAG .', '', '', '']",2
"['The same annotation scheme as in our previous work on anger detection has been applied , see e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'user6-4 angry', 'serv']","['The same annotation scheme as in our previous work on anger detection has been applied , see e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'user angry,', 'servings']","['The same annotation scheme as in our previous work on anger detection has been applied , see e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '-4 angry', '']","['The same annotation scheme as in our previous work on anger detection has been applied , see e.g. #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '', '']",2
"['', '', '', '- doing so until all classes have been merged', 'This process produces a hierarchical clustering of the word types in the corpus , and these clusterings have been found useful in many applications #TAUTHOR_TAG .', '']","['', '', '', 'doing so until all classes have been merged.', 'This process produces a hierarchical clustering of the word types in the corpus , and these clusterings have been found useful in many applications #TAUTHOR_TAG .', '']","['', '', '', '- doing so until all classes have been merged', 'This process produces a hierarchical clustering of the word types in the corpus , and these clusterings have been found useful in many applications #TAUTHOR_TAG .', '']","['', '', '', '', 'This process produces a hierarchical clustering of the word types in the corpus , and these clusterings have been found useful in many applications #TAUTHOR_TAG .', '']",4
"['Following #TAUTHOR_TAG , we also compare the performance of our system with a system using features based on the Brown clusters of the word types in a document .', '']","['Following #TAUTHOR_TAG , we also compare the performance of our system with a system using features based on the Brown clusters of the word types in a document .', '']","['Following #TAUTHOR_TAG , we also compare the performance of our system with a system using features based on the Brown clusters of the word types in a document .', '']","['Following #TAUTHOR_TAG , we also compare the performance of our system with a system using features based on the Brown clusters of the word types in a document .', '']",5
"['In this section we describe in detail the baseline NER system we use.', 'It is inspired by the system described in #TAUTHOR_TAG .', 'Because NER annotations are commonly not nested (for, Army"" is treated as a single entity, instead of organization"") is to a', '']","['In this section we describe in detail the baseline NER system we use.', 'It is inspired by the system described in #TAUTHOR_TAG .', 'Because NER annotations are commonly not nested (for example, Army"" is treated as a single entity, instead of organization Army"") is to a', '']","['In this section we describe in detail the baseline NER system we use.', 'It is inspired by the system described in #TAUTHOR_TAG .', 'Because NER annotations are commonly not nested (for example, is treated as a single entity, instead of it is to', '']","['In this section we describe in detail the baseline NER system we use.', 'It is inspired by the system described in #TAUTHOR_TAG .', '', '']",4
"['', 'generally accepted the semantics of verbs in particular are correlated withag properties', 'exc', '- models basis a implementing our scheme.', 'This choice is inspired by recent work on learning syntactic categories #TAUTHOR_TAG , which successfully utilized such language models to represent word window contexts of target words .', '']","['', 'generally accepted the semantics of verbs in particular are correlated with properties', 'excel', 'models basis a implementing our scheme.', 'This choice is inspired by recent work on learning syntactic categories #TAUTHOR_TAG , which successfully utilized such language models to represent word window contexts of target words .', '']","['', 'accepted the semantics of verbs in particular are correlated withagmatic properties', 'exc', 'the basis a concrete model implementing our scheme.', 'This choice is inspired by recent work on learning syntactic categories #TAUTHOR_TAG , which successfully utilized such language models to represent word window contexts of target words .', '']","['', 'It is generally accepted that the semantics of verbs in particular are correlated with their syntagmatic properties #AUTHOR_TAG .', '', '', 'This choice is inspired by recent work on learning syntactic categories #TAUTHOR_TAG , which successfully utilized such language models to represent word window contexts of target words .', '']",4
"['of as weather structured or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #TAUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry orric.']","['of as weather structured or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #TAUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']","['of as weather reports structured or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #TAUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry orric.']","['', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #TAUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'In these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']",1
"['Our motivation for generation of material for language education exists in work such as #AUTHOR_TAG and #TAUTHOR_TAG , which deal with automatic generation of classic fill in the blank questions .', 'Our work is naturally complementary to these efforts, as their methods require a corpus of in-vocab text to serve as seed sentences.']","['Our motivation for generation of material for language education exists in work such as #AUTHOR_TAG and #TAUTHOR_TAG , which deal with automatic generation of classic fill in the blank questions .', 'Our work is naturally complementary to these efforts, as their methods require a corpus of in-vocab text to serve as seed sentences.']","['Our motivation for generation of material for language education exists in work such as #AUTHOR_TAG and #TAUTHOR_TAG , which deal with automatic generation of classic fill in the blank questions .', 'Our work is naturally complementary to these efforts, as their methods require a corpus of in-vocab text to serve as seed sentences.']","['Our motivation for generation of material for language education exists in work such as #AUTHOR_TAG and #TAUTHOR_TAG , which deal with automatic generation of classic fill in the blank questions .', 'Our work is naturally complementary to these efforts, as their methods require a corpus of in-vocab text to serve as seed sentences.']",4
"['of ofative as structured or #AUTHOR_TAG which generates descriptions of objects', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #TAUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'sem are sometimes also introduced that responses to previous lines of or']","['of of as structured or #AUTHOR_TAG which generates descriptions of objects', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #TAUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'semantic are sometimes also introduced that responses to previous lines of or']","['of of as structured or #AUTHOR_TAG which generates descriptions of objects', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #TAUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'sem are sometimes also introduced that seek responses to previous lines of or']","['', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #TAUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan A et al. , 2009 ) , where specified meter or rhyme schemes are enforced .', 'In these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']",1
"['weather or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan #TAUTHOR_TAG , where specified meter or rhyme schemes are enforced .', 'papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry orric.']","['weather or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan #TAUTHOR_TAG , where specified meter or rhyme schemes are enforced .', 'papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']","['weather reports or #AUTHOR_TAG which generates descriptions of objects from', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan #TAUTHOR_TAG , where specified meter or rhyme schemes are enforced .', 'these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry orric.']","['', 'Our work is more similar to NLG work that concentrates on structural constraints such as generative poetry #AUTHOR_TAG #AUTHOR_TAG #AUTHOR_TAG or song lyrics #AUTHOR_TAG ( Ramakrishnan #TAUTHOR_TAG , where specified meter or rhyme schemes are enforced .', 'In these papers soft semantic goals are sometimes also introduced that seek responses to previous lines of poetry or lyric.']",1
"['a character n- , is most and followed by many', '', 'presence a all diction experiments', 'of wordsL): Instead of using the raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'We use length as the only feature to train a decision tree for each and use the nodes the', '']","['a character , is most and followed by many', '', 'presence a all dictionaries experiments.', 'of words (L): Instead of using the raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'We use length as the only feature to train a decision tree for each and use the nodes the', '']","['a character n- , is most and followed by', '', 'presence a features all available dictionaries', 'of wordsL): Instead of using the raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'We use length as the only feature to train a decision tree for each fold and use the nodes the tree', '']","['', '', '', '3. Length of words (L): Instead of using the raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'We use length as the only feature to train a decision tree for each fold and use the nodes obtained from the tree to create boolean features.', '']",2
"['with a character n-- approach , which is most common and followed by many language identification', '', 'ence in DictionariesD): We use presence in a dictionary as a features for all available dictionaries in previous experiments.', 'raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'the only', '']","['with a character n-gram-based approach , which is most common and followed by many language identification', '', 'Presence in Dictionaries (D): We use presence in a dictionary as a features for all available dictionaries in previous experiments.', 'raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'the only', '']","['with a character n--based approach , which is most common and followed by many language identification researchers.', '', 'in DictionariesD): We use presence in a dictionary as a features for all available dictionaries in previous experiments.', 'raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', 'the only feature', '']","['', '', '2. Presence in Dictionaries (D): We use presence in a dictionary as a features for all available dictionaries in previous experiments.', 'raw length value as a feature , we follow our previous work #TAUTHOR_TAG and create multiple features for length using a decision tree ( J48 ) .', '', '']",2
"['The shape-based metric.', ""The only disambiguation metric that we used in our previous work #TAUTHOR_TAG b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right ."", 'The explanation for this metric is that text processing is, essentially, a left-to-right process.', 'In many genres, people write texts so that the most important ideas go first, both at the paragraph and at the text', 'the', '(see #AUTHOR_TAG c)']","['The shape-based metric.', ""The only disambiguation metric that we used in our previous work #TAUTHOR_TAG b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right ."", 'The explanation for this metric is that text processing is, essentially, a left-to-right process.', 'In many genres, people write texts so that the most important ideas go first, both at the paragraph and at the text', 'the', '(see #AUTHOR_TAG c)']","['The shape-based metric.', ""The only disambiguation metric that we used in our previous work #TAUTHOR_TAG b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right ."", 'The explanation for this metric is that text processing is, essentially, a left-to-right process.', 'In many genres, people write texts so that the most important ideas go first, both at the paragraph and at the text levels.', 'the', '(see #AUTHOR_TAG c)']","['The shape-based metric.', ""The only disambiguation metric that we used in our previous work #TAUTHOR_TAG b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right ."", 'The explanation for this metric is that text processing is, essentially, a left-to-right process.', 'In many genres, people write texts so that the most important ideas go first, both at the paragraph and at the text levels.', '', '']",2
"['', '', 'is', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', 'is', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']",0
"['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus #TAUTHOR_TAG .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', '']","['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus #TAUTHOR_TAG .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', '']","['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus #TAUTHOR_TAG .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', '']","['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus #TAUTHOR_TAG .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', '']",0
"['', '', 'parallel is', 'A number of alignment techniques have been proposed , varying from statistical methods #AUTHOR_TAG to lexical methods #TAUTHOR_TAG .', 'The we adopted', '', '', '', '', '']","['', '', 'parallel is', 'A number of alignment techniques have been proposed , varying from statistical methods #AUTHOR_TAG to lexical methods #TAUTHOR_TAG .', 'The we adopted', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #AUTHOR_TAG to lexical methods #TAUTHOR_TAG .', 'The method we adopted is', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #AUTHOR_TAG to lexical methods #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in #TAUTHOR_TAG .', 'We hope to implement such correspondences in our future research.']","['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in #TAUTHOR_TAG .', 'We hope to implement such correspondences in our future research.']","['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in #TAUTHOR_TAG .', 'We hope to implement such correspondences in our future research.']","['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in #TAUTHOR_TAG .', 'We hope to implement such correspondences in our future research.']",3
"['', '', 'is', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', 'is', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']","['', '', '', 'A number of alignment techniques have been proposed , varying from statistical methods #TAUTHOR_TAG to lexical methods #AUTHOR_TAG .', '', '', '', '', '', '']",0
"['we with A Atl- hint', 'Figure 4 shows the architecture of Atlas-Andes; any other system built with APE look similar.', ""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #TAUTHOR_TAG .""]","['we with APE hints', 'Figure 4 shows the architecture of Atlas-Andes; any other system built with APE look similar.', ""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #TAUTHOR_TAG .""]","['with A', 'Figure 4 shows the architecture of Atlas-Andes; any other system built with APE would look similar.', ""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #TAUTHOR_TAG .""]","['', 'Figure 4 shows the architecture of Atlas-Andes; any other system built with APE would look similar.', ""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #TAUTHOR_TAG .""]",5
"[""2 See #TAUTHOR_TAG for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]","[""2 See #TAUTHOR_TAG for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]","[""2 See #TAUTHOR_TAG for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]","[""2 See #TAUTHOR_TAG for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]",0
"['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #TAUTHOR_TAG ) .', 'an act to sol the', '', '', '', '']","['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #TAUTHOR_TAG ) .', 'an act to solicit the', '', '', '', '']","['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #TAUTHOR_TAG ) .', 'to sol', '', '', '', '']","['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #TAUTHOR_TAG ) .', '', '', '', '', '']",1
"['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'initiative models contribution to domain/problemsolving goals, initiative the- ', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'initiative models contribution to domain/problemsolving goals, initiative the', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'task initiative models contribution to domain/problemsolving goals, dialogue initiative ', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', '', '']",0
"['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'initiative models contribution to domain/problemsolving goals, initiative the- ', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'initiative models contribution to domain/problemsolving goals, initiative the', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'task initiative models contribution to domain/problemsolving goals, dialogue initiative ', '']","['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction #TAUTHOR_TAG .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', '', '']",0
"['We conducted two experiments to evaluate MIMICs automatic adaptation capabilities.', 'We compared MIMIC with two control systems: MIM- a nonadapt mixed-init version of MIMIC that resembles the behavior of many existing dialogue systems.', 'In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail #TAUTHOR_TAG .', 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information.', '', '', '']","[""We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities."", 'We compared MIMIC with two control systems: MIMIC-MI, a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems.', 'In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail #TAUTHOR_TAG .', 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information.', '', '', '']","['We conducted two experiments to evaluate MIMICs automatic adaptation capabilities.', 'We compared MIMIC with two control systems: MIM- a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems.', 'In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail #TAUTHOR_TAG .', 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information.', '', '', '']","[""We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities."", 'We compared MIMIC with two control systems: MIMIC-SI, a system-initiative version of MIMIC in which the system retains both initiatives throughout the dialogue, and MIMIC-MI, a nonadaptive mixed-initiative version of MIMIC that resembles the behavior of many existing dialogue systems.', 'In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail #TAUTHOR_TAG .', 'Each experiment involved eight users interacting with MIMIC and MIMIC-SI or MIMIC-MI to perform a set of tasks, each requiring the user to obtain specific movie information.', '', '', '']",2
"['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results #TAUTHOR_TAG , which we leave for future work .']","['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results #TAUTHOR_TAG , which we leave for future work .']","['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results #TAUTHOR_TAG , which we leave for future work .']","['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results #TAUTHOR_TAG , which we leave for future work .']",3
"['We conducted two experiments to evaluate MICs automatic adaptation capabilities', 'We compared MIC with two control systems', '', '', '', '', ', a number of performance features , largely based on the PARADISE dialogue evaluation scheme #TAUTHOR_TAG , were automatically logged , derived , or manually annotated .', '']","[""We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities."", 'We compared MIMIC with two control systems:', '', '', '', '', ', a number of performance features , largely based on the PARADISE dialogue evaluation scheme #TAUTHOR_TAG , were automatically logged , derived , or manually annotated .', '']","['We conducted two experiments to evaluate MICs automatic adaptation capabilities.', 'We compared MIC with two control systems', '', '', '', '', ', a number of performance features , largely based on the PARADISE dialogue evaluation scheme #TAUTHOR_TAG , were automatically logged , derived , or manually annotated .', '']","[""We conducted two experiments to evaluate MIMIC's automatic adaptation capabilities."", '', '', '', '', '', 'Furthermore , a number of performance features , largely based on the PARADISE dialogue evaluation scheme #TAUTHOR_TAG , were automatically logged , derived , or manually annotated .', '']",5
"['', 'The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project #TAUTHOR_TAG .', 'It is intended to both speed the development of SLSs and to localize the speech-specific code within the application.', 'JAVOX allows developers to add speechfaces']","['', 'The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project #TAUTHOR_TAG .', 'It is intended to both speed the development of SLSs and to localize the speech-specific code within the application.', 'JAVOX allows developers to add speech interfaces']","['', 'The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project #TAUTHOR_TAG .', 'It is intended to both speed the development of SLSs and to localize the speech-specific code within the application.', 'JAVOX allows developers to add speech interfaces']","['', 'The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project #TAUTHOR_TAG .', 'It is intended to both speed the development of SLSs and to localize the speech-specific code within the application.', '']",1
"['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #AUTHOR_TAG hua Chen and Chen, 94; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications #TAUTHOR_TAG Lin , 99 ) .', 'Fur', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #AUTHOR_TAG hua Chen and Chen, 94; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications #TAUTHOR_TAG Lin , 99 ) .', 'Furuse', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #AUTHOR_TAG hua Chen and Chen, 94; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications #TAUTHOR_TAG Lin , 99 ) .', 'Fur', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #AUTHOR_TAG hua Chen and Chen, 94; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications #TAUTHOR_TAG Lin , 99 ) .', '', '', '', '']",0
"['Finding relevant units in a text has been explored in many areas of natural language processing.', '', '', 'This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #TAUTHOR_TAG .']","['Finding relevant units in a text has been explored in many areas of natural language processing.', '', '', 'This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #TAUTHOR_TAG .']","['Finding relevant units in a text has been explored in many areas of natural language processing.', '', '', 'This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #TAUTHOR_TAG .']","['Finding relevant units in a text has been explored in many areas of natural language processing.', '', '', 'This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #TAUTHOR_TAG .']",0
"['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #TAUTHOR_TAG ; hua Chen and Chen , 94 ; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications #AUTHOR_TAG Lin, 99).', '', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #TAUTHOR_TAG ; hua Chen and Chen , 94 ; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications #AUTHOR_TAG Lin, 99).', '', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #TAUTHOR_TAG ; hua Chen and Chen , 94 ; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications #AUTHOR_TAG Lin, 99).', '', '', '', '']","['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints #TAUTHOR_TAG ; hua Chen and Chen , 94 ; #AUTHOR_TAG .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications #AUTHOR_TAG Lin, 99).', '', '', '', '']",5
"['The speech and language processing architecture is based on that of the SRI CommandTalk system #TAUTHOR_TAG ; Stent et a. , 1999 ) .', 'The system a aboutd Open', '', '', '', '', '']","['The speech and language processing architecture is based on that of the SRI CommandTalk system #TAUTHOR_TAG ; Stent et a. , 1999 ) .', 'The system a about SPd Open', '', '', '', '', '']","['The speech and language processing architecture is based on that of the SRI CommandTalk system #TAUTHOR_TAG ; Stent et a. , 1999 ) .', 'The system a suite about', '', '', '', '', '']","['The speech and language processing architecture is based on that of the SRI CommandTalk system #TAUTHOR_TAG ; Stent et a. , 1999 ) .', '', '', '', '', '', '']",5
"['', '', 'recent on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot #AUTHOR_TAG and NCARArs InterBOT project #AUTHOR_TAG', '.', 'CornmandTalk #TAUTHOR_TAG , Circuit Fix-It Shop #AUTHOR_TAG and TRAINS-96 #AUTHOR_TAG are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .', '', '', '', '', '']","['', '', 'recent on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot #AUTHOR_TAG and NCARArs InterBOT project #AUTHOR_TAG', 'task.', 'CornmandTalk #TAUTHOR_TAG , Circuit Fix-It Shop #AUTHOR_TAG and TRAINS-96 #AUTHOR_TAG are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .', '', '', '', '', '']","['', '', 'recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot #AUTHOR_TAG and NCARArs InterBOT project #AUTHOR_TAG .', '', 'CornmandTalk #TAUTHOR_TAG , Circuit Fix-It Shop #AUTHOR_TAG and TRAINS-96 #AUTHOR_TAG are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .', '', '', '', '', '']","['', '', 'More recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot #AUTHOR_TAG and NCARArs InterBOT project #AUTHOR_TAG .', '', 'CornmandTalk #TAUTHOR_TAG , Circuit Fix-It Shop #AUTHOR_TAG and TRAINS-96 #AUTHOR_TAG are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .', '', '', '', '', '']",0
"['', '', '', '', '', 'isation toward a common format is required.', 'This is done with transducers (Kaplan and]).', 'ech', '(ceptiveates', '', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #TAUTHOR_TAG .', '']","['', '', '', '', '', 'normalisation toward a common format is required.', 'This is done with transducers (Kaplan and', '', '(deceptive', '', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #TAUTHOR_TAG .', '']","['', '', '', '', '', 'toward a common format is required.', 'This is done with transducers (Kaplan and', '', '(ceptiveates', '', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #TAUTHOR_TAG .', '']","['', '', '', '', '', '', 'This is done with transducers (Kaplan and Kay, [10]).', '', '', '', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #TAUTHOR_TAG .', '']",5
"['', '', 'boundaries the is processed into a- by an alignment', 'This alignment is done on the basis of both length ( Gale and Church #TAUTHOR_TAG and a notion of cognateness ( Simard [ 16 ] )', '', 'common format', '', '', '', '', '', '']","['', '', 'boundaries the is processed into a by an alignment', 'This alignment is done on the basis of both length ( Gale and Church #TAUTHOR_TAG and a notion of cognateness ( Simard [ 16 ] )', '', 'common format', '', '', '', '', '', '']","['', '', 'sentence boundaries the text is processed into a- by', 'This alignment is done on the basis of both length ( Gale and Church #TAUTHOR_TAG and a notion of cognateness ( Simard [ 16 ] )', '', 'a common format', '', '', '', '', '', '']","['', '', '', 'This alignment is done on the basis of both length ( Gale and Church #TAUTHOR_TAG and a notion of cognateness ( Simard [ 16 ] ) .', '', '', '', '', '', '', '', '']",5
"['â\x80¢ Before indexing the text , we process it with Textract #TAUTHOR_TAG , which performs lemmatization , and discovers proper names and technical terms .', '', '']","['â\x80¢ Before indexing the text , we process it with Textract #TAUTHOR_TAG , which performs lemmatization , and discovers proper names and technical terms .', '', '']","['â\x80¢ Before indexing the text , we process it with Textract #TAUTHOR_TAG , which performs lemmatization , and discovers proper names and technical terms .', '', '']","['â\x80¢ Before indexing the text , we process it with Textract #TAUTHOR_TAG , which performs lemmatization , and discovers proper names and technical terms .', '', '']",5
"['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German #TAUTHOR_TAG .']","['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German #TAUTHOR_TAG .']","['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German #TAUTHOR_TAG .']","['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German #TAUTHOR_TAG .']",5
"['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing #TAUTHOR_TAG .', 'The design criterion ofines is to a set of basic we build multVM-', '', '', '', '', '', '', '', '']","['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing #TAUTHOR_TAG .', 'The design criterion of sines is to a set of basic, we build', '', '', '', '', '', '', '', '']","['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing #TAUTHOR_TAG .', 'The fundamental design criterion ofines is to a set of basic we examined buildVM-', '', '', '', '', '', '', '', '']","['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']",5
"['The NP-based QA System.', 'Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #TAUTHOR_TAG .', 'Empire identifies base NPs --non-recursive noun phrases --using a very simple algorithm that matches part-of-speech tag sequences based on a learned noun phrase grammar.', 'The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal .', 'the filter the', '']","['The NP-based QA System.', 'Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #TAUTHOR_TAG .', 'Empire identifies base NPs --non-recursive noun phrases --using a very simple algorithm that matches part-of-speech tag sequences based on a learned noun phrase grammar.', 'The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal .', 'the filter the', '']","['The NP-based QA System.', 'Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #TAUTHOR_TAG .', 'Empire identifies base NPs --non-recursive noun phrases --using a very simple algorithm that matches part-of-speech tag sequences based on a learned noun phrase grammar.', 'The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal #AUTHOR_TAG .', 'the NP filter the application', '']","['The NP-based QA System.', 'Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #TAUTHOR_TAG .', 'Empire identifies base NPs --non-recursive noun phrases --using a very simple algorithm that matches part-of-speech tag sequences based on a learned noun phrase grammar.', 'The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal #AUTHOR_TAG .', '', '']",5
"['ization algorithms will', '', 'Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings #TAUTHOR_TAG , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task #AUTHOR_TAG :']","['summarization algorithms will', '', 'Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings #TAUTHOR_TAG , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task #AUTHOR_TAG :']","['will improve', '', 'Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings #TAUTHOR_TAG , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task #AUTHOR_TAG :']","['', '', 'Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings #TAUTHOR_TAG , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task #AUTHOR_TAG :']",1
"['The aim of this paper is to give a detailed account of the techniques used in TnT.', ', we present results of the tagger on the NEGRA corpus #AUTHOR_TAG and the Pennbank', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in #TAUTHOR_TAG .', '.']","['The aim of this paper is to give a detailed account of the techniques used in TnT.', 'Additionally, we present results of the tagger on the NEGRA corpus #AUTHOR_TAG and the Penn Treebank', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in #TAUTHOR_TAG .', '.']","['The aim of this paper is to give a detailed account of the techniques used in TnT.', ', we present results of the tagger on the NEGRA corpus #AUTHOR_TAG and the Penn Treebank', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in #TAUTHOR_TAG .', ' #AUTHOR_TAG .']","['The aim of this paper is to give a detailed account of the techniques used in TnT.', 'Additionally, we present results of the tagger on the NEGRA corpus #AUTHOR_TAG and the Penn Treebank #AUTHOR_TAG .', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in #TAUTHOR_TAG .', '']",1
"['', '', '', '', '', '', '', 'According to current tagger comparisons ( van #AUTHOR_TAG , and according to a comparsion of the results presented here with those in #TAUTHOR_TAG , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .', 'It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.']","['', '', '', '', '', '', '', 'According to current tagger comparisons ( van #AUTHOR_TAG , and according to a comparsion of the results presented here with those in #TAUTHOR_TAG , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .', 'It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.']","['', '', '', '', '', '', '', 'According to current tagger comparisons ( van #AUTHOR_TAG , and according to a comparsion of the results presented here with those in #TAUTHOR_TAG , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .', 'It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.']","['', '', '', '', '', '', '', 'According to current tagger comparisons ( van #AUTHOR_TAG , and according to a comparsion of the results presented here with those in #TAUTHOR_TAG , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .', 'It is a very interesting future research topic to determine the advantages of either of these approaches, to find the reason for their high accuracies, and to find a good combination of both.']",1
"['', ')) and densitylot', 'sem', ""This confirms that although Kozima 's approach #TAUTHOR_TAG is computationally expensive , it does produce more precise segmentation .""]","['', 'and density', 'semantic', ""This confirms that although Kozima 's approach #TAUTHOR_TAG is computationally expensive , it does produce more precise segmentation .""]","['', ')) andlot', 'sem', ""This confirms that although Kozima 's approach #TAUTHOR_TAG is computationally expensive , it does produce more precise segmentation .""]","['', '', '', ""This confirms that although Kozima 's approach #TAUTHOR_TAG is computationally expensive , it does produce more precise segmentation .""]",1
"[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure #TAUTHOR_TAG to compute block similarity ."", 'similarity a function of word co- occurrence statistics in given', '', '', '']","[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure #TAUTHOR_TAG to compute block similarity ."", 'similarity a function of word co- occurrence statistics in given', '', '', '']","[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure #TAUTHOR_TAG to compute block similarity ."", 'Word similarity a function of word co- occurrence statistics in given', '', '', '']","[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure #TAUTHOR_TAG to compute block similarity ."", 'Word similarity is a function of word co- occurrence statistics in the given document.', '', '', '']",2
"['In related work, #AUTHOR_TAG describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #TAUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .', '']","['In related work, #AUTHOR_TAG describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #TAUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .', '']","['In related work, #AUTHOR_TAG describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #TAUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .', '']","['In related work, #AUTHOR_TAG describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #TAUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .', '']",1
"['we an mathematical in', 'stochsee Section ', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #TAUTHOR_TAG and #AUTHOR_TAG .', 'We leave this for future work.']","['we an mathematical in', 'stochastic (see Section', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #TAUTHOR_TAG and #AUTHOR_TAG .', 'We leave this for future work.']","['an original mathematical argument in', 'stochsee Section 1).', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #TAUTHOR_TAG and #AUTHOR_TAG .', 'We leave this for future work.']","['', '', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #TAUTHOR_TAG and #AUTHOR_TAG .', 'We leave this for future work.']",3
"['we have an mathematical in', 'stochsee Section ', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #AUTHOR_TAG and #TAUTHOR_TAG .', 'We leave this for future work.']","['we have an mathematical in', 'stochastic (see Section', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #AUTHOR_TAG and #TAUTHOR_TAG .', 'We leave this for future work.']","['we have provided an original mathematical argument in', 'stochsee Section 1).', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #AUTHOR_TAG and #TAUTHOR_TAG .', 'We leave this for future work.']","['', '', 'We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in #AUTHOR_TAG and #TAUTHOR_TAG .', 'We leave this for future work.']",3
"['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #TAUTHOR_TAG .', 'WindowDiff returns 0 in case of a perfect segmentation; 1 is the worst possible score.', 'However, it only takes into account segment boundaries and disregards segment types.', '.', '', '', '', '', '', '', 'after']","['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #TAUTHOR_TAG .', 'WindowDiff returns 0 in case of a perfect segmentation; 1 is the worst possible score.', 'However, it only takes into account segment boundaries and disregards segment types.', '', '', '', '', '', '', '', 'after']","['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #TAUTHOR_TAG .', 'WindowDiff returns 0 in case of a perfect segmentation; 1 is the worst possible score.', 'However, it only takes into account segment boundaries and disregards segment types.', '', '', '', '', '', '', '', 'after']","['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #TAUTHOR_TAG .', 'WindowDiff returns 0 in case of a perfect segmentation; 1 is the worst possible score.', 'However, it only takes into account segment boundaries and disregards segment types.', '', '', '', '', '', '', '', '']",5
"['Merony some relations, there is no contradiction when y 1 and y 2 share a meronym, ie. ""part of"" relation.', 'For example, in the set born in(Mozart,•) there is no contradiction between the y values ""Salzburg"" and ""Austria"", but ""Salzburg"" conflicts with ""Vienna"".', 'Although this is only true in cases where y occurs in an upward monotone context #TAUTHOR_TAG , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare', 'assigned contradictions between meronyms a probability to zero.', 'used']","['Meronyms: some relations, there is no contradiction when y 1 and y 2 share a meronym, i.e. ""part of"" relation.', 'For example, in the set born in(Mozart,•) there is no contradiction between the y values ""Salzburg"" and ""Austria"", but ""Salzburg"" conflicts with ""Vienna"".', 'Although this is only true in cases where y occurs in an upward monotone context #TAUTHOR_TAG , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare', 'assigned contradictions between meronyms a probability to zero.', 'used']","['Merony some relations, there is no contradiction when y 1 and y 2 share a meronym, ie. ""part of"" relation.', 'For example, in the set born in(Mozart,•) there is no contradiction between the y values ""Salzburg"" and ""Austria"", but ""Salzburg"" conflicts with ""Vienna"".', 'Although this is only true in cases where y occurs in an upward monotone context #TAUTHOR_TAG , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare .', 'assigned contradictions between meronyms a probability to zero.', 'We used']","['Meronyms: For some relations, there is no contradiction when y 1 and y 2 share a meronym, i.e. ""part of"" relation.', 'For example, in the set born in(Mozart,•) there is no contradiction between the y values ""Salzburg"" and ""Austria"", but ""Salzburg"" conflicts with ""Vienna"".', 'Although this is only true in cases where y occurs in an upward monotone context #TAUTHOR_TAG , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare .', 'We therefore simply assigned contradictions between meronyms a probability close to zero.', '']",4
"['use', '4', 'We parse each sentence with the Collins parser #TAUTHOR_TAG .', 'Then the document has one big parse tree, is DO']","['use', '', 'We parse each sentence with the Collins parser #TAUTHOR_TAG .', 'Then the document has one big parse tree, is']","['we use', '', 'We parse each sentence with the Collins parser #TAUTHOR_TAG .', 'Then the document has one big parse tree, is DO']","['', '', 'We parse each sentence with the Collins parser #TAUTHOR_TAG .', '']",5
"[' #AUTHOR_TAG , we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.', 'It is based on the dataset of #TAUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .', 'experiments use F9 as final blind test set.']","[' #AUTHOR_TAG , we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.�8', 'It is based on the dataset of #TAUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .', 'experiments use F9 as final blind test set.']","[' #AUTHOR_TAG , we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.�8', 'It is based on the dataset of #TAUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .', 'experiments use F9 as final blind test set.']","[' #AUTHOR_TAG , we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.�8', 'It is based on the dataset of #TAUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .', 'All our experiments use F9 as their final blind test set.']",2
"['an', '', '', '', 'We collect substring rationales for a sentiment classification task #TAUTHOR_TAG and use them to obtain significant accuracy improvements for each annotator', '', '']","['', '', '', '', 'We collect substring rationales for a sentiment classification task #TAUTHOR_TAG and use them to obtain significant accuracy improvements for each annotator', '', '']","['', '', '', '', 'We collect substring rationales for a sentiment classification task #TAUTHOR_TAG and use them to obtain significant accuracy improvements for each annotator .', '', '']","['', '', '', '', 'We collect substring rationales for a sentiment classification task #TAUTHOR_TAG and use them to obtain significant accuracy improvements for each annotator .', '', '']",5
"['where f (•) extracts a feature vector from a classified, θ are the corresponding weights of those features, and Z θ (x) def = y ux is a normalizer', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let { 1 ... v 17744 } be the set of word types with count ≥ 4 in the 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y u(x, is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let {v 1 ..., v 17744 } be the set of word types with count ≥ 4 in the 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y ux is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'let V = {v 1 ... v 17744 } be the set of word types with count ≥ 4 in the full 2000-document corpus.', '', '', '', '']","['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y u(x, y) is a normalizer.', 'We use the same set of binary features as in previous work on this dataset #TAUTHOR_TAG .', 'Specifically, let V = {v 1 , ..., v 17744 } be the set of word types with count ≥ 4 in the full 2000-document corpus.', '', '', '', '']",5
"['', '', '', 'We gather similar words using #TAUTHOR_TAG a ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text']","['', '', '', 'We gather similar words using #TAUTHOR_TAG a ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text']","['', '', '', 'We gather similar words using #TAUTHOR_TAG a ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text .4']","['', '', '', ""We gather similar words using #TAUTHOR_TAG a ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text .4 We also use #AUTHOR_TAG 's approach to obtaining web-counts .""]",5
"['We also made use of the person-name/instance pairs automatically extracted by #TAUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.', 'We have features for all concepts and therefore learn their association with each verb.']","['We also made use of the person-name/instance pairs automatically extracted by #TAUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.', 'We have features for all concepts and therefore learn their association with each verb.']","['We also made use of the person-name/instance pairs automatically extracted by #TAUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.', 'We have features for all concepts and therefore learn their association with each verb.']","['We also made use of the person-name/instance pairs automatically extracted by #TAUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.', 'We have features for all concepts and therefore learn their association with each verb.']",5
"['we evaluate D on a common application of selectional preferences choosing the correct antecedent for in', ""We study the cases where a 9Recall that even the #TAUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) ."", 'the direct object pred', 'pron ante obey', '']","['we evaluate DSP on a common application of selectional preferences: choosing the correct antecedent for in', ""We study the cases where a 9Recall that even the #TAUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) ."", 'the direct object', 'obey', '']","['we evaluate D on a common application of selectional preferences: choosing the correct antecedent for in', ""We study the cases where a 9Recall that even the #TAUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) ."", 'the direct object', 'must obey', '']","['Finally, we evaluate DSP on a common application of selectional preferences: choosing the correct antecedent for pronouns in text #AUTHOR_TAG .', ""We study the cases where a 9Recall that even the #TAUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) ."", '', '', '']",1
"['', 'weights on-rence features (', 'specificityrank verb context', 'The DSP parameters for eat for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', "" #TAUTHOR_TAG a ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", '', '']","['', 'weights on features (Section', 'similarityranking verb', 'The DSP parameters for eat, for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', "" #TAUTHOR_TAG a ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", '', '']","['', 'on (', '', 'The DSP parameters for eat for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', "" #TAUTHOR_TAG a ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", '', '']","['', '', '', 'The DSP parameters for eat, for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', "" #TAUTHOR_TAG a ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", '', '']",0
"['DC', '', '', 'search this cor replic', 'not be able to a each example.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #TAUTHOR_TAG approach will be undefined if the pair is unobserved on the web .', 'As a reasonable default for these cases, we assign them a negative decision.']","['LDC', '', '', 'search this corpus replicable.', 'not be able to a each example.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #TAUTHOR_TAG approach will be undefined if the pair is unobserved on the web .', 'As a reasonable default for these cases, we assign them a negative decision.']","['', '', '', 'this corpus replic', 'not be able to a score each example.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #TAUTHOR_TAG approach will be undefined if the pair is unobserved on the web .', 'As a reasonable default for these cases, we assign them a negative decision.']","['', '', '', '', 'not be able to provide a score for each example.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #TAUTHOR_TAG approach will be undefined if the pair is unobserved on the web .', 'As a reasonable default for these cases, we assign them a negative decision.']",5
"['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'refer this as Pairation', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'refer this as Pairwise', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'We refer this as Pair', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'We refer to this as Pairwise Disambiguation.', '', '']",1
"['The advantage of tuning similarity to the application of interest has been shown previously by #TAUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.', '', '']","['The advantage of tuning similarity to the application of interest has been shown previously by #TAUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.', '', '']","['The advantage of tuning similarity to the application of interest has been shown previously by #TAUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.', '', '']","['The advantage of tuning similarity to the application of interest has been shown previously by #TAUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.', '', '']",1
"['', '', '', ""a MI is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of (v, n, n ′ ) triples: Pr(v|n) = Pr(v, n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f (v, n)."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #TAUTHOR_TAG .']","['', '', '', ""a MI is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of (v, n, n ′ ) triples: Pr(v|n) = Pr(v, n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f (v, n)."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #TAUTHOR_TAG .']","['', '', '', ""is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of (v, n, n ′ ) triples: Pr(v|n) = Pr(v, n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f (v, n)."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #TAUTHOR_TAG .']","['', '', '', ""Thus rather than a single training procedure, we can actually partition the examples by predicate, and train a For a fixed verb, MI is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of (v, n, n ′ ) triples: Pr(v|n) = Pr(v, n)/Pr(n), which was shown to be a better measure of association than co-occurrence frequency f (v, n)."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #TAUTHOR_TAG .']",0
"['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'refer this as Pairation', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'refer this as Pairwise', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'We refer this as Pair', '', '']","['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models #TAUTHOR_TAG .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.', 'The models score correctly if they rank observed (and thus plausible) arguments above corresponding unobserved (and thus likely implausible) ones.', 'We refer to this as Pairwise Disambiguation.', '', '']",1
"['Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following #AUTHOR_TAG', ', we might have a class Mexican and that the entire class is suitable for eating.', 'Usually , the classes are from WordNet #AUTHOR_TAG , although they can also be inferred from clustering #TAUTHOR_TAG .', 'number Word']","['Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following #AUTHOR_TAG', 'example, we might have a class Mexican and that the entire class is suitable for eating.', 'Usually , the classes are from WordNet #AUTHOR_TAG , although they can also be inferred from clustering #TAUTHOR_TAG .', 'number']","['Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following #AUTHOR_TAG .', ', we might have a class Mexican Food and that the entire class is suitable for eating.', 'Usually , the classes are from WordNet #AUTHOR_TAG , although they can also be inferred from clustering #TAUTHOR_TAG .', 'a number Word']","['Most approaches to SPs generalize from observed predicate-argument pairs to semantically similar ones by modeling the semantic class of the argument, following #AUTHOR_TAG .', 'For example, we might have a class Mexican Food and learn that the entire class is suitable for eating.', 'Usually , the classes are from WordNet #AUTHOR_TAG , although they can also be inferred from clustering #TAUTHOR_TAG .', '']",0
"['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (and', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', '', '', '', '']",1
"['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules #TAUTHOR_TAG .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', 'extract sem arguments']","['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules #TAUTHOR_TAG .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', 'semantic arguments.']","['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules #TAUTHOR_TAG .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', '']","['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules #TAUTHOR_TAG .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', '']",0
"['', '', 'to', "" #AUTHOR_TAG compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #TAUTHOR_TAG a ) 's information-theoretic metric work best ."", '']","['', '', 'to', "" #AUTHOR_TAG compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #TAUTHOR_TAG a ) 's information-theoretic metric work best ."", '']","['', '', 'to', "" #AUTHOR_TAG compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #TAUTHOR_TAG a ) 's information-theoretic metric work best ."", '']","['', '', '', "" #AUTHOR_TAG compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #TAUTHOR_TAG a ) 's information-theoretic metric work best ."", '']",0
"['We parsed the 3 GB AQUAINT corpus #AUTHOR_TAG using Minipar #TAUTHOR_TAG b ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data', 'bs and n', '', '']","['We parsed the 3 GB AQUAINT corpus #AUTHOR_TAG using Minipar #TAUTHOR_TAG b ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data', 'Verbs and', '', '']","['We parsed the 3 GB AQUAINT corpus #AUTHOR_TAG using Minipar #TAUTHOR_TAG b ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data .', 'bs and n', '', '']","['We parsed the 3 GB AQUAINT corpus #AUTHOR_TAG using Minipar #TAUTHOR_TAG b ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data .', '', '', '']",5
"['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (and', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', 'never occurred (', '', '', '']","['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times #TAUTHOR_TAG .', 'Presumably the lower bound is to help ensure the negative argument is unobserved because it is unsuitable, not because of data sparseness.', '', '', '', '']",1
"['', 'the positives automaticallypus then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) #TAUTHOR_TAG .', 'The MI between a verb predicate, v, and its object argument, n, is:']","['', 'the positives, automatically then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) #TAUTHOR_TAG .', 'The MI between a verb predicate, v, and its object argument, n, is:']","['', 'the positives, automatically then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) #TAUTHOR_TAG .', 'The MI between a verb predicate, v, and its object argument, n, is:']","['', 'To create the positives, we automatically parse a large corpus, and then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) #TAUTHOR_TAG .', 'The MI between a verb predicate, v, and its object argument, n, is:']",5
"['every feature feature', '', 'icate will be completely independent', ""For a fixed verb , MI is proportional to #TAUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."", 'Normalizing by Prv)ielding MI) to a constantbs', '']","['every feature feature', '', 'predicate will be completely independent', ""a fixed verb , MI is proportional to #TAUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."", 'Normalizing by Pr(v) (yielding MI) to a constant', '']","['some feature', '', 'will be completely independent', ""a 1For a fixed verb , MI is proportional to #TAUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."", 'Normalizing by Prv)ielding MI) to a constant threshold', '']","['', '', '', ""Thus rather than a single training procedure , we can actually partition the examples by predicate , and train a 1For a fixed verb , MI is proportional to #TAUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) ."", 'Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', '']",4
"['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by #TAUTHOR_TAG .']","['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by #TAUTHOR_TAG .']","['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by #TAUTHOR_TAG .']","['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by #TAUTHOR_TAG .']",1
"['ual Entailment systems are given two textual fragments text and H, and attempt to decide if the meaning of H can be inferred', ""While many approaches have addressed this problem , our work is most closely related to that of #TAUTHOR_TAG , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms ."", '']","['Textual Entailment systems are given two textual fragments, text and H, and attempt to decide if the meaning of H can be inferred', ""While many approaches have addressed this problem , our work is most closely related to that of #TAUTHOR_TAG , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms ."", '']","['ual Entailment systems are given two textual fragments, text T and hypothesis H, and attempt to decide if the meaning of H can be inferred', ""While many approaches have addressed this problem , our work is most closely related to that of #TAUTHOR_TAG , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms ."", '']","['Textual Entailment systems are given two textual fragments, text T and hypothesis H, and attempt to decide if the meaning of H can be inferred from the meaning of T #AUTHOR_TAG .', ""While many approaches have addressed this problem , our work is most closely related to that of #TAUTHOR_TAG , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms ."", '']",1
"['The studies presented by #TAUTHOR_TAG and #AUTHOR_TAG differed in the number of states that they used .', 'evaluated against the reduced tag set of 17 tags developed by #AUTHOR_TAG , while #AUTHOR_TAG evaluated against the full Penn Treebank tag set.', 'ran all our estimators in to Noah with his']","['The studies presented by #TAUTHOR_TAG and #AUTHOR_TAG differed in the number of states that they used .', 'evaluated against the reduced tag set of 17 tags developed by #AUTHOR_TAG , while #AUTHOR_TAG evaluated against the full Penn Treebank tag set.', 'ran all our estimators in to Noah with his']","['The studies presented by #TAUTHOR_TAG and #AUTHOR_TAG differed in the number of states that they used .', 'evaluated against the reduced tag set of 17 tags developed by #AUTHOR_TAG , while #AUTHOR_TAG evaluated against the full Penn Treebank tag set.', 'We ran all our estimators in to Noah Smith with his']","['The studies presented by #TAUTHOR_TAG and #AUTHOR_TAG differed in the number of states that they used .', 'evaluated against the reduced tag set of 17 tags developed by #AUTHOR_TAG , while #AUTHOR_TAG evaluated against the full Penn Treebank tag set.', '']",1
"['As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear.', 'On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #TAUTHOR_TAG .', 'This perhapsatively']","['As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear.', 'On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #TAUTHOR_TAG .', 'This perhaps comparatively']","['As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear.', 'On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #TAUTHOR_TAG .', 'This']","['As might be expected, our evaluation measures disagree somewhat, but the following broad tendancies seem clear.', 'On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #TAUTHOR_TAG .', '']",1
['The resulting training procedure is analogous to the one presented in #AUTHOR_TAG and #TAUTHOR_TAG .'],['The resulting training procedure is analogous to the one presented in #AUTHOR_TAG and #TAUTHOR_TAG .'],['The resulting training procedure is analogous to the one presented in #AUTHOR_TAG and #TAUTHOR_TAG .'],['The resulting training procedure is analogous to the one presented in #AUTHOR_TAG and #TAUTHOR_TAG .'],1
"['', '', '', '', '', '', '', 'm and n are the number of nodes of the two trees ( m > = n ) #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', '', 'm and n are the number of nodes of the two trees ( m > = n ) #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', '', 'm and n are the number of nodes of the two trees ( m > = n ) #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '']",3
"['of future', 'we to explore our estim on other language in to obtain more on its', 'Secondly , as #TAUTHOR_TAG show , marginalizing out the different segmentations during decoding leads to improved performance .', 'including achieving a', '', '']","['of future', 'we to explore our estimator on other language in to obtain more on its', 'Secondly , as #TAUTHOR_TAG show , marginalizing out the different segmentations during decoding leads to improved performance .', 'including achieving a', '', '']","['of', 'we plan to explore our estim on other language pairs in to obtain more evidence on its', 'Secondly , as #TAUTHOR_TAG show , marginalizing out the different segmentations during decoding leads to improved performance .', '', '', '']","['', 'Firstly, we plan to explore our estimator on other language pairs in order to obtain more evidence on its behavior.', 'Secondly , as #TAUTHOR_TAG show , marginalizing out the different segmentations during decoding leads to improved performance .', '', '', '']",3
"['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['A good study comparing document categorization algorithms can be found in #AUTHOR_TAG .', 'More recently , #AUTHOR_TAG has performed a good survey of document categorization ; recent works can also be found in #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']",0
"['De #AUTHOR_TAG segmentation the gener lead overitting training', 'Based on this advise ( Moore and #TAUTHOR_TAG exclude the latent segmentation variables and opt for a heuristic training procedure', '', '', '', '']","['(De #AUTHOR_TAG segmentation the generative lead overfitting training', 'Based on this advise ( Moore and #TAUTHOR_TAG exclude the latent segmentation variables and opt for a heuristic training procedure', '', '', '', '']","['De #AUTHOR_TAG that segmentation the generative translation model lead overitting', 'Based on this advise ( Moore and #TAUTHOR_TAG exclude the latent segmentation variables and opt for a heuristic training procedure .', '', '', '', '']","['', 'Based on this advise ( Moore and #TAUTHOR_TAG exclude the latent segmentation variables and opt for a heuristic training procedure .', '', '', '', '']",1
"['we identify a set of,, and training', '', 'variables we wish to consider are an increased number of word ; more flexible regions -- see #TAUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries', '', '', '']","['we identify a set of features, variables, and training', '', 'variables we wish to consider are an increased number of word ; more flexible regions -- see #TAUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries', '', '', '']","['identify a set of and training methods', '', 'ent variables we wish to consider are an increased number of word classes ; more flexible regions -- see #TAUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries .', '', '', '']","['', '', 'Latent variables we wish to consider are an increased number of word classes ; more flexible regions -- see #TAUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries .', '', '', '']",0
"['In future work, we would like to identify a set of features, latent variables, and training methods that port well across languages and string-transduction tasks.', 'We would like to use features that look at wide context on the input side , which is inexpensive #TAUTHOR_TAG .', '', '', '', '']","['In future work, we would like to identify a set of features, latent variables, and training methods that port well across languages and string-transduction tasks.', 'We would like to use features that look at wide context on the input side , which is inexpensive #TAUTHOR_TAG .', '', '', '', '']","['In future work, we would like to identify a set of features, latent variables, and training methods that port well across languages and string-transduction tasks.', 'We would like to use features that look at wide context on the input side , which is inexpensive #TAUTHOR_TAG .', '', '', '', '']","['In future work, we would like to identify a set of features, latent variables, and training methods that port well across languages and string-transduction tasks.', 'We would like to use features that look at wide context on the input side , which is inexpensive #TAUTHOR_TAG .', '', '', '', '']",3
"['', '', '', '', '', '', '', '', 'to improve the similarity', ' #TAUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']","['', '', '', '', '', '', '', '', 'to improve the similarity', ' #TAUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']","['', '', '', '', '', '', '', '', 'to improve the similarity estimates.', ' #TAUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']",0
"['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #TAUTHOR_TAG , to ranking models for Web search applications .']","['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #TAUTHOR_TAG , to ranking models for Web search applications .']","['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #TAUTHOR_TAG , to ranking models for Web search applications .']","['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #TAUTHOR_TAG , to ranking models for Web search applications .']",0
"['As already mentioned in the literature , see for example #TAUTHOR_TAG , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .', 'Many applications of semantic relations in NLP are connected to parap', '', '', '', '', '', '', '', '']","['As already mentioned in the literature , see for example #TAUTHOR_TAG , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .', 'Many applications of semantic relations in NLP are connected to paraphrasing', '', '', '', '', '', '', '', '']","['As already mentioned in the literature , see for example #TAUTHOR_TAG , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .', 'Many applications of semantic relations in NLP are connected to parap', '', '', '', '', '', '', '', '']","['As already mentioned in the literature , see for example #TAUTHOR_TAG , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .', 'Many applications of semantic relations in NLP are connected to paraphrasing or query expansion, see for example #AUTHOR_TAG .', '', '', '', '', '', '', '', '']",0
"['', '', '', '', '', 'riv a singleative', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', 'rivaling a single generative', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set #TAUTHOR_TAG .', '', '', '', '']",1
"['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #TAUTHOR_TAG and products of latent variable grammars #AUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #TAUTHOR_TAG and products of latent variable grammars #AUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #TAUTHOR_TAG and products of latent variable grammars #AUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #TAUTHOR_TAG and products of latent variable grammars #AUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']",1
"['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #AUTHOR_TAG and products of latent variable grammars #TAUTHOR_TAG , despite being a single generative PCFG .', 'Our most model achie an', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #AUTHOR_TAG and products of latent variable grammars #TAUTHOR_TAG , despite being a single generative PCFG .', 'Our most model achieves an', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #AUTHOR_TAG and products of latent variable grammars #TAUTHOR_TAG , despite being a single generative PCFG .', 'Our most achie', '', '', '', '']","['', '', '', '', '', 'Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches #AUTHOR_TAG and products of latent variable grammars #TAUTHOR_TAG , despite being a single generative PCFG .', '', '', '', '', '']",1
"[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement #TAUTHOR_TAG ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", ""In to these 'Subject of thetopicshift cue can be for a"", '', '', '']","[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement #TAUTHOR_TAG ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", ""In to these, 'Subject of the 'topic-shift cue can be for a"", '', '', '']","[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement #TAUTHOR_TAG ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", ""In to these 'Subject of can be for"", '', '', '']","[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement #TAUTHOR_TAG ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", '', '', '', '']",0
"['we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system #TAUTHOR_TAG yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', 'results suggest a for improving']","['we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system #TAUTHOR_TAG yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', 'results suggest a for improving']","['we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system #TAUTHOR_TAG yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', 'suggest for']","['Finally, we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system #TAUTHOR_TAG yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', '']",0
"['We run our techniques on a large set of relations to output a first repository of typed functional relations', '2', 'Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity #TAUTHOR_TAG , mutual exclusion , symmetry , etc. .', 'These properties are very useful in increasing our understanding about these Open IE relation strings.', 'We believe that the general principles developed in this work, for example, connecting the Open IE knowledge with an existing knowledge resource, will come in very handy in identifying these other properties.']","['We run our techniques on a large set of relations to output a first repository of typed functional relations.', '2', 'Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity #TAUTHOR_TAG , mutual exclusion , symmetry , etc. .', 'These properties are very useful in increasing our understanding about these Open IE relation strings.', 'We believe that the general principles developed in this work, for example, connecting the Open IE knowledge with an existing knowledge resource, will come in very handy in identifying these other properties.']","['We run our techniques on a large set of relations to output a first repository of typed functional relations.', '', 'Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity #TAUTHOR_TAG , mutual exclusion , symmetry , etc. .', 'These properties are very useful in increasing our understanding about these Open IE relation strings.', 'We believe that the general principles developed in this work, for example, connecting the Open IE knowledge with an existing knowledge resource, will come in very handy in identifying these other properties.']","['We run our techniques on a large set of relations to output a first repository of typed functional relations.', '', 'Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity #TAUTHOR_TAG , mutual exclusion , symmetry , etc. .', 'These properties are very useful in increasing our understanding about these Open IE relation strings.', 'We believe that the general principles developed in this work, for example, connecting the Open IE knowledge with an existing knowledge resource, will come in very handy in identifying these other properties.']",0
"['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in #TAUTHOR_TAG .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one of the Indonesian-English bi-text', 'built simple concaten', 'The two tables are then merged as all phrase pairs from the one are retained, and to them are added those phrase pairs from the second one that are not present in the first one', '', '']","['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in #TAUTHOR_TAG .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one of the Indonesian-English bi-text.', 'built simple concatenation.', 'The two tables are then merged as all phrase pairs from the one are retained, and to them are added those phrase pairs from the second one that are not present in the first one.', '', '']","['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in #TAUTHOR_TAG .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one copy of the Indonesian-English bi-text.', 'is built', 'The two tables are then merged as all phrase pairs from the one are retained, and to them are added those phrase pairs from the second one that are not present in the first one.', '', '']","['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in #TAUTHOR_TAG .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one copy of the Indonesian-English bi-text.', '', 'The two tables are then merged as follows: all phrase pairs from the first one are retained, and to them are added those phrase pairs from the second one that are not present in the first one.', '', '']",5
"['third relevant line of research rext which for', 'our previous work #TAUTHOR_TAG experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of alltexts was', '', '']","['third relevant line of research reusing which for', 'our previous work #TAUTHOR_TAG experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all was', '', '']","['A third relevant line of research re which for', 'our previous work #TAUTHOR_TAG experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all bi-texts was', '', '']","['', 'For example , our previous work #TAUTHOR_TAG experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all bi-texts was English .', '', '']",1
"['', '', '', '', '', '', '', '', '', 'We found the same number using our previous approach #TAUTHOR_TAG , which is roughly equivalent to our core module .', 'Our approach with similar estimated productivity.']","['', '', '', '', '', '', '', '', '', 'We found the same number using our previous approach #TAUTHOR_TAG , which is roughly equivalent to our core module .', 'Our approach with similar estimated productivity.']","['', '', '', '', '', '', '', '', '', 'We found the same number using our previous approach #TAUTHOR_TAG , which is roughly equivalent to our core module .', 'Our approach with similar estimated productivity.']","['', '', '', '', '', '', '', '', '', 'We found the same number using our previous approach #TAUTHOR_TAG , which is roughly equivalent to our core module .', '']",2
"['We take some core ideas from our previous work on mining script information #TAUTHOR_TAG .', '', '', '', '', '']","['We take some core ideas from our previous work on mining script information #TAUTHOR_TAG .', '', '', '', '', '']","['We take some core ideas from our previous work on mining script information #TAUTHOR_TAG .', '', '', '', '', '']","['We take some core ideas from our previous work on mining script information #TAUTHOR_TAG .', '', '', '', '', '']",2
"['paraphrases are difficult to use tasks', '', '', '', '', '', '', 'Our own work #TAUTHOR_TAG extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .', 'gram', '']","['paraphrases are difficult to use tasks.', '', '', '', '', '', '', 'Our own work #TAUTHOR_TAG extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .', '', '']","[', sentential paraphrases are difficult to use', '', '', '', '', '', '', 'Our own work #TAUTHOR_TAG extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .', 'gram', '']","['', '', '', '', '', '', '', 'Our own work #TAUTHOR_TAG extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .', '', '']",2
"['Provided with the candidate fragment elements , we previously #TAUTHOR_TAG used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .', 'in the applying a dependency parser to constrain the boundary of the fragments (', '', '']","['Provided with the candidate fragment elements , we previously #TAUTHOR_TAG used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .', 'in the applying a dependency parser to constrain the boundary of the fragments', '', '']","['Provided with the candidate fragment elements , we previously #TAUTHOR_TAG used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .', 'in applying a dependency parser to constrain the boundary of the fragments (', '', '']","['Provided with the candidate fragment elements , we previously #TAUTHOR_TAG used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .', 'We extend this step in the current system by applying a dependency parser to constrain the boundary of the fragments (Sec.', '', '']",2
"['Similar to #TAUTHOR_TAG a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each ; and IL summar select the summary']","['Similar to #TAUTHOR_TAG a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each ; and ILP summarization select the summary']","['Similar to #TAUTHOR_TAG a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each sentence ; and select the best summary sentences']","['Similar to #TAUTHOR_TAG a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each sentence ; and then an ILP summarization method to select the best summary sentences from the multiple compressed sentences .']",1
"['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work #TAUTHOR_TAG where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .', 'Rather we showed that the quality of translation was markedly inferior, compared to overall translation quality, for sentences that were translated into multiple English sentences.', 'This over a.', '', '']","['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work #TAUTHOR_TAG where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .', 'Rather we showed that the quality of translation was markedly inferior, compared to overall translation quality, for sentences that were translated into multiple English sentences.', 'This over a sentence.', '', '']","['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work #TAUTHOR_TAG where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .', 'Rather we showed that the quality of translation was markedly inferior, compared to overall translation quality, for sentences that were translated into multiple English sentences.', 'over', '', '']","['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work #TAUTHOR_TAG where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .', 'Rather we showed that the quality of translation was markedly inferior, compared to overall translation quality, for sentences that were translated into multiple English sentences.', '', '', '']",1
"['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules #TAUTHOR_TAG .', 'tectogrammaticalctors are assigned by the C4.5ifier (2aboktsk']","['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules #TAUTHOR_TAG .', 'tectogrammatical functors are assigned by the C4.5 classifier (2abokrtsk9']","['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules #TAUTHOR_TAG .', 'tectogrammatical functors are assigned by the C4.5 classifier (2aboktsk']","['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules #TAUTHOR_TAG .', 'Subsequently, tectogrammatical functors are assigned by the C4.5 classifier (2abokrtsk9 et al., 2002).']",5
"['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors', 'We carried out two parallel experiments with two parsers available for Czech , parser I #AUTHOR_TAG and parser II #TAUTHOR_TAG .', '']","['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors.', 'We carried out two parallel experiments with two parsers available for Czech , parser I #AUTHOR_TAG and parser II #TAUTHOR_TAG .', '']","['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors.', 'We carried out two parallel experiments with two parsers available for Czech , parser I #AUTHOR_TAG and parser II #TAUTHOR_TAG .', '']","['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors.', 'We carried out two parallel experiments with two parsers available for Czech , parser I #AUTHOR_TAG and parser II #TAUTHOR_TAG .', '']",5
"['we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #TAUTHOR_TAG on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'entrytranslation pairs seen in the corpusJ become more probable', '', '']","['we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #TAUTHOR_TAG on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'entry/translation pairs seen in the corpus become more probable.', '', '']","['we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #TAUTHOR_TAG on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'the entry/translation pairs seen in the parallel corpusJ become more probable', '', '']","['To make the dictionary more sensitive to a specific domain, which is in our case the domain of financial news, we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #TAUTHOR_TAG on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'As a result, the entry/translation pairs seen in the parallel corpus of WSJ become more probable.', '', '']",5
"['', '', '', '', 'For the evaluation of the results we use the BLEU score #TAUTHOR_TAG .', '', '']","['', '', '', '', 'For the evaluation of the results we use the BLEU score #TAUTHOR_TAG .', '', '']","['', '', '', '', 'For the evaluation of the results we use the BLEU score #TAUTHOR_TAG .', '', '']","['', '', '', '', 'For the evaluation of the results we use the BLEU score #TAUTHOR_TAG .', '', '']",5
"['', '', '', '', '', '', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder #TAUTHOR_TAG , trained on the same parallel corpus .']","['', '', '', '', '', '', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder #TAUTHOR_TAG , trained on the same parallel corpus .']","['', '', '', '', '', '', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder #TAUTHOR_TAG , trained on the same parallel corpus .']","['', '', '', '', '', '', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder #TAUTHOR_TAG , trained on the same parallel corpus .']",1
"[""We evaluated our translations with IBM 's BLEU evaluation metric #TAUTHOR_TAG , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", 'We used four reference retranslations of 490 sentences fifth', 'each in against']","[""We evaluated our translations with IBM 's BLEU evaluation metric #TAUTHOR_TAG , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", 'We used four reference retranslations of 490 sentences fifth', 'each in against']","[""We evaluated our translations with IBM 's BLEU evaluation metric #TAUTHOR_TAG , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", 'We used four reference retranslations of 490 sentences', 'each reference in against']","[""We evaluated our translations with IBM 's BLEU evaluation metric #TAUTHOR_TAG , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", '', '']",5
"['', '', '', 'lex.', 'We performed translation experiments with an implementation of the IBM-4 translation model #TAUTHOR_TAG .', 'A description of the system can be found in #AUTHOR_TAG .', 'Table5 presents anish', '', '', '', '', '', '']","['', '', '', 'lexicon distribution.', 'We performed translation experiments with an implementation of the IBM-4 translation model #TAUTHOR_TAG .', 'A description of the system can be found in #AUTHOR_TAG .', 'Table 5 presents an', '', '', '', '', '', '']","['', '', '', '', 'We performed translation experiments with an implementation of the IBM-4 translation model #TAUTHOR_TAG .', 'A description of the system can be found in #AUTHOR_TAG .', 'Table 5 presents an assessmentish', '', '', '', '', '', '']","['', '', '', '', 'We performed translation experiments with an implementation of the IBM-4 translation model #TAUTHOR_TAG .', 'A description of the system can be found in #AUTHOR_TAG .', '', '', '', '', '', '', '']",5
"['The maximum entropy approach #TAUTHOR_TAG presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.', 'The distribution is required to satisfy constraints, which represent facts known from the data.', 'These constraints are expressed on the basis of feature functions hu,(s,t),']","['The maximum entropy approach #TAUTHOR_TAG presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.', 'The distribution is required to satisfy constraints, which represent facts known from the data.', 'These constraints are expressed on the basis of feature functions hu,(s,t),']","['The maximum entropy approach #TAUTHOR_TAG presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.', 'The distribution is required to satisfy constraints, which represent facts known from the data.', 'These constraints are expressed on the basis of feature functions hu,(s,t),']","['The maximum entropy approach #TAUTHOR_TAG presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.', 'The distribution is required to satisfy constraints, which represent facts known from the data.', 'These constraints are expressed on the basis of feature functions hu,(s,t),']",5
"['The input string be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string can be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string can be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']",0
"['where A = {Am } is the set of model parameters with one weight A, for each feature function hm', 'For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance #TAUTHOR_TAG or #AUTHOR_TAG .']","['where A = {Am } is the set of model parameters with one weight A, for each feature function hm', 'For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance #TAUTHOR_TAG or #AUTHOR_TAG .']","['where A = {Am } is the set of model parameters with one weight A, for each feature function hm .', 'For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance #TAUTHOR_TAG or #AUTHOR_TAG .']","['where A = {Am } is the set of model parameters with one weight A, for each feature function hm .', 'For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance #TAUTHOR_TAG or #AUTHOR_TAG .']",0
"['The input string be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string can be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']","['The input string can be preprocessed before being passed to the search algorithm.', 'If necessary, the inverse of these transformations will be applied to the generated output string.', 'In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example #TAUTHOR_TAG .']",0
"['Due to using a global model like CRFs , our previous work in #TAUTHOR_TAG c ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', 'Though those are better than results that the results of character-level parsing approach ( state-']","['Due to using a global model like CRFs , our previous work in #TAUTHOR_TAG c ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', 'Though those are better than results that the results of character-level parsing approach (Scheme']","['Due to using a global model like CRFs , our previous work in #TAUTHOR_TAG c ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', 'Though those results are slightly better than the results that the results of character-level dependency parsing approach (']","['Due to using a global model like CRFs , our previous work in #TAUTHOR_TAG c ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', '']",1
"['1 The representation in #TAUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'we use our an intermediate in approximating an unrestricted context-free grammar with autom.', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]","['1 The representation in #TAUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'we use our an intermediate in approximating an unrestricted context-free grammar, with automaton.', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]","['1 The representation in #TAUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'we use our an intermediate result in approximating an unrestricted context-free grammar, with', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]","['1 The representation in #TAUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'However, in this paper we use our representation as an intermediate result in approximating an unrestricted context-free grammar, with the final objective of obtaining a single minimal deterministic automaton.', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]",1
"['By restricting height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and was rediscovered by #AUTHOR_TAG and recently by #TAUTHOR_TAG .', 'treatment the historical of method']","['By restricting height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and was rediscovered by #AUTHOR_TAG and recently by #TAUTHOR_TAG .', 'treatment the historical of method.']","['By restricting the height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and was rediscovered by #AUTHOR_TAG and recently by #TAUTHOR_TAG .', 'treatment the historical roots of']","['By restricting the height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and was rediscovered by #AUTHOR_TAG and recently by #TAUTHOR_TAG .', '']",0
"['We rephrase the method of #TAUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', '', '', '']","['We rephrase the method of #TAUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', '', '', '']","['We rephrase the method of #TAUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', '', '', '']","['We rephrase the method of #TAUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', '', '', '']",5
"['This method can be generalized , inspired by #TAUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', 'By ignoring the probabilities, each N = 1, 2, 3 .... gives rise to a superset approximation that can be described as follows: The set of strings derivable from a nonterminal A is approximated by the set of strings al that']","['This method can be generalized , inspired by #TAUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', 'By ignoring the probabilities, each N = 1, 2, 3 .... gives rise to a superset approximation that can be described as follows: The set of strings derivable from a nonterminal A is approximated by the set of strings al that']","['This method can be generalized , inspired by #TAUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', 'By ignoring the probabilities, each N = 1, 2, 3 .... gives rise to a superset approximation that can be described as follows: The set of strings derivable from a nonterminal A is approximated by the set of strings al that']","['This method can be generalized , inspired by #TAUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', '']",0
['See #TAUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],['See #TAUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],['See #TAUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],['See #TAUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],0
"['', '', '', 'considering this eliminates selfding is purely prag of the we have tried thatont approximations, this has the lowest complexity in terms of the sizes of intermediate structures and of the resulting finite automata', 'The full formulation of the integrated grammar transformation and construction of the finite automaton is rather long and is therefore not given here.', 'A very similar formulation , for another grammar transformation , is given in #TAUTHOR_TAG .']","['', '', '', 'considering this eliminates self-embedding is purely pragmatic: of the we have tried that approximations, this has the lowest complexity in terms of the sizes of intermediate structures and of the resulting finite automata.In', 'full formulation of the integrated grammar transformation and construction of the finite automaton is rather long and is therefore not given here.', 'A very similar formulation , for another grammar transformation , is given in #TAUTHOR_TAG .']","['', '', '', 'considering this transformation eliminates selfding is purely prag of we have tried thatontrivial subset approximations, this transformation has the lowest complexity in terms of the sizes of intermediate structures and of the resulting finite automata', 'The full formulation of the integrated grammar transformation and construction of the finite automaton is rather long and is therefore not given here.', 'A very similar formulation , for another grammar transformation , is given in #TAUTHOR_TAG .']","['', '', '', '', '', 'A very similar formulation , for another grammar transformation , is given in #TAUTHOR_TAG .']",1
"['in and employed in expert,-based', '(', 'these rules are by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by #AUTHOR_TAG , Mc #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['in and employed in expert, knowledge-based', '(Post', 'these rules are by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by #AUTHOR_TAG , Mc #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['in and employed in expert', '(', 'these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by #AUTHOR_TAG , Mc #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['', '', 'Conventionally, these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by #AUTHOR_TAG , Mc #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']",0
"['It is also conceivable that data-driven techniques can actually outperform traditional rules.', ', this possibility is not usually given much credence.', ""For instance , #TAUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) ."", '520).', 'this stating ""such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as by poor transcription scores"" (p.', '115 note 4).']","['It is also conceivable that data-driven techniques can actually outperform traditional rules.', 'However, this possibility is not usually given much credence.', ""For instance , #TAUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) ."", '520).', 'this stating ""such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as by poor transcription scores"" (p.', '115, note 14).']","['It is also conceivable that data-driven techniques can actually outperform traditional rules.', ', this possibility is not usually given much credence.', ""For instance , #TAUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) ."", '520).', 'this further, stating ""such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as by poor transcription scores"" (p.', '115, note 14).']","['It is also conceivable that data-driven techniques can actually outperform traditional rules.', 'However, this possibility is not usually given much credence.', ""For instance , #TAUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) ."", '520).', ' #AUTHOR_TAG takes this further, stating ""such training-based strategies are often assumed to exhibit much more intelligence than they do in practice, as revealed by their poor transcription scores"" (p.', '115, note 14).']",0
"['', '', 'See also the work of #TAUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .', '']","['', '', 'See also the work of #TAUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .', '']","['', '', 'See also the work of #TAUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .', '']","['', '', 'See also the work of #TAUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .', '']",0
"['the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #TAUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .', '', '', '']","['the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #TAUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .', '', '', '']","['the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #TAUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .', '', '', '']","['Clearly, the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #TAUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .', '', '', '']",0
"['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #TAUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']","['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #TAUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']","['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #TAUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']","['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #TAUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']",0
"['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #TAUTHOR_TAG b ) .', 'These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution.', 'review these Table 1.']","['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #TAUTHOR_TAG b ) .', 'These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution.', 'review these Table 1.']","['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #TAUTHOR_TAG b ) .', 'These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution.', 'Table 1.']","['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #TAUTHOR_TAG b ) .', 'These models involve conditional probabilities, but they can be compared to symmetric models if the latter are normalized by the appropriate marginal distribution.', '']",0
"['The probability distribution trans (.1, ~) is a word-to-word translation model.', 'Unlike the models proposed by #TAUTHOR_TAG b ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', ""Brown and his colleagues' models, 4.3, generate bitext given other hall so"", '']","['The probability distribution trans (.1, ~) is a word-to-word translation model.', 'Unlike the models proposed by #TAUTHOR_TAG b ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', ""Brown and his colleagues' models, 4.3, generate bitext given other hall so"", '']","['The probability distribution trans (.1, ~) is a word-to-word translation model.', 'Unlike the models proposed by #TAUTHOR_TAG b ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', ""Brown and his colleagues' models, Section 4.3, generate one the bitext given the other hall so"", '']","['The probability distribution trans (.1, ~) is a word-to-word translation model.', 'Unlike the models proposed by #TAUTHOR_TAG b ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', '', '']",1
"['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag #TAUTHOR_TAG , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !"", 'Method B exploits this property under the hypothesis that ""one sense per collocation"" holds for translational collocations.', 'This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u,) was generated from the concept and should be', '', '', '']","['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag #TAUTHOR_TAG , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !"", 'Method B exploits this property under the hypothesis that ""one sense per collocation"" holds for translational collocations.', 'This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u, v) was generated from the concept and should be', '', '', '']","['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag #TAUTHOR_TAG , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !"", 'Method B exploits this property under the hypothesis that ""one sense per collocation"" holds for translational collocations.', 'This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u, v) was generated from the same concept and should be', '', '', '']","['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag #TAUTHOR_TAG , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !"", 'Method B exploits this property under the hypothesis that ""one sense per collocation"" holds for translational collocations.', 'This hypothesis implies that if u and v are possible mutual translations, and a token u co-occurs with a token v in the bitext, then with very high probability the pair (u, v) was generated from the same concept and should be linked.', '', '', '']",5
"['In informal experiments described elsewhere #TAUTHOR_TAG , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere #TAUTHOR_TAG , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere #TAUTHOR_TAG , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere #TAUTHOR_TAG , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']",2
"['¢ cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #TAUTHOR_TAG , â\x80¢ certain machine-assisted translation tools ( e.g. , Mackitch 1994 ; Melamed 1996a ) ,¢']","['cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #TAUTHOR_TAG , â\x80¢ certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) ,']","['¢ cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #TAUTHOR_TAG , â\x80¢ certain machine-assisted translation tools ( e.g. , Mackitch 1994 ; Melamed 1996a ) ,¢']","['â\x80¢ cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #TAUTHOR_TAG , â\x80¢ certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) , â\x80¢ concordancing for bilingual lexicography ( e.g. , Catizone , Russell , and Warwick 1989 ; Gale and Church 1991 ) ,']",0
"[""In this situation , #TAUTHOR_TAG b , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']","[""In this situation , #TAUTHOR_TAG b , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']","[""In this situation , #TAUTHOR_TAG b , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']","[""In this situation , #TAUTHOR_TAG b , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']",4
"['estimation aux only', '', '', 'frequent are translated less than rare (Catizone,, andwick ', 'we', 'aux', 'effect aux linked word.', 'Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #TAUTHOR_TAG .', 'Brown et al. 1993).', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = classu, v)) = log B((u, v)[coocu), z)"" (3)6']","['estimation auxiliary only', '', '', 'frequent are translated less than rare (Catizone, Russell, and Warwick', 'we', 'auxiliary', 'effected auxiliary linked word texts.', 'Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #TAUTHOR_TAG .', 'Brown et al. 1993).', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = class(u, v)) = log B(links(u, v)[cooc(u, v), z)"" (37)']","['the estimation only', '', '', 'are translated less consistently than rare words (Catizone,, and', '', '', 'linked word tokens', 'Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #TAUTHOR_TAG .', 'Brown et al. 1993).', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = classu, v)) = log B((u, v)[coocu, v), A z)"" (3']","['', '', '', 'For example, frequent words are translated less consistently than rare words (Catizone, Russell, and Warwick 1989).', '', '', '', 'Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #TAUTHOR_TAG .', 'Brown et al. 1993).', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = class(u, v)) = log B(links(u, v)[cooc(u, v), A z)"" (37) Section 6.1.1 describes the link classes used in the experiments below.']",5
"[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models #TAUTHOR_TAG b ) ."", 'Objective and more accurate tests can be carried out using a ""gold', 'an', '', '', '', '']","[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models #TAUTHOR_TAG b ) ."", 'Objective and more accurate tests can be carried out using a ""gold', '', '', '', '', '']","[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models #TAUTHOR_TAG b ) ."", 'Objective and more accurate tests can be carried out using a ""gold standard.""', '', '', '', '', '']","[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models #TAUTHOR_TAG b ) ."", 'Objective and more accurate tests can be carried out using a ""gold standard.""', '', '', '', '', '']",1
"['In informal experiments described elsewhere ( Melamed 1995 I found that the G2 statistic suggested by #TAUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere ( Melamed 1995 I found that the G2 statistic suggested by #TAUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere ( Melamed 1995 I found that the G2 statistic suggested by #TAUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']","['In informal experiments described elsewhere ( Melamed 1995 ) , I found that the G2 statistic suggested by #TAUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']",0
"['The above equation holds regardless of how we represent concepts.', 'There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #TAUTHOR_TAG , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .', '']","['The above equation holds regardless of how we represent concepts.', 'There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #TAUTHOR_TAG , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .', '']","['The above equation holds regardless of how we represent concepts.', 'There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #TAUTHOR_TAG , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .', '']","['The above equation holds regardless of how we represent concepts.', 'There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #TAUTHOR_TAG , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .', '']",0
"['â\x80¢ cross-language information retrieval ( e.g. , #TAUTHOR_TAG , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al.1997 ) ,¢ certain machine-assisted tools ( Mackitch  ; Melamed 19']","['â\x80¢ cross-language information retrieval ( e.g. , #TAUTHOR_TAG , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al. 1997 ) , certain machine-assisted tools ( Macklovitch ; Melamed 1996a']","['â\x80¢ cross-language information retrieval ( e.g. , #TAUTHOR_TAG , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al.1997 ) ,¢ certain machine-assisted translation tools ( Mack ; Melamed 1996a']","['â\x80¢ cross-language information retrieval ( e.g. , #TAUTHOR_TAG , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al. 1997 ) , â\x80¢ certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) , â\x80¢ concordancing for bilingual lexicography ( e.g. , Catizone , Russell , and Warwick 1989 ; Gale and Church 1991 ) ,']",0
"[""Many other such cases are described in Danlos 's book #TAUTHOR_TAG ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.', 'This is largely due to the fact that pipelined systems cannot perform general search over a decision space that includes decisions made in more than one module.']","[""Many other such cases are described in Danlos 's book #TAUTHOR_TAG ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.', 'This is largely due to the fact that pipelined systems cannot perform general search over a decision space that includes decisions made in more than one module.']","[""Many other such cases are described in Danlos 's book #TAUTHOR_TAG ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.', 'This is largely due to the fact that pipelined systems cannot perform general search over a decision space that includes decisions made in more than one module.']","[""Many other such cases are described in Danlos 's book #TAUTHOR_TAG ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.', 'This is largely due to the fact that pipelined systems cannot perform general search over a decision space that includes decisions made in more than one module.']",0
"['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems #TAUTHOR_TAG .']","['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems #TAUTHOR_TAG .']","['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems #TAUTHOR_TAG .']","['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems #TAUTHOR_TAG .']",0
"['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #TAUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mittal et.9).']","['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #TAUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mittal et al.']","['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #TAUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mitt']","['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #TAUTHOR_TAG and #AUTHOR_TAG .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mittal et al. 1998).']",0
"['', '', 'approach has at its center a le #AUTHOR_TAG', 'Thex is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model #TAUTHOR_TAG .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']","['', '', 'approach has at its center a #AUTHOR_TAG', 'The is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model #TAUTHOR_TAG .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']","['', '', 'has at its center a lexicon #AUTHOR_TAG .', 'The lexicon is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model #TAUTHOR_TAG .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']","['', '', '', 'The lexicon is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model #TAUTHOR_TAG .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']",0
"['lyskyalle `` #AUTHOR_TAG contextensitive SPE [ be replaced by a much simpler one , based on finite-state transducers ( FSTs ) ; the same conclusion was reached independently by Kaplan and Kay , whose work remained an underground classic until it was finally published in #TAUTHOR_TAG .', 'These-level the Xerox rule (al', 'now dominant tools in JapanesexAc reducing morph', '']","['Shortly Halle `` #AUTHOR_TAG context-sensitive SPE [ be replaced by a much simpler one , based on finite-state transducers ( FSTs ) ; the same conclusion was reached independently by Kaplan and Kay , whose work remained an underground classic until it was finally published in #TAUTHOR_TAG .', 'These two-level the Xerox rule', 'now dominant tools in Japanese reducing morphological', '']","['lysky `` #AUTHOR_TAG SPE [ could ] be replaced by a much simpler one , based on finite-state transducers ( FSTs ) ; the same conclusion was reached independently by Kaplan and Kay , whose work remained an underground classic until it was finally published in #TAUTHOR_TAG .', 'These works- the Xerox rule compiler (al', 'are now dominant tools inAc', '']","['', '', '', '']",0
"['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #TAUTHOR_TAG b ) is of course an empirical question .']","['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #TAUTHOR_TAG b ) is of course an empirical question .']","['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #TAUTHOR_TAG b ) is of course an empirical question .']","['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #TAUTHOR_TAG b ) is of course an empirical question .']",0
"['', 'In some cases rankings may work well enough.', ' #TAUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 Moreulatively , imagine an OT grammar forlistic revision of parsed sentences', '', '', '', '', '']","['', 'In some cases rankings may work well enough.', ' #TAUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 More speculatively , imagine an OT grammar for stylistic revision of parsed sentences', '', '', '', '', '']","['', 'In some cases rankings may work well enough.', ' #TAUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 Moreulatively , imagine an OT grammar forlistic revision of parsed sentences .', '', '', '', '', '']","['', 'In some cases rankings may work well enough.', ' #TAUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 More speculatively , imagine an OT grammar for stylistic revision of parsed sentences .', '', '', '', '', '']",0
"['hidden', 'functions', 'typical OT grammars offer much richer finite-state models of left context #TAUTHOR_TAG a ) than provided by the traditional HMM finite-state topologies', '', '', '']","['hidden', 'functions', 'typical OT grammars offer much richer finite-state models of left context #TAUTHOR_TAG a ) than provided by the traditional HMM finite-state topologies', '', '', '']","['hidden', 'functions', 'typical OT grammars offer much richer finite-state models of left context #TAUTHOR_TAG a ) than provided by the traditional HMM finite-state topologies .', '', '', '']","['', '', 'But typical OT grammars offer much richer finite-state models of left context #TAUTHOR_TAG a ) than provided by the traditional HMM finite-state topologies .', '', '', '']",0
"['', 'a', '', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993"", ' #TAUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']","['', 'a', '', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993)."", ' #TAUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']","['', '', '', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993"", ' #TAUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']","['', '', '', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993)."", ' #TAUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']",0
"['we want to retain legomena with a 2 compute the corresponding significance ands exact test', '', '', '', '', '', 's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests).', ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure #TAUTHOR_TAG :""]","['we want to retain legomena with a 2-0 compute the corresponding significance and exact test', '', '', '', '', '', 'exact test leads to a slightly better recall with the same precision scores (0.31 for both tests).', ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure #TAUTHOR_TAG :""]","['we want to retain dis legomena with compute the corresponding significance levels ands exact test', '', '', '', '', '', 'exact test leads to a slightly better recall with the same precision scores (0.31 for both tests).', ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure #TAUTHOR_TAG :""]","['', '', '', '', '', '', ""For the higherfrequency words, Fisher's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests)."", ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure #TAUTHOR_TAG :""]",0
"['ofmar is measured', '', '', '(', 'For example , #TAUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 500000000000000000500000000000000500000000000500000000500 ,', '', '', '', '']","['of grammar is measured', '', '', '(or', 'For example , #TAUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 5000000000000000005000000000000005000000000005000000005000 ,', '', '', '', '']","['of is measured', '', '', '(', 'For example , #TAUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 5000000000000000005000000000000005000000000005000000005000 ,', '', '', '', '']","['', '', '', '', 'For example , #TAUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 5000000000000000005000000000000005000000000005000000005000 , are not context-free , which implies that Chinese is not a context-free language and thus might parse in exponential worst-case time .', '', '', '', '']",0
"['', '', '', '', 'For some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes #TAUTHOR_TAG .', 'This parser produces trees to represent the structure of the sentences that compose the text.', 'However is set to ""skip"" or surrender attempts to parse clauses after reaching a time-out threshold.', 'When the parser sk parse', '']","['', '', '', '', 'For some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes #TAUTHOR_TAG .', 'This parser produces trees to represent the structure of the sentences that compose the text.', 'However, is set to ""skip"" or surrender attempts to parse clauses after reaching a time-out threshold.', 'When the parser parse', '']","['', '', '', '', 'For some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes #TAUTHOR_TAG .', 'This parser produces trees to represent the structure of the sentences that compose the text.', 'However it is set to ""skip"" or surrender attempts to parse clauses after reaching a time-out threshold.', 'When the parser skips,', '']","['', '', '', '', 'For example , some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes #TAUTHOR_TAG .', 'This parser produces trees to represent the structure of the sentences that compose the text.', 'However, it is set to ""skip"" or surrender attempts to parse clauses after reaching a time-out threshold.', '', '']",0
"['ari', 'this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection #TAUTHOR_TAG b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']","['', 'this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection #TAUTHOR_TAG b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']","['', 'Using this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection #TAUTHOR_TAG b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']","['', 'Using this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection #TAUTHOR_TAG b ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']",0
"['The algorithm we implemented is inspired by the work of #TAUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.', ' #AUTHOR_TAG']","['The algorithm we implemented is inspired by the work of #TAUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.', ' #AUTHOR_TAG']","['The algorithm we implemented is inspired by the work of #TAUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.', ' #AUTHOR_TAG']","['The algorithm we implemented is inspired by the work of #TAUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.', ' #AUTHOR_TAG']",4
"['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #TAUTHOR_TAG , page 75 ) .', '', '']","['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #TAUTHOR_TAG , page 75 ) .', '', '']","['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #TAUTHOR_TAG , page 75 ) .', '', '']","['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #TAUTHOR_TAG , page 75 ) .', '', '']",4
"['', '', '', '', 'and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work #TAUTHOR_TAG a ) , while being more than an order of magnitude faster .']","['', '', '', '', 'and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work #TAUTHOR_TAG a ) , while being more than an order of magnitude faster .']","['', '', '', '', 'and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work #TAUTHOR_TAG a ) , while being more than an order of magnitude faster .']","['', '', '', '', 'For the joint segmentation and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work #TAUTHOR_TAG a ) , while being more than an order of magnitude faster .']",1
"['Previously #TAUTHOR_TAG , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']","['Previously #TAUTHOR_TAG , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']","['Previously #TAUTHOR_TAG , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']","['Previously #TAUTHOR_TAG , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']",2
"['', '', 'This evaluation set-up is an improvement versus the one we previously reported #TAUTHOR_TAG , in which fixed partitions were used for training , development , and testing .']","['', '', 'This evaluation set-up is an improvement versus the one we previously reported #TAUTHOR_TAG , in which fixed partitions were used for training , development , and testing .']","['', '', 'This evaluation set-up is an improvement versus the one we previously reported #TAUTHOR_TAG , in which fixed partitions were used for training , development , and testing .']","['', '', 'This evaluation set-up is an improvement versus the one we previously reported #TAUTHOR_TAG , in which fixed partitions were used for training , development , and testing .']",2
"['We now give an overview of the training algorithm, which is crucial to both the speed and accuracy of the resulting decoder.', 'CCGBank #TAUTHOR_TAG is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.', 'All other hypotheses that can be constructed from the same bag of words are non-gold hypotheses.', '', '']","['We now give an overview of the training algorithm, which is crucial to both the speed and accuracy of the resulting decoder.', 'CCGBank #TAUTHOR_TAG is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.', 'All other hypotheses that can be constructed from the same bag of words are non-gold hypotheses.', '', '']","['We now give an overview of the training algorithm, which is crucial to both the speed and accuracy of the resulting decoder.', 'CCGBank #TAUTHOR_TAG is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.', 'All other hypotheses that can be constructed from the same bag of words are non-gold hypotheses.', '', '']","['We now give an overview of the training algorithm, which is crucial to both the speed and accuracy of the resulting decoder.', 'CCGBank #TAUTHOR_TAG is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.', 'All other hypotheses that can be constructed from the same bag of words are non-gold hypotheses.', '', '']",5
"['', '', '', '', '', '', '', '', 'In our previous papers #TAUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010', '', '']","['', '', '', '', '', '', '', '', 'In our previous papers #TAUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010', '', '']","['', '', '', '', '', '', '', '', 'In our previous papers #TAUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010', '', '']","['', '', '', '', '', '', '', '', 'In our previous papers #TAUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 ) , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010 ) .', '', '']",1
"['', '', '', '', '', '', '', 'This was done by MERT optimization #TAUTHOR_TAG towards post-edits under the TER target metric .', '', '', '', '']","['', '', '', '', '', '', '', 'This was done by MERT optimization #TAUTHOR_TAG towards post-edits under the TER target metric .', '', '', '', '']","['', '', '', '', '', '', '', 'This was done by MERT optimization #TAUTHOR_TAG towards post-edits under the TER target metric .', '', '', '', '']","['', '', '', '', '', '', '', 'This was done by MERT optimization #TAUTHOR_TAG towards post-edits under the TER target metric .', '', '', '', '']",5
"['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set #TAUTHOR_TAG .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on un to', '', '', '', '', '', '', '', '', '']","['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set #TAUTHOR_TAG .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on unseen to', '', '', '', '', '', '', '', '', '']","['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set #TAUTHOR_TAG .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on un to', '', '', '', '', '', '', '', '', '']","['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set #TAUTHOR_TAG .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on unseen data we would like to bound.', '', '', '', '', '', '', '', '', '']",1
"['', '', 'prepare SMT creators corpus used their own WMT10 system #AUTHOR_TAG , based on the Moses phrase-based decoder #TAUTHOR_TAG with dense features .', 'similar system using theolingual and parallel data 5 Ken', '', '', '', '', '', '', '']","['', '', 'prepare SMT creators corpus used their own WMT10 system #AUTHOR_TAG , based on the Moses phrase-based decoder #TAUTHOR_TAG with dense features .', 'similar system using the monolingual and parallel data: 5-gram KenLM', '', '', '', '', '', '', '']","['', '', 'prepare SMT outputs the creators the corpus used their own WMT10 system #AUTHOR_TAG , based on the Moses phrase-based decoder #TAUTHOR_TAG with dense features .', 'a similar Moses system using theolingual and parallel data:', '', '', '', '', '', '', '']","['', '', 'To prepare SMT outputs for post-editing , the creators of the corpus used their own WMT10 system #AUTHOR_TAG , based on the Moses phrase-based decoder #TAUTHOR_TAG with dense features .', '', '', '', '', '', '', '', '']",5
"['In contrast , a single statistical model allows one to maintain a single table #TAUTHOR_TAG .']","['In contrast , a single statistical model allows one to maintain a single table #TAUTHOR_TAG .']","['In contrast , a single statistical model allows one to maintain a single table #TAUTHOR_TAG .']","['In contrast , a single statistical model allows one to maintain a single table #TAUTHOR_TAG .']",0
['IGEN uses standard chart generation techniques #TAUTHOR_TAG in its base generator to efficiently produce generation candidates .'],['IGEN uses standard chart generation techniques #TAUTHOR_TAG in its base generator to efficiently produce generation candidates .'],['IGEN uses standard chart generation techniques #TAUTHOR_TAG in its base generator to efficiently produce generation candidates .'],['IGEN uses standard chart generation techniques #TAUTHOR_TAG in its base generator to efficiently produce generation candidates .'],0
"[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain #TAUTHOR_TAG .""]","[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain #TAUTHOR_TAG .""]","[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain #TAUTHOR_TAG .""]","[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain #TAUTHOR_TAG .""]",0
['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of #AUTHOR_TAG ) #TAUTHOR_TAG a ) .'],['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of #AUTHOR_TAG ) #TAUTHOR_TAG a ) .'],['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of #AUTHOR_TAG ) #TAUTHOR_TAG a ) .'],['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of #AUTHOR_TAG ) #TAUTHOR_TAG a ) .'],0
"['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in #TAUTHOR_TAG b ) .']","['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in #TAUTHOR_TAG b ) .']","['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in #TAUTHOR_TAG b ) .']","['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in #TAUTHOR_TAG b ) .']",0
"[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent #TAUTHOR_TAG .""]","[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent #TAUTHOR_TAG .""]","[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent #TAUTHOR_TAG .""]","[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent #TAUTHOR_TAG .""]",0
"['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, ']","['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, 2']","['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, v 2']","['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, v 2 is the second most likely interpretation, etc.).']",5
"['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #TAUTHOR_TAG and the references therein ) .']","['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #TAUTHOR_TAG and the references therein ) .']","['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #TAUTHOR_TAG and the references therein ) .']","['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #TAUTHOR_TAG and the references therein ) .']",0
"['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature #TAUTHOR_TAG .', 'randomly sampled adjectives (difficult slow,', 'ject to unous ""', '', '', '', '', '', '', '', 'frequency (diff v estimated only on the basis of infinit constructions (see ( 7', '']","['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature #TAUTHOR_TAG .', 'randomly sampled adjectives (difficult, slow,', 'to unambiguous', '', '', '', '', '', '', '', 'frequency (difficult, v) estimated only on the basis of infinitival constructions (see ( 17)).', '']","['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature #TAUTHOR_TAG .', 'we randomly sampled nine adjectives (difficult', 'to unous ""', '', '', '', '', '', '', '', '(diff was estimated only on the basis of infinitival constructions (see ( 7', '']","['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly selected from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '', 'As a result, the frequency f (difficult, v) was estimated only on the basis of infinitival constructions (see ( 17)).', '']",5
"['', '', '', '', '', '', '', '.', ' #TAUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', 'ej treatsouns as having a qualia structure as part of theirx entries', 'structure for has a equivalent', '', '', '', '']","['', '', '', '', '', '', '', 'eat.', ' #TAUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', 'treats nouns as having a qualia structure as part of their entries,', 'structure for has a equivalent', '', '', '', '']","['', '', '', '', '', '', '', '.', ' #TAUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', 'ej treats nouns as having a qualia structure as part of theirx', 'for has a value equivalent', '', '', '', '']","['', '', '', '', '', '', '', '', ' #TAUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', '', '', '', '', '', '']",0
"['We have presented an ensemble approach to word sense disambiguation #TAUTHOR_TAG where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']","['We have presented an ensemble approach to word sense disambiguation #TAUTHOR_TAG where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']","['We have presented an ensemble approach to word sense disambiguation #TAUTHOR_TAG where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']","['We have presented an ensemble approach to word sense disambiguation #TAUTHOR_TAG where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']",0
['See #TAUTHOR_TAG for a discussion .'],['See #TAUTHOR_TAG for a discussion .'],['See #TAUTHOR_TAG for a discussion .'],['See #TAUTHOR_TAG for a discussion .'],0
['Other definitions of predicates may be found in #TAUTHOR_TAG .'],['Other definitions of predicates may be found in #TAUTHOR_TAG .'],['Other definitions of predicates may be found in #TAUTHOR_TAG .'],['Other definitions of predicates may be found in #TAUTHOR_TAG .'],0
"['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #TAUTHOR_TAG .']","['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #TAUTHOR_TAG .']","['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #TAUTHOR_TAG .']","['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #TAUTHOR_TAG .']",1
['The task we used to compare different generalisation techniques is similar to that used by #TAUTHOR_TAG and #AUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #TAUTHOR_TAG and #AUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #TAUTHOR_TAG and #AUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #TAUTHOR_TAG and #AUTHOR_TAG .'],1
"['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important #TAUTHOR_TAG .']","['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important #TAUTHOR_TAG .']","['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important #TAUTHOR_TAG .']","['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important #TAUTHOR_TAG .']",4
"['However , #TAUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']","['However , #TAUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']","['However , #TAUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']","['However , #TAUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']",4
['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and #TAUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and #TAUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and #TAUTHOR_TAG .'],['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and #TAUTHOR_TAG .'],1
"['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #TAUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']","['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #TAUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']","['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #TAUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']","['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #TAUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']",1
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]",1
"['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #TAUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']","['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #TAUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']","['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #TAUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']","['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #TAUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']",0
"['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice #TAUTHOR_TAG , whose specifier is the external argument .', '']","['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice #TAUTHOR_TAG , whose specifier is the external argument .', '']","['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice #TAUTHOR_TAG , whose specifier is the external argument .', '']","['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice #TAUTHOR_TAG , whose specifier is the external argument .', '']",0
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]",1
"['In this paper , I present a computational implementation of Distributed Morphology #TAUTHOR_TAG , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']","['In this paper , I present a computational implementation of Distributed Morphology #TAUTHOR_TAG , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']","['In this paper , I present a computational implementation of Distributed Morphology #TAUTHOR_TAG , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']","['In this paper , I present a computational implementation of Distributed Morphology #TAUTHOR_TAG , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']",5
"['A commonxical semantic representation in the computational linguistics literature is a frame-based model where syntactic are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #AUTHOR_TAG and PropBank #TAUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over arguments.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #AUTHOR_TAG and PropBank #TAUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #AUTHOR_TAG and PropBank #TAUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over their arguments.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #AUTHOR_TAG and PropBank #TAUTHOR_TAG .""]",0
"['In #TAUTHOR_TAG , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']","['In #TAUTHOR_TAG , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']","['In #TAUTHOR_TAG , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']","['In #TAUTHOR_TAG , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']",2
"['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']",0
"['', '', 'a set of features and a small number ofxical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a #TAUTHOR_TAG style analysis', '']","['', '', 'a set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a #TAUTHOR_TAG style analysis', '']","['', '', 'a minimal set of features and a small number ofxical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a #TAUTHOR_TAG style analysis .', '']","['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a #TAUTHOR_TAG style analysis .', '']",0
"['Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Unders, activities and states both depict situations that are inherently temporally unbounded (atelic); states static situations, whereas activities denote on-going dynamic situations.', 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (tic); achievements are punctual, whereas accomplishments extend a period of time.', ' #TAUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']","['Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Under classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states static situations, whereas activities denote on-going dynamic situations.', 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (telic); achievements are punctual, whereas accomplishments extend a period of time.', ' #TAUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']","['Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Unders classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states static situations, whereas activities denote on-going dynamic situations.', 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (tic); achievements are punctual, whereas accomplishments extend a period of time.', ' #TAUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']","[""Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Under Vendler's classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states denote static situations, whereas activities denote on-going dynamic situations."", 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (telic); achievements are punctual, whereas accomplishments extend over a period of time.', ' #TAUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']",0
"['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #TAUTHOR_TAG using a #AUTHOR_TAG style analysis .', '']","['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #TAUTHOR_TAG using a #AUTHOR_TAG style analysis .', '']","['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #TAUTHOR_TAG using a #AUTHOR_TAG style analysis .', '']","['', '', 'With a minimal set of features and a small number of lexical entries , #AUTHOR_TAG has successfully modeled many of the argument alternations described by #TAUTHOR_TAG using a #AUTHOR_TAG style analysis .', '']",0
"['', '', 'compos derivedhe', ""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #TAUTHOR_TAG a ) , among many others ."", 'Note that such an approach is no longer lexicalist: each lexical semantic structures.', '']","['', '', 'compositionally derived', ""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #TAUTHOR_TAG a ) , among many others ."", 'Note that such an approach is no longer lexicalist: each lexical semantic structures.', '']","['', '', 'derived', ""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #TAUTHOR_TAG a ) , among many others ."", 'Note that such an approach is no longer lexicalist: each lexical item semantic structures.', '']","['', '', '', ""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #TAUTHOR_TAG a ) , among many others ."", 'Note that such an approach is no longer lexicalist: each lexical item does not fully encode its associated syntactic and semantic structures.', '']",0
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]","['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program #TAUTHOR_TAG .""]",1
"['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #TAUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'izing heads introduce relevant eventive interpretations in the syntax and correspond to (assumed) universal primitives of the human cognitive system.', 'abstract (categoryless) concepts and basically correspond to- items drawn from encyclopedic.', '']","['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #TAUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system.', 'abstract (categoryless) concepts and basically correspond to items drawn from encyclopedic knowledge.', '']","['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #TAUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'izing heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system.', 'abstract (categoryless) concepts and basically correspond to-class items drawn from encyclopedic knowledge.', '']","['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #TAUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'Verbalizing heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system.', 'On the other hand, verbal roots represent abstract (categoryless) concepts and basically correspond to open-class items drawn from encyclopedic knowledge.', '']",5
"['A commonxical semantic representation in the computational linguistics is a frame-based model where syntactic are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed simple predicates over.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #TAUTHOR_TAG and PropBank #AUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics is a frame-based model where syntactic are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed simple predicates over arguments.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #TAUTHOR_TAG and PropBank #AUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed simple predicates over.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #TAUTHOR_TAG and PropBank #AUTHOR_TAG .""]","['A common lexical semantic representation in the computational linguistics literature is a frame-based model where syntactic arguments are associated with various semantic roles (essentially frame slots).', 'Verbs are viewed as simple predicates over their arguments.', ""This approach has its roots in Fillmore 's #AUTHOR_TAG , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet #TAUTHOR_TAG and PropBank #AUTHOR_TAG .""]",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']",0
"['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']","['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques #TAUTHOR_TAG , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #TAUTHOR_TAG b ; #AUTHOR_TAG .', 'Consider the following example:']",0
"[' #TAUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .', 'I have adapted for needs and developed grammar fragments that reflect my non-lexicalist semantic framework', '""The flattened."" is shown in Figure .']","[' #TAUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .', 'I have adapted for needs and developed grammar fragments that reflect my non-lexicalist semantic framework.', '""The flattened."" is shown in Figure 1.']","[' #TAUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .', 'I have adapted for needs and developed grammar fragments that reflect my non-lexicalist semantic framework.', 'the sentence ""The tire flattened."" is shown in Figure 1.']","[' #TAUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .', 'I have adapted it for my needs and developed grammar fragments that reflect my non-lexicalist semantic framework.', '']",2
"['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns #TAUTHOR_TAG , possibly arranged in an inheritance hierarchy .', 'The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class.', 'lex']","['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns #TAUTHOR_TAG , possibly arranged in an inheritance hierarchy .', 'The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class.', 'lexical']","['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns #TAUTHOR_TAG , possibly arranged in an inheritance hierarchy .', 'The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class.', '']","['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns #TAUTHOR_TAG , possibly arranged in an inheritance hierarchy .', 'The argument structure and syntax-tosemantics mapping would then only need to be specified once for each verb class.', '']",1
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #AUTHOR_TAG b ; Rappaport #TAUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #AUTHOR_TAG b ; Rappaport #TAUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #AUTHOR_TAG b ; Rappaport #TAUTHOR_TAG .', 'Consider the following example:']","['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity #AUTHOR_TAG b ; Rappaport #TAUTHOR_TAG .', 'Consider the following example:']",0
"['Dowty breaks the event described by (2) into two subevents, the activity ofeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by #AUTHOR_TAG , describes a basic set of event templates corresponding to Vendler 's event classes #TAUTHOR_TAG : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]","['Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by #AUTHOR_TAG , describes a basic set of event templates corresponding to Vendler 's event classes #TAUTHOR_TAG : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]","['Dowty breaks the event described by (2) into two subevents, the activity ofeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by #AUTHOR_TAG , describes a basic set of event templates corresponding to Vendler 's event classes #TAUTHOR_TAG : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]","['Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by #AUTHOR_TAG , describes a basic set of event templates corresponding to Vendler 's event classes #TAUTHOR_TAG : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]",0
"['', '', '', '', '', '', 'surface format via language generation tools', ' #TAUTHOR_TAG b ) and #AUTHOR_TAG a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']","['', '', '', '', '', '', 'surface format via language generation tools.', ' #TAUTHOR_TAG b ) and #AUTHOR_TAG a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']","['', '', '', '', '', '', 'the surface structure format via language generation tools.', ' #TAUTHOR_TAG b ) and #AUTHOR_TAG a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']","['', '', '', '', '', '', '', ' #TAUTHOR_TAG b ) and #AUTHOR_TAG a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']",0
"['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #TAUTHOR_TAG .', 'Later works, such as #AUTHOR_TAG a), #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method.', '', '']","['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #TAUTHOR_TAG .', 'Later works, such as #AUTHOR_TAG a), #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method.', '', '']","['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #TAUTHOR_TAG .', 'Later works, such as #AUTHOR_TAG a), #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method.', '', '']","['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #TAUTHOR_TAG .', 'Later works, such as #AUTHOR_TAG a), #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b), further made use of part-ofspeech taggers and electronic dictionaries, such as WordNet and VerbNet, to increase the robustness of the method.', '', '']",0
"['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools.', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #TAUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #TAUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #TAUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #TAUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']",0
"['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']",0
"['', '', 'presented', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools', '']","['', '', 'presented', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools.', '']","['', '', 'is presented', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']","['', 'The first lexical substitution method was proposed by #AUTHOR_TAG .', 'Later works , such as #AUTHOR_TAG a ) , #TAUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .', '', '']",0
"['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation #TAUTHOR_TAG , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', 'The feature of the n-gram corpus is pages 2', '5', '']","['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation #TAUTHOR_TAG , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', 'The feature of the n-gram corpus is pages', '', '']","['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation #TAUTHOR_TAG , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', 'The striking feature of the n-gram corpus is', '', '']","['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation #TAUTHOR_TAG , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', '', '', '']",0
"['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer #TAUTHOR_TAG .', 'The is act', '', '']","['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer #TAUTHOR_TAG .', 'The is act', '', '']","['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer #TAUTHOR_TAG .', 'is', '', '']","['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer #TAUTHOR_TAG .', '', '', '']",0
"['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools.', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', '', ' #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #TAUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"['The semantic method is the most sophisticated approach for linguistic stegography, and perhaps impractical given the current-ofthe-art for NLP technology.', 'It requires some sophisticated tools and knowledge to model natural language semantics.', ' #AUTHOR_TAG transform', ' #TAUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']","['The semantic method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology.', 'It requires some sophisticated tools and knowledge to model natural language semantics.', ' #AUTHOR_TAG transformations', ' #TAUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']","['The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology.', 'It requires some sophisticated tools and knowledge to model natural language semantics.', ' #AUTHOR_TAG', ' #TAUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']","['The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology.', 'It requires some sophisticated tools and knowledge to model natural language semantics.', '', ' #TAUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']",0
"['1 gives summary', '', '', '', '', '', '', '', 'parap chart compares the gold price at the end of last year with the end of this year.', ' #TAUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .', 'Section 4 describes parap']","['1 gives summary', '', '', '', '', '', '', '', 'paraphrase chart compares the gold price at the end of last year with the end of this year.', ' #TAUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .', 'Section 4 describes paraphrase']","['1 gives summary statistics', '', '', '', '', '', '', '', 'The chart compares the gold price at the end of last year with the end of this year.', ' #TAUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .', 'Section 4 describes']","['', '', '', '', '', '', '', '', '', ' #TAUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .', '']",0
"['', '', 'The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #TAUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']","['', '', 'The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #TAUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']","['', '', 'The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #TAUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']","['', '', 'The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #TAUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']",5
"['', '', 'presented', '', 'other wordsxical subst the secret message is embedded into syntactic parse trees of the sentences.', ' #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools', '']","['', '', 'presented', '', 'other words, lexical substitution the secret message is embedded into syntactic parse trees of the sentences.', ' #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', 'tools.', '']","['', '', 'is presented', '', 'other words performing lexical substitution the secret message is embedded into syntactic parse trees of the sentences.', ' #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', 'In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences.', ' #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"[' transformations in Listicography.', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words #TAUTHOR_TAG .', 'Our proposed', '', '']","['2 transformations in Linguistic', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words #TAUTHOR_TAG .', 'Our proposed', '', '']","['the previous transformations in Listic Steganography.', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words #TAUTHOR_TAG .', 'Our proposed', '', '']","['', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words #TAUTHOR_TAG .', '', '', '']",1
"['', '', 'Our proposed method is based on the automatically acquired paraphrase dictionary described in #TAUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .', 'One advantage of the dictionary is that it has wide coverage, being automatically extracted; however a disadvantage is that it contains many paraphrases which are either inappropriate or only appropriate in certain contexts.', 'to']","['', '', 'Our proposed method is based on the automatically acquired paraphrase dictionary described in #TAUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .', 'One advantage of the dictionary is that it has wide coverage, being automatically extracted; however, a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts.', 'to']","['', '', 'Our proposed method is based on the automatically acquired paraphrase dictionary described in #TAUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .', 'One advantage of the dictionary is that it has wide coverage, being automatically extracted; however a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts.', 'to']","['', '', 'Our proposed method is based on the automatically acquired paraphrase dictionary described in #TAUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .', 'One advantage of the dictionary is that it has wide coverage, being automatically extracted; however, a disadvantage is that it contains many paraphrases which are either inappropriate, or only appropriate in certain contexts.', '']",5
"['', '', '', '', 'any steg cover', 'ub natural and electronic text is an obvious medium to consider.', 'However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media #TAUTHOR_TAG .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.', 'Language the', '', 'transformations reli problemistic Steganography']","['', '', '', '', 'any steganography cover', 'natural and electronic text is an obvious medium to consider.', 'However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media #TAUTHOR_TAG .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.', 'Language the', '', 'transformations reliably problem Steganography.']","['', '', '', '', 'any steganography system', 'natural languages and is an obvious medium to consider.', 'However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media #TAUTHOR_TAG .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.', 'Language the property', '', 'istic transformationsistic Steganography.']","['', '', '', '', '', '', 'However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media #TAUTHOR_TAG .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.', '', '', '']",0
"['to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method.', 'We use the #TAUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .', '', '', '', '']","['to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method.', 'We use the #TAUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .', '', '', '', '']","['to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method.', 'We use the #TAUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .', '', '', '', '']","['In order to improve the grammaticality checking, we use a parser as an addition to the basic Google ngram method.', 'We use the #TAUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .', '', '', '', '']",5
"['', '', 'presented', '', '', ' #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', 'presented', '', '', ' #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', 'is presented', '', '', ' #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']","['', '', '', '', '', ' #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG and #AUTHOR_TAG a ) all belong to the syntactic transformation category .', '', '']",0
"['In our previous work #TAUTHOR_TAG , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'We use a language model to pick the best path we the ambiguity in the lattice and passed it to our SMT system.', '', '']","['In our previous work #TAUTHOR_TAG , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'We use a language model to pick the best path; we the ambiguity in the lattice and passed it to our SMT system.', '', '']","['In our previous work #TAUTHOR_TAG , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'use a language model to pick the best path; we kept the ambiguity in the lattice and passed it to our SMT system.', '', '']","['In our previous work #TAUTHOR_TAG , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system.', '', '']",1
"['use the-source #AUTHOR_TAG to build a phrase-based SMT system trained mostly MSA (64M words) L corpor DA.', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + #TAUTHOR_TAG .', 'Phrase translations to10 words are extracted in the phrase', '', '', '', '', '', '', '', '']","['use the open-source #AUTHOR_TAG to build a phrase-based SMT system trained mostly MSA (64M words side) LDC corpora DA data.', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + #TAUTHOR_TAG .', 'Phrase translations to 10 words are extracted in the phrase', '', '', '', '', '', '', '', '']","['We use #AUTHOR_TAG to build a phrase-based SMT system trained mostly MSA data (64M words', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + #TAUTHOR_TAG .', 'Phrase translations to10 words are extracted in', '', '', '', '', '', '', '', '']","['We use the open-source Moses toolkit #AUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data.', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + #TAUTHOR_TAG .', 'Phrase translations of up to 10 words are extracted in the Moses phrase table.', '', '', '', '', '', '', '', '']",5
"['', '', '', '', '', 'MSA the translation.', 'This is a similar conclusion to our previous work in #TAUTHOR_TAG .']","['', '', '', '', '', 'MSA the translation.', 'This is a similar conclusion to our previous work in #TAUTHOR_TAG .']","['', '', '', '', '', 'M the English translation.', 'This is a similar conclusion to our previous work in #TAUTHOR_TAG .']","['', '', '', '', '', '', 'This is a similar conclusion to our previous work in #TAUTHOR_TAG .']",1
"['We use the open-source Moses toolkit #TAUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .', '', '', '', '', '', '', '', '', '', '', '']","['We use the open-source Moses toolkit #TAUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .', '', '', '', '', '', '', '', '', '', '', '']","['We use the open-source Moses toolkit #TAUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .', '', '', '', '', '', '', '', '', '', '', '']","['We use the open-source Moses toolkit #TAUTHOR_TAG to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .', '', '', '', '', '', '', '', '', '', '', '']",5
"['assumptions and computational theoriesencies either dis disfluencies make processing more', '', '', '', '', '', 'speech production and speech processing are done incrementally, using contextual information the moments of processing (see, e.g., Tanenhaus et al.195', 'This sort processing requires quite a architecture and different mechanisms for ambiguity resolution.', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are #TAUTHOR_TAG Shriberg , Bear , & #AUTHOR_TAG .']","['assumptions and computational theories either disfluencies make processing more', '', '', '', '', '', 'speech production and speech processing are done incrementally, using contextual information the moments of processing (see, e.g., Tanenhaus et al. 1995).', 'This sort processing requires quite a architecture and different mechanisms for ambiguity resolution', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are #TAUTHOR_TAG Shriberg , Bear , & #AUTHOR_TAG .']","['and computational theoriesencies either disfluencies make processing', '', '', '', '', '', ', speech production and speech processing are done incrementally, using contextual information the earliest moments of processing (see, e.g., Tanenhaus et al.195', 'This sort processing requires quite a different architecture and different mechanisms for ambiguity resolution', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are #TAUTHOR_TAG Shriberg , Bear , & #AUTHOR_TAG .']","['', '', '', '', '', '', 'In humans, speech production and speech processing are done incrementally, using contextual information from the earliest moments of processing (see, e.g., Tanenhaus et al. 1995).', '', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are #TAUTHOR_TAG Shriberg , Bear , & #AUTHOR_TAG .']",0
"['Similar to our previous work #AUTHOR_TAG b ) , we used the supervised WSD approach described in #TAUTHOR_TAG for our experiments , using the naive Bayes algorithm as our classifier .', 'sources includesof- and local coll.', 'ves', '']","['Similar to our previous work #AUTHOR_TAG b ) , we used the supervised WSD approach described in #TAUTHOR_TAG for our experiments , using the naive Bayes algorithm as our classifier .', 'sources include and local collocations.', 'achieves', '']","['Similar to our previous work #AUTHOR_TAG b ) , we used the supervised WSD approach described in #TAUTHOR_TAG for our experiments , using the naive Bayes algorithm as our classifier .', 'ledge sources used includesof- and local collocations.', 'ves', '']","['Similar to our previous work #AUTHOR_TAG b ) , we used the supervised WSD approach described in #TAUTHOR_TAG for our experiments , using the naive Bayes algorithm as our classifier .', '', '', '']",5
"['', '', '', '', '', 'We chose to follow #TAUTHOR_TAG and split the sentences evenly to facilitate further comparison .']","['', '', '', '', '', 'We chose to follow #TAUTHOR_TAG and split the sentences evenly to facilitate further comparison .']","['', '', '', '', '', 'We chose to follow #TAUTHOR_TAG and split the sentences evenly to facilitate further comparison .']","['', '', '', '', '', 'We chose to follow #TAUTHOR_TAG and split the sentences evenly to facilitate further comparison .']",5
"['We built a two-stage baseline system , using the perceptron segmentation model from our previous work #TAUTHOR_TAG and the perceptron POS tagging model from #AUTHOR_TAG .', '', '', '']","['We built a two-stage baseline system , using the perceptron segmentation model from our previous work #TAUTHOR_TAG and the perceptron POS tagging model from #AUTHOR_TAG .', '', '', '']","['We built a two-stage baseline system , using the perceptron segmentation model from our previous work #TAUTHOR_TAG and the perceptron POS tagging model from #AUTHOR_TAG .', '', '', '']","['We built a two-stage baseline system , using the perceptron segmentation model from our previous work #TAUTHOR_TAG and the perceptron POS tagging model from #AUTHOR_TAG .', '', '', '']",2
"['ical Dirich ( observ.', 'Our HDP extension is also inspired from the Bayesian model proposed by #TAUTHOR_TAG .', ', their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task #AUTHOR_TAG .']","['Dirichlet observable L.', 'Our HDP extension is also inspired from the Bayesian model proposed by #TAUTHOR_TAG .', 'However, their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task #AUTHOR_TAG .']","['( observ', 'Our HDP extension is also inspired from the Bayesian model proposed by #TAUTHOR_TAG .', ', their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task #AUTHOR_TAG .']","['', 'Our HDP extension is also inspired from the Bayesian model proposed by #TAUTHOR_TAG .', 'However, their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task #AUTHOR_TAG .']",4
"['ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG :  .']","['ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']","['ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']","['ME approach has the merit of easily combining different features to predict the probability of each class. We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']",4
"['ME approach has the merit of easily combining different features to predict the probability of each class.', 'We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG :  .']","['ME approach has the merit of easily combining different features to predict the probability of each class.', 'We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']","['ME approach has the merit of easily combining different features to predict the probability of each class.', 'We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']","['ME approach has the merit of easily combining different features to predict the probability of each class.', 'We incorporate into the ME based model the following informative context-based features to train CBSM and CBTM.', 'These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work #TAUTHOR_TAG : 1 .']",4
"['More recently , an alignment selection approach was proposed in #TAUTHOR_TAG , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).', '', '', '', '']","['More recently , an alignment selection approach was proposed in #TAUTHOR_TAG , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).', '', '', '', '']","['More recently , an alignment selection approach was proposed in #TAUTHOR_TAG , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).', '', '', '', '']","['More recently , an alignment selection approach was proposed in #TAUTHOR_TAG , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).', '', '', '', '']",1
"['', '', '', '', ""Inspired by #TAUTHOR_TAG , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'P a S, will be substituted byPˆ', 'This strategy severely increases the of to train', 'this use a cluster CTBal types,', '', '']","['', '', '', '', ""Inspired by #TAUTHOR_TAG , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'NP a S, will be substituted by', 'This strategy severely increases the of to train', 'this use a cluster CTB types,', '', '']","['', '', '', '', ""Inspired by #TAUTHOR_TAG , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'a S, will be substituted byPˆ', 'This strategy severely increases the number of to', 'use a cluster CTB phrasal types,', '', '']","['', '', '', '', ""Inspired by #TAUTHOR_TAG , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'For example, an NP immediately dominated by a S, will be substituted by NPˆS.', '', '', '', '']",4
"['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach #TAUTHOR_TAG .', '', '', '', '', '', '']","['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach #TAUTHOR_TAG .', '', '', '', '', '', '']","['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach #TAUTHOR_TAG .', '', '', '', '', '', '']","['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach #TAUTHOR_TAG .', '', '', '', '', '', '']",4
['Previous sentiment-analysis work in different domains has considered inter-document similarity #AUTHOR_TAG or explicit inter-document references in the form of hyperlinks #TAUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #AUTHOR_TAG or explicit inter-document references in the form of hyperlinks #TAUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #AUTHOR_TAG or explicit inter-document references in the form of hyperlinks #TAUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #AUTHOR_TAG or explicit inter-document references in the form of hyperlinks #TAUTHOR_TAG .'],0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cludingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['More sophisticated approaches have been proposed #TAUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', ' #AUTHOR_TAG citation analysis #AUTHOR_TAG and computational rhetical analysis #AUTHOR_TAG']","['More sophisticated approaches have been proposed #TAUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', ' #AUTHOR_TAG citation analysis #AUTHOR_TAG and computational rhetorical analysis #AUTHOR_TAG']","['More sophisticated approaches have been proposed #TAUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', ' #AUTHOR_TAG citation analysis #AUTHOR_TAG and computational rhetorical analysis #AUTHOR_TAG .']","['More sophisticated approaches have been proposed #TAUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', '']",0
"['', 'More approaches have been proposed including anpol', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', 'More approaches have been proposed including an', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', 'More sophisticated approaches have been proposedpol', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', '', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a document or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', '', '']",0
"['arity classifiers proposed in the recent categorize in- dependently labeled', 'linked l', 'For, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see #AUTHOR_TAG but cfXXX #TAUTHOR_TAG .', '']","['classifiers proposed in the recent categorize in- dependently. labeled', 'linked', 'For example, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see #AUTHOR_TAG but cfXXX #TAUTHOR_TAG .', '']","['proposed in the recent literature categorize in- dependently. A be labeled', '', 'For, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see #AUTHOR_TAG but cfXXX #TAUTHOR_TAG .', '']","['', '', 'For example, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see #AUTHOR_TAG but cfXXX #TAUTHOR_TAG .', '']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #TAUTHOR_TAG .', '']",0
"['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.', 'Fol- lowing standard practice in sentiment analysis #TAUTHOR_TAG , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.', 'The ind value for each speech segment s was based on the signed distanceds fromthevectorrepresentingstothe trained SVM decision plane:  � ds 3�4s� d s �3�s�34s def ds = 3s dev']","['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.5', 'Fol- lowing standard practice in sentiment analysis #TAUTHOR_TAG , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.', 'The ind value for each speech segment s was based on the signed distanceds fromthevectorrepresentingstothe trained SVM decision plane: \x0e � ds \x0e23�4s� d s �23�4s� def ds = deviation']","['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.', 'Fol- lowing standard practice in sentiment analysis #TAUTHOR_TAG , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.', 'The ind value for each speech segment s was based on the signed distanceds fromthevectorrepresentingstothe trained SVM decision plane: \x0e � ds \x0e23�4s� d s �23�4s� ds ��23�4s def ds = 3']","['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.5', 'Fol- lowing standard practice in sentiment analysis #TAUTHOR_TAG , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.', '']",5
['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cludingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['properties Det a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['properties a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a proposal falls the realm analysis, an extremely active research area devoted to', 'we treat a debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .""]",0
['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyper- links #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyper- links #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyper- links #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyper- links #AUTHOR_TAG .'],0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cludingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']",3
"['', 'More sophisticated approaches have been proposed , including an revers makes use ofpolarity indicators within speech segments', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #TAUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']","['', 'More sophisticated approaches have been proposed , including an reversal makes use of sentimentpolarity indicators within speech segments', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #TAUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']","['', 'More sophisticated approaches have been proposed , makes use ofpolarity indicators within speech segments', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #TAUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']","['', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that, in an interesting reversal of our problem, makes use of sentimentpolarity indicators within speech segments #AUTHOR_TAG .', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #TAUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evalu', '', '', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled #TAUTHOR_TAG .', 'Many interesting opinion-oriented documents, however, can be linked through certain relationships that occur in the context of evaluative discussions.', '', '', '']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['We used a simple method to learn to identify cross-speaker references indicating agreement.', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #TAUTHOR_TAG .', 'ging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetical analysis #AUTHOR_TAG']","['We used a simple method to learn to identify cross-speaker references indicating agreement.', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #TAUTHOR_TAG .', 'tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG']","['We used a simple method to learn to identify cross-speaker references indicating agreement.', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #TAUTHOR_TAG .', ' #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']","['We used a simple method to learn to identify cross-speaker references indicating agreement.', 'More sophisticated approaches have been proposed #AUTHOR_TAG , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments #TAUTHOR_TAG .', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #AUTHOR_TAG .']",0
"['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']",1
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' #TAUTHOR_TAG ."", 'much media attention has been focused recently on the potential Internet sites on politics  or at 3', 'important to help understand and analyzeically orient']","[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' #TAUTHOR_TAG ."", 'much media attention has been focused recently on the potential Internet sites on politics 2 or at 3', 'important to help understand and analyze politically oriented']","[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' #TAUTHOR_TAG ."", ', much media attention has been focused recently on the potential impact Internet sites on politics 2 or at', 'important to help understand and analyze politically orient']","[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' #TAUTHOR_TAG ."", 'Additionally, much media attention has been focused recently on the potential impact that Internet sites may have on politics 2 , or at least on political journalism 3 .', '']",0
"['a a proposal falls analysis an extremely active research area', 'since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a a proposal falls analysis, an extremely active research area', 'since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a proposal falls analysis an extremely active research area', 'since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['', 'In particular, since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , Kondor and #AUTHOR_TAG , and #AUTHOR_TAG .', ' #TAUTHOR_TAG maintains a survey of this area .']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , Kondor and #AUTHOR_TAG , and #AUTHOR_TAG .', ' #TAUTHOR_TAG maintains a survey of this area .']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , Kondor and #AUTHOR_TAG , and #AUTHOR_TAG .', ' #TAUTHOR_TAG maintains a survey of this area .']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , Kondor and #AUTHOR_TAG , and #AUTHOR_TAG .', ' #TAUTHOR_TAG maintains a survey of this area .']",0
['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']",0
"['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']",1
"['supportoppose problem can be approached through standard vector machines', 'explo', 'Our classification framework , directly inspired by #TAUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .', '']","['support/oppose problem can be approached through standard vector machines', 'exploited', 'Our classification framework , directly inspired by #TAUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .', '']","['The support/oppose classification problem can be approached through support vector machines', '', 'Our classification framework , directly inspired by #TAUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .', '']","['', '', 'Our classification framework , directly inspired by #TAUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .', '']",5
['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text #TAUTHOR_TAG .'],0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']",0
"['Notable early papers on graph-based semisupervised learning include #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']",0
"['currently not have an efficient means to encode disagreement information as constraints; we to incorpor such information in future.', 'Relationships between the unlabeled items #TAUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']","['currently not have an efficient means to encode disagreement information as constraints; we to incorporating such information in future work.', 'Relationships between the unlabeled items #TAUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']","['currently do not have an efficient means to encode disagreement information as hard constraints; we plan to such information in future work.', 'Relationships between the unlabeled items #TAUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']","['We currently do not have an efficient means to encode disagreement information as hard constraints; we plan to investigate incorporating such information in future work.', 'Relationships between the unlabeled items #TAUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']",0
"['', 'to , given the dense nature of language and the fact that ( U.S. ) bills often reach several hundred pages in length #TAUTHOR_TAG .', '']","['', 'to , given the dense nature of language and the fact that ( U.S. ) bills often reach several hundred pages in length #TAUTHOR_TAG .', '']","['', 'to , given the dense nature ofative language and the fact that ( U.S. ) bills often reach several hundred pages in length #TAUTHOR_TAG .', '']","['', '', '']",0
"['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']","['As has been previously observed and exploited in the NLP literature #TAUTHOR_TAG , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .', '']",1
"['properties Det a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['properties a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a proposal falls the realm analysis, an extremely active research area devoted to', 'we treat a debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .""]",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']",0
"['properties Det a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['properties a a proposal falls realm analysis, an extremely active research area devoted to', 'we debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['a proposal falls the realm analysis, an extremely active research area devoted to', 'we treat a debate `` , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .']","['', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents #TAUTHOR_TAG .""]",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a document or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', '', '']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is prov and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, includingual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']","['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed #TAUTHOR_TAG .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']","['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .', ' #AUTHOR_TAG maintains a survey of this area.']",0
"['', 'More approaches have been proposed including anpol', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', 'More approaches have been proposed including an', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', 'More sophisticated approaches have been proposedpol', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']","['', '', 'Also relevant is work on the general problems of dialog-act tagging #AUTHOR_TAG , citation analysis #AUTHOR_TAG , and computational rhetorical analysis #TAUTHOR_TAG .']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or, mostproposed direct relationships tolabel texts', 'An exception is #TAUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or author, most previously-proposed direct relationships to texts)', 'An exception is #TAUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or, mostproposed methods relationships to', 'An exception is #TAUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit #AUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) #AUTHOR_TAG .', 'An exception is #TAUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']",0
"['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']","['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work #TAUTHOR_TAG .']",3
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"". ""conservative"") of a document or', '']","['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit #TAUTHOR_TAG .', '', '']",0
"['-polarity classifiers proposed in the recent literature categorize each document independently.', 'A others of inter-document labeled', 'be linked through of', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #TAUTHOR_TAG but cfXXX #AUTHOR_TAG ) .', '']","['sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A others of inter-document labeled', 'be linked through of', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #TAUTHOR_TAG but cfXXX #AUTHOR_TAG ) .', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others of inter- be labeled', 'can be linked through of', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #TAUTHOR_TAG but cfXXX #AUTHOR_TAG ) .', '']","['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', '', '', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #TAUTHOR_TAG but cfXXX #AUTHOR_TAG ) .', '']",0
['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],['Previous sentiment-analysis work in different domains has considered inter-document similarity #TAUTHOR_TAG or explicit inter-document references in the form of hyperlinks #AUTHOR_TAG .'],0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']","['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ; see #AUTHOR_TAG for an active bibliography ) .', '']",0
"['', 'final', '', 'Our plan is to implement a windowed or moving-average version of BLEU as in #TAUTHOR_TAG .']","['', 'final', '', 'Our plan is to implement a windowed or moving-average version of BLEU as in #TAUTHOR_TAG .']","['', '', '', 'Our plan is to implement a windowed or moving-average version of BLEU as in #TAUTHOR_TAG .']","['', '', '', 'Our plan is to implement a windowed or moving-average version of BLEU as in #TAUTHOR_TAG .']",3
"['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']","['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. #TAUTHOR_TAG .', '', '', '', '', '', '', '', '', '']",0
"['The right column in Table1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in parallel.', 'an average of 51.8 the improvement over the English only variant (50.6) is.', 'This contrasts with the findings described in #TAUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .', 'So this casts some doubt on these.', 'However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement.', 'This to a 5 for', '', '', '']","['The right column in Table 1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in parallel.', 'an average of 51.8 the improvement over the English only variant (50.6) is minimal.', 'This contrasts with the findings described in #TAUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .', 'So this casts some doubt on these.', 'However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement.', 'This to a 50 for', '', '', '']","['The right column in Table 1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in parallel.', 'an average score of 51.8 the improvement over the English only variant (50.6) is.', 'This contrasts with the findings described in #TAUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .', 'So this casts some doubt on these.', 'However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement.', 'This to a score 5 for', '', '', '']","['The right column in Table 1 shows the scores if (using the product-of-ranks algorithm) four source languages are taken into account in parallel.', 'As can be seen, with an average score of 51.8 the improvement over the English only variant (50.6) is minimal.', 'This contrasts with the findings described in #TAUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .', 'So this casts some doubt on these.', 'However, as English was not considered as a source language there, the performance levels were mostly between 10 and 20, leaving much room for improvement.', '', '', '', '']",1
"['always translations to source', 'already have word equations for four and all we want is to compute the translations into a fifth language, we can simply extend our approach to what we call the product-of-ranks algorithm.', 'As suggested in #TAUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .', 'So for each candidate we obtain a product of ranks.', 'We then assume that the candidate with the smallest product will be the best translation.', 'the nervous in, Spanishioso their', '', '', '']","['always translations to source', 'already have word equations for four and all we want is to compute the translations into a fifth language, we can simply extend our approach to what we call the product-of-ranks algorithm.', 'As suggested in #TAUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .', 'So for each candidate we obtain a product of ranks.', 'We then assume that the candidate with the smallest product will be the best translation.', 'the nervous in English, Spanish, their', '', '', '']","['always translations to', 'already have word equations for and all we want is to compute the translations into a fifth language, we can simply extend our approach to what we call the product-of-ranks algorithm.', 'As suggested in #TAUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .', 'So for each candidate we obtain a product of ranks.', 'We then assume that the candidate with the smallest product will be the best translation. 3', 'nervous in Spanishioso their', '', '', '']","['', 'However, if we assume, for example, that we already have word equations for four languages, and all we want is to compute the translations into a fifth language, then we can simply extend our approach to what we call the product-of-ranks algorithm.', 'As suggested in #TAUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .', 'So for each candidate we obtain a product of ranks.', 'We then assume that the candidate with the smallest product will be the best translation. 3', '', '', '', '']",4
"['Whereas #TAUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', 'We were to light on criteria performance', '', '']","['Whereas #TAUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', 'We were to light on criteria performance,', '', '']","['Whereas #TAUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', 'We were to some light on performance', '', '']","['Whereas #TAUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', '', '', '']",1
"['ocussed rules', '', '', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #TAUTHOR_TAG .', '']","['focussed rules', '', '', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #TAUTHOR_TAG .', '']","['has focussed', '', '', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #TAUTHOR_TAG .', '']","['', '', '', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #TAUTHOR_TAG .', '']",3
"['we expected to see clear benefits from both using Gaz andString', '', '', '', '', '', '', 'entries too', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #TAUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']","['we expected to see clear benefits from both using and SimString', '', '', '', '', '', '', 'entries too', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #TAUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']","['we expected to see clear benefits from both using Gazetteers andString', '', '', '', '', '', '', 'is too', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #TAUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']","['', '', '', '', '', '', '', '', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #TAUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']",3
"['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #TAUTHOR_TAG .', 'The A', '']","['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #TAUTHOR_TAG .', 'The', '']","['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #TAUTHOR_TAG .', 'The model', '']","['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #TAUTHOR_TAG .', '', '']",5
"['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks #TAUTHOR_TAG .', 'Thus, the classifiers trained on the learner data make use of a discriminative model.', '']","['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks #TAUTHOR_TAG .', 'Thus, the classifiers trained on the learner data make use of a discriminative model.', '']","['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks #TAUTHOR_TAG .', 'Thus, the classifiers trained on the learner data make use of a discriminative model.', '']","['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks #TAUTHOR_TAG .', 'Thus, the classifiers trained on the learner data make use of a discriminative model.', '']",4
"['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']",1
"['row the Table6 results', 'is for', '', '', '', '', '', '', '', '', 'approach discovers words are highly Agree categories and these words turn to be useful features for classification', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['row the Table 6 results.', 'is for', '', '', '', '', '', '', '', '', 'approach discovers words are highly categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['the Table 6', 'is for', '', '', '', '', '', '', '', '', 'discovers the words are highly Agreeree categories and these words turn to be useful features for classification', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', 'The MI approach discovers the words that are highly associated with Agree/Disagree categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']",4
"['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']","['Another line of research that is correlated with ours is recognition of agreement/disagreement #TAUTHOR_TAG and classification of stances #AUTHOR_TAG in online forums .', '']",1
"['row the Table6 results', 'is for', '', '', '', '', '', '', '', '', 'approach discovers words are highly Agree categories and these words turn to be useful features for classification', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['row the Table 6 results.', 'is for', '', '', '', '', '', '', '', '', 'approach discovers words are highly categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['the Table 6', 'is for', '', '', '', '', '', '', '', '', 'discovers the words are highly Agreeree categories and these words turn to be useful features for classification', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', 'The MI approach discovers the words that are highly associated with Agree/Disagree categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement #TAUTHOR_TAG .']",4

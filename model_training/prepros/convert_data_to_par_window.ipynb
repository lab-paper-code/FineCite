{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Optional, Dict\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "CITE_MARKER = '#AUTHOR_TAG'\n",
    "IGNORE_SENTS = {'----------------------------------'}\n",
    "\n",
    "# Define the argument values as Python variables\n",
    "input_directory = \"/raid/deallab/CCE_Data/raw_data/multicite/\"\n",
    "file_name = 'full_raw.json'\n",
    "output_directory = \"/raid/deallab/CCE_Data/model_training/data/seq_tagger/\"\n",
    "model_name =  \"allenai/scibert_scivocab_uncased\"\n",
    "rand_state = 99\n",
    "train_prob = 0.7  # Specify the probability if needed\n",
    "dev_prob = 0.1    # Specify the probability if needed\n",
    "test_prob = 0.2   # Specify the probability if needed\n",
    "\n",
    "# stuff need from model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=False, use_fast=True)\n",
    "tokenizer.add_special_tokens({'additional_special_tokens': [CITE_MARKER]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper\n",
    "\n",
    "# replace html tags in the sentence\n",
    "def replace_html(sentence: str, new_cite_token: str) -> str:\n",
    "    pattern = '<span style=\"background: yellow; display: inline-block\">.*?</span>'\n",
    "    return re.sub(pattern, new_cite_token, sentence)\n",
    "\n",
    "# Tokenize the input sentence using the provided tokenizer and return length\n",
    "def compute_num_tokens(sentence: str, tokenizer):\n",
    "    encodings_from_sent = tokenizer(\n",
    "        sentence,\n",
    "        is_split_into_words=False,\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    return len(encodings_from_sent['input_ids'])\n",
    "\n",
    "# describes  where the citation is in the context window\n",
    "def _describe_window(window_sent_pos: List[int], window_num_tokens: int,\n",
    "                     cite_sent_pos: List[int],\n",
    "                     gold_context_sent_pos: List[int], gold_context_num_tokens: int):\n",
    "\n",
    "    # Determine the positions of citation sentences within the window\n",
    "    where_are_cite_in_window = [window_sent_pos.index(i) for i in cite_sent_pos]\n",
    "    print(f'Token Window:{window_num_tokens}\\tToken Gold:{gold_context_num_tokens}\\tSent Window: {len(window_sent_pos)}\\tSent Gold: {len(gold_context_sent_pos)}\\tCiteInWindow: {where_are_cite_in_window}')\n",
    "    \n",
    "    \n",
    "def build_section_dict(paper: dict):\n",
    "    section_dict = {}\n",
    "    current_section = 0\n",
    "    for idx, sent_dict in enumerate(paper):\n",
    "        text = sent_dict['text']\n",
    "        if text[:2] + text[-2:] == '****':\n",
    "            current_section += 1\n",
    "        else:\n",
    "            section_dict[idx] = current_section\n",
    "    return section_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_examples(examples: list, train_prob: float, dev_prob: float, test_prob: float):\n",
    "    \"\"\"\n",
    "    output looks like:\n",
    "    {\n",
    "        0: {'train': [...], 'dev': [...], 'test': [...]},\n",
    "        1: {'train': [...], 'dev': [...], 'test': [...]},\n",
    "        ...\n",
    "        k: {'train': [...], 'dev': [...], 'test': [...]},\n",
    "    }\n",
    "    \"\"\"\n",
    "    assert train_prob + dev_prob + test_prob == 1.0\n",
    "    num_folds = int(1.0 / test_prob)\n",
    "    assert 1.0 / test_prob == num_folds  # check that we can evenly divide into folds\n",
    "\n",
    "    paper_ids = list({example['instance_id'].split('_')[1] for example in examples})\n",
    "    random.shuffle(paper_ids)\n",
    "\n",
    "    num_test = int(len(paper_ids) / num_folds)\n",
    "    num_train = int((len(paper_ids) - num_test) * train_prob / (train_prob + dev_prob))\n",
    "    num_dev = len(paper_ids) - num_test - num_train\n",
    "    assert num_train + num_dev + num_test == len(paper_ids)\n",
    "\n",
    "    # precompute the CV paper ID assignments\n",
    "    fold_to_paper_ids = {}\n",
    "    for fold in range(num_folds):\n",
    "        # Determine the range of paper IDs for the test set in the current fold\n",
    "        start_test = fold * num_test\n",
    "        end_test = start_test + num_test\n",
    "        test = paper_ids[start_test:end_test]\n",
    "\n",
    "        # Determine the remaining paper IDs for the training and development sets\n",
    "        remaining_paper_ids = [paper_id for paper_id in paper_ids if paper_id not in test]\n",
    "        random.shuffle(remaining_paper_ids)\n",
    "        train = remaining_paper_ids[:num_train]\n",
    "        dev = remaining_paper_ids[num_train:]\n",
    "        assert len(train) + len(dev) + len(test) == len(paper_ids)\n",
    "        fold_to_paper_ids[fold] = (train, dev, test)\n",
    "\n",
    "\n",
    "    # split examples s.t. all examples from same paper go to same split\n",
    "    fold_to_examples = {}\n",
    "    for fold, (train, dev, test) in fold_to_paper_ids.items():\n",
    "        fold_to_examples[fold] = {\n",
    "            'train': [],\n",
    "            'dev': [],\n",
    "            'test': []\n",
    "        }\n",
    "        for example in examples:\n",
    "            paper_id = example['instance_id'].split('_')[1]\n",
    "            if paper_id in train:\n",
    "                fold_to_examples[fold]['train'].append(example)\n",
    "            elif paper_id in dev:\n",
    "                fold_to_examples[fold]['dev'].append(example)\n",
    "            else:\n",
    "                fold_to_examples[fold]['test'].append(example)\n",
    "    return fold_to_examples\n",
    "\n",
    "def build_window(gold_context_sent_pos: List[int],                                                  # annotations\n",
    "                 sent_pos_to_num_tokens: List[int],                                                 # resources\n",
    "                 section_pos: List[int],\n",
    "                 paper_num_sents: int, max_model_num_tokens: int                                    # constraints\n",
    "                 ) -> Optional[List[int]]:\n",
    "\n",
    "    # let's always include the full gold context, at minimum (unless it truncates due to window, in which case we skip)\n",
    "    gold_context_num_tokens = sum([sent_pos_to_num_tokens[gold_sent_pos] for gold_sent_pos in gold_context_sent_pos])\n",
    "    section_sent_num_tokens = sum([sent_pos_to_num_tokens[section_sent_pos] for section_sent_pos in section_pos])\n",
    "\n",
    "    # validate our constraints before getting the actual sentence text\n",
    "    if gold_context_num_tokens > max_model_num_tokens:  # too long for even this longformer\n",
    "        print(f'Skipping... Token Gold: {gold_context_num_tokens}')\n",
    "        return None\n",
    "    elif section_sent_num_tokens < max_model_num_tokens:\n",
    "        return section_pos\n",
    "    else:\n",
    "\n",
    "        # now let's randomly append sentences to front/back of gold context\n",
    "        window_sent_pos = [sent_pos for sent_pos in gold_context_sent_pos]\n",
    "        window_num_tokens = gold_context_num_tokens\n",
    "        while window_num_tokens <= max_model_num_tokens:\n",
    "            before_sent_id = min(window_sent_pos) - 1\n",
    "            after_sent_id = max(window_sent_pos) + 1\n",
    "            \n",
    "            #check if sent in section\n",
    "            if before_sent_id not in section_pos and after_sent_id in section_pos:\n",
    "                new_sent_id = after_sent_id\n",
    "            elif after_sent_id not in section_pos and before_sent_id in section_pos:\n",
    "                new_sent_id = before_sent_id\n",
    "            elif before_sent_id < min(section_pos) and after_sent_id > max(section_pos):\n",
    "                break\n",
    "            else:\n",
    "                choice = random.randint(0, 1)\n",
    "                if choice == 0:\n",
    "                    new_sent_id = after_sent_id\n",
    "                else:\n",
    "                    new_sent_id = before_sent_id\n",
    "\n",
    "            # token length check\n",
    "            new_sent_num_tokens = sent_pos_to_num_tokens[new_sent_id]\n",
    "            if window_num_tokens + new_sent_num_tokens <= max_model_num_tokens:\n",
    "\n",
    "                # now add to window\n",
    "                window_sent_pos.append(new_sent_id)\n",
    "                window_num_tokens += sent_pos_to_num_tokens[new_sent_id]\n",
    "\n",
    "            else:\n",
    "                # ran out of space so end adding phase\n",
    "                break\n",
    "\n",
    "        window_sent_pos = sorted(window_sent_pos)\n",
    "        return window_sent_pos\n",
    "\n",
    "def build_all_examples(raw_data_dict: Dict) -> List[Dict]:\n",
    "    \n",
    "    active_logger = False\n",
    "    n = 0\n",
    "    all_examples = []\n",
    "    for paper_id, data in tqdm(raw_data_dict.items(), position=0):\n",
    "        paper = data['x']                          # paper\n",
    "        intent_to_annotations = data['y']          # intent & context annotations\n",
    "\n",
    "        # 0) clean out IGNORED SENTS\n",
    "        clean_paper = [sent_dict for sent_dict in paper if sent_dict['text'] not in IGNORE_SENTS]\n",
    "\n",
    "        # 1) build an easy lookup for sentences from its ID (str) to its list position (int) and the oposite around\n",
    "        sent_id_to_list_pos: Dict[str, int] = {sent_dict['sent_id']: i for i, sent_dict in enumerate(clean_paper)}\n",
    "        sent_pos_to_sent_id: Dict[int, str] = {sent_pos: sent_id for sent_id, sent_pos in sent_id_to_list_pos.items()}\n",
    "        \n",
    "        # 1.5) build section lookup table from sentence ID to section idx and the other way around\n",
    "        sent_pos_to_section_idx = build_section_dict(clean_paper)\n",
    "        section_idx_to_sent_pos = defaultdict(list)\n",
    "        for sent_pos, section_idx in sent_pos_to_section_idx.items():\n",
    "            section_idx_to_sent_pos[section_idx].append(sent_pos)\n",
    "\n",
    "        # 2) clean html and get tokens length per sentence\n",
    "        sent_pos_to_clean_text = [replace_html(sent_dict['text'], new_cite_token=CITE_MARKER) for sent_dict in clean_paper]\n",
    "        sent_pos_to_num_tokens: List[int] = [compute_num_tokens(clean_sent, tokenizer) for clean_sent in sent_pos_to_clean_text]\n",
    "        \n",
    "        # 3) convert concat all citation contex always taking the biggest one if ther are multiple\n",
    "        cite_sent_dict = {}\n",
    "        for intent, context in intent_to_annotations.items():\n",
    "            gold_context = context['gold_contexts']\n",
    "            cite_sents = context['cite_sentences']\n",
    "            if len(cite_sents) != len(gold_context):\n",
    "                print('length is not matching')\n",
    "                continue\n",
    "            for i, sent in enumerate(cite_sents):\n",
    "                cite_sent_dict[sent]=gold_context[i]\n",
    "\n",
    "        # 4) create a training example out of each gold context (i.e. each cite mention)\n",
    "        #    note, this code is a bit annoying because we want to convert all sent_ids to positions first\n",
    "        for idx, (sent_id, gold_context_sent_ids) in enumerate(intent_to_annotations.items()):\n",
    "\n",
    "            # 4a) build valid window\n",
    "            gold_context_sent_pos = [sent_id_to_list_pos[sent_id] for sent_id in gold_context_sent_ids if sent_id in sent_id_to_list_pos]   # ignores if annotated an ignored sent\n",
    "            if not gold_context_sent_pos: continue\n",
    "            counter = Counter([sent_pos_to_section_idx[sent_pos] for sent_pos in gold_context_sent_pos if sent_pos in sent_pos_to_section_idx])\n",
    "            if not counter: continue\n",
    "            gold_context_section_idx = counter.most_common()[0][0]\n",
    "            window_sent_pos: Optional[List[int]] = build_window(gold_context_sent_pos=gold_context_sent_pos,\n",
    "                                                                sent_pos_to_num_tokens=sent_pos_to_num_tokens,\n",
    "                                                                section_pos = section_idx_to_sent_pos[gold_context_section_idx],\n",
    "                                                                paper_num_sents=len(clean_paper),\n",
    "                                                                max_model_num_tokens=500)   # conservatively stay within 512\n",
    "            if window_sent_pos is None:\n",
    "                continue\n",
    "\n",
    "            # verify there is at least one <CITE>\n",
    "            if sent_id_to_list_pos[sent_id] not in window_sent_pos:\n",
    "                continue\n",
    "            if active_logger:\n",
    "                _describe_window(window_sent_pos=window_sent_pos,\n",
    "                                window_num_tokens=sum([sent_pos_to_num_tokens[pos] for pos in window_sent_pos]),\n",
    "                                cite_sent_pos=sent_id_to_list_pos[sent_id],\n",
    "                                gold_context_sent_pos=gold_context_sent_pos,\n",
    "                                gold_context_num_tokens=sum([sent_pos_to_num_tokens[pos] for pos in gold_context_sent_pos]))\n",
    "\n",
    "            # 4b) get the text and labels\n",
    "            example = {\n",
    "                'id': n,\n",
    "                'instance_id': f'{paper_id}__{sent_id}',\n",
    "                'sentences': [],\n",
    "                'labels': [],\n",
    "                'sent_ids': []\n",
    "            }\n",
    "            for w_pos in window_sent_pos:\n",
    "                example['sentences'].append(sent_pos_to_clean_text[w_pos])\n",
    "                example['labels'].append('context' if w_pos in gold_context_sent_pos else 'not-context')\n",
    "                example['sent_ids'].append(sent_pos_to_sent_id[w_pos])\n",
    "\n",
    "            all_examples.append(example)\n",
    "            n += 1\n",
    "\n",
    "    return all_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gold_contexts': [['8f0aab7fd30ffc56cc477b25e6bb16-C001-11']], 'cite_sentences': ['8f0aab7fd30ffc56cc477b25e6bb16-C001-11']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gold_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# build examples\u001b[39;00m\n\u001b[1;32m      6\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(rand_state)\n\u001b[0;32m----> 7\u001b[0m all_examples \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_all_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# stuff for output\u001b[39;00m\n\u001b[1;32m     10\u001b[0m outdir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrand_state\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__tr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_prob\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdev_prob\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-t\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_prob\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[59], line 142\u001b[0m, in \u001b[0;36mbuild_all_examples\u001b[0;34m(raw_data_dict)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m intent, context \u001b[38;5;129;01min\u001b[39;00m intent_to_annotations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(context)\n\u001b[0;32m--> 142\u001b[0m     gold_context \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgold_context\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    143\u001b[0m     cite_sent \u001b[38;5;241m=\u001b[39m context[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cite_sents, gold_context)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gold_context'"
     ]
    }
   ],
   "source": [
    "# stuff for input\n",
    "with open(os.path.join(input_directory, file_name)) as f_in:\n",
    "    d = json.load(f_in)\n",
    "\n",
    "# build examples\n",
    "random.seed(rand_state)\n",
    "all_examples = build_all_examples(raw_data_dict=d)\n",
    "\n",
    "# stuff for output\n",
    "outdir = os.path.join(output_directory, f'section__{rand_state}__tr{train_prob}-v{dev_prob}-t{test_prob}'.replace('/', '-').replace('.', ''))\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "out_file = os.path.join(outdir, 'full.json')\n",
    "with open(out_file, 'w') as outfile:\n",
    "    json.dump({'data': all_examples}, outfile, indent=4)\n",
    "\n",
    "# now do the splitting & log it\n",
    "logfile = os.path.join(outdir, 'log.txt')\n",
    "with open(logfile, 'w') as f_log:\n",
    "\n",
    "    fold_to_splits = split_examples(examples=all_examples, train_prob=train_prob, dev_prob=dev_prob, test_prob=test_prob)\n",
    "    for fold, splits in fold_to_splits.items():\n",
    "        folddir = os.path.join(outdir, f'{fold}/')\n",
    "        os.makedirs(folddir, exist_ok=True)\n",
    "        trainfile = os.path.join(folddir, 'train.jsonl')\n",
    "        devfile = os.path.join(folddir, 'dev.jsonl')\n",
    "        testfile = os.path.join(folddir, 'test.jsonl')\n",
    "        train = splits['train']\n",
    "        dev = splits['dev']\n",
    "        test = splits['test']\n",
    "        with open(trainfile, 'w') as f_train:\n",
    "            for e in train:\n",
    "                json.dump(e, f_train)\n",
    "                f_train.write('\\n')\n",
    "        with open(devfile, 'w') as f_val:\n",
    "            for e in dev:\n",
    "                json.dump(e, f_val)\n",
    "                f_val.write('\\n')\n",
    "        with open(testfile, 'w') as f_test:\n",
    "            for e in test:\n",
    "                json.dump(e, f_test)\n",
    "                f_test.write('\\n')\n",
    "\n",
    "        f_log.write(f'Counting rare class in Fold {fold} \\n')\n",
    "        f_log.write('train ' + f\"{Counter([sum([1 if tag == 'context' else 0 for tag in e['labels']]) for e in train])} / {len(train)}\\n\")\n",
    "        f_log.write('dev ' + f\"{Counter([sum([1 if tag == 'context' else 0 for tag in e['labels']]) for e in dev])} / {len(dev)}\\n\")\n",
    "        f_log.write('test ' + f\"{Counter([sum([1 if tag == 'context' else 0 for tag in e['labels']]) for e in test])} / {len(test)}\\n\")\n",
    "        f_log.write('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

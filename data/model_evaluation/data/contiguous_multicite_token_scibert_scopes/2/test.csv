token_context,word_context,seg_context,sent_cotext,label
"['follow the data preprocessing protocol from  #TAUTHOR_TAG.', 'we use the grid corpus']","['follow the data preprocessing protocol from  #TAUTHOR_TAG.', 'we use the grid corpus [ 13 ], which consists of video and audio recordings of 34 speakers ( which we name s1 to s34 ) saying 1000 sentences each.', 'all sentences have a fixed structure : command ( 4 ) + color ( 4 ) + preposition ( 4 ) + letter ( 25 ) + digit ( 10 ) + adverb ( 4 ), for example "" place red']","['follow the data preprocessing protocol from  #TAUTHOR_TAG.', 'we use the grid corpus [ 13 ], which consists of video and audio recordings of 34 speakers ( which we name s1 to s34 ) saying 1000 sentences each.', 'all sentences have a fixed']","['follow the data preprocessing protocol from  #TAUTHOR_TAG.', 'we use the grid corpus [ 13 ], which consists of video and audio recordings of 34 speakers ( which we name s1 to s34 ) saying 1000 sentences each.', 'all sentences have a fixed structure : command ( 4 ) + color ( 4 ) + preposition ( 4 ) + letter ( 25 ) + digit ( 10 ) + adverb ( 4 ), for example "" place red at j 2, please "", where the number of alternative words is given in parentheses.', 'there are 51 distinct words ; alternatives are randomly distributed so that context cannot be used for classification.', 'each sentence has a length of 3 seconds at 25 frames per second, so the total data per speaker is 3000 seconds ( 50 minutes ).', 'using the annotations contained in the corpus, we segmented all videos at word level, yielding 6000 word samples per speaker.', 'we experiment on speakers s1 - s19 : speakers 1 - 9 form the development speakers, used to determine optimal parameters ; speakers 10 - 19 are the evaluation speakers, held back until the final evaluation of the systems.', '']",5
"['follow the data preprocessing protocol from  #TAUTHOR_TAG.', 'we use the grid corpus']","['follow the data preprocessing protocol from  #TAUTHOR_TAG.', 'we use the grid corpus [ 13 ], which consists of video and audio recordings of 34 speakers ( which we name s1 to s34 ) saying 1000 sentences each.', 'all sentences have a fixed structure : command ( 4 ) + color ( 4 ) + preposition ( 4 ) + letter ( 25 ) + digit ( 10 ) + adverb ( 4 ), for example "" place red']","['follow the data preprocessing protocol from  #TAUTHOR_TAG.', 'we use the grid corpus [ 13 ], which consists of video and audio recordings of 34 speakers ( which we name s1 to s34 ) saying 1000 sentences each.', 'all sentences have a fixed']","['follow the data preprocessing protocol from  #TAUTHOR_TAG.', 'we use the grid corpus [ 13 ], which consists of video and audio recordings of 34 speakers ( which we name s1 to s34 ) saying 1000 sentences each.', 'all sentences have a fixed structure : command ( 4 ) + color ( 4 ) + preposition ( 4 ) + letter ( 25 ) + digit ( 10 ) + adverb ( 4 ), for example "" place red at j 2, please "", where the number of alternative words is given in parentheses.', 'there are 51 distinct words ; alternatives are randomly distributed so that context cannot be used for classification.', 'each sentence has a length of 3 seconds at 25 frames per second, so the total data per speaker is 3000 seconds ( 50 minutes ).', 'using the annotations contained in the corpus, we segmented all videos at word level, yielding 6000 word samples per speaker.', 'we experiment on speakers s1 - s19 : speakers 1 - 9 form the development speakers, used to determine optimal parameters ; speakers 10 - 19 are the evaluation speakers, held back until the final evaluation of the systems.', '']",5
"[' #TAUTHOR_TAG.', 'we run the lipreader as a single - speaker system with different topologies, optionally using dropout ( always with 50']","[' #TAUTHOR_TAG.', 'we run the lipreader as a single - speaker system with different topologies, optionally using dropout ( always with 50 % dropout ratio ) to avoid overfitting the training set.', 'adversarial training is not used ( i. e.']","['prior work  #TAUTHOR_TAG.', 'we run the lipreader as a single - speaker system with different topologies, optionally using dropout ( always with 50 % dropout ratio ) to avoid overfitting the training set.', 'adversarial training is not used (']","['first experiment deals with establishing a baseline for our experiments, building on prior work  #TAUTHOR_TAG.', 'we run the lipreader as a single - speaker system with different topologies, optionally using dropout ( always with 50 % dropout ratio ) to avoid overfitting the training set.', 'adversarial training is not used ( i. e. the weight in figure 2 is set to zero ).', 'table 1 shows the resulting test set accuracies averaged over the development speakers.', 'without using dropout, the accuracy on the test set is ∼79 %.', 'note in particular that the baseline cannot substantially be improved by increasing the layer size or adding more layers.', '']",5
[') best system from  #TAUTHOR_TAG'],['recomputed ) best system from  #TAUTHOR_TAG'],['recomputed ) best system from  #TAUTHOR_TAG'],"['', 'learn to confuse speakers instead of separating them. the speaker classifier and the joint network work for opposite objectives ( hence, "" adversarial "" ) ; an idea first presented in the context of factorial codes [ 39 ].', 'figure 2 shows a graphical overview of the system : the joint part is at the top, at the bottom are word classifier', '( left ) and speaker classifier ( right ). table 1 : baseline word accuracies on single speakers, averaged over the development set, with standard deviation. layer types', 'are fc ( fully connected feedforward ), dp ( dropout ), and lstm, followed by the number of neurons / cells. * marks the ( reimplemented and recomputed ) best system from  #TAUTHOR_TAG']",4
[') best system from  #TAUTHOR_TAG'],['recomputed ) best system from  #TAUTHOR_TAG'],['recomputed ) best system from  #TAUTHOR_TAG'],"['', 'learn to confuse speakers instead of separating them. the speaker classifier and the joint network work for opposite objectives ( hence, "" adversarial "" ) ; an idea first presented in the context of factorial codes [ 39 ].', 'figure 2 shows a graphical overview of the system : the joint part is at the top, at the bottom are word classifier', '( left ) and speaker classifier ( right ). table 1 : baseline word accuracies on single speakers, averaged over the development set, with standard deviation. layer types', 'are fc ( fully connected feedforward ), dp ( dropout ), and lstm, followed by the number of neurons / cells. * marks the ( reimplemented and recomputed ) best system from  #TAUTHOR_TAG']",6
"['adjuncts  #TAUTHOR_TAG.', 'whereas']","['adjuncts  #TAUTHOR_TAG.', 'whereas']","['with specific adjuncts  #TAUTHOR_TAG.', 'whereas']","['describe a computational verb lexicon called verbnet which utilizes levin verb classes  #AUTHOR_TAG to systematically construct lexical entries.', 'we have used lexicalized tree adjoining grammar ( ltag )  #AUTHOR_TAG to capture the syntax associated with each verb class, and have added semantic predicates.', 'we also show how regular extensions of verb meaning can be achieved through the adjunction of particular syntactic phrases.', 'we base these regular extensions on intersective levin classes, a fine - grained variation on levin classes, as a source of semantic components associated with specific adjuncts  #TAUTHOR_TAG.', 'whereas previous research on tying semantics to levin classes  #AUTHOR_TAG has not explicitly implemented the close relation between syntax and semantics hypothesized by levin, our lexical resource combines traditional lexical semantic information, such as thematic roles and semantic predicates, with syntactic frames and selectional restrictions.', 'in order to increase the utility of verbnet, we also include links to entries in wordnet, which is one of the most widely used online lexical databases in natural language processing applications']",5
"['adjuncts  #TAUTHOR_TAG.', 'whereas']","['adjuncts  #TAUTHOR_TAG.', 'whereas']","['with specific adjuncts  #TAUTHOR_TAG.', 'whereas']","['describe a computational verb lexicon called verbnet which utilizes levin verb classes  #AUTHOR_TAG to systematically construct lexical entries.', 'we have used lexicalized tree adjoining grammar ( ltag )  #AUTHOR_TAG to capture the syntax associated with each verb class, and have added semantic predicates.', 'we also show how regular extensions of verb meaning can be achieved through the adjunction of particular syntactic phrases.', 'we base these regular extensions on intersective levin classes, a fine - grained variation on levin classes, as a source of semantic components associated with specific adjuncts  #TAUTHOR_TAG.', 'whereas previous research on tying semantics to levin classes  #AUTHOR_TAG has not explicitly implemented the close relation between syntax and semantics hypothesized by levin, our lexical resource combines traditional lexical semantic information, such as thematic roles and semantic predicates, with syntactic frames and selectional restrictions.', 'in order to increase the utility of verbnet, we also include links to entries in wordnet, which is one of the most widely used online lexical databases in natural language processing applications']",0
[' #TAUTHOR_TAG'],"['this would conflict with the causation of motion', 'which is the intrinsic meaning of the class  #TAUTHOR_TAG.  #AUTHOR_TAG and  #AUTHOR_TAG also defined compositional semantics for classes of verbs implemented in fb - ltag, but they represented general semantic components (']","[' #TAUTHOR_TAG.  #AUTHOR_TAG and  #AUTHOR_TAG also defined compositional semantics for classes of verbs implemented in fb - ltag, but they represented general semantic components (']","['', 'exertion of force. adjunction of a path pp implying motion modifies membership of these verbs to the carry class. push / pull verbs can appear in the conative construction,', 'which emphasizes their forceful semantic component and ability to express an attempted action where any result that might be associated with', 'the verb is not necessarily achieved ; carry verbs ( used with a goal or directional phrase ) cannot take the conative alternation because this would conflict with the causation of motion', 'which is the intrinsic meaning of the class  #TAUTHOR_TAG.  #AUTHOR_TAG and  #AUTHOR_TAG also defined compositional semantics for classes of verbs implemented in fb - ltag, but they represented general semantic components ( e. g., motion, manner ) as features on the nodes of the trees. our use of separate logical forms gives a more detailed semantics for the sentence, so that for an event involving motion, it is possible to know not only that the event has a motion semantic component, but also which entity is actually in motion']",0
"['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information,']","['. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['and syllable - word seg - mentation will directly influence the stw conversion accuracy. conventionally, there are two approaches to resolve the two critical problems : ( 1 ) linguistic approach : based on syntax parsing, semantic template matching and contextual information  #AUTHOR_TAG ; and ( 2 ) statistical approach : based on the n - gram models where n is usually 2, i. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user - friendly than', 'the statistical approach on understanding why such a system makes a mistake. the statistical language model ( slm ) used in the statistical approach requires less effort and has been widely adopted in commercial chinese input systems. in our previous work  #TAUTHOR_TAG, a wordpair ( wp ) identifier was proposed and shown a simple and effective way to improve chinese input systems by providing tonal and toneless stw accuracies of 98. 5 % and 90. 7 % on the identified poly - syllabic words, respectively. in  #TAUTHOR_TAG, we have shown that the wp identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better stw accuracy to improve chinese input systems. as per our computation, poly - syllabic words cover about 70 % characters of chinese sentences. since the identified character ratio of the wp identifier  #TAUTHOR_TAG is about 55 %, there are still about 15 % improving', 'room left. the objective of this study is to illustrate a word support model ( wsm ) that is able to improve our wp - identifier', 'by achieving better identified character ratio and stw accuracy on the identified poly - syllabic words with the same word - pair database. we conduct stw experiments to show the tonal and toneless stw accuracies of a commercial input product ( microsoft input method editor 2003, msime )', ', and an optimized bigram model, bigram  #TAUTHOR_TAG, can both be improved by our wsm and achieve better st', '##w improvements than that of these systems with the wp identifier. the remainder of this paper is arranged as follows.', 'in section 2, we present an auto wordpair ( auto - wp ) generation used to generate the wp', 'database. then, we develop a word support model with the wp database to perform stw conversion on identifying words from the chinese syllables. in section 3, we report and analyze our stw experimental results. finally, in section 4, we give our conclusions and suggest some future research directions']",0
"['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information,']","['. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['and syllable - word seg - mentation will directly influence the stw conversion accuracy. conventionally, there are two approaches to resolve the two critical problems : ( 1 ) linguistic approach : based on syntax parsing, semantic template matching and contextual information  #AUTHOR_TAG ; and ( 2 ) statistical approach : based on the n - gram models where n is usually 2, i. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user - friendly than', 'the statistical approach on understanding why such a system makes a mistake. the statistical language model ( slm ) used in the statistical approach requires less effort and has been widely adopted in commercial chinese input systems. in our previous work  #TAUTHOR_TAG, a wordpair ( wp ) identifier was proposed and shown a simple and effective way to improve chinese input systems by providing tonal and toneless stw accuracies of 98. 5 % and 90. 7 % on the identified poly - syllabic words, respectively. in  #TAUTHOR_TAG, we have shown that the wp identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better stw accuracy to improve chinese input systems. as per our computation, poly - syllabic words cover about 70 % characters of chinese sentences. since the identified character ratio of the wp identifier  #TAUTHOR_TAG is about 55 %, there are still about 15 % improving', 'room left. the objective of this study is to illustrate a word support model ( wsm ) that is able to improve our wp - identifier', 'by achieving better identified character ratio and stw accuracy on the identified poly - syllabic words with the same word - pair database. we conduct stw experiments to show the tonal and toneless stw accuracies of a commercial input product ( microsoft input method editor 2003, msime )', ', and an optimized bigram model, bigram  #TAUTHOR_TAG, can both be improved by our wsm and achieve better st', '##w improvements than that of these systems with the wp identifier. the remainder of this paper is arranged as follows.', 'in section 2, we present an auto wordpair ( auto - wp ) generation used to generate the wp', 'database. then, we develop a word support model with the wp database to perform stw conversion on identifying words from the chinese syllables. in section 3, we report and analyze our stw experimental results. finally, in section 4, we give our conclusions and suggest some future research directions']",0
"['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information,']","['. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['and syllable - word seg - mentation will directly influence the stw conversion accuracy. conventionally, there are two approaches to resolve the two critical problems : ( 1 ) linguistic approach : based on syntax parsing, semantic template matching and contextual information  #AUTHOR_TAG ; and ( 2 ) statistical approach : based on the n - gram models where n is usually 2, i. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user - friendly than', 'the statistical approach on understanding why such a system makes a mistake. the statistical language model ( slm ) used in the statistical approach requires less effort and has been widely adopted in commercial chinese input systems. in our previous work  #TAUTHOR_TAG, a wordpair ( wp ) identifier was proposed and shown a simple and effective way to improve chinese input systems by providing tonal and toneless stw accuracies of 98. 5 % and 90. 7 % on the identified poly - syllabic words, respectively. in  #TAUTHOR_TAG, we have shown that the wp identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better stw accuracy to improve chinese input systems. as per our computation, poly - syllabic words cover about 70 % characters of chinese sentences. since the identified character ratio of the wp identifier  #TAUTHOR_TAG is about 55 %, there are still about 15 % improving', 'room left. the objective of this study is to illustrate a word support model ( wsm ) that is able to improve our wp - identifier', 'by achieving better identified character ratio and stw accuracy on the identified poly - syllabic words with the same word - pair database. we conduct stw experiments to show the tonal and toneless stw accuracies of a commercial input product ( microsoft input method editor 2003, msime )', ', and an optimized bigram model, bigram  #TAUTHOR_TAG, can both be improved by our wsm and achieve better st', '##w improvements than that of these systems with the wp identifier. the remainder of this paper is arranged as follows.', 'in section 2, we present an auto wordpair ( auto - wp ) generation used to generate the wp', 'database. then, we develop a word support model with the wp database to perform stw conversion on identifying words from the chinese syllables. in section 3, we report and analyze our stw experimental results. finally, in section 4, we give our conclusions and suggest some future research directions']",0
"['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information,']","['. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['and syllable - word seg - mentation will directly influence the stw conversion accuracy. conventionally, there are two approaches to resolve the two critical problems : ( 1 ) linguistic approach : based on syntax parsing, semantic template matching and contextual information  #AUTHOR_TAG ; and ( 2 ) statistical approach : based on the n - gram models where n is usually 2, i. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user - friendly than', 'the statistical approach on understanding why such a system makes a mistake. the statistical language model ( slm ) used in the statistical approach requires less effort and has been widely adopted in commercial chinese input systems. in our previous work  #TAUTHOR_TAG, a wordpair ( wp ) identifier was proposed and shown a simple and effective way to improve chinese input systems by providing tonal and toneless stw accuracies of 98. 5 % and 90. 7 % on the identified poly - syllabic words, respectively. in  #TAUTHOR_TAG, we have shown that the wp identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better stw accuracy to improve chinese input systems. as per our computation, poly - syllabic words cover about 70 % characters of chinese sentences. since the identified character ratio of the wp identifier  #TAUTHOR_TAG is about 55 %, there are still about 15 % improving', 'room left. the objective of this study is to illustrate a word support model ( wsm ) that is able to improve our wp - identifier', 'by achieving better identified character ratio and stw accuracy on the identified poly - syllabic words with the same word - pair database. we conduct stw experiments to show the tonal and toneless stw accuracies of a commercial input product ( microsoft input method editor 2003, msime )', ', and an optimized bigram model, bigram  #TAUTHOR_TAG, can both be improved by our wsm and achieve better st', '##w improvements than that of these systems with the wp identifier. the remainder of this paper is arranged as follows.', 'in section 2, we present an auto wordpair ( auto - wp ) generation used to generate the wp', 'database. then, we develop a word support model with the wp database to perform stw conversion on identifying words from the chinese syllables. in section 3, we report and analyze our stw experimental results. finally, in section 4, we give our conclusions and suggest some future research directions']",0
"['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information,']","['. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['and syllable - word seg - mentation will directly influence the stw conversion accuracy. conventionally, there are two approaches to resolve the two critical problems : ( 1 ) linguistic approach : based on syntax parsing, semantic template matching and contextual information  #AUTHOR_TAG ; and ( 2 ) statistical approach : based on the n - gram models where n is usually 2, i. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user - friendly than', 'the statistical approach on understanding why such a system makes a mistake. the statistical language model ( slm ) used in the statistical approach requires less effort and has been widely adopted in commercial chinese input systems. in our previous work  #TAUTHOR_TAG, a wordpair ( wp ) identifier was proposed and shown a simple and effective way to improve chinese input systems by providing tonal and toneless stw accuracies of 98. 5 % and 90. 7 % on the identified poly - syllabic words, respectively. in  #TAUTHOR_TAG, we have shown that the wp identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better stw accuracy to improve chinese input systems. as per our computation, poly - syllabic words cover about 70 % characters of chinese sentences. since the identified character ratio of the wp identifier  #TAUTHOR_TAG is about 55 %, there are still about 15 % improving', 'room left. the objective of this study is to illustrate a word support model ( wsm ) that is able to improve our wp - identifier', 'by achieving better identified character ratio and stw accuracy on the identified poly - syllabic words with the same word - pair database. we conduct stw experiments to show the tonal and toneless stw accuracies of a commercial input product ( microsoft input method editor 2003, msime )', ', and an optimized bigram model, bigram  #TAUTHOR_TAG, can both be improved by our wsm and achieve better st', '##w improvements than that of these systems with the wp identifier. the remainder of this paper is arranged as follows.', 'in section 2, we present an auto wordpair ( auto - wp ) generation used to generate the wp', 'database. then, we develop a word support model with the wp database to perform stw conversion on identifying words from the chinese syllables. in section 3, we report and analyze our stw experimental results. finally, in section 4, we give our conclusions and suggest some future research directions']",0
"['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information,']","['. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['and syllable - word seg - mentation will directly influence the stw conversion accuracy. conventionally, there are two approaches to resolve the two critical problems : ( 1 ) linguistic approach : based on syntax parsing, semantic template matching and contextual information  #AUTHOR_TAG ; and ( 2 ) statistical approach : based on the n - gram models where n is usually 2, i. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user - friendly than', 'the statistical approach on understanding why such a system makes a mistake. the statistical language model ( slm ) used in the statistical approach requires less effort and has been widely adopted in commercial chinese input systems. in our previous work  #TAUTHOR_TAG, a wordpair ( wp ) identifier was proposed and shown a simple and effective way to improve chinese input systems by providing tonal and toneless stw accuracies of 98. 5 % and 90. 7 % on the identified poly - syllabic words, respectively. in  #TAUTHOR_TAG, we have shown that the wp identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better stw accuracy to improve chinese input systems. as per our computation, poly - syllabic words cover about 70 % characters of chinese sentences. since the identified character ratio of the wp identifier  #TAUTHOR_TAG is about 55 %, there are still about 15 % improving', 'room left. the objective of this study is to illustrate a word support model ( wsm ) that is able to improve our wp - identifier', 'by achieving better identified character ratio and stw accuracy on the identified poly - syllabic words with the same word - pair database. we conduct stw experiments to show the tonal and toneless stw accuracies of a commercial input product ( microsoft input method editor 2003, msime )', ', and an optimized bigram model, bigram  #TAUTHOR_TAG, can both be improved by our wsm and achieve better st', '##w improvements than that of these systems with the wp identifier. the remainder of this paper is arranged as follows.', 'in section 2, we present an auto wordpair ( auto - wp ) generation used to generate the wp', 'database. then, we develop a word support model with the wp database to perform stw conversion on identifying words from the chinese syllables. in section 3, we report and analyze our stw experimental results. finally, in section 4, we give our conclusions and suggest some future research directions']",0
"['traditional chinese ( msime ) as our experimental commercial chinese input system.', 'in addition, following  #TAUTHOR_TAG, an optimized bigram model called bigram was developed.', 'the bigram stw system is a bigrambased model developing by srilm  #AUTHOR_TAG with good - turing']","['traditional chinese ( msime ) as our experimental commercial chinese input system.', 'in addition, following  #TAUTHOR_TAG, an optimized bigram model called bigram was developed.', 'the bigram stw system is a bigrambased model developing by srilm  #AUTHOR_TAG with good - turing back - off smoothing  #AUTHOR_TAG, as well as']","['traditional chinese ( msime ) as our experimental commercial chinese input system.', 'in addition, following  #TAUTHOR_TAG, an optimized bigram model called bigram was developed.', 'the bigram stw system is a bigrambased model developing by srilm  #AUTHOR_TAG with good - turing back - off smoothing  #AUTHOR_TAG, as well as']","['selected microsoft input method editor 2003 for traditional chinese ( msime ) as our experimental commercial chinese input system.', 'in addition, following  #TAUTHOR_TAG, an optimized bigram model called bigram was developed.', 'the bigram stw system is a bigrambased model developing by srilm  #AUTHOR_TAG with good - turing back - off smoothing  #AUTHOR_TAG, as well as forward and backward longest syllable - word first strategies  #AUTHOR_TAG.', 'the system dictionary of the bigram is same with that of the wp identifier and the wsm.', '']",0
"['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information,']","['. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['and syllable - word seg - mentation will directly influence the stw conversion accuracy. conventionally, there are two approaches to resolve the two critical problems : ( 1 ) linguistic approach : based on syntax parsing, semantic template matching and contextual information  #AUTHOR_TAG ; and ( 2 ) statistical approach : based on the n - gram models where n is usually 2, i. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user - friendly than', 'the statistical approach on understanding why such a system makes a mistake. the statistical language model ( slm ) used in the statistical approach requires less effort and has been widely adopted in commercial chinese input systems. in our previous work  #TAUTHOR_TAG, a wordpair ( wp ) identifier was proposed and shown a simple and effective way to improve chinese input systems by providing tonal and toneless stw accuracies of 98. 5 % and 90. 7 % on the identified poly - syllabic words, respectively. in  #TAUTHOR_TAG, we have shown that the wp identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better stw accuracy to improve chinese input systems. as per our computation, poly - syllabic words cover about 70 % characters of chinese sentences. since the identified character ratio of the wp identifier  #TAUTHOR_TAG is about 55 %, there are still about 15 % improving', 'room left. the objective of this study is to illustrate a word support model ( wsm ) that is able to improve our wp - identifier', 'by achieving better identified character ratio and stw accuracy on the identified poly - syllabic words with the same word - pair database. we conduct stw experiments to show the tonal and toneless stw accuracies of a commercial input product ( microsoft input method editor 2003, msime )', ', and an optimized bigram model, bigram  #TAUTHOR_TAG, can both be improved by our wsm and achieve better st', '##w improvements than that of these systems with the wp identifier. the remainder of this paper is arranged as follows.', 'in section 2, we present an auto wordpair ( auto - wp ) generation used to generate the wp', 'database. then, we develop a word support model with the wp database to perform stw conversion on identifying words from the chinese syllables. in section 3, we report and analyze our stw experimental results. finally, in section 4, we give our conclusions and suggest some future research directions']",1
"['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information,']","['. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic']","['and syllable - word seg - mentation will directly influence the stw conversion accuracy. conventionally, there are two approaches to resolve the two critical problems : ( 1 ) linguistic approach : based on syntax parsing, semantic template matching and contextual information  #AUTHOR_TAG ; and ( 2 ) statistical approach : based on the n - gram models where n is usually 2, i. e. bigram model  #AUTHOR_TAG lee 2003', '). from the studies ( hsu 1994 ;  #TAUTHOR_TAG, the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user - friendly than', 'the statistical approach on understanding why such a system makes a mistake. the statistical language model ( slm ) used in the statistical approach requires less effort and has been widely adopted in commercial chinese input systems. in our previous work  #TAUTHOR_TAG, a wordpair ( wp ) identifier was proposed and shown a simple and effective way to improve chinese input systems by providing tonal and toneless stw accuracies of 98. 5 % and 90. 7 % on the identified poly - syllabic words, respectively. in  #TAUTHOR_TAG, we have shown that the wp identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better stw accuracy to improve chinese input systems. as per our computation, poly - syllabic words cover about 70 % characters of chinese sentences. since the identified character ratio of the wp identifier  #TAUTHOR_TAG is about 55 %, there are still about 15 % improving', 'room left. the objective of this study is to illustrate a word support model ( wsm ) that is able to improve our wp - identifier', 'by achieving better identified character ratio and stw accuracy on the identified poly - syllabic words with the same word - pair database. we conduct stw experiments to show the tonal and toneless stw accuracies of a commercial input product ( microsoft input method editor 2003, msime )', ', and an optimized bigram model, bigram  #TAUTHOR_TAG, can both be improved by our wsm and achieve better st', '##w improvements than that of these systems with the wp identifier. the remainder of this paper is arranged as follows.', 'in section 2, we present an auto wordpair ( auto - wp ) generation used to generate the wp', 'database. then, we develop a word support model with the wp database to perform stw conversion on identifying words from the chinese syllables. in section 3, we report and analyze our stw experimental results. finally, in section 4, we give our conclusions and suggest some future research directions']",5
[' #TAUTHOR_TAG step 1'],[' #TAUTHOR_TAG step 1.'],[' #TAUTHOR_TAG step 1.'],"[' #TAUTHOR_TAG step 1. get forward and backward word segmentations : generate two types of word segmentations for a given chinese sentence by forward maximum matching ( fmm ) and backward maximum matching ( bmm ) techniques  #AUTHOR_TAG with the system dictionary.', 'step 2. get initial wp set : extract all the combinations of word - pairs from the fmm and the bmm segmentations of step 1 to be the initial wp set.', 'step 3. get finial wp set : select out the wordpairs comprised of two poly - syllabic words from the initial wp set into the finial wp set.', 'for the final wp set, if the word - pair is not found in the wp data - base, insert it into the wp database and set its frequency to 1 ; otherwise, increase its frequency by 1']",5
"['purpose of this experiment is to demonstrate the tonal and toneless stw accuracies among the identified words by using the wsm with the system wp database.', 'the comparative system is the wp identifier  #TAUTHOR_TAG.', 'table 2 is the experimental results.', 'the wp database and system dictionary of the wp identifier is same with that of the wsm.', 'from']","['purpose of this experiment is to demonstrate the tonal and toneless stw accuracies among the identified words by using the wsm with the system wp database.', 'the comparative system is the wp identifier  #TAUTHOR_TAG.', 'table 2 is the experimental results.', 'the wp database and system dictionary of the wp identifier is same with that of the wsm.', 'from']","['purpose of this experiment is to demonstrate the tonal and toneless stw accuracies among the identified words by using the wsm with the system wp database.', 'the comparative system is the wp identifier  #TAUTHOR_TAG.', 'table 2 is the experimental results.', 'the wp database and system dictionary of the wp identifier is same with that of the wsm.', 'from']","['purpose of this experiment is to demonstrate the tonal and toneless stw accuracies among the identified words by using the wsm with the system wp database.', 'the comparative system is the wp identifier  #TAUTHOR_TAG.', 'table 2 is the experimental results.', 'the wp database and system dictionary of the wp identifier is same with that of the wsm.', 'from table']",5
"['traditional chinese ( msime ) as our experimental commercial chinese input system.', 'in addition, following  #TAUTHOR_TAG, an optimized bigram model called bigram was developed.', 'the bigram stw system is a bigrambased model developing by srilm  #AUTHOR_TAG with good - turing']","['traditional chinese ( msime ) as our experimental commercial chinese input system.', 'in addition, following  #TAUTHOR_TAG, an optimized bigram model called bigram was developed.', 'the bigram stw system is a bigrambased model developing by srilm  #AUTHOR_TAG with good - turing back - off smoothing  #AUTHOR_TAG, as well as']","['traditional chinese ( msime ) as our experimental commercial chinese input system.', 'in addition, following  #TAUTHOR_TAG, an optimized bigram model called bigram was developed.', 'the bigram stw system is a bigrambased model developing by srilm  #AUTHOR_TAG with good - turing back - off smoothing  #AUTHOR_TAG, as well as']","['selected microsoft input method editor 2003 for traditional chinese ( msime ) as our experimental commercial chinese input system.', 'in addition, following  #TAUTHOR_TAG, an optimized bigram model called bigram was developed.', 'the bigram stw system is a bigrambased model developing by srilm  #AUTHOR_TAG with good - turing back - off smoothing  #AUTHOR_TAG, as well as forward and backward longest syllable - word first strategies  #AUTHOR_TAG.', 'the system dictionary of the bigram is same with that of the wp identifier and the wsm.', '']",5
['of our previous work  #TAUTHOR_TAG'],['of our previous work  #TAUTHOR_TAG'],"['of our previous work  #TAUTHOR_TAG.', '( 2']","['', 'this observation is similarly with that of our previous work  #TAUTHOR_TAG.', '( 2 ) the major problem of error conversions in tonal and toneless stw systems is different.', '']",3
['of our previous work  #TAUTHOR_TAG'],['of our previous work  #TAUTHOR_TAG'],"['of our previous work  #TAUTHOR_TAG.', '( 2']","['', 'this observation is similarly with that of our previous work  #TAUTHOR_TAG.', '( 2 ) the major problem of error conversions in tonal and toneless stw systems is different.', '']",3
['the wp identifier  #TAUTHOR_TAG'],['the wp identifier  #TAUTHOR_TAG'],['the wp identifier  #TAUTHOR_TAG'],"['this paper, we present a word support model ( wsm ) to improve the wp identifier  #TAUTHOR_TAG and support the chinese language processing on the stw conversion problem.', 'all of the wp data can be generated fully automatically by applying the auto - wp on the given corpus.', 'we are encouraged by the fact that the wsm with wp knowledge is able to achieve state - of - the - art tonal and toneless stw accuracies of 99 % and 92 %, respectively, for the identified poly - syllabic words.', 'the wsm can be easily integrated into existing chinese input systems by identifying words as a post processing.', 'our experimental results show that, by applying the wsm as an adaptation processing together with the msime ( a trigram - like model ) and the bigram ( an optimized bigram model ), the average tonal and toneless stw improvements of the two chinese input systems are 37 % and 35 %, respectively.', 'currently, our wsm with the mixed wp database comprised of udn2001 and as wp database is able to achieve more than 98 % identified character ratios of poly - syllabic words in tonal and toneless stw conversions among the udn2001 and the as corpus.', '']",6
"['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['mining is a relatively new subfield in natural language processing that aims to automatically identify and extract arguments, and their underlying structures, from textual documents  #AUTHOR_TAG.', 'some such documents are written by professionals and contain well - formed, explicit arguments - i. e., propositions supported by evidence and connected through reasoning.', 'however, informal arguments in online argumentative discourses can exhibit different styles.', 'recent work has begun to model different aspects of these naturally occurring lay arguments, with tasks including stance classification  #AUTHOR_TAG, argument summarization  #AUTHOR_TAG, sarcasm detection  #AUTHOR_TAG and classification of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is the fact that arguments in online user comments, unlike those written by professionals, often have inappropriate or missing justifications.', '']",0
"['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['mining is a relatively new subfield in natural language processing that aims to automatically identify and extract arguments, and their underlying structures, from textual documents  #AUTHOR_TAG.', 'some such documents are written by professionals and contain well - formed, explicit arguments - i. e., propositions supported by evidence and connected through reasoning.', 'however, informal arguments in online argumentative discourses can exhibit different styles.', 'recent work has begun to model different aspects of these naturally occurring lay arguments, with tasks including stance classification  #AUTHOR_TAG, argument summarization  #AUTHOR_TAG, sarcasm detection  #AUTHOR_TAG and classification of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is the fact that arguments in online user comments, unlike those written by professionals, often have inappropriate or missing justifications.', '']",0
"['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['mining is a relatively new subfield in natural language processing that aims to automatically identify and extract arguments, and their underlying structures, from textual documents  #AUTHOR_TAG.', 'some such documents are written by professionals and contain well - formed, explicit arguments - i. e., propositions supported by evidence and connected through reasoning.', 'however, informal arguments in online argumentative discourses can exhibit different styles.', 'recent work has begun to model different aspects of these naturally occurring lay arguments, with tasks including stance classification  #AUTHOR_TAG, argument summarization  #AUTHOR_TAG, sarcasm detection  #AUTHOR_TAG and classification of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is the fact that arguments in online user comments, unlike those written by professionals, often have inappropriate or missing justifications.', '']",0
['. )  #TAUTHOR_TAG also used tens'],['subjective ones. )  #TAUTHOR_TAG also used tense and person counts'],['##ifiable subjective ones. )  #TAUTHOR_TAG also used tens'],"['', ' #AUTHOR_TAG extracted clause - specific features using the stanford syntactic parser and the penn treebank.', '( merely using clause tags without capturing dependencies for important clauses may not help much in distinguishing objective verifiable claims from unverifiable subjective ones. )  #TAUTHOR_TAG also used tense and person counts for distinguishing verifiable claims from unverifiable claims.', 'we hypothesize that word2vec and dependency context - based embeddings can inherently capture these linguistic characteristics and can replace these features.', 'dependency context based embeddings capture functional similarities across the words using different contexts  #AUTHOR_TAG.', ' #AUTHOR_TAG have shown that dependency - based models produce word embeddings that better capture functional properties of words for question type classification and relation detection.', 'task - specific embeddings.', 'compiling embeddings for the specific vocabulary present in the task data can also be helpful in a classification task.', ' #AUTHOR_TAG use enriched task - specific word embeddings and show improvement in a twitter sentiment classification task.', ' #AUTHOR_TAG compiled a speech - event lexicon containing the most frequent speech anchors ( predicates such as "" said "" and "" wrote "" ) from mpqa 2. 0, a corpus manually annotated for opinions and other private states.', 'these anchors can help in correctly distinguishing verifiable claims from unverifiable ones when the propositions contain both objective and subjective expressions.', 'in our work, we use factual embeddings learned from the labelled factbank corpus ( sauri and  #AUTHOR_TAG containing various speech event predicates ( see § 3. 3']",0
"['with inappropriate or missing justification  #TAUTHOR_TAG.', 'the certainty and factuality signals present in such claims may be appropriate']","['with inappropriate or missing justification  #TAUTHOR_TAG.', 'the certainty and factuality signals present in such claims may be appropriate']","['distinguishing claims.', 'in online argumentative discourse, claims often serve as implicit arguments with inappropriate or missing justification  #TAUTHOR_TAG.', 'the certainty and factuality signals present in such claims may be appropriate']","['', 'dependency embeddings of size 100 are concatenated with equally sized word2vec and factual embeddings, resulting in a 300 - dimension concatenated embedding vector.', 'factuality - and certainty - signalling embeddings.', 'we investigate the use of certainty - and factualityrelated distributed signals for distinguishing claims.', 'in online argumentative discourse, claims often serve as implicit arguments with inappropriate or missing justification  #TAUTHOR_TAG.', 'the certainty and factuality signals present in such claims may be appropriate for determining its factuality or verifiability.', 'as the claims in our data set are objective, subjective and factual types, predicates, adverbs and other modals ( related to certainty and factuality ) present in factbank 1. 0 may help in better distinguishing various types of claims.', 'as an example, consider the sentence in figure 2, a complex claim of type "" verifiable non - experiential "".', 'the predicate "" seems "" and the modal verb "" must "" can be viewed as certainty and factuality information related to the speaker\'s commitment to their utterance.', 'factual embeddings of these co - occurrence indicators can help in better identifying the type of the claim.', 'we compile these extra linguistic']",0
"['regulation room website.', '2  #TAUTHOR_TAG and  #AUTHOR_TAG used this corpus']","['regulation room website.', '2  #TAUTHOR_TAG and  #AUTHOR_TAG used this corpus']","['the regulation room website.', '2  #TAUTHOR_TAG and  #AUTHOR_TAG used this corpus']","['experiments use the two claim data sets introduced in § 1, further details of which are given below.', 'factual and feeling debate forum posts  #AUTHOR_TAG.', 'this corpus is compiled from the internet argument corpus.', 'it consists of quote - response pairs that are manually annotated according to whether the response is primarily a "" factual "" - or "" feeling "" - based argument.', 'in our experiments, we use the training and test splits from  #AUTHOR_TAG ; these consist of claims that can span multiple sentences.', 'the annotation distribution for these splits is shown in table 1.', 'we also use a development set to tune the hyper - parameters of the model.', ' #AUTHOR_TAG.', 'this corpus consists of 9476 manually annotated sentences and independent clauses from 1047 user comments extracted from the regulation room website.', '2  #TAUTHOR_TAG and  #AUTHOR_TAG used this corpus for examining each proposition with respect to its verifiability to determine the desirable types of support for the analysis of arguments.', 'the propositions are manually annotated with three classes - "" verifiable experiential "", "" verifiable non - experiential "", and "" unverifiable "" - where the support types are evidence, optional evidence, and reason, respectively.', 'the annotation distribution and our train / test splits are shown in table 2']",0
"['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['mining is a relatively new subfield in natural language processing that aims to automatically identify and extract arguments, and their underlying structures, from textual documents  #AUTHOR_TAG.', 'some such documents are written by professionals and contain well - formed, explicit arguments - i. e., propositions supported by evidence and connected through reasoning.', 'however, informal arguments in online argumentative discourses can exhibit different styles.', 'recent work has begun to model different aspects of these naturally occurring lay arguments, with tasks including stance classification  #AUTHOR_TAG, argument summarization  #AUTHOR_TAG, sarcasm detection  #AUTHOR_TAG and classification of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is the fact that arguments in online user comments, unlike those written by professionals, often have inappropriate or missing justifications.', '']",1
"['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is']","['mining is a relatively new subfield in natural language processing that aims to automatically identify and extract arguments, and their underlying structures, from textual documents  #AUTHOR_TAG.', 'some such documents are written by professionals and contain well - formed, explicit arguments - i. e., propositions supported by evidence and connected through reasoning.', 'however, informal arguments in online argumentative discourses can exhibit different styles.', 'recent work has begun to model different aspects of these naturally occurring lay arguments, with tasks including stance classification  #AUTHOR_TAG, argument summarization  #AUTHOR_TAG, sarcasm detection  #AUTHOR_TAG and classification of propositions and arguments  #TAUTHOR_TAG.', 'of particular interest is the fact that arguments in online user comments, unlike those written by professionals, often have inappropriate or missing justifications.', '']",4
['. )  #TAUTHOR_TAG also used tens'],['subjective ones. )  #TAUTHOR_TAG also used tense and person counts'],['##ifiable subjective ones. )  #TAUTHOR_TAG also used tens'],"['', ' #AUTHOR_TAG extracted clause - specific features using the stanford syntactic parser and the penn treebank.', '( merely using clause tags without capturing dependencies for important clauses may not help much in distinguishing objective verifiable claims from unverifiable subjective ones. )  #TAUTHOR_TAG also used tense and person counts for distinguishing verifiable claims from unverifiable claims.', 'we hypothesize that word2vec and dependency context - based embeddings can inherently capture these linguistic characteristics and can replace these features.', 'dependency context based embeddings capture functional similarities across the words using different contexts  #AUTHOR_TAG.', ' #AUTHOR_TAG have shown that dependency - based models produce word embeddings that better capture functional properties of words for question type classification and relation detection.', 'task - specific embeddings.', 'compiling embeddings for the specific vocabulary present in the task data can also be helpful in a classification task.', ' #AUTHOR_TAG use enriched task - specific word embeddings and show improvement in a twitter sentiment classification task.', ' #AUTHOR_TAG compiled a speech - event lexicon containing the most frequent speech anchors ( predicates such as "" said "" and "" wrote "" ) from mpqa 2. 0, a corpus manually annotated for opinions and other private states.', 'these anchors can help in correctly distinguishing verifiable claims from unverifiable ones when the propositions contain both objective and subjective expressions.', 'in our work, we use factual embeddings learned from the labelled factbank corpus ( sauri and  #AUTHOR_TAG containing various speech event predicates ( see § 3. 3']",6
"['regulation room website.', '2  #TAUTHOR_TAG and  #AUTHOR_TAG used this corpus']","['regulation room website.', '2  #TAUTHOR_TAG and  #AUTHOR_TAG used this corpus']","['the regulation room website.', '2  #TAUTHOR_TAG and  #AUTHOR_TAG used this corpus']","['experiments use the two claim data sets introduced in § 1, further details of which are given below.', 'factual and feeling debate forum posts  #AUTHOR_TAG.', 'this corpus is compiled from the internet argument corpus.', 'it consists of quote - response pairs that are manually annotated according to whether the response is primarily a "" factual "" - or "" feeling "" - based argument.', 'in our experiments, we use the training and test splits from  #AUTHOR_TAG ; these consist of claims that can span multiple sentences.', 'the annotation distribution for these splits is shown in table 1.', 'we also use a development set to tune the hyper - parameters of the model.', ' #AUTHOR_TAG.', 'this corpus consists of 9476 manually annotated sentences and independent clauses from 1047 user comments extracted from the regulation room website.', '2  #TAUTHOR_TAG and  #AUTHOR_TAG used this corpus for examining each proposition with respect to its verifiability to determine the desirable types of support for the analysis of arguments.', 'the propositions are manually annotated with three classes - "" verifiable experiential "", "" verifiable non - experiential "", and "" unverifiable "" - where the support types are evidence, optional evidence, and reason, respectively.', 'the annotation distribution and our train / test splits are shown in table 2']",5
['rich languages like arabic  #TAUTHOR_TAG present significant'],['rich languages like arabic  #TAUTHOR_TAG present significant'],['rich languages like arabic  #TAUTHOR_TAG present significant challenges to many natural language processing applications as the one described above'],"['rich languages like arabic  #TAUTHOR_TAG present significant challenges to many natural language processing applications as the one described above because a word often conveys complex meanings decomposable into several morphemes ( i. e. prefix, stem, suffix ).', 'by segmenting words into morphemes, we can improve the performance of natural language systems including machine translation ( brown et al. 1993 ) and information retrieval ( franz, m. and mccarley, s. 2002 ).', 'in this paper, we present a cross - lingual english - arabic search engine combined with an on demand arabicenglish statistical machine translation system that relies on source language analysis for both improved search and translation.', 'we developed novel statistical learning algorithms for performing arabic word segmentation ( lee, y. et al 2003 ) into morphemes and morphological source language ( arabic ) analysis ( lee, y. et al 2003b ).', 'these components improve both monolingual ( arabic ) search and cross - lingual ( english - arabic ) search and machine translation.', 'in addition, the system supports either document translation or convolutional models for cross - lingual search ( franz, m. and mccarley, s. 2002 ).', '']",0
['rich languages like arabic  #TAUTHOR_TAG present significant'],['rich languages like arabic  #TAUTHOR_TAG present significant'],['rich languages like arabic  #TAUTHOR_TAG present significant challenges to many natural language processing applications as the one described above'],"['rich languages like arabic  #TAUTHOR_TAG present significant challenges to many natural language processing applications as the one described above because a word often conveys complex meanings decomposable into several morphemes ( i. e. prefix, stem, suffix ).', 'by segmenting words into morphemes, we can improve the performance of natural language systems including machine translation ( brown et al. 1993 ) and information retrieval ( franz, m. and mccarley, s. 2002 ).', 'in this paper, we present a cross - lingual english - arabic search engine combined with an on demand arabicenglish statistical machine translation system that relies on source language analysis for both improved search and translation.', 'we developed novel statistical learning algorithms for performing arabic word segmentation ( lee, y. et al 2003 ) into morphemes and morphological source language ( arabic ) analysis ( lee, y. et al 2003b ).', 'these components improve both monolingual ( arabic ) search and cross - lingual ( english - arabic ) search and machine translation.', 'in addition, the system supports either document translation or convolutional models for cross - lingual search ( franz, m. and mccarley, s. 2002 ).', '']",6
"['word embedding in authorship attribution for bangla language for various architectures.', 'another type of embedding, which we tried to analyze in this paper is character embedding.', 'character cnn was first introduced by zhang  #TAUTHOR_TAG']","['word embedding in authorship attribution for bangla language for various architectures.', 'another type of embedding, which we tried to analyze in this paper is character embedding.', 'character cnn was first introduced by zhang  #TAUTHOR_TAG']","['word embedding in authorship attribution for bangla language for various architectures.', 'another type of embedding, which we tried to analyze in this paper is character embedding.', 'character cnn was first introduced by zhang  #TAUTHOR_TAG']","['attribution is generally concerned with the identification of the original author of a given text from a set of given authors.', 'it has a wide range of applications including plagiarism detection, forensic linguistics, etc.', 'each author has a distinctive writing style that is exploited by statistical analysis to detect the author.', 'however, in bangla language, the amount of work done in this area is not very rich despite being one of the most spoken languages.', 'in traditional methods, texts are represented using independent features such as lexical n - gram or frequency - based representation.', 'in this approach, words of similar context are likely to be represented in different vector space as the features are independent.', 'so, the semantic values of the words might be lost, which is problematic.', 'word embedding, also generally known as distributed term representations, offers a solution to this problem by encoding semantic similarity from their co - occurrences.', 'chowdhury [ 1 ] experimented with the effectiveness of word embedding in authorship attribution for bangla language for various architectures.', 'another type of embedding, which we tried to analyze in this paper is character embedding.', 'character cnn was first introduced by zhang  #TAUTHOR_TAG for the text classification task.', 'through the empirical experiment of sebastian [ 3 ] and jozefowicz [ 4 ], character level nlp has been proven to be very promising in various ways.', 'although it may seem that character on its own does not have any semantic value, radford [ 5 ] illustrates that character - level models can capture the semantic properties of text.', 'character level models are also better at handling out - of - vocabulary words, misspelling, etc and provide an open vocabulary.', 'another major advantage is that it reduces the dimension to as low as 16, unlike word embedding where the dimension can increase up to 300 while the vocabulary is also huge.', 'so, character embedding removes the bottleneck in training tasks and gives huge advantages on computational complexity.', 'our approach in this paper was to investigate how character embedding performs in the task of authorship attribution in bangla language.', 'bangla language has numerous words with joint letters which can be written in a few different forms.', 'moreover, there are some words with the same meaning but slightly different spelling.', 'these inconsistencies are not recognized by word - level models but character - level models can capture and relate words of this kind, making such models more appropriate for bangla language.', 'comparison of character embedding with word embedding is discussed according to the findings.', 'experiments with and without pretrained embedding layers have also been done to show the effectiveness of information captured in the embeddings']",0
"['26 ].', 'pure character level classification was first explored using cnn architecture  #TAUTHOR_TAG.', 'jozefowicz']","['character level translations [ 26 ].', 'pure character level classification was first explored using cnn architecture  #TAUTHOR_TAG.', 'jozefowicz [ 4 ] shows that a character - level language model can significantly outperform']","['26 ].', 'pure character level classification was first explored using cnn architecture  #TAUTHOR_TAG.', 'jozefowicz [ 4 ] shows that a character - level language model can significantly outperform']","['words in continuous vector spaces is considered as one of the breakthroughs of nlp.', 'word embeddings are learned in the form of an embedding layer or separately in an unsupervised manner.', 'among the unsupervised techniques include continuous bag - of - words ( cbow ) and skip - gram models famously implemented by word2vec and fasttext.', 'also, there are co - occurrence statistical methods such as glove.', 'santos [ 18 ] used word embeddings with convolutional models showing significant improvements over baseline methods.', 'word embeddings have been used to improve the performance of sentiment analysis [ 19 ].', 'often pre - trained embeddings are used or are learned for specific tasks such as tree - structured long short - term memory networks [ 20 ] and multi - perspective sentence similarity modeling [ 21 ].', 'although words started to be used as units of text, various works have started to break down words and work at subword and character levels.', 'wieting [ 22 ] creates subword embedding from counts of character n - grams.', '2 ) character embedding : character level embeddings are used in various ways, either by themselves or to produce embeddings of higher levels e. g for words.', 'character embeddings have been employed in pos tagging [ 23 ], language modelling [ 23 ] and dependency parsing [ 24 ].', 'character - rnn were used for machine translation, for representing words [ 25 ] or to generate character level translations [ 26 ].', 'pure character level classification was first explored using cnn architecture  #TAUTHOR_TAG.', 'jozefowicz [ 4 ] shows that a character - level language model can significantly outperform state of the art models.', 'their best performing model combines an lstm with cnn input over the characters.', 'besides using either just word or character embeddings, ideas of combining them also have been introduced [ 27 ].', 'attempts to learn character embedding and serve as pre - trained have also been explored [ 28 ]']",0
"['- level cnn can sufficiently replace words for classifications  #TAUTHOR_TAG.', 'this means cnn does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited.', 'to this end, cnn was used in this paper to']","['- level cnn can sufficiently replace words for classifications  #TAUTHOR_TAG.', 'this means cnn does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited.', 'to this end, cnn was used in this paper to']","['- level cnn can sufficiently replace words for classifications  #TAUTHOR_TAG.', 'this means cnn does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited.', 'to this end, cnn was used in this paper to']","['- level cnn can sufficiently replace words for classifications  #TAUTHOR_TAG.', 'this means cnn does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited.', 'to this end, cnn was used in this paper to perform the task of author attribution.', 'an elaborate set of experiments were performed on 3 different datasets to conclude with an architecture that successfully extracts the character level features of any sample text.', 'the same architecture was used to prepare the pre - trained character embeddings for classification tasks.', 'the model is a deep neural network starting with 4 convolutional layers, each followed with a maxpool layer of kernel size 3.', 'as standardized in computer vision, for the convolutional layers, the number of filters increases while decreasing the kernel size at each layer.', 'the kernel sizes are respectively 7, 3, 1 and 1.', 'the number of filters is 64, 128, 256 and 256.', 'beneath all is an embedding layer where each character is represented as a vector of length v, i. e, the alphabet size.', 'the convolutional layers are stacked with a fully connected layer of 512 activation nodes, activation function relu and dropout.', 'finally, an output layer with softmax is used to provide the classification probabilities.', 'for optimization adam optimizer is used along with categorical cross - entropy as the loss function']",0
"['it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['long as the dataset is big enough.', 'when the number of authors increased, the number of samples per author decreased making it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['accuracies achieved ( in percents ) on the test set of the datasets, with pre - trained embeddings for both word and character levels are summarized in table ii.', 'because the datasets were balanced, the comparison of accuracies is sufficient.', 'accuracy comparison ( in percents ) of the proposed model with and without pre - trained character embeddings are summarized in table iii.', 'from the accuracy comparisons shown in table ii we see that skip - gram implemented by fasttext performs well in the given datasets.', 'so we can infer that subword level classification tends to extract a good amount of meaning information and styles from the text.', 'on the other hand, the word2vec models, which use entire words have worse performance.', 'character level model performs reasonably well in competition with subword level as long as the dataset is big enough.', 'when the number of authors increased, the number of samples per author decreased making it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this can be illustrated from figure 1 that with a larger number of samples, the char - cnn model raises steeply and performs competitively with the other models.', 'in terms of the number of parameters, character level model is much superior to its word - level counterparts.', 'the embedding vectors for the word level models is of size embedding vector * vocabulary size.', 'i. e. 300 * 60000.', 'on the other hand, the character embedding matrix is of size 253 * 253 given that we initially used one - hot vectors.', 'this size can also be reduced to as low as 253 * 16 as were done in some research [ 4 ].', 'another thing to consider is the time it takes to train the models.', 'for the word embedding models, a pure cnn does not work satisfactorily, so an lstm layer had to be added to add sequential information in the model.', 'this improves accuracy with the cost of taking more time to train, around 15 - 20 minutes.', 'on the other hand, the character - level model works significantly well with only using convolutional layers taking less than 2 minutes to train.', 'this effect of training time become largely magnified on largescale cases, making the word - level model unfit for light - weight devices.', 'as stated in the paper  #TAUTHOR_TAG, convnets with character embedding can completely replace words and work even without any semantic meanings.', 'which means that convolutional layers can extract whatever information necessary for author attribution, given enough data.', 'to illustrate the need of pre - trained character embeddings, we see from iii that using']",0
"['it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['long as the dataset is big enough.', 'when the number of authors increased, the number of samples per author decreased making it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['accuracies achieved ( in percents ) on the test set of the datasets, with pre - trained embeddings for both word and character levels are summarized in table ii.', 'because the datasets were balanced, the comparison of accuracies is sufficient.', 'accuracy comparison ( in percents ) of the proposed model with and without pre - trained character embeddings are summarized in table iii.', 'from the accuracy comparisons shown in table ii we see that skip - gram implemented by fasttext performs well in the given datasets.', 'so we can infer that subword level classification tends to extract a good amount of meaning information and styles from the text.', 'on the other hand, the word2vec models, which use entire words have worse performance.', 'character level model performs reasonably well in competition with subword level as long as the dataset is big enough.', 'when the number of authors increased, the number of samples per author decreased making it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this can be illustrated from figure 1 that with a larger number of samples, the char - cnn model raises steeply and performs competitively with the other models.', 'in terms of the number of parameters, character level model is much superior to its word - level counterparts.', 'the embedding vectors for the word level models is of size embedding vector * vocabulary size.', 'i. e. 300 * 60000.', 'on the other hand, the character embedding matrix is of size 253 * 253 given that we initially used one - hot vectors.', 'this size can also be reduced to as low as 253 * 16 as were done in some research [ 4 ].', 'another thing to consider is the time it takes to train the models.', 'for the word embedding models, a pure cnn does not work satisfactorily, so an lstm layer had to be added to add sequential information in the model.', 'this improves accuracy with the cost of taking more time to train, around 15 - 20 minutes.', 'on the other hand, the character - level model works significantly well with only using convolutional layers taking less than 2 minutes to train.', 'this effect of training time become largely magnified on largescale cases, making the word - level model unfit for light - weight devices.', 'as stated in the paper  #TAUTHOR_TAG, convnets with character embedding can completely replace words and work even without any semantic meanings.', 'which means that convolutional layers can extract whatever information necessary for author attribution, given enough data.', 'to illustrate the need of pre - trained character embeddings, we see from iii that using']",0
"['- level cnn can sufficiently replace words for classifications  #TAUTHOR_TAG.', 'this means cnn does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited.', 'to this end, cnn was used in this paper to']","['- level cnn can sufficiently replace words for classifications  #TAUTHOR_TAG.', 'this means cnn does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited.', 'to this end, cnn was used in this paper to']","['- level cnn can sufficiently replace words for classifications  #TAUTHOR_TAG.', 'this means cnn does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited.', 'to this end, cnn was used in this paper to']","['- level cnn can sufficiently replace words for classifications  #TAUTHOR_TAG.', 'this means cnn does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited.', 'to this end, cnn was used in this paper to perform the task of author attribution.', 'an elaborate set of experiments were performed on 3 different datasets to conclude with an architecture that successfully extracts the character level features of any sample text.', 'the same architecture was used to prepare the pre - trained character embeddings for classification tasks.', 'the model is a deep neural network starting with 4 convolutional layers, each followed with a maxpool layer of kernel size 3.', 'as standardized in computer vision, for the convolutional layers, the number of filters increases while decreasing the kernel size at each layer.', 'the kernel sizes are respectively 7, 3, 1 and 1.', 'the number of filters is 64, 128, 256 and 256.', 'beneath all is an embedding layer where each character is represented as a vector of length v, i. e, the alphabet size.', 'the convolutional layers are stacked with a fully connected layer of 512 activation nodes, activation function relu and dropout.', 'finally, an output layer with softmax is used to provide the classification probabilities.', 'for optimization adam optimizer is used along with categorical cross - entropy as the loss function']",5
"['it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['long as the dataset is big enough.', 'when the number of authors increased, the number of samples per author decreased making it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this']","['accuracies achieved ( in percents ) on the test set of the datasets, with pre - trained embeddings for both word and character levels are summarized in table ii.', 'because the datasets were balanced, the comparison of accuracies is sufficient.', 'accuracy comparison ( in percents ) of the proposed model with and without pre - trained character embeddings are summarized in table iii.', 'from the accuracy comparisons shown in table ii we see that skip - gram implemented by fasttext performs well in the given datasets.', 'so we can infer that subword level classification tends to extract a good amount of meaning information and styles from the text.', 'on the other hand, the word2vec models, which use entire words have worse performance.', 'character level model performs reasonably well in competition with subword level as long as the dataset is big enough.', 'when the number of authors increased, the number of samples per author decreased making it difficult for the character - level model to collect enough information.', 'with larger datasets, this model will be able to perform significantly better  #TAUTHOR_TAG.', 'this can be illustrated from figure 1 that with a larger number of samples, the char - cnn model raises steeply and performs competitively with the other models.', 'in terms of the number of parameters, character level model is much superior to its word - level counterparts.', 'the embedding vectors for the word level models is of size embedding vector * vocabulary size.', 'i. e. 300 * 60000.', 'on the other hand, the character embedding matrix is of size 253 * 253 given that we initially used one - hot vectors.', 'this size can also be reduced to as low as 253 * 16 as were done in some research [ 4 ].', 'another thing to consider is the time it takes to train the models.', 'for the word embedding models, a pure cnn does not work satisfactorily, so an lstm layer had to be added to add sequential information in the model.', 'this improves accuracy with the cost of taking more time to train, around 15 - 20 minutes.', 'on the other hand, the character - level model works significantly well with only using convolutional layers taking less than 2 minutes to train.', 'this effect of training time become largely magnified on largescale cases, making the word - level model unfit for light - weight devices.', 'as stated in the paper  #TAUTHOR_TAG, convnets with character embedding can completely replace words and work even without any semantic meanings.', 'which means that convolutional layers can extract whatever information necessary for author attribution, given enough data.', 'to illustrate the need of pre - trained character embeddings, we see from iii that using']",3
"['character level convnets  #TAUTHOR_TAG.', 'besides such network also work better with non - curated texts, which are hard']","['character level convnets  #TAUTHOR_TAG.', 'besides such network also work better with non - curated texts, which are hard']","['character level convnets  #TAUTHOR_TAG.', 'besides such network also work better with non - curated texts, which are hard']","['far no work has been done to evaluate the usefulness of character embeddings for classification task in bangla language.', 'we attempt to fill this gap and compare character embeddings with word embeddings showing that character embeddings perform almost as good as the best word embedding model.', 'but besides accuracy, character level classification has a greater hand in terms of memory, time and number of parameters.', 'considering the small size of our datasets, we hope to have improved performance with larger datasets, as is the case for character level convnets  #TAUTHOR_TAG.', 'besides such network also work better with non - curated texts, which are hard for wordlevel embeddings to capture, thus more applicable to real - life scenarios.', 'furthermore, we analyzed the importance of pretrained character embedding for author attribution and showed that pre - training can result in better performances.', 'since very large corpus is not available in bangla language yet, we must come up with solutions that tackle attribution tasks sufficiently well even with little data.', 'therefore our future works include the combination of both character and word level embeddings to perform attribution task, in an attempt to combine the power of both types of embeddings.', 'more advanced levels of transfer learning can also be performed by using language models in place of embeddings before classification.', 'language models and embeddings can also be combined to give greater generalization for bangla language']",3
"['- spell ( las )  #TAUTHOR_TAG,']","['listenattend - spell ( las )  #TAUTHOR_TAG,']","['- spell ( las )  #TAUTHOR_TAG,']","['', 'time - restricted self - attention was used as a drop - in replacement for individual layers in the state - of - theart lattice - free mmi model [ 26 ], an hmm - nn system.', 'hybrid self - attention / lstm encoders were studied in the context of listenattend - spell ( las )  #TAUTHOR_TAG, and the transformer was directly adapted to speech in [ 19, 28, 29 ] ; both are encoder - decoder systems.', '']",0
"[').', 'one can also assign interpretations ; for example,  #TAUTHOR_TAG argue their las self - attention heads are differentiated phoneme detectors.', 'further inductive biases like filter widths and causality could be expressed through time - restricted']","['to suffice ).', 'one can also assign interpretations ; for example,  #TAUTHOR_TAG argue their las self - attention heads are differentiated phoneme detectors.', 'further inductive biases like filter widths and causality could be expressed through time - restricted self - attention [ 26 ] and directed self - attention [ 25 ], respectively']","[').', 'one can also assign interpretations ; for example,  #TAUTHOR_TAG argue their las self - attention heads are differentiated phoneme detectors.', 'further inductive biases like filter widths and causality could be expressed through time - restricted self - attention [ 26 ] and directed']","['path length table 1 : operation complexity of each layer type, based on [ 22 ].', 't is input length, d is no. of hidden units, and k is filter / context width.', 'we also see inspiration from convolutional blocks : residual connections, layer normalization, and tied dense layers with relu for representation learning.', 'in particular, multi - head attention is akin to having a number of infinitely - wide filters whose weights adapt to the content ( allowing fewer "" filters "" to suffice ).', 'one can also assign interpretations ; for example,  #TAUTHOR_TAG argue their las self - attention heads are differentiated phoneme detectors.', 'further inductive biases like filter widths and causality could be expressed through time - restricted self - attention [ 26 ] and directed self - attention [ 25 ], respectively']",0
"['- spell ( las )  #TAUTHOR_TAG,']","['listenattend - spell ( las )  #TAUTHOR_TAG,']","['- spell ( las )  #TAUTHOR_TAG,']","['', 'time - restricted self - attention was used as a drop - in replacement for individual layers in the state - of - theart lattice - free mmi model [ 26 ], an hmm - nn system.', 'hybrid self - attention / lstm encoders were studied in the context of listenattend - spell ( las )  #TAUTHOR_TAG, and the transformer was directly adapted to speech in [ 19, 28, 29 ] ; both are encoder - decoder systems.', '']",4
"['- attentional las  #TAUTHOR_TAG, san']","['self - attentional las  #TAUTHOR_TAG, san - ctc works respectably']","['- attentional las  #TAUTHOR_TAG, san']","['train both character - and phoneme - label systems on the 80 - hour wsj training set to validate our architectural choices.', 'similar to [ 17, 19 ], we use 40 - dim.', 'mel - scale filter banks and hence 120 - dim.', 'features.', 'we warmup for 8000 steps, use a dropout of 0. 2, and switch schedules at epoch 40.', 'for the wsj dataset, we compare with similar mle - trained, end - to - end, open - vocabulary systems in table 2.', 'we get an eval92 cer of 4. 7 %, outdoing all previous ctc - like results except 4. 6 % with a trainable frontend [ 40 ].', 'we use the provided extended 3 - gram lm to retrieve wers.', 'for phoneme training, our labels come from the cmu pronunciation lexicon ( table 3 ).', 'these models train in one day ( tesla v100 ), comparable to the speech transformer [ 19 ] ; however, san - ctc gives further benefits at inference time as token predictions are generated in parallel.', 'we also evaluate design choices in table 4.', 'here, we consider the effects of downsampling and position encoding on accuracy for our fixed training regime.', 'we see that unlike self - attentional las  #TAUTHOR_TAG, san - ctc works respectably even with no position en - coding ; in fact, the contribution of position is relatively minor ( compare with [ 21 ], where location in an encoder - decoder system improved cer by 3 % absolute ).', 'lossy downsampling appears to preserve performance in cer while degrading wer ( as information about frame transitions is lost ).', 'we believe these observations align with the monotonicity and independence assumptions of ctc.', 'inspired by  #TAUTHOR_TAG, we plot the standard deviation of attention weights for each head as training progresses ; see figure 2 for details.', 'in the first layers, we similarly observe a differentiation of variances, along with wide - context heads ; in later layers, unlike  #TAUTHOR_TAG we still see mild differentiation of variances.', 'inspired by [ 26 ], we further plot the attention weights relative to the current time position ( here, per head ).', 'character labels gave forward - and backward - attending heads ( incidentally, averaging these would retrieve the bimodal distribution in [ 26 ] ) at all layers.', 'this suggests a gradual expansion of context over depth, as is often engineered in convolutional ctc.', 'this also suggests possibly using fewer heads, directed self - attention [ 25 ], and restricted contexts for faster training ( table 1 ).', 'phoneme labels gave a sharp backward - attending']",4
"['- attentional las  #TAUTHOR_TAG, san']","['self - attentional las  #TAUTHOR_TAG, san - ctc works respectably']","['- attentional las  #TAUTHOR_TAG, san']","['train both character - and phoneme - label systems on the 80 - hour wsj training set to validate our architectural choices.', 'similar to [ 17, 19 ], we use 40 - dim.', 'mel - scale filter banks and hence 120 - dim.', 'features.', 'we warmup for 8000 steps, use a dropout of 0. 2, and switch schedules at epoch 40.', 'for the wsj dataset, we compare with similar mle - trained, end - to - end, open - vocabulary systems in table 2.', 'we get an eval92 cer of 4. 7 %, outdoing all previous ctc - like results except 4. 6 % with a trainable frontend [ 40 ].', 'we use the provided extended 3 - gram lm to retrieve wers.', 'for phoneme training, our labels come from the cmu pronunciation lexicon ( table 3 ).', 'these models train in one day ( tesla v100 ), comparable to the speech transformer [ 19 ] ; however, san - ctc gives further benefits at inference time as token predictions are generated in parallel.', 'we also evaluate design choices in table 4.', 'here, we consider the effects of downsampling and position encoding on accuracy for our fixed training regime.', 'we see that unlike self - attentional las  #TAUTHOR_TAG, san - ctc works respectably even with no position en - coding ; in fact, the contribution of position is relatively minor ( compare with [ 21 ], where location in an encoder - decoder system improved cer by 3 % absolute ).', 'lossy downsampling appears to preserve performance in cer while degrading wer ( as information about frame transitions is lost ).', 'we believe these observations align with the monotonicity and independence assumptions of ctc.', 'inspired by  #TAUTHOR_TAG, we plot the standard deviation of attention weights for each head as training progresses ; see figure 2 for details.', 'in the first layers, we similarly observe a differentiation of variances, along with wide - context heads ; in later layers, unlike  #TAUTHOR_TAG we still see mild differentiation of variances.', 'inspired by [ 26 ], we further plot the attention weights relative to the current time position ( here, per head ).', 'character labels gave forward - and backward - attending heads ( incidentally, averaging these would retrieve the bimodal distribution in [ 26 ] ) at all layers.', 'this suggests a gradual expansion of context over depth, as is often engineered in convolutional ctc.', 'this also suggests possibly using fewer heads, directed self - attention [ 25 ], and restricted contexts for faster training ( table 1 ).', 'phoneme labels gave a sharp backward - attending']",4
"['- spell ( las )  #TAUTHOR_TAG,']","['listenattend - spell ( las )  #TAUTHOR_TAG,']","['- spell ( las )  #TAUTHOR_TAG,']","['', 'time - restricted self - attention was used as a drop - in replacement for individual layers in the state - of - theart lattice - free mmi model [ 26 ], an hmm - nn system.', 'hybrid self - attention / lstm encoders were studied in the context of listenattend - spell ( las )  #TAUTHOR_TAG, and the transformer was directly adapted to speech in [ 19, 28, 29 ] ; both are encoder - decoder systems.', '']",1
"['incorporation of noise / speaker contexts, as  #TAUTHOR_TAG suggest regarding the broad - context attention heads in the first layer of their self - attentional las model']","['incorporation of noise / speaker contexts, as  #TAUTHOR_TAG suggest regarding the broad - context attention heads in the first layer of their self - attentional las model']","['. g., english characters [ 36 ] ).', 'wide contexts also enable incorporation of noise / speaker contexts, as  #TAUTHOR_TAG suggest regarding the broad - context attention heads in the first layer of their self - attentional las model']","['practice, one models p ( π, t | x ) with a neural network.', 'as inspired by hmms, the model simplification of conditional independence can be tempered by multiple layers of ( recurrent ) bidirectional long short - term memory units ( blstms ) [ 1 ] [ 2 ] [ 3 ] [ 4 ].', 'however, these are computationally expensive ( table 1 ), leading to simplifications like gated recurrent units ( grus ) [ 8, 32 ] ; furthermore, the success of the relu ( x ) = max ( 0, x ) nonlinearity in preventing vanishing gradients enabled the use of vanilla bidirectional recurrent deep neural networks ( brdnns ) [ 5, 6, 33 ] to further reduce operations per layer.', 'convolutions over time and / or frequency were first used as initial layers to recurrent neural models, beginning with hmm - nns [ 34 ] and later with ctc, where they are viewed as promoting invariance to temporal and spectral translation in asr [ 8 ], or image translation in handwriting recognition [ 35 ] ; they also serve as a form of dimensionality reduction ( section 2. 4 ).', 'however, these networks were still bottlenecked by the sequentiality of operations at the recurrent layers, leading [ 8 ] to propose row convolutions for unidirectional rnns, which had finite lookaheads to enable online processing while having some future context.', 'this led to convolution - only ctc models for long - range temporal dependencies [ 9 ] [ 10 ] [ 11 ].', 'however, these models have to be very deep ( e. g., 17 - 19 convolutional layers on librispeech [ 23 ] ) to cover the same context ( table 1 ).', 'while in theory, a relatively local context could suffices for asr, this is complicated by alphabets l which violate the conditional independence assumption of ctc ( e. g., english characters [ 36 ] ).', 'wide contexts also enable incorporation of noise / speaker contexts, as  #TAUTHOR_TAG suggest regarding the broad - context attention heads in the first layer of their self - attentional las model']",1
"['latter was found necessary for self - attentional las  #TAUTHOR_TAG, as additive encodings did not give convergence.', 'however, the monotonicity of ctc is a further positional inductive bias, which may enable the success of content - only and additive encodings']","['latter was found necessary for self - attentional las  #TAUTHOR_TAG, as additive encodings did not give convergence.', 'however, the monotonicity of ctc is a further positional inductive bias, which may enable the success of content - only and additive encodings']","['adds the encoding to the embedding ; and concatenative, where one takes demb = 40 and concatenates it to the embedding.', 'the latter was found necessary for self - attentional las  #TAUTHOR_TAG, as additive encodings did not give convergence.', 'however, the monotonicity of ctc is a further positional inductive bias, which may enable the success of content - only and additive encodings']","['- attention is inherently content - based [ 22 ], and so one often encodes position into the post - embedding vectors.', 'we use standard trigonometric embeddings, where for 0 ≤ i ≤ demb / 2, we define', 'for position t. we consider three approaches : content - only [ 21 ], which forgoes position encodings ; additive [ 19 ], which takes demb = dh and adds the encoding to the embedding ; and concatenative, where one takes demb = 40 and concatenates it to the embedding.', 'the latter was found necessary for self - attentional las  #TAUTHOR_TAG, as additive encodings did not give convergence.', 'however, the monotonicity of ctc is a further positional inductive bias, which may enable the success of content - only and additive encodings']",1
"['22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2']","['in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling,']","['in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling,']","['now replace recurrent and convolutional layers for ctc with self - attention [ 24 ].', 'our proposed framework ( figure 1a ) is built around self - attention layers, as used in the transformer encoder [ 22 ], previous explorations of self - attention in asr [ 19,  #TAUTHOR_TAG, and defined in section 2. 3.', 'the other stages are downsampling, which reduces input length t via methods like those in section 2. 4 ; embedding, which learns a dh - dim. embedding that also describes token position ( section 2. 5 ) ; and projection, where each final representation is mapped framewise to logits over the intermediate alphabet l.', ""the first implements self - attention, where the success of attention in ctc and encoder - decoder models [ 14, 31 ] is parallelized by using each position's representation to attend to all others, giving a contextualized representation for that position."", 'hence, the full receptive field is immediately available at the cost of o ( t 2 ) inner products ( table 1 ), enabling richer representations in fewer layers']",3
"['- attentional las  #TAUTHOR_TAG, san']","['self - attentional las  #TAUTHOR_TAG, san - ctc works respectably']","['- attentional las  #TAUTHOR_TAG, san']","['train both character - and phoneme - label systems on the 80 - hour wsj training set to validate our architectural choices.', 'similar to [ 17, 19 ], we use 40 - dim.', 'mel - scale filter banks and hence 120 - dim.', 'features.', 'we warmup for 8000 steps, use a dropout of 0. 2, and switch schedules at epoch 40.', 'for the wsj dataset, we compare with similar mle - trained, end - to - end, open - vocabulary systems in table 2.', 'we get an eval92 cer of 4. 7 %, outdoing all previous ctc - like results except 4. 6 % with a trainable frontend [ 40 ].', 'we use the provided extended 3 - gram lm to retrieve wers.', 'for phoneme training, our labels come from the cmu pronunciation lexicon ( table 3 ).', 'these models train in one day ( tesla v100 ), comparable to the speech transformer [ 19 ] ; however, san - ctc gives further benefits at inference time as token predictions are generated in parallel.', 'we also evaluate design choices in table 4.', 'here, we consider the effects of downsampling and position encoding on accuracy for our fixed training regime.', 'we see that unlike self - attentional las  #TAUTHOR_TAG, san - ctc works respectably even with no position en - coding ; in fact, the contribution of position is relatively minor ( compare with [ 21 ], where location in an encoder - decoder system improved cer by 3 % absolute ).', 'lossy downsampling appears to preserve performance in cer while degrading wer ( as information about frame transitions is lost ).', 'we believe these observations align with the monotonicity and independence assumptions of ctc.', 'inspired by  #TAUTHOR_TAG, we plot the standard deviation of attention weights for each head as training progresses ; see figure 2 for details.', 'in the first layers, we similarly observe a differentiation of variances, along with wide - context heads ; in later layers, unlike  #TAUTHOR_TAG we still see mild differentiation of variances.', 'inspired by [ 26 ], we further plot the attention weights relative to the current time position ( here, per head ).', 'character labels gave forward - and backward - attending heads ( incidentally, averaging these would retrieve the bimodal distribution in [ 26 ] ) at all layers.', 'this suggests a gradual expansion of context over depth, as is often engineered in convolutional ctc.', 'this also suggests possibly using fewer heads, directed self - attention [ 25 ], and restricted contexts for faster training ( table 1 ).', 'phoneme labels gave a sharp backward - attending']",3
['one concatenates k consecutive frames into one  #TAUTHOR_TAG'],['one concatenates k consecutive frames into one  #TAUTHOR_TAG'],"['one concatenates k consecutive frames into one  #TAUTHOR_TAG.', 'note that ctc will still require u ≤ t / k, however']","['speech, the input length t of frames can be many times larger than the output length u, in contrast to the roughly word - to - word setting of machine translation.', 'this is especially prohibitive for self - attention in terms of memory : recall that an attention matrix of dimension', '∈ r t ×t is created, giving the t 2 factor in table 1.', 'a convolutional frontend is a typical downsampling strategy [ 8, 19 ] ; however, we leave integrating other layer types into san - ctc as future work.', 'instead, we consider three fixed approaches, from least - to most - preserving of the input data : subsampling, which only takes every k - th frame ; pooling, which aggregates every k consecutive frames via a statistic ( average, maximum ) ; reshaping, where one concatenates k consecutive frames into one  #TAUTHOR_TAG.', 'note that ctc will still require u ≤ t / k, however']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[': most research in machine learning has been focused on binary classification, in which the learned classifier outputs one of two possible answers.', 'important fundamental questions can be analyzed in terms of binary classification, but realworld natural language processing problems often involve richer output spaces.', 'in this tutorial, we will focus on classifiers with a large number of possible outputs with interesting structure.', 'notable examples include information retrieval, part - of - speech tagging, np chucking, parsing, entity extraction, and phoneme recognition.', 'our algorithmic framework will be that of online learning, for several reasons.', 'first, online algorithms are in general conceptually simple and easy to implement.', 'in particular, online algorithms process one example at a time and thus require little working memory.', 'second, our example applications have all been treated successfully using online algorithms.', 'third, the analysis of online algorithms uses simpler mathematical tools than other types of algorithms.', 'fourth, the online learning framework provides a very general setting which can be applied to a broad setting of problems, where the only machinery assumed is the ability to perform exact inference, which computes a maxima over some score function.', 'goals : ( 1 ) to provide the audience systematic methods to design, analyze and implement efficiently learning algorithms for their specific complex - output problems : from simple binary classification through multi - class categorization to information extraction, parsing and speech recognition.', '( 2 ) to introduce new online algorithms which provide state - of - the - art performance in practice backed by interesting theoretical guarantees.', 'the tutorial is divided into two parts.', 'in the first half we introduce online learning and describe the perceptron algorithm  #AUTHOR_TAG and the passive - aggressive framework  #AUTHOR_TAG.', 'we then discuss in detail an approach for deriving algorithms for complex natural language processing  #AUTHOR_TAG.', 'in the second half we discuss is detail relevant applications including text classification  #AUTHOR_TAG, named entity recognition  #TAUTHOR_TAG, parsing ( mc  #AUTHOR_TAG, and other tasks.', 'we also relate the online algorithms to their batch counterparts']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['tutorial is divided into two parts.', 'in the first half we introduce online learning and describe the perceptron algorithm  #AUTHOR_TAG and the passive - aggressive framework  #AUTHOR_TAG.', 'we then discuss in detail an approach for deriving algorithms for complex natural language processing  #AUTHOR_TAG.', 'in the second half we discuss is detail relevant applications including text classification  #AUTHOR_TAG, named entity recognition  #TAUTHOR_TAG, parsing ( mc  #AUTHOR_TAG, and other tasks.', 'we also relate the online algorithms to their batch counterparts']",5
"['', 'this paper presents some experiments carried out based on two syntactic tree alignment algorithms presented in  #TAUTHOR_TAG and [ tinsley']","['statistical machine translation systems ).', 'this paper presents some experiments carried out based on two syntactic tree alignment algorithms presented in  #TAUTHOR_TAG and [ tinsley']","['for statistical machine translation systems ).', 'this paper presents some experiments carried out based on two syntactic tree alignment algorithms presented in  #TAUTHOR_TAG and [ tinsley']","['.', 'the alignment of syntactic trees is the task of aligning the internal and leaf nodes of two sentences in different languages structured as trees.', 'the output of the alignment can be used, for instance, as knowledge resource for learning translation rules ( for rule - based machine translation systems ) or models ( for statistical machine translation systems ).', 'this paper presents some experiments carried out based on two syntactic tree alignment algorithms presented in  #TAUTHOR_TAG and [ tinsley et al. 2007 ].', 'aiming at improving the performance of internal nodes alignment, some approaches for combining the output of these two algorithms were evaluated in brazilian portuguese and english parallel trees']",0
"['aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['are aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['', 'after the alignment of leaf nodes, the internal nodes are aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to each pair of aligned leaf nodes in source and target trees based on the lexical alignment.', '']",0
"['aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['are aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['', 'after the alignment of leaf nodes, the internal nodes are aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to each pair of aligned leaf nodes in source and target trees based on the lexical alignment.', '']",0
"['', 'this paper, therefore, proposes the combination of two syntactic tree alignment methods -  #TAUTHOR_TAG ] ( a']","['( mt ).', 'this paper, therefore, proposes the combination of two syntactic tree alignment methods -  #TAUTHOR_TAG ] ( a bottom - up approach ) and [ tinsley']","['', 'this paper, therefore, proposes the combination of two syntactic tree alignment methods -  #TAUTHOR_TAG ] ( a bottom - up approach ) and [ tinsley']","['', 'the alignment produced by the automatic methods can be very useful for machine translation ( mt ).', 'this paper, therefore, proposes the combination of two syntactic tree alignment methods -  #TAUTHOR_TAG ] ( a bottom - up approach ) and [ tinsley et al. 2007 ] ( a topdown approach ) - aiming at improving their performance evaluated on brazilian portuguese ( pt ) and english ( en ) pair of languages.', '']",6
"['', 'this paper, therefore, proposes the combination of two syntactic tree alignment methods -  #TAUTHOR_TAG ] ( a']","['( mt ).', 'this paper, therefore, proposes the combination of two syntactic tree alignment methods -  #TAUTHOR_TAG ] ( a bottom - up approach ) and [ tinsley']","['', 'this paper, therefore, proposes the combination of two syntactic tree alignment methods -  #TAUTHOR_TAG ] ( a bottom - up approach ) and [ tinsley']","['', 'the alignment produced by the automatic methods can be very useful for machine translation ( mt ).', 'this paper, therefore, proposes the combination of two syntactic tree alignment methods -  #TAUTHOR_TAG ] ( a bottom - up approach ) and [ tinsley et al. 2007 ] ( a topdown approach ) - aiming at improving their performance evaluated on brazilian portuguese ( pt ) and english ( en ) pair of languages.', '']",1
"['aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['are aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to']","['', 'after the alignment of leaf nodes, the internal nodes are aligned following various approaches and distinct criteria.', 'for instance, the method presented in  #TAUTHOR_TAG ] assigns a prime number to each pair of aligned leaf nodes in source and target trees based on the lexical alignment.', '']",5
"['- based on  #TAUTHOR_TAG, our implementation ( model 1 ) assigns prime numbers to']","['- based on  #TAUTHOR_TAG, our implementation ( model 1 ) assigns prime numbers to']","['', 'model 1 - based on  #TAUTHOR_TAG, our implementation ( model 1 ) assigns prime numbers to each pair of aligned terminal nodes 1.', 'for those nonaligned terminal nodes, model 1 assigns the value 1 and for those nodes with multiple alignments, it assigns the product of the prime numbers of each alignment.', 'then, in a second step, the values are propagated']","['. 1.', 'model 1 - based on  #TAUTHOR_TAG, our implementation ( model 1 ) assigns prime numbers to each pair of aligned terminal nodes 1.', 'for those nonaligned terminal nodes, model 1 assigns the value 1 and for those nodes with multiple alignments, it assigns the product of the prime numbers of each alignment.', '']",5
"['- based on  #TAUTHOR_TAG, our implementation ( model 1 ) assigns prime numbers to']","['- based on  #TAUTHOR_TAG, our implementation ( model 1 ) assigns prime numbers to']","['', 'model 1 - based on  #TAUTHOR_TAG, our implementation ( model 1 ) assigns prime numbers to each pair of aligned terminal nodes 1.', 'for those nonaligned terminal nodes, model 1 assigns the value 1 and for those nodes with multiple alignments, it assigns the product of the prime numbers of each alignment.', 'then, in a second step, the values are propagated']","['. 1.', 'model 1 - based on  #TAUTHOR_TAG, our implementation ( model 1 ) assigns prime numbers to each pair of aligned terminal nodes 1.', 'for those nonaligned terminal nodes, model 1 assigns the value 1 and for those nodes with multiple alignments, it assigns the product of the prime numbers of each alignment.', '']",3
['of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to'],"['of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs']","['classification of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs well for co - hyponymy']","['classification of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs well for co - hyponymy detection. in another attempt,  #AUTHOR_TAG b ) proposed various', 'complex network measures which can be used as features to build a supervised classifier model for co - hyponymy detection, and showed improvements over other baseline approaches.', 'recently, with the', 'emergence of various network representation learning methods  #AUTHOR_TAG, attempts have been made to convert distributional thesa', '##uri network into low dimensional vector space.  #AUTHOR_TAG apply distributional thesaurus embedding for synonym extraction and expansion tasks whereas  #AUTHOR_TAG a ) use it', '']",0
['of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to'],"['of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs']","['classification of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs well for co - hyponymy']","['classification of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs well for co - hyponymy detection. in another attempt,  #AUTHOR_TAG b ) proposed various', 'complex network measures which can be used as features to build a supervised classifier model for co - hyponymy detection, and showed improvements over other baseline approaches.', 'recently, with the', 'emergence of various network representation learning methods  #AUTHOR_TAG, attempts have been made to convert distributional thesa', '##uri network into low dimensional vector space.  #AUTHOR_TAG apply distributional thesaurus embedding for synonym extraction and expansion tasks whereas  #AUTHOR_TAG a ) use it', '']",0
['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],"['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a set of baseline methodologies, the descriptions of which are presented in table 1.', 'following the same experimental setup, we report the accuracy measure for ten - fold cross validation and compare our models with the baselines in proposed by  #AUTHOR_TAG.', 'table 2 represents the performance of all the baseline models proposed by  #AUTHOR_TAG.', 'in table 3 we show the performance of the best supervised model ( svmdiff ) and the best semi - supervised model ( cosinep ) proposed by  #AUTHOR_TAG along with our models.', 'here, the best model proposed by  #AUTHOR_TAG b ) uses svm classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network.', '']",0
['of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to'],"['of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs']","['classification of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs well for co - hyponymy']","['classification of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs well for co - hyponymy detection. in another attempt,  #AUTHOR_TAG b ) proposed various', 'complex network measures which can be used as features to build a supervised classifier model for co - hyponymy detection, and showed improvements over other baseline approaches.', 'recently, with the', 'emergence of various network representation learning methods  #AUTHOR_TAG, attempts have been made to convert distributional thesa', '##uri network into low dimensional vector space.  #AUTHOR_TAG apply distributional thesaurus embedding for synonym extraction and expansion tasks whereas  #AUTHOR_TAG a ) use it', '']",5
"['co - hyponymy detection  #TAUTHOR_TAG b ).', 'for']","['co - hyponymy detection  #TAUTHOR_TAG b ).', 'for']","['co - hyponymy detection  #TAUTHOR_TAG b ).', 'for']","['perform experiments using three benchmark datasets for co - hyponymy detection  #TAUTHOR_TAG b ).', 'for each of these, we follow the same experimental setup as discussed by the authors and compare our method with the method proposed by the author as well as the state - of - the - art models by  #AUTHOR_TAG b ).', 'we perform the analysis of three datasets to investigate the extent of overlap present in these publicly available benchmark datasets and find out that 45. 7 % word pairs of dataset prepared by  #AUTHOR_TAG are present in dataset root9 prepared by  #TAUTHOR_TAG.', 'this intersection set comprises 27. 8 % of the root9 dataset.', 'similarly 36. 7 % word pairs of dataset prepared by  #AUTHOR_TAG are present in the whole dataset prepared by  #AUTHOR_TAG b ).', 'this intersection set comprises 44. 9 % of the dataset prepared by  #AUTHOR_TAG b )']",5
"['co - hyponymy detection  #TAUTHOR_TAG b ).', 'for']","['co - hyponymy detection  #TAUTHOR_TAG b ).', 'for']","['co - hyponymy detection  #TAUTHOR_TAG b ).', 'for']","['perform experiments using three benchmark datasets for co - hyponymy detection  #TAUTHOR_TAG b ).', 'for each of these, we follow the same experimental setup as discussed by the authors and compare our method with the method proposed by the author as well as the state - of - the - art models by  #AUTHOR_TAG b ).', 'we perform the analysis of three datasets to investigate the extent of overlap present in these publicly available benchmark datasets and find out that 45. 7 % word pairs of dataset prepared by  #AUTHOR_TAG are present in dataset root9 prepared by  #TAUTHOR_TAG.', 'this intersection set comprises 27. 8 % of the root9 dataset.', 'similarly 36. 7 % word pairs of dataset prepared by  #AUTHOR_TAG are present in the whole dataset prepared by  #AUTHOR_TAG b ).', 'this intersection set comprises 44. 9 % of the dataset prepared by  #AUTHOR_TAG b )']",5
['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],"['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a set of baseline methodologies, the descriptions of which are presented in table 1.', 'following the same experimental setup, we report the accuracy measure for ten - fold cross validation and compare our models with the baselines in proposed by  #AUTHOR_TAG.', 'table 2 represents the performance of all the baseline models proposed by  #AUTHOR_TAG.', 'in table 3 we show the performance of the best supervised model ( svmdiff ) and the best semi - supervised model ( cosinep ) proposed by  #AUTHOR_TAG along with our models.', 'here, the best model proposed by  #AUTHOR_TAG b ) uses svm classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network.', '']",5
['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],"['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a set of baseline methodologies, the descriptions of which are presented in table 1.', 'following the same experimental setup, we report the accuracy measure for ten - fold cross validation and compare our models with the baselines in proposed by  #AUTHOR_TAG.', 'table 2 represents the performance of all the baseline models proposed by  #AUTHOR_TAG.', 'in table 3 we show the performance of the best supervised model ( svmdiff ) and the best semi - supervised model ( cosinep ) proposed by  #AUTHOR_TAG along with our models.', 'here, the best model proposed by  #AUTHOR_TAG b ) uses svm classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network.', '']",5
['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],"['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a set of baseline methodologies, the descriptions of which are presented in table 1.', 'following the same experimental setup, we report the accuracy measure for ten - fold cross validation and compare our models with the baselines in proposed by  #AUTHOR_TAG.', 'table 2 represents the performance of all the baseline models proposed by  #AUTHOR_TAG.', 'in table 3 we show the performance of the best supervised model ( svmdiff ) and the best semi - supervised model ( cosinep ) proposed by  #AUTHOR_TAG along with our models.', 'here, the best model proposed by  #AUTHOR_TAG b ) uses svm classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network.', '']",5
['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],"['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a set of baseline methodologies, the descriptions of which are presented in table 1.', 'following the same experimental setup, we report the accuracy measure for ten - fold cross validation and compare our models with the baselines in proposed by  #AUTHOR_TAG.', 'table 2 represents the performance of all the baseline models proposed by  #AUTHOR_TAG.', 'in table 3 we show the performance of the best supervised model ( svmdiff ) and the best semi - supervised model ( cosinep ) proposed by  #AUTHOR_TAG along with our models.', 'here, the best model proposed by  #AUTHOR_TAG b ) uses svm classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network.', '']",5
['of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to'],"['of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs']","['classification of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs well for co - hyponymy']","['classification of hypernymy and co - hyponymy.  #TAUTHOR_TAG proposed a supervised method based on a random forest algorithm to learn taxonomic', '##al semantic relations and they have shown that the model performs well for co - hyponymy detection. in another attempt,  #AUTHOR_TAG b ) proposed various', 'complex network measures which can be used as features to build a supervised classifier model for co - hyponymy detection, and showed improvements over other baseline approaches.', 'recently, with the', 'emergence of various network representation learning methods  #AUTHOR_TAG, attempts have been made to convert distributional thesa', '##uri network into low dimensional vector space.  #AUTHOR_TAG apply distributional thesaurus embedding for synonym extraction and expansion tasks whereas  #AUTHOR_TAG a ) use it', '']",4
['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],"['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a set of baseline methodologies, the descriptions of which are presented in table 1.', 'following the same experimental setup, we report the accuracy measure for ten - fold cross validation and compare our models with the baselines in proposed by  #AUTHOR_TAG.', 'table 2 represents the performance of all the baseline models proposed by  #AUTHOR_TAG.', 'in table 3 we show the performance of the best supervised model ( svmdiff ) and the best semi - supervised model ( cosinep ) proposed by  #AUTHOR_TAG along with our models.', 'here, the best model proposed by  #AUTHOR_TAG b ) uses svm classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network.', '']",7
['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a'],['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for'],"['- hyp vs hyper  #TAUTHOR_TAG and  #AUTHOR_TAG b ) for root9 dataset a set of baseline methodologies, the descriptions of which are presented in table 1.', 'following the same experimental setup, we report the accuracy measure for ten - fold cross validation and compare our models with the baselines in proposed by  #AUTHOR_TAG.', 'table 2 represents the performance of all the baseline models proposed by  #AUTHOR_TAG.', 'in table 3 we show the performance of the best supervised model ( svmdiff ) and the best semi - supervised model ( cosinep ) proposed by  #AUTHOR_TAG along with our models.', 'here, the best model proposed by  #AUTHOR_TAG b ) uses svm classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network.', '']",3
"['', 'using the model of  #TAUTHOR_TAG, we compare several key model configurations.', 'results show that our human - translated dataset is significantly more reliable compared']","['the spider  #AUTHOR_TAG b ) dataset into chinese.', 'using the model of  #TAUTHOR_TAG, we compare several key model configurations.', 'results show that our human - translated dataset is significantly more reliable compared']","['', 'using the model of  #TAUTHOR_TAG, we compare several key model configurations.', 'results show that our human - translated dataset is significantly more reliable compared']","['', 'among a wide range of possible semantic representations, sql offers a standardized interface to knowledge bases across tasks  #AUTHOR_TAG.', ' #AUTHOR_TAG b ) released a manually labelled dataset for parsing natural language questions into complex sql, which facilitates related research.', "" #AUTHOR_TAG b )'s dataset is exclusive for english questions."", 'intuitively, the same semantic parsing task can be applied cross - lingual, since sql is a universal semantic representation and database interface.', 'however, for languages other than english, there can be added difficulties parsing into sql.', 'take chinese for example, the additional challenges can be at least two - fold.', 'first, structures of relational databases, in particular names and column names of db tables, are typically represented in english.', 'this adds to the challenges to question - to - db mapping.', 'second, the basic semantic unit for denoting columns or cells can be words, but word segmentation can be erroneous.', 'it is also interesting to study the influence of other linguistic characteristics of chinese, such as zero - pronoun, on its sql parsing.', 'we investigate parsing chinese questions to sql by creating a first dataset, and empirically evaluating a strong baseline model on the dataset.', 'in particular, we translate the spider  #AUTHOR_TAG b ) dataset into chinese.', 'using the model of  #TAUTHOR_TAG, we compare several key model configurations.', 'results show that our human - translated dataset is significantly more reliable compared to a dataset composed of machine - translated questions.', 'in addition, the overall accuracy for chinese sql semantic parsing can be comparable to that for english.', 'we found that cross - lingual word embeddings are useful for matching chinese questions with english table columns and keywords and that language characteristics have a significant influence on parsing results.', 'we release our dataset named cspider and code at https : / / github. com / taolusi / chisp']",5
"['use the neural semantic parsing method of  #TAUTHOR_TAG as the baseline model, which can be']","['use the neural semantic parsing method of  #TAUTHOR_TAG as the baseline model, which can be']","['use the neural semantic parsing method of  #TAUTHOR_TAG as the baseline model, which can be regarded as a sequence - to - tree model.', 'in particular, the input question is encoded using an lstm sequence encoder, and the output is']","['use the neural semantic parsing method of  #TAUTHOR_TAG as the baseline model, which can be regarded as a sequence - to - tree model.', 'in particular, the input question is encoded using an lstm sequence encoder, and the output is a sql query in its syntactic tree form.', '']",5
"['from  #TAUTHOR_TAG, but tuned on the chinese spider development set.', '']","['from  #TAUTHOR_TAG, but tuned on the chinese spider development set.', '']","['from  #TAUTHOR_TAG, but tuned on the chinese spider development set.', 'we use character and word embeddings from tencent embedding ; both of them are not fine - tuned during model training.', 'embedding sizes are set']","['', 'the second is component matching f1, namely the f1 scores for select, where, group by, order by and all keywords, respectively.', 'hyperparameters.', 'our hyperparameters are mostly taken from  #TAUTHOR_TAG, but tuned on the chinese spider development set.', 'we use character and word embeddings from tencent embedding ; both of them are not fine - tuned during model training.', 'embedding sizes are set to 200 for both characters and words.', 'for the different choices of keywords and column names embeddings, sizes are set to 200 and 300, respectively.', 'adam  #AUTHOR_TAG is used for optimization, with a learning rate of 1e - 4.', 'dropout is used for the output of lstm with a rate of 0. 5.', 'for word - based models, segmentation is necessary.', 'we take two segmentors with different performances, including the jieba segmentor and the model of  #AUTHOR_TAG, which we name jieba and yz, respectively.', 'to verify their accuracy, we manually segment the first 100 sentences from the test set.', 'jieba and yz give f1 scores of 89. 8 % and 91. 7 %, respectively']",5
['improving the model of  #TAUTHOR_TAG since the'],['improving the model of  #TAUTHOR_TAG since the'],"['work improving the model of  #TAUTHOR_TAG since the release of the spider dataset  #AUTHOR_TAG.', 'at the time of our investigation, however, the models are not published']","['', 'existing semantic parsing datasets for chinese include a small corpus for assigning semantic roles  #AUTHOR_TAG and semeval - 2016 task 9 for chinese semantic dependency parsing  #AUTHOR_TAG, but these data are not related to sql.', 'to our knowledge, we are the first to release a chinese sql semantic parsing dataset.', 'there has been a line of work improving the model of  #TAUTHOR_TAG since the release of the spider dataset  #AUTHOR_TAG.', 'at the time of our investigation, however, the models are not published.', 'we thus chose the model of  #AUTHOR_TAG a ) as our baseline.', 'the choice of more different neural models is orthogonal to our dataset contribution, but can empirically give more insights about the conclusions']",1
['improving the model of  #TAUTHOR_TAG since the'],['improving the model of  #TAUTHOR_TAG since the'],"['work improving the model of  #TAUTHOR_TAG since the release of the spider dataset  #AUTHOR_TAG.', 'at the time of our investigation, however, the models are not published']","['', 'existing semantic parsing datasets for chinese include a small corpus for assigning semantic roles  #AUTHOR_TAG and semeval - 2016 task 9 for chinese semantic dependency parsing  #AUTHOR_TAG, but these data are not related to sql.', 'to our knowledge, we are the first to release a chinese sql semantic parsing dataset.', 'there has been a line of work improving the model of  #TAUTHOR_TAG since the release of the spider dataset  #AUTHOR_TAG.', 'at the time of our investigation, however, the models are not published.', 'we thus chose the model of  #AUTHOR_TAG a ) as our baseline.', 'the choice of more different neural models is orthogonal to our dataset contribution, but can empirically give more insights about the conclusions']",0
"['from  #TAUTHOR_TAG, but tuned on the chinese spider development set.', '']","['from  #TAUTHOR_TAG, but tuned on the chinese spider development set.', '']","['from  #TAUTHOR_TAG, but tuned on the chinese spider development set.', 'we use character and word embeddings from tencent embedding ; both of them are not fine - tuned during model training.', 'embedding sizes are set']","['', 'the second is component matching f1, namely the f1 scores for select, where, group by, order by and all keywords, respectively.', 'hyperparameters.', 'our hyperparameters are mostly taken from  #TAUTHOR_TAG, but tuned on the chinese spider development set.', 'we use character and word embeddings from tencent embedding ; both of them are not fine - tuned during model training.', 'embedding sizes are set to 200 for both characters and words.', 'for the different choices of keywords and column names embeddings, sizes are set to 200 and 300, respectively.', 'adam  #AUTHOR_TAG is used for optimization, with a learning rate of 1e - 4.', 'dropout is used for the output of lstm with a rate of 0. 5.', 'for word - based models, segmentation is necessary.', 'we take two segmentors with different performances, including the jieba segmentor and the model of  #AUTHOR_TAG, which we name jieba and yz, respectively.', 'to verify their accuracy, we manually segment the first 100 sentences from the test set.', 'jieba and yz give f1 scores of 89. 8 % and 91. 7 %, respectively']",6
"["" #TAUTHOR_TAG's model on their english dataset but under our split."", 'ht and mt denote human translation and machine']","["" #TAUTHOR_TAG's model on their english dataset but under our split."", 'ht and mt denote human translation and machine']","["" #TAUTHOR_TAG's model on their english dataset but under our split."", 'ht and mt denote human translation and machine translation of questions, respectively.', 'both ht']","['overall exact matching results are shown in table 3.', ""in this table, eng represents the results of  #TAUTHOR_TAG's model on their english dataset but under our split."", 'ht and mt denote human translation and machine translation of questions, respectively.', 'both ht and mt results are evaluated on human translated questions.', 'c - ml and c - s denote the results of our chinese models based on characters with multi - lingual embeddings and monolingual embeddings, respectively, while wy - ml, wy - s denote the wordbased models applying yz segmentor with multilingual embeddings and monolingual embeddings, respectively.', 'finally, wj - ml and wj - s denote the word model with multi - lingual embeddings and monolingual embeddings with the jieba segmentor, respectively.', 'first, compared to the best results of human translation ( c - ml and wy - ml ), machine translation results show a large disadvantage ( e. g. 7. 1 % vs 12. 1 % using c - ml ).', 'we further did a manual inspection of 100 randomly picked machinetranslated sentences.', '']",4
"["" #TAUTHOR_TAG's model on their english dataset but under our split."", 'ht and mt denote human translation and machine']","["" #TAUTHOR_TAG's model on their english dataset but under our split."", 'ht and mt denote human translation and machine']","["" #TAUTHOR_TAG's model on their english dataset but under our split."", 'ht and mt denote human translation and machine translation of questions, respectively.', 'both ht']","['overall exact matching results are shown in table 3.', ""in this table, eng represents the results of  #TAUTHOR_TAG's model on their english dataset but under our split."", 'ht and mt denote human translation and machine translation of questions, respectively.', 'both ht and mt results are evaluated on human translated questions.', 'c - ml and c - s denote the results of our chinese models based on characters with multi - lingual embeddings and monolingual embeddings, respectively, while wy - ml, wy - s denote the wordbased models applying yz segmentor with multilingual embeddings and monolingual embeddings, respectively.', 'finally, wj - ml and wj - s denote the word model with multi - lingual embeddings and monolingual embeddings with the jieba segmentor, respectively.', 'first, compared to the best results of human translation ( c - ml and wy - ml ), machine translation results show a large disadvantage ( e. g. 7. 1 % vs 12. 1 % using c - ml ).', 'we further did a manual inspection of 100 randomly picked machinetranslated sentences.', '']",4
"['paragraphs are supplied to the', 'baseline qa model introduced in  #TAUTHOR_TAG, it improved the qa']","['paragraphs are supplied to the', 'baseline qa model introduced in  #TAUTHOR_TAG, it improved the qa']","['paragraphs are supplied to the', 'baseline qa model introduced in  #TAUTHOR_TAG, it improved the qa performance on the hidden test set by 10. 59 f', '##1 points.']","['', 'hop reasoning from a large corpus containing millions of paragraphs. when the retrieved paragraphs are supplied to the', 'baseline qa model introduced in  #TAUTHOR_TAG, it improved the qa performance on the hidden test set by 10. 59 f', '##1 points.']",0
"['paragraphs are supplied to the', 'baseline qa model introduced in  #TAUTHOR_TAG, it improved the qa']","['paragraphs are supplied to the', 'baseline qa model introduced in  #TAUTHOR_TAG, it improved the qa']","['paragraphs are supplied to the', 'baseline qa model introduced in  #TAUTHOR_TAG, it improved the qa performance on the hidden test set by 10. 59 f', '##1 points.']","['', 'hop reasoning from a large corpus containing millions of paragraphs. when the retrieved paragraphs are supplied to the', 'baseline qa model introduced in  #TAUTHOR_TAG, it improved the qa performance on the hidden test set by 10. 59 f', '##1 points.']",5
['subset  #TAUTHOR_TAG'],"[""contains questions from'hard'subset  #TAUTHOR_TAG""]","['subset  #TAUTHOR_TAG. however', ', within that hard subset, we']","['', 'modeling the chain of documents is important. this makes intuitive sense, since', 'to answer questions such as the county where a person is from ( figure', ""1 ), modeling context about the person, should be helpful. we also evaluate, if our model performs well on single - hop questions as well. this evaluation is a bit tricky to do in hotpotqa, since the evaluataion set only contains questions from'hard'subset  #TAUTHOR_TAG. however"", ', within that hard subset, we find the set of question, that has the answer span present in all', 'the supporting passages ( single - hop ( hard ) ) and only in one of the supporting passages ( multi - hop ( hard ) ) 11. the', 'intuition is that if there are multiple evidence containing the answer spans then it might be a little easier for a downstream qa model to identify the answer', 'span. figure 3 shows that our model performs equally well on both type of queries', 'and hence can be applied in a practical setting. baseline reader  #TAUTHOR_TAG table 2 shows the performance on the qa task. we were able to achieve better scores than reported in the baseline reader model of  #TAUTHOR_TAG by', 'using adam  #AUTHOR_TAG instead of standard sgd ( our re - implementation ). next, we use the top - 10 paragraphs retrieved by', '']",5
['subset  #TAUTHOR_TAG'],"[""contains questions from'hard'subset  #TAUTHOR_TAG""]","['subset  #TAUTHOR_TAG. however', ', within that hard subset, we']","['', 'modeling the chain of documents is important. this makes intuitive sense, since', 'to answer questions such as the county where a person is from ( figure', ""1 ), modeling context about the person, should be helpful. we also evaluate, if our model performs well on single - hop questions as well. this evaluation is a bit tricky to do in hotpotqa, since the evaluataion set only contains questions from'hard'subset  #TAUTHOR_TAG. however"", ', within that hard subset, we find the set of question, that has the answer span present in all', 'the supporting passages ( single - hop ( hard ) ) and only in one of the supporting passages ( multi - hop ( hard ) ) 11. the', 'intuition is that if there are multiple evidence containing the answer spans then it might be a little easier for a downstream qa model to identify the answer', 'span. figure 3 shows that our model performs equally well on both type of queries', 'and hence can be applied in a practical setting. baseline reader  #TAUTHOR_TAG table 2 shows the performance on the qa task. we were able to achieve better scores than reported in the baseline reader model of  #TAUTHOR_TAG by', 'using adam  #AUTHOR_TAG instead of standard sgd ( our re - implementation ). next, we use the top - 10 paragraphs retrieved by', '']",5
['subset  #TAUTHOR_TAG'],"[""contains questions from'hard'subset  #TAUTHOR_TAG""]","['subset  #TAUTHOR_TAG. however', ', within that hard subset, we']","['', 'modeling the chain of documents is important. this makes intuitive sense, since', 'to answer questions such as the county where a person is from ( figure', ""1 ), modeling context about the person, should be helpful. we also evaluate, if our model performs well on single - hop questions as well. this evaluation is a bit tricky to do in hotpotqa, since the evaluataion set only contains questions from'hard'subset  #TAUTHOR_TAG. however"", ', within that hard subset, we find the set of question, that has the answer span present in all', 'the supporting passages ( single - hop ( hard ) ) and only in one of the supporting passages ( multi - hop ( hard ) ) 11. the', 'intuition is that if there are multiple evidence containing the answer spans then it might be a little easier for a downstream qa model to identify the answer', 'span. figure 3 shows that our model performs equally well on both type of queries', 'and hence can be applied in a practical setting. baseline reader  #TAUTHOR_TAG table 2 shows the performance on the qa task. we were able to achieve better scores than reported in the baseline reader model of  #TAUTHOR_TAG by', 'using adam  #AUTHOR_TAG instead of standard sgd ( our re - implementation ). next, we use the top - 10 paragraphs retrieved by', '']",7
['subset  #TAUTHOR_TAG'],"[""contains questions from'hard'subset  #TAUTHOR_TAG""]","['subset  #TAUTHOR_TAG. however', ', within that hard subset, we']","['', 'modeling the chain of documents is important. this makes intuitive sense, since', 'to answer questions such as the county where a person is from ( figure', ""1 ), modeling context about the person, should be helpful. we also evaluate, if our model performs well on single - hop questions as well. this evaluation is a bit tricky to do in hotpotqa, since the evaluataion set only contains questions from'hard'subset  #TAUTHOR_TAG. however"", ', within that hard subset, we find the set of question, that has the answer span present in all', 'the supporting passages ( single - hop ( hard ) ) and only in one of the supporting passages ( multi - hop ( hard ) ) 11. the', 'intuition is that if there are multiple evidence containing the answer spans then it might be a little easier for a downstream qa model to identify the answer', 'span. figure 3 shows that our model performs equally well on both type of queries', 'and hence can be applied in a practical setting. baseline reader  #TAUTHOR_TAG table 2 shows the performance on the qa task. we were able to achieve better scores than reported in the baseline reader model of  #TAUTHOR_TAG by', 'using adam  #AUTHOR_TAG instead of standard sgd ( our re - implementation ). next, we use the top - 10 paragraphs retrieved by', '']",4
"['wordpiece models ( wpm ) in general  #TAUTHOR_TAG 17 ], but', 'shows']","['wordpiece models ( wpm ) in general  #TAUTHOR_TAG 17 ], but', 'shows']","['wordpiece models ( wpm ) in general  #TAUTHOR_TAG 17 ], but', 'shows better']","[""recognizer's phoneme set, foreign words are modeled as a phoneme"", '- level contextual fst for biasing. it is unclear whether such an approach can be directly applied to e2e models. phoneme - only e2e systems have been shown to have inferior performance compared to grapheme or wordpiece models ( wpm ) in general  #TAUTHOR_TAG 17 ], but', 'shows better recognition of rare words and proper nouns. in this work we propose to incorporate phonemes to a wordpiece e2e model as modeling units and use phoneme - level fst for contextual biasing. we propose a word - frequency based sampling strategy to randomly tokenize rare words into', 'phonemes in the target sequence using a lexicon. this approach also mitigates accuracy regressions that have been observed when using phoneme - only e2e models  #TAUTHOR_TAG 17 ].', 'we train our model using only american english data and thus its wordpieces and phoneme set ( no data from foreign languages ). in inference, given a list of foreign words, we bias the recognition using an english phoneme - level bias', '']",0
"['wordpiece models ( wpm ) in general  #TAUTHOR_TAG 17 ], but', 'shows']","['wordpiece models ( wpm ) in general  #TAUTHOR_TAG 17 ], but', 'shows']","['wordpiece models ( wpm ) in general  #TAUTHOR_TAG 17 ], but', 'shows better']","[""recognizer's phoneme set, foreign words are modeled as a phoneme"", '- level contextual fst for biasing. it is unclear whether such an approach can be directly applied to e2e models. phoneme - only e2e systems have been shown to have inferior performance compared to grapheme or wordpiece models ( wpm ) in general  #TAUTHOR_TAG 17 ], but', 'shows better recognition of rare words and proper nouns. in this work we propose to incorporate phonemes to a wordpiece e2e model as modeling units and use phoneme - level fst for contextual biasing. we propose a word - frequency based sampling strategy to randomly tokenize rare words into', 'phonemes in the target sequence using a lexicon. this approach also mitigates accuracy regressions that have been observed when using phoneme - only e2e models  #TAUTHOR_TAG 17 ].', 'we train our model using only american english data and thus its wordpieces and phoneme set ( no data from foreign languages ). in inference, given a list of foreign words, we bias the recognition using an english phoneme - level bias', '']",1
"['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['wordpiece - phoneme model differs from a wordpiece - only model in that it may decompose a few words to phonemes in training.', 'the output of the model is a single softmax whose symbol set is the union of wordpiece and phoneme symbols.', 'we use a pronunciation lexicon to obtain phoneme sequences of words.', 'since phonemes show strength in recognizing rare words  #TAUTHOR_TAG, we want to present these words as phonemes more often.', 'in a target sentence, we decide to randomly present the i th word as phonemes with a probability', ', 1. 0 ) where p0 and t are constants and c ( i ) is an integer representing the number of time the word appears in our entire training corpus.', 'therefore, the words that appear t times or less will be presented as phonemes with probability p0.', 'for words that appear more than t times, the more frequent they are, the less likely they are presented as phonemes 2.', 'note that the decision of whether to use wordpieces or phonemes is made randomly at each gradient iteration, and thus a given sentence could have different target sequences at different epochs.', 'we use context - independent phonemes as in  #TAUTHOR_TAG']",1
"['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['wordpiece - phoneme model differs from a wordpiece - only model in that it may decompose a few words to phonemes in training.', 'the output of the model is a single softmax whose symbol set is the union of wordpiece and phoneme symbols.', 'we use a pronunciation lexicon to obtain phoneme sequences of words.', 'since phonemes show strength in recognizing rare words  #TAUTHOR_TAG, we want to present these words as phonemes more often.', 'in a target sentence, we decide to randomly present the i th word as phonemes with a probability', ', 1. 0 ) where p0 and t are constants and c ( i ) is an integer representing the number of time the word appears in our entire training corpus.', 'therefore, the words that appear t times or less will be presented as phonemes with probability p0.', 'for words that appear more than t times, the more frequent they are, the less likely they are presented as phonemes 2.', 'note that the decision of whether to use wordpieces or phonemes is made randomly at each gradient iteration, and thus a given sentence could have different target sequences at different epochs.', 'we use context - independent phonemes as in  #TAUTHOR_TAG']",5
"['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words  #TAUTHOR_TAG,']","['wordpiece - phoneme model differs from a wordpiece - only model in that it may decompose a few words to phonemes in training.', 'the output of the model is a single softmax whose symbol set is the union of wordpiece and phoneme symbols.', 'we use a pronunciation lexicon to obtain phoneme sequences of words.', 'since phonemes show strength in recognizing rare words  #TAUTHOR_TAG, we want to present these words as phonemes more often.', 'in a target sentence, we decide to randomly present the i th word as phonemes with a probability', ', 1. 0 ) where p0 and t are constants and c ( i ) is an integer representing the number of time the word appears in our entire training corpus.', 'therefore, the words that appear t times or less will be presented as phonemes with probability p0.', 'for words that appear more than t times, the more frequent they are, the less likely they are presented as phonemes 2.', 'note that the decision of whether to use wordpieces or phonemes is made randomly at each gradient iteration, and thus a given sentence could have different target sequences at different epochs.', 'we use context - independent phonemes as in  #TAUTHOR_TAG']",3
"['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops']","['generate words as outputs, we search through a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops around state 0 ( we show only a few for simplicity ), but also has a pronunciation section ( states 1 through 14 ).', 'the pronunciation section is a prefix tree with phonemes as inputs, and outputs are wordpieces of the corresponding word produced by the wpm in section 3. 1.', 'specifically, for each word in the biasing list, we look up pronunciations from the lexicon and split the word into its constituent wordpieces.', '']",3
"['', 'of phonemes to oov words, as observed in  #TAUTHOR_TAG']","['##nce of the wordpiece - phoneme model to the robustness', 'of phonemes to oov words, as observed in  #TAUTHOR_TAG. since the word', '##piece - phoneme model contains both wordpieces and phonemes as modeling units, we']","['- formance of the wordpiece - phoneme model to the robustness', 'of phonemes to oov words, as observed in  #TAUTHOR_TAG. since the word', '##piece - phoneme model contains both wordpieces and phonemes as modeling units, we can further']","['% better than the wordpiece model. we attribute the superior per - formance of the wordpiece - phoneme model to the robustness', 'of phonemes to oov words, as observed in  #TAUTHOR_TAG. since the word', '##piece - phoneme model contains both wordpieces and phonemes as modeling units, we can further perform wordpiece biasing in addition to', 'phoneme - based biasing by building a wordpiece fst in parallel to the phoneme fst. this further', '']",3
"['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops']","['generate words as outputs, we search through a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops around state 0 ( we show only a few for simplicity ), but also has a pronunciation section ( states 1 through 14 ).', 'the pronunciation section is a prefix tree with phonemes as inputs, and outputs are wordpieces of the corresponding word produced by the wpm in section 3. 1.', 'specifically, for each word in the biasing list, we look up pronunciations from the lexicon and split the word into its constituent wordpieces.', '']",4
"['', 'of phonemes to oov words, as observed in  #TAUTHOR_TAG']","['##nce of the wordpiece - phoneme model to the robustness', 'of phonemes to oov words, as observed in  #TAUTHOR_TAG. since the word', '##piece - phoneme model contains both wordpieces and phonemes as modeling units, we']","['- formance of the wordpiece - phoneme model to the robustness', 'of phonemes to oov words, as observed in  #TAUTHOR_TAG. since the word', '##piece - phoneme model contains both wordpieces and phonemes as modeling units, we can further']","['% better than the wordpiece model. we attribute the superior per - formance of the wordpiece - phoneme model to the robustness', 'of phonemes to oov words, as observed in  #TAUTHOR_TAG. since the word', '##piece - phoneme model contains both wordpieces and phonemes as modeling units, we can further perform wordpiece biasing in addition to', 'phoneme - based biasing by building a wordpiece fst in parallel to the phoneme fst. this further', '']",4
"['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops']","['generate words as outputs, we search through a decoding graph similar to  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops around state 0 ( we show only a few for simplicity ), but also has a pronunciation section ( states 1 through 14 ).', 'the pronunciation section is a prefix tree with phonemes as inputs, and outputs are wordpieces of the corresponding word produced by the wpm in section 3. 1.', 'specifically, for each word in the biasing list, we look up pronunciations from the lexicon and split the word into its constituent wordpieces.', '']",6
"['##t  #TAUTHOR_TAG, called inferlit']","['effective representations, we propose a lightweight version of infersent  #TAUTHOR_TAG, called inferlite,']","['##t  #TAUTHOR_TAG, called inferlit']","['language inference has been shown to be an effective supervised task for learning generic sentence embeddings.', 'in order to better understand the components that lead to effective representations, we propose a lightweight version of infersent  #TAUTHOR_TAG, called inferlite, that does not use any recurrent layers and operates on a collection of pre - trained word embeddings.', 'we show that a simple instance of our model that makes no use of context, word ordering or position can still obtain competitive performance on the majority of downstream prediction tasks, with most performance gaps being filled by adding local contextual information through temporal convolutions.', 'our models can be trained in under 1 hour on a single gpu and allows for fast inference of new representations.', 'finally we describe a semantic hashing layer that allows our model to learn generic binary codes for sentences']",6
"['', 'recently,  #TAUTHOR_TAG showed that']","['', 'recently,  #TAUTHOR_TAG showed that']","['', 'recently,  #TAUTHOR_TAG showed that a bidirectional lstm with max pooling trained']","['', 'much of the motivation behind this work is to mimic the successful use of feature transfer in computer vision.', 'recently,  #TAUTHOR_TAG showed that a bidirectional lstm with max pooling trained to perform natural language inference ( nli ), called infersent, outperforms several other encoding functions on a suite of downstream prediction tasks.', 'this method could match or outperform existing models that learns generic embeddings in an unsupervised setting, often requiring several days or weeks to train  #AUTHOR_TAG.', 'however, a better understanding of what properties induce a useful generic embedding remains illusive.', 'in this work we propose a lightweight version of infersent, called inferlite.', '']",0
"['', ' #TAUTHOR_TAG showed that similar']","['of unlabelled data.', ' #TAUTHOR_TAG showed that similar']","['of the above methods relied on a large corpus of unlabelled data.', ' #TAUTHOR_TAG showed that similar']","['large body of work on distributional semantics have considered encoding phrase and sentence meaning into vectors e. g.  #AUTHOR_TAG.', 'the first attempt at using neural networks for learning generic sentence embeddings was  #AUTHOR_TAG, who proposed a sequenceto - sequence extension of the skip - gram model but applied at the sentence level.', 'this method was taught to encode a sentence and predict its neighbours, harnessing a large collection of books for training  #AUTHOR_TAG.', 'a similar approach, fastsent, was proposed by  #AUTHOR_TAG which replaced the rnn encoder of skip - thoughts with word embedding summation.', 'methods using rnn encoders tend to perform poorly on sts evaluations, as shown by  #AUTHOR_TAG.', ' #AUTHOR_TAG showed a simple weighted bag of words with the first principal component subtracted, can be competitive on many sentencing encoding tasks.', 'attempts to learn generic encoders with discriminative objectives were considered by  #AUTHOR_TAG and  #AUTHOR_TAG who replaced the decoder of skip - thoughts with classification tasks based on discourse relations and prediction of target sentences from an encoded candidate.', 'all of the above methods relied on a large corpus of unlabelled data.', ' #TAUTHOR_TAG showed that similar or improved performance can be obtained using nli datasets as a source of supervisory information.', 'the state of the art sentence encoders utilize multi - task learning  #AUTHOR_TAG by training an encoder to simultaneously do well on a collection of tasks such as nli, next sentence prediction and translation.', 'the use of gating for selecting word representations has been considered in previous work.', ' #AUTHOR_TAG introduced a method for choosing between word and character embeddings while method for word embedding selection.', 'gating has also been widely applied to multimodal fusion  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'our work is also related to recent methods that induce contextualized word representations ( mc  #AUTHOR_TAG as well as pre - training language models for task - dependent fine - tuning  #AUTHOR_TAG.', 'we differ from these approaches in that we aim to infer a transferable sentence vector without any additional fine - tuning']",0
"['', 'recently,  #TAUTHOR_TAG showed that']","['', 'recently,  #TAUTHOR_TAG showed that']","['', 'recently,  #TAUTHOR_TAG showed that a bidirectional lstm with max pooling trained']","['', 'much of the motivation behind this work is to mimic the successful use of feature transfer in computer vision.', 'recently,  #TAUTHOR_TAG showed that a bidirectional lstm with max pooling trained to perform natural language inference ( nli ), called infersent, outperforms several other encoding functions on a suite of downstream prediction tasks.', 'this method could match or outperform existing models that learns generic embeddings in an unsupervised setting, often requiring several days or weeks to train  #AUTHOR_TAG.', 'however, a better understanding of what properties induce a useful generic embedding remains illusive.', 'in this work we propose a lightweight version of infersent, called inferlite.', '']",3
"['of snli  #AUTHOR_TAG and multinli  #AUTHOR_TAG datasets as in  #TAUTHOR_TAG.', 'table 1 summarizes the properties of the embeddings we consider.', 'at a high level, our method takes as']","['of snli  #AUTHOR_TAG and multinli  #AUTHOR_TAG datasets as in  #TAUTHOR_TAG.', 'table 1 summarizes the properties of the embeddings we consider.', 'at a high level, our method takes as']","['of snli  #AUTHOR_TAG and multinli  #AUTHOR_TAG datasets as in  #TAUTHOR_TAG.', 'table 1 summarizes the properties of the embeddings we consider.', 'at a high level, our method takes as']","['method operates on a collection of pre - trained word representations and is then trained on the concatenation of snli  #AUTHOR_TAG and multinli  #AUTHOR_TAG datasets as in  #TAUTHOR_TAG.', 'table 1 summarizes the properties of the embeddings we consider.', 'at a high level, our method takes as input a collection of embeddings for each word and learns a gated controller to decide how to weight each representation.', 'after encoding each word in a sentence, the sentence embedding is obtained by max pooling the transformed word representations.', ' #AUTHOR_TAG, which learn a shared encoder in a multi - task setting, we instead fix the prediction task to nli but use embeddings obtained from alternative tasks.', 'figure 1 illustrates our model.', 'we begin by defining notation.', 'suppose we are given a sentence of words s = w 1,..., w t which we would like to encode into a vector.', 'let k be the number of embedding types ( e. g. glove, news, query ) and let e k denote the word embedding matrix for type k. define e c = [ e 1 ;... ; e k ] to be the concatenation of word embedding matrices of all k types.', 'we break our model description into four modules : encoder, controller, fusion and reduction.', 'in the appendix we include an ablation study that analyzes the effect of our design choices.', 'encoder.', '']",5
"['##wise and absolute difference  #TAUTHOR_TAG.', 'this joint']","['with their componentwise and absolute difference  #TAUTHOR_TAG.', 'this joint']","['##wise and absolute difference  #TAUTHOR_TAG.', 'this joint vector']","['', 'where denotes a component - wise product, w f f 0 is a time distributed matrix multiply, f is a relu activation function and g c 0 is added as a skip connection.', 'in the appendix we demonstrate that the added skip connection is crucial to the success of the model.', 'reduction.', 'the final reduction operation simply applies max pooling across tokens :', 'resulting in a sentence vector s. this resulting vector corresponds to the embedding for which we evaluate all downstream tasks with.', 'for training on nli, we follow existing work and compute the concatenation of the embeddings of premise and hypothesis sentences along with their componentwise and absolute difference  #TAUTHOR_TAG.', 'this joint vector is fed into a 2 hidden layer feedforward network with relu activations, followed by a softmax layer to predict whether the sentence pairs are neutral, entailed or contradictory.', 'after training on nli, the weights of the model are frozen and used for encoding new sentences.', '( 2016 ).', ""there are three main differences : 1 ) we generalize to multiple embedding types 2 ) we only apply gating at the end of the last layer as a way of weighting all embedding types ( instead of each layer ) and 3 ) we use a skip connection from the controller's transformed input to the fusion layer."", 'we note that our encoder module can be reduced to the gated convolutional encoder in van den  #AUTHOR_TAG if we use one embedding type, remove the time distributed layers and only use a single convolutional layer']",5
"['embeddings as in  #TAUTHOR_TAG.', 'we']","['embeddings as in  #TAUTHOR_TAG.', 'we']","['##96 - dimensional embeddings as in  #TAUTHOR_TAG.', 'we consider encoders that use convolutional filters of length 1 ( no context ) or length 3 ( local context ), with a stack of m = 3 convolutional layers.', 'all word embeddings are pre - trained, normalized']","['use the senteval toolkit  #AUTHOR_TAG for evaluating our sentence embeddings.', 'all of our models are trained to optimize performance on the concatenation of snli and multinli, using the concatenated development sets for early stopping.', 'we use 4096 - dimensional embeddings as in  #TAUTHOR_TAG.', 'we consider encoders that use convolutional filters of length 1 ( no context ) or length 3 ( local context ), with a stack of m = 3 convolutional layers.', 'all word embeddings are pre - trained, normalized to unit length and held fixed during training.', 'full hyperparameter details are included in the appendix, including an ablation study comparing the effect of the choice of m.', 'we first analyze performance of our model on nli prior to evaluating our models on downstream tasks.', 'figure 2 shows development set accuracy on nli for models with and without context, using various feature combinations.', 'here we observe that a ) using local context improves nli performance and b ) adding additional embedding types leads to improved performance.', 'tables 2 and 3 show results on downstream evaluation tasks.', 'here several observations can be made.', '']",5
[';  #TAUTHOR_TAG ; tan et al.'],['( pang et al. 2008 ;  #TAUTHOR_TAG ; tan et al.'],"['sentiment analysis ( pang et al. 2008 ;  #TAUTHOR_TAG ; tan et al. 2008 ).', ' #AUTHOR_TAG experimented with various features like unigrams, bi - grams and adjectives']","['learning methods have been widely applied for sentiment analysis ( pang et al. 2008 ;  #TAUTHOR_TAG ; tan et al. 2008 ).', ' #AUTHOR_TAG experimented with various features like unigrams, bi - grams and adjectives for sentiment classification of movie reviews using different machine learning algorithms namely naive bayes ( nb ), support vector machines ( svm ), and maximum - entropy ( me ).', 'feature selection methods improve the performance of sentiment classification by eliminating the noisy and irrelevant features from feature vector.', ' #AUTHOR_TAG investigated with various feature selection methods with different machine learning algorithm for sentiment classification.', 'their experimental results show that ig performs better as compared to other feature selection methods and svm is best machine learning algorithms.', 'categorical probability proportion difference ( cppd ) feature selection method is proposed which computes the importance of a feature based on its class discriminating ability for sentiment classification ( agarwal et al. 2012 ).', 'various features are extracted from the text for sentiment classification.', 'further, minimum redundancy maximum relevancy ( mrmr ) and ig feature selection methods are used to select prominent features for better sentiment classification by machine learning algorithms ( agarwal et al. 2013 ).', 'rough set based dimensionality reduction method is applied for data reduction to characterize bookmarks and it is compared with conventional entropy based reduction method ( jensen et al. 2009 ).', 'dimension reduction method based on fuzzy - rough sets and ant colony optimization ( aco ) method is proposed ( jensen et al. 2006 ), which is applied to the web categorisation problem.', 'experimental result show significant reduction in the data redundancy.', 'rough set theory is applied to select relevant features for web - page classification.', 'their experimental results show that the rough set based feature selection method with svm gives better accuracy ( wakaki et al. 2004 ).', 'applicability of rs theory for various existing text classification techniques are discussed in detail with e - mail categorization as an example application ( chouchoulas et al. 2001 )']",0
"['as  #TAUTHOR_TAG, "" not _ ""']","['as  #TAUTHOR_TAG, "" not _ ""']","['as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t']","['the evaluation of the proposed method, one of the most popular publically available movie review dataset ( pang et al. 2004 ) is used.', 'this standard dataset contains 2000 reviews comprising 1000 positive and 1000 negative reviews.', 'product review dataset consisting amazon products reviews is also used provided by  #AUTHOR_TAG.', 'we used product reviews of books, dvd and electronics for experiments.', 'each domain has 1000 positive and 1000 negative labelled reviews.', 'documents are initially pre - processed as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t, can\'t, never, couldn\'t, didn\'t, wouldn\'t, don\'t ) and first punctuation mark in the sentence.', '( ii ) words occurring in less than 3 documents are removed from the feature set.', 'binary weighting scheme has been identified as a better weighting scheme as compared to frequency based schemes for sentiment classification  #TAUTHOR_TAG ; therefore we also used binary weighting method for representing text.', 'in addition, there is no need of using separate discretisation method in case of binary weighting scheme as required by rsar feature selection algorithm.', 'noisy and irrelevant features are eliminated from the feature vector generated after pre - processing using various feature selection methods discussed before.', 'further, prominent feature vector is used by machine learning algorithms.', 'support vector machine ( svm ) and naive bayes ( nb ) classifiers are the mostly used for sentiment classification  #TAUTHOR_TAG ; tan et al. 2008 ).', 'therefore, we report the classification results of svm and nb classifier for classifying review documents into positive or negative sentiment polarity.', 'for the evaluation of proposed methods 10 fold cross validation method is used.', 'fmeasure value is reported as a performance measure of various classifiers ( agarwal et al. 2013']",0
"['as  #TAUTHOR_TAG, "" not _ ""']","['as  #TAUTHOR_TAG, "" not _ ""']","['as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t']","['the evaluation of the proposed method, one of the most popular publically available movie review dataset ( pang et al. 2004 ) is used.', 'this standard dataset contains 2000 reviews comprising 1000 positive and 1000 negative reviews.', 'product review dataset consisting amazon products reviews is also used provided by  #AUTHOR_TAG.', 'we used product reviews of books, dvd and electronics for experiments.', 'each domain has 1000 positive and 1000 negative labelled reviews.', 'documents are initially pre - processed as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t, can\'t, never, couldn\'t, didn\'t, wouldn\'t, don\'t ) and first punctuation mark in the sentence.', '( ii ) words occurring in less than 3 documents are removed from the feature set.', 'binary weighting scheme has been identified as a better weighting scheme as compared to frequency based schemes for sentiment classification  #TAUTHOR_TAG ; therefore we also used binary weighting method for representing text.', 'in addition, there is no need of using separate discretisation method in case of binary weighting scheme as required by rsar feature selection algorithm.', 'noisy and irrelevant features are eliminated from the feature vector generated after pre - processing using various feature selection methods discussed before.', 'further, prominent feature vector is used by machine learning algorithms.', 'support vector machine ( svm ) and naive bayes ( nb ) classifiers are the mostly used for sentiment classification  #TAUTHOR_TAG ; tan et al. 2008 ).', 'therefore, we report the classification results of svm and nb classifier for classifying review documents into positive or negative sentiment polarity.', 'for the evaluation of proposed methods 10 fold cross validation method is used.', 'fmeasure value is reported as a performance measure of various classifiers ( agarwal et al. 2013']",0
"['as  #TAUTHOR_TAG, "" not _ ""']","['as  #TAUTHOR_TAG, "" not _ ""']","['as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t']","['the evaluation of the proposed method, one of the most popular publically available movie review dataset ( pang et al. 2004 ) is used.', 'this standard dataset contains 2000 reviews comprising 1000 positive and 1000 negative reviews.', 'product review dataset consisting amazon products reviews is also used provided by  #AUTHOR_TAG.', 'we used product reviews of books, dvd and electronics for experiments.', 'each domain has 1000 positive and 1000 negative labelled reviews.', 'documents are initially pre - processed as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t, can\'t, never, couldn\'t, didn\'t, wouldn\'t, don\'t ) and first punctuation mark in the sentence.', '( ii ) words occurring in less than 3 documents are removed from the feature set.', 'binary weighting scheme has been identified as a better weighting scheme as compared to frequency based schemes for sentiment classification  #TAUTHOR_TAG ; therefore we also used binary weighting method for representing text.', 'in addition, there is no need of using separate discretisation method in case of binary weighting scheme as required by rsar feature selection algorithm.', 'noisy and irrelevant features are eliminated from the feature vector generated after pre - processing using various feature selection methods discussed before.', 'further, prominent feature vector is used by machine learning algorithms.', 'support vector machine ( svm ) and naive bayes ( nb ) classifiers are the mostly used for sentiment classification  #TAUTHOR_TAG ; tan et al. 2008 ).', 'therefore, we report the classification results of svm and nb classifier for classifying review documents into positive or negative sentiment polarity.', 'for the evaluation of proposed methods 10 fold cross validation method is used.', 'fmeasure value is reported as a performance measure of various classifiers ( agarwal et al. 2013']",5
"['as  #TAUTHOR_TAG, "" not _ ""']","['as  #TAUTHOR_TAG, "" not _ ""']","['as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t']","['the evaluation of the proposed method, one of the most popular publically available movie review dataset ( pang et al. 2004 ) is used.', 'this standard dataset contains 2000 reviews comprising 1000 positive and 1000 negative reviews.', 'product review dataset consisting amazon products reviews is also used provided by  #AUTHOR_TAG.', 'we used product reviews of books, dvd and electronics for experiments.', 'each domain has 1000 positive and 1000 negative labelled reviews.', 'documents are initially pre - processed as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t, can\'t, never, couldn\'t, didn\'t, wouldn\'t, don\'t ) and first punctuation mark in the sentence.', '( ii ) words occurring in less than 3 documents are removed from the feature set.', 'binary weighting scheme has been identified as a better weighting scheme as compared to frequency based schemes for sentiment classification  #TAUTHOR_TAG ; therefore we also used binary weighting method for representing text.', 'in addition, there is no need of using separate discretisation method in case of binary weighting scheme as required by rsar feature selection algorithm.', 'noisy and irrelevant features are eliminated from the feature vector generated after pre - processing using various feature selection methods discussed before.', 'further, prominent feature vector is used by machine learning algorithms.', 'support vector machine ( svm ) and naive bayes ( nb ) classifiers are the mostly used for sentiment classification  #TAUTHOR_TAG ; tan et al. 2008 ).', 'therefore, we report the classification results of svm and nb classifier for classifying review documents into positive or negative sentiment polarity.', 'for the evaluation of proposed methods 10 fold cross validation method is used.', 'fmeasure value is reported as a performance measure of various classifiers ( agarwal et al. 2013']",3
"['as  #TAUTHOR_TAG, "" not _ ""']","['as  #TAUTHOR_TAG, "" not _ ""']","['as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t']","['the evaluation of the proposed method, one of the most popular publically available movie review dataset ( pang et al. 2004 ) is used.', 'this standard dataset contains 2000 reviews comprising 1000 positive and 1000 negative reviews.', 'product review dataset consisting amazon products reviews is also used provided by  #AUTHOR_TAG.', 'we used product reviews of books, dvd and electronics for experiments.', 'each domain has 1000 positive and 1000 negative labelled reviews.', 'documents are initially pre - processed as follows : ( i ) negation handling is performed as  #TAUTHOR_TAG, "" not _ "" is added to every words occurring after the negation word ( no, not, isn\'t, can\'t, never, couldn\'t, didn\'t, wouldn\'t, don\'t ) and first punctuation mark in the sentence.', '( ii ) words occurring in less than 3 documents are removed from the feature set.', 'binary weighting scheme has been identified as a better weighting scheme as compared to frequency based schemes for sentiment classification  #TAUTHOR_TAG ; therefore we also used binary weighting method for representing text.', 'in addition, there is no need of using separate discretisation method in case of binary weighting scheme as required by rsar feature selection algorithm.', 'noisy and irrelevant features are eliminated from the feature vector generated after pre - processing using various feature selection methods discussed before.', 'further, prominent feature vector is used by machine learning algorithms.', 'support vector machine ( svm ) and naive bayes ( nb ) classifiers are the mostly used for sentiment classification  #TAUTHOR_TAG ; tan et al. 2008 ).', 'therefore, we report the classification results of svm and nb classifier for classifying review documents into positive or negative sentiment polarity.', 'for the evaluation of proposed methods 10 fold cross validation method is used.', 'fmeasure value is reported as a performance measure of various classifiers ( agarwal et al. 2013']",1
"['code  #TAUTHOR_TAG.', '']","['code  #TAUTHOR_TAG.', '']","['code  #TAUTHOR_TAG.', '']","['language to code generation, a subtask of semantic parsing, is the problem of converting natural language ( nl ) descriptions to code  #TAUTHOR_TAG.', 'this task is challenging because it has a well - defined structured output and the input structure and output structure are in different forms.', 'a number of neural network approaches have been proposed to solve this task.', 'sequential approaches  #AUTHOR_TAG convert the target code into a sequence of symbols and apply a sequence - tosequence model, but this approach does not ensure that the output will be syntactically correct.', '1 code available at https : / / github. com / sweetpeach / recode tree - based approaches  #TAUTHOR_TAG represent code as abstract syntax trees ( asts ), which has proven effective in improving accuracy as it enforces the well - formedness of the output code.', 'however, representing code as a tree is not a trivial task, as the number of nodes in the tree often greatly exceeds the length of the nl description.', 'as a result, tree - based approaches are often incapable of generating correct code for phrases in the corresponding nl description that have low frequency in the training data.', 'in machine translation ( mt ) problems  #AUTHOR_TAG, hybrid methods combining retrieval of salient examples and neural models have proven successful in dealing with rare words.', 'following the intuition of these models, we hypothesize that our model can benefit from querying pairs of nl descriptions and ast structures from training data.', ""in this paper, we propose recode, and adaptation of's retrieval - based approach neural mt method to the code generation problem by expanding it to apply to generation of tree structures."", 'our main contribution is to introduce the use of retrieval methods in neural code generation models.', 'we also propose a dynamic programming - based sentence - tosentence alignment method that can be applied to similar sentences to perform word substitution and enable retrieval of imperfect matches.', 'these contributions allow us to improve on previous stateof - the - art results']",0
"['code  #TAUTHOR_TAG.', '']","['code  #TAUTHOR_TAG.', '']","['code  #TAUTHOR_TAG.', '']","['language to code generation, a subtask of semantic parsing, is the problem of converting natural language ( nl ) descriptions to code  #TAUTHOR_TAG.', 'this task is challenging because it has a well - defined structured output and the input structure and output structure are in different forms.', 'a number of neural network approaches have been proposed to solve this task.', 'sequential approaches  #AUTHOR_TAG convert the target code into a sequence of symbols and apply a sequence - tosequence model, but this approach does not ensure that the output will be syntactically correct.', '1 code available at https : / / github. com / sweetpeach / recode tree - based approaches  #TAUTHOR_TAG represent code as abstract syntax trees ( asts ), which has proven effective in improving accuracy as it enforces the well - formedness of the output code.', 'however, representing code as a tree is not a trivial task, as the number of nodes in the tree often greatly exceeds the length of the nl description.', 'as a result, tree - based approaches are often incapable of generating correct code for phrases in the corresponding nl description that have low frequency in the training data.', 'in machine translation ( mt ) problems  #AUTHOR_TAG, hybrid methods combining retrieval of salient examples and neural models have proven successful in dealing with rare words.', 'following the intuition of these models, we hypothesize that our model can benefit from querying pairs of nl descriptions and ast structures from training data.', ""in this paper, we propose recode, and adaptation of's retrieval - based approach neural mt method to the code generation problem by expanding it to apply to generation of tree structures."", 'our main contribution is to introduce the use of retrieval methods in neural code generation models.', 'we also propose a dynamic programming - based sentence - tosentence alignment method that can be applied to similar sentences to perform word substitution and enable retrieval of imperfect matches.', 'these contributions allow us to improve on previous stateof - the - art results']",0
"['in this work, we start with the syntactic code gen - eration model by  #TAUTHOR_TAG, which uses sequences of actions to']","['as an ast a. in this work, we start with the syntactic code gen - eration model by  #TAUTHOR_TAG, which uses sequences of actions to']","['as an ast a. in this work, we start with the syntactic code gen - eration model by  #TAUTHOR_TAG, which uses sequences of actions to']","['an nl description q, our purpose is to generate code ( e. g. python ) represented as an ast a. in this work, we start with the syntactic code gen - eration model by  #TAUTHOR_TAG, which uses sequences of actions to generate the ast before converting it to surface code.', 'formally, we want to find the best generated asta given by :', 'where y t is the action taken at time step t and y < t = y 1... y t−1 and t is the number of total time steps of the whole action sequence resulting in ast a.', 'we have two types of actions to build an ast : applyrule and gentoken.', '']",0
"[' #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']","[' #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']","[', leading to low exact match accuracy  #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']",[' #TAUTHOR_TAG'],0
"['code  #TAUTHOR_TAG.', '']","['code  #TAUTHOR_TAG.', '']","['code  #TAUTHOR_TAG.', '']","['language to code generation, a subtask of semantic parsing, is the problem of converting natural language ( nl ) descriptions to code  #TAUTHOR_TAG.', 'this task is challenging because it has a well - defined structured output and the input structure and output structure are in different forms.', 'a number of neural network approaches have been proposed to solve this task.', 'sequential approaches  #AUTHOR_TAG convert the target code into a sequence of symbols and apply a sequence - tosequence model, but this approach does not ensure that the output will be syntactically correct.', '1 code available at https : / / github. com / sweetpeach / recode tree - based approaches  #TAUTHOR_TAG represent code as abstract syntax trees ( asts ), which has proven effective in improving accuracy as it enforces the well - formedness of the output code.', 'however, representing code as a tree is not a trivial task, as the number of nodes in the tree often greatly exceeds the length of the nl description.', 'as a result, tree - based approaches are often incapable of generating correct code for phrases in the corresponding nl description that have low frequency in the training data.', 'in machine translation ( mt ) problems  #AUTHOR_TAG, hybrid methods combining retrieval of salient examples and neural models have proven successful in dealing with rare words.', 'following the intuition of these models, we hypothesize that our model can benefit from querying pairs of nl descriptions and ast structures from training data.', ""in this paper, we propose recode, and adaptation of's retrieval - based approach neural mt method to the code generation problem by expanding it to apply to generation of tree structures."", 'our main contribution is to introduce the use of retrieval methods in neural code generation models.', 'we also propose a dynamic programming - based sentence - tosentence alignment method that can be applied to similar sentences to perform word substitution and enable retrieval of imperfect matches.', 'these contributions allow us to improve on previous stateof - the - art results']",1
"['in this work, we start with the syntactic code gen - eration model by  #TAUTHOR_TAG, which uses sequences of actions to']","['as an ast a. in this work, we start with the syntactic code gen - eration model by  #TAUTHOR_TAG, which uses sequences of actions to']","['as an ast a. in this work, we start with the syntactic code gen - eration model by  #TAUTHOR_TAG, which uses sequences of actions to']","['an nl description q, our purpose is to generate code ( e. g. python ) represented as an ast a. in this work, we start with the syntactic code gen - eration model by  #TAUTHOR_TAG, which uses sequences of actions to generate the ast before converting it to surface code.', 'formally, we want to find the best generated asta given by :', 'where y t is the action taken at time step t and y < t = y 1... y t−1 and t is the number of total time steps of the whole action sequence resulting in ast a.', 'we have two types of actions to build an ast : applyrule and gentoken.', '']",5
"['assigned a score, based on the best similarity score  #TAUTHOR_TAG of all instances where']","['assigned a score, based on the best similarity score  #TAUTHOR_TAG of all instances where']","['sentences are assigned a score, based on the best similarity score  #TAUTHOR_TAG of all instances where they appeared.', 'we normalize the scores for each input sentence by']","['- gram subtrees from all retrieved sentences are assigned a score, based on the best similarity score  #TAUTHOR_TAG of all instances where they appeared.', 'we normalize the scores for each input sentence by subtracting the average over the training dataset.', 'at decoding time, incorporate these retrievalderived scores into beam search : for a given time step, all actions that would result in one of the retrieved n - grams u to be in the prediction tree has its log probability log ( p ( y t | y t−1 1 ) ) increased by λ * score ( u ) where λ is a hyperparameter, and score ( u ) is the maximal sim ( q, q m ) from which u is extracted.', 'the probability distribution is then renormalized']",5
"['by  #TAUTHOR_TAG.', 'hs consists of python classes that implement hearthstone card descriptions while django contains pairs of python source code and english pseudo - code from django web']","[' #AUTHOR_TAG datasets, as preprocessed by  #TAUTHOR_TAG.', 'hs consists of python classes that implement hearthstone card descriptions while django contains pairs of python source code and english pseudo - code from django web framework.', '']","['by  #TAUTHOR_TAG.', 'hs consists of python classes that implement hearthstone card descriptions while django contains pairs of python source code and english pseudo - code from django web framework.', '']","['evaluate recode with the hearthstone ( hs )  #AUTHOR_TAG and django  #AUTHOR_TAG datasets, as preprocessed by  #TAUTHOR_TAG.', 'hs consists of python classes that implement hearthstone card descriptions while django contains pairs of python source code and english pseudo - code from django web framework.', 'table 1 summarizes dataset statistics.', 'for evaluation metrics, we use accuracy of exact match and the bleu score following  #TAUTHOR_TAG']",5
"['by  #TAUTHOR_TAG.', 'hs consists of python classes that implement hearthstone card descriptions while django contains pairs of python source code and english pseudo - code from django web']","[' #AUTHOR_TAG datasets, as preprocessed by  #TAUTHOR_TAG.', 'hs consists of python classes that implement hearthstone card descriptions while django contains pairs of python source code and english pseudo - code from django web framework.', '']","['by  #TAUTHOR_TAG.', 'hs consists of python classes that implement hearthstone card descriptions while django contains pairs of python source code and english pseudo - code from django web framework.', '']","['evaluate recode with the hearthstone ( hs )  #AUTHOR_TAG and django  #AUTHOR_TAG datasets, as preprocessed by  #TAUTHOR_TAG.', 'hs consists of python classes that implement hearthstone card descriptions while django contains pairs of python source code and english pseudo - code from django web framework.', 'table 1 summarizes dataset statistics.', 'for evaluation metrics, we use accuracy of exact match and the bleu score following  #TAUTHOR_TAG']",5
"['the neural code generation model, we use the settings explained in  #TAUTHOR_TAG.', 'for']","['the neural code generation model, we use the settings explained in  #TAUTHOR_TAG.', 'for']","['the neural code generation model, we use the settings explained in  #TAUTHOR_TAG.', 'for the retrieval method, we tuned hyperparameters and achieved best result when we set n max = 4 and λ = 3 for both datasets 3.', 'for hs, we set m = 3 and m = 10 for django.', ""we compare our model with  #TAUTHOR_TAG's model""]","['the neural code generation model, we use the settings explained in  #TAUTHOR_TAG.', 'for the retrieval method, we tuned hyperparameters and achieved best result when we set n max = 4 and λ = 3 for both datasets 3.', 'for hs, we set m = 3 and m = 10 for django.', ""we compare our model with  #TAUTHOR_TAG's model that we call yn17 for brevity, and a sequence - to - sequence ( seq2seq ) model that we implemented."", 'seq2seq is an attentionenabled encoder - decoder model  #AUTHOR_TAG.', 'the encoder is a bidirectional lstm and the decoder is an lstm.', 'we ran statistical significance tests for recode and yn17, using bootstrap resampling with n = 10, 000.', 'for the bleu scores of both datasets, p < 0. 001.', 'for the exact match accuracy, p < 0. 001 for django dataset, but for hearthstone, p > 0. 3, showing that the retrieval - based model is on par with yn17.', 'it is worth noting, though, that hs consists of long and complex code, and that generating exact matches is very difficult, making exact match accuracy a less reliable metric']",5
"['the neural code generation model, we use the settings explained in  #TAUTHOR_TAG.', 'for']","['the neural code generation model, we use the settings explained in  #TAUTHOR_TAG.', 'for']","['the neural code generation model, we use the settings explained in  #TAUTHOR_TAG.', 'for the retrieval method, we tuned hyperparameters and achieved best result when we set n max = 4 and λ = 3 for both datasets 3.', 'for hs, we set m = 3 and m = 10 for django.', ""we compare our model with  #TAUTHOR_TAG's model""]","['the neural code generation model, we use the settings explained in  #TAUTHOR_TAG.', 'for the retrieval method, we tuned hyperparameters and achieved best result when we set n max = 4 and λ = 3 for both datasets 3.', 'for hs, we set m = 3 and m = 10 for django.', ""we compare our model with  #TAUTHOR_TAG's model that we call yn17 for brevity, and a sequence - to - sequence ( seq2seq ) model that we implemented."", 'seq2seq is an attentionenabled encoder - decoder model  #AUTHOR_TAG.', 'the encoder is a bidirectional lstm and the decoder is an lstm.', 'we ran statistical significance tests for recode and yn17, using bootstrap resampling with n = 10, 000.', 'for the bleu scores of both datasets, p < 0. 001.', 'for the exact match accuracy, p < 0. 001 for django dataset, but for hearthstone, p > 0. 3, showing that the retrieval - based model is on par with yn17.', 'it is worth noting, though, that hs consists of long and complex code, and that generating exact matches is very difficult, making exact match accuracy a less reliable metric']",5
"[' #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']","[' #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']","[', leading to low exact match accuracy  #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']",[' #TAUTHOR_TAG'],6
"[' #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']","[' #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']","[', leading to low exact match accuracy  #TAUTHOR_TAG.', 'analyzing our result, we find this intuition to be']",[' #TAUTHOR_TAG'],3
['to ours are  #TAUTHOR_TAG and  #AUTHOR_TAG which represent code as an ast'],"['to ours are  #TAUTHOR_TAG and  #AUTHOR_TAG which represent code as an ast.', 'another close']","['', ' #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG treat semantic parsing as a sequence generation task by linearizing trees.', 'the closest work to ours are  #TAUTHOR_TAG and  #AUTHOR_TAG which represent code as an ast.', 'another close work is  #AUTHOR_TAG, which uses a two - staged structure - aware neural architecture.', '']","['', ' #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG treat semantic parsing as a sequence generation task by linearizing trees.', 'the closest work to ours are  #TAUTHOR_TAG and  #AUTHOR_TAG which represent code as an ast.', 'another close work is  #AUTHOR_TAG, which uses a two - staged structure - aware neural architecture.', '']",3
['english  #TAUTHOR_TAG used in'],['english  #TAUTHOR_TAG used in'],['english  #TAUTHOR_TAG used in the recent offenseval ( sem'],"['the age of social media, offensive content online has become prevalent in recent years.', 'there are many types of offensive content online such as racist and sexist posts and insults and threats targeted at individuals or groups.', 'as such content increasingly occurs online, it has become a growing issue for online communities.', 'this has come to the attention of social media platforms and authorities underlining the urgency to moderate and deal with such content.', 'several studies in nlp have approached offensive language identification applying machine learning and deep learning systems on annotated data to identify such content.', 'researchers in the field have worked with different definitions of offensive language with hate speech being the most studied among these types.', ' #AUTHOR_TAG investigate the similarity between these subtasks.', 'with a few noteworthy exceptions, most research so far has dealt with english, due to the availability of language resources.', 'this gap in the literature recently started to be addressed with studies on spanish ( aragon et al., 2018 ), hindi  #AUTHOR_TAG, and german  #AUTHOR_TAG, to name a few.', 'in this paper we contribute in this direction presenting the first greek annotated dataset for offensive language identification : the offensive greek tweet dataset ( ogtd ).', 'ogtd uses a working definition of offensive language inspired by the olid dataset for english  #TAUTHOR_TAG used in the recent offenseval ( semeval - 2019 task 6 )  #AUTHOR_TAG b ).', 'in its version, 1. 0 ogtd contains nearly 4, 800 posts collected from twitter and manually annotated by a team of volunteers, resulting in a highquality annotated dataset.', 'we trained a number of systems on this dataset and our best results have been obtained from a system using lstms and gru with attention which achieved 0. 89 f1 score']",5
"['hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['##ness inspired by the first layer of the hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['bulk of work on detecting abusive posts online addressed particular types of such language like textual attacks and hate speech  #AUTHOR_TAG, ag - gression  #AUTHOR_TAG, and others.', 'ogtd considers a more general definition of offensiveness inspired by the first layer of the hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity, and considers the target of offensive posts as indicators of potential hate speech posts ( insults targeted at groups ) and cyberbulling posts ( insults targeted at individuals ).', 'offensive language : previous work presented a dataset with sentences labelled as flame ( i. e. attacking or containing abusive words ) or okay  #AUTHOR_TAG with a naive bayes hybrid classifier and a user offensiveness estimation using an offensive lexicon and sentence syntactic structures  #AUTHOR_TAG.', 'a dataset of 3. 3m comments from the yahoo finance and news website, labelled as abusive or clean, was utilized in several experiments using ngrams, linguistic and syntactic features, combined with different types of word and comment embeddings as distributional semantics features  #AUTHOR_TAG.', 'the usefulness of character n - grams for abusive language detection was explored on the same dataset with three different methods.', 'the most recent project expanded on existing ideas for defining offensive language and presented the olid ( offensive language identification dataset ), a corpus of twitter posts hierarchically annotated on three levels, whether they contain offensive language or not, whether the offense is targeted and finally, the target of the offense  #TAUTHOR_TAG.', 'a cnn ( convolutional neural network ) deep learning approach outperformed every model trained, with pre - trained fasttext embeddings and updateable embeddings learned by the model as features.', 'in offenseval ( semeval - 2019 task 6 ), participants had the opportunity to use the olid to train their own systems, with the top teams outperforming the original models trained on the dataset.', 'hate speech : a study dataset of tweets posted after the murder of drummer lee rigby in the uk, manually annotated as offensive or antagonistic in terms of race ethnicity or religion for hate speech identification with multiple clas - sifiers  #AUTHOR_TAG.', 'a logistic regression classifier trained with paragraph2vec 1 word representations of comments from yahoo finance  #AUTHOR_TAG.', 'the latest approaches in detecting hate speech include a dataset of twitter posts, labelled as hateful, offensive or clean, used to train a logistic regression classifier with part - of - speech and word n - grams and a sentiment lexicon and a linear svm trained on']",5
"['hashtags included tweets discussing the elections.', 'the intuition behind this approach is that twitter as a microblogging service often gathers complaints and profane comments on widely viewed television and politics, and as such, this period was a good opportunity for data collection.', 'following the methodology described in  #TAUTHOR_TAG and others, including a recent comparable danish dataset  #AUTHOR_TAG, we collected tweets using keywords']","['hashtags included tweets discussing the elections.', 'the intuition behind this approach is that twitter as a microblogging service often gathers complaints and profane comments on widely viewed television and politics, and as such, this period was a good opportunity for data collection.', 'following the methodology described in  #TAUTHOR_TAG and others, including a recent comparable danish dataset  #AUTHOR_TAG, we collected tweets using keywords']","['as series, reality and entertainment shows.', 'due to the municipal, regional as well as the european parliament election taking place at the time, many hashtags included tweets discussing the elections.', 'the intuition behind this approach is that twitter as a microblogging service often gathers complaints and profane comments on widely viewed television and politics, and as such, this period was a good opportunity for data collection.', 'following the methodology described in  #TAUTHOR_TAG and others, including a recent comparable danish dataset  #AUTHOR_TAG, we collected tweets using keywords']","['posts in ogtd v1. 0 were collected between  #AUTHOR_TAG.', 'we used the twitter api initially collecting tweets from popular and trending hashtags in greece, including television programs such as series, reality and entertainment shows.', 'due to the municipal, regional as well as the european parliament election taking place at the time, many hashtags included tweets discussing the elections.', 'the intuition behind this approach is that twitter as a microblogging service often gathers complaints and profane comments on widely viewed television and politics, and as such, this period was a good opportunity for data collection.', 'following the methodology described in  #TAUTHOR_TAG and others, including a recent comparable danish dataset  #AUTHOR_TAG, we collected tweets using keywords such as sensitive or obscene language.', 'queries for tweets containing common curse words and expressions usually found in offensive messages in greek as keywords ( such as the well - known word for "" asshole "", "" μαλακας "" ( malakas ) or "" go to hell "", "" στο διαολο "" ( sto diaolo ), etc. ) returned a large number of tweets.', 'aiming to compile a dataset including offensive tweets of diverse types ( sexist, racist, etc. ) targeted at various social groups, the twitter api was queried with expletives such as "" πουτανα "" ( poutana, "" whore "" ), "" καριολα "" ( kariola, "" bitch "" ), "" πουστης "" ( poustis, "" faggot "" ), etc. and their plural forms, to explore the semantic and pragmatic differences of the expletives mentioned above in their different contextual environments.', 'the challenge is to recognize between ironic and insulting uses of these swear words, a common phenomenon in greek.', 'the final query for data collection was for tweets containing "" εισαι "" ( eisai, "" you are "" ) as a keyword, inspired by  #TAUTHOR_TAG.', 'this particular keyword is considered a stop word as it is quite common and frequent in languages but was suspected to prove helpful for building the dataset for this particular project, as offensive language often follows the following structure : auxiliary verb ( be ) + noun / adjective.', 'the immediacy of social media and specifically twitter provides the opportunity for targeted insults to be investigated, following data mining of tweets including "" you are "" as a keyword.', 'in fact, many tweets']",5
"['hashtags included tweets discussing the elections.', 'the intuition behind this approach is that twitter as a microblogging service often gathers complaints and profane comments on widely viewed television and politics, and as such, this period was a good opportunity for data collection.', 'following the methodology described in  #TAUTHOR_TAG and others, including a recent comparable danish dataset  #AUTHOR_TAG, we collected tweets using keywords']","['hashtags included tweets discussing the elections.', 'the intuition behind this approach is that twitter as a microblogging service often gathers complaints and profane comments on widely viewed television and politics, and as such, this period was a good opportunity for data collection.', 'following the methodology described in  #TAUTHOR_TAG and others, including a recent comparable danish dataset  #AUTHOR_TAG, we collected tweets using keywords']","['as series, reality and entertainment shows.', 'due to the municipal, regional as well as the european parliament election taking place at the time, many hashtags included tweets discussing the elections.', 'the intuition behind this approach is that twitter as a microblogging service often gathers complaints and profane comments on widely viewed television and politics, and as such, this period was a good opportunity for data collection.', 'following the methodology described in  #TAUTHOR_TAG and others, including a recent comparable danish dataset  #AUTHOR_TAG, we collected tweets using keywords']","['posts in ogtd v1. 0 were collected between  #AUTHOR_TAG.', 'we used the twitter api initially collecting tweets from popular and trending hashtags in greece, including television programs such as series, reality and entertainment shows.', 'due to the municipal, regional as well as the european parliament election taking place at the time, many hashtags included tweets discussing the elections.', 'the intuition behind this approach is that twitter as a microblogging service often gathers complaints and profane comments on widely viewed television and politics, and as such, this period was a good opportunity for data collection.', 'following the methodology described in  #TAUTHOR_TAG and others, including a recent comparable danish dataset  #AUTHOR_TAG, we collected tweets using keywords such as sensitive or obscene language.', 'queries for tweets containing common curse words and expressions usually found in offensive messages in greek as keywords ( such as the well - known word for "" asshole "", "" μαλακας "" ( malakas ) or "" go to hell "", "" στο διαολο "" ( sto diaolo ), etc. ) returned a large number of tweets.', 'aiming to compile a dataset including offensive tweets of diverse types ( sexist, racist, etc. ) targeted at various social groups, the twitter api was queried with expletives such as "" πουτανα "" ( poutana, "" whore "" ), "" καριολα "" ( kariola, "" bitch "" ), "" πουστης "" ( poustis, "" faggot "" ), etc. and their plural forms, to explore the semantic and pragmatic differences of the expletives mentioned above in their different contextual environments.', 'the challenge is to recognize between ironic and insulting uses of these swear words, a common phenomenon in greek.', 'the final query for data collection was for tweets containing "" εισαι "" ( eisai, "" you are "" ) as a keyword, inspired by  #TAUTHOR_TAG.', 'this particular keyword is considered a stop word as it is quite common and frequent in languages but was suspected to prove helpful for building the dataset for this particular project, as offensive language often follows the following structure : auxiliary verb ( be ) + noun / adjective.', 'the immediacy of social media and specifically twitter provides the opportunity for targeted insults to be investigated, following data mining of tweets including "" you are "" as a keyword.', 'in fact, many tweets']",5
"['methodology described in olid  #TAUTHOR_TAG.', 'duplicate punctuation such']","['methodology described in olid  #TAUTHOR_TAG.', 'duplicate punctuation such']","['collected a set of 49, 154 tweets.', 'urls, emojis and emoticons were removed, while usernames and user mentions were filtered as @ user following the same methodology described in olid  #TAUTHOR_TAG.', 'duplicate punctuation such']","['collected a set of 49, 154 tweets.', 'urls, emojis and emoticons were removed, while usernames and user mentions were filtered as @ user following the same methodology described in olid  #TAUTHOR_TAG.', 'duplicate punctuation such as question and exclamation marks was normalized.', 'after removing duplicate tweets, the dataset was comprised of 46, 218 tweets of which 5, 000 were randomly sampled for annotation.', 'we used light - tag 2 to annotate the dataset due to its simple and straightforward user interface and limitless annotations, provided by the software creators.', 'based on explicit annotation guidelines written in greek and our proposal of the definition of offensive language, a team of three volunteers were asked to classify each tweet found in the dataset with one of the following tags : offensive, not offensive and spam, which was introduced to filter out spam from the dataset.', 'inter - annotator agreement was subsequently calculated and labels with 100 % agreement were deemed acceptable annotations.', 'in cases of disagreement, labels with majority agreement above 66 % were selected as the actual annotations of the tweets in question.', 'for labels with complete disagreement between annotators, one of the authors of this paper reviewed the tweets with two extra human judges, to get the desired majority agreement above 66 %.', ""figure 1 is a confusion matrix that shows the inter - annotator agreement or reliability, statistically measured by cohen's kappa coefficient."", 'the benchmark annotated dataset produced contained 4, 779 tweets, containing over 29 % offensive content']",5
"['of topics popular among greek people ( e. g. political elections, tv shows, etc. ).', 'tweets were manually annotated by a team volunteers through an annotation platform.', 'we used the same guidelines used in the annotation of the english olid dataset  #TAUTHOR_TAG.', 'finally, we run several machine learning and deep learning classifiers and the best results were']","['of topics popular among greek people ( e. g. political elections, tv shows, etc. ).', 'tweets were manually annotated by a team volunteers through an annotation platform.', 'we used the same guidelines used in the annotation of the english olid dataset  #TAUTHOR_TAG.', 'finally, we run several machine learning and deep learning classifiers and the best results were']","['an array of topics popular among greek people ( e. g. political elections, tv shows, etc. ).', 'tweets were manually annotated by a team volunteers through an annotation platform.', 'we used the same guidelines used in the annotation of the english olid dataset  #TAUTHOR_TAG.', 'finally, we run several machine learning and deep learning classifiers and the best results were achieved by a lstm and gr']","['paper presented the offensive greek tweet dataset ( ogtd ), a manually annotated dataset for offensive language identification and the first greek dataset of its kind.', 'the ogtd v1. 0 contains a total of 4, 779 tweets, encompassing posts related to an array of topics popular among greek people ( e. g. political elections, tv shows, etc. ).', 'tweets were manually annotated by a team volunteers through an annotation platform.', 'we used the same guidelines used in the annotation of the english olid dataset  #TAUTHOR_TAG.', 'finally, we run several machine learning and deep learning classifiers and the best results were achieved by a lstm and gru with attention model']",5
"['hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['##ness inspired by the first layer of the hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['bulk of work on detecting abusive posts online addressed particular types of such language like textual attacks and hate speech  #AUTHOR_TAG, ag - gression  #AUTHOR_TAG, and others.', 'ogtd considers a more general definition of offensiveness inspired by the first layer of the hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity, and considers the target of offensive posts as indicators of potential hate speech posts ( insults targeted at groups ) and cyberbulling posts ( insults targeted at individuals ).', 'offensive language : previous work presented a dataset with sentences labelled as flame ( i. e. attacking or containing abusive words ) or okay  #AUTHOR_TAG with a naive bayes hybrid classifier and a user offensiveness estimation using an offensive lexicon and sentence syntactic structures  #AUTHOR_TAG.', 'a dataset of 3. 3m comments from the yahoo finance and news website, labelled as abusive or clean, was utilized in several experiments using ngrams, linguistic and syntactic features, combined with different types of word and comment embeddings as distributional semantics features  #AUTHOR_TAG.', 'the usefulness of character n - grams for abusive language detection was explored on the same dataset with three different methods.', 'the most recent project expanded on existing ideas for defining offensive language and presented the olid ( offensive language identification dataset ), a corpus of twitter posts hierarchically annotated on three levels, whether they contain offensive language or not, whether the offense is targeted and finally, the target of the offense  #TAUTHOR_TAG.', 'a cnn ( convolutional neural network ) deep learning approach outperformed every model trained, with pre - trained fasttext embeddings and updateable embeddings learned by the model as features.', 'in offenseval ( semeval - 2019 task 6 ), participants had the opportunity to use the olid to train their own systems, with the top teams outperforming the original models trained on the dataset.', 'hate speech : a study dataset of tweets posted after the murder of drummer lee rigby in the uk, manually annotated as offensive or antagonistic in terms of race ethnicity or religion for hate speech identification with multiple clas - sifiers  #AUTHOR_TAG.', 'a logistic regression classifier trained with paragraph2vec 1 word representations of comments from yahoo finance  #AUTHOR_TAG.', 'the latest approaches in detecting hate speech include a dataset of twitter posts, labelled as hateful, offensive or clean, used to train a logistic regression classifier with part - of - speech and word n - grams and a sentiment lexicon and a linear svm trained on']",0
"['hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['##ness inspired by the first layer of the hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['bulk of work on detecting abusive posts online addressed particular types of such language like textual attacks and hate speech  #AUTHOR_TAG, ag - gression  #AUTHOR_TAG, and others.', 'ogtd considers a more general definition of offensiveness inspired by the first layer of the hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity, and considers the target of offensive posts as indicators of potential hate speech posts ( insults targeted at groups ) and cyberbulling posts ( insults targeted at individuals ).', 'offensive language : previous work presented a dataset with sentences labelled as flame ( i. e. attacking or containing abusive words ) or okay  #AUTHOR_TAG with a naive bayes hybrid classifier and a user offensiveness estimation using an offensive lexicon and sentence syntactic structures  #AUTHOR_TAG.', 'a dataset of 3. 3m comments from the yahoo finance and news website, labelled as abusive or clean, was utilized in several experiments using ngrams, linguistic and syntactic features, combined with different types of word and comment embeddings as distributional semantics features  #AUTHOR_TAG.', 'the usefulness of character n - grams for abusive language detection was explored on the same dataset with three different methods.', 'the most recent project expanded on existing ideas for defining offensive language and presented the olid ( offensive language identification dataset ), a corpus of twitter posts hierarchically annotated on three levels, whether they contain offensive language or not, whether the offense is targeted and finally, the target of the offense  #TAUTHOR_TAG.', 'a cnn ( convolutional neural network ) deep learning approach outperformed every model trained, with pre - trained fasttext embeddings and updateable embeddings learned by the model as features.', 'in offenseval ( semeval - 2019 task 6 ), participants had the opportunity to use the olid to train their own systems, with the top teams outperforming the original models trained on the dataset.', 'hate speech : a study dataset of tweets posted after the murder of drummer lee rigby in the uk, manually annotated as offensive or antagonistic in terms of race ethnicity or religion for hate speech identification with multiple clas - sifiers  #AUTHOR_TAG.', 'a logistic regression classifier trained with paragraph2vec 1 word representations of comments from yahoo finance  #AUTHOR_TAG.', 'the latest approaches in detecting hate speech include a dataset of twitter posts, labelled as hateful, offensive or clean, used to train a logistic regression classifier with part - of - speech and word n - grams and a sentiment lexicon and a linear svm trained on']",0
"['hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['##ness inspired by the first layer of the hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity,']","['bulk of work on detecting abusive posts online addressed particular types of such language like textual attacks and hate speech  #AUTHOR_TAG, ag - gression  #AUTHOR_TAG, and others.', 'ogtd considers a more general definition of offensiveness inspired by the first layer of the hierarchical annotation model described in  #TAUTHOR_TAG.', ' #TAUTHOR_TAG model distinguishes targeted from general profanity, and considers the target of offensive posts as indicators of potential hate speech posts ( insults targeted at groups ) and cyberbulling posts ( insults targeted at individuals ).', 'offensive language : previous work presented a dataset with sentences labelled as flame ( i. e. attacking or containing abusive words ) or okay  #AUTHOR_TAG with a naive bayes hybrid classifier and a user offensiveness estimation using an offensive lexicon and sentence syntactic structures  #AUTHOR_TAG.', 'a dataset of 3. 3m comments from the yahoo finance and news website, labelled as abusive or clean, was utilized in several experiments using ngrams, linguistic and syntactic features, combined with different types of word and comment embeddings as distributional semantics features  #AUTHOR_TAG.', 'the usefulness of character n - grams for abusive language detection was explored on the same dataset with three different methods.', 'the most recent project expanded on existing ideas for defining offensive language and presented the olid ( offensive language identification dataset ), a corpus of twitter posts hierarchically annotated on three levels, whether they contain offensive language or not, whether the offense is targeted and finally, the target of the offense  #TAUTHOR_TAG.', 'a cnn ( convolutional neural network ) deep learning approach outperformed every model trained, with pre - trained fasttext embeddings and updateable embeddings learned by the model as features.', 'in offenseval ( semeval - 2019 task 6 ), participants had the opportunity to use the olid to train their own systems, with the top teams outperforming the original models trained on the dataset.', 'hate speech : a study dataset of tweets posted after the murder of drummer lee rigby in the uk, manually annotated as offensive or antagonistic in terms of race ethnicity or religion for hate speech identification with multiple clas - sifiers  #AUTHOR_TAG.', 'a logistic regression classifier trained with paragraph2vec 1 word representations of comments from yahoo finance  #AUTHOR_TAG.', 'the latest approaches in detecting hate speech include a dataset of twitter posts, labelled as hateful, offensive or clean, used to train a logistic regression classifier with part - of - speech and word n - grams and a sentiment lexicon and a linear svm trained on']",3
"['other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby']","['other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations']","['these type features improve generalization to novel entities by allowing the model to hone in on positions with particularly relevant bits of dialogue context during its soft attention and copying. other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations of candidate system', 'responses based on']","['', 'to copy over the relevant entities from the input context, thereby learning to extract important dialogue context. in our best performing model, we augment the inputs to the encoder by adding entity type features. classes present in the knowledge base of the', 'dataset, namely the 8 distinct entity types referred to in table 1, are encoded as one - hot vectors. whenever a token of a', ""certain entity type is seen during encoding, we append the appropriate one - hot vector to the token's word embedding before it is fed into the recurrent cell. these type features improve generalization to novel entities by allowing the model to hone in on positions with particularly relevant bits of dialogue context during its soft attention and copying. other cited"", 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations of candidate system', 'responses based on whether there is lexical entity class matching with provided dialogue context. in these works, such features are referred to as match features. all of our architectures use an lstm cell as the recurrent unit  #AUTHOR_TAG with a bias of 1 added to the forget gate in the style of  #AUTHOR_TAG']",0
"['other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby']","['other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations']","['these type features improve generalization to novel entities by allowing the model to hone in on positions with particularly relevant bits of dialogue context during its soft attention and copying. other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations of candidate system', 'responses based on']","['', 'to copy over the relevant entities from the input context, thereby learning to extract important dialogue context. in our best performing model, we augment the inputs to the encoder by adding entity type features. classes present in the knowledge base of the', 'dataset, namely the 8 distinct entity types referred to in table 1, are encoded as one - hot vectors. whenever a token of a', ""certain entity type is seen during encoding, we append the appropriate one - hot vector to the token's word embedding before it is fed into the recurrent cell. these type features improve generalization to novel entities by allowing the model to hone in on positions with particularly relevant bits of dialogue context during its soft attention and copying. other cited"", 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations of candidate system', 'responses based on whether there is lexical entity class matching with provided dialogue context. in these works, such features are referred to as match features. all of our architectures use an lstm cell as the recurrent unit  #AUTHOR_TAG with a bias of 1 added to the forget gate in the style of  #AUTHOR_TAG']",0
"['other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby']","['other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations']","['these type features improve generalization to novel entities by allowing the model to hone in on positions with particularly relevant bits of dialogue context during its soft attention and copying. other cited', 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations of candidate system', 'responses based on']","['', 'to copy over the relevant entities from the input context, thereby learning to extract important dialogue context. in our best performing model, we augment the inputs to the encoder by adding entity type features. classes present in the knowledge base of the', 'dataset, namely the 8 distinct entity types referred to in table 1, are encoded as one - hot vectors. whenever a token of a', ""certain entity type is seen during encoding, we append the appropriate one - hot vector to the token's word embedding before it is fed into the recurrent cell. these type features improve generalization to novel entities by allowing the model to hone in on positions with particularly relevant bits of dialogue context during its soft attention and copying. other cited"", 'work using the dstc2 dataset  #TAUTHOR_TAG implement similar mechanisms whereby they expand the feature representations of candidate system', 'responses based on whether there is lexical entity class matching with provided dialogue context. in these works, such features are referred to as match features. all of our architectures use an lstm cell as the recurrent unit  #AUTHOR_TAG with a bias of 1 added to the forget gate in the style of  #AUTHOR_TAG']",4
[':  #TAUTHOR_TAG report a per'],['accuracy :  #TAUTHOR_TAG report a'],"[' #TAUTHOR_TAG report a per - turn response accuracy,']","['of dialogue systems is known to be difficult.', ""we employ several metrics for assessing specific aspects of our model, drawn from previous work : • per - response accuracy :  #TAUTHOR_TAG report a per - turn response accuracy, which tests their model's ability to select the system response at a certain timestep."", 'their system does a multiclass classification over a predefined candidate set of responses, which was created by aggregating all system responses seen in the training, validation, and test sets.', 'our model actually generates each individual token of the response, and we consider a prediction to be correct only if every token of the model output matches the corresponding token in the gold response.', 'evaluating using this metric on our model is therefore significantly more stringent a test than for the model of  #TAUTHOR_TAG.', ""• per - dialogue accuracy :  #TAUTHOR_TAG also report a per - dialogue accuracy, which assesses their model's ability to produce every system response of the dialogue correctly."", '']",4
[':  #TAUTHOR_TAG report a per'],['accuracy :  #TAUTHOR_TAG report a'],"[' #TAUTHOR_TAG report a per - turn response accuracy,']","['of dialogue systems is known to be difficult.', ""we employ several metrics for assessing specific aspects of our model, drawn from previous work : • per - response accuracy :  #TAUTHOR_TAG report a per - turn response accuracy, which tests their model's ability to select the system response at a certain timestep."", 'their system does a multiclass classification over a predefined candidate set of responses, which was created by aggregating all system responses seen in the training, validation, and test sets.', 'our model actually generates each individual token of the response, and we consider a prediction to be correct only if every token of the model output matches the corresponding token in the gold response.', 'evaluating using this metric on our model is therefore significantly more stringent a test than for the model of  #TAUTHOR_TAG.', ""• per - dialogue accuracy :  #TAUTHOR_TAG also report a per - dialogue accuracy, which assesses their model's ability to produce every system response of the dialogue correctly."", '']",4
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['our experiments, we used dialogues extracted from the dialogue state tracking challenge 2 ( dstc2 )  #AUTHOR_TAG, a restaurant reservation system dataset.', 'while the goal of the original challenge was building a system for inferring dialogue state, for our study, we use the version of the data from  #TAUTHOR_TAG, which ignores the dialogue state annotations, using only the raw text of the dialogues.', '']",5
[':  #TAUTHOR_TAG report a per'],['accuracy :  #TAUTHOR_TAG report a'],"[' #TAUTHOR_TAG report a per - turn response accuracy,']","['of dialogue systems is known to be difficult.', ""we employ several metrics for assessing specific aspects of our model, drawn from previous work : • per - response accuracy :  #TAUTHOR_TAG report a per - turn response accuracy, which tests their model's ability to select the system response at a certain timestep."", 'their system does a multiclass classification over a predefined candidate set of responses, which was created by aggregating all system responses seen in the training, validation, and test sets.', 'our model actually generates each individual token of the response, and we consider a prediction to be correct only if every token of the model output matches the corresponding token in the gold response.', 'evaluating using this metric on our model is therefore significantly more stringent a test than for the model of  #TAUTHOR_TAG.', ""• per - dialogue accuracy :  #TAUTHOR_TAG also report a per - dialogue accuracy, which assesses their model's ability to produce every system response of the dialogue correctly."", '']",5
[':  #TAUTHOR_TAG report a per'],['accuracy :  #TAUTHOR_TAG report a'],"[' #TAUTHOR_TAG report a per - turn response accuracy,']","['of dialogue systems is known to be difficult.', ""we employ several metrics for assessing specific aspects of our model, drawn from previous work : • per - response accuracy :  #TAUTHOR_TAG report a per - turn response accuracy, which tests their model's ability to select the system response at a certain timestep."", 'their system does a multiclass classification over a predefined candidate set of responses, which was created by aggregating all system responses seen in the training, validation, and test sets.', 'our model actually generates each individual token of the response, and we consider a prediction to be correct only if every token of the model output matches the corresponding token in the gold response.', 'evaluating using this metric on our model is therefore significantly more stringent a test than for the model of  #TAUTHOR_TAG.', ""• per - dialogue accuracy :  #TAUTHOR_TAG also report a per - dialogue accuracy, which assesses their model's ability to produce every system response of the dialogue correctly."", '']",3
"['model of  #TAUTHOR_TAG, which is a variant']","['model of  #TAUTHOR_TAG, which is a variant']","['of  #TAUTHOR_TAG, which is a variant']","['table 2, we present the results of our models compared to the reported performance of the best performing model of  #TAUTHOR_TAG, which is a variant of an end - to - end memory network  #AUTHOR_TAG.', '']",1
"['model of  #TAUTHOR_TAG, which is a variant']","['model of  #TAUTHOR_TAG, which is a variant']","['of  #TAUTHOR_TAG, which is a variant']","['table 2, we present the results of our models compared to the reported performance of the best performing model of  #TAUTHOR_TAG, which is a variant of an end - to - end memory network  #AUTHOR_TAG.', '']",7
['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions'],['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism'],"['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism for modeling coherence. in this work, in contrast', ', we propose a supervised neural model for text segmentation that explicitly takes coherence into account : we augment the segmentation prediction objective with an auxiliary coherence modeling objective']","['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism for modeling coherence. in this work, in contrast', "", we propose a supervised neural model for text segmentation that explicitly takes coherence into account : we augment the segmentation prediction objective with an auxiliary coherence modeling objective. our proposed model, dubbed coherence - aware text segmentation ( cats ), encodes a sentence sequence using two hierarchically connected transformer networks ( vaswani et al. 2017 ; devlin et al. 2018 ). similar to  #TAUTHOR_TAG, cats'main learning objective is a binary"", 'sentence - level segmentation prediction. however, cats augments the segmentation objective with an auxiliary coherence - based objec - tive which pushes the model to predict higher coherence for original text snippets than for corrupt ( i. e., fake ) sentence sequences. we empirically show ( 1 ) that even without the auxiliary coherence objective, the two - level transformer model for text segmentation ( tlt - ts ) yields state - of - the - art performance across multiple benchmarks, ( 2', '']",4
['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions'],['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism'],"['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism for modeling coherence. in this work, in contrast', ', we propose a supervised neural model for text segmentation that explicitly takes coherence into account : we augment the segmentation prediction objective with an auxiliary coherence modeling objective']","['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism for modeling coherence. in this work, in contrast', "", we propose a supervised neural model for text segmentation that explicitly takes coherence into account : we augment the segmentation prediction objective with an auxiliary coherence modeling objective. our proposed model, dubbed coherence - aware text segmentation ( cats ), encodes a sentence sequence using two hierarchically connected transformer networks ( vaswani et al. 2017 ; devlin et al. 2018 ). similar to  #TAUTHOR_TAG, cats'main learning objective is a binary"", 'sentence - level segmentation prediction. however, cats augments the segmentation objective with an auxiliary coherence - based objec - tive which pushes the model to predict higher coherence for original text snippets than for corrupt ( i. e., fake ) sentence sequences. we empirically show ( 1 ) that even without the auxiliary coherence objective, the two - level transformer model for text segmentation ( tlt - ts ) yields state - of - the - art performance across multiple benchmarks, ( 2', '']",4
"[',  #TAUTHOR_TAG identify wikipedia as a free large -']","['intra - sentence similarities and performs segmentation based on the cliques of the similarity graph.', 'finally,  #TAUTHOR_TAG identify wikipedia as a free large - scale']","[',  #TAUTHOR_TAG identify wikipedia as a free large - scale source of manually segmented texts that can be']","['segmentation tasks come in two main flavors : ( 1 ) linear ( i. e., sequential ) text segmentation and ( 2 ) hierarchical segmentation in which top - level segments are further broken down into sub - segments.', 'while the hierarchical segmentation received a non - negligible research attention ( yaari 1997 ; eisenstein 2009 ; du, buntine, and john - son 2013 ), the vast majority of the proposed models ( including this work ) focus on linear segmentation ( hearst 1994 ; beeferman, berger, and lafferty 1999 ; choi 2000 ; brants, chen, and tsochantaridis 2002 ; misra et al. 2009 ; riedl and biemann 2012 ; glavas, nanni, and ponzetto 2016 ; koshorek et al. 2018, inter alia ).', 'in one of the pioneering segmentation efforts,  #AUTHOR_TAG proposed an unsupervised texttiling algorithm based on the lexical overlap between adjacent sentences and paragraphs.', ' #AUTHOR_TAG computes the similarities between sentences in a similar fashion, but renormalizes them within the local context ; the segments are then obtained through divisive clustering.', ' #AUTHOR_TAG and  #AUTHOR_TAG minimize the segmentation cost via exhaustive search with dynamic programming.', 'following the assumption that topical cohesion guides the segmentation of the text, a number of segmentation approaches based on topic models have been proposed.', ' #AUTHOR_TAG induce latent representations of text snippets using probabilistic latent semantic analysis ( hofmann 1999 ) and segment based on similarities between latent representations of adjacent snippets.', ' #AUTHOR_TAG and  #AUTHOR_TAG leverage topic vectors of snippets obtained with the latent dirichlet allocation model ( blei, ng, and jordan 2003 ).', "" #AUTHOR_TAG finds a globally optimal segmentation based on the similarities of snippets'topic vectors using dynamic programming,  #AUTHOR_TAG adjust the texttiling model of ( hearst 1994 ) to use topic vectors instead of sparse lexicalized representations of snippets."", ' #AUTHOR_TAG proposed a first graphbased model for text segmentation.', 'they segment lecture transcripts by first inducing a fully connected sentence graph with edge weights corresponding to cosine similarities between sparse bag - of - word sentence vectors and then running a minimum normalized multiway cut algorithm to obtain the segments.', 'glavas,  #AUTHOR_TAG propose graphseg, a graph - based segmentation algorithm similar in nature to ( malioutov and barzilay 2006 ), which uses dense sentence vectors, obtained by aggregating word embeddings, to compute intra - sentence similarities and performs segmentation based on the cliques of the similarity graph.', 'finally,  #TAUTHOR_TAG identify wikipedia as a free large - scale source of manually segmented texts that can be']",4
['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions'],['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism'],"['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism for modeling coherence. in this work, in contrast', ', we propose a supervised neural model for text segmentation that explicitly takes coherence into account : we augment the segmentation prediction objective with an auxiliary coherence modeling objective']","['neural segmentation model  #TAUTHOR_TAG directly learns to predict binary sentence - level segmentation decisions and has no explicit mechanism for modeling coherence. in this work, in contrast', "", we propose a supervised neural model for text segmentation that explicitly takes coherence into account : we augment the segmentation prediction objective with an auxiliary coherence modeling objective. our proposed model, dubbed coherence - aware text segmentation ( cats ), encodes a sentence sequence using two hierarchically connected transformer networks ( vaswani et al. 2017 ; devlin et al. 2018 ). similar to  #TAUTHOR_TAG, cats'main learning objective is a binary"", 'sentence - level segmentation prediction. however, cats augments the segmentation objective with an auxiliary coherence - based objec - tive which pushes the model to predict higher coherence for original text snippets than for corrupt ( i. e., fake ) sentence sequences. we empirically show ( 1 ) that even without the auxiliary coherence objective, the two - level transformer model for text segmentation ( tlt - ts ) yields state - of - the - art performance across multiple benchmarks, ( 2', '']",3
"['created by  #TAUTHOR_TAG from english ( en ) wikipedia, we created wik']","['created by  #TAUTHOR_TAG from english ( en ) wikipedia, we created wiki - 50 - cs, wiki - 50 - fi, and wiki - 50 - tr datasets consisting of 50 randomly selected pages from czech ( cs ), finnish ( fi ), and turkish ( tr ) wikipedia, respectively.', '']","['created by  #TAUTHOR_TAG from english ( en ) wikipedia, we created wik']","['##i - 727k corpus.', ' #AUTHOR_TAG leveraged the manual structuring of wikipedia pages into sections to automatically create a large segmentation - annotated corpus.', 'wiki - 727k consists of 727, 746 documents created from english ( en ) wikipedia pages, divided into training ( 80 % ), development ( 10 % ), and test portions ( 10 % ).', 'we train, optimize, and evaluate our models on respective portions of the wiki - 727k dataset.', 'standard test corpora.', ' #AUTHOR_TAG additionally created a small evaluation set wiki - 50 to allow for comparative evaluation against unsupervised segmentation models, e. g., the graphseg model of glavas,  #AUTHOR_TAG, for which evaluation on large datasets is prohibitively slow.', 'for years, the synthetic dataset of  #AUTHOR_TAG was used as a standard becnhmark for text segmentation models.', 'choi dataset contains 920 documents, each of which is a concatenation of 10 paragraphs randomly sampled from the brown corpus.', 'choi dataset is divided into subsets containing only documents with specific variability of segment lengths ( e. g., segments with 3 - 5 or with 9 - 11 sentences ).', '7 finally, we evaluate the performance of our models on two small datasets, cities and elements, created by  #AUTHOR_TAG from wikipedia pages dedicated to the cities of the world and chemical elements, respectively.', 'other languages.', 'in order to test the performance of our transformer - based models in zero - shot language transfer setup, we prepared small evaluation datasets in other languages.', 'analogous to the wiki - 50 dataset created by  #TAUTHOR_TAG from english ( en ) wikipedia, we created wiki - 50 - cs, wiki - 50 - fi, and wiki - 50 - tr datasets consisting of 50 randomly selected pages from czech ( cs ), finnish ( fi ), and turkish ( tr ) wikipedia, respectively.', '']",3
"['created by  #TAUTHOR_TAG from english ( en ) wikipedia, we created wik']","['created by  #TAUTHOR_TAG from english ( en ) wikipedia, we created wiki - 50 - cs, wiki - 50 - fi, and wiki - 50 - tr datasets consisting of 50 randomly selected pages from czech ( cs ), finnish ( fi ), and turkish ( tr ) wikipedia, respectively.', '']","['created by  #TAUTHOR_TAG from english ( en ) wikipedia, we created wik']","['##i - 727k corpus.', ' #AUTHOR_TAG leveraged the manual structuring of wikipedia pages into sections to automatically create a large segmentation - annotated corpus.', 'wiki - 727k consists of 727, 746 documents created from english ( en ) wikipedia pages, divided into training ( 80 % ), development ( 10 % ), and test portions ( 10 % ).', 'we train, optimize, and evaluate our models on respective portions of the wiki - 727k dataset.', 'standard test corpora.', ' #AUTHOR_TAG additionally created a small evaluation set wiki - 50 to allow for comparative evaluation against unsupervised segmentation models, e. g., the graphseg model of glavas,  #AUTHOR_TAG, for which evaluation on large datasets is prohibitively slow.', 'for years, the synthetic dataset of  #AUTHOR_TAG was used as a standard becnhmark for text segmentation models.', 'choi dataset contains 920 documents, each of which is a concatenation of 10 paragraphs randomly sampled from the brown corpus.', 'choi dataset is divided into subsets containing only documents with specific variability of segment lengths ( e. g., segments with 3 - 5 or with 9 - 11 sentences ).', '7 finally, we evaluate the performance of our models on two small datasets, cities and elements, created by  #AUTHOR_TAG from wikipedia pages dedicated to the cities of the world and chemical elements, respectively.', 'other languages.', 'in order to test the performance of our transformer - based models in zero - shot language transfer setup, we prepared small evaluation datasets in other languages.', 'analogous to the wiki - 50 dataset created by  #TAUTHOR_TAG from english ( en ) wikipedia, we created wiki - 50 - cs, wiki - 50 - fi, and wiki - 50 - tr datasets consisting of 50 randomly selected pages from czech ( cs ), finnish ( fi ), and turkish ( tr ) wikipedia, respectively.', '']",6
"[' #TAUTHOR_TAG, a hierarchical encoder based on recurrent components, across the board']","[' #TAUTHOR_TAG, a hierarchical encoder based on recurrent components, across the board.', 'the improved']","[' #TAUTHOR_TAG, a hierarchical encoder based on recurrent components, across the board.', 'the improved performance']","['', ""table 1 shows models'performance on five en evaluation datasets."", 'both our transformer - based models - tlt - ts and cats - outperform the competing supervised model of  #TAUTHOR_TAG, a hierarchical encoder based on recurrent components, across the board.', '']",7
"[' #TAUTHOR_TAG, a hierarchical encoder based on recurrent components, across the board']","[' #TAUTHOR_TAG, a hierarchical encoder based on recurrent components, across the board.', 'the improved']","[' #TAUTHOR_TAG, a hierarchical encoder based on recurrent components, across the board.', 'the improved performance']","['', ""table 1 shows models'performance on five en evaluation datasets."", 'both our transformer - based models - tlt - ts and cats - outperform the competing supervised model of  #TAUTHOR_TAG, a hierarchical encoder based on recurrent components, across the board.', '']",7
"[',  #TAUTHOR_TAG identify wikipedia as a free large -']","['intra - sentence similarities and performs segmentation based on the cliques of the similarity graph.', 'finally,  #TAUTHOR_TAG identify wikipedia as a free large - scale']","[',  #TAUTHOR_TAG identify wikipedia as a free large - scale source of manually segmented texts that can be']","['segmentation tasks come in two main flavors : ( 1 ) linear ( i. e., sequential ) text segmentation and ( 2 ) hierarchical segmentation in which top - level segments are further broken down into sub - segments.', 'while the hierarchical segmentation received a non - negligible research attention ( yaari 1997 ; eisenstein 2009 ; du, buntine, and john - son 2013 ), the vast majority of the proposed models ( including this work ) focus on linear segmentation ( hearst 1994 ; beeferman, berger, and lafferty 1999 ; choi 2000 ; brants, chen, and tsochantaridis 2002 ; misra et al. 2009 ; riedl and biemann 2012 ; glavas, nanni, and ponzetto 2016 ; koshorek et al. 2018, inter alia ).', 'in one of the pioneering segmentation efforts,  #AUTHOR_TAG proposed an unsupervised texttiling algorithm based on the lexical overlap between adjacent sentences and paragraphs.', ' #AUTHOR_TAG computes the similarities between sentences in a similar fashion, but renormalizes them within the local context ; the segments are then obtained through divisive clustering.', ' #AUTHOR_TAG and  #AUTHOR_TAG minimize the segmentation cost via exhaustive search with dynamic programming.', 'following the assumption that topical cohesion guides the segmentation of the text, a number of segmentation approaches based on topic models have been proposed.', ' #AUTHOR_TAG induce latent representations of text snippets using probabilistic latent semantic analysis ( hofmann 1999 ) and segment based on similarities between latent representations of adjacent snippets.', ' #AUTHOR_TAG and  #AUTHOR_TAG leverage topic vectors of snippets obtained with the latent dirichlet allocation model ( blei, ng, and jordan 2003 ).', "" #AUTHOR_TAG finds a globally optimal segmentation based on the similarities of snippets'topic vectors using dynamic programming,  #AUTHOR_TAG adjust the texttiling model of ( hearst 1994 ) to use topic vectors instead of sparse lexicalized representations of snippets."", ' #AUTHOR_TAG proposed a first graphbased model for text segmentation.', 'they segment lecture transcripts by first inducing a fully connected sentence graph with edge weights corresponding to cosine similarities between sparse bag - of - word sentence vectors and then running a minimum normalized multiway cut algorithm to obtain the segments.', 'glavas,  #AUTHOR_TAG propose graphseg, a graph - based segmentation algorithm similar in nature to ( malioutov and barzilay 2006 ), which uses dense sentence vectors, obtained by aggregating word embeddings, to compute intra - sentence similarities and performs segmentation based on the cliques of the similarity graph.', 'finally,  #TAUTHOR_TAG identify wikipedia as a free large - scale source of manually segmented texts that can be']",1
[') task  #TAUTHOR_TAG focuses on'],['( fever ) task  #TAUTHOR_TAG focuses on'],[') task  #TAUTHOR_TAG focuses on'],"['increasing amounts of textual information on the web have brought demands to develop techniques to extract and verify a fact.', 'the fact extraction and verification ( fever ) task  #TAUTHOR_TAG focuses on verification of textual claims against evidence.', '']",0
[') task  #TAUTHOR_TAG focuses on'],['( fever ) task  #TAUTHOR_TAG focuses on'],[') task  #TAUTHOR_TAG focuses on'],"['increasing amounts of textual information on the web have brought demands to develop techniques to extract and verify a fact.', 'the fact extraction and verification ( fever ) task  #TAUTHOR_TAG focuses on verification of textual claims against evidence.', '']",5
[') task  #TAUTHOR_TAG focuses on'],['( fever ) task  #TAUTHOR_TAG focuses on'],[') task  #TAUTHOR_TAG focuses on'],"['increasing amounts of textual information on the web have brought demands to develop techniques to extract and verify a fact.', 'the fact extraction and verification ( fever ) task  #TAUTHOR_TAG focuses on verification of textual claims against evidence.', '']",5
"['the nearestp dataset described in  #TAUTHOR_TAG.', 'in']","['the nearestp dataset described in  #TAUTHOR_TAG.', 'in']","['the nearestp dataset described in  #TAUTHOR_TAG.', 'in']","['rte component, we adopt deiste ( deep explorations of inter - sentence interactions for textual entailment ) model that is the state - of - the - art in rte tasks  #AUTHOR_TAG.', 'rte component is trained on labeled claims paired with sentencelevel evidence.', 'to build the model, we utilize the nearestp dataset described in  #TAUTHOR_TAG.', 'in a case where multiple sentences are required as evidence, the texts of the sentences are concatenated.', 'we use adam  #AUTHOR_TAG as an optimizer and utilize 300 dimensional glove vector which is adapted by the baseline system.', 'the other model parameters are the same as the parameters described in  #AUTHOR_TAG.', 'claims labelled as nei are easier to predict correctly than supported and refuted because unlike supported and refuted, nei dose not need evidence.', 'therefore, our rte component are designed to predict the claims as nei if the model can not predict claims as supported or refuted with high confidence.', 'rte prediction process is composed of three steps.', 'firstly, we calculate the probability score of each label for pairs of a claim and candidate sentence using deiste model.', 'secondly, we decide a prediction label using the following equations.', 'where s is a set of pairs of a claim and candidate sentence ; a = { supported, refuted } ; p s, a is a probability score of a pair for label a ; p t is a threshold value ; label pred is prediction label for a claim.', 'finally, we sort candidate sentences in descending order of scores and select at most 5 evidence sentences with the same label as predicted label.', 'we also apply grid search to find the best threshold p t and set it to 0. 93']",5
"['parameter tuning and performance evaluation, we used a development and test datasets used in  #TAUTHOR_TAG']","['parameter tuning and performance evaluation, we used a development and test datasets used in  #TAUTHOR_TAG']","['parameter tuning and performance evaluation, we used a development and test datasets used in  #TAUTHOR_TAG']","['used official training dataset for training rte component.', 'for parameter tuning and performance evaluation, we used a development and test datasets used in  #TAUTHOR_TAG']",5
['to the cube - pruning parser of  #TAUTHOR_TAG'],['to the cube - pruning parser of  #TAUTHOR_TAG'],"['to the cube - pruning parser of  #TAUTHOR_TAG.', 'this results in the highest reported scores on wsj evaluation set ( uas 93']","['learning algorithms like the perceptron are widely used for structured prediction tasks.', 'for sequential search problems, like left - to - right tagging and parsing, beam search has been successfully combined with perceptron variants that accommodate search errors  #AUTHOR_TAG.', 'however, perceptron training with inexact search is less studied for bottom - up parsing and, more generally, inference over hypergraphs.', 'in this paper, we generalize the violation - fixing perceptron of  #AUTHOR_TAG to hypergraphs and apply it to the cube - pruning parser of  #TAUTHOR_TAG.', 'this results in the highest reported scores on wsj evaluation set ( uas 93. 50 % and las 92. 41 % respectively ) without the aid of additional resources']",5
[' #TAUTHOR_TAG and shown'],[' #TAUTHOR_TAG and shown'],[' #TAUTHOR_TAG and shown'],[' #TAUTHOR_TAG'],5
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['', 'at the root nodes but skips any non - violations. this is the strategy used by  #TAUTHOR_TAG']",5
['of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],['of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],['ran a number of experiments on the cubepruning dependency parser of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],"['ran a number of experiments on the cubepruning dependency parser of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are the complete and incomplete states and the hyperedges are the instantiations of the two parsing rules in the eisner algorithm  #AUTHOR_TAG.', 'the feature templates we used are a superset of  #TAUTHOR_TAG.', '']",5
['of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],['of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],['ran a number of experiments on the cubepruning dependency parser of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],"['ran a number of experiments on the cubepruning dependency parser of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are the complete and incomplete states and the hyperedges are the instantiations of the two parsing rules in the eisner algorithm  #AUTHOR_TAG.', 'the feature templates we used are a superset of  #TAUTHOR_TAG.', '']",5
[' #TAUTHOR_TAG and shown'],[' #TAUTHOR_TAG and shown'],[' #TAUTHOR_TAG and shown'],[' #TAUTHOR_TAG'],0
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['', 'at the root nodes but skips any non - violations. this is the strategy used by  #TAUTHOR_TAG']",0
['of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],['of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],['ran a number of experiments on the cubepruning dependency parser of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are'],"['ran a number of experiments on the cubepruning dependency parser of  #TAUTHOR_TAG search space can be represented as a hypergraph in which the nodes are the complete and incomplete states and the hyperedges are the instantiations of the two parsing rules in the eisner algorithm  #AUTHOR_TAG.', 'the feature templates we used are a superset of  #TAUTHOR_TAG.', '']",0
"['without max - violation update strategies  #TAUTHOR_TAG, showing the']","['without max - violation update strategies  #TAUTHOR_TAG, showing the']","['without max - violation update strategies  #TAUTHOR_TAG, showing the importance of update strategies in inexact hypergraph search.', 'the uas score on penn']","['', 'we utilized a linear chain crf tagger which has an accuracy of 96. 9 % on the validation data and 97. 3 % on the evaluation data 2.', 'for chinese, we use the chinese penn treebank converted to dependencies and split into train / - validation / evaluation according to  #AUTHOR_TAG.', 'we report both unlabeled attachment scores ( uas ) and labeled attachment scores ( las ), ignoring punctuations  #AUTHOR_TAG.', 'table 1 displays the results.', 'our improved cube - pruned parser represents a significant improvement over the feature - rich transition - based parser of  #AUTHOR_TAG with a large beam size.', 'it also improves over the baseline cube - pruning parser without max - violation update strategies  #TAUTHOR_TAG, showing the importance of update strategies in inexact hypergraph search.', '']",4
"[',  #TAUTHOR_TAG, schul']","['a synchronic perspective,  #TAUTHOR_TAG, schulte im  #AUTHOR_TAG and schulte im  #AUTHOR_TAG a ) are closest to our approach, since they predict the compositionality of compounds using vector space representations.', 'however,']","['a synchronic perspective,  #TAUTHOR_TAG, schulte im  #AUTHOR_TAG and schul']","['a synchronic perspective,  #TAUTHOR_TAG, schulte im  #AUTHOR_TAG and schulte im  #AUTHOR_TAG a ) are closest to our approach, since they predict the compositionality of compounds using vector space representations.', 'however, schulte im  #AUTHOR_TAG use german data and do not investigate diachronic changes.', ""they report a spearman's ρ of 0. 65 for predicting the compositionality of compounds based on the features of their semantic space and find that the modifiers mainly influence the compositionality of the whole compound, contrary to their expectation that the head should be the main source of influence."", 'this is true for both the human annotation and their vector space model.', 'schulte im  #AUTHOR_TAG a ) further investigate the role of heads and modifiers on the prediction of compositionality and report ρ values between 0. 35 and 0. 61 for their models on german and english data.', "" #AUTHOR_TAG also report spearman's ρ between their surveyed compositionality values and word vectors."", 'they achieve ρ values of around 0. 68, depending on the model.', 'from a diachronic perspective, we follow the general methodological approach of  #AUTHOR_TAG, who use ppmi, svd and word2vec based vector spaces to investigate a shift in meaning for chosen words with a known semantic change ( gay, broadcast, etc. ).', ""they use time series to detect a significant change - point for two words, using cosine similarity and spearman's ρ."", 'they also compute the displacement for a single word embedding by calculating the cosine similarity between a point in time t and a later point in time t + ∆. we adapt this methodology and make use of the same corpus ( google books ngram )']",0
"['to measure compositionality for compounds in different languages ( von der  #TAUTHOR_TAG ; schulte im  #AUTHOR_TAG b ).', 'some of these works have used large corpora']","['to measure compositionality for compounds in different languages ( von der  #TAUTHOR_TAG ; schulte im  #AUTHOR_TAG b ).', 'some of these works have used large corpora']","['to measure compositionality for compounds in different languages ( von der  #TAUTHOR_TAG ; schulte im  #AUTHOR_TAG b ).', 'some of these works have used large corpora']","['studies have been conducted in order to measure compositionality for compounds in different languages ( von der  #TAUTHOR_TAG ; schulte im  #AUTHOR_TAG b ).', 'some of these works have used large corpora to extract vector - based representations of compounds and their parts to automatically determine the compositionality of a given compound.', 'the models were validated on the basis of their correlation with human compositionality ratings for a set of compounds.', 'because we are interested in the diachronic perspective on compounds, we use a time - stamped corpus : the google books ngram corpus 2  #AUTHOR_TAG it contains books from the 1500s to the 2000s, from which we retrieve the contextual information of compounds and their constituents per year.', 'we operate on 5 - grams, which is the largest unit provided by google ngrams and use the words appearing in the 5 - grams as both target words and context.', 'we use the part - of - speech information already included in the google ngram corpus to extract noun - noun patterns.', 'we then regard all other tokens in the 5 - gram as context words and from this build up a semantic space rep - resentation of noun compounds for each year.', '']",0
"[',  #TAUTHOR_TAG, schul']","['a synchronic perspective,  #TAUTHOR_TAG, schulte im  #AUTHOR_TAG and schulte im  #AUTHOR_TAG a ) are closest to our approach, since they predict the compositionality of compounds using vector space representations.', 'however,']","['a synchronic perspective,  #TAUTHOR_TAG, schulte im  #AUTHOR_TAG and schul']","['a synchronic perspective,  #TAUTHOR_TAG, schulte im  #AUTHOR_TAG and schulte im  #AUTHOR_TAG a ) are closest to our approach, since they predict the compositionality of compounds using vector space representations.', 'however, schulte im  #AUTHOR_TAG use german data and do not investigate diachronic changes.', ""they report a spearman's ρ of 0. 65 for predicting the compositionality of compounds based on the features of their semantic space and find that the modifiers mainly influence the compositionality of the whole compound, contrary to their expectation that the head should be the main source of influence."", 'this is true for both the human annotation and their vector space model.', 'schulte im  #AUTHOR_TAG a ) further investigate the role of heads and modifiers on the prediction of compositionality and report ρ values between 0. 35 and 0. 61 for their models on german and english data.', "" #AUTHOR_TAG also report spearman's ρ between their surveyed compositionality values and word vectors."", 'they achieve ρ values of around 0. 68, depending on the model.', 'from a diachronic perspective, we follow the general methodological approach of  #AUTHOR_TAG, who use ppmi, svd and word2vec based vector spaces to investigate a shift in meaning for chosen words with a known semantic change ( gay, broadcast, etc. ).', ""they use time series to detect a significant change - point for two words, using cosine similarity and spearman's ρ."", 'they also compute the displacement for a single word embedding by calculating the cosine similarity between a point in time t and a later point in time t + ∆. we adapt this methodology and make use of the same corpus ( google books ngram )']",3
"['annotated compositionality ratings of reddy.', 'like  #TAUTHOR_TAG and schulte im  #AUTHOR_TAG, we opt']","['annotated compositionality ratings of reddy.', 'like  #TAUTHOR_TAG and schulte im  #AUTHOR_TAG, we opt']","['proposed metrics and the annotated compositionality ratings of reddy.', 'like  #TAUTHOR_TAG and schulte im  #AUTHOR_TAG, we opt']","['first carry out a quantitative experiment, to see if our features bolster the prediction of compositionality in noun - noun compounds.', 'to do so, we calculate correlation scores between our proposed metrics and the annotated compositionality ratings of reddy.', ""like  #TAUTHOR_TAG and schulte im  #AUTHOR_TAG, we opt for spearman's ρ."", 'to find the best configuration of a time span and cut - off for the regression models, we use the r 2 metric.', 'table 1 presents our findings ; we will discuss them in the following section 5']",3
"['to measure compositionality for compounds in different languages ( von der  #TAUTHOR_TAG ; schulte im  #AUTHOR_TAG b ).', 'some of these works have used large corpora']","['to measure compositionality for compounds in different languages ( von der  #TAUTHOR_TAG ; schulte im  #AUTHOR_TAG b ).', 'some of these works have used large corpora']","['to measure compositionality for compounds in different languages ( von der  #TAUTHOR_TAG ; schulte im  #AUTHOR_TAG b ).', 'some of these works have used large corpora']","['studies have been conducted in order to measure compositionality for compounds in different languages ( von der  #TAUTHOR_TAG ; schulte im  #AUTHOR_TAG b ).', 'some of these works have used large corpora to extract vector - based representations of compounds and their parts to automatically determine the compositionality of a given compound.', 'the models were validated on the basis of their correlation with human compositionality ratings for a set of compounds.', 'because we are interested in the diachronic perspective on compounds, we use a time - stamped corpus : the google books ngram corpus 2  #AUTHOR_TAG it contains books from the 1500s to the 2000s, from which we retrieve the contextual information of compounds and their constituents per year.', 'we operate on 5 - grams, which is the largest unit provided by google ngrams and use the words appearing in the 5 - grams as both target words and context.', 'we use the part - of - speech information already included in the google ngram corpus to extract noun - noun patterns.', 'we then regard all other tokens in the 5 - gram as context words and from this build up a semantic space rep - resentation of noun compounds for each year.', '']",5
"['was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['findings. 6 future work our current work was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['r 2 value occurs when observing time in stretches of 20 years ( scores ) and compounds having a frequency cut - off of', 'at least 100. a few other observations could be made : in general the cut - off seems', 'to improve the r 2 metric and the time spans of 10 and 20 years appear to be the most informative and', 'stable for the cut - off values. also, using temporal information almost always outperforms the setup that ignores all temporal', 'information. for our following experiment, we choose to use the configuration', 'with the highest r 2 value : a time span of 20 years and a cut - off', 'of 100. since lmi achieved the highest ρ values, we also choose lmi over the other features. we group the compounds of reddy into three groups based on the human ratings they obtained', ': low ( 0 - 1 ), med ( 2 - 3 ) and high ( 4 - 5 ). each group contains around 30 compounds. we then plot the lmi values of these three groups with their confidence interval across the time step of 20 years, shown in figure 1. we can observe that there is a separation between the groups towards the later years, and that the', 'period between 1940s and 1960s caused a noticeable change in the compositionality of the reddy compounds. we find the same trends for all three information theory based features. although care should', 'be taken given the small data sets ( especially for the earlier decades ) on which the models were build and tested, the slope of the lines for the three groups of compounds seems to suggest that less compositional compounds go through a more', 'pronounced change in compositionality than compositional compounds, as expected. we also show the graphs', 'for sim - with - head and sim - with - mod ( figures 2 and 3 ) for the different groups of compounds across time, as these underperformed', 'in our previous experiment. both figures based on cosine based features largely confound the three groups of compounds', 'across time, reinforcing our previous findings. 6 future work our current work was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', '']",5
"['was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['findings. 6 future work our current work was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['r 2 value occurs when observing time in stretches of 20 years ( scores ) and compounds having a frequency cut - off of', 'at least 100. a few other observations could be made : in general the cut - off seems', 'to improve the r 2 metric and the time spans of 10 and 20 years appear to be the most informative and', 'stable for the cut - off values. also, using temporal information almost always outperforms the setup that ignores all temporal', 'information. for our following experiment, we choose to use the configuration', 'with the highest r 2 value : a time span of 20 years and a cut - off', 'of 100. since lmi achieved the highest ρ values, we also choose lmi over the other features. we group the compounds of reddy into three groups based on the human ratings they obtained', ': low ( 0 - 1 ), med ( 2 - 3 ) and high ( 4 - 5 ). each group contains around 30 compounds. we then plot the lmi values of these three groups with their confidence interval across the time step of 20 years, shown in figure 1. we can observe that there is a separation between the groups towards the later years, and that the', 'period between 1940s and 1960s caused a noticeable change in the compositionality of the reddy compounds. we find the same trends for all three information theory based features. although care should', 'be taken given the small data sets ( especially for the earlier decades ) on which the models were build and tested, the slope of the lines for the three groups of compounds seems to suggest that less compositional compounds go through a more', 'pronounced change in compositionality than compositional compounds, as expected. we also show the graphs', 'for sim - with - head and sim - with - mod ( figures 2 and 3 ) for the different groups of compounds across time, as these underperformed', 'in our previous experiment. both figures based on cosine based features largely confound the three groups of compounds', 'across time, reinforcing our previous findings. 6 future work our current work was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', '']",4
"['was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['findings. 6 future work our current work was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', 'such as german.']","['r 2 value occurs when observing time in stretches of 20 years ( scores ) and compounds having a frequency cut - off of', 'at least 100. a few other observations could be made : in general the cut - off seems', 'to improve the r 2 metric and the time spans of 10 and 20 years appear to be the most informative and', 'stable for the cut - off values. also, using temporal information almost always outperforms the setup that ignores all temporal', 'information. for our following experiment, we choose to use the configuration', 'with the highest r 2 value : a time span of 20 years and a cut - off', 'of 100. since lmi achieved the highest ρ values, we also choose lmi over the other features. we group the compounds of reddy into three groups based on the human ratings they obtained', ': low ( 0 - 1 ), med ( 2 - 3 ) and high ( 4 - 5 ). each group contains around 30 compounds. we then plot the lmi values of these three groups with their confidence interval across the time step of 20 years, shown in figure 1. we can observe that there is a separation between the groups towards the later years, and that the', 'period between 1940s and 1960s caused a noticeable change in the compositionality of the reddy compounds. we find the same trends for all three information theory based features. although care should', 'be taken given the small data sets ( especially for the earlier decades ) on which the models were build and tested, the slope of the lines for the three groups of compounds seems to suggest that less compositional compounds go through a more', 'pronounced change in compositionality than compositional compounds, as expected. we also show the graphs', 'for sim - with - head and sim - with - mod ( figures 2 and 3 ) for the different groups of compounds across time, as these underperformed', 'in our previous experiment. both figures based on cosine based features largely confound the three groups of compounds', 'across time, reinforcing our previous findings. 6 future work our current work was limited to english compounds from  #TAUTHOR_TAG. we plan to expand our models to other languages for which compositionality ratings are available,', '']",4
"['1, 3 ] - grams  #TAUTHOR_TAG.', 'lexicon features']","['use tf. idf - weighted word [ 1, 3 ] - grams  #TAUTHOR_TAG.', 'lexicon features.', 'we try to capture the typical vocabulary of propaganda by considering representations reflecting the']","['1, 3 ] - grams  #TAUTHOR_TAG.', 'lexicon features.', 'we try to capture the typical vocabulary of propaganda by considering representations reflecting the frequency of specific words from a number of lexicons coming']","['train a maximum entropy classifier with l2 regularization to discriminate propagandistic vs non - propagandistic news articles.', 'we use the confidence of the classifier, a value in the range [ 0, 1 ], to group articles into bins.', 'we call this value the propaganda index, since it reflects the probability for an article to have a propagandistic intent.', 'we use four families of features : word n - gram features we use tf. idf - weighted word [ 1, 3 ] - grams  #TAUTHOR_TAG.', 'lexicon features.', ""we try to capture the typical vocabulary of propaganda by considering representations reflecting the frequency of specific words from a number of lexicons coming from the wiktionary, linguistic inquiry and word count ( liwc ), wilson's subjectives, hyland hedges, and hooper's assertives."", ' #AUTHOR_TAG showed that the words in some of these lexicons appear more frequently in propagandistic than in trustworthy articles.', 'style, vocabulary richness, and readability.', 'our writing style representation consists of tf. idf - weighted character 3 - grams.', 'this representation captures different style markers, such as prefixes, suffixes, and punctuation marks.', '']",5
"['1, 3 ] - grams  #TAUTHOR_TAG.', 'lexicon features']","['use tf. idf - weighted word [ 1, 3 ] - grams  #TAUTHOR_TAG.', 'lexicon features.', 'we try to capture the typical vocabulary of propaganda by considering representations reflecting the']","['1, 3 ] - grams  #TAUTHOR_TAG.', 'lexicon features.', 'we try to capture the typical vocabulary of propaganda by considering representations reflecting the frequency of specific words from a number of lexicons coming']","['train a maximum entropy classifier with l2 regularization to discriminate propagandistic vs non - propagandistic news articles.', 'we use the confidence of the classifier, a value in the range [ 0, 1 ], to group articles into bins.', 'we call this value the propaganda index, since it reflects the probability for an article to have a propagandistic intent.', 'we use four families of features : word n - gram features we use tf. idf - weighted word [ 1, 3 ] - grams  #TAUTHOR_TAG.', 'lexicon features.', ""we try to capture the typical vocabulary of propaganda by considering representations reflecting the frequency of specific words from a number of lexicons coming from the wiktionary, linguistic inquiry and word count ( liwc ), wilson's subjectives, hyland hedges, and hooper's assertives."", ' #AUTHOR_TAG showed that the words in some of these lexicons appear more frequently in propagandistic than in trustworthy articles.', 'style, vocabulary richness, and readability.', 'our writing style representation consists of tf. idf - weighted character 3 - grams.', 'this representation captures different style markers, such as prefixes, suffixes, and punctuation marks.', '']",5
"['incorporation of word embeddings to represent the context of words and concepts  #TAUTHOR_TAG.', 'moreover,']","['incorporation of word embeddings to represent the context of words and concepts  #TAUTHOR_TAG.', 'moreover,']","['the incorporation of word embeddings to represent the context of words and concepts  #TAUTHOR_TAG.', 'moreover, it is']","['holds great potential for analyses in the social sciences both due to its explosive popularity, increasing accessibility to large amounts of data and its dynamic nature.', 'for sentiment analysis on twitter the best performing approaches  #AUTHOR_TAG have used a set of rich lexical features.', 'however, the development of lexica can be time consuming and is not always suitable when shifting between domains, which examine new topics and user populations  #AUTHOR_TAG.', 'excitingly, the state of the art has recently shifted toward novel semi - supervised techniques such as the incorporation of word embeddings to represent the context of words and concepts  #TAUTHOR_TAG.', 'moreover, it is important to be able to identify sentiment in relation to particular entities, topics or events ( aspect - based sentiment ).', 'we have followed a hybrid approach which incorporates traditional lexica, unigrams and bigrams as well as word embeddings using word2vec  #AUTHOR_TAG to train classifiers for subtasks a and b. for subtask c, sentiment targeted towards a particular topic, we have developed a set of different strategies which use either syntactic dependencies or token - level associations with the topic word in combination with our a classifier to produce sentiment annotations']",0
[' #AUTHOR_TAG a ;  #TAUTHOR_TAG sentiment - specific word embeddings have been used as features'],[' #AUTHOR_TAG a ;  #TAUTHOR_TAG sentiment - specific word embeddings have been used as features'],[' #AUTHOR_TAG a ;  #TAUTHOR_TAG sentiment - specific word embeddings have been used as features'],"['- based sentiment analysis ( subtask a ) in tweets is a long standing task where the goal is to classify the sentiment of a designated expression within the tweet as either positive, negative or neutral.', 'the state of the art for subtask a achieves high performance usually based on methodologies employing features obtained from either manually or automatically generated lexica  #AUTHOR_TAG.', 'however, lexica by definition lack contextual information and are oftain domain dependent.', 'recent work  #AUTHOR_TAG a ) has successfully used sentiment - specific word embeddings, vector representations of the n - gram context of positive, negative and neutral sentiment in tweets to obtain performance which approaches that of lexicon - based approaches.', 'here we employ a combination of lexical features and word embeddings to maximise our performance in task a. we build phrase - based classifiers both with an emphasis on the distinction between positive and negative sentiment, which conforms to the distribution of training data in task a, as well as phrasebased classifiers trained on a balanced set of positive, negative and neutral tweets.', 'we use the latter to identify sentiment in the vicinity of topic words in task c, for targeted sentiment assignment.', 'in previous work  #AUTHOR_TAG a ;  #TAUTHOR_TAG sentiment - specific word embeddings have been used as features for identification of tweet - level sentiment but not phrase - level sentiment.', 'other work which considered word embeddings for phrase level sentiment ( dos  #AUTHOR_TAG did not focus on producing sentiment - specific representations and the embeddings learnt were a combination of character and word embeddings, where the relative contribution of the word embeddings is not clear.', 'in this work we present two different strategies for learning phrase level sentiment specific word embeddings']",0
[' #AUTHOR_TAG a ;  #TAUTHOR_TAG sentiment - specific word embeddings have been used as features'],[' #AUTHOR_TAG a ;  #TAUTHOR_TAG sentiment - specific word embeddings have been used as features'],[' #AUTHOR_TAG a ;  #TAUTHOR_TAG sentiment - specific word embeddings have been used as features'],"['- based sentiment analysis ( subtask a ) in tweets is a long standing task where the goal is to classify the sentiment of a designated expression within the tweet as either positive, negative or neutral.', 'the state of the art for subtask a achieves high performance usually based on methodologies employing features obtained from either manually or automatically generated lexica  #AUTHOR_TAG.', 'however, lexica by definition lack contextual information and are oftain domain dependent.', 'recent work  #AUTHOR_TAG a ) has successfully used sentiment - specific word embeddings, vector representations of the n - gram context of positive, negative and neutral sentiment in tweets to obtain performance which approaches that of lexicon - based approaches.', 'here we employ a combination of lexical features and word embeddings to maximise our performance in task a. we build phrase - based classifiers both with an emphasis on the distinction between positive and negative sentiment, which conforms to the distribution of training data in task a, as well as phrasebased classifiers trained on a balanced set of positive, negative and neutral tweets.', 'we use the latter to identify sentiment in the vicinity of topic words in task c, for targeted sentiment assignment.', 'in previous work  #AUTHOR_TAG a ;  #TAUTHOR_TAG sentiment - specific word embeddings have been used as features for identification of tweet - level sentiment but not phrase - level sentiment.', 'other work which considered word embeddings for phrase level sentiment ( dos  #AUTHOR_TAG did not focus on producing sentiment - specific representations and the embeddings learnt were a combination of character and word embeddings, where the relative contribution of the word embeddings is not clear.', 'in this work we present two different strategies for learning phrase level sentiment specific word embeddings']",1
"['', 'by  #TAUTHOR_TAG ( average, maximum and minimum ), resulting in 2, 400 features. extra features : we used several features, potentially', 'indicative of sentiment, a subset of those in  #AUTHOR_TAG. these include : the total number of words of the target phrase, its position within the tweet ( "" start']","['strategy, class and dimension, we used the functions suggested', 'by  #TAUTHOR_TAG ( average, maximum and minimum ), resulting in 2, 400 features. extra features : we used several features, potentially', 'indicative of sentiment, a subset of those in  #AUTHOR_TAG. these include : the total number of words of the target phrase, its position within the tweet ( "" start "",']","['used the functions suggested', 'by  #TAUTHOR_TAG ( average, maximum and minimum ), resulting in 2, 400 features. extra features : we used several features, potentially', 'indicative of sentiment, a subset of those in  #AUTHOR_TAG. these include : the total number of words of the target phrase, its position within the tweet ( "" start "",']","[""6, 800 polarised terms ), nrc's emotion lexicon  #AUTHOR_TAG ( about"", '14, 000 words annotated based on 10 emotional dimensions ), the sentiment140 lexicon ( 62, 468 unigrams, 677, 968 bigrams and 480, 010 non - contiguous pairs ) and', ""nrc's hashtag sentiment lexicon  #AUTHOR_TAG ( 54, 129 unigrams"", ', 316, 531 bigrams and 308, 808 non - contiguous pairs ). we extracted the number of', 'words in the text that appear in every dimension of the bing liu and nrc emotion lexica. for every lexicon, we extracted features indicating the number of positive unigrams, bigrams and pairs, their maximum sentimental value as', 'indicated by each lexicon, the sum of their sentiment values and the value of the last non - zero ( non - neutral ) token. all features were extracted both from the tweet as well as the target. word embeddings : we used the tweets collected by  #AUTHOR_TAG as training data for sentiment - specific word embeddings. these tweets contain emoticons and hashtags for six different emotions, which we group together to compile positive and negative subsets. to create phrase - level word embeddings, we applied two strategies : ( i ) we searched for positive and negative words ( as', ""defined in bing liu's lexicon ) in the corpus ; ( ii ) we performed chi - squared feature selection and extracted the"", '5, 000 most important tokens to be used as our index ; for both strategies, we extracted the phrase included in the 2 - token - length, two - sided window. the embeddings were learnt by using gensim ( rehurek and  #AUTHOR_TAG, a python', 'package that integrates word2vec 1. in both cases, we created representations', 'of length equal to 100 2. for each strategy, class and dimension, we used the functions suggested', 'by  #TAUTHOR_TAG ( average, maximum and minimum ), resulting in 2, 400 features. extra features : we used several features, potentially', 'indicative of sentiment, a subset of those in  #AUTHOR_TAG. these include : the total number of words of the target phrase, its position within the tweet ( "" start "", "" end "", or "" other "" ), the average word length of the target / context and the presence of elongated words, urls and user mentions. we manually labelled various emoticons as positive ( strong / weak ), negative ( strong /', 'weak ) and "" other "" and counted how many times each label appeared in the target and its context']",5
"['employed the word embeddings encoding sentiment information generated through the unified models in  #TAUTHOR_TAG.', 'similar to tang, we']","['employed the word embeddings encoding sentiment information generated through the unified models in  #TAUTHOR_TAG.', 'similar to tang, we']","['employed the word embeddings encoding sentiment information generated through the unified models in  #TAUTHOR_TAG.', 'similar to tang, we represent each tweet by the min, average, max and sum on']","[""learned positive and negative word embeddings separately by training on the happy and non - happy tweets from purver & battersby's multi - class twitter emoticon and hashtag corpus  #AUTHOR_TAG, as with subtask a. the difference with subtask a is that here we used the whole tweet as our input ( compared to the two - sided window around a polarised word in subtask a ) in order to create tweet - level representations."", 'we set the word embeddings dimension to 100 in order to gain enough semantic information whilst reducing training time.', 'we also employed the word embeddings encoding sentiment information generated through the unified models in  #TAUTHOR_TAG.', 'similar to tang, we represent each tweet by the min, average, max and sum on each dimension of the word embeddings of all the words in the tweet.', 'in the end, the number of our word embeddings features is 4 [UNK] 100 = 400.', ""a tweet's representations of word embeddings generated from the happy and non - happy subset of tweets and the embeddings generated by tang et al. were incorporated into the feature set."", 'their word embeddings have 50 dimensions, so another 4 [UNK] 50 = 200 features are added to our feature set']",5
"[""by  #TAUTHOR_TAG, we didn't integrate the sentiment information in the word embeddings training process, but rather the sentiment - specific nature of the embeddings was reflected in""]","[""by  #TAUTHOR_TAG, we didn't integrate the sentiment information in the word embeddings training process, but rather the sentiment - specific nature of the embeddings was reflected in""]","[""by  #TAUTHOR_TAG, we didn't integrate the sentiment information in the word embeddings training process, but rather the sentiment - specific nature of the embeddings was reflected in the choice of different training datasets, yielding different word embedding features for positive and negative tweets."", 'to measure the contributions of our word embeddings and tang']","['', ""contrary to the approach by  #TAUTHOR_TAG, we didn't integrate the sentiment information in the word embeddings training process, but rather the sentiment - specific nature of the embeddings was reflected in the choice of different training datasets, yielding different word embedding features for positive and negative tweets."", ""to measure the contributions of our word embeddings and tang's sentiment - specific word embeddings separately in the f1 score, we performed a further test."", ""when we only removed tang's word embeddings features, the f1 score dropped by 0. 15 % ; when we only removed our word embedding features, the f1 score dropped by 1. 21 %."", 'this illustrates that for our approach, our word embedding features contribute more.', ""however, it is the combination of the two types of word embeddings that boosts our classifier's performance."", 'in subtask c the goal is to identify the sentiment targeted towards a particular topic or entity.', 'this is closely linked to aspect - based sentiment  #AUTHOR_TAG and is very important for understanding the reasons behind the manifestation of different reactions']",4
['in automatic frame semantic role labeling for english  #TAUTHOR_TAG and for other languages'],"['in automatic frame semantic role labeling for english  #TAUTHOR_TAG and for other languages.', 'this']","[', including the interplay between semantic frames and constructions in different languages.', 'we will also report on the state of the art in automatic frame semantic role labeling for english  #TAUTHOR_TAG and for other languages.', 'this']","['', 'will translations to be "" frame preserving ""? this tutorial will discuss the methodology and status of the alignment effort, and of a recently launched parallel manual annotation task, and theoretical issues that have emerged in this area of research, including the interplay between semantic frames and constructions in different languages.', 'we will also report on the state of the art in automatic frame semantic role labeling for english  #TAUTHOR_TAG and for other languages.', 'this can be regarded as a structured prediction task which maps a sentence to a graph with nodes for each predicator and']",7
['in automatic frame semantic role labeling for english  #TAUTHOR_TAG and for other languages'],"['in automatic frame semantic role labeling for english  #TAUTHOR_TAG and for other languages.', 'this']","[', including the interplay between semantic frames and constructions in different languages.', 'we will also report on the state of the art in automatic frame semantic role labeling for english  #TAUTHOR_TAG and for other languages.', 'this']","['', 'will translations to be "" frame preserving ""? this tutorial will discuss the methodology and status of the alignment effort, and of a recently launched parallel manual annotation task, and theoretical issues that have emerged in this area of research, including the interplay between semantic frames and constructions in different languages.', 'we will also report on the state of the art in automatic frame semantic role labeling for english  #TAUTHOR_TAG and for other languages.', 'this can be regarded as a structured prediction task which maps a sentence to a graph with nodes for each predicator and its arguments and adjuncts, linked by arcs representing the frame semantic roles.', 'recent approaches rely on neural architectures to learn representations which enforce global consistency for each classification decision and can learn from disparate data.', 'participants in this tutorial will learn about :', '1. multilingual framenet, its methodology and practices 2.', 'cross - linguistic similarities and differences among the languages  #AUTHOR_TAG ), aligning framenet to other lexical resources (  #AUTHOR_TAG, ( 2008 ), ferrandez et al. ( 2010 ) ) and linking to ontologies and reasoning  #AUTHOR_TAG']",7
"['syntax and semantics  #TAUTHOR_TAG.', 'she has']","['syntax and semantics  #TAUTHOR_TAG.', 'she has']","['syntax and semantics  #TAUTHOR_TAG.', 'she has']","['##abha swayamdipta ( swabha @ cs. cmu. edu, http : / / www. cs. cmu. edu / [UNK] ) is a phd student at the language technologies institute at carnegie mellon university ( currently a visiting student at u washington ).', 'she works with noah smith and chris dyer on developing efficient algorithms for broad - coverage semantic parsing, with a focus on exploiting the relationship between syntax and semantics  #TAUTHOR_TAG.', '']",7
"['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the']","['', 'shown its merits in word segmentation task, some researchers still hold the belief that on iv words ds can perform better than ct even in the restriction of bakeoff closed test. consequently, many strategies are proposed to balance the iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the results of ct and ds is a straight - forward', 'one, which is introduced in  #TAUTHOR_TAG. the basic assumption of such combination is that ds method performs better on iv words', 'and  #TAUTHOR_TAG this belief from the fact that ds achieves higher', 'iv recall rate as table 1 shows. in which as, cityu, msra and pku are four corpora used in bakeoff 2005 ( also see table 2 for detail ). we provide a more detailed evaluation metric', '']",0
"['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the']","['', 'shown its merits in word segmentation task, some researchers still hold the belief that on iv words ds can perform better than ct even in the restriction of bakeoff closed test. consequently, many strategies are proposed to balance the iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the results of ct and ds is a straight - forward', 'one, which is introduced in  #TAUTHOR_TAG. the basic assumption of such combination is that ds method performs better on iv words', 'and  #TAUTHOR_TAG this belief from the fact that ds achieves higher', 'iv recall rate as table 1 shows. in which as, cityu, msra and pku are four corpora used in bakeoff 2005 ( also see table 2 for detail ). we provide a more detailed evaluation metric', '']",0
"['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the']","['', 'shown its merits in word segmentation task, some researchers still hold the belief that on iv words ds can perform better than ct even in the restriction of bakeoff closed test. consequently, many strategies are proposed to balance the iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the results of ct and ds is a straight - forward', 'one, which is introduced in  #TAUTHOR_TAG. the basic assumption of such combination is that ds method performs better on iv words', 'and  #TAUTHOR_TAG this belief from the fact that ds achieves higher', 'iv recall rate as table 1 shows. in which as, cityu, msra and pku are four corpora used in bakeoff 2005 ( also see table 2 for detail ). we provide a more detailed evaluation metric', '']",0
"['', 'in  #TAUTHOR_TAG, the above ct method is developed as sub']","['', 'in  #TAUTHOR_TAG, the above ct method is developed as subword - based tagging.', 'first, the most frequent multi - character words']","['', 'in  #TAUTHOR_TAG, the above ct method is developed as sub']","['ct scheme, each character in one sentence is labeled as "" b "" if it is the beginning of a word, "" o "" tag means the current character is a single - character word, other character is labeled as "" i "".', 'for example, "" [UNK] [UNK] [UNK] ( whole china ) "" is labeled as ""', 'in  #TAUTHOR_TAG, the above ct method is developed as subword - based tagging.', 'first, the most frequent multi - character words and all single characters in training corpus are collected as subwords.', 'during the subwordbased tagging, a subword is viewed as an unit instead of several separate characters and given only one tag.', 'for example, in subword - based tagging, "" [UNK] [UNK] [UNK] ( whole china ) "" is labeled as "" [UNK] ( whole ) / o [UNK] [UNK] ( china ) / o "", if the word "" [UNK] [UNK] ( china ) "" is collected as a subword.', 'as the preprocessing, both training and test corpora are segmented by maximum match with subword set as dictionary.', 'after this preprocessing, every sentence in both training and test corpora becomes subword sequence.', 'finally, the tagger is trained by crfs approach 3 on the training data.', 'although word information is integrated into this method, it still works in the scheme of "" iob "" tagging.', 'thus, we still call subwordbased tagging as a special ct method and in the reminder of this paper "" ct "" means subwordbased tagging in  #TAUTHOR_TAG and "" pure ct "" means ct without subword']",0
"['be calculated according to the following formula in  #TAUTHOR_TAG :', 'here,']","['be calculated according to the following formula in  #TAUTHOR_TAG :', 'here,']","['measure ( cm ) means to seek an optimal tradeoff between performance on iv and oov words.', 'the basic idea of cm comes from the belief that ct performs better on oov words while ds performs better on iv words.', 'when both results of ct and ds are available, the cm can be calculated according to the following formula in  #TAUTHOR_TAG :', 'here, w is a subword, iob t is']","['measure ( cm ) means to seek an optimal tradeoff between performance on iv and oov words.', 'the basic idea of cm comes from the belief that ct performs better on oov words while ds performs better on iv words.', 'when both results of ct and ds are available, the cm can be calculated according to the following formula in  #TAUTHOR_TAG :', 'here, w is a subword, iob t is "" iob "" tag given by ct and w t is "" iob "" tag generated by ds.', 'in the first term of the right hand side of the formula,', 'is the marginal probability of iob t ( we call this marginal probability "" mp "" for short will be kept, otherwise it will be replaced with w t.', 'thus, the cm ultimately is the marginal probability of the "" iob "" tag ( mp ).', 'in the experiment of this paper, mp is used as cm because it is equivalent to  #TAUTHOR_TAG but more convenient to express']",0
"['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to make cm yield a better result.', 'in this paper, = 0. 8 and t = 0. 7 ( parameters in two papers,  #TAUTHOR_TAG and zhang et al. 2006b, are different. and our parameters are consistent with zhang et al. 2006b which is confirmed by dr zhang through email ) are used in cm, namely mp = 0. 875 is the threshold.', 'here, in table 4, we provide some statistics on the results of ct when mp is less than 0. 875.', '']",0
"['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the']","['', 'shown its merits in word segmentation task, some researchers still hold the belief that on iv words ds can perform better than ct even in the restriction of bakeoff closed test. consequently, many strategies are proposed to balance the iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the results of ct and ds is a straight - forward', 'one, which is introduced in  #TAUTHOR_TAG. the basic assumption of such combination is that ds method performs better on iv words', 'and  #TAUTHOR_TAG this belief from the fact that ds achieves higher', 'iv recall rate as table 1 shows. in which as, cityu, msra and pku are four corpora used in bakeoff 2005 ( also see table 2 for detail ). we provide a more detailed evaluation metric', '']",1
"['described in  #TAUTHOR_TAG,', '']","['described in  #TAUTHOR_TAG,', 'namely dictionary -']","['described in  #TAUTHOR_TAG,', '']","['thing have to be emphasized is that the single character in test corpus will be defined as oov if it does not appear in training', 'corpus. we will see later in this section, by this evaluation, some facts covered by the bakeoff evaluation can be illustrated by our new evaluation metric. here, we repeat two experiments described in  #TAUTHOR_TAG,', 'namely dictionary - based approach and subword - based tagging. for ct method, top 2000 most frequent multi - character words and all single characters in training corpus are selected as subwords and the feature templates', 'used for crf model is listed in table 3. we present all the segmentation results in table 6 to see the strength and weakness of each method conveniently. based on', 'iv and oov recall as we show in table 1,  #TAUTHOR_TAG that the ds performs better on iv word identification while ct performs better on oov words. but we can see from the results in table 6 ( the', '']",1
"['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to make cm yield a better result.', 'in this paper, = 0. 8 and t = 0. 7 ( parameters in two papers,  #TAUTHOR_TAG and zhang et al. 2006b, are different. and our parameters are consistent with zhang et al. 2006b which is confirmed by dr zhang through email ) are used in cm, namely mp = 0. 875 is the threshold.', 'here, in table 4, we provide some statistics on the results of ct when mp is less than 0. 875.', '']",1
['confidence measure in  #TAUTHOR_TAG has a representation flaw and'],['confidence measure in  #TAUTHOR_TAG has a representation flaw and'],['confidence measure in  #TAUTHOR_TAG has a representation flaw and'],"['this paper, we first provided a detailed evaluation metric, which provides the necessary information to judge the performance of each method on iv and oov word identification.', 'second, by this evaluation metric, we show that characterbased tagging outperforms dictionary - based segmentation not only on oov words but also on iv words within bakeoff closed tests.', 'furthermore, our experiments show that confidence measure in  #TAUTHOR_TAG has a representation flaw and we propose an eiv tag method to revise the combination.', '']",1
"['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used']","['iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the']","['', 'shown its merits in word segmentation task, some researchers still hold the belief that on iv words ds can perform better than ct even in the restriction of bakeoff closed test. consequently, many strategies are proposed to balance the iv and oov performance  #AUTHOR_TAG,  #TAUTHOR_TAG. among these strategies, the confidence measure used to combine the results of ct and ds is a straight - forward', 'one, which is introduced in  #TAUTHOR_TAG. the basic assumption of such combination is that ds method performs better on iv words', 'and  #TAUTHOR_TAG this belief from the fact that ds achieves higher', 'iv recall rate as table 1 shows. in which as, cityu, msra and pku are four corpora used in bakeoff 2005 ( also see table 2 for detail ). we provide a more detailed evaluation metric', '']",7
"['', 'in  #TAUTHOR_TAG, the above ct method is developed as sub']","['', 'in  #TAUTHOR_TAG, the above ct method is developed as subword - based tagging.', 'first, the most frequent multi - character words']","['', 'in  #TAUTHOR_TAG, the above ct method is developed as sub']","['ct scheme, each character in one sentence is labeled as "" b "" if it is the beginning of a word, "" o "" tag means the current character is a single - character word, other character is labeled as "" i "".', 'for example, "" [UNK] [UNK] [UNK] ( whole china ) "" is labeled as ""', 'in  #TAUTHOR_TAG, the above ct method is developed as subword - based tagging.', 'first, the most frequent multi - character words and all single characters in training corpus are collected as subwords.', 'during the subwordbased tagging, a subword is viewed as an unit instead of several separate characters and given only one tag.', 'for example, in subword - based tagging, "" [UNK] [UNK] [UNK] ( whole china ) "" is labeled as "" [UNK] ( whole ) / o [UNK] [UNK] ( china ) / o "", if the word "" [UNK] [UNK] ( china ) "" is collected as a subword.', 'as the preprocessing, both training and test corpora are segmented by maximum match with subword set as dictionary.', 'after this preprocessing, every sentence in both training and test corpora becomes subword sequence.', 'finally, the tagger is trained by crfs approach 3 on the training data.', 'although word information is integrated into this method, it still works in the scheme of "" iob "" tagging.', 'thus, we still call subwordbased tagging as a special ct method and in the reminder of this paper "" ct "" means subwordbased tagging in  #TAUTHOR_TAG and "" pure ct "" means ct without subword']",7
"['described in  #TAUTHOR_TAG,', '']","['described in  #TAUTHOR_TAG,', 'namely dictionary -']","['described in  #TAUTHOR_TAG,', '']","['thing have to be emphasized is that the single character in test corpus will be defined as oov if it does not appear in training', 'corpus. we will see later in this section, by this evaluation, some facts covered by the bakeoff evaluation can be illustrated by our new evaluation metric. here, we repeat two experiments described in  #TAUTHOR_TAG,', 'namely dictionary - based approach and subword - based tagging. for ct method, top 2000 most frequent multi - character words and all single characters in training corpus are selected as subwords and the feature templates', 'used for crf model is listed in table 3. we present all the segmentation results in table 6 to see the strength and weakness of each method conveniently. based on', 'iv and oov recall as we show in table 1,  #TAUTHOR_TAG that the ds performs better on iv word identification while ct performs better on oov words. but we can see from the results in table 6 ( the', '']",7
[') are comparable with that in  #TAUTHOR_TAG.'],[') are comparable with that in  #TAUTHOR_TAG.'],['are comparable with that in  #TAUTHOR_TAG.'],"['', 'on all four corpora the overall f measure of eiv result is higher than that of ct alone, which show that our eiv method works well. now, let ""', 's check what changes happened in the number of error tags after eiv condition added into the cm. we can see from', 'the table 5 columns about eiv, there are more errors eliminated than the new errors introduced after eiv condition added into cm and most ct tags of subwords contained in oov words maintained unchanged as we supposed. and then, our results ( in table 6 lines about eiv ) are comparable with that in  #TAUTHOR_TAG. thus, there may', 'be some similar strategies in  #TAUTHOR_TAG']",7
"['is exactly the method implemented in  #TAUTHOR_TAG, it does not mean the generative language model in general']","['is exactly the method implemented in  #TAUTHOR_TAG, it does not mean the generative language model in general']","['is exactly the method implemented in  #TAUTHOR_TAG, it does not mean the generative language model in general']","['', 'this method guarantees exhaustive generation of possible segmentations for any input sentence.', 'however, the exponential time and space of the length of the input sentence are needed for such a search and it is always intractable in practice.', 'thus, we use the trigram language model to select top b ( b is a constant predefined before search and in our experiment 3 is used ) best candidates with highest probability at each stage so that the search algorithm can work in practice.', 'finally, when the whole sentence has been read, the best candidate with the highest probability will be selected as the segmentation result.', 'here, the term "" dictionary - based "" is exactly the method implemented in  #TAUTHOR_TAG, it does not mean the generative language model in general']",5
"['described in  #TAUTHOR_TAG,', '']","['described in  #TAUTHOR_TAG,', 'namely dictionary -']","['described in  #TAUTHOR_TAG,', '']","['thing have to be emphasized is that the single character in test corpus will be defined as oov if it does not appear in training', 'corpus. we will see later in this section, by this evaluation, some facts covered by the bakeoff evaluation can be illustrated by our new evaluation metric. here, we repeat two experiments described in  #TAUTHOR_TAG,', 'namely dictionary - based approach and subword - based tagging. for ct method, top 2000 most frequent multi - character words and all single characters in training corpus are selected as subwords and the feature templates', 'used for crf model is listed in table 3. we present all the segmentation results in table 6 to see the strength and weakness of each method conveniently. based on', 'iv and oov recall as we show in table 1,  #TAUTHOR_TAG that the ds performs better on iv word identification while ct performs better on oov words. but we can see from the results in table 6 ( the', '']",5
"['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to make cm yield a better result.', 'in this paper, = 0. 8 and t = 0. 7 ( parameters in two papers,  #TAUTHOR_TAG and zhang et al. 2006b, are different. and our parameters are consistent with zhang et al. 2006b which is confirmed by dr zhang through email ) are used in cm, namely mp = 0. 875 is the threshold.', 'here, in table 4, we provide some statistics on the results of ct when mp is less than 0. 875.', '']",5
[' #TAUTHOR_TAG and produces comparable'],[' #TAUTHOR_TAG and produces comparable'],[' #TAUTHOR_TAG and produces comparable results with combination with'],"['', 'on three of the four corpora ( as, msra and pku ) this pure ct method gets the best result.', 'even on iv word, this pure ct approach outperforms  #TAUTHOR_TAG and produces comparable results with combination with eiv tags, which shows that pure ct method can perform well on iv words too.', 'moreover, this character - based tagging approach is more clear and simple than the confidence measure method.', 'although character - based tagging became mainstream approach in the last two bakeoffs, it does not mean that word information is valueless in chinese word segmentation.', 'a word - based perceptron algorithm is proposed recently  #AUTHOR_TAG, which views chinese word segmentation task from a new angle instead of character - based tagging and gets comparable results with the best results of bakeoff.', 'table 6 results of different approach used in our experiments ( white background lines are the results we repeat  #TAUTHOR_TAG and they have some trivial difference with table 1. ) therefore, the most important thing worth to pay attention in future study is how to integrate linguistic information into the statistical model effectively, no matter character or word information']",5
"['described in  #TAUTHOR_TAG,', '']","['described in  #TAUTHOR_TAG,', 'namely dictionary -']","['described in  #TAUTHOR_TAG,', '']","['thing have to be emphasized is that the single character in test corpus will be defined as oov if it does not appear in training', 'corpus. we will see later in this section, by this evaluation, some facts covered by the bakeoff evaluation can be illustrated by our new evaluation metric. here, we repeat two experiments described in  #TAUTHOR_TAG,', 'namely dictionary - based approach and subword - based tagging. for ct method, top 2000 most frequent multi - character words and all single characters in training corpus are selected as subwords and the feature templates', 'used for crf model is listed in table 3. we present all the segmentation results in table 6 to see the strength and weakness of each method conveniently. based on', 'iv and oov recall as we show in table 1,  #TAUTHOR_TAG that the ds performs better on iv word identification while ct performs better on oov words. but we can see from the results in table 6 ( the', '']",4
"['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to']","['repeat the experiments about cm in  #TAUTHOR_TAG and show that there is a representation flaw in the cm formula.', 'furthermore, we propose an eiv tag method to make cm yield a better result.', 'in this paper, = 0. 8 and t = 0. 7 ( parameters in two papers,  #TAUTHOR_TAG and zhang et al. 2006b, are different. and our parameters are consistent with zhang et al. 2006b which is confirmed by dr zhang through email ) are used in cm, namely mp = 0. 875 is the threshold.', 'here, in table 4, we provide some statistics on the results of ct when mp is less than 0. 875.', '']",4
[' #TAUTHOR_TAG and produces comparable'],[' #TAUTHOR_TAG and produces comparable'],[' #TAUTHOR_TAG and produces comparable results with combination with'],"['', 'on three of the four corpora ( as, msra and pku ) this pure ct method gets the best result.', 'even on iv word, this pure ct approach outperforms  #TAUTHOR_TAG and produces comparable results with combination with eiv tags, which shows that pure ct method can perform well on iv words too.', 'moreover, this character - based tagging approach is more clear and simple than the confidence measure method.', 'although character - based tagging became mainstream approach in the last two bakeoffs, it does not mean that word information is valueless in chinese word segmentation.', 'a word - based perceptron algorithm is proposed recently  #AUTHOR_TAG, which views chinese word segmentation task from a new angle instead of character - based tagging and gets comparable results with the best results of bakeoff.', 'table 6 results of different approach used in our experiments ( white background lines are the results we repeat  #TAUTHOR_TAG and they have some trivial difference with table 1. ) therefore, the most important thing worth to pay attention in future study is how to integrate linguistic information into the statistical model effectively, no matter character or word information']",4
[' #TAUTHOR_TAG and produces comparable'],[' #TAUTHOR_TAG and produces comparable'],[' #TAUTHOR_TAG and produces comparable results with combination with'],"['', 'on three of the four corpora ( as, msra and pku ) this pure ct method gets the best result.', 'even on iv word, this pure ct approach outperforms  #TAUTHOR_TAG and produces comparable results with combination with eiv tags, which shows that pure ct method can perform well on iv words too.', 'moreover, this character - based tagging approach is more clear and simple than the confidence measure method.', 'although character - based tagging became mainstream approach in the last two bakeoffs, it does not mean that word information is valueless in chinese word segmentation.', 'a word - based perceptron algorithm is proposed recently  #AUTHOR_TAG, which views chinese word segmentation task from a new angle instead of character - based tagging and gets comparable results with the best results of bakeoff.', 'table 6 results of different approach used in our experiments ( white background lines are the results we repeat  #TAUTHOR_TAG and they have some trivial difference with table 1. ) therefore, the most important thing worth to pay attention in future study is how to integrate linguistic information into the statistical model effectively, no matter character or word information']",4
"['be calculated according to the following formula in  #TAUTHOR_TAG :', 'here,']","['be calculated according to the following formula in  #TAUTHOR_TAG :', 'here,']","['measure ( cm ) means to seek an optimal tradeoff between performance on iv and oov words.', 'the basic idea of cm comes from the belief that ct performs better on oov words while ds performs better on iv words.', 'when both results of ct and ds are available, the cm can be calculated according to the following formula in  #TAUTHOR_TAG :', 'here, w is a subword, iob t is']","['measure ( cm ) means to seek an optimal tradeoff between performance on iv and oov words.', 'the basic idea of cm comes from the belief that ct performs better on oov words while ds performs better on iv words.', 'when both results of ct and ds are available, the cm can be calculated according to the following formula in  #TAUTHOR_TAG :', 'here, w is a subword, iob t is "" iob "" tag given by ct and w t is "" iob "" tag generated by ds.', 'in the first term of the right hand side of the formula,', 'is the marginal probability of iob t ( we call this marginal probability "" mp "" for short will be kept, otherwise it will be replaced with w t.', 'thus, the cm ultimately is the marginal probability of the "" iob "" tag ( mp ).', 'in the experiment of this paper, mp is used as cm because it is equivalent to  #TAUTHOR_TAG but more convenient to express']",3
[') are comparable with that in  #TAUTHOR_TAG.'],[') are comparable with that in  #TAUTHOR_TAG.'],['are comparable with that in  #TAUTHOR_TAG.'],"['', 'on all four corpora the overall f measure of eiv result is higher than that of ct alone, which show that our eiv method works well. now, let ""', 's check what changes happened in the number of error tags after eiv condition added into the cm. we can see from', 'the table 5 columns about eiv, there are more errors eliminated than the new errors introduced after eiv condition added into cm and most ct tags of subwords contained in oov words maintained unchanged as we supposed. and then, our results ( in table 6 lines about eiv ) are comparable with that in  #TAUTHOR_TAG. thus, there may', 'be some similar strategies in  #TAUTHOR_TAG']",3
"['one which deliberately exposes real - world individuals, organisations and events to ridicule.', 'previous works  #TAUTHOR_TAG rely on various linguistic and hand']","['one which deliberately exposes real - world individuals, organisations and events to ridicule.', 'previous works  #TAUTHOR_TAG rely on various linguistic and handcrafted semantic features']","['one which deliberately exposes real - world individuals, organisations and events to ridicule.', 'previous works  #TAUTHOR_TAG rely on various linguistic and hand']","[""today's day and age of social media, there are ample opportunities for fake news production, dissemination and consumption."", ' #AUTHOR_TAG break down fake news into three categories, hoax, propaganda and satire.', 'a hoax article typically tries to convince the reader about a cookedup story while propaganda ones usually mislead the reader into believing a false political or social agenda.', ' #AUTHOR_TAG defines a satirical article as the one which deliberately exposes real - world individuals, organisations and events to ridicule.', 'previous works  #TAUTHOR_TAG rely on various linguistic and handcrafted semantic features for differentiating between news articles.', 'however, none of them try to model the interaction of sentences within the document.', 'we observed a pattern in the way sentences cluster in different kind of news articles.', 'specifically, satirical articles had a more coherent story and thus all the sentences in the document seemed similar to each other.', 'on the other hand, the trusted news articles were also coherent but the similarity between sentences from different parts of the document was not that strong, as depicted in figure 1.', 'we believe that the reason for such kind of behaviour is the presence of factual jumps across sections in a trusted document.', 'in this work, we propose a graph neural network - based model to classify news articles while capturing the interaction of sentences across the document.', 'we present a series of experiments on news corpus with varying reliability dataset  #AUTHOR_TAG and satirical legitimate news dataset  #TAUTHOR_TAG.', 'our results demonstrate that the proposed model achieves state - of - the - art performance on these datasets and provides interesting insights.', 'experiments performed in out - of - domain settings establish the generalizability of our proposed method']",0
"[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the']","[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the']","[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the task']","['##re, according to  #AUTHOR_TAG, is complicated because it occupies more than one place in the framework for humor, proposed by  #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the task of identifying satirical news articles from the trusted ones are often constructed by collecting documents from different online sources  #TAUTHOR_TAG.', 'mc  #AUTHOR_TAG hypothesized that this encourages the models to learn characteristics for different publication sources rather than characteristics of satire.', 'in this work, we show that our proposed model generalizes to articles from unseen publication sources.', "" #TAUTHOR_TAG's work by offering a quantitative study of linguistic differences found in articles of different types of fake news such as hoax, propaganda and satire."", 'they also proposed predictive models for graded deception across multiple domains.', "" #AUTHOR_TAG found that neural methods didn't perform well for this task and proposed to use a max - entropy classifier."", 'we show that our proposed neural network based on graph convolutional layers can outperform this model.', 'recent works by  #AUTHOR_TAG ;  #AUTHOR_TAG show that sophisticated neural models can be used for satirical news detection.', 'to the best of our knowledge, none of the previous works represent individual documents as graphs where the nodes represent the sentences for performing clas - sification using a graph neural network']",0
"[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the']","[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the']","[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the task']","['##re, according to  #AUTHOR_TAG, is complicated because it occupies more than one place in the framework for humor, proposed by  #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the task of identifying satirical news articles from the trusted ones are often constructed by collecting documents from different online sources  #TAUTHOR_TAG.', 'mc  #AUTHOR_TAG hypothesized that this encourages the models to learn characteristics for different publication sources rather than characteristics of satire.', 'in this work, we show that our proposed model generalizes to articles from unseen publication sources.', "" #TAUTHOR_TAG's work by offering a quantitative study of linguistic differences found in articles of different types of fake news such as hoax, propaganda and satire."", 'they also proposed predictive models for graded deception across multiple domains.', "" #AUTHOR_TAG found that neural methods didn't perform well for this task and proposed to use a max - entropy classifier."", 'we show that our proposed neural network based on graph convolutional layers can outperform this model.', 'recent works by  #AUTHOR_TAG ;  #AUTHOR_TAG show that sophisticated neural models can be used for satirical news detection.', 'to the best of our knowledge, none of the previous works represent individual documents as graphs where the nodes represent the sentences for performing clas - sification using a graph neural network']",0
"['one which deliberately exposes real - world individuals, organisations and events to ridicule.', 'previous works  #TAUTHOR_TAG rely on various linguistic and hand']","['one which deliberately exposes real - world individuals, organisations and events to ridicule.', 'previous works  #TAUTHOR_TAG rely on various linguistic and handcrafted semantic features']","['one which deliberately exposes real - world individuals, organisations and events to ridicule.', 'previous works  #TAUTHOR_TAG rely on various linguistic and hand']","[""today's day and age of social media, there are ample opportunities for fake news production, dissemination and consumption."", ' #AUTHOR_TAG break down fake news into three categories, hoax, propaganda and satire.', 'a hoax article typically tries to convince the reader about a cookedup story while propaganda ones usually mislead the reader into believing a false political or social agenda.', ' #AUTHOR_TAG defines a satirical article as the one which deliberately exposes real - world individuals, organisations and events to ridicule.', 'previous works  #TAUTHOR_TAG rely on various linguistic and handcrafted semantic features for differentiating between news articles.', 'however, none of them try to model the interaction of sentences within the document.', 'we observed a pattern in the way sentences cluster in different kind of news articles.', 'specifically, satirical articles had a more coherent story and thus all the sentences in the document seemed similar to each other.', 'on the other hand, the trusted news articles were also coherent but the similarity between sentences from different parts of the document was not that strong, as depicted in figure 1.', 'we believe that the reason for such kind of behaviour is the presence of factual jumps across sections in a trusted document.', 'in this work, we propose a graph neural network - based model to classify news articles while capturing the interaction of sentences across the document.', 'we present a series of experiments on news corpus with varying reliability dataset  #AUTHOR_TAG and satirical legitimate news dataset  #TAUTHOR_TAG.', 'our results demonstrate that the proposed model achieves state - of - the - art performance on these datasets and provides interesting insights.', 'experiments performed in out - of - domain settings establish the generalizability of our proposed method']",5
"['##rical and legitimate news database  #TAUTHOR_TAG, rpn : random political news dataset  #AUTHOR_TAG and lun :  #AUTHOR_TAG for our experiments']","['use sln : satirical and legitimate news database  #TAUTHOR_TAG, rpn : random political news dataset  #AUTHOR_TAG and lun :  #AUTHOR_TAG for our experiments.', 'table 1 shows the statistics.', 'since']","[': satirical and legitimate news database  #TAUTHOR_TAG, rpn : random political news dataset  #AUTHOR_TAG and lun :  #AUTHOR_TAG for our experiments']","['use sln : satirical and legitimate news database  #TAUTHOR_TAG, rpn : random political news dataset  #AUTHOR_TAG and lun :  #AUTHOR_TAG for our experiments.', 'table 1 shows the statistics.', 'since all of the previous methods on the aforementioned datasets are non - neural, we implement the following neural baselines,', '• cnn : in this model, we apply a 1 - d cnn ( convolutional neural network ) layer  #AUTHOR_TAG with filter size 3 over the word embeddings of the sentences within a document.', '']",5
"[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the']","[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the']","[' #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the task']","['##re, according to  #AUTHOR_TAG, is complicated because it occupies more than one place in the framework for humor, proposed by  #AUTHOR_TAG : it clearly has an aggressive and social function, and often expresses an intellectual aspect as well.', ' #TAUTHOR_TAG defines news satire as a genre of satire that mimics the format and style of journalistic reporting.', 'datasets created for the task of identifying satirical news articles from the trusted ones are often constructed by collecting documents from different online sources  #TAUTHOR_TAG.', 'mc  #AUTHOR_TAG hypothesized that this encourages the models to learn characteristics for different publication sources rather than characteristics of satire.', 'in this work, we show that our proposed model generalizes to articles from unseen publication sources.', "" #TAUTHOR_TAG's work by offering a quantitative study of linguistic differences found in articles of different types of fake news such as hoax, propaganda and satire."", 'they also proposed predictive models for graded deception across multiple domains.', "" #AUTHOR_TAG found that neural methods didn't perform well for this task and proposed to use a max - entropy classifier."", 'we show that our proposed neural network based on graph convolutional layers can outperform this model.', 'recent works by  #AUTHOR_TAG ;  #AUTHOR_TAG show that sophisticated neural models can be used for satirical news detection.', 'to the best of our knowledge, none of the previous works represent individual documents as graphs where the nodes represent the sentences for performing clas - sification using a graph neural network']",4
['paper  #TAUTHOR_TAG reports a'],"['sln as an out of domain test set ( just one overlapping source, no overlap in articles ), whereas the sota paper  #TAUTHOR_TAG reports a 10fold']","['as an out of domain test set ( just one overlapping source, no overlap in articles ), whereas the sota paper  #TAUTHOR_TAG reports a 10fold cross validation number on sl']","['', 'we only report f1 - score following the sota paper.', ""similarity model does not seem to have much impact on the gcn model, and considering the computing cost, we don't experiment with it for the 4 - way classification scenario."", 'given that we use sln as an out of domain test set ( just one overlapping source, no overlap in articles ), whereas the sota paper  #TAUTHOR_TAG reports a 10fold cross validation number on sln.', 'we believe that our results are quite strong, the gat + 2 attn heads model achieves an accuracy of 87 % on the entire rpn dataset when used as an out - of - domain test set.', 'the sota paper  #AUTHOR_TAG on rpn reports a 5 - fold cross validation accuracy of 91 %.', 'these results indicate the generalizability of our proposed model across datasets.', 'we also present results of four way classification in table 3.', 'all of our proposed methods outperform sota on both the in - domain and out of domain test set.', 'to further understand the working of our proposed model, we closely inspect the attention maps generated by the gat model for satirical and trusted news articles for the sln dataset.', 'from figure 3, we can see that the attention map generated for the trusted news article only focuses on two specific sentence whereas the attention weights are much more distributed in case of a satirical article.', 'interestingly enough the highlighted sentences in case of the trusted news article were the starting sentence of two different paragraphs in the article indicating the presence of similar sentence clusters within a document.', 'this opens a new avenue for understanding the differences between different kind of text articles for future research']",4
['jacana - freebase  #TAUTHOR_TAG'],['jacana - freebase  #TAUTHOR_TAG'],"['jacana - freebase  #TAUTHOR_TAG.', 'we find that']","['', 'we compare two open - source, state - ofthe - art systems on the task of freebase qa : the semantic parsing system sempre  #AUTHOR_TAG, and the ie system jacana - freebase  #TAUTHOR_TAG.', 'we find that these two systems are on par with each other, with no significant differences in terms of accuracy between them.', 'a major distinction between the work of  #AUTHOR_TAG and  #TAUTHOR_TAG is the ability of the former to represent, and compose, aggregation operators ( such as argmax, or count ), as well as integrate disparate pieces of information.', 'this representational capability was important in previous, closed - domain tasks such as geoquery.', 'the move to freebase by the sp community was meant to', 'provide richer, open - domain challenges.', 'while the vocabulary increased, our analysis suggests that compositionality and complexity decreased.', 'we therefore conclude that the semantic parsing community should target more challenging opendomain datasets, ones that "" standard ie "" methods are less capable of attacking']",7
['jacana - freebase  #TAUTHOR_TAG'],['jacana - freebase  #TAUTHOR_TAG'],"['jacana - freebase  #TAUTHOR_TAG.', 'we find that']","['', 'we compare two open - source, state - ofthe - art systems on the task of freebase qa : the semantic parsing system sempre  #AUTHOR_TAG, and the ie system jacana - freebase  #TAUTHOR_TAG.', 'we find that these two systems are on par with each other, with no significant differences in terms of accuracy between them.', 'a major distinction between the work of  #AUTHOR_TAG and  #TAUTHOR_TAG is the ability of the former to represent, and compose, aggregation operators ( such as argmax, or count ), as well as integrate disparate pieces of information.', 'this representational capability was important in previous, closed - domain tasks such as geoquery.', 'the move to freebase by the sp community was meant to', 'provide richer, open - domain challenges.', 'while the vocabulary increased, our analysis suggests that compositionality and complexity decreased.', 'we therefore conclude that the semantic parsing community should target more challenging opendomain datasets, ones that "" standard ie "" methods are less capable of attacking']",0
"['##ana - freebase 2  #TAUTHOR_TAG treats qa from a kb as a binary classification problem.', 'free']","['##ana - freebase 2  #TAUTHOR_TAG treats qa from a kb as a binary classification problem.', 'freebase is a gigantic graph with millions of nodes ( topics ) and billions of edges ( relations ).', '']","['##ana - freebase 2  #TAUTHOR_TAG treats qa from a kb as a binary classification problem.', 'free']","['##ana - freebase 2  #TAUTHOR_TAG treats qa from a kb as a binary classification problem.', 'freebase is a gigantic graph with millions of nodes ( topics ) and billions of edges ( relations ).', '']",0
['and  #TAUTHOR_TAG tested'],['and  #TAUTHOR_TAG tested'],['and  #TAUTHOR_TAG tested'],"['and  #TAUTHOR_TAG tested their systems on the webquestions dataset, which contains 3778 training questions and 2032 test questions collected from the google suggest api.', 'each question came with a standard answer from freebase annotated by amazon mechanical turk.', ' #AUTHOR_TAG reported a score of 31. 4 % in terms of accuracy ( with partial credit if inexact match ) on the test set and later in  #AUTHOR_TAG revised it to 35. 7 %.', 'berant et al. focused on accuracy - how many questions were correctly answered by the system.', '']",0
[' #TAUTHOR_TAG and'],"['reviews in', 'english  #AUTHOR_TAG, a twitter dataset  #TAUTHOR_TAG and']",[' #TAUTHOR_TAG and'],"['', 'evaluation between the different methods is somewhat difficult. this has serious implications for generalisability of methods. we correct that limitation in our study. there are', 'two papers taking a similar approach to our work in terms of generalisability although', ""they do not combine them with the reproduction issues that we highlight.  #AUTHOR_TAG compared results across semeval's laptop and restaurant reviews in"", 'english  #AUTHOR_TAG, a twitter dataset  #TAUTHOR_TAG and their own chinese news comments dataset. they did perform a comparison across different languages,', 'domains, corpora types, and different methods ; svm with features  #AUTHOR_TAG, rec - nn  #TAUTHOR_TAG, tdlstm  #AUTHOR_TAG a ), memory neural network ( mnet )  #AUTHOR_TAG b ) and', 'their own attention method. however, the chinese dataset was not', 'released, and the methods were not compared across all datasets. by contrast, we compare all methods across all datasets, using techniques that are', 'not just from the recurrent neural network ( rnn ) family. a second paper, by  #AUTHOR_TAG compares seven approaches to ( document and sentence level ) sentiment analysis on six benchmark', 'datasets, but does not systematically explore reproduction issues as we do in our paper']",0
[' #TAUTHOR_TAG and'],"['reviews in', 'english  #AUTHOR_TAG, a twitter dataset  #TAUTHOR_TAG and']",[' #TAUTHOR_TAG and'],"['', 'evaluation between the different methods is somewhat difficult. this has serious implications for generalisability of methods. we correct that limitation in our study. there are', 'two papers taking a similar approach to our work in terms of generalisability although', ""they do not combine them with the reproduction issues that we highlight.  #AUTHOR_TAG compared results across semeval's laptop and restaurant reviews in"", 'english  #AUTHOR_TAG, a twitter dataset  #TAUTHOR_TAG and their own chinese news comments dataset. they did perform a comparison across different languages,', 'domains, corpora types, and different methods ; svm with features  #AUTHOR_TAG, rec - nn  #TAUTHOR_TAG, tdlstm  #AUTHOR_TAG a ), memory neural network ( mnet )  #AUTHOR_TAG b ) and', 'their own attention method. however, the chinese dataset was not', 'released, and the methods were not compared across all datasets. by contrast, we compare all methods across all datasets, using techniques that are', 'not just from the recurrent neural network ( rnn ) family. a second paper, by  #AUTHOR_TAG compares seven approaches to ( document and sentence level ) sentiment analysis on six benchmark', 'datasets, but does not systematically explore reproduction issues as we do in our paper']",0
[' #TAUTHOR_TAG and'],"['reviews in', 'english  #AUTHOR_TAG, a twitter dataset  #TAUTHOR_TAG and']",[' #TAUTHOR_TAG and'],"['', 'evaluation between the different methods is somewhat difficult. this has serious implications for generalisability of methods. we correct that limitation in our study. there are', 'two papers taking a similar approach to our work in terms of generalisability although', ""they do not combine them with the reproduction issues that we highlight.  #AUTHOR_TAG compared results across semeval's laptop and restaurant reviews in"", 'english  #AUTHOR_TAG, a twitter dataset  #TAUTHOR_TAG and their own chinese news comments dataset. they did perform a comparison across different languages,', 'domains, corpora types, and different methods ; svm with features  #AUTHOR_TAG, rec - nn  #TAUTHOR_TAG, tdlstm  #AUTHOR_TAG a ), memory neural network ( mnet )  #AUTHOR_TAG b ) and', 'their own attention method. however, the chinese dataset was not', 'released, and the methods were not compared across all datasets. by contrast, we compare all methods across all datasets, using techniques that are', 'not just from the recurrent neural network ( rnn ) family. a second paper, by  #AUTHOR_TAG compares seven approaches to ( document and sentence level ) sentiment analysis on six benchmark', 'datasets, but does not systematically explore reproduction issues as we do in our paper']",0
"['of their experiments are performed on  #TAUTHOR_TAG twitter data set.', 'for']","['of their experiments are performed on  #TAUTHOR_TAG twitter data set.', 'for']","['of their experiments are performed on  #TAUTHOR_TAG twitter data set.', 'for']","['', 'target - dep + uses the features of target - dep and adds two additional contexts left and right sentiment ( ls & rs ) contexts where only the words within a specified lexicon are kept and the rest of the words are zero vectors.', 'all of their experiments are performed on  #TAUTHOR_TAG twitter data set.', 'for each of the experiments below we used the following configurations unless otherwise stated : we performed 5 fold stratified cross validation, features are scaled using max min scaling before inputting into the svm, and used the respective c - values for the svm stated in the paper for each of the models.', 'one major difficulty with the description of the method in the paper and re - implementation is handling the same target multiple appearances issue as originally raised by  #AUTHOR_TAG.', 'as the method requires context with regards to the target word, if there is more than one appearance of the target word then the method does not specify which to use.', 'we therefore took the approach of  #AUTHOR_TAG and found all of the features for each appearance and performed median pooling over features.', 'this change could explain the subtle differences between the results we report and those of the original paper']",0
"[') contain more targets per sentence with the exception of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the only dataset that has a small difference between']","['2, generally the social media datasets ( twitter and youtube ) contain more targets per sentence with the exception of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the only dataset that has a small difference between']","[') contain more targets per sentence with the exception of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the only dataset that has a small difference between the number of unique sentiments per sentence is the']","['are evaluating our models over six different english datasets deliberately chosen to represent a range of domains, types and mediums.', 'as highlighted above, previous papers tend to only carry out evaluations on one or two datasets which limits the generalisability of their results.', 'in this paper, we do not consider the quality or inter - annotator agreement levels of these datasets but it has been noted that some datasets may have issues here.', 'for example,  #AUTHOR_TAG point out that the  #AUTHOR_TAG dataset does not state their inter - annotator agreement scores nor do they have aspect terms that express neutral opinion.', 'we only use a subset of the english datasets available.', 'for two reasons.', 'first, the time it takes to write parsers and run the models.', 'second, we only used datasets that contain three distinct sentiments (  #AUTHOR_TAG only has two ).', 'from the datasets we have used, we have only had issue with parsing  #AUTHOR_TAG where the annotations for the first set of the data contains the target span but the second set does not.', 'thus making it impossible to use the second set of annotation and forcing us to only use a subset of the dataset.', 'an as example of this : "" got rid of bureaucrats\'and we put that money, into 9000 more doctors and nurses \'... to turn the doctors into bureaucrats # battlefornumber10 "" in that tweet\'bureaucrats\'was annotated as negative but it does not state if it was the first or second instance of\'bureaucrats\'since it does not use target spans.', 'as we can see from table 2, generally the social media datasets ( twitter and youtube ) contain more targets per sentence with the exception of  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the only dataset that has a small difference between the number of unique sentiments per sentence is the']",4
"['test all of the methods on the test data set of  #TAUTHOR_TAG and show the difference between the original and reproduced models in figure 2.', 'finally, we show the effect of scaling using max min and not scaling the data.', 'as stated before, we have been using max min scaling on the np features, however did not mention scaling in their paper.', 'the library']","['test all of the methods on the test data set of  #TAUTHOR_TAG and show the difference between the original and reproduced models in figure 2.', 'finally, we show the effect of scaling using max min and not scaling the data.', 'as stated before, we have been using max min scaling on the np features, however did not mention scaling in their paper.', 'the library']","['test all of the methods on the test data set of  #TAUTHOR_TAG and show the difference between the original and reproduced models in figure 2.', 'finally, we show the effect of scaling using max min and not scaling the data.', 'as stated before, we have been using max min scaling on the np features, however did not mention scaling in their paper.', 'the library they were using, liblinear  #AUTHOR_TAG, suggests in its practical guide  #AUTHOR_TAG to scale each feature to [ 0, 1 ] but this was not re - iterated by.', ""we are using scikit - learn's  #AUTHOR_TAG linearsvc which is a wrapper of liblinear, hence making""]","['test all of the methods on the test data set of  #TAUTHOR_TAG and show the difference between the original and reproduced models in figure 2.', 'finally, we show the effect of scaling using max min and not scaling the data.', 'as stated before, we have been using max min scaling on the np features, however did not mention scaling in their paper.', 'the library they were using, liblinear  #AUTHOR_TAG, suggests in its practical guide  #AUTHOR_TAG to scale each feature to [ 0, 1 ] but this was not re - iterated by.', ""we are using scikit - learn's  #AUTHOR_TAG linearsvc which is a wrapper of liblinear, hence making it appropriate to use here."", 'as can be seen in figure 2, not scaling can affect the results by around one - third']",5
"['on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['3.', 'tdparse + the features of tdparse and ls and rs contexts.', 'the experiments are performed on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['extended the np work of and instead of using the full tweet / sentence / text contexts they used the full dependency graph of the target word.', 'thus, they created three different methods : 1. tdparse - uses only the full dependency graph context, 2.', 'tdparse the feature of tdparse - and the left and right contexts, and 3.', 'tdparse + the features of tdparse and ls and rs contexts.', 'the experiments are performed on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', 'we also scale our features using max min scaling before inputting into the svm.', 'we used all three sentiment lexicons as in the original paper, and we found the c - value by performing 5 fold stratified cross validation on the training datasets.', 'the results of these experiments can be seen in figure 3 10.', 'as found with the results of replication, scaling is very important but is typically overlooked when reporting.', ' #AUTHOR_TAG a ) was the first to use lstms specifically for tdsa.', 'they created three different models : 1. lstm a standard lstm that runs over the length of the sentence and takes no target information into account, 2.', '']",5
"['on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['3.', 'tdparse + the features of tdparse and ls and rs contexts.', 'the experiments are performed on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['extended the np work of and instead of using the full tweet / sentence / text contexts they used the full dependency graph of the target word.', 'thus, they created three different methods : 1. tdparse - uses only the full dependency graph context, 2.', 'tdparse the feature of tdparse - and the left and right contexts, and 3.', 'tdparse + the features of tdparse and ls and rs contexts.', 'the experiments are performed on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', 'we also scale our features using max min scaling before inputting into the svm.', 'we used all three sentiment lexicons as in the original paper, and we found the c - value by performing 5 fold stratified cross validation on the training datasets.', 'the results of these experiments can be seen in figure 3 10.', 'as found with the results of replication, scaling is very important but is typically overlooked when reporting.', ' #AUTHOR_TAG a ) was the first to use lstms specifically for tdsa.', 'they created three different models : 1. lstm a standard lstm that runs over the length of the sentence and takes no target information into account, 2.', '']",5
"['test all of the methods on the test data set of  #TAUTHOR_TAG and show the difference between the original and reproduced models in figure 2.', 'finally, we show the effect of scaling using max min and not scaling the data.', 'as stated before, we have been using max min scaling on the np features, however did not mention scaling in their paper.', 'the library']","['test all of the methods on the test data set of  #TAUTHOR_TAG and show the difference between the original and reproduced models in figure 2.', 'finally, we show the effect of scaling using max min and not scaling the data.', 'as stated before, we have been using max min scaling on the np features, however did not mention scaling in their paper.', 'the library']","['test all of the methods on the test data set of  #TAUTHOR_TAG and show the difference between the original and reproduced models in figure 2.', 'finally, we show the effect of scaling using max min and not scaling the data.', 'as stated before, we have been using max min scaling on the np features, however did not mention scaling in their paper.', 'the library they were using, liblinear  #AUTHOR_TAG, suggests in its practical guide  #AUTHOR_TAG to scale each feature to [ 0, 1 ] but this was not re - iterated by.', ""we are using scikit - learn's  #AUTHOR_TAG linearsvc which is a wrapper of liblinear, hence making""]","['test all of the methods on the test data set of  #TAUTHOR_TAG and show the difference between the original and reproduced models in figure 2.', 'finally, we show the effect of scaling using max min and not scaling the data.', 'as stated before, we have been using max min scaling on the np features, however did not mention scaling in their paper.', 'the library they were using, liblinear  #AUTHOR_TAG, suggests in its practical guide  #AUTHOR_TAG to scale each feature to [ 0, 1 ] but this was not re - iterated by.', ""we are using scikit - learn's  #AUTHOR_TAG linearsvc which is a wrapper of liblinear, hence making it appropriate to use here."", 'as can be seen in figure 2, not scaling can affect the results by around one - third']",3
"['on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['3.', 'tdparse + the features of tdparse and ls and rs contexts.', 'the experiments are performed on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['extended the np work of and instead of using the full tweet / sentence / text contexts they used the full dependency graph of the target word.', 'thus, they created three different methods : 1. tdparse - uses only the full dependency graph context, 2.', 'tdparse the feature of tdparse - and the left and right contexts, and 3.', 'tdparse + the features of tdparse and ls and rs contexts.', 'the experiments are performed on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', 'we also scale our features using max min scaling before inputting into the svm.', 'we used all three sentiment lexicons as in the original paper, and we found the c - value by performing 5 fold stratified cross validation on the training datasets.', 'the results of these experiments can be seen in figure 3 10.', 'as found with the results of replication, scaling is very important but is typically overlooked when reporting.', ' #AUTHOR_TAG a ) was the first to use lstms specifically for tdsa.', 'they created three different models : 1. lstm a standard lstm that runs over the length of the sentence and takes no target information into account, 2.', '']",3
"['on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['3.', 'tdparse + the features of tdparse and ls and rs contexts.', 'the experiments are performed on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', '']","['extended the np work of and instead of using the full tweet / sentence / text contexts they used the full dependency graph of the target word.', 'thus, they created three different methods : 1. tdparse - uses only the full dependency graph context, 2.', 'tdparse the feature of tdparse - and the left and right contexts, and 3.', 'tdparse + the features of tdparse and ls and rs contexts.', 'the experiments are performed on the  #TAUTHOR_TAG and  #AUTHOR_TAG twitter datasets where we train and test on the previously specified train and test splits.', 'we also scale our features using max min scaling before inputting into the svm.', 'we used all three sentiment lexicons as in the original paper, and we found the c - value by performing 5 fold stratified cross validation on the training datasets.', 'the results of these experiments can be seen in figure 3 10.', 'as found with the results of replication, scaling is very important but is typically overlooked when reporting.', ' #AUTHOR_TAG a ) was the first to use lstms specifically for tdsa.', 'they created three different models : 1. lstm a standard lstm that runs over the length of the sentence and takes no target information into account, 2.', '']",3
['##ing instances of hate speech  #TAUTHOR_TAG. this filtering'],"['##ing instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with']","['##ing instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with']","['i. e., that can be easily implemented in a computer program ) can be contested. "" generally, the current consensus among researchers seems to', 'be that hate speech can be seen as a phenomenon encompassing issues such as : personal attacks, attacks on a specific group or minority, and abusive language', 'targeting specific group characteristics ( e. g., ethnicity, religion, gender, sexual orientation ). 2. creating resources for studying hat', '##e speech is far from trivial. hate speech comprises a very small fraction of online content, and on most social platforms it is heavily moderated. for', 'example,  #AUTHOR_TAG report that in their corpus of comments on yahoo! articles collected between april 2014 and april 2015, the percentage of abusive comments is around 3. 4 % on', 'finance articles and 10. 7 % on news. since the', 'phenomenon is elusive, researchers often use lists of offensive', 'terms to collect datasets with the aim to increase the likelihood of', 'catching instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with a variety of biases, which may go undetected. 3. finally', ', hate speech is present in user - generated content that is not under the control of the researcher. social media data is typically collected by', 'public apis that may lead to inconsistent results. for example, gonzalez - bailon et al. ( 2014 ) find that the twitter search api yields a smaller dataset than the stream api when using the same filtering parameters. furthermore, users might delete their profiles or moderate their own questionable content themselves. thus, datasets', 'on which research experiments are performed are ephemeral, which makes replication', 'of results very difficult. in this paper, we focus on the latter two points. we consider a particular hate', 'speech corpus - a twitter corpus collected by  #TAUTHOR_TAG ; gamback and  #AUTHOR_TAG - and analyse it critically to better understand its usefulness as a hate speech resource. in particular, we make the following contributions : • we report the outcome of a reproduction', 'experiment, where we attempt to replicate the results by  #TAUTHOR_TAG on hate speech detection using their twitter corpus. • we use the corpus to study a novel aspect related to hat', '##e speech : the popularity of tweets containing hate speech. to this end, we develop models for the task of predicting', 'whether a hate tweet will be interacted with and perform detailed feature analyses. • we perform a quantitative and qualitative analysis', 'of the corpus to analyse its possible biases and assess the generality of the results obtained', 'for the hate speech detection and popularity tasks']",0
['##ing instances of hate speech  #TAUTHOR_TAG. this filtering'],"['##ing instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with']","['##ing instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with']","['i. e., that can be easily implemented in a computer program ) can be contested. "" generally, the current consensus among researchers seems to', 'be that hate speech can be seen as a phenomenon encompassing issues such as : personal attacks, attacks on a specific group or minority, and abusive language', 'targeting specific group characteristics ( e. g., ethnicity, religion, gender, sexual orientation ). 2. creating resources for studying hat', '##e speech is far from trivial. hate speech comprises a very small fraction of online content, and on most social platforms it is heavily moderated. for', 'example,  #AUTHOR_TAG report that in their corpus of comments on yahoo! articles collected between april 2014 and april 2015, the percentage of abusive comments is around 3. 4 % on', 'finance articles and 10. 7 % on news. since the', 'phenomenon is elusive, researchers often use lists of offensive', 'terms to collect datasets with the aim to increase the likelihood of', 'catching instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with a variety of biases, which may go undetected. 3. finally', ', hate speech is present in user - generated content that is not under the control of the researcher. social media data is typically collected by', 'public apis that may lead to inconsistent results. for example, gonzalez - bailon et al. ( 2014 ) find that the twitter search api yields a smaller dataset than the stream api when using the same filtering parameters. furthermore, users might delete their profiles or moderate their own questionable content themselves. thus, datasets', 'on which research experiments are performed are ephemeral, which makes replication', 'of results very difficult. in this paper, we focus on the latter two points. we consider a particular hate', 'speech corpus - a twitter corpus collected by  #TAUTHOR_TAG ; gamback and  #AUTHOR_TAG - and analyse it critically to better understand its usefulness as a hate speech resource. in particular, we make the following contributions : • we report the outcome of a reproduction', 'experiment, where we attempt to replicate the results by  #TAUTHOR_TAG on hate speech detection using their twitter corpus. • we use the corpus to study a novel aspect related to hat', '##e speech : the popularity of tweets containing hate speech. to this end, we develop models for the task of predicting', 'whether a hate tweet will be interacted with and perform detailed feature analyses. • we perform a quantitative and qualitative analysis', 'of the corpus to analyse its possible biases and assess the generality of the results obtained', 'for the hate speech detection and popularity tasks']",0
"['features.', 'the algorithm.', ' #TAUTHOR_TAG state that they use a logistic regression classifier']","['features.', 'the algorithm.', ' #TAUTHOR_TAG state that they use a logistic regression classifier']","['present us with this problem : the algorithm and the features.', 'the algorithm.', ' #TAUTHOR_TAG state that they use a logistic regression classifier']","['with any replication study, our aim here is to mimic the original experimental setup as closely as possible, in hopes of obtaining same or comparable results.', 'unfortunately, this effort is already potentially hindered by the fact that the twitter corpus has shrunk over time.', 'however, the difference is not too large, and we expect it not to have a significant impact on the results.', 'a much more prominent obstacle is the lack of certain implementation details in the original paper that make reproduction difficult.', 'at several points in the pipeline, we were left to our own devices and resort to making educated guesses as to what may have been done, due to the lack of comprehensive documentation.', 'more specifically, there are two important aspects of the pipeline that present us with this problem : the algorithm and the features.', 'the algorithm.', ' #TAUTHOR_TAG state that they use a logistic regression classifier for their hate speech prediction task. what is not mentioned is which implementation of the algorithm is used, how the model was fit to the data, whether the features were scaled, and whether any other additional parameters had been used.', 'due to its popularity and accessibility, we opt for the scikitlearn  #AUTHOR_TAG python implementation of the logistic regression algorithm.', '4 in addition, after fitting the model, we do not do additional scaling of the features when working with just n - grams ( as these are already scaled when extracted ), but we do scale our other features using the scaling function']",0
"['features.', ' #TAUTHOR_TAG explore several feature types :']","['features.', ' #TAUTHOR_TAG explore several feature types :']","['features.', ' #TAUTHOR_TAG explore several feature types : they employ n - gram features - specifically, they find that character n - grams of lengths']","['features.', ' #TAUTHOR_TAG explore several feature types : they employ n - gram features - specifically, they find that character n - grams of lengths up to 4 perform best - and in addition, they combine them with gender information, geographic location information and tweet length, finding that combining n - gram features with gender features yields slightly better results than just n - gram features do, while mixing in any of the other features results in slightly lower scores.', 'as a rule of thumb, we would attempt to replicate the best performing setup ( character n - grams in combination with gender ).', 'however, this proved to be difficult, as user gender information is not provided by twitter ( hence it cannot be scraped from the twitter api ) and has not been made available by the authors along with their dataset.', 'however, they do describe how they went about procuring the gender information for themselves ( by performing semi - automatic, heuristics - based annotation ), but only managed to annotate about 52 % of the users.', 'this, in combination with the fact that in the original experiment the f1 score improvement when gender is considered is minor ( 0. 04 points ) and not statistically significant, led us to focus our efforts on replicating only the experiments involving n - gram features.', 'however, extracting the n - gram features is also shown to be a nontrivial task, as the original paper does not state how the features are encoded : whether it is using a bag - of - ngrams approach, a frequency count approach, or a tf - idf measure for each n - gram.', 'we opt for tf - idf because it is most informative, and just as easy to implement as the more basic approaches']",0
"[' #TAUTHOR_TAG, naive']","[' #TAUTHOR_TAG, naive bayes, decision trees, random forests,']","[' #TAUTHOR_TAG, naive bayes, decision trees, random forests,']","['date, most research on hate speech within the nlp community has been done in the area of automatic detection using a variety of techniques, from lists of prominent keywords  #AUTHOR_TAG to regression classifiers as seen in the previous section  #TAUTHOR_TAG, naive bayes, decision trees, random forests, and linear svms, as well as deep learning models with convolutional neural networks ( gamback and  #AUTHOR_TAG.', 'our intent in this section is to explore hate speech beyond just detection, using the twitter corpus by  #TAUTHOR_TAG.', 'given that twitter is a platform that enables sharing ideas, and given that extreme ideas have a tendency to intensely spread through social networks  #AUTHOR_TAG, our question is : how does the fact that a tweet is a hate tweet affect its popularity']",0
"['of the corpus by  #TAUTHOR_TAG, common to all twitter datasets.', 'in this']","['of the corpus by  #TAUTHOR_TAG, common to all twitter datasets.', 'in this section, we analyse other characteristics of the corpus']","['of the corpus by  #TAUTHOR_TAG, common to all twitter datasets.', 'in this section, we analyse other characteristics of the corpus']","['the field of hate speech research is yet to mature, with disagreement about what exactly the phenomenon entails  #AUTHOR_TAG and without a unified annotation framework ( fiser et al., 2017 ), it is warranted to look at the data and examples in more detail, with considerations for potential shortcomings.', 'in section 2., we pointed out the ephemeral nature of the corpus by  #TAUTHOR_TAG, common to all twitter datasets.', 'in this section, we analyse other characteristics of the corpus related to the challenges of data collection for hate speech analysis we mentioned in the introduction ( point 2 ), which can result in undesirable biases.', 'tweet collection.', 'given the small fraction of online content comprised of hate speech, collecting a significant amount of examples is an extremely difficult task.', 'at present, it is not feasible to collect a large sample of tweets and then manually label them as hate or non hate, as the fraction of instances labeled with the positive class will be negligible.', 'the only way to model the phenomenon is to target tweets already likely to contain hate speech.', 'driven by this rationale, the authors of the corpus have obtained their dataset by performing an initial manual search of common slurs and terms used pertaining to religious, sexual, gender, and ethnic minorities.', 'the full list of terms they queried for is not very long : mkr, asian drive, femi - nazi, immigrant, nigger, sjw, womenagainstfeminism, blameonenotall, islam terrorism, notallmen, victimcard, victim card, arab terror, gamergate, jsil, racecard, race card.', 'in the results obtained from these queries, they identified frequently occurring terms in tweets that contain hate speech and references to specific entities ( such as mkr, addressed further below ).', 'in addition to this, they identified a small number of prolific users from these searches.', 'this manner of tweet collection allowed the authors to obtain quite a considerable amount of data.', 'however, this approach to data collection inevitably introduces many biases into the dataset, as will be demonstrated further in this section.', 'qualitative observations on tweet content.', 'according to the annotation guidelines devised by  #TAUTHOR_TAG for the purpose of annotating this corpus, a tweet is tagged as offensive if it : ( 1 ) uses a sexist or racial slur, ( 2 ) attacks a minority, ( 3 ) seeks to silence a minority, ( 4 ) criticizes a minority ( without a well founded argument ), ( 5 ) promotes, but does not']",0
['##ing instances of hate speech  #TAUTHOR_TAG. this filtering'],"['##ing instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with']","['##ing instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with']","['i. e., that can be easily implemented in a computer program ) can be contested. "" generally, the current consensus among researchers seems to', 'be that hate speech can be seen as a phenomenon encompassing issues such as : personal attacks, attacks on a specific group or minority, and abusive language', 'targeting specific group characteristics ( e. g., ethnicity, religion, gender, sexual orientation ). 2. creating resources for studying hat', '##e speech is far from trivial. hate speech comprises a very small fraction of online content, and on most social platforms it is heavily moderated. for', 'example,  #AUTHOR_TAG report that in their corpus of comments on yahoo! articles collected between april 2014 and april 2015, the percentage of abusive comments is around 3. 4 % on', 'finance articles and 10. 7 % on news. since the', 'phenomenon is elusive, researchers often use lists of offensive', 'terms to collect datasets with the aim to increase the likelihood of', 'catching instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with a variety of biases, which may go undetected. 3. finally', ', hate speech is present in user - generated content that is not under the control of the researcher. social media data is typically collected by', 'public apis that may lead to inconsistent results. for example, gonzalez - bailon et al. ( 2014 ) find that the twitter search api yields a smaller dataset than the stream api when using the same filtering parameters. furthermore, users might delete their profiles or moderate their own questionable content themselves. thus, datasets', 'on which research experiments are performed are ephemeral, which makes replication', 'of results very difficult. in this paper, we focus on the latter two points. we consider a particular hate', 'speech corpus - a twitter corpus collected by  #TAUTHOR_TAG ; gamback and  #AUTHOR_TAG - and analyse it critically to better understand its usefulness as a hate speech resource. in particular, we make the following contributions : • we report the outcome of a reproduction', 'experiment, where we attempt to replicate the results by  #TAUTHOR_TAG on hate speech detection using their twitter corpus. • we use the corpus to study a novel aspect related to hat', '##e speech : the popularity of tweets containing hate speech. to this end, we develop models for the task of predicting', 'whether a hate tweet will be interacted with and perform detailed feature analyses. • we perform a quantitative and qualitative analysis', 'of the corpus to analyse its possible biases and assess the generality of the results obtained', 'for the hate speech detection and popularity tasks']",5
['##ing instances of hate speech  #TAUTHOR_TAG. this filtering'],"['##ing instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with']","['##ing instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with']","['i. e., that can be easily implemented in a computer program ) can be contested. "" generally, the current consensus among researchers seems to', 'be that hate speech can be seen as a phenomenon encompassing issues such as : personal attacks, attacks on a specific group or minority, and abusive language', 'targeting specific group characteristics ( e. g., ethnicity, religion, gender, sexual orientation ). 2. creating resources for studying hat', '##e speech is far from trivial. hate speech comprises a very small fraction of online content, and on most social platforms it is heavily moderated. for', 'example,  #AUTHOR_TAG report that in their corpus of comments on yahoo! articles collected between april 2014 and april 2015, the percentage of abusive comments is around 3. 4 % on', 'finance articles and 10. 7 % on news. since the', 'phenomenon is elusive, researchers often use lists of offensive', 'terms to collect datasets with the aim to increase the likelihood of', 'catching instances of hate speech  #TAUTHOR_TAG. this filtering process, however, has the risk of producing corpora with a variety of biases, which may go undetected. 3. finally', ', hate speech is present in user - generated content that is not under the control of the researcher. social media data is typically collected by', 'public apis that may lead to inconsistent results. for example, gonzalez - bailon et al. ( 2014 ) find that the twitter search api yields a smaller dataset than the stream api when using the same filtering parameters. furthermore, users might delete their profiles or moderate their own questionable content themselves. thus, datasets', 'on which research experiments are performed are ephemeral, which makes replication', 'of results very difficult. in this paper, we focus on the latter two points. we consider a particular hate', 'speech corpus - a twitter corpus collected by  #TAUTHOR_TAG ; gamback and  #AUTHOR_TAG - and analyse it critically to better understand its usefulness as a hate speech resource. in particular, we make the following contributions : • we report the outcome of a reproduction', 'experiment, where we attempt to replicate the results by  #TAUTHOR_TAG on hate speech detection using their twitter corpus. • we use the corpus to study a novel aspect related to hat', '##e speech : the popularity of tweets containing hate speech. to this end, we develop models for the task of predicting', 'whether a hate tweet will be interacted with and perform detailed feature analyses. • we perform a quantitative and qualitative analysis', 'of the corpus to analyse its possible biases and assess the generality of the results obtained', 'for the hate speech detection and popularity tasks']",5
['aim to replicate the results on hate speech detection by  #TAUTHOR_TAG using the hate speech twitter corpus'],['aim to replicate the results on hate speech detection by  #TAUTHOR_TAG using the hate speech twitter corpus'],['aim to replicate the results on hate speech detection by  #TAUTHOR_TAG using the hate speech twitter corpus'],"['aim to replicate the results on hate speech detection by  #TAUTHOR_TAG using the hate speech twitter corpus created by the authors.', '2 the dataset is a useful resource as it is one of few freely available corpora for hate speech research ; it is manually annotated and distinguishes between two types of hate speech - sexism and racismwhich allows for more nuanced insight and analysis.', 'additionally, as a twitter corpus, it provides opportunity for any type of analysis and feature examination typical for twitter corpora, such as user and tweet metadata, user interaction, etc']",5
"[' #TAUTHOR_TAG, naive']","[' #TAUTHOR_TAG, naive bayes, decision trees, random forests,']","[' #TAUTHOR_TAG, naive bayes, decision trees, random forests,']","['date, most research on hate speech within the nlp community has been done in the area of automatic detection using a variety of techniques, from lists of prominent keywords  #AUTHOR_TAG to regression classifiers as seen in the previous section  #TAUTHOR_TAG, naive bayes, decision trees, random forests, and linear svms, as well as deep learning models with convolutional neural networks ( gamback and  #AUTHOR_TAG.', 'our intent in this section is to explore hate speech beyond just detection, using the twitter corpus by  #TAUTHOR_TAG.', 'given that twitter is a platform that enables sharing ideas, and given that extreme ideas have a tendency to intensely spread through social networks  #AUTHOR_TAG, our question is : how does the fact that a tweet is a hate tweet affect its popularity']",5
"['work  #TAUTHOR_TAG.', 'we']","['work  #TAUTHOR_TAG.', 'we']","['.', 'we use an large set of features inspired by related work  #TAUTHOR_TAG.', 'we divide our features']","['.', 'we use an large set of features inspired by related work  #TAUTHOR_TAG.', 'we divide our features into three groups : tweet features ( metadata about the the tweet itself ), user features ( metadata about the author of a tweet ) and content features ( features derived from the content of the tweet ), with the largest number of features falling into the latter group.', 'the features are listed in table 5.', 'models and results.', 'we train a logistic regression classifier, as well as a linear svm classifier to compare their performances.', 'we also train separate models for likes and for retweets.', 'one pair of models was trained on the whole corpus, and two additional pairs of classifiers were trained on just the hate speech portion and non - hate speech portion of the corpus respectively.', 'we tested all models using 10 - fold cross validation,']",7
"['of the corpus by  #TAUTHOR_TAG, common to all twitter datasets.', 'in this']","['of the corpus by  #TAUTHOR_TAG, common to all twitter datasets.', 'in this section, we analyse other characteristics of the corpus']","['of the corpus by  #TAUTHOR_TAG, common to all twitter datasets.', 'in this section, we analyse other characteristics of the corpus']","['the field of hate speech research is yet to mature, with disagreement about what exactly the phenomenon entails  #AUTHOR_TAG and without a unified annotation framework ( fiser et al., 2017 ), it is warranted to look at the data and examples in more detail, with considerations for potential shortcomings.', 'in section 2., we pointed out the ephemeral nature of the corpus by  #TAUTHOR_TAG, common to all twitter datasets.', 'in this section, we analyse other characteristics of the corpus related to the challenges of data collection for hate speech analysis we mentioned in the introduction ( point 2 ), which can result in undesirable biases.', 'tweet collection.', 'given the small fraction of online content comprised of hate speech, collecting a significant amount of examples is an extremely difficult task.', 'at present, it is not feasible to collect a large sample of tweets and then manually label them as hate or non hate, as the fraction of instances labeled with the positive class will be negligible.', 'the only way to model the phenomenon is to target tweets already likely to contain hate speech.', 'driven by this rationale, the authors of the corpus have obtained their dataset by performing an initial manual search of common slurs and terms used pertaining to religious, sexual, gender, and ethnic minorities.', 'the full list of terms they queried for is not very long : mkr, asian drive, femi - nazi, immigrant, nigger, sjw, womenagainstfeminism, blameonenotall, islam terrorism, notallmen, victimcard, victim card, arab terror, gamergate, jsil, racecard, race card.', 'in the results obtained from these queries, they identified frequently occurring terms in tweets that contain hate speech and references to specific entities ( such as mkr, addressed further below ).', 'in addition to this, they identified a small number of prolific users from these searches.', 'this manner of tweet collection allowed the authors to obtain quite a considerable amount of data.', 'however, this approach to data collection inevitably introduces many biases into the dataset, as will be demonstrated further in this section.', 'qualitative observations on tweet content.', 'according to the annotation guidelines devised by  #TAUTHOR_TAG for the purpose of annotating this corpus, a tweet is tagged as offensive if it : ( 1 ) uses a sexist or racial slur, ( 2 ) attacks a minority, ( 3 ) seeks to silence a minority, ( 4 ) criticizes a minority ( without a well founded argument ), ( 5 ) promotes, but does not']",7
"['embeddings. here, we also try to mimic the word2vec  #TAUTHOR_TAG embeddings (']","['embeddings. here, we also try to mimic the word2vec  #TAUTHOR_TAG embeddings (']","['word embeddings. here, we also try to mimic the word2vec  #TAUTHOR_TAG embeddings (']","['lı ; ler and lar ; in and ın are asserted to be distant from each', 'other in regard to their word representations under a character n - gram level model such as fasttext  #AUTHOR_TAG, although the', 'two words are semantically similar and both referring to colors. in this paper, we argue that learning word representations through morphemes rather than characters lead to more accurate word vectors especially in morphologically complex languages. such character - based models are strongly affected', 'by the orthographic commonness of words', ', that governs orthographically similar words to have similar word representations. we introduce a model to learn morpheme', 'and word representations especially for morphologically very complex words without using an external supervised morphological segmentation', 'system. instead, we use an unsupervised segmentation model to initialize our model with a list of candidate morphological segmentations of each word in the training data. we do not provide a', 'single segmentation per word like others  #AUTHOR_TAG, but instead we provide a list of potential segmentations of each word. therefore, our model relaxes the requirement of an external segmentation system', 'in morpheme - based representation learning. to our knowledge, this will be the first attempt in co -', 'learning of morpheme representations and word representations in an unsupervised framework without assuming a single morphological segmentation per word. our model is', 'mostly similar to that of  #AUTHOR_TAG and  #AUTHOR_TAG since we also aim to learn morpheme and word representations. our model is akin to that of  #AUTHOR_TAG from the training perspective since they infer the out - of - vocabulary word embeddings from pre - trained word embeddings. here, we also try to mimic the word2vec  #TAUTHOR_TAG embeddings ( i. e. that are the expected outputs of the', 'model ) to learn the rare word representations with a complex morphology. our model shows some architectural similarities to that of  #AUTHOR_TAG. both models use the attention mechanism to up - weight the correct morphological', 'segmentation of a word. however, their model is character - based and our model', 'is morpheme - based where different segmentations of each word contribute to the resulting vector. it should be noted that our main concern is to investigate what character - based models cannot learn that', 'the morpheme - based models learn. as for the experimental setting, we have chosen turkish language that has a complex morphology and severe allomorphy. the results show that a morpheme - based model is better at estimating word representations of morphologically complex words ( with at least 2 - 3 suffixes ) compared to other word - based and character - based models. we present experimental results on turkish as an agglutinative language and english as a morphologically poor language']",5
"['for training, we use the pre - trained word', '##2vec  #TAUTHOR_TAG vectors in order to minimize the cost between the']","['for training, we use the pre - trained word', '##2vec  #TAUTHOR_TAG vectors in order to minimize the cost between the']","['attention. for training, we use the pre - trained word', '##2vec  #TAUTHOR_TAG vectors in order to minimize the cost between the']","['', 'segmentation of a given word. therefore, we train the', 'model with a list of potential segmentations of each word in training data. since a word is represented by different morpheme sequences that refer to different segmentations of', 'the same word, we use an attention model over these sequences that are learned by the bilstms. attention model learns a weight α i for each segmentation, such that weighted sum of the embeddings of all candidate segmentations : where v s', 'i is the vector for segmentation s i that is the output of a bi - lstm. the weight α i is estimated as follows  #AUTHOR_TAG : here,', 'a feed - forward layer is used with a softmax function that is applied over the outputs of bi', '- lstms. w · v s i denotes the corresponding column in the weight matrix of the feed - forward layer in the attention. for training, we use the pre - trained word', '##2vec  #TAUTHOR_TAG vectors in order to minimize the cost between the learned and pre - trained vectors with the following objective function :', 'where h ( w k ) is the cost for the kth word w k in a training set of size n', 'with a l2 regularization term on the model parameters', 'θ. we use the cosine proximity loss between the learned and the pretrained vector']",5
"['training word2vec  #TAUTHOR_TAG.', 'for turkish,']","['training word2vec  #TAUTHOR_TAG.', 'for turkish,']","['training word2vec  #TAUTHOR_TAG.', 'for turkish, we trained word2']","['all experiments, morpheme vectors have a dimension of d morph = 75, while the forward and backward lstms have a dimension of d lst m = 300.', 'since the output of the bi - lstms is the concatenation of the forward and backward lstms, the bi - lstm output has a dimensionality of d bilst m = 600.', 'the output of the bi - lstms is reduced to half after feeding the output through a feed - forward layer that results with a word vector dimension of d word = 300.', 'our model is implemented in keras, and publicly available 3.', 'for the pre - trained word vectors, we used the word vectors of dimension 300 that were obtained by training word2vec  #TAUTHOR_TAG.', 'for turkish, we trained word2vec on boun corpus  #AUTHOR_TAG that contains 361 million word tokens.', ""for english, we used the google's pre - trained word2vec model 4 that was trained on 100 billion words with a vocabulary size of 3m."", 'for training of our model, we used the most frequent 200k words from the pre - trained vocabularies to filter out the noise for both languages.', ""in order to compare the quality of our embeddings against the embeddings obtained from character n - gram level model fasttext  #AUTHOR_TAG, we used the pre - trained word vectors trained on wikipedia  #AUTHOR_TAG and we used the google's pre - trained word vectors 5."", 'in order to compare our model with the character - based model by  #AUTHOR_TAG, we used text8 corpus 6.', 'model en tr word2vec  #AUTHOR_TAG only for testing reasons, we used pc - kimmo  #AUTHOR_TAG for english and the two - level turkish morphology ( akın and akın, 2007 ) for turkish in order to segment test sets to obtain the actual morphemes for generating word representations from the morpheme vectors that are learned in a fully unsupervised setting.', 'unsupervised segmentation system also could be used for the evaluation step, but we wanted to minimize the effect of incorrect segmentations to be able to evaluate the embeddings properly.', 'yet, we discuss the effect of the supervised vs unsupervised segmentations in section 5. 5.', 'we did only intrinsic evaluation with a set of experiments that assess the quality of the word and morpheme representations']",5
"[' #TAUTHOR_TAG that involves 10675 questions.', 'since there is no analogy']","[' #TAUTHOR_TAG that involves 10675 questions.', 'since there is no analogy']","[' #TAUTHOR_TAG that involves 10675 questions.', 'since there is no analogy dataset for turkish, we prepared a turkish analogy set synanalog']","['', 'here, we tested only the syntactic analogy on a list of word tuples since our focus is especially morphologically complex languages.', 'for english, we used the syntactic relations section provided in the google analogy dataset  #TAUTHOR_TAG that involves 10675 questions.', 'since there is no analogy dataset for turkish, we prepared a turkish analogy set synanalogytr 8 with 206 syntactic questions that involves inflected word forms.', 'the syntactic word tuples are judged by 40 human annotators in a scale from 1 to 10, where 1 shows a weak word analogy.', 'most words involve more than one suffix to test the morphological regularity in the analogy task.', 'the results are given in table 6 and table 7 for english and turkish.', 'the results show that our model outperforms both word2vec  #TAUTHOR_TAG and fasttext  #AUTHOR_TAG on both turkish and english languages.', 'additionally, some examples to analogy results are given in table 9 and the nearest neighbors of the turkish word kitap - lar - dan - mıs ( it was from the books ) are given in table 8']",5
['word2vec  #TAUTHOR_TAG have been successful in learning'],['word2vec  #TAUTHOR_TAG have been successful in learning'],['word2vec  #TAUTHOR_TAG have been successful in learning word representations'],"['word representation models such as word2vec  #TAUTHOR_TAG have been successful in learning word representations for frequent words.', 'since these classical models are based on collecting contextual information in a very large corpus, they estimate deficient word representations for rare words due to insufficient contextual information.', 'this has a negative consequence in some natural language processing tasks that make use of the word representations.', 'one approach to overcome this deficiency in estimating rare word representations is to apply compositional methods.', 'each word comprises of different subword units, such as characters, character n - grams, or morphemes.', ' #AUTHOR_TAG apply compositional methods by having the stem and affix representations in order to estimate the distributional representation of morphologically complex words.', ' #AUTHOR_TAG introduce an extension to word2vec  #TAUTHOR_TAG by representing each word in terms of the vector representations of its n - grams, which was earlier applied by schutze ( 1993 ) that learns the representations of fourgrams by applying singular value decomposition ( svd ).', ' #AUTHOR_TAG represent each character n - gram with a vector representation and words are estimated by the summation of the subword representations.', 'their results show that compositional methods that are originally proposed for estimating the meaning of phrases can also be used for estimating the meaning of a word by combining the information coming from different subword units.', ' #AUTHOR_TAG introduce compositional models that use character - level features show that the representations of rare words can be estimated more accurately ( in both semantic and syntactic tasks ) than the word - based models since the character - level models share more features across different words that helps to mitigate sparsity.', 'cotterell and schutze ( 2015 ) encode morphological tags within word embeddings by using a log - bilinear model, thereby leading morphologically similar words to have closer word representations in the embedding space.', ' #AUTHOR_TAG learn word representations based on morphemes that are obtained from an external morphological segmentation system.', ' #AUTHOR_TAG enhance word vectors with some character - level features such as capitalization.', ' #AUTHOR_TAG incorporate morphological information as a prior distribution to improve word embeddings.', 'they use morfessor  #AUTHOR_TAG as an external morphological segmentation system to extract the inner structure of words']",0
['word2vec  #TAUTHOR_TAG have been successful in learning'],['word2vec  #TAUTHOR_TAG have been successful in learning'],['word2vec  #TAUTHOR_TAG have been successful in learning word representations'],"['word representation models such as word2vec  #TAUTHOR_TAG have been successful in learning word representations for frequent words.', 'since these classical models are based on collecting contextual information in a very large corpus, they estimate deficient word representations for rare words due to insufficient contextual information.', 'this has a negative consequence in some natural language processing tasks that make use of the word representations.', 'one approach to overcome this deficiency in estimating rare word representations is to apply compositional methods.', 'each word comprises of different subword units, such as characters, character n - grams, or morphemes.', ' #AUTHOR_TAG apply compositional methods by having the stem and affix representations in order to estimate the distributional representation of morphologically complex words.', ' #AUTHOR_TAG introduce an extension to word2vec  #TAUTHOR_TAG by representing each word in terms of the vector representations of its n - grams, which was earlier applied by schutze ( 1993 ) that learns the representations of fourgrams by applying singular value decomposition ( svd ).', ' #AUTHOR_TAG represent each character n - gram with a vector representation and words are estimated by the summation of the subword representations.', 'their results show that compositional methods that are originally proposed for estimating the meaning of phrases can also be used for estimating the meaning of a word by combining the information coming from different subword units.', ' #AUTHOR_TAG introduce compositional models that use character - level features show that the representations of rare words can be estimated more accurately ( in both semantic and syntactic tasks ) than the word - based models since the character - level models share more features across different words that helps to mitigate sparsity.', 'cotterell and schutze ( 2015 ) encode morphological tags within word embeddings by using a log - bilinear model, thereby leading morphologically similar words to have closer word representations in the embedding space.', ' #AUTHOR_TAG learn word representations based on morphemes that are obtained from an external morphological segmentation system.', ' #AUTHOR_TAG enhance word vectors with some character - level features such as capitalization.', ' #AUTHOR_TAG incorporate morphological information as a prior distribution to improve word embeddings.', 'they use morfessor  #AUTHOR_TAG as an external morphological segmentation system to extract the inner structure of words']",0
['word2vec  #TAUTHOR_TAG on turkish despite'],['word2vec  #TAUTHOR_TAG on turkish despite'],['word2vec  #TAUTHOR_TAG on turkish despite the highly agglutinative morphological structure'],"['', 'the second group involves 57 semantically unrelated word pairs that are orthographically similar through their suffixes.', 'an example word pair in this group is kitaplardan ( from the books ) and kasaplardan ( from the butchers ) with two suffixes lar ( for the plural ) and dan ( for the ablative case ) with semantically unrelated two stems kitap ( the book ) and kasap ( the butcher ).', 'some other example word pairs in the turkish word pair list is given in table 5.', 'as seen on the table, our morpheme - based model is better at learning word representations with multiple suffixes.', 'the results are given in table 3.', ""english words mostly do not involve any suffixes, which hinders our model's performance."", 'however, our model performs better than both fasttext  #AUTHOR_TAG and word2vec  #TAUTHOR_TAG on turkish despite the highly agglutinative morphological structure of the language.', 'it shows that our model learns better word representations for morphologically complex words, whereas words with no suffixes are not estimated as good as the complex ones.', 'we also compared our model against the character - based model char2vec  #AUTHOR_TAG.', 'for this purpose, we trained our model on the same dataset and parameters as char2vec to be able to compare with their reported results.', 'the dataset is called text8 corpus and consists of the first 100mb of a cleaned - up dumb of wikipedia in 2006.', 'for the evaluation, we tested our word embeddings on rare words ( rw )  #AUTHOR_TAG and wordsim353  #AUTHOR_TAG datasets.', 'the results are given in table 4.', 'our results outperform char2vec  #AUTHOR_TAG on both word similarity test sets.', 'this shows that our model learns better word embeddings for both in - vocabulary and rare words compared to char2vec  #AUTHOR_TAG']",4
"[' #TAUTHOR_TAG that involves 10675 questions.', 'since there is no analogy']","[' #TAUTHOR_TAG that involves 10675 questions.', 'since there is no analogy']","[' #TAUTHOR_TAG that involves 10675 questions.', 'since there is no analogy dataset for turkish, we prepared a turkish analogy set synanalog']","['', 'here, we tested only the syntactic analogy on a list of word tuples since our focus is especially morphologically complex languages.', 'for english, we used the syntactic relations section provided in the google analogy dataset  #TAUTHOR_TAG that involves 10675 questions.', 'since there is no analogy dataset for turkish, we prepared a turkish analogy set synanalogytr 8 with 206 syntactic questions that involves inflected word forms.', 'the syntactic word tuples are judged by 40 human annotators in a scale from 1 to 10, where 1 shows a weak word analogy.', 'most words involve more than one suffix to test the morphological regularity in the analogy task.', 'the results are given in table 6 and table 7 for english and turkish.', 'the results show that our model outperforms both word2vec  #TAUTHOR_TAG and fasttext  #AUTHOR_TAG on both turkish and english languages.', 'additionally, some examples to analogy results are given in table 9 and the nearest neighbors of the turkish word kitap - lar - dan - mıs ( it was from the books ) are given in table 8']",4
"['based model word2vec  #TAUTHOR_TAG, character - based model char2vec  #AUTHOR_TAG, and']","['model word2vec  #TAUTHOR_TAG, character - based model char2vec  #AUTHOR_TAG, and']","['the word - based model word2vec  #TAUTHOR_TAG, character - based model char2vec  #AUTHOR_TAG, and the character n - gram level model fasttext  #AUTHOR_TAG.', 'our results are also competitive for the english language.', 'we leave other languages and experiments such as morphological segmentation task for the future work.', 'another goal is']","['work shows that character level models learn more representative word embeddings for rare words ( including morphologically complex words ) compared to word level models, which is a sign that incorporating subword information improves the word representations.', 'however, in this paper, we argued that morpheme - based representation models can learn better word embeddings ( especially for the syntactic tasks ) since they incorporate the syntactic and semantic information through the morphemes better compared to character level models.', 'we pointed to the poor representation of allomorphs in complex words where the character - level models estimate a low word similarity between semantically similar words with different forms of the same morpheme, i. e. allomorphs.', 'moreover, we pointed to the character level models that assign a high word similar - ity to the words that are orthographically similar but semantically unrelated.', 'we introduce a morpheme - based representation model that learns word embeddings through the morphemes that are obtained from a list of morphological segmentations for each word.', 'therefore, our work introduces the idea of releasing the need for using an external morphological segmentation system in such representation learning models that are based on subword information.', 'our morpheme - based model morph2vec learns better word representations for morphologically complex words compared to the word - based model word2vec  #TAUTHOR_TAG, character - based model char2vec  #AUTHOR_TAG, and the character n - gram level model fasttext  #AUTHOR_TAG.', 'our results are also competitive for the english language.', 'we leave other languages and experiments such as morphological segmentation task for the future work.', 'another goal is to perform extrinsic evaluation on a different task such as part - of - speech tagging using the learned word embeddings']",4
"['not be aligned.', 'the second step is to perform dictionary induction by learning a linear projection, in the form of a matrix, between language vector spaces  #TAUTHOR_TAG.', 'our key insight for bantu languages is that one can create a single vector space for them, obviating the need for learning a projection matrix for each bantu language.', 'this means we only need to learn a single projection matrix,']","['not be aligned.', 'the second step is to perform dictionary induction by learning a linear projection, in the form of a matrix, between language vector spaces  #TAUTHOR_TAG.', 'our key insight for bantu languages is that one can create a single vector space for them, obviating the need for learning a projection matrix for each bantu language.', 'this means we only need to learn a single projection matrix,']","['not be aligned.', 'the second step is to perform dictionary induction by learning a linear projection, in the form of a matrix, between language vector spaces  #TAUTHOR_TAG.', 'our key insight for bantu languages is that one can create a single vector space for them, obviating the need for learning a projection matrix for each bantu language.', 'this means we only need to learn a single projection matrix,']","['', 'to answer this question we propose an approach based on distributed representations of words  #AUTHOR_TAG a ).', 'the first step is to create a vector space for each language, derived from a text corpus for the language.', 'notice that these text corpora need not be aligned.', 'the second step is to perform dictionary induction by learning a linear projection, in the form of a matrix, between language vector spaces  #TAUTHOR_TAG.', 'our key insight for bantu languages is that one can create a single vector space for them, obviating the need for learning a projection matrix for each bantu language.', 'this means we only need to learn a single projection matrix, for inducing multiple english to bantu bilingual dictionaries, using the small bilingual dictionary english−l bantu1.', 'additionally, we modify the corpus corresponding to l bantu2 to have a greater vocabulary intersection with l bantu1.', 'this step is inspired by the extensive use of bases and affixes, common to bantu languages.', 'words with the']",0
"['generating word vector representations, as demonstrated by results on a various semantic tasks  #TAUTHOR_TAG']","['generating word vector representations, as demonstrated by results on a various semantic tasks  #TAUTHOR_TAG']","['generating word vector representations, as demonstrated by results on a various semantic tasks  #TAUTHOR_TAG']","['representations of words, in the form of real - valued vectors, encode word semantics based on collocation of words in text  #AUTHOR_TAG a ;  #AUTHOR_TAG.', 'such vector representations have been shown to improve performance of various nlp tasks including semantic role labeling, partof - speech tagging, and named entity recognition  #AUTHOR_TAG.', 'in this work we use the skip - gram model with negative sampling to generate word vectors  #AUTHOR_TAG a ).', 'it is one of the most competitive methods for generating word vector representations, as demonstrated by results on a various semantic tasks  #TAUTHOR_TAG']",0
"['for a pair of languages, we use the projection matrix approach  #TAUTHOR_TAG.', 'it takes as input a small bilingual']","['for a pair of languages, we use the projection matrix approach  #TAUTHOR_TAG.', 'it takes as input a small bilingual']","['induce a bilingual dictionary for a pair of languages, we use the projection matrix approach  #TAUTHOR_TAG.', 'it takes as input a small bilingual dictionary containing pairs of translations from the source language to the target language.', 'training data is comprised of vector representations of word pairs', ', where x i ∈ r s is']","['induce a bilingual dictionary for a pair of languages, we use the projection matrix approach  #TAUTHOR_TAG.', 'it takes as input a small bilingual dictionary containing pairs of translations from the source language to the target language.', 'training data is comprised of vector representations of word pairs', '']",5
['can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],"['', 'links, and ac1 acts as the head, with no outgoing links. we also specify the type of ac, with the head ac marked as', 'claim and the remaining acs marked as premise. lastly, we note that the order of arguments components can be a strong', 'indicator of how components should related. linking to the first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG. given the task at hand, we propose a modification of a pointer network ( pn )  #AUTHOR_TAG b ). a pn is a sequence - to - sequence model that outputs a distribution over the encoding indices at each decoding timestep. the pn is a promising model for link extraction in argumentative text because it inherently possesses three important characteristics : 1 ) it is able to model the sequential nature of acs ; 2 ) it constrains', 'acs to have a single outgoing link, thus partly enforcing the', '']",5
['can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],"['', 'links, and ac1 acts as the head, with no outgoing links. we also specify the type of ac, with the head ac marked as', 'claim and the remaining acs marked as premise. lastly, we note that the order of arguments components can be a strong', 'indicator of how components should related. linking to the first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG. given the task at hand, we propose a modification of a pointer network ( pn )  #AUTHOR_TAG b ). a pn is a sequence - to - sequence model that outputs a distribution over the encoding indices at each decoding timestep. the pn is a promising model for link extraction in argumentative text because it inherently possesses three important characteristics : 1 ) it is able to model the sequential nature of acs ; 2 ) it constrains', 'acs to have a single outgoing link, thus partly enforcing the', '']",5
['can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],"['', 'links, and ac1 acts as the head, with no outgoing links. we also specify the type of ac, with the head ac marked as', 'claim and the remaining acs marked as premise. lastly, we note that the order of arguments components can be a strong', 'indicator of how components should related. linking to the first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG. given the task at hand, we propose a modification of a pointer network ( pn )  #AUTHOR_TAG b ). a pn is a sequence - to - sequence model that outputs a distribution over the encoding indices at each decoding timestep. the pn is a promising model for link extraction in argumentative text because it inherently possesses three important characteristics : 1 ) it is able to model the sequential nature of acs ; 2 ) it constrains', 'acs to have a single outgoing link, thus partly enforcing the', '']",5
['can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],"['', 'links, and ac1 acts as the head, with no outgoing links. we also specify the type of ac, with the head ac marked as', 'claim and the remaining acs marked as premise. lastly, we note that the order of arguments components can be a strong', 'indicator of how components should related. linking to the first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG. given the task at hand, we propose a modification of a pointer network ( pn )  #AUTHOR_TAG b ). a pn is a sequence - to - sequence model that outputs a distribution over the encoding indices at each decoding timestep. the pn is a promising model for link extraction in argumentative text because it inherently possesses three important characteristics : 1 ) it is able to model the sequential nature of acs ; 2 ) it constrains', 'acs to have a single outgoing link, thus partly enforcing the', '']",5
['can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],"['', 'links, and ac1 acts as the head, with no outgoing links. we also specify the type of ac, with the head ac marked as', 'claim and the remaining acs marked as premise. lastly, we note that the order of arguments components can be a strong', 'indicator of how components should related. linking to the first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG. given the task at hand, we propose a modification of a pointer network ( pn )  #AUTHOR_TAG b ). a pn is a sequence - to - sequence model that outputs a distribution over the encoding indices at each decoding timestep. the pn is a promising model for link extraction in argumentative text because it inherently possesses three important characteristics : 1 ) it is able to model the sequential nature of acs ; 2 ) it constrains', 'acs to have a single outgoing link, thus partly enforcing the', '']",5
['of  #TAUTHOR_TAG and focus on three different types of features to represent our acs : 1 ) bag - of - words of the ac'],['of  #TAUTHOR_TAG and focus on three different types of features to represent our acs : 1 ) bag - of - words of the ac ; 2 ) embedding representation'],"['- answering dataset  #AUTHOR_TAG.', 'we follow the work of  #TAUTHOR_TAG and focus on three different types of features to represent our acs : 1 ) bag - of - words of the ac ; 2 ) embedding representation']","['each timestep of the decoder, the network takes in the representation of an ac.', 'each ac is itself a sequence of tokens, similar to the recently proposed question - answering dataset  #AUTHOR_TAG.', 'we follow the work of  #TAUTHOR_TAG and focus on three different types of features to represent our acs : 1 ) bag - of - words of the ac ; 2 ) embedding representation based on glove embeddings  #AUTHOR_TAG ; 3 ) structural features : whether or not the ac is the first ac in a paragraph, and whether the ac is in an opening, body, or closing paragraph.', 'see section 6 for an ablation study of the proposed features']",5
"['##s  #TAUTHOR_TAG, as']","['of persuasive essays  #TAUTHOR_TAG, as']","[' #TAUTHOR_TAG, as']","['we have previously mentioned, our work assumes that acs have already been identified.', 'that is, the token sequence that comprises a given ac is already known.', 'the order of acs corresponds directly to the order in which the acs appear in the text.', 'since acs are non - overlapping, there is no ambiguity in this ordering.', 'we test the effectiveness of our proposed model on a dataset of persuasive essays  #TAUTHOR_TAG, as well as a dataset of microtexts  #AUTHOR_TAG.', 'the feature space for the persuasive essay corpus has roughly 3, 000 dimensions, and the microtext corpus feature space has between 2, 500 and 3, 000 dimensions, depending on the data split ( see below ).', 'the persuasive essay corpus contains a total of 402 essays, with a frozen set of 80 essays held out for testing.', 'there are three ac types in this corpus : major claim, claim, and premise.', 'we follow the creators of the corpus and only evaluate acs within a given paragraph.', 'that is, each training / test example is a sequence of acs from a paragraph.', 'this results in a 1, 405 / 144 training / test split.', '']",5
['ilp joint model  #TAUTHOR_TAG provides constrains'],['ilp joint model  #TAUTHOR_TAG provides constrains'],"['these classifiers enforce structural or global constraints.', 'conversely, the ilp joint model  #TAUTHOR_TAG provides constrains']","['results of our experiments are presented in tables 1 and 2.', 'for each corpus, we present f1 scores for the ac type classification experiment, with a macro - averaged score of the individual class f1 scores.', 'we also present the f1 scores for predicting the presence / absence of links between acs, as well as the associated macro - average between these two values.', 'we implement and compare four types of neural models : 1 ) the previously described pn - based model depicted in figure 3 ( called pn in the tables ) ; 2 ) the same as 1 ), but without the fullyconnected input layers ; 3 ) the same as 1 ), but the model only predicts the link task, and is therefore not optimized for type prediction ; 4 ) a non - sequence - to - sequence model that uses the hidden layers produced by the blstm encoder with the same type of attention as the pn ( called blstm in the table ).', 'that is, d i in equation 3 is replaced by e i.', 'in both corpora we compare against the following previously proposed models : base classifier  #AUTHOR_TAG is feature - rich, task - specific ( ac type or link extraction ) svm classifier.', 'neither of these classifiers enforce structural or global constraints.', 'conversely, the ilp joint model  #TAUTHOR_TAG provides constrains by sharing prediction information between the base classifier.', 'for example, the model attempts to enforce a tree structure among acs within a given paragraph, as well as using incoming link predictions to better predict the type class claim.', 'for the microtext corpus only, we have the following comparative models : simple  #AUTHOR_TAG is a feature - rich logistic regression classifier.', 'best eg  #AUTHOR_TAG creates an evidence graph ( eg ) from the predictions of a set of base classifier.', 'the eg models the potential argument structure, and offers a global optimization objective that the base classifiers attempt to optimize by adjusting their individual weights.', 'lastly, mp + p  #AUTHOR_TAG combines predictions from base classifiers with a mstparser, which applies 1 - best mira structured learning']",5
"['essays  #TAUTHOR_TAG, and']","['persuasive essays  #TAUTHOR_TAG, and']","['persuasive essays  #TAUTHOR_TAG, and']","['this paper we have proposed how to use a modified pn  #AUTHOR_TAG b ) to extract links between acs in argumentative text.', 'we evaluate our models on two corpora : a corpus of persuasive essays  #TAUTHOR_TAG, and a corpus of microtexts  #AUTHOR_TAG.', 'the pn model records state - of - the - art results on the persuasive essay corpus, as well as achieving state - of - the - art results for link prediction on the microtext corpus, despite only having 90 training examples.', 'the results show that jointly modeling the two prediction tasks is crucial for high performance, as well as the presence of a fully - connected layer prior to the lstm input.', 'future work can attempt to learn the ac representations themselves, such as in  #AUTHOR_TAG.', 'lastly, future work can integrate subtasks 1 and 4 into the model.', 'the representations produced by equation 3 could potentially be used to predict the type of link connecting acs, i. e. supporting or attacking ; this is the fourth subtask in the pipeline.', 'in addition, a segmenting technique, such as the one proposed by  #AUTHOR_TAG, can accomplish subtask 1']",5
['can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],['first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG'],"['', 'links, and ac1 acts as the head, with no outgoing links. we also specify the type of ac, with the head ac marked as', 'claim and the remaining acs marked as premise. lastly, we note that the order of arguments components can be a strong', 'indicator of how components should related. linking to the first argument component can provide a competitive baseline heuristic  #TAUTHOR_TAG. given the task at hand, we propose a modification of a pointer network ( pn )  #AUTHOR_TAG b ). a pn is a sequence - to - sequence model that outputs a distribution over the encoding indices at each decoding timestep. the pn is a promising model for link extraction in argumentative text because it inherently possesses three important characteristics : 1 ) it is able to model the sequential nature of acs ; 2 ) it constrains', 'acs to have a single outgoing link, thus partly enforcing the', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],['( ilp ) framework  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
['ilp joint model  #TAUTHOR_TAG provides constrains'],['ilp joint model  #TAUTHOR_TAG provides constrains'],"['these classifiers enforce structural or global constraints.', 'conversely, the ilp joint model  #TAUTHOR_TAG provides constrains']","['results of our experiments are presented in tables 1 and 2.', 'for each corpus, we present f1 scores for the ac type classification experiment, with a macro - averaged score of the individual class f1 scores.', 'we also present the f1 scores for predicting the presence / absence of links between acs, as well as the associated macro - average between these two values.', 'we implement and compare four types of neural models : 1 ) the previously described pn - based model depicted in figure 3 ( called pn in the tables ) ; 2 ) the same as 1 ), but without the fullyconnected input layers ; 3 ) the same as 1 ), but the model only predicts the link task, and is therefore not optimized for type prediction ; 4 ) a non - sequence - to - sequence model that uses the hidden layers produced by the blstm encoder with the same type of attention as the pn ( called blstm in the table ).', 'that is, d i in equation 3 is replaced by e i.', 'in both corpora we compare against the following previously proposed models : base classifier  #AUTHOR_TAG is feature - rich, task - specific ( ac type or link extraction ) svm classifier.', 'neither of these classifiers enforce structural or global constraints.', 'conversely, the ilp joint model  #TAUTHOR_TAG provides constrains by sharing prediction information between the base classifier.', 'for example, the model attempts to enforce a tree structure among acs within a given paragraph, as well as using incoming link predictions to better predict the type class claim.', 'for the microtext corpus only, we have the following comparative models : simple  #AUTHOR_TAG is a feature - rich logistic regression classifier.', 'best eg  #AUTHOR_TAG creates an evidence graph ( eg ) from the predictions of a set of base classifier.', 'the eg models the potential argument structure, and offers a global optimization objective that the base classifiers attempt to optimize by adjusting their individual weights.', 'lastly, mp + p  #AUTHOR_TAG combines predictions from base classifiers with a mstparser, which applies 1 - best mira structured learning']",0
['ilp joint model  #TAUTHOR_TAG provides constrains'],['ilp joint model  #TAUTHOR_TAG provides constrains'],"['these classifiers enforce structural or global constraints.', 'conversely, the ilp joint model  #TAUTHOR_TAG provides constrains']","['results of our experiments are presented in tables 1 and 2.', 'for each corpus, we present f1 scores for the ac type classification experiment, with a macro - averaged score of the individual class f1 scores.', 'we also present the f1 scores for predicting the presence / absence of links between acs, as well as the associated macro - average between these two values.', 'we implement and compare four types of neural models : 1 ) the previously described pn - based model depicted in figure 3 ( called pn in the tables ) ; 2 ) the same as 1 ), but without the fullyconnected input layers ; 3 ) the same as 1 ), but the model only predicts the link task, and is therefore not optimized for type prediction ; 4 ) a non - sequence - to - sequence model that uses the hidden layers produced by the blstm encoder with the same type of attention as the pn ( called blstm in the table ).', 'that is, d i in equation 3 is replaced by e i.', 'in both corpora we compare against the following previously proposed models : base classifier  #AUTHOR_TAG is feature - rich, task - specific ( ac type or link extraction ) svm classifier.', 'neither of these classifiers enforce structural or global constraints.', 'conversely, the ilp joint model  #TAUTHOR_TAG provides constrains by sharing prediction information between the base classifier.', 'for example, the model attempts to enforce a tree structure among acs within a given paragraph, as well as using incoming link predictions to better predict the type class claim.', 'for the microtext corpus only, we have the following comparative models : simple  #AUTHOR_TAG is a feature - rich logistic regression classifier.', 'best eg  #AUTHOR_TAG creates an evidence graph ( eg ) from the predictions of a set of base classifier.', 'the eg models the potential argument structure, and offers a global optimization objective that the base classifiers attempt to optimize by adjusting their individual weights.', 'lastly, mp + p  #AUTHOR_TAG combines predictions from base classifiers with a mstparser, which applies 1 - best mira structured learning']",1
"['averaging embeddings ( which', 'is used by  #TAUTHOR_TAG in their system ) is in']","['averaging embeddings ( which', 'is used by  #TAUTHOR_TAG in their system ) is in fact']","['create a multi - word embedding. the popular method of averaging embeddings ( which', 'is used by  #TAUTHOR_TAG in their system']","['input. the results show that this extra layer of depth is crucial for good performance on this task. without it, the pn model is only able to perform competitively with the base classifier. the results dictate that even a simple fully - connected layer with sigmoid activation', 'can provide a useful dimensionality reduction for feature representation. finally, the pn', 'model that only extracts links suffers a large drop in performance, conveying that the joint aspect of the pn', 'model is crucial for high performance in the link prediction task. table 3 shows the results of an ablation study for ac feature representation. regarding link prediction, bow features', 'are clearly the most important, as their absence results in the highest drop in performance. conversely, the presence', 'of structural features provides the smallest boost in performance, as the model is still able to record state - of - the - art results compared to the ilp joint model. this shows that', ', one one hand, the pn model is able to capture structural ques through sequence modeling and semantics ( the ilp joint model directly integrates these structural features ), however the pn model still does benefit from their explicit presence in the feature representation. when considering type prediction, both bow and structural features', ""are important, and it is the embedding features that provide the least benefit. the ablation results also provide an interesting insight into the effectiveness of different'pooling'strategies for using individual token embeddings to create a multi - word embedding. the popular method of averaging embeddings ( which"", 'is used by  #TAUTHOR_TAG in their system ) is in fact the worst method, although its performance', 'is still competitive with the previous state - of - the - art. conversely, max pooling', 'produces results that are on par with the pn results from table 1. table 4 shows the', 'results on the persuasive essay test set with the examples binned by sequence length. first, it is not a surprise to', 'see that the model performs best when the sequences are the shortest. as the sequence length increases, the accuracy on link prediction drops. this is possibly due to the fact that as the length', 'increases, a given ac has more possibilities as to which other ac it', 'can link to, making the task more difficult. conversely, there is actually a rise in no link prediction accuracy from', 'the second to third row. this is likely due to the fact that since the model predicts at most one outgoing link, it indirectly predicts no link for the remaining acs in the sequence. since', 'the chance probability is low for having a link between a given ac in a long sequence, the no link performance is actually better in longer sequences']",1
"['##ization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an']","['of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an']","['of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on']","['', 'our work builds on sequence - to - sequence models  #AUTHOR_TAG, which have been extensively applied to the task of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an input document.', '']",5
['the decoder from generating repeated information  #TAUTHOR_TAG'],['progress and dissuades the decoder from generating repeated information  #TAUTHOR_TAG'],"['the decoder from generating repeated information  #TAUTHOR_TAG.', 'to combine encoder and decoder attention, we alternate between each type of attention at every layer.', 'previous work used pointer networks to copy proper nouns and other entities from']","['', 'in contrast to previous work, we use multi - hop attention, such that the attention is added at each layer of the decoder.', 'in addition to attending over encoder states  #AUTHOR_TAG, we also use intra - attention in the decoder to enable the model to refer back to previously generated words at any time scale.', 'the mechanism allows the decoder to keep track of its progress and dissuades the decoder from generating repeated information  #TAUTHOR_TAG.', 'to combine encoder and decoder attention, we alternate between each type of attention at every layer.', 'previous work used pointer networks to copy proper nouns and other entities from the input  #AUTHOR_TAG which introduces additional complexity to the model.', 'instead, we rely on sub - word tokenization and weight sharing.', 'this choice is simpler but also very effective as we demonstrate in our experiments.', 'we use bytepair - encoding ( bpe ) to tokenize the data which has been shown to enable copying of proper nouns in translation  #AUTHOR_TAG.', 'we share the representation of the tokens in the encoder and decoder embeddings as well as in the last layer of the decoder']",5
[' #TAUTHOR_TAG and'],[' #TAUTHOR_TAG and'],['version  #TAUTHOR_TAG and'],"['use the cnn / dailymail dataset  #AUTHOR_TAG which consists of online news articles along with multi - sentence summaries.', 'the statistics of the dataset are reported in table 1 after limiting the length of the train documents to 400, as suggested by  #AUTHOR_TAG.', 'we evaluate on two versions of this dataset, the entity anonymized version  #TAUTHOR_TAG and the full text version  #AUTHOR_TAG 1.', 'we use bpe with 30k types  #AUTHOR_TAG.', 'for models not trained with bpe, the source and target vocabulary consists of all words appearing at least 20 times, creating a source vocabulary size of 47, 174 and a target vocabulary size of 21, 214']",5
"['', 'summaries are generated using beam search with beam of size 5.', 'to avoid repetition, we prevent the decoder from generating the same trigram more than once during test, following  #TAUTHOR_TAG']","['', 'summaries are generated using beam search with beam of size 5.', 'to avoid repetition, we prevent the decoder from generating the same trigram more than once during test, following  #TAUTHOR_TAG']","['', 'summaries are generated using beam search with beam of size 5.', 'to avoid repetition, we prevent the decoder from generating the same trigram more than once during test, following  #TAUTHOR_TAG']","['implement our models in torch  #AUTHOR_TAG and on top of the fairseq library 2.', 'our model architecture consists of 8 convolutional encoder and decoder layers, each with kernel width 3.', 'we use 512 hidden units for the encoder and decoder side, and embedding size 256.', 'we add dropout 0. 2 to the convolutional and fully connected layers.', ""we train our models following  #AUTHOR_TAG, using nesterov's accelerated gradient method  #AUTHOR_TAG with gradient clipping 0. 1  #AUTHOR_TAG, momentum 0. 99, and learning rate 0. 2."", 'we reduce the learning rate by an order of magnitude when the validation perplexity ceases to improve, and terminate training when the learning rate drops below 10 5.', 'summaries are generated using beam search with beam of size 5.', 'to avoid repetition, we prevent the decoder from generating the same trigram more than once during test, following  #TAUTHOR_TAG']",5
['abstractive baselines  #TAUTHOR_TAG and report results on the lead - 3 extraction baseline which simply selects the first three sentences of the input article as its summary'],['abstractive baselines  #TAUTHOR_TAG and report results on the lead - 3 extraction baseline which simply selects the first three sentences of the input article as its summary'],['we compare to existing abstractive baselines  #TAUTHOR_TAG and report results on the lead - 3 extraction baseline which simply selects the first three sentences of the input article as its summary'],"['evaluate using the standard rouge metric  #AUTHOR_TAG and report the f1 scores for rouge - 1, rouge - 2, and rouge - l. we compare to existing abstractive baselines  #TAUTHOR_TAG and report results on the lead - 3 extraction baseline which simply selects the first three sentences of the input article as its summary']",5
"['65 ml, no intra - attention  #TAUTHOR_TAG 38 the control variables.', 'second, we']","['ml words - lvt2k - temp - att  #AUTHOR_TAG 35. 46 13. 30 32. 65 ml, no intra - attention  #TAUTHOR_TAG 38 the control variables.', 'second, we']","['ml words - lvt2k - temp - att  #AUTHOR_TAG 35. 46 13. 30 32. 65 ml, no intra - attention  #TAUTHOR_TAG 38 the control variables.', 'second, we evaluate the effect of providing non - reference control variables.', 'table 3 reports the result of these experiments for each variable as well as their combined effect.', 'all control variables improve the quality of the generated summary.', 'however, length control is the']","['first evaluate the design choices of our convolutional summarization model and then the impact of manipulating the individual control variables.', 'finally, we show that the control variables are generally beneficial for model performance.', 'to that end, we quantify the rouge score when setting the control variables automatically at test time.', ' #AUTHOR_TAG.', 'first, we add a constraint to avoid repeated trigrams at generation time which improves f1 - rouge1 by + 2. 86.', 'next, we add intra - attention to enable the model to examine past generations over long distances.', 'this improves the accuracy obtained with the trigram constraint by a further 0. 51 f1 - rouge1.', 'the modest improvement is likely because the two features address a similar problem : the trigram constraint avoids repeated generations through constraining inference whereas intra - attention addresses the same problem through a change in the actual model.', 'finally, we switch data tokenization to bpe instead of a word - based vocabulary which gives another + 0. 79 f1 - rouge1.', 'the bpe vocabulary improves the ability to copy proper nouns and rare inflections, both of which are difficult to model in word - based vocabularies.', 'our improvements with bpe are comparable to results on machine translation  #AUTHOR_TAG.', 'table 3 : summarization when setting the control variables to the ground truth, as if simulating true user preferences our summarizer allows the user to control the length of the generated summary, the entities on which it focuses on, as well as the source style it imitates ( see section 2 ).', 'first, we evaluate the effect of providing the true reference variables at decoding time.', 'this simulates a user which expresses preferences through specifying values of model rouge - 1 rouge - 2 rouge - l lead - 3  #AUTHOR_TAG 39. 2 15. 7 35. 5 ml words - lvt2k - temp - att  #AUTHOR_TAG 35. 46 13. 30 32. 65 ml, no intra - attention  #TAUTHOR_TAG 38 the control variables.', 'second, we evaluate the effect of providing non - reference control variables.', 'table 3 reports the result of these experiments for each variable as well as their combined effect.', 'all control variables improve the quality of the generated summary.', 'however, length control is the most impactful variable, followed by entity control and source style.', 'furthermore, the advantages of each control variable can be combined to produce an even stronger summary : we obtain + 2. 2 f1 - rouge1 when combining all three control variables.', 'next, we discuss each variable in detail']",5
[' #TAUTHOR_TAG and'],[' #TAUTHOR_TAG and'],[' #TAUTHOR_TAG and'],"['', 'table 4 shows results on the entity - anonymized version of the dataset used by  #TAUTHOR_TAG and table 5 reports results on the original version of the dataset used by  #AUTHOR_TAG.', 'in both cases, our method achieves a slight advantage over alternatives.', 'on the original text, we report 39. 75 f1 - rouge1 as opposed to 39. 53 for  #AUTHOR_TAG.', 'on the entity - anonymized text, we report 38. 68 f1 - rouge1 as opposed to 38. 30 for the best maximum likelihood training setting of  #TAUTHOR_TAG.', 'our model does not outperform the reinforcement learning model of  #TAUTHOR_TAG which optimizes rouge.', 'however, training objectives are orthogonal to our work on control variables and we expect their training objective to equally benefit our model.', '']",5
"['##ization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an']","['of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an']","['of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on']","['', 'our work builds on sequence - to - sequence models  #AUTHOR_TAG, which have been extensively applied to the task of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an input document.', '']",0
"['##ization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an']","['of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an']","['of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on']","['', 'our work builds on sequence - to - sequence models  #AUTHOR_TAG, which have been extensively applied to the task of abstractive summarization  #TAUTHOR_TAG.', 'these models are neural language models conditioned on an input document.', '']",0
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",0
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",0
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",0
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",0
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",0
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",6
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",4
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",4
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",4
[' #TAUTHOR_TAG and'],[' #TAUTHOR_TAG and'],[' #TAUTHOR_TAG and'],"['', 'table 4 shows results on the entity - anonymized version of the dataset used by  #TAUTHOR_TAG and table 5 reports results on the original version of the dataset used by  #AUTHOR_TAG.', 'in both cases, our method achieves a slight advantage over alternatives.', 'on the original text, we report 39. 75 f1 - rouge1 as opposed to 39. 53 for  #AUTHOR_TAG.', 'on the entity - anonymized text, we report 38. 68 f1 - rouge1 as opposed to 38. 30 for the best maximum likelihood training setting of  #TAUTHOR_TAG.', 'our model does not outperform the reinforcement learning model of  #TAUTHOR_TAG which optimizes rouge.', 'however, training objectives are orthogonal to our work on control variables and we expect their training objective to equally benefit our model.', '']",4
[' #TAUTHOR_TAG and'],[' #TAUTHOR_TAG and'],[' #TAUTHOR_TAG and'],"['', 'table 4 shows results on the entity - anonymized version of the dataset used by  #TAUTHOR_TAG and table 5 reports results on the original version of the dataset used by  #AUTHOR_TAG.', 'in both cases, our method achieves a slight advantage over alternatives.', 'on the original text, we report 39. 75 f1 - rouge1 as opposed to 39. 53 for  #AUTHOR_TAG.', 'on the entity - anonymized text, we report 38. 68 f1 - rouge1 as opposed to 38. 30 for the best maximum likelihood training setting of  #TAUTHOR_TAG.', 'our model does not outperform the reinforcement learning model of  #TAUTHOR_TAG which optimizes rouge.', 'however, training objectives are orthogonal to our work on control variables and we expect their training objective to equally benefit our model.', '']",4
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",3
[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG following'],[' #TAUTHOR_TAG'],"['summarization has been an active field of research for close to 60 years  #AUTHOR_TAG.', 'efforts in both extractive and abstractive methods have followed advances in the field of natural language processing, pattern recognition, and machine learning  #AUTHOR_TAG.', 'recently, sequence - to - sequence neural networks  #AUTHOR_TAG have been applied to abstractive summarization  #TAUTHOR_TAG following their success in both machine translation  #AUTHOR_TAG b ), parsing  #AUTHOR_TAG a ) and image captioning  #AUTHOR_TAG b ).', 'research in abstractive summarization with sequence - to - sequence models focuses on neural architectures  #TAUTHOR_TAG.', 'summarization models have benefited from architectural advances in machine translation and related fields.', 'for instance, attention mechanisms  #AUTHOR_TAG enable generation to focus on a targeted part of the source document.', 'pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous  #TAUTHOR_TAG.', 'summarization also has distinct challenges.', 'for instance, the generation of multi - sentence summaries differs from individual sentence translation : when doing left - to - right decoding, the decoder needs to be aware of its previous generation at a larger time scale, otherwise the network tends to produce repeated text.', 'to address this impediment,  #AUTHOR_TAG introduce coverage modeling,  #TAUTHOR_TAG propose intra - decoder attention, and  #AUTHOR_TAG equip the decoder with an estimator of unigram frequency.', '']",3
"['from  #TAUTHOR_TAG.', 'in particular,']","['from  #TAUTHOR_TAG.', 'in particular,']","['use the romance and arabic language data from  #TAUTHOR_TAG.', 'in particular, each training file contains 12, 000 high - resource examples mixed with']","['use the romance and arabic language data from  #TAUTHOR_TAG.', 'in particular, each training file contains 12, 000 high - resource examples mixed with 50 or 200 fixed spanish instances.', '']",5
"[')  #TAUTHOR_TAG.', 'neural network quantization refers to compressing']","['( rnn )  #TAUTHOR_TAG.', 'neural network quantization refers to compressing']","[')  #TAUTHOR_TAG.', 'neural network quantization refers to compressing the original network by reducing number of bits required to represent weight matrices, and it has been studied for different model architectures']","['event detection ( aed ), the task of detecting whether certain events occur in an audio clip, can be applied in many industry applications [ 1, 2, 3, 23 ].', 'the accuracy of aed models have been increased in a large scale in recent years based on deep learning approaches.', 'however, to ensure high performance, those models are of large scale computation and memory intense, which makes it a challenge to deploy for real industrial applications with limited computation resources and memory.', 'our paper is focused on increasing the computation efficiency for aed models while maintaining their accuracies, so that aed deployment for resource - constraint industrial applications is feasible.', 'compression of neural networks has been explored in broad context.', 'we focus on two widely used and effective methods for deep models : low - rank matrix factorization and and quantization.', 'singular value decomposition ( svd ) is a common factorization technique and has been explored in feedforward networks [ 9, 10, 21, 22 ] and recurrent neural networks ( rnn )  #TAUTHOR_TAG.', 'neural network quantization refers to compressing the original network by reducing number of bits required to represent weight matrices, and it has been studied for different model architectures [ 12, 13, 14, 15, 16, 19, 20 ].', 'by reducing the bit - width of weights, model size is reduced, and it also brings considerable acceleration via efficient low bit - width arithmetic operations supports available on hardware.', 'for the quantization approach, it is important to fine - tune models with quantized weights to reduce the performance loss with quantized networks.', 'here we refer quantization with fine - turning as quantization training.', '32nd conference on neural information processing systems ( nips 2018 ), montreal, canada']",0
"['weight matrices is based on the svd compression of lstm  #TAUTHOR_TAG.', 'let']","['weight matrices is based on the svd compression of lstm  #TAUTHOR_TAG.', 'let']","['weight matrices is based on the svd compression of lstm  #TAUTHOR_TAG.', 'let']","['start by formulating the multi - class audio event detection problem.', 'given an audio signal i ( e. g. log mel - filter bank energies ( lfbes ) ), the task is to train a model f to predict a multi - hot vector y ∈ { 0, 1 } c, with c being the size of event set e and y c being a binary indicator whether event c is present in i. we denote d l = { ( i, y ) } as the labeled training dataset.', 'model f is trained using cross - entropy loss : l = − ( i, y ) ∈dl c c = 1 { w c y c log f c ( i ) + ( 1 − y c ) log ( 1 − f c ( i ) ) }, where w c is the penalty of positive mis - classification of class c. specifically we focus on the rnn - based model in this paper.', 'compared to cnns, it is more memory efficient and easier to deploy on devices with constrained resources.', 'low - rank matrix factorization the factorization of weight matrices is based on the svd compression of lstm  #TAUTHOR_TAG.', 'let w', 'quantization training quantization refers to representing floating - point values with n - bit integers ( n < 32 ).', 'as formulated in 2.', 'note the scaling factor α and minimum value β in equation 2 are not quantized.', 'v', 'as the quantization function ( q n ) is discrete, its gradient is almost zero everywhere.', 'to solve this problem, we apply straight - through estimator [ 18 ] to approximate the gradient of full - precision parameter ( ∂l ∂v ) with gradient of quantized value ( ∂l ∂v ) in the fine - tuning.', 'to combine low - rank matrix factorization and quantization training, the quantization operatorq n is applied to z l h, z l x andv lr h.', 'we quantize both model parameters and inputs.', 'the original rnn is first trained in full - precision until convergence.', 'after the low - rank matrix factorization is applied ( equation 1 ), the model is quantized and fine - tuned with quantization training.', 'we find the finetuning step is important to maintain performance with quantization']",0
"[')  #TAUTHOR_TAG.', 'neural network quantization refers to compressing']","['( rnn )  #TAUTHOR_TAG.', 'neural network quantization refers to compressing']","[')  #TAUTHOR_TAG.', 'neural network quantization refers to compressing the original network by reducing number of bits required to represent weight matrices, and it has been studied for different model architectures']","['event detection ( aed ), the task of detecting whether certain events occur in an audio clip, can be applied in many industry applications [ 1, 2, 3, 23 ].', 'the accuracy of aed models have been increased in a large scale in recent years based on deep learning approaches.', 'however, to ensure high performance, those models are of large scale computation and memory intense, which makes it a challenge to deploy for real industrial applications with limited computation resources and memory.', 'our paper is focused on increasing the computation efficiency for aed models while maintaining their accuracies, so that aed deployment for resource - constraint industrial applications is feasible.', 'compression of neural networks has been explored in broad context.', 'we focus on two widely used and effective methods for deep models : low - rank matrix factorization and and quantization.', 'singular value decomposition ( svd ) is a common factorization technique and has been explored in feedforward networks [ 9, 10, 21, 22 ] and recurrent neural networks ( rnn )  #TAUTHOR_TAG.', 'neural network quantization refers to compressing the original network by reducing number of bits required to represent weight matrices, and it has been studied for different model architectures [ 12, 13, 14, 15, 16, 19, 20 ].', 'by reducing the bit - width of weights, model size is reduced, and it also brings considerable acceleration via efficient low bit - width arithmetic operations supports available on hardware.', 'for the quantization approach, it is important to fine - tune models with quantized weights to reduce the performance loss with quantized networks.', 'here we refer quantization with fine - turning as quantization training.', '32nd conference on neural information processing systems ( nips 2018 ), montreal, canada']",5
"['weight matrices is based on the svd compression of lstm  #TAUTHOR_TAG.', 'let']","['weight matrices is based on the svd compression of lstm  #TAUTHOR_TAG.', 'let']","['weight matrices is based on the svd compression of lstm  #TAUTHOR_TAG.', 'let']","['start by formulating the multi - class audio event detection problem.', 'given an audio signal i ( e. g. log mel - filter bank energies ( lfbes ) ), the task is to train a model f to predict a multi - hot vector y ∈ { 0, 1 } c, with c being the size of event set e and y c being a binary indicator whether event c is present in i. we denote d l = { ( i, y ) } as the labeled training dataset.', 'model f is trained using cross - entropy loss : l = − ( i, y ) ∈dl c c = 1 { w c y c log f c ( i ) + ( 1 − y c ) log ( 1 − f c ( i ) ) }, where w c is the penalty of positive mis - classification of class c. specifically we focus on the rnn - based model in this paper.', 'compared to cnns, it is more memory efficient and easier to deploy on devices with constrained resources.', 'low - rank matrix factorization the factorization of weight matrices is based on the svd compression of lstm  #TAUTHOR_TAG.', 'let w', 'quantization training quantization refers to representing floating - point values with n - bit integers ( n < 32 ).', 'as formulated in 2.', 'note the scaling factor α and minimum value β in equation 2 are not quantized.', 'v', 'as the quantization function ( q n ) is discrete, its gradient is almost zero everywhere.', 'to solve this problem, we apply straight - through estimator [ 18 ] to approximate the gradient of full - precision parameter ( ∂l ∂v ) with gradient of quantized value ( ∂l ∂v ) in the fine - tuning.', 'to combine low - rank matrix factorization and quantization training, the quantization operatorq n is applied to z l h, z l x andv lr h.', 'we quantize both model parameters and inputs.', 'the original rnn is first trained in full - precision until convergence.', 'after the low - rank matrix factorization is applied ( equation 1 ), the model is quantized and fine - tuned with quantization training.', 'we find the finetuning step is important to maintain performance with quantization']",5
['follow the practice of  #TAUTHOR_TAG to set'],['follow the practice of  #TAUTHOR_TAG to set'],"['different lstm layers, we follow the practice of  #TAUTHOR_TAG to set the same threshold τ across layers as']",[' #TAUTHOR_TAG'],5
['of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )'],['of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )'],"['by 13 features, 9 of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )']","['by 13 features, 9 of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow ) to classify questions with respect to their expected answer type', '. the taxonomy consists of 6 coarse and 50 fine semantic classes. the training corpus used consists of 5, 500 questions. some of these are manually constructed, while other stems from the trec - 8 and trec - 9 conferences. the test corpus comprise 500 questions from the trec - 10 conference. the input to the classifiers is a list of features. the features used were words, part', '- ofspeech tags, chunks, named entities, head chunks ( e. g. the first noun chunk in a sentence ), and semantically related words ( words that', 'often occur with a specific question class ). apart from these primitive features, a set of', 'operators were used to compose more complex features.  #AUTHOR_TAG used the same taxonomy as  #TAUTHOR_TAG, as well as the same training and testing data. in an initial experiment they compared different machine', '']",0
['of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )'],['of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )'],"['by 13 features, 9 of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )']","['by 13 features, 9 of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow ) to classify questions with respect to their expected answer type', '. the taxonomy consists of 6 coarse and 50 fine semantic classes. the training corpus used consists of 5, 500 questions. some of these are manually constructed, while other stems from the trec - 8 and trec - 9 conferences. the test corpus comprise 500 questions from the trec - 10 conference. the input to the classifiers is a list of features. the features used were words, part', '- ofspeech tags, chunks, named entities, head chunks ( e. g. the first noun chunk in a sentence ), and semantically related words ( words that', 'often occur with a specific question class ). apart from these primitive features, a set of', 'operators were used to compose more complex features.  #AUTHOR_TAG used the same taxonomy as  #TAUTHOR_TAG, as well as the same training and testing data. in an initial experiment they compared different machine', '']",0
"[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","['order to compare the five algorithms ( naive bayes ( nb ), k nearest neighbours ( knn ), decision tree learning ( dt ), sparse network of winnows ( snow ), and support vector machines ( svm ) ) significance testing have been used.', 'significance scores can not be found in any previous work on question classification and hence it is difficult to draw any real conclusions from this work.', 'for present purposes the micro and macro sign tests established by  #AUTHOR_TAG have been used.', 'thses were originally developed for the text categorization task, but as question classification bears many resemblances and can be seen as a special case of text categorization.', 'the taxonomy used is the taxonomy proposed by  #TAUTHOR_TAG.', 'this taxonomy has been chosen since it is the most frequently used one in earlier work in the field  #TAUTHOR_TAG.', 'the corpora used is both the corpus constructed and tagged by  #TAUTHOR_TAG, as well as a newly tagged corpus extracted from the answerbus logs.', 'answerbus is a question answering system that has been online and logged real users questions.', 'the answerbus corpus consists of 25, 000 questions.', 'for present purposes 2, 000 questions have been selected and tagged according to the aforementioned taxonomy.', 'questions are in all experiments treated as a bag - of - words and represented as binary feature vectors.', 'the results will be reported in terms of microand macro - averaged precision, recall and f - score.', '']",0
[' #TAUTHOR_TAG on question classification'],[' #TAUTHOR_TAG on question classification'],[' #TAUTHOR_TAG on question classification might be'],"['results in this paper indicate that some of the results found in previous work  #TAUTHOR_TAG on question classification might be incorrect due to an unbiased training and test corpus.', 'this bias stems from the fact that the training corpus is derived exclusively from trec - 10 data, while the training data stems from other sources.', 'since the trec conferences have an explicit agenda that shifts from year to year this is perhaps no surprise.', 'in relation to this, trec material is maybe not the best source of information if one is interested in how different machine learners might perform on actual user data']",0
['of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )'],['of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )'],"['by 13 features, 9 of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )']","['by 13 features, 9 of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow ) to classify questions with respect to their expected answer type', '. the taxonomy consists of 6 coarse and 50 fine semantic classes. the training corpus used consists of 5, 500 questions. some of these are manually constructed, while other stems from the trec - 8 and trec - 9 conferences. the test corpus comprise 500 questions from the trec - 10 conference. the input to the classifiers is a list of features. the features used were words, part', '- ofspeech tags, chunks, named entities, head chunks ( e. g. the first noun chunk in a sentence ), and semantically related words ( words that', 'often occur with a specific question class ). apart from these primitive features, a set of', 'operators were used to compose more complex features.  #AUTHOR_TAG used the same taxonomy as  #TAUTHOR_TAG, as well as the same training and testing data. in an initial experiment they compared different machine', '']",3
"[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","['order to compare the five algorithms ( naive bayes ( nb ), k nearest neighbours ( knn ), decision tree learning ( dt ), sparse network of winnows ( snow ), and support vector machines ( svm ) ) significance testing have been used.', 'significance scores can not be found in any previous work on question classification and hence it is difficult to draw any real conclusions from this work.', 'for present purposes the micro and macro sign tests established by  #AUTHOR_TAG have been used.', 'thses were originally developed for the text categorization task, but as question classification bears many resemblances and can be seen as a special case of text categorization.', 'the taxonomy used is the taxonomy proposed by  #TAUTHOR_TAG.', 'this taxonomy has been chosen since it is the most frequently used one in earlier work in the field  #TAUTHOR_TAG.', 'the corpora used is both the corpus constructed and tagged by  #TAUTHOR_TAG, as well as a newly tagged corpus extracted from the answerbus logs.', 'answerbus is a question answering system that has been online and logged real users questions.', 'the answerbus corpus consists of 25, 000 questions.', 'for present purposes 2, 000 questions have been selected and tagged according to the aforementioned taxonomy.', 'questions are in all experiments treated as a bag - of - words and represented as binary feature vectors.', 'the results will be reported in terms of microand macro - averaged precision, recall and f - score.', '']",3
['of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )'],['of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )'],"['by 13 features, 9 of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow )']","['by 13 features, 9 of which are semantic features based on wordnet.  #TAUTHOR_TAG use a sparse network of winnows ( snow ) to classify questions with respect to their expected answer type', '. the taxonomy consists of 6 coarse and 50 fine semantic classes. the training corpus used consists of 5, 500 questions. some of these are manually constructed, while other stems from the trec - 8 and trec - 9 conferences. the test corpus comprise 500 questions from the trec - 10 conference. the input to the classifiers is a list of features. the features used were words, part', '- ofspeech tags, chunks, named entities, head chunks ( e. g. the first noun chunk in a sentence ), and semantically related words ( words that', 'often occur with a specific question class ). apart from these primitive features, a set of', 'operators were used to compose more complex features.  #AUTHOR_TAG used the same taxonomy as  #TAUTHOR_TAG, as well as the same training and testing data. in an initial experiment they compared different machine', '']",5
"[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","['order to compare the five algorithms ( naive bayes ( nb ), k nearest neighbours ( knn ), decision tree learning ( dt ), sparse network of winnows ( snow ), and support vector machines ( svm ) ) significance testing have been used.', 'significance scores can not be found in any previous work on question classification and hence it is difficult to draw any real conclusions from this work.', 'for present purposes the micro and macro sign tests established by  #AUTHOR_TAG have been used.', 'thses were originally developed for the text categorization task, but as question classification bears many resemblances and can be seen as a special case of text categorization.', 'the taxonomy used is the taxonomy proposed by  #TAUTHOR_TAG.', 'this taxonomy has been chosen since it is the most frequently used one in earlier work in the field  #TAUTHOR_TAG.', 'the corpora used is both the corpus constructed and tagged by  #TAUTHOR_TAG, as well as a newly tagged corpus extracted from the answerbus logs.', 'answerbus is a question answering system that has been online and logged real users questions.', 'the answerbus corpus consists of 25, 000 questions.', 'for present purposes 2, 000 questions have been selected and tagged according to the aforementioned taxonomy.', 'questions are in all experiments treated as a bag - of - words and represented as binary feature vectors.', 'the results will be reported in terms of microand macro - averaged precision, recall and f - score.', '']",5
"[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","[' #TAUTHOR_TAG.', 'this taxonomy has been chosen']","['order to compare the five algorithms ( naive bayes ( nb ), k nearest neighbours ( knn ), decision tree learning ( dt ), sparse network of winnows ( snow ), and support vector machines ( svm ) ) significance testing have been used.', 'significance scores can not be found in any previous work on question classification and hence it is difficult to draw any real conclusions from this work.', 'for present purposes the micro and macro sign tests established by  #AUTHOR_TAG have been used.', 'thses were originally developed for the text categorization task, but as question classification bears many resemblances and can be seen as a special case of text categorization.', 'the taxonomy used is the taxonomy proposed by  #TAUTHOR_TAG.', 'this taxonomy has been chosen since it is the most frequently used one in earlier work in the field  #TAUTHOR_TAG.', 'the corpora used is both the corpus constructed and tagged by  #TAUTHOR_TAG, as well as a newly tagged corpus extracted from the answerbus logs.', 'answerbus is a question answering system that has been online and logged real users questions.', 'the answerbus corpus consists of 25, 000 questions.', 'for present purposes 2, 000 questions have been selected and tagged according to the aforementioned taxonomy.', 'questions are in all experiments treated as a bag - of - words and represented as binary feature vectors.', 'the results will be reported in terms of microand macro - averaged precision, recall and f - score.', '']",5
"['by  #TAUTHOR_TAG, but since the test']","['by  #TAUTHOR_TAG, but since the test']","['by  #TAUTHOR_TAG, but since the test corpus']","['first experiment is intended to be a straightforward re - examination of previous work to establish what differences in performance there really are between machine learners.', 'this experiment has been done under two different settings.', 'first, we have used the corpus originally developed by  #TAUTHOR_TAG, but since the test corpus used consists of questions solely from trec - 10 and the trec conferences have a specific agenda the test corpus might be slightly different from the training data.', 'therefore, a second setting was used where the questions from the training and test corpora were pooled together and a randomized test corpus was extracted.', '']",4
"['by  #TAUTHOR_TAG, but since the test']","['by  #TAUTHOR_TAG, but since the test']","['by  #TAUTHOR_TAG, but since the test corpus']","['first experiment is intended to be a straightforward re - examination of previous work to establish what differences in performance there really are between machine learners.', 'this experiment has been done under two different settings.', 'first, we have used the corpus originally developed by  #TAUTHOR_TAG, but since the test corpus used consists of questions solely from trec - 10 and the trec conferences have a specific agenda the test corpus might be slightly different from the training data.', 'therefore, a second setting was used where the questions from the training and test corpora were pooled together and a randomized test corpus was extracted.', '']",6
['layer that came before it  #TAUTHOR_TAG'],['layer that came before it  #TAUTHOR_TAG'],"['a refined abstraction of the layer that came before it  #TAUTHOR_TAG.', '']","['- of - the - art deep neural networks leverage task - specific architectures to develop hierarchical representations of their input, with each layer building a refined abstraction of the layer that came before it  #TAUTHOR_TAG.', 'for text classification, one can think of this as a single reader building up an increasingly refined understanding of the content.', '']",0
['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2'],"['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2, 000 news outlets on the web.', 'the task has four classes, and for each class there are 30, 000 training documents and']",['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2'],"['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2, 000 news outlets on the web.', 'the task has four classes, and for each class there are 30, 000 training documents and 1, 900 test documents.', 'a random sample of the training set was used for hyper - parameter tuning.', 'the training and testing settings of this task are exactly the same as those presented for the stanford sentiment treebank task in section 3. 1, except that the mini - batch size is reduced to 23, and each view has a dimension of 100.', 'the test errors obtained by various methods are presented in table 3.', 'these results show that the bag - of - words mvn outperforms the state - of - theart accuracy obtained by the non - neural n - gram tfidf approach  #AUTHOR_TAG, as well as several very deep cnns  #TAUTHOR_TAG.', 'accuracy was further improved when the mvn was augmented with 4 convolutional features.', 'in figure 4, we show how accuracy and loss evolve on the validation set during mvn training.', 'these curves show that training is quite stable.', 'the mvn achieves its best results in just a few thousand iterations']",0
['layer that came before it  #TAUTHOR_TAG'],['layer that came before it  #TAUTHOR_TAG'],"['a refined abstraction of the layer that came before it  #TAUTHOR_TAG.', '']","['- of - the - art deep neural networks leverage task - specific architectures to develop hierarchical representations of their input, with each layer building a refined abstraction of the layer that came before it  #TAUTHOR_TAG.', 'for text classification, one can think of this as a single reader building up an increasingly refined understanding of the content.', '']",4
['layer that came before it  #TAUTHOR_TAG'],['layer that came before it  #TAUTHOR_TAG'],"['a refined abstraction of the layer that came before it  #TAUTHOR_TAG.', '']","['- of - the - art deep neural networks leverage task - specific architectures to develop hierarchical representations of their input, with each layer building a refined abstraction of the layer that came before it  #TAUTHOR_TAG.', 'for text classification, one can think of this as a single reader building up an increasingly refined understanding of the content.', '']",4
['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2'],"['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2, 000 news outlets on the web.', 'the task has four classes, and for each class there are 30, 000 training documents and']",['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2'],"['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2, 000 news outlets on the web.', 'the task has four classes, and for each class there are 30, 000 training documents and 1, 900 test documents.', 'a random sample of the training set was used for hyper - parameter tuning.', 'the training and testing settings of this task are exactly the same as those presented for the stanford sentiment treebank task in section 3. 1, except that the mini - batch size is reduced to 23, and each view has a dimension of 100.', 'the test errors obtained by various methods are presented in table 3.', 'these results show that the bag - of - words mvn outperforms the state - of - theart accuracy obtained by the non - neural n - gram tfidf approach  #AUTHOR_TAG, as well as several very deep cnns  #TAUTHOR_TAG.', 'accuracy was further improved when the mvn was augmented with 4 convolutional features.', 'in figure 4, we show how accuracy and loss evolve on the validation set during mvn training.', 'these curves show that training is quite stable.', 'the mvn achieves its best results in just a few thousand iterations']",4
"['is, we replace equation 5 with v i = s']","['that is, we replace equation 5 with v i = s']","['is, we replace equation 5 with v i = s']","['', 'negative ) classes, but achieve the highest f', '- measures on the 2 ( neutral ) class. meanwhile, the non - neutral classes each have a different view that achieves the highest f - measure. this suggests that some views', 'have specialized in order to better separate subsets of the training data. we provide an ablation study in table 2. first', ', we construct a traditional ensemble model. we independently train eight mvn models, each with a single view, to serve as weak learners. we have them vote with equal weight for the final classification', ', obtaining a test - set accuracy of 50. 2.', 'next, we restrict the views in the mvn to be unaware of each other', '. that is, we replace equation 5 with v i = s']",5
['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2'],"['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2, 000 news outlets on the web.', 'the task has four classes, and for each class there are 30, 000 training documents and']",['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2'],"['ag corpus  #TAUTHOR_TAG contains categorized news articles from more than 2, 000 news outlets on the web.', 'the task has four classes, and for each class there are 30, 000 training documents and 1, 900 test documents.', 'a random sample of the training set was used for hyper - parameter tuning.', 'the training and testing settings of this task are exactly the same as those presented for the stanford sentiment treebank task in section 3. 1, except that the mini - batch size is reduced to 23, and each view has a dimension of 100.', 'the test errors obtained by various methods are presented in table 3.', 'these results show that the bag - of - words mvn outperforms the state - of - theart accuracy obtained by the non - neural n - gram tfidf approach  #AUTHOR_TAG, as well as several very deep cnns  #TAUTHOR_TAG.', 'accuracy was further improved when the mvn was augmented with 4 convolutional features.', 'in figure 4, we show how accuracy and loss evolve on the validation set during mvn training.', 'these curves show that training is quite stable.', 'the mvn achieves its best results in just a few thousand iterations']",5
"['translation  #TAUTHOR_TAG.', 'the other is']","['translation  #TAUTHOR_TAG.', 'the other is']","['translation  #TAUTHOR_TAG.', 'the other is']","['contrasted two translation methods for the workshop on statistical machine translation ( wmt2006 ) shared - task.', 'one is a phrase - based translation in which a phrasal unit is employed for translation  #TAUTHOR_TAG.', 'the other is a hierarchical phrase - based translation in which translation is realized as a set of paired production rules  #AUTHOR_TAG.', 'section 2 discusses those two models and details extraction algorithms, decoding algorithms and feature functions.', 'we also explored three types of corpus preprocessing in section 3.', 'as expected, different tokenization would lead to different word alignments which, in turn, resulted in the divergence of the extracted phrase / rule size.', 'in our method, phrase / rule translation pairs extracted from three distinctly word - aligned corpora are aggregated into one large phrase / rule translation table.', 'the experiments and the final translation results are presented in section 4']",0
"['statistical translation  #TAUTHOR_TAG, a bilingual text is decomposed as']","['scenario of how a translation is constituted.', 'in a phrase - based statistical translation  #TAUTHOR_TAG, a bilingual text is decomposed as']","['of various feature functions depending on the scenario of how a translation is constituted.', 'in a phrase - based statistical translation  #TAUTHOR_TAG, a bilingual text is decomposed as k phrase translation pairs (']","['used a log - linear approach  #AUTHOR_TAG in which a foreign language sentence', 'in this framework, the posterior probability pr ( e i 1 | f j 1 ) is directly maximized using a log - linear combination of feature functions h m ( e i 1, f j 1 ), such as a ngram language model or a translation model.', 'when decoding, the denominator is dropped since it depends only on f j 1.', 'feature function scaling factors λ m are optimized based on a maximum likelihood approach  #AUTHOR_TAG or on a direct error minimization approach  #AUTHOR_TAG.', 'this modeling allows the integration of various feature functions depending on the scenario of how a translation is constituted.', 'in a phrase - based statistical translation  #TAUTHOR_TAG, a bilingual text is decomposed as k phrase translation pairs ( e 1, fa 1 ), ( e 2, fa 2 ),... : the input foreign sentence is segmented into phrasesf k 1, mapped into corresponding englishe k 1, then, reordered to form the output english sentence according to a phrase alignment index mappinga.', 'in a hierarchical phrase - based translation  #AUTHOR_TAG, translation is modeled after a weighted synchronous - cfg consisting of production rules whose right - hand side is paired  #AUTHOR_TAG :', 'x → γ, α, ∼ where x is a non - terminal, γ and α are strings of terminals and non - terminals.', '∼ is a one - to - one correspondence for the non - terminals appeared in γ and α.', 'starting from an initial non - terminal, each rule rewrites non - terminals in γ and α that are associated with ∼']",0
"['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model that counts the number of words skipped.', '• the number of words in english - side and the number of phrases that constitute translation.', 'for details, please refer to  #TAUTHOR_TAG.', 'in addition, we added three feature functions to restrict reorderings and to represent globalized insertion / deletion of words :', '• lexicalized reordering feature function scores whether a phrase translation pair is monotonically translated or not :', '• deletion feature function penalizes words that do not constitute a translation according to a 80, 260, 191 111, 153, 303 103, 523, 206 80, 666, 414 110, 787, 982 102, 940, 840 lexicon model t ( f | e )  #AUTHOR_TAG :', 'the deletion model simply counts the number of words whose lexicon model probability is lower than a threshold τ del.', 'likewise, we also added an insertion model h ins ( e i 1, f j 1 ) that penalizes the spuriously inserted english words using a lexicon model t ( e | f ).', 'for the hierarchical phrase - based model, we employed the same feature set except for the distortion model and the lexicalized reordering model']",0
"['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, manyto - many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, manyto - many word alignments are induced by running a one - to - many word alignment model, such as giza + +  #AUTHOR_TAG, in both directions and by combining the results based on a heuristic  #AUTHOR_TAG.', 'second, phrase translation pairs are extracted from the word aligned corpus  #TAUTHOR_TAG.', 'the method exhaustively extracts phrase pairs ( f j + m j, e i + n i ) from a sentence pair ( f j 1, e i 1 ) that do not violate the word alignment constraints a.', 'in the hierarchical phrase - based model, production rules are accumulated by computing "" holes "" for extracted contiguous phrases  #AUTHOR_TAG :', '2.', 'a rule x → γ, α and a phrase pair ( f, e ) s. t.', 'γ = γ ′ f γ ′ ′ and α = α ′ e α ′ ′ constitutes a rule']",3
"['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, manyto - many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, manyto - many word alignments are induced by running a one - to - many word alignment model, such as giza + +  #AUTHOR_TAG, in both directions and by combining the results based on a heuristic  #AUTHOR_TAG.', 'second, phrase translation pairs are extracted from the word aligned corpus  #TAUTHOR_TAG.', 'the method exhaustively extracts phrase pairs ( f j + m j, e i + n i ) from a sentence pair ( f j 1, e i 1 ) that do not violate the word alignment constraints a.', 'in the hierarchical phrase - based model, production rules are accumulated by computing "" holes "" for extracted contiguous phrases  #AUTHOR_TAG :', '2.', 'a rule x → γ, α and a phrase pair ( f, e ) s. t.', 'γ = γ ′ f γ ′ ′ and α = α ′ e α ′ ′ constitutes a rule']",3
['to those described in  #TAUTHOR_TAG :'],['to those described in  #TAUTHOR_TAG :'],"['to those described in  #TAUTHOR_TAG : it starts from an initial empty hypothesis.', 'from an existing hypothesis, new hypothesis']","['decoder for the phrase - based model is a left - toright generation decoder with a beam search strategy synchronized with the cardinality of already translated foreign words.', 'the decoding process is very similar to those described in  #TAUTHOR_TAG : it starts from an initial empty hypothesis.', 'from an existing hypothesis, new hypothesis is generated by consuming a phrase translation pair that covers untranslated foreign word positions.', 'the score for the newly generated hypothesis is updated by combining the scores of feature functions described in section 2. 3.', 'the english side of the phrase is simply concatenated to form a new prefix of english sentence.', 'in the hierarchical phrase - based model, decoding is realized as an earley - style top - down parser on the foreign language side with a beam search strategy synchronized with the cardinality of already translated foreign words  #AUTHOR_TAG.', ""the major difference to the phrase - based model's decoder is the handling of non - terminals, or holes, in each rule""]",3
"['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model that counts the number of words skipped.', '• the number of words in english - side and the number of phrases that constitute translation.', 'for details, please refer to  #TAUTHOR_TAG.', 'in addition, we added three feature functions to restrict reorderings and to represent globalized insertion / deletion of words :', '• lexicalized reordering feature function scores whether a phrase translation pair is monotonically translated or not :', '• deletion feature function penalizes words that do not constitute a translation according to a 80, 260, 191 111, 153, 303 103, 523, 206 80, 666, 414 110, 787, 982 102, 940, 840 lexicon model t ( f | e )  #AUTHOR_TAG :', 'the deletion model simply counts the number of words whose lexicon model probability is lower than a threshold τ del.', 'likewise, we also added an insertion model h ins ( e i 1, f j 1 ) that penalizes the spuriously inserted english words using a lexicon model t ( e | f ).', 'for the hierarchical phrase - based model, we employed the same feature set except for the distortion model and the lexicalized reordering model']",3
"['grow - diagfinal ""  #TAUTHOR_TAG.', 'different preprocessing']","['alignment refinement heuristic of "" grow - diagfinal ""  #TAUTHOR_TAG.', 'different preprocessing']","['grow - diagfinal ""  #TAUTHOR_TAG.', 'different preprocessing']","['prepared three kinds of corpora differentiated by tokenization methods.', 'first, the simplest preprocessing is lower - casing ( lower ).', ""second, corpora were transformed by a porter's algorithm based multilingual stemmer ( stem ) 1."", 'third, mixed - cased corpora were truncated to the prefix of four letters of each word ( prefix4 ).', 'for each differently tokenized corpus, we computed word alignments by a hmm translation model  #AUTHOR_TAG and by a word alignment refinement heuristic of "" grow - diagfinal ""  #TAUTHOR_TAG.', 'different preprocessing yields quite divergent alignment points as illustrated in table 1.', 'the table also shows the numbers for the intersection and union of three alignment annotations.', 'the ( hierarchical ) phrase translation pairs are extracted from three distinctly word aligned corpora.', '']",3
"['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, manyto - many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, manyto - many word alignments are induced by running a one - to - many word alignment model, such as giza + +  #AUTHOR_TAG, in both directions and by combining the results based on a heuristic  #AUTHOR_TAG.', 'second, phrase translation pairs are extracted from the word aligned corpus  #TAUTHOR_TAG.', 'the method exhaustively extracts phrase pairs ( f j + m j, e i + n i ) from a sentence pair ( f j 1, e i 1 ) that do not violate the word alignment constraints a.', 'in the hierarchical phrase - based model, production rules are accumulated by computing "" holes "" for extracted contiguous phrases  #AUTHOR_TAG :', '2.', 'a rule x → γ, α and a phrase pair ( f, e ) s. t.', 'γ = γ ′ f γ ′ ′ and α = α ′ e α ′ ′ constitutes a rule']",5
"['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, manyto - many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, many']","['phrase extraction algorithm is based on those presented by  #TAUTHOR_TAG.', 'first, manyto - many word alignments are induced by running a one - to - many word alignment model, such as giza + +  #AUTHOR_TAG, in both directions and by combining the results based on a heuristic  #AUTHOR_TAG.', 'second, phrase translation pairs are extracted from the word aligned corpus  #TAUTHOR_TAG.', 'the method exhaustively extracts phrase pairs ( f j + m j, e i + n i ) from a sentence pair ( f j 1, e i 1 ) that do not violate the word alignment constraints a.', 'in the hierarchical phrase - based model, production rules are accumulated by computing "" holes "" for extracted contiguous phrases  #AUTHOR_TAG :', '2.', 'a rule x → γ, α and a phrase pair ( f, e ) s. t.', 'γ = γ ′ f γ ′ ′ and α = α ′ e α ′ ′ constitutes a rule']",5
['to those described in  #TAUTHOR_TAG :'],['to those described in  #TAUTHOR_TAG :'],"['to those described in  #TAUTHOR_TAG : it starts from an initial empty hypothesis.', 'from an existing hypothesis, new hypothesis']","['decoder for the phrase - based model is a left - toright generation decoder with a beam search strategy synchronized with the cardinality of already translated foreign words.', 'the decoding process is very similar to those described in  #TAUTHOR_TAG : it starts from an initial empty hypothesis.', 'from an existing hypothesis, new hypothesis is generated by consuming a phrase translation pair that covers untranslated foreign word positions.', 'the score for the newly generated hypothesis is updated by combining the scores of feature functions described in section 2. 3.', 'the english side of the phrase is simply concatenated to form a new prefix of english sentence.', 'in the hierarchical phrase - based model, decoding is realized as an earley - style top - down parser on the foreign language side with a beam search strategy synchronized with the cardinality of already translated foreign words  #AUTHOR_TAG.', ""the major difference to the phrase - based model's decoder is the handling of non - terminals, or holes, in each rule""]",5
"['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model']","['phrase - based model uses a standard pharaoh feature functions listed as follows  #TAUTHOR_TAG :', '• relative - count based phrase translation probabilities in both directions.', '• lexically weighted feature functions in both directions.', '• the supplied trigram language model.', '• distortion model that counts the number of words skipped.', '• the number of words in english - side and the number of phrases that constitute translation.', 'for details, please refer to  #TAUTHOR_TAG.', 'in addition, we added three feature functions to restrict reorderings and to represent globalized insertion / deletion of words :', '• lexicalized reordering feature function scores whether a phrase translation pair is monotonically translated or not :', '• deletion feature function penalizes words that do not constitute a translation according to a 80, 260, 191 111, 153, 303 103, 523, 206 80, 666, 414 110, 787, 982 102, 940, 840 lexicon model t ( f | e )  #AUTHOR_TAG :', 'the deletion model simply counts the number of words whose lexicon model probability is lower than a threshold τ del.', 'likewise, we also added an insertion model h ins ( e i 1, f j 1 ) that penalizes the spuriously inserted english words using a lexicon model t ( e | f ).', 'for the hierarchical phrase - based model, we employed the same feature set except for the distortion model and the lexicalized reordering model']",5
"['grow - diagfinal ""  #TAUTHOR_TAG.', 'different preprocessing']","['alignment refinement heuristic of "" grow - diagfinal ""  #TAUTHOR_TAG.', 'different preprocessing']","['grow - diagfinal ""  #TAUTHOR_TAG.', 'different preprocessing']","['prepared three kinds of corpora differentiated by tokenization methods.', 'first, the simplest preprocessing is lower - casing ( lower ).', ""second, corpora were transformed by a porter's algorithm based multilingual stemmer ( stem ) 1."", 'third, mixed - cased corpora were truncated to the prefix of four letters of each word ( prefix4 ).', 'for each differently tokenized corpus, we computed word alignments by a hmm translation model  #AUTHOR_TAG and by a word alignment refinement heuristic of "" grow - diagfinal ""  #TAUTHOR_TAG.', 'different preprocessing yields quite divergent alignment points as illustrated in table 1.', 'the table also shows the numbers for the intersection and union of three alignment annotations.', 'the ( hierarchical ) phrase translation pairs are extracted from three distinctly word aligned corpora.', '']",5
"[' #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or']","['form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or document - aligned comparable']","['on parallel data in the form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or']","['objective of bilingual lexicon induction is to find translation pairs between two languages.', 'specifically, we aim to pair each word in the source vocabulary with its translation in the target vocabulary.', 'in this paper, we assume that the languages are sufficiently closely related to allow some translation pairs to be identified on the basis of orthographic similarity.', 'our setting is completely unsupervised : we extract the bilingual lexicons from non - parallel monolingual corpora representing the same domain.', 'by contrast, most of the prior work depend on parallel data in the form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or document - aligned comparable corpora ( vulic and  #AUTHOR_TAG.', 'other prior work assumes access to additional resources or features, such as dependency parsers  #AUTHOR_TAG, temporal and web - based features ( irvine and callison -  #AUTHOR_TAG, or babelnet  #AUTHOR_TAG.', 'our approach consists of two stages : we first create a seed set of translation pairs, and then iteratively expand the lexicon with a bootstrapping procedure.', 'the seed set is constructed by identifying words with similar spelling ( cognates ).', 'we filter out non - translation pairs that look similar but differ in meaning ( false friends ) by imposing a relative - frequency constraint.', '']",0
"[' #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or']","['form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or document - aligned comparable']","['on parallel data in the form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or']","['objective of bilingual lexicon induction is to find translation pairs between two languages.', 'specifically, we aim to pair each word in the source vocabulary with its translation in the target vocabulary.', 'in this paper, we assume that the languages are sufficiently closely related to allow some translation pairs to be identified on the basis of orthographic similarity.', 'our setting is completely unsupervised : we extract the bilingual lexicons from non - parallel monolingual corpora representing the same domain.', 'by contrast, most of the prior work depend on parallel data in the form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or document - aligned comparable corpora ( vulic and  #AUTHOR_TAG.', 'other prior work assumes access to additional resources or features, such as dependency parsers  #AUTHOR_TAG, temporal and web - based features ( irvine and callison -  #AUTHOR_TAG, or babelnet  #AUTHOR_TAG.', 'our approach consists of two stages : we first create a seed set of translation pairs, and then iteratively expand the lexicon with a bootstrapping procedure.', 'the seed set is constructed by identifying words with similar spelling ( cognates ).', 'we filter out non - translation pairs that look similar but differ in meaning ( false friends ) by imposing a relative - frequency constraint.', '']",0
"[' #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or']","['form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or document - aligned comparable']","['on parallel data in the form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or']","['objective of bilingual lexicon induction is to find translation pairs between two languages.', 'specifically, we aim to pair each word in the source vocabulary with its translation in the target vocabulary.', 'in this paper, we assume that the languages are sufficiently closely related to allow some translation pairs to be identified on the basis of orthographic similarity.', 'our setting is completely unsupervised : we extract the bilingual lexicons from non - parallel monolingual corpora representing the same domain.', 'by contrast, most of the prior work depend on parallel data in the form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or document - aligned comparable corpora ( vulic and  #AUTHOR_TAG.', 'other prior work assumes access to additional resources or features, such as dependency parsers  #AUTHOR_TAG, temporal and web - based features ( irvine and callison -  #AUTHOR_TAG, or babelnet  #AUTHOR_TAG.', 'our approach consists of two stages : we first create a seed set of translation pairs, and then iteratively expand the lexicon with a bootstrapping procedure.', 'the seed set is constructed by identifying words with similar spelling ( cognates ).', 'we filter out non - translation pairs that look similar but differ in meaning ( false friends ) by imposing a relative - frequency constraint.', '']",3
['of  #TAUTHOR_TAG'],['of  #TAUTHOR_TAG'],"['the source vocabulary, we must expand the seed lexicon to cover all such words.', 'we adapt the approach of  #TAUTHOR_TAG']","['our task is to find translations for each of a given set of source - language words, which we refer to as the source vocabulary, we must expand the seed lexicon to cover all such words.', 'we adapt the approach of  #TAUTHOR_TAG for learning a linear transformation between the source and target vector spaces to enable it to function given only a small, noisy seed.', 'we use word2vec  #AUTHOR_TAG a ) to map words in our source and target corpora to ndimensional vectors.', 'the mapping is derived in a strictly monolingual context of both the source and target languages.', 'while  #TAUTHOR_TAG derive the translation matrix using five thousand translation pairs obtained via google translate,', 'for c iterations do', 'train source - target tm t on']",3
['supervised word - vector - based method of  #TAUTHOR_TAG ( using the'],['supervised word - vector - based method of  #TAUTHOR_TAG ( using the'],"['of the supervised word - vector - based method of  #TAUTHOR_TAG ( using the same vectors as our method ), and the reported results of an em - based method of  #AUTHOR_TAG']","['this section we compare our method to two prior methods, our reimplementation of the supervised word - vector - based method of  #TAUTHOR_TAG ( using the same vectors as our method ), and the reported results of an em - based method of  #AUTHOR_TAG']",3
"['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the']","['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the']","['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the accuracy']","['evaluate the induced lexicon after 40 iterations of bidirectional bootstrapping by comparing it to the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the accuracy of an ed - itdist baseline method, which matches words in the source and target vocabularies.', 'we use an implementation of the hungarian algorithm 1  #AUTHOR_TAG to solve the minimum bipartite matching problem, where the edge cost for any source - target pair is the normalized edit distance between the two words.', 'the results in table 2 show that the method of  #TAUTHOR_TAG ( mik13 - auto ), represented by the first translation matrix derived on our automatically extracted the seed lexicon, performs well below the edit distance baseline.', 'by contrast, our bootstrapping approach ( bootstrapauto ) achieves an average accuracy of 85 % on the six datasets']",3
"['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the']","['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the']","['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the accuracy']","['evaluate the induced lexicon after 40 iterations of bidirectional bootstrapping by comparing it to the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the accuracy of an ed - itdist baseline method, which matches words in the source and target vocabularies.', 'we use an implementation of the hungarian algorithm 1  #AUTHOR_TAG to solve the minimum bipartite matching problem, where the edge cost for any source - target pair is the normalized edit distance between the two words.', 'the results in table 2 show that the method of  #TAUTHOR_TAG ( mik13 - auto ), represented by the first translation matrix derived on our automatically extracted the seed lexicon, performs well below the edit distance baseline.', 'by contrast, our bootstrapping approach ( bootstrapauto ) achieves an average accuracy of 85 % on the six datasets']",3
"[' #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or']","['form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or document - aligned comparable']","['on parallel data in the form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or']","['objective of bilingual lexicon induction is to find translation pairs between two languages.', 'specifically, we aim to pair each word in the source vocabulary with its translation in the target vocabulary.', 'in this paper, we assume that the languages are sufficiently closely related to allow some translation pairs to be identified on the basis of orthographic similarity.', 'our setting is completely unsupervised : we extract the bilingual lexicons from non - parallel monolingual corpora representing the same domain.', 'by contrast, most of the prior work depend on parallel data in the form of a small bitext  #AUTHOR_TAG, a gold seed lexicon  #TAUTHOR_TAG, or document - aligned comparable corpora ( vulic and  #AUTHOR_TAG.', 'other prior work assumes access to additional resources or features, such as dependency parsers  #AUTHOR_TAG, temporal and web - based features ( irvine and callison -  #AUTHOR_TAG, or babelnet  #AUTHOR_TAG.', 'our approach consists of two stages : we first create a seed set of translation pairs, and then iteratively expand the lexicon with a bootstrapping procedure.', 'the seed set is constructed by identifying words with similar spelling ( cognates ).', 'we filter out non - translation pairs that look similar but differ in meaning ( false friends ) by imposing a relative - frequency constraint.', '']",5
['of  #TAUTHOR_TAG'],['of  #TAUTHOR_TAG'],"['the source vocabulary, we must expand the seed lexicon to cover all such words.', 'we adapt the approach of  #TAUTHOR_TAG']","['our task is to find translations for each of a given set of source - language words, which we refer to as the source vocabulary, we must expand the seed lexicon to cover all such words.', 'we adapt the approach of  #TAUTHOR_TAG for learning a linear transformation between the source and target vector spaces to enable it to function given only a small, noisy seed.', 'we use word2vec  #AUTHOR_TAG a ) to map words in our source and target corpora to ndimensional vectors.', 'the mapping is derived in a strictly monolingual context of both the source and target languages.', 'while  #TAUTHOR_TAG derive the translation matrix using five thousand translation pairs obtained via google translate,', 'for c iterations do', 'train source - target tm t on']",5
['supervised word - vector - based method of  #TAUTHOR_TAG ( using the'],['supervised word - vector - based method of  #TAUTHOR_TAG ( using the'],"['of the supervised word - vector - based method of  #TAUTHOR_TAG ( using the same vectors as our method ), and the reported results of an em - based method of  #AUTHOR_TAG']","['this section we compare our method to two prior methods, our reimplementation of the supervised word - vector - based method of  #TAUTHOR_TAG ( using the same vectors as our method ), and the reported results of an em - based method of  #AUTHOR_TAG']",5
"['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the']","['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the']","['the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the accuracy']","['evaluate the induced lexicon after 40 iterations of bidirectional bootstrapping by comparing it to the lexicon after the first iteration in a single direction, which is equivalent to the method of  #TAUTHOR_TAG.', ' #AUTHOR_TAG, we also report the accuracy of an ed - itdist baseline method, which matches words in the source and target vocabularies.', 'we use an implementation of the hungarian algorithm 1  #AUTHOR_TAG to solve the minimum bipartite matching problem, where the edge cost for any source - target pair is the normalized edit distance between the two words.', 'the results in table 2 show that the method of  #TAUTHOR_TAG ( mik13 - auto ), represented by the first translation matrix derived on our automatically extracted the seed lexicon, performs well below the edit distance baseline.', 'by contrast, our bootstrapping approach ( bootstrapauto ) achieves an average accuracy of 85 % on the six datasets']",5
['of  #TAUTHOR_TAG'],['of  #TAUTHOR_TAG'],"['the source vocabulary, we must expand the seed lexicon to cover all such words.', 'we adapt the approach of  #TAUTHOR_TAG']","['our task is to find translations for each of a given set of source - language words, which we refer to as the source vocabulary, we must expand the seed lexicon to cover all such words.', 'we adapt the approach of  #TAUTHOR_TAG for learning a linear transformation between the source and target vector spaces to enable it to function given only a small, noisy seed.', 'we use word2vec  #AUTHOR_TAG a ) to map words in our source and target corpora to ndimensional vectors.', 'the mapping is derived in a strictly monolingual context of both the source and target languages.', 'while  #TAUTHOR_TAG derive the translation matrix using five thousand translation pairs obtained via google translate,', 'for c iterations do', 'train source - target tm t on']",4
"[':', 'unlike  #TAUTHOR_TAG, our']","['values :', 'unlike  #TAUTHOR_TAG, our']","['of the two cosine similarity values :', 'unlike  #TAUTHOR_TAG, our']",[' #TAUTHOR_TAG'],4
['##ag  #TAUTHOR_TAG and hp'],"['ltag  #TAUTHOR_TAG and hpsg  #AUTHOR_TAG, following an']",['##ag  #TAUTHOR_TAG and hp'],"['parsing techniques have been developed for lexicalized grammars such as lexicalized tree adjoining grammar ( ltag )  #AUTHOR_TAG, and head - driven phrase structure grammar ( hpsg )  #AUTHOR_TAG.', 'along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms  #AUTHOR_TAG van  #AUTHOR_TAG.', 'however, these realizations sometimes exhibit quite different performance in each grammar formalism  #AUTHOR_TAG.', 'if we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations.', 'this should also allow us to integrate the advantages of the realizations into one generic parsing technique, which yields the further advancement of the whole parsing community.', 'in this paper, we compare cfg filtering techniques for ltag  #TAUTHOR_TAG and hpsg  #AUTHOR_TAG, following an approach to parsing comparison among different grammar formalisms ).', 'the key idea of the approach is to use strongly equivalent grammars, which generate equivalent parse results for the same input, obtained by a grammar conversion as demonstrated by.', 'the parsers with cfg filtering predict possible parse trees by a cfg approximated from a given grammar.', 'comparison of those parsers are interesting because effective cfg filters allow us to bring the empirical time complexity of the parsers close to that of cfg parsing.', 'investigating the difference between the ways of context - free ( cf ) approximation of ltag and hpsg will thereby enlighten a way of further optimization for both techniques.', 'we performed a comparison between the existing cfg filtering techniques for ltag  #AUTHOR_TAG and hpsg  #AUTHOR_TAG, using strongly equivalent grammars obtained by converting ltags extracted from the penn treebank  #AUTHOR_TAG into hpsg - style.', 'we compared the parsers with respect to the size of the approximated cfg and its effectiveness as a filter']",5
['filtering  #TAUTHOR_TAG'],"['this section, we introduce a grammar conversion ) and cfg filtering  #TAUTHOR_TAG']","['this section, we introduce a grammar conversion ) and cfg filtering  #TAUTHOR_TAG']","['this section, we introduce a grammar conversion ) and cfg filtering  #TAUTHOR_TAG']",5
"['filtering techniques for ltag  #TAUTHOR_TAG,']","['cfg filtering techniques for ltag  #TAUTHOR_TAG,']","['cfg filtering techniques for ltag  #TAUTHOR_TAG, every branching of elementary trees in']","['cfg filtering techniques for ltag  #TAUTHOR_TAG, every branching of elementary trees in a given grammar is extracted as a cfg rule as shown in figure 1']",5
['the other work  #TAUTHOR_TAG cannot avoid'],['the other work  #TAUTHOR_TAG cannot avoid'],['the other work  #TAUTHOR_TAG cannot avoid generating invalid'],[' #TAUTHOR_TAG'],5
['the other work  #TAUTHOR_TAG cannot avoid'],['the other work  #TAUTHOR_TAG cannot avoid'],['the other work  #TAUTHOR_TAG cannot avoid generating invalid'],[' #TAUTHOR_TAG'],1
"['8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['fundamental properties of the language. most importantly', ', it is clear from some recent studies [ 8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['the analyses performed with co - occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for the success', 'of the model. therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. most importantly', ', it is clear from some recent studies [ 8,  #TAUTHOR_TAG ] that novel topological measurements', 'should be introduced to capture a wider range of linguistic features. many of the applications relying on network analysis outperform other traditional shallow strategies', '']",1
"['8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['fundamental properties of the language. most importantly', ', it is clear from some recent studies [ 8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['the analyses performed with co - occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for the success', 'of the model. therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. most importantly', ', it is clear from some recent studies [ 8,  #TAUTHOR_TAG ] that novel topological measurements', 'should be introduced to capture a wider range of linguistic features. many of the applications relying on network analysis outperform other traditional shallow strategies', '']",2
"['8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['fundamental properties of the language. most importantly', ', it is clear from some recent studies [ 8,  #TAUTHOR_TAG ] that novel topological measurements', '']","['the analyses performed with co - occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for the success', 'of the model. therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. most importantly', ', it is clear from some recent studies [ 8,  #TAUTHOR_TAG ] that novel topological measurements', 'should be introduced to capture a wider range of linguistic features. many of the applications relying on network analysis outperform other traditional shallow strategies', '']",5
"['.', 'examples of combinations of distinct strategies are described in  #TAUTHOR_TAG, [ 19 ] and [ 20 ].', 'in sum, the network framework has proven applicable to']","['same time in a hybrid way.', 'examples of combinations of distinct strategies are described in  #TAUTHOR_TAG, [ 19 ] and [ 20 ].', 'in sum, the network framework has proven applicable to']","[', the introduction of a hybrid classifier that could consider both linguistic ( deeper linguistic processing [ 18 ] ) and topological attributes at the same time in a hybrid way.', 'examples of combinations of distinct strategies are described in  #TAUTHOR_TAG, [ 19 ] and [ 20 ].', 'in sum, the network framework has proven applicable to']","['conception of measurements that are able to capture semantic aspects, since the topological measurements of co - occurrence networks capture mostly syntactic factors [ 8 ].', 'although such networks have proved useful in some semantical - dependent tasks ( see e. g. a topological approach to word sense disambiguation in [ 17 ] ), i believe that the creation of novel semantic - based measurements would improve the state of the art.', 'alternative forms to create the network could also be useful to grasp semantical features hidden in the topological space.', 'in ( ii ), i suggest, for example, the introduction of a hybrid classifier that could consider both linguistic ( deeper linguistic processing [ 18 ] ) and topological attributes at the same time in a hybrid way.', 'examples of combinations of distinct strategies are described in  #TAUTHOR_TAG, [ 19 ] and [ 20 ].', 'in sum, the network framework has proven applicable to understand the properties of the language and its applications, especially those related to the textual classification in several levels.', 'despite the limitations imposed by the restrict understanding of the mechanisms behind the classification, it is worth noting that the such representation remains entirely generic, being therefore useful to many tasks as well as for analyzing the evolution of languages, cultures and emotional trends.', 'for this reason, i believe that the use of complex networks in both practical and theoretical investigations shall yield novels insights into the mechanisms behind the language']",5
['.  #TAUTHOR_TAG. it is so'],['.  #TAUTHOR_TAG. it is so'],['zellers et al.  #TAUTHOR_TAG. it is so'],"['', 'by zellers et al.  #TAUTHOR_TAG. it is so because they always condition their rationale prediction', 'module on correct answer and as such it is bound to be better than a model which', '']",5
[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly learn'],[' #TAUTHOR_TAG'],5
"['0  #TAUTHOR_TAG.', 'vcr dataset contains 290k multiple choice']","['is vcr 1. 0  #TAUTHOR_TAG.', 'vcr dataset contains 290k multiple choice']","['dataset used in all experiments in this work is vcr 1. 0  #TAUTHOR_TAG.', 'vcr dataset contains 290k multiple choice questions which has been collected from 110k movie scenes.', 'the dataset provides object annotations, labels']","['dataset used in all experiments in this work is vcr 1. 0  #TAUTHOR_TAG.', 'vcr dataset contains 290k multiple choice questions which has been collected from 110k movie scenes.', 'the dataset provides object annotations, labels and classes for all objects in the image.', 'the questions, answers and rationales are quite open ended.', ""a lot of questions seek to ask'why?'making the task non - trivial""]",5
"['time loss plateaus.', 'we train the model using the whole vcr dataset for 20 epochs as was done in  #TAUTHOR_TAG to align with the baselines.', '']","['time loss plateaus.', 'we train the model using the whole vcr dataset for 20 epochs as was done in  #TAUTHOR_TAG to align with the baselines.', '']","['. 5 every time loss plateaus.', 'we train the model using the whole vcr dataset for 20 epochs as was done in  #TAUTHOR_TAG to align with the baselines.', '']","['use resnet50 [ 7 ] as backbone to extract image features in all experiments.', 'the rest of the model has been explained in secion 3.', 'for training, we use adam optimizer with a learning rate of 2e - 4 and weight decay of 1e - 4.', 'we use a learning rate strategy which reduces the learning rate by 0. 5 every time loss plateaus.', 'we train the model using the whole vcr dataset for 20 epochs as was done in  #TAUTHOR_TAG to align with the baselines.', 'we also use gradient clipping while training.', 'we use two losses for all our methods - answer prediction loss and rationale prediction loss, corresponding to each module.', ""all our results have been reported on the validation set of the dataset as test set labels are not available since it's an ongoing challenge."", 'we report test set results only for our best model which was submitted to the leaderboard.', 'we compare only this model with state - of - the - art.', 'we define certain terms which we are going to use henceforth : q - > a - answer prediction network, given question and image, qa - > r - rationale prediction network, given question, image and answer, q - > ar - rnswer and rationale both prediction network, given question and image']",5
['.  #TAUTHOR_TAG since they'],['al.  #TAUTHOR_TAG since they'],['.  #TAUTHOR_TAG since they feed'],[' #TAUTHOR_TAG'],5
['.  #TAUTHOR_TAG since they'],['al.  #TAUTHOR_TAG since they'],['.  #TAUTHOR_TAG since they feed'],[' #TAUTHOR_TAG'],5
['.  #TAUTHOR_TAG since they'],['al.  #TAUTHOR_TAG since they'],['.  #TAUTHOR_TAG since they feed'],[' #TAUTHOR_TAG'],5
"['', 'we also summarize results of other baselines reported in  #TAUTHOR_TAG']","['visual common sense reasoning task.', 'we also summarize results of other baselines reported in  #TAUTHOR_TAG']","['', 'we also summarize results of other baselines reported in  #TAUTHOR_TAG.', 'as can be seen from']","['', 'we conclude from this that gradient flow between the two q - > a and qa - > r modules enabled by our end - to - end joint learning scheme, helps the network learn better answers for better / correct reasons.', 'comparison with state - of - the - art : we provide comparison of our best model against state - of - the - art for visual common sense reasoning task.', 'we also summarize results of other baselines reported in  #TAUTHOR_TAG.', 'as can be seen from table 3, our gumbel - softmax method performs better than the baseline  #TAUTHOR_TAG a task.', 'for the qa - > r task, it is to be expected that our method should perform worse than the baseline as we are providing predicted answers, rather than the correct answer to the qa - > r module.', 'still, our approach performs comparably against the baseline on the task.', '']",5
['.  #TAUTHOR_TAG. it is so'],['.  #TAUTHOR_TAG. it is so'],['zellers et al.  #TAUTHOR_TAG. it is so'],"['', 'by zellers et al.  #TAUTHOR_TAG. it is so because they always condition their rationale prediction', 'module on correct answer and as such it is bound to be better than a model which', '']",0
['.  #TAUTHOR_TAG. it is so'],['.  #TAUTHOR_TAG. it is so'],['zellers et al.  #TAUTHOR_TAG. it is so'],"['', 'by zellers et al.  #TAUTHOR_TAG. it is so because they always condition their rationale prediction', 'module on correct answer and as such it is bound to be better than a model which', '']",0
['.  #TAUTHOR_TAG. it is so'],['.  #TAUTHOR_TAG. it is so'],['zellers et al.  #TAUTHOR_TAG. it is so'],"['', 'by zellers et al.  #TAUTHOR_TAG. it is so because they always condition their rationale prediction', 'module on correct answer and as such it is bound to be better than a model which', '']",0
[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly learn'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly learn'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly learn'],[' #TAUTHOR_TAG'],0
[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly learn'],[' #TAUTHOR_TAG'],0
['.  #TAUTHOR_TAG since they'],['al.  #TAUTHOR_TAG since they'],['.  #TAUTHOR_TAG since they feed'],[' #TAUTHOR_TAG'],0
['.  #TAUTHOR_TAG. it is so'],['.  #TAUTHOR_TAG. it is so'],['zellers et al.  #TAUTHOR_TAG. it is so'],"['', 'by zellers et al.  #TAUTHOR_TAG. it is so because they always condition their rationale prediction', 'module on correct answer and as such it is bound to be better than a model which', '']",4
[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly learn'],[' #TAUTHOR_TAG'],4
['.  #TAUTHOR_TAG since they'],['al.  #TAUTHOR_TAG since they'],['.  #TAUTHOR_TAG since they feed'],[' #TAUTHOR_TAG'],4
"['baseline  #TAUTHOR_TAG, which gives the']","['baseline  #TAUTHOR_TAG, which gives the']","['the rationale prediction module, unlike the baseline  #TAUTHOR_TAG, which gives']","['##max : our softmax approach performs well on q - > a task and acheives best result on qa - > r task among the four approaches we tried.', ""it is to be noted that for the qa - > r task, we don't provide the correct answer as input to the model."", 'rather, a weighted average of answers ( according to probabilities predicted by q - > a module ) is provided to the rationale prediction module, unlike the baseline  #TAUTHOR_TAG, which gives the correct answer as input.', 'gumbel - softmax : for gumbel - softmax, we anneal the temperature τ from 5 to 1 for 10 epochs and then keep it constant at 1.', 'as can be seen from 1, this model gives the best result among all the approaches we used.', 'again, we provided the gumbel - softmax weighted average of answer representation to the rationale prediction module rather than the correct answer as was used in the baseline.', 'reinforcement learning sampling : surprisingly, the rl sampling based method performed poorly as compared to softmax and gumbel - softmax based method.', 'the reason may be attributed to small number of samples being drawn for the expectation loss calculation.', 'we were constrained by resource availability to limit the number of drawn samples to only 64 in each iteration.', 'we leave this open to further direct cross entropy : this method performs the worst.', 'a plausible reason could be that the model fails to segregate subtle changes presented to it by the same rationale with different answers.', 'we conclude that with the open - ended nature of rationales and answers and close similarity between them, the task becomes too difficult for the model, when asked to choose from sixteen possible choices']",4
"['', 'we also summarize results of other baselines reported in  #TAUTHOR_TAG']","['visual common sense reasoning task.', 'we also summarize results of other baselines reported in  #TAUTHOR_TAG']","['', 'we also summarize results of other baselines reported in  #TAUTHOR_TAG.', 'as can be seen from']","['', 'we conclude from this that gradient flow between the two q - > a and qa - > r modules enabled by our end - to - end joint learning scheme, helps the network learn better answers for better / correct reasons.', 'comparison with state - of - the - art : we provide comparison of our best model against state - of - the - art for visual common sense reasoning task.', 'we also summarize results of other baselines reported in  #TAUTHOR_TAG.', 'as can be seen from table 3, our gumbel - softmax method performs better than the baseline  #TAUTHOR_TAG a task.', 'for the qa - > r task, it is to be expected that our method should perform worse than the baseline as we are providing predicted answers, rather than the correct answer to the qa - > r module.', 'still, our approach performs comparably against the baseline on the task.', '']",4
[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly'],[' #TAUTHOR_TAG propose to jointly learn'],[' #TAUTHOR_TAG'],6
['. suggestion detection :  #TAUTHOR_TAG'],['. suggestion detection :  #TAUTHOR_TAG'],"['. suggestion detection :  #TAUTHOR_TAG pointed out that wish is a broader', 'category, which might not', 'bear suggestions every time.']","['', ""##n't so big, it wouldn't be nearly so fun. mood and modality"", ': modality is a grammatical category that allows the expression of aspects related to the attitude of a speaker towards his statement,', 'in terms of degree of certainty, reliability, subjectivity, sources of information, and perspective  #AUTHOR_TAG. subjunctive mood originated', ""from the typological studies of modality  #AUTHOR_TAG. some works equate its presence with'counterfactuality' #AUTHOR_TAG, while some do not  #AUTHOR_TAG. other concepts like'event modality ','irrealis' #AUTHOR_TAG,"", 'have definitions similar to that of subjunctive mood.  #AUTHOR_TAG studied modality and negation for french', 'language, with an objective to examine its effect on sentiment polarity.  #AUTHOR_TAG performed sentiment analysis on conditional sentences. our objective however', 'is inclined towards wish and suggestion detection, rather than sentiment analysis. wish detection :  #AUTHOR_TAG performed wish detection on datasets obtained from', 'political discussion forums and product reviews. they automatically extracted sentence templates from a corpus of new year wishes, and used them as features with a statistical classifier. suggestion detection :  #TAUTHOR_TAG pointed out that wish is a broader', 'category, which might not', 'bear suggestions every time. they performed suggestion detection, where they focussed only on suggestion bearing wishes, and used manually formulated syntactic patterns for their detection.  #AUTHOR_TAG also extracted suggestions from', 'product reviews and used syntactico - semantic patterns for suggestion detection.', 'none of these works on suggestion detection used a statistical classifier.', 'none of these works aligned the problem of wish and suggestion detection with subjunctive mood, or identified features related to it. wish and suggestion detection remain young', 'problems, and our work contributes towards the same']",0
['. suggestion detection :  #TAUTHOR_TAG'],['. suggestion detection :  #TAUTHOR_TAG'],"['. suggestion detection :  #TAUTHOR_TAG pointed out that wish is a broader', 'category, which might not', 'bear suggestions every time.']","['', ""##n't so big, it wouldn't be nearly so fun. mood and modality"", ': modality is a grammatical category that allows the expression of aspects related to the attitude of a speaker towards his statement,', 'in terms of degree of certainty, reliability, subjectivity, sources of information, and perspective  #AUTHOR_TAG. subjunctive mood originated', ""from the typological studies of modality  #AUTHOR_TAG. some works equate its presence with'counterfactuality' #AUTHOR_TAG, while some do not  #AUTHOR_TAG. other concepts like'event modality ','irrealis' #AUTHOR_TAG,"", 'have definitions similar to that of subjunctive mood.  #AUTHOR_TAG studied modality and negation for french', 'language, with an objective to examine its effect on sentiment polarity.  #AUTHOR_TAG performed sentiment analysis on conditional sentences. our objective however', 'is inclined towards wish and suggestion detection, rather than sentiment analysis. wish detection :  #AUTHOR_TAG performed wish detection on datasets obtained from', 'political discussion forums and product reviews. they automatically extracted sentence templates from a corpus of new year wishes, and used them as features with a statistical classifier. suggestion detection :  #TAUTHOR_TAG pointed out that wish is a broader', 'category, which might not', 'bear suggestions every time. they performed suggestion detection, where they focussed only on suggestion bearing wishes, and used manually formulated syntactic patterns for their detection.  #AUTHOR_TAG also extracted suggestions from', 'product reviews and used syntactico - semantic patterns for suggestion detection.', 'none of these works on suggestion detection used a statistical classifier.', 'none of these works aligned the problem of wish and suggestion detection with subjunctive mood, or identified features related to it. wish and suggestion detection remain young', 'problems, and our work contributes towards the same']",0
['. suggestion detection :  #TAUTHOR_TAG'],['. suggestion detection :  #TAUTHOR_TAG'],"['. suggestion detection :  #TAUTHOR_TAG pointed out that wish is a broader', 'category, which might not', 'bear suggestions every time.']","['', ""##n't so big, it wouldn't be nearly so fun. mood and modality"", ': modality is a grammatical category that allows the expression of aspects related to the attitude of a speaker towards his statement,', 'in terms of degree of certainty, reliability, subjectivity, sources of information, and perspective  #AUTHOR_TAG. subjunctive mood originated', ""from the typological studies of modality  #AUTHOR_TAG. some works equate its presence with'counterfactuality' #AUTHOR_TAG, while some do not  #AUTHOR_TAG. other concepts like'event modality ','irrealis' #AUTHOR_TAG,"", 'have definitions similar to that of subjunctive mood.  #AUTHOR_TAG studied modality and negation for french', 'language, with an objective to examine its effect on sentiment polarity.  #AUTHOR_TAG performed sentiment analysis on conditional sentences. our objective however', 'is inclined towards wish and suggestion detection, rather than sentiment analysis. wish detection :  #AUTHOR_TAG performed wish detection on datasets obtained from', 'political discussion forums and product reviews. they automatically extracted sentence templates from a corpus of new year wishes, and used them as features with a statistical classifier. suggestion detection :  #TAUTHOR_TAG pointed out that wish is a broader', 'category, which might not', 'bear suggestions every time. they performed suggestion detection, where they focussed only on suggestion bearing wishes, and used manually formulated syntactic patterns for their detection.  #AUTHOR_TAG also extracted suggestions from', 'product reviews and used syntactico - semantic patterns for suggestion detection.', 'none of these works on suggestion detection used a statistical classifier.', 'none of these works aligned the problem of wish and suggestion detection with subjunctive mood, or identified features related to it. wish and suggestion detection remain young', 'problems, and our work contributes towards the same']",0
"['1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['are annotated as wishes.', 'table 1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['are the datasets which we use for our experiments.', '• wish detection oxford dictionary defines the noun wish as, a desire or hope for something to happen.', ' #AUTHOR_TAG follow this definition of wish and provide manually annotated datasets, where each sentence is labelled as wish or non - wish.', 'following two datasets are made available : a. political discussions : 6379 sentences, out of which 34 % are annotated wishes.', 'b. product reviews : 1235 sentences, out of which 12 % are annotated as wishes.', 'table 1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with an objective to extract suggestions for improvements.', 'they considered suggestions as a subset of wishes, and thus retained the labels of only suggestion bearing wishes.', 'they also annotated additional product reviews, but their data is not available for open research.', '• suggestion detection product reviews ( new ) : we re - annotated the product review dataset from  #AUTHOR_TAG, for suggestions.', '']",0
['. suggestion detection :  #TAUTHOR_TAG'],['. suggestion detection :  #TAUTHOR_TAG'],"['. suggestion detection :  #TAUTHOR_TAG pointed out that wish is a broader', 'category, which might not', 'bear suggestions every time.']","['', ""##n't so big, it wouldn't be nearly so fun. mood and modality"", ': modality is a grammatical category that allows the expression of aspects related to the attitude of a speaker towards his statement,', 'in terms of degree of certainty, reliability, subjectivity, sources of information, and perspective  #AUTHOR_TAG. subjunctive mood originated', ""from the typological studies of modality  #AUTHOR_TAG. some works equate its presence with'counterfactuality' #AUTHOR_TAG, while some do not  #AUTHOR_TAG. other concepts like'event modality ','irrealis' #AUTHOR_TAG,"", 'have definitions similar to that of subjunctive mood.  #AUTHOR_TAG studied modality and negation for french', 'language, with an objective to examine its effect on sentiment polarity.  #AUTHOR_TAG performed sentiment analysis on conditional sentences. our objective however', 'is inclined towards wish and suggestion detection, rather than sentiment analysis. wish detection :  #AUTHOR_TAG performed wish detection on datasets obtained from', 'political discussion forums and product reviews. they automatically extracted sentence templates from a corpus of new year wishes, and used them as features with a statistical classifier. suggestion detection :  #TAUTHOR_TAG pointed out that wish is a broader', 'category, which might not', 'bear suggestions every time. they performed suggestion detection, where they focussed only on suggestion bearing wishes, and used manually formulated syntactic patterns for their detection.  #AUTHOR_TAG also extracted suggestions from', 'product reviews and used syntactico - semantic patterns for suggestion detection.', 'none of these works on suggestion detection used a statistical classifier.', 'none of these works aligned the problem of wish and suggestion detection with subjunctive mood, or identified features related to it. wish and suggestion detection remain young', 'problems, and our work contributes towards the same']",1
"['1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['are annotated as wishes.', 'table 1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['are the datasets which we use for our experiments.', '• wish detection oxford dictionary defines the noun wish as, a desire or hope for something to happen.', ' #AUTHOR_TAG follow this definition of wish and provide manually annotated datasets, where each sentence is labelled as wish or non - wish.', 'following two datasets are made available : a. political discussions : 6379 sentences, out of which 34 % are annotated wishes.', 'b. product reviews : 1235 sentences, out of which 12 % are annotated as wishes.', 'table 1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with an objective to extract suggestions for improvements.', 'they considered suggestions as a subset of wishes, and thus retained the labels of only suggestion bearing wishes.', 'they also annotated additional product reviews, but their data is not available for open research.', '• suggestion detection product reviews ( new ) : we re - annotated the product review dataset from  #AUTHOR_TAG, for suggestions.', '']",1
"['1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['are annotated as wishes.', 'table 1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with']","['are the datasets which we use for our experiments.', '• wish detection oxford dictionary defines the noun wish as, a desire or hope for something to happen.', ' #AUTHOR_TAG follow this definition of wish and provide manually annotated datasets, where each sentence is labelled as wish or non - wish.', 'following two datasets are made available : a. political discussions : 6379 sentences, out of which 34 % are annotated wishes.', 'b. product reviews : 1235 sentences, out of which 12 % are annotated as wishes.', 'table 1 presents some examples from these datasets.', ' #TAUTHOR_TAG worked on product review dataset of the wish corpus, with an objective to extract suggestions for improvements.', 'they considered suggestions as a subset of wishes, and thus retained the labels of only suggestion bearing wishes.', 'they also annotated additional product reviews, but their data is not available for open research.', '• suggestion detection product reviews ( new ) : we re - annotated the product review dataset from  #AUTHOR_TAG, for suggestions.', '']",3
"[', urge, require ; 28 different verbs were obtained.', ' #TAUTHOR_TAG also used a similar but much smaller subset { love, like, prefer and suggest } in their rules']","['members have common syntactic and semantic properties.', 'we collect all members of the verbnet verb classes advice, wish, want, urge, require ; 28 different verbs were obtained.', ' #TAUTHOR_TAG also used a similar but much smaller subset { love, like, prefer and suggest } in their rules']","[', want, urge, require ; 28 different verbs were obtained.', ' #TAUTHOR_TAG also used a similar but much smaller subset { love, like, prefer and suggest } in their rules']","[""condition indicator'if': this is a binary feature, whose value depends on the presence and absence of'if'in a sentence."", '• suggestion and wish verbs : we collect some suggestion and wish indicator verbs observed in the subjunctive mood dataset.', 'we then expand this set of verbs by using verbnet 3. 2  #AUTHOR_TAG.', 'verbnet is a wide coverage verb lexicon, which places verbs into classes whose members have common syntactic and semantic properties.', 'we collect all members of the verbnet verb classes advice, wish, want, urge, require ; 28 different verbs were obtained.', ' #TAUTHOR_TAG also used a similar but much smaller subset { love, like, prefer and suggest } in their rules']",3
"['direct specialization', 'transfer based on the composition of the crosslingual projection and the post - specialization function  #TAUTHOR_TAG, with substantial gains']","['direct specialization', 'transfer based on the composition of the crosslingual projection and the post - specialization function  #TAUTHOR_TAG, with substantial gains across all experimental setups.', 'in order to boost the']","['specialization transfer method consistently outperforms the direct specialization', 'transfer based on the composition of the crosslingual projection and the post - specialization function  #TAUTHOR_TAG, with substantial gains']","['', 'language constraints. we verify the usefulness of our specialization transfer method in the intrinsic word similarity task for 8 target languages, followed by 3 downstream tasks in 5 languages : lexical simplification, dialog state tracking, and semantic textual similarity. we observe', 'large improvements over purely distributional word vectors for all target languages and in all tasks. moreover, we show that the proposed specialization transfer method consistently outperforms the direct specialization', 'transfer based on the composition of the crosslingual projection and the post - specialization function  #TAUTHOR_TAG, with substantial gains across all experimental setups.', 'in order to boost the integration of external lexical knowledge into distributional models beyond english, we will release our code and lists of wordnet - style lexical relations generated by', 'our transfer method for all target languages at : https : / / github. com / cambridgeltl / xling - postspec']",0
['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell'],['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in'],['- art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingu'],"['language constraints. this allows for monolingual application of retrofitting or post - specialization in the target language. our experiments show that the proposed specialization transfer via lexical relation induction ( clsri ) outperforms the previous state - of - the - art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingual semantic specialization our goal is to fine - tune the distributional vectors of a target language l t leveraging', 'structured knowledge in the form of lexical constraints, available only for a resource - rich source language l s.', '']",0
['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell'],['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in'],['- art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingu'],"['language constraints. this allows for monolingual application of retrofitting or post - specialization in the target language. our experiments show that the proposed specialization transfer via lexical relation induction ( clsri ) outperforms the previous state - of - the - art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingual semantic specialization our goal is to fine - tune the distributional vectors of a target language l t leveraging', 'structured knowledge in the form of lexical constraints, available only for a resource - rich source language l s.', '']",0
"['on semantic specialization  #TAUTHOR_TAG, inter ali']","['on semantic specialization  #TAUTHOR_TAG, inter alia ) is']","['standard language understanding evaluation task used in prior work on semantic specialization  #TAUTHOR_TAG, inter alia ) is dialog state tracking (']","['standard language understanding evaluation task used in prior work on semantic specialization  #TAUTHOR_TAG, inter alia ) is dialog state tracking ( dst )  #AUTHOR_TAG.', 'a dst model is a fundamental building block of statistical modular dialogue systems  #AUTHOR_TAG.', ""its task is to maintain the information of the user's goals during a multi - turn conversation by updating the dialog belief state at each turn."", 'distinguishing true similarity as captured in specialized word vectors from broader relatedness is crucial for dst to succeed : e. g., a dialog system for restaurant bookings should not confuse the western and the eastern part of town, or thai and japanese cuisine.', 'evaluation setup.', 'to be directly comparable to prior work when evaluating the effects of specialized word embeddings on dst, we rely on the neural belief tracker ( nbt ) v2 : it is a fully statistical dst model that operates solely on the basis of pretrained word vectors, and they are pivotal to its performance.', '15 again following prior work, our evaluation data come from the multilingual wizard - of - oz ( woz ) dataset, which is available in two target languages : german and italian.', 'it contains 1, 200 dialogues split into training ( 600 dialogues ), development ( 200 ), and test data ( 400 ).', 'we report the standard dst metric of joint goal accuracy : it refers to the proportion of dialog turns where all the users goals were correctly identified']",0
"[' #TAUTHOR_TAG, vectors specialized for semantic similarity']","[' #TAUTHOR_TAG, vectors specialized for semantic similarity']","['the results.', 'first, as already confirmed in prior work  #TAUTHOR_TAG, vectors specialized for semantic similarity']","['', 'first, as already confirmed in prior work  #TAUTHOR_TAG, vectors specialized for semantic similarity are indeed important for dst : we observe improvements with all specialized vectors.', '']",0
"[' #TAUTHOR_TAG, retrofitting ( clsri - ar ) and the cross - lingual post - specialization transfer ( x - ps ) are substantially better in']","[' #TAUTHOR_TAG, retrofitting ( clsri - ar ) and the cross - lingual post - specialization transfer ( x - ps ) are substantially better in']","['.', 'the results are reported in table 3.', 'as shown in previous work  #TAUTHOR_TAG, retrofitting ( clsri - ar ) and the cross - lingual post - specialization transfer ( x - ps ) are substantially better in']","['simplification ( ls ) aims to automatically replace complex words ( i. e., specialized terms, words used less frequently and known to fewer speakers ) with their simpler in - context synonyms : the simplified text must be grammatical and retain the meaning of the original text.', 'lexical simplification critically depends on discerning semantic similarity from other types of semantic relatedness, as the meaning of the original text might not be preserved otherwise ( e. g., "" the orange automobile crashed. "" vs. "" the orange wheel crashed. "" ).', 'evaluation setup.', 'to evaluate the effects of similarity - based specialization on ls, we employ light - ls ( glavas andstajner, 2015 ), a languageagnostic ls tool that makes simplifications based on word similarities in a given vector space.', 'the quality of similarity - based information encoded in the vector space encode is thus expected to directly correlate with the performance of light - ls.', 'we use ls datasets for italian ( it )  #AUTHOR_TAG, spanish ( es )  #AUTHOR_TAG, and portuguese ( pt )  #AUTHOR_TAG to evaluate the specialized spaces in those languages.', 'we rely on the standard ls evaluation metric of accuracy  #AUTHOR_TAG glavas andstajner, 2015 ) : it quantifies both the quality and frequency of replacements as a number of correct simplifications divided by the total number of complex words.', 'results and analysis.', 'the results are reported in table 3.', 'as shown in previous work  #TAUTHOR_TAG, retrofitting ( clsri - ar ) and the cross - lingual post - specialization transfer ( x - ps ) are substantially better in the ls task than the original distributional space.', 'however, our full clsri - ps model results in substantial boosts in the ls task ( 13 - 17 % ) over the previous best reported scores of x - ps as well as over clsri - ar']",0
"['direct specialization', 'transfer based on the composition of the crosslingual projection and the post - specialization function  #TAUTHOR_TAG, with substantial gains']","['direct specialization', 'transfer based on the composition of the crosslingual projection and the post - specialization function  #TAUTHOR_TAG, with substantial gains across all experimental setups.', 'in order to boost the']","['specialization transfer method consistently outperforms the direct specialization', 'transfer based on the composition of the crosslingual projection and the post - specialization function  #TAUTHOR_TAG, with substantial gains']","['', 'language constraints. we verify the usefulness of our specialization transfer method in the intrinsic word similarity task for 8 target languages, followed by 3 downstream tasks in 5 languages : lexical simplification, dialog state tracking, and semantic textual similarity. we observe', 'large improvements over purely distributional word vectors for all target languages and in all tasks. moreover, we show that the proposed specialization transfer method consistently outperforms the direct specialization', 'transfer based on the composition of the crosslingual projection and the post - specialization function  #TAUTHOR_TAG, with substantial gains across all experimental setups.', 'in order to boost the integration of external lexical knowledge into distributional models beyond english, we will release our code and lists of wordnet - style lexical relations generated by', 'our transfer method for all target languages at : https : / / github. com / cambridgeltl / xling - postspec']",4
['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell'],['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in'],['- art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingu'],"['language constraints. this allows for monolingual application of retrofitting or post - specialization in the target language. our experiments show that the proposed specialization transfer via lexical relation induction ( clsri ) outperforms the previous state - of - the - art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingual semantic specialization our goal is to fine - tune the distributional vectors of a target language l t leveraging', 'structured knowledge in the form of lexical constraints, available only for a resource - rich source language l s.', '']",4
['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell'],['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in'],['- art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingu'],"['language constraints. this allows for monolingual application of retrofitting or post - specialization in the target language. our experiments show that the proposed specialization transfer via lexical relation induction ( clsri ) outperforms the previous state - of - the - art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingual semantic specialization our goal is to fine - tune the distributional vectors of a target language l t leveraging', 'structured knowledge in the form of lexical constraints, available only for a resource - rich source language l s.', '']",4
"['in line with and  #TAUTHOR_TAG,']","['in line with and  #TAUTHOR_TAG,']","['in line with and  #TAUTHOR_TAG, we implement this']",[' #TAUTHOR_TAG'],4
"['of  #TAUTHOR_TAG and', '']","['- overlapping configurations for the baseline model of  #TAUTHOR_TAG and', '']","['of  #TAUTHOR_TAG and', '']","['batch size', 'of 48 ( including negative examples ) for a maximum of 10 iterations. early stopping was implemented', 'based on the f 1 score on a development set comprising 5 % of the source language constraints. the hidden', 'layer dimensionality is 300, and we use k = 5 specialization sub - tensors. regarding the quality of the stm predictions, the best models achieve an f 1 score of 81. 4 on attract constraints, and an f 1 score of 66. 9 on repel constraints. 7 ar and post', '- specialization. we retain the exact hyper - parameter configuration for attract - repel from the original work : δ a = 0. 6, δ r = 0. 0,', 'λ p = 10 −9. adagrad', ' #AUTHOR_TAG is employed', 'to optimize the model parameters for 5 epochs, feeding batches of size | b a | = | b r | = 50, again as in prior work. of skip - gram with negative sampling (', ""sgns ) that builds representations for each word's constituent character n - grams and sums them up to obtain the"", ""entire word's representation. 6 https : / / github. com / facebook"", '##research / fasttext / tree / master / alignment owing to the difference in the amount of supervision, the post - specialization model has partially non - overlapping configurations for the baseline model of  #TAUTHOR_TAG and', '']",4
"['baseline method for cross - lingual specialization  #TAUTHOR_TAG.', 'in']","['baseline method for cross - lingual specialization  #TAUTHOR_TAG.', 'in']","['the distributional vectors and the baseline method for cross - lingual specialization  #TAUTHOR_TAG.', 'in all languages but two ( de and ru ) even the clsri - ar model without post - specialization is superior to']","['', 'results and analysis.', 'we summarize the results for word similarity in table 1.', 'the full clsri - ps model outperforms both the distributional vectors and the baseline method for cross - lingual specialization  #TAUTHOR_TAG.', 'in all languages but two ( de and ru ) even the clsri - ar model without post - specialization is superior to both baselines, and the post - specialization step additionally improves the results, supporting the findings from prior work.', 'crucially, the performance of clsri - ps remains strong even for distant language pairs ( e. g., for en - he, en - tr or en - fi ), whereas the x - ps baseline shows a drop in performance for such cases.', 'we suspect that it is because the success of our clsri - ps method depends less on the quality of the underlying shared cross - lingual vector space, which is known to deteriorate for more distant language pairs ( søgaard et al., 2018 ;']",4
['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell'],['specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in'],['- art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingu'],"['language constraints. this allows for monolingual application of retrofitting or post - specialization in the target language. our experiments show that the proposed specialization transfer via lexical relation induction ( clsri ) outperforms the previous state - of - the - art specialization transfer method of  #TAUTHOR_TAG 3 methodology clsri in a nutshell. in cross - lingual semantic specialization our goal is to fine - tune the distributional vectors of a target language l t leveraging', 'structured knowledge in the form of lexical constraints, available only for a resource - rich source language l s.', '']",5
"['in line with and  #TAUTHOR_TAG,']","['in line with and  #TAUTHOR_TAG,']","['in line with and  #TAUTHOR_TAG, we implement this']",[' #TAUTHOR_TAG'],3
"['of  #TAUTHOR_TAG and', '']","['- overlapping configurations for the baseline model of  #TAUTHOR_TAG and', '']","['of  #TAUTHOR_TAG and', '']","['batch size', 'of 48 ( including negative examples ) for a maximum of 10 iterations. early stopping was implemented', 'based on the f 1 score on a development set comprising 5 % of the source language constraints. the hidden', 'layer dimensionality is 300, and we use k = 5 specialization sub - tensors. regarding the quality of the stm predictions, the best models achieve an f 1 score of 81. 4 on attract constraints, and an f 1 score of 66. 9 on repel constraints. 7 ar and post', '- specialization. we retain the exact hyper - parameter configuration for attract - repel from the original work : δ a = 0. 6, δ r = 0. 0,', 'λ p = 10 −9. adagrad', ' #AUTHOR_TAG is employed', 'to optimize the model parameters for 5 epochs, feeding batches of size | b a | = | b r | = 50, again as in prior work. of skip - gram with negative sampling (', ""sgns ) that builds representations for each word's constituent character n - grams and sums them up to obtain the"", ""entire word's representation. 6 https : / / github. com / facebook"", '##research / fasttext / tree / master / alignment owing to the difference in the amount of supervision, the post - specialization model has partially non - overlapping configurations for the baseline model of  #TAUTHOR_TAG and', '']",3
"['of  #TAUTHOR_TAG and', '']","['- overlapping configurations for the baseline model of  #TAUTHOR_TAG and', '']","['of  #TAUTHOR_TAG and', '']","['batch size', 'of 48 ( including negative examples ) for a maximum of 10 iterations. early stopping was implemented', 'based on the f 1 score on a development set comprising 5 % of the source language constraints. the hidden', 'layer dimensionality is 300, and we use k = 5 specialization sub - tensors. regarding the quality of the stm predictions, the best models achieve an f 1 score of 81. 4 on attract constraints, and an f 1 score of 66. 9 on repel constraints. 7 ar and post', '- specialization. we retain the exact hyper - parameter configuration for attract - repel from the original work : δ a = 0. 6, δ r = 0. 0,', 'λ p = 10 −9. adagrad', ' #AUTHOR_TAG is employed', 'to optimize the model parameters for 5 epochs, feeding batches of size | b a | = | b r | = 50, again as in prior work. of skip - gram with negative sampling (', ""sgns ) that builds representations for each word's constituent character n - grams and sums them up to obtain the"", ""entire word's representation. 6 https : / / github. com / facebook"", '##research / fasttext / tree / master / alignment owing to the difference in the amount of supervision, the post - specialization model has partially non - overlapping configurations for the baseline model of  #TAUTHOR_TAG and', '']",3
"[' #TAUTHOR_TAG, vectors specialized for semantic similarity']","[' #TAUTHOR_TAG, vectors specialized for semantic similarity']","['the results.', 'first, as already confirmed in prior work  #TAUTHOR_TAG, vectors specialized for semantic similarity']","['', 'first, as already confirmed in prior work  #TAUTHOR_TAG, vectors specialized for semantic similarity are indeed important for dst : we observe improvements with all specialized vectors.', '']",7
['models only at parsing time  #TAUTHOR_TAG'],"[""attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG""]","["" #AUTHOR_TAG attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG."", 'in']","['ensemble models have been proposed for the parsing of syntactic dependencies.', ""these approaches can generally be classified in two categories : models that integrate base parsers at learning time, e. g., using stacking ( nivre and mc  #AUTHOR_TAG attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG."", '']",0
"['reparsing  #TAUTHOR_TAG.', '6 however, it is not clear that this step is necessary']","['reparsing  #TAUTHOR_TAG.', '6 however, it is not clear that this step is necessary.', 'in other words,']","['reparsing  #TAUTHOR_TAG.', '6 however, it is not clear that this step is necessary']","['guarantee that the resulting dependency tree is well - formed, most previous work used the dynamic programming algorithm of  #AUTHOR_TAG for reparsing  #TAUTHOR_TAG.', '6 however, it is not clear that this step is necessary.', 'in other words, how many sentences are not wellformed if one uses a simple word - by - word voting scheme?', 'to answer this, we analyzed the output of our best word - by - word voting scheme ( six base parsers weighted by the pos of the modifier ).', 'the results for both in - domain and out - of - domain testing corpora are listed in table 4.', '']",0
['models only at parsing time  #TAUTHOR_TAG'],"[""attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG""]","["" #AUTHOR_TAG attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG."", 'in']","['ensemble models have been proposed for the parsing of syntactic dependencies.', ""these approaches can generally be classified in two categories : models that integrate base parsers at learning time, e. g., using stacking ( nivre and mc  #AUTHOR_TAG attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG."", '']",3
['models only at parsing time  #TAUTHOR_TAG'],"[""attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG""]","["" #AUTHOR_TAG attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG."", 'in']","['ensemble models have been proposed for the parsing of syntactic dependencies.', ""these approaches can generally be classified in two categories : models that integrate base parsers at learning time, e. g., using stacking ( nivre and mc  #AUTHOR_TAG attardi and dell' #AUTHOR_TAG, and approaches that combine independently - trained models only at parsing time  #TAUTHOR_TAG."", '']",5
"['deep learning methods reach better performance  #TAUTHOR_TAG.', 'in this paper, we propose to']","['deep learning methods reach better performance  #TAUTHOR_TAG.', 'in this paper, we propose to']","['art deep learning methods reach better performance  #TAUTHOR_TAG.', 'in this paper, we propose to combine string kernels ( low']","['essay scoring ( aes ) is the task of assigning grades to essays written in an educational setting, using a computer - based system with natural language processing capabilities.', 'the aim of designing such systems is to reduce the involvement of human graders as far as possible.', 'aes is a challenging task as it relies on grammar as well as semantics, pragmatics and discourse  #AUTHOR_TAG.', 'although traditional aes methods typically rely on handcrafted features  #AUTHOR_TAG, recent results indicate that state - of - the - art deep learning methods reach better performance  #TAUTHOR_TAG.', 'in this paper, we propose to combine string kernels ( low - level character n - gram features ) and word embeddings ( high - level semantic features ) to obtain state - of - the - art aes results.', 'since recent methods based on string kernels have demonstrated remarkable performance in various text classification tasks ranging from authorship identification  #AUTHOR_TAG and sentiment analysis ( gimenez - perez et al., 2017 ; to native language identification  #AUTHOR_TAG dialect identification, we believe that string kernels can reach equally good results in aes.', 'to the best of our knowledge, string kernels have never been used for this task.', 'as string kernels are a simple approach that relies solely on character n - grams as features, it is fairly obvious that such an approach will not to cover several aspects ( e. g. : semantics, discourse ) required for the aes task.', 'to solve this problem, we propose to combine string kernels with a recent approach based on word embeddings, namely the bag - of - super - wordembeddings ( boswe ).', 'to our knowledge, this is the first successful attempt to combine string kernels and word embeddings.', 'we evaluate our approach on the automated student assessment prize data set, in both in - domain and cross - domain settings.', '']",0
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",0
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",5
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",5
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",5
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",5
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",5
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",5
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",3
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",3
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",3
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",3
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",3
"['##art', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores']","['theart', 'methods  #TAUTHOR_TAG. we observe that the difference between our best qwk scores and the other approaches are sometimes much higher in the', 'cross - domain setting than in the in - domain setting. we particularly', 'notice that the difference from  #AUTHOR_TAG when n t = 0 is always higher than 10 %.', 'our highest improvement ( more than 54 %, from 0. 187 to 0. 728 ) over  #AUTHOR_TAG is recorded for the pair 5→6, when n t = 0. our score in this case ( 0. 728 ) is even higher than both scores of  #AUTHOR_TAG and  #TAUTHOR_TAG when they', 'use n t', '= 50. different from the in - domain setting, we note that the', 'combination of string kernels and word embeddings does not always provide better', 'results than string kernels alone, particularly when the number of target samples ( n t', ') added into the training set is less or equal to 25. discussion. it is worth noting that in a set of preliminary experiments ( not included in', 'the paper ), we actually considered another approach based on word embeddings. we tried', '']",3
"['7 ], low supervision  #TAUTHOR_TAG,']","['hard parameter sharing [ 7 ], low supervision  #TAUTHOR_TAG,']","['7 ], low supervision  #TAUTHOR_TAG,']","['trainable parameters for the components that differentiate multi - task learning approaches.', 'we build on recent work trying to learn where to split merged networks [ 21 ], as well as work trying to learn how best to combine private and shared subspaces [ 5, 18 ].', 'our model is empirically justified and deals with the dirtiness [ 16 ] of loosely related tasks.', 'we show that it is a generalization of various multi - task learning algorithms such as hard parameter sharing [ 7 ], low supervision  #TAUTHOR_TAG, and cross - stitch networks [ 21 ], as well as transfer learning algorithms such as frustratingly easy domain adaptation [ 9 ].', 'moreover, we study what task properties predict gains, and what properties correlate with learning certain types of sharing, as well as the inductive bias of the resulting architecture.', 'figure 1 : a sluice network with one main task a and one auxiliary task b. it consists of a shared input layer ( shown left ), two task - specific output layers ( right ), and three hidden layers per task, each partitioned into two subspaces.', 'α parameters control which subspaces are shared between main and auxiliary task, while β parameters control which layer outputs are used for prediction']",5
"['7, 9,  #TAUTHOR_TAG 21 ].', 'we show how to derive each of these below.', 'hard parameter sharing in the two networks appears if all α values']","['can be seen as a generalization over several existing algorithms for transfer and multi - task learning, including [ 7, 9,  #TAUTHOR_TAG 21 ].', 'we show how to derive each of these below.', 'hard parameter sharing in the two networks appears if all α values']","['7, 9,  #TAUTHOR_TAG 21 ].', 'we show how to derive each of these below.', 'hard parameter sharing in the two networks appears if all α values are set to the same constant [ 7, 8 ].', 'this is equivalent']","['architecture is very flexible and can be seen as a generalization over several existing algorithms for transfer and multi - task learning, including [ 7, 9,  #TAUTHOR_TAG 21 ].', 'we show how to derive each of these below.', 'hard parameter sharing in the two networks appears if all α values are set to the same constant [ 7, 8 ].', 'this is equivalent to a mean - constrained 0 - regularizer ω ( · ) = | · | w i 0 and i λili < 1. if the sum of weighted losses are smaller than 1, the loss with penalty is always the highest when all parameters are shared.', 'group lasso the 1 / 2 group lasso regularizer is g g = 1 | | g1, i, g | | 2, a weighted sum over the 2 norms of the groups, often used to enforce subspace sharing [ 33, 26 ].', 'our architecture learns a 1 / 2 group lasso over the two subspaces ( with the same degrees of freedom ), when all αa, b and αb, a - values are set to 0.', 'when the outer layer α - values are not shared, we get block communication between the networks']",5
"['with part - of - speech tagging ( pos ) as an auxiliary task, following  #TAUTHOR_TAG.', 'example annotations for']","['with part - of - speech tagging ( pos ) as an auxiliary task, following  #TAUTHOR_TAG.', 'example annotations for']","['with part - of - speech tagging ( pos ) as an auxiliary task, following  #TAUTHOR_TAG.', 'example annotations for']","['', 'dataset provides data annotated for an array of tasks across different languages and domains.', 'we present experiments with the english portions of datasets, for which we show statistics in table 1.', '2 tasks in multi - task learning, one task is usually considered the main task, while other tasks are used as auxiliary tasks to improve performance on the main task.', 'as main tasks, we use chunking ( chunk ), named entity recognition ( ner ), and a simplified version of semantic role labeling ( srl ) where we only identify headwords, and pair them with part - of - speech tagging ( pos ) as an auxiliary task, following  #TAUTHOR_TAG.', 'example annotations for each task can be found in table 2.', 'model we use a state - ofthe - art bilstm - based sequence labeling model [ 23 ] as the building block of our model.', 'the bilstm consists of 3 layers with a hidden dimension of 100.', 'at every time step, the model receives as input the concatenation between the 64 - dimensional embedding of a word and its character - level embedding produced by a bi - lstm over 100 - dimensional character embeddings.', 'both word and character embeddings are randomly initialized.', 'the output layer is an mlp with a dimensionality of 100.', 'we initialize α parameters with a bias towards one source subspace for each direction and initialize β parameters with a bias towards the last layer']",5
"['by  #TAUTHOR_TAG, which predicts']","['by  #TAUTHOR_TAG, which predicts']","['the low supervision model by  #TAUTHOR_TAG, which predicts the auxiliary task at']","['train our models with sgd, an initial learning rate of 0. 1, and learning rate decay.', 'during training, we randomly sample from the data for each task.', 'we perform early stopping with patience of 2 and hyperparameter optimization on the in - domain development data of the newswire domain.', 'we use the same hyperparameters for all comparison models across all domains.', 'we train our models on each domain and evaluate them both on the in - domain test set as well as on the test sets of all other domains to evaluate their out - of - domain generalization ability.', 'baseline models as baselines, we compare against i ) a single - task model only trained on chunking ; ii ) the low supervision model by  #TAUTHOR_TAG, which predicts the auxiliary task at the first layer ; iii ) an mtl model based on hard parameter sharing [ 6 ] ; and iv ) cross - stitch networks [ 21 ].', 'we compare these against our complete sluice network with subspace constraints and learned α and β parameters.', 'we provide a detailed ablation analysis of our model in section 5']",5
['be better modeled with one hidden layer ; another one with two  #TAUTHOR_TAG'],['be better modeled with one hidden layer ; another one with two  #TAUTHOR_TAG'],"['may be better modeled with one hidden layer ; another one with two  #TAUTHOR_TAG.', 'our architecture, however, is flexible enough to learn this, if']","['', 'we assume that all the deep networks have the same hyper - parameters at the outset.', 'with loosely related tasks, one task may be better modeled with one hidden layer ; another one with two  #TAUTHOR_TAG.', 'our architecture, however, is flexible enough to learn this, if we initially associate each task with the union of the a priori task networks.', '']",0
"['', 'we split the space in two, leading to three subspaces, if we only share one half across the two networks.', 'low supervision  #TAUTHOR_TAG propose a model where only']","['with g i, k, 2 to αa, a. note that [ 9 ] discusses three subspaces.', 'we split the space in two, leading to three subspaces, if we only share one half across the two networks.', 'low supervision  #TAUTHOR_TAG propose a model where only']","['9 ] discusses three subspaces.', 'we split the space in two, leading to three subspaces, if we only share one half across the two networks.', 'low supervision  #TAUTHOR_TAG propose a model where']","['approach to domain adaptation in [ 9 ], which relies on a shared and a private space for each task or domain, can be encoded in sluice networks by setting all αa, b - and αb, a - weights associated with g i, k, 1 to 0, while setting all αa, b - weights associated with g i, k, 2 to αb, b, and αb, a - weights associated with g i, k, 2 to αa, a. note that [ 9 ] discusses three subspaces.', 'we split the space in two, leading to three subspaces, if we only share one half across the two networks.', 'low supervision  #TAUTHOR_TAG propose a model where only the inner layers of two deep recurrent works are shared.', 'this is obtained using heavy mean - constrained l0 regularization over the first layer li, 1, e. g., ω ( w ) = k i | | li, 1 | | 0 with i λil ( i ) < 1, while for the auxiliary task, only the first layer β parameter is set to 1.', 'cross - stitch networks [ 21 ] introduce cross - stitch networks that have α values control the flow between layers of two convolutional neural networks.', 'their model corresponds to setting the α - values associated with gi, j, 1 be identical to those for gi, j, 2, and by letting all but the β - value associated with the outer layer be 0.', 'in our experiments, we include hard parameter sharing, low supervision, and cross - stitch networks as baselines.', 'we do not report results for group lasso and frustratingly easy domain adaptation, which were consistently inferior on development data by some margin']",0
['be better modeled with one hidden layer ; another one with two  #TAUTHOR_TAG'],['be better modeled with one hidden layer ; another one with two  #TAUTHOR_TAG'],"['may be better modeled with one hidden layer ; another one with two  #TAUTHOR_TAG.', 'our architecture, however, is flexible enough to learn this, if']","['', 'we assume that all the deep networks have the same hyper - parameters at the outset.', 'with loosely related tasks, one task may be better modeled with one hidden layer ; another one with two  #TAUTHOR_TAG.', 'our architecture, however, is flexible enough to learn this, if we initially associate each task with the union of the a priori task networks.', '']",1
"['##efining it  #TAUTHOR_TAG 11 ], we enable our model to']","['##efining it  #TAUTHOR_TAG 11 ], we enable our model to']","['##efining it  #TAUTHOR_TAG 11 ], we enable our model to']","['##efining it  #TAUTHOR_TAG 11 ], we enable our model to learn hierarchical relations by associating different tasks with different layers if this is beneficial for learning.', 'inspired by advances in residual learning [ 12 ], we employ skip - connections from each layer, controlled using β parameters.', 'this layer acts as a mixture model, returning a mixture of expert predictions :', '']",4
"['7, 9,  #TAUTHOR_TAG 21 ].', 'we show how to derive each of these below.', 'hard parameter sharing in the two networks appears if all α values']","['can be seen as a generalization over several existing algorithms for transfer and multi - task learning, including [ 7, 9,  #TAUTHOR_TAG 21 ].', 'we show how to derive each of these below.', 'hard parameter sharing in the two networks appears if all α values']","['7, 9,  #TAUTHOR_TAG 21 ].', 'we show how to derive each of these below.', 'hard parameter sharing in the two networks appears if all α values are set to the same constant [ 7, 8 ].', 'this is equivalent']","['architecture is very flexible and can be seen as a generalization over several existing algorithms for transfer and multi - task learning, including [ 7, 9,  #TAUTHOR_TAG 21 ].', 'we show how to derive each of these below.', 'hard parameter sharing in the two networks appears if all α values are set to the same constant [ 7, 8 ].', 'this is equivalent to a mean - constrained 0 - regularizer ω ( · ) = | · | w i 0 and i λili < 1. if the sum of weighted losses are smaller than 1, the loss with penalty is always the highest when all parameters are shared.', 'group lasso the 1 / 2 group lasso regularizer is g g = 1 | | g1, i, g | | 2, a weighted sum over the 2 norms of the groups, often used to enforce subspace sharing [ 33, 26 ].', 'our architecture learns a 1 / 2 group lasso over the two subspaces ( with the same degrees of freedom ), when all αa, b and αb, a - values are set to 0.', 'when the outer layer α - values are not shared, we get block communication between the networks']",3
"[', there is more sharing at inner layers, which is in line with  #TAUTHOR_TAG, while chunk']","['simplified srl, there is more sharing at inner layers, which is in line with  #TAUTHOR_TAG, while chunking']","['there is more sharing at inner layers, which is in line with  #TAUTHOR_TAG, while chunk']","['', 'overall, we find that learnable α parameters are preferable over constant α parameters.', 'learned β parameters marginally outperform skip - connections in the hard parameter sharing setting, while skip - connections are competitive with learned β values in the learned α setting.', 'in addition, modeling subspaces explicitly helps for almost all domains.', 'finally, concatenation of layer outputs is a viable form to share information across layers.', 'chunking, ner, and srl.', 'we present inner, middle, and outer layer left to right.', 'figure 2 presents the final α weights in the sluice networks for chunking, ner, and srl, trained with newswire as training data.', 'we see that a ) for the low - level simplified srl, there is more sharing at inner layers, which is in line with  #TAUTHOR_TAG, while chunking and ner also rely on the outer layer, and b ) more information is shared from the more complex target tasks than vice versa']",3
"['in  #TAUTHOR_TAG, whereas']","['in  #TAUTHOR_TAG, whereas']","['of the smoother loss surface in multi - task learning, is a good regularizer, confirming the findings in  #TAUTHOR_TAG, whereas the sluice network is even']","['to fit noise sluice networks can learn to disregard sharing completely, so we expect them to be as good as single - task networks to fit random noise, potentially even better.', 'we verify this by computing a learning curve for random relabelings of 200 sentences annotated with syntactic chunking brackets, as well as 100 gold standard pos - annotated sentences.', 'the figure in 3 shows that hard parameter sharing, while learning faster because of the smoother loss surface in multi - task learning, is a good regularizer, confirming the findings in  #TAUTHOR_TAG, whereas the sluice network is even better at fitting noise than the single - task models.', 'while ability to fit noise is not necessarily a problem [ 32 ], this means that it can be beneficial to add inductive bias to the regularizer, especially when working with small amounts of data']",3
"['recent years  #TAUTHOR_TAG.', 'specifically, kb']","['recent years  #TAUTHOR_TAG.', 'specifically,']","['recent years  #TAUTHOR_TAG.', 'specifically']","['', 'therefore, this task has attracted more attention in recent years  #TAUTHOR_TAG.', '']",0
"['recent years  #TAUTHOR_TAG.', 'specifically, kb']","['recent years  #TAUTHOR_TAG.', 'specifically,']","['recent years  #TAUTHOR_TAG.', 'specifically']","['', 'therefore, this task has attracted more attention in recent years  #TAUTHOR_TAG.', '']",0
"[', generated questions from  #TAUTHOR_TAG']","[', generated questions from  #TAUTHOR_TAG may be difficult']","['new york "" ). therefore, generated questions from  #TAUTHOR_TAG']","['', 'refined type "" us state "" for the entity "" new york "" ). therefore, generated questions from  #TAUTHOR_TAG may be difficult to contain definitive answers. to address the aforementioned two issues', ', we exploit more diversified contexts for the given facts as', 'textual contexts in an encoder - decoder model. specifically, besides using predicate contexts from the distant supervision utilized by  #TAUTHOR_TAG, we further leverage the domain, range and even topic for the given predicate as contexts, which are off - the - shelf in kb', '']",0
"[', generated questions from  #TAUTHOR_TAG']","[', generated questions from  #TAUTHOR_TAG may be difficult']","['new york "" ). therefore, generated questions from  #TAUTHOR_TAG']","['', 'refined type "" us state "" for the entity "" new york "" ). therefore, generated questions from  #TAUTHOR_TAG may be difficult to contain definitive answers. to address the aforementioned two issues', ', we exploit more diversified contexts for the given facts as', 'textual contexts in an encoder - decoder model. specifically, besides using predicate contexts from the distant supervision utilized by  #TAUTHOR_TAG, we further leverage the domain, range and even topic for the given predicate as contexts, which are off - the - shelf in kb', '']",0
"[', generated questions from  #TAUTHOR_TAG']","[', generated questions from  #TAUTHOR_TAG may be difficult']","['new york "" ). therefore, generated questions from  #TAUTHOR_TAG']","['', 'refined type "" us state "" for the entity "" new york "" ). therefore, generated questions from  #TAUTHOR_TAG may be difficult to contain definitive answers. to address the aforementioned two issues', ', we exploit more diversified contexts for the given facts as', 'textual contexts in an encoder - decoder model. specifically, besides using predicate contexts from the distant supervision utilized by  #TAUTHOR_TAG, we further leverage the domain, range and even topic for the given predicate as contexts, which are off - the - shelf in kb', '']",0
"['( mlp ) projected from s t.', ' #TAUTHOR_TAG demonstrated the']","['( mlp ) projected from s t.', ' #TAUTHOR_TAG demonstrated the']","['( mlp ) projected from s t.', ' #TAUTHOR_TAG demonstrated the effectiveness']","['study found that most questions contain the subject name or its aligns in simplequestion  #AUTHOR_TAG.', 'however, the predicate name and object name hardly appear in the question.', 'therefore, we only copy the subject name in the kb copy, where p cpkb ( y t | s t, f ), the probability of copying the subject name, is calculated by a neural network function with a multilayer perceptron ( mlp ) projected from s t.', ' #TAUTHOR_TAG demonstrated the effectiveness of pos copy for the context.', 'however, such a copy mechanism heavily relies on pos tagging.', 'inspired by the copynet  #AUTHOR_TAG, we directly copy words in the textual contexts c, and it does not rely on any pos tagging.', 'specifically, the input sequence χ for the context copy is the concatenation of all words in the textual contexts c. unfortunately, χ is prone to contain repeated words because it consists of rich contexts for subject, predicate and object.', 'the repeated words in the input sequence tend to cause repetition problems in output sequences  #AUTHOR_TAG.', 'we adopt the maxout pointer to address the repetition problem.', 'instead of summing all the probabilistic scores for repeated input words, we limit the probabilistic score of repeated words to their maximum score as equation 13']",0
"[',  #TAUTHOR_TAG introduced extra contexts for']","['generalization,  #TAUTHOR_TAG introduced extra contexts for']","['the generalization,  #TAUTHOR_TAG introduced extra contexts for the input fact,']",[' #TAUTHOR_TAG'],0
"[',  #TAUTHOR_TAG introduced extra contexts for']","['generalization,  #TAUTHOR_TAG introduced extra contexts for']","['the generalization,  #TAUTHOR_TAG introduced extra contexts for the input fact,']",[' #TAUTHOR_TAG'],0
"['recent years  #TAUTHOR_TAG.', 'specifically, kb']","['recent years  #TAUTHOR_TAG.', 'specifically,']","['recent years  #TAUTHOR_TAG.', 'specifically']","['', 'therefore, this task has attracted more attention in recent years  #TAUTHOR_TAG.', '']",1
"[', generated questions from  #TAUTHOR_TAG']","[', generated questions from  #TAUTHOR_TAG may be difficult']","['new york "" ). therefore, generated questions from  #TAUTHOR_TAG']","['', 'refined type "" us state "" for the entity "" new york "" ). therefore, generated questions from  #TAUTHOR_TAG may be difficult to contain definitive answers. to address the aforementioned two issues', ', we exploit more diversified contexts for the given facts as', 'textual contexts in an encoder - decoder model. specifically, besides using predicate contexts from the distant supervision utilized by  #TAUTHOR_TAG, we further leverage the domain, range and even topic for the given predicate as contexts, which are off - the - shelf in kb', '']",1
"[',  #TAUTHOR_TAG introduced extra contexts for']","['generalization,  #TAUTHOR_TAG introduced extra contexts for']","['the generalization,  #TAUTHOR_TAG introduced extra contexts for the input fact,']",[' #TAUTHOR_TAG'],1
"[', generated questions from  #TAUTHOR_TAG']","[', generated questions from  #TAUTHOR_TAG may be difficult']","['new york "" ). therefore, generated questions from  #TAUTHOR_TAG']","['', 'refined type "" us state "" for the entity "" new york "" ). therefore, generated questions from  #TAUTHOR_TAG may be difficult to contain definitive answers. to address the aforementioned two issues', ', we exploit more diversified contexts for the given facts as', 'textual contexts in an encoder - decoder model. specifically, besides using predicate contexts from the distant supervision utilized by  #TAUTHOR_TAG, we further leverage the domain, range and even topic for the given predicate as contexts, which are off - the - shelf in kb', '']",5
['mentioned entity type  #TAUTHOR_TAG with the type that best describe the'],['mentioned entity type  #TAUTHOR_TAG with the type that best describe the'],"['mentioned entity type  #TAUTHOR_TAG with the type that best describe the entity 3.', 'the kb copy needs subject names as the copy source, and we map entities with their names similar to those in  #AUTHOR_TAG.', 'the data details are in appendix a and submitted supplementary data']","['conduct experiments on the simplequestion dataset  #AUTHOR_TAG, and there are 75910 / 10845 / 21687 question answering pairs ( qa - pairs ) for training / validation / test.', 'in order to obtain diversified contexts, we additionally employ domain, range and topic of the predicate to improve the coverage of predicate contexts.', 'in this way, 100 % predicates ( rather than 44 % 2 of those in elsahar et al. ) have contexts.', 'for the subject and object context, we combine the most frequently mentioned entity type  #TAUTHOR_TAG with the type that best describe the entity 3.', 'the kb copy needs subject names as the copy source, and we map entities with their names similar to those in  #AUTHOR_TAG.', 'the data details are in appendix a and submitted supplementary data']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG, we adopt some word - overlap based metrics ( wbms )']","[' #TAUTHOR_TAG, we adopt some word - overlap based metrics ( wbms ) for natural language generation including bleu - 4  #AUTHOR_TAG, rouge l  #AUTHOR_TAG and meteor  #AUTHOR_TAG.', 'however, such metrics still suffer from some limitations  #AUTHOR_TAG.', '']",5
"['', '( 3 )  #TAUTHOR_TAG.', 'although this model is designed to a zero - shot setting ( for']","['', '( 3 )  #TAUTHOR_TAG.', 'although this model is designed to a zero - shot setting ( for unseen predicates']","['best in  #AUTHOR_TAG.', '( 3 )  #TAUTHOR_TAG.', 'although this model is designed to a zero - shot setting ( for']","['compare our model with following methods.', '( 1 ) template : a baseline in  #AUTHOR_TAG, it randomly chooses a candidate fact f c in the training data to generate the question, where f c shares the same predicate with the input fact.', '( 2 )  #AUTHOR_TAG : we compare our methods with the single placeholder model, which performs best in  #AUTHOR_TAG.', '( 3 )  #TAUTHOR_TAG.', 'although this model is designed to a zero - shot setting ( for unseen predicates and entity type ), it has good abilities to generate better questions ( on known or unknown predicates and entity types ) represented in the additional context input and spo copy mechanism']",5
['replaced by contexts used in  #TAUTHOR_TAG'],['replaced by contexts used in  #TAUTHOR_TAG'],"['w / o diversified contexts "" represents that diversified contexts are replaced by contexts used in  #TAUTHOR_TAG']","['', 'this demonstrates that the answer - aware loss does not force all predicates to generate questions with answer type words.', 'table 4 : ablation study by removing the main components, where "" w / o "" means without, and "" w / o diversified contexts "" represents that diversified contexts are replaced by contexts used in  #TAUTHOR_TAG']",5
"['4, replacing diversified contexts with contexts used in  #TAUTHOR_TAG, has more obvious performance degradation']","['4, replacing diversified contexts with contexts used in  #TAUTHOR_TAG, has more obvious performance degradation']","['4, replacing diversified contexts with contexts used in  #TAUTHOR_TAG, has more obvious performance degradation']","['order to validate the effectiveness of model components, we remove some important components in our model, including context copy, kb copy, answer - aware loss and diversified contexts.', 'the results are shown in table 4.', 'we can see that removing any component brings performance decline on all metrics.', 'it demonstrates that all these components are useful.', 'specifically, the last line in table 4, replacing diversified contexts with contexts used in  #TAUTHOR_TAG, has more obvious performance degradation']",5
['. 96  #TAUTHOR_TAG 2'],['2. 96  #TAUTHOR_TAG 2. 23 our model ans loss 3. 56 human evaluation is important'],['. 96  #TAUTHOR_TAG 2'],"['2. 96  #TAUTHOR_TAG 2. 23 our model ans loss 3. 56 human evaluation is important for generated questions.', 'following  #TAUTHOR_TAG, we sample 100 questions from each system, and then two annotators measure the naturalness by a score of 0 - 5.', 'the kappa coefficient for inter - annotator is 0. 629, and p - value for all scores is less than 0. 005.', 'as shown in table 5,  #TAUTHOR_TAG pre - trained kb embeddings may provide rich structured relational information among entities.', 'however, it heavily relies on large - scale triplets, which is time and resource - intensive.', 'to investigate the effectiveness of pre - trained kb embedding for kbqg, we report the performance of kbqg whether using pre - trained kb embeddings by simply applying transe. table 6 shows that the performance of kbqg is degraded without transe embeddings.', 'in comparison,  #TAUTHOR_TAG obtain obvious degradation on all metrics while there is only a slight decline in our model.', 'we believe that it may owe to the contextaugmented fact encoder since our model drops to 40. 87 on the bleu4 score without contextaugmented fact encoder and transe embeddings']",5
['. 96  #TAUTHOR_TAG 2'],['2. 96  #TAUTHOR_TAG 2. 23 our model ans loss 3. 56 human evaluation is important'],['. 96  #TAUTHOR_TAG 2'],"['2. 96  #TAUTHOR_TAG 2. 23 our model ans loss 3. 56 human evaluation is important for generated questions.', 'following  #TAUTHOR_TAG, we sample 100 questions from each system, and then two annotators measure the naturalness by a score of 0 - 5.', 'the kappa coefficient for inter - annotator is 0. 629, and p - value for all scores is less than 0. 005.', 'as shown in table 5,  #TAUTHOR_TAG pre - trained kb embeddings may provide rich structured relational information among entities.', 'however, it heavily relies on large - scale triplets, which is time and resource - intensive.', 'to investigate the effectiveness of pre - trained kb embedding for kbqg, we report the performance of kbqg whether using pre - trained kb embeddings by simply applying transe. table 6 shows that the performance of kbqg is degraded without transe embeddings.', 'in comparison,  #TAUTHOR_TAG obtain obvious degradation on all metrics while there is only a slight decline in our model.', 'we believe that it may owe to the contextaugmented fact encoder since our model drops to 40. 87 on the bleu4 score without contextaugmented fact encoder and transe embeddings']",5
"[', generated questions from  #TAUTHOR_TAG']","[', generated questions from  #TAUTHOR_TAG may be difficult']","['new york "" ). therefore, generated questions from  #TAUTHOR_TAG']","['', 'refined type "" us state "" for the entity "" new york "" ). therefore, generated questions from  #TAUTHOR_TAG may be difficult to contain definitive answers. to address the aforementioned two issues', ', we exploit more diversified contexts for the given facts as', 'textual contexts in an encoder - decoder model. specifically, besides using predicate contexts from the distant supervision utilized by  #TAUTHOR_TAG, we further leverage the domain, range and even topic for the given predicate as contexts, which are off - the - shelf in kb', '']",6
"[', generated questions from  #TAUTHOR_TAG']","[', generated questions from  #TAUTHOR_TAG may be difficult']","['new york "" ). therefore, generated questions from  #TAUTHOR_TAG']","['', 'refined type "" us state "" for the entity "" new york "" ). therefore, generated questions from  #TAUTHOR_TAG may be difficult to contain definitive answers. to address the aforementioned two issues', ', we exploit more diversified contexts for the given facts as', 'textual contexts in an encoder - decoder model. specifically, besides using predicate contexts from the distant supervision utilized by  #TAUTHOR_TAG, we further leverage the domain, range and even topic for the given predicate as contexts, which are off - the - shelf in kb', '']",6
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG, we adopt some word - overlap based metrics ( wbms )']","[' #TAUTHOR_TAG, we adopt some word - overlap based metrics ( wbms ) for natural language generation including bleu - 4  #AUTHOR_TAG, rouge l  #AUTHOR_TAG and meteor  #AUTHOR_TAG.', 'however, such metrics still suffer from some limitations  #AUTHOR_TAG.', '']",6
"['f, where e f is pre - trained using transe  #AUTHOR_TAG to capture much more fact information in previous work  #TAUTHOR_TAG.', 'in our model, e f can be pre - trained or randomly initiated ( details in sec. 4. 7']","['f, where e f is pre - trained using transe  #AUTHOR_TAG to capture much more fact information in previous work  #TAUTHOR_TAG.', 'in our model, e f can be pre - trained or randomly initiated ( details in sec. 4. 7. 1 )']","[', where e f is pre - trained using transe  #AUTHOR_TAG to capture much more fact information in previous work  #TAUTHOR_TAG.', 'in our model, e f can be pre - trained or randomly initiated ( details in sec. 4. 7. 1 )']","['contrast to general sequence - to - sequence ( seq2seq ) model  #AUTHOR_TAG, the input fact is not a word sequence but instead a structured triplet f = ( s, p, o ).', 'we employ a fact encoder to transform each atom in the fact into a fixed embedding, and the embedding is obtained from a kb embedding matrix.', 'for example, the subject embedding e s ∈ r d is looked up from the kb embedding matrix e f ∈ r k, d, where k represents the size of kb vocabulary, and the size of kb embedding is equal to the number of hidden units ( d ) in equation 3.', 'similarly, the predicate embedding e p and the object embedding e o are mapped from the kb embedding matrix e f, where e f is pre - trained using transe  #AUTHOR_TAG to capture much more fact information in previous work  #TAUTHOR_TAG.', 'in our model, e f can be pre - trained or randomly initiated ( details in sec. 4. 7. 1 )']",4
['as  #TAUTHOR_TAG'],['as  #TAUTHOR_TAG'],"['as  #TAUTHOR_TAG.', '']","['make our model comparable to the comparison methods, we keep most parameter values the same as  #TAUTHOR_TAG.', 'we utilize rmsprop algorithm with a decreasing learning rate ( 0. 001 ), batch size ( 200 ) to optimize the model.', 'the size of kb embeddings is 200, and kb embeddings are pre - trained by transe  #AUTHOR_TAG.', 'the word embeddings are initialized by the pre - trained glove word vectors 4 with 200 dimensions.', 'in the transformer, we set the hidden units d to 200, and we employ 4 paralleled attention head and a stack of 5 identical layers.', 'we set the weight ( λ ) of the answer - aware loss to 0. 2.', 'in table 1, we compare our model with the typical baselines on word - overlap based metrics.', 'it is evident that our model is remarkably better than baselines on all metrics, where the bleu4 score increases 4. 53 compared with the strongest baseline  #TAUTHOR_TAG.', 'especially, incorporating answer - aware loss ( the last line in table 1 ) further improves the performance ( + 5. 16 bleu4 )']",4
['5  #TAUTHOR_TAG 71'],[' #TAUTHOR_TAG 71. 5'],['5  #TAUTHOR_TAG 71'],"['evaluate the ability of our model on predicate identification, we sample 100 generated questions model pred.', ' #AUTHOR_TAG 53. 5  #TAUTHOR_TAG 71. 5 our model ans loss 75. 5 from each model, and then two annotators are employed to judge whether the generated question expresses the given predicate.', 'the kappa for inter - annotator statistics is 0. 611, and p - value for all scores is less than 0. 005.', 'as shown in table 2, we can see that our model has a significant improvement in the predicate identification.', 'table 3 : performances on answer coverage, where "" ans cov "" denotes the metric of answer coverage. "" λ "" is the weight of the answer - aware loss in equation 16.', 'table 3 reports performances on blue4 and answer coverage ( ans cov ).', 'we can obtain that']",4
['. 96  #TAUTHOR_TAG 2'],['2. 96  #TAUTHOR_TAG 2. 23 our model ans loss 3. 56 human evaluation is important'],['. 96  #TAUTHOR_TAG 2'],"['2. 96  #TAUTHOR_TAG 2. 23 our model ans loss 3. 56 human evaluation is important for generated questions.', 'following  #TAUTHOR_TAG, we sample 100 questions from each system, and then two annotators measure the naturalness by a score of 0 - 5.', 'the kappa coefficient for inter - annotator is 0. 629, and p - value for all scores is less than 0. 005.', 'as shown in table 5,  #TAUTHOR_TAG pre - trained kb embeddings may provide rich structured relational information among entities.', 'however, it heavily relies on large - scale triplets, which is time and resource - intensive.', 'to investigate the effectiveness of pre - trained kb embedding for kbqg, we report the performance of kbqg whether using pre - trained kb embeddings by simply applying transe. table 6 shows that the performance of kbqg is degraded without transe embeddings.', 'in comparison,  #TAUTHOR_TAG obtain obvious degradation on all metrics while there is only a slight decline in our model.', 'we believe that it may owe to the contextaugmented fact encoder since our model drops to 40. 87 on the bleu4 score without contextaugmented fact encoder and transe embeddings']",4
['. 96  #TAUTHOR_TAG 2'],['2. 96  #TAUTHOR_TAG 2. 23 our model ans loss 3. 56 human evaluation is important'],['. 96  #TAUTHOR_TAG 2'],"['2. 96  #TAUTHOR_TAG 2. 23 our model ans loss 3. 56 human evaluation is important for generated questions.', 'following  #TAUTHOR_TAG, we sample 100 questions from each system, and then two annotators measure the naturalness by a score of 0 - 5.', 'the kappa coefficient for inter - annotator is 0. 629, and p - value for all scores is less than 0. 005.', 'as shown in table 5,  #TAUTHOR_TAG pre - trained kb embeddings may provide rich structured relational information among entities.', 'however, it heavily relies on large - scale triplets, which is time and resource - intensive.', 'to investigate the effectiveness of pre - trained kb embedding for kbqg, we report the performance of kbqg whether using pre - trained kb embeddings by simply applying transe. table 6 shows that the performance of kbqg is degraded without transe embeddings.', 'in comparison,  #TAUTHOR_TAG obtain obvious degradation on all metrics while there is only a slight decline in our model.', 'we believe that it may owe to the contextaugmented fact encoder since our model drops to 40. 87 on the bleu4 score without contextaugmented fact encoder and transe embeddings']",4
[' #TAUTHOR_TAG 69'],[' #TAUTHOR_TAG 69. 13 + gen'],['53 + gen data  #TAUTHOR_TAG 69'],"['type accuracy human - labeled data 68. 97 + gen data  #AUTHOR_TAG 68. 53 + gen data  #TAUTHOR_TAG 69. 13 + gen data ( our model ans loss ) 69. 57 previous experiments demonstrate that our model can deliver more precise questions.', '']",4
"[',  #TAUTHOR_TAG introduced extra contexts for']","['generalization,  #TAUTHOR_TAG introduced extra contexts for']","['the generalization,  #TAUTHOR_TAG introduced extra contexts for the input fact,']",[' #TAUTHOR_TAG'],4
['as  #TAUTHOR_TAG'],['as  #TAUTHOR_TAG'],"['as  #TAUTHOR_TAG.', '']","['make our model comparable to the comparison methods, we keep most parameter values the same as  #TAUTHOR_TAG.', 'we utilize rmsprop algorithm with a decreasing learning rate ( 0. 001 ), batch size ( 200 ) to optimize the model.', 'the size of kb embeddings is 200, and kb embeddings are pre - trained by transe  #AUTHOR_TAG.', 'the word embeddings are initialized by the pre - trained glove word vectors 4 with 200 dimensions.', 'in the transformer, we set the hidden units d to 200, and we employ 4 paralleled attention head and a stack of 5 identical layers.', 'we set the weight ( λ ) of the answer - aware loss to 0. 2.', 'in table 1, we compare our model with the typical baselines on word - overlap based metrics.', 'it is evident that our model is remarkably better than baselines on all metrics, where the bleu4 score increases 4. 53 compared with the strongest baseline  #TAUTHOR_TAG.', 'especially, incorporating answer - aware loss ( the last line in table 1 ) further improves the performance ( + 5. 16 bleu4 )']",3
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['', 'meanwhile, word representation models based on subword units, such as characters or word segments, have been shown to perform well in many nlp tasks such as pos tagging ( dos  #AUTHOR_TAG, language modeling  #AUTHOR_TAG, machine translation  #AUTHOR_TAG, dependency parsing  #AUTHOR_TAG, and sequence labeling  #TAUTHOR_TAG.', 'these representations are effective because they can represent oov words better by leveraging the orthographic similarity among words.', 'as for indonesian ner, the earliest work was done by  #AUTHOR_TAG which relied on a rulebased approach.', 'more recent research mainly used machine learning methods such as conditional random fields ( crf )  #AUTHOR_TAG and support vector machines  #AUTHOR_TAG.', 'the most commonly used datasets are news articles  #AUTHOR_TAG, wikipedia / dbpedia articles  #AUTHOR_TAG, medical texts  #AUTHOR_TAG, and twitter data  #AUTHOR_TAG.', 'to the best of our knowledge, there has been no work that used neural networks for indonesian ner nor ner for indonesian conversational texts.', 'in this paper, we report the ability of a neural network - based approach for indonesian ner in conversational data.', 'we employed the neural sequence labeling model of  #TAUTHOR_TAG and experimented with two word representation models : word - level']",0
,,,,0
,,,,0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['', 'meanwhile, word representation models based on subword units, such as characters or word segments, have been shown to perform well in many nlp tasks such as pos tagging ( dos  #AUTHOR_TAG, language modeling  #AUTHOR_TAG, machine translation  #AUTHOR_TAG, dependency parsing  #AUTHOR_TAG, and sequence labeling  #TAUTHOR_TAG.', 'these representations are effective because they can represent oov words better by leveraging the orthographic similarity among words.', 'as for indonesian ner, the earliest work was done by  #AUTHOR_TAG which relied on a rulebased approach.', 'more recent research mainly used machine learning methods such as conditional random fields ( crf )  #AUTHOR_TAG and support vector machines  #AUTHOR_TAG.', 'the most commonly used datasets are news articles  #AUTHOR_TAG, wikipedia / dbpedia articles  #AUTHOR_TAG, medical texts  #AUTHOR_TAG, and twitter data  #AUTHOR_TAG.', 'to the best of our knowledge, there has been no work that used neural networks for indonesian ner nor ner for indonesian conversational texts.', 'in this paper, we report the ability of a neural network - based approach for indonesian ner in conversational data.', 'we employed the neural sequence labeling model of  #TAUTHOR_TAG and experimented with two word representation models : word - level']",5
,,,,5
,,,,5
"['reported an empirical evaluation of neural sequence labeling models by  #TAUTHOR_TAG on ner in indonesian conversational texts.', 'the neural models, even without character embedding, outperform']","['reported an empirical evaluation of neural sequence labeling models by  #TAUTHOR_TAG on ner in indonesian conversational texts.', 'the neural models, even without character embedding, outperform']","['reported an empirical evaluation of neural sequence labeling models by  #TAUTHOR_TAG on ner in indonesian conversational texts.', 'the neural models, even without character embedding, outperform the crf baseline, which is a typical model for indonesian ner.', 'the models employing character embedding have an improvement']","['reported an empirical evaluation of neural sequence labeling models by  #TAUTHOR_TAG on ner in indonesian conversational texts.', 'the neural models, even without character embedding, outperform the crf baseline, which is a typical model for indonesian ner.', 'the models employing character embedding have an improvement up to 4 f 1 points compared to the word embeddingonly counterpart.', 'we demonstrated that by using character embedding, we could gain improvement as high as 15 f 1 points on entities having oov words.', '']",5
,,,,3
"['reported an empirical evaluation of neural sequence labeling models by  #TAUTHOR_TAG on ner in indonesian conversational texts.', 'the neural models, even without character embedding, outperform']","['reported an empirical evaluation of neural sequence labeling models by  #TAUTHOR_TAG on ner in indonesian conversational texts.', 'the neural models, even without character embedding, outperform']","['reported an empirical evaluation of neural sequence labeling models by  #TAUTHOR_TAG on ner in indonesian conversational texts.', 'the neural models, even without character embedding, outperform the crf baseline, which is a typical model for indonesian ner.', 'the models employing character embedding have an improvement']","['reported an empirical evaluation of neural sequence labeling models by  #TAUTHOR_TAG on ner in indonesian conversational texts.', 'the neural models, even without character embedding, outperform the crf baseline, which is a typical model for indonesian ner.', 'the models employing character embedding have an improvement up to 4 f 1 points compared to the word embeddingonly counterpart.', 'we demonstrated that by using character embedding, we could gain improvement as high as 15 f 1 points on entities having oov words.', '']",7
"[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', 'data']","['', '.  #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', '']",0
"[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', 'data']","['', '.  #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', '']",0
"['decoder model from  #TAUTHOR_TAG, which']","['encoder - decoder model from  #TAUTHOR_TAG, which']","[': the encoder - decoder model from  #TAUTHOR_TAG, which itself is adapted from']","['both asr and ast tasks we use the same end - to - end system architecture shown in figure 1 : the encoder - decoder model from  #TAUTHOR_TAG, which itself is adapted from [ 2 ], [ 4 ] and [ 3 ].', 'details of the architecture and training parameters are described in section 3. 4.', 'after pretraining an asr model, we transfer only its encoder parameters to the ast task.', 'previous experiments  #TAUTHOR_TAG showed that the encoder accounts for most of the benefits of transferring the parameters.', 'transferring also the decoder and attention mechanism does bring some improvements, but is only feasible when the asr pretraining language is the same as the ast target language, which is not true in most of our experiments.', 'in addition to pretraining, we experimented with data augmentation.', ""specifically, we augmented the ast data using kaldi's [ 13 ] 3 - way speed perturbation, adding versions of the ast data where the audio is sped down and up by a factor of 0. 9 and 1. 1, respectively."", '1 to evaluate asr performance we compute the word error rate ( wer ).', '2 to evaluate ast performance we calculate the 4 - gram bleu score [ 14 ] on four reference translations.', '']",0
"['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['', 'to explore the effects of using a large amount of pretraining data from an unrelated language, we used the aishell - 1 corpus of mandarin chinese [ 17 ], which contains 150 hours of read speech.', 'transcriptions with annotated word boundaries are available in both hanzi ( chinese characters ) and romanized versions, and we built models with each.', 'to compare to the globalphone data, we also created a 20 - hour subset of the romanized aishell ( zh - ai - small ) by randomly selecting utterances from a subset of the speakers ( 81, roughly the number present in most of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in terms of style and channel ( both are conversational telephone speech ).', 'however, as noted by  #TAUTHOR_TAG, the fisher spanish speech contains many words that are actually in english ( code - switching ), so pretraining on english may provide an unfair advantage relative to other languages']",0
"[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', 'data']","['', '.  #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', '']",1
"['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['', 'to explore the effects of using a large amount of pretraining data from an unrelated language, we used the aishell - 1 corpus of mandarin chinese [ 17 ], which contains 150 hours of read speech.', 'transcriptions with annotated word boundaries are available in both hanzi ( chinese characters ) and romanized versions, and we built models with each.', 'to compare to the globalphone data, we also created a 20 - hour subset of the romanized aishell ( zh - ai - small ) by randomly selecting utterances from a subset of the speakers ( 81, roughly the number present in most of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in terms of style and channel ( both are conversational telephone speech ).', 'however, as noted by  #TAUTHOR_TAG, the fisher spanish speech contains many words that are actually in english ( code - switching ), so pretraining on english may provide an unfair advantage relative to other languages']",1
"[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', 'data']","['', '.  #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', '']",6
"[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain']","[' #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', 'data']","['', '.  #TAUTHOR_TAG, but pretrain the encoder using a number of different asr datasets : the 150hour aishell corpus of chinese as well as seven globalphone languages, each with about 20 hours of', '']",5
"['decoder model from  #TAUTHOR_TAG, which']","['encoder - decoder model from  #TAUTHOR_TAG, which']","[': the encoder - decoder model from  #TAUTHOR_TAG, which itself is adapted from']","['both asr and ast tasks we use the same end - to - end system architecture shown in figure 1 : the encoder - decoder model from  #TAUTHOR_TAG, which itself is adapted from [ 2 ], [ 4 ] and [ 3 ].', 'details of the architecture and training parameters are described in section 3. 4.', 'after pretraining an asr model, we transfer only its encoder parameters to the ast task.', 'previous experiments  #TAUTHOR_TAG showed that the encoder accounts for most of the benefits of transferring the parameters.', 'transferring also the decoder and attention mechanism does bring some improvements, but is only feasible when the asr pretraining language is the same as the ast target language, which is not true in most of our experiments.', 'in addition to pretraining, we experimented with data augmentation.', ""specifically, we augmented the ast data using kaldi's [ 13 ] 3 - way speed perturbation, adding versions of the ast data where the audio is sped down and up by a factor of 0. 9 and 1. 1, respectively."", '1 to evaluate asr performance we compute the word error rate ( wer ).', '2 to evaluate ast performance we calculate the 4 - gram bleu score [ 14 ] on four reference translations.', '']",5
"['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in']","['', 'to explore the effects of using a large amount of pretraining data from an unrelated language, we used the aishell - 1 corpus of mandarin chinese [ 17 ], which contains 150 hours of read speech.', 'transcriptions with annotated word boundaries are available in both hanzi ( chinese characters ) and romanized versions, and we built models with each.', 'to compare to the globalphone data, we also created a 20 - hour subset of the romanized aishell ( zh - ai - small ) by randomly selecting utterances from a subset of the speakers ( 81, roughly the number present in most of the globalphone datasets ).', 'finally, to reproduce one of the experiments from  #TAUTHOR_TAG, we pretrained one model using 300 hours of switchboard english [ 18 ].', 'this data is the most similar to the ast speech data in terms of style and channel ( both are conversational telephone speech ).', 'however, as noted by  #TAUTHOR_TAG, the fisher spanish speech contains many words that are actually in english ( code - switching ), so pretraining on english may provide an unfair advantage relative to other languages']",5
"['described in  #TAUTHOR_TAG, input speech features are']","['described in  #TAUTHOR_TAG, input speech features are']","['the architecture and training procedure described in  #TAUTHOR_TAG, input speech features are fed into a stack of two cnn layers.', 'in each cnn layer we stride the input with a factor']","['the architecture and training procedure described in  #TAUTHOR_TAG, input speech features are fed into a stack of two cnn layers.', 'in each cnn layer we stride the input with a factor of 2 along time, apply the points in the circled group come from different runs on the same dataset but with different bpe or learning rate schedules.', 'the spearman rank correlation of these points is - 0. 97 ; the correlation is - 0. 92 when using test sets to compute both asr and bleu.', 'relu activation [ 20 ] followed by batch normalization [ 21 ].', '']",5
"['described in  #TAUTHOR_TAG, input speech features are']","['described in  #TAUTHOR_TAG, input speech features are']","['the architecture and training procedure described in  #TAUTHOR_TAG, input speech features are fed into a stack of two cnn layers.', 'in each cnn layer we stride the input with a factor']","['the architecture and training procedure described in  #TAUTHOR_TAG, input speech features are fed into a stack of two cnn layers.', 'in each cnn layer we stride the input with a factor of 2 along time, apply the points in the circled group come from different runs on the same dataset but with different bpe or learning rate schedules.', 'the spearman rank correlation of these points is - 0. 97 ; the correlation is - 0. 92 when using test sets to compute both asr and bleu.', 'relu activation [ 20 ] followed by batch normalization [ 21 ].', '']",5
"['by  #TAUTHOR_TAG.', 'this discrepancy might be']","['by  #TAUTHOR_TAG.', 'this discrepancy might be']","['by  #TAUTHOR_TAG.', 'this discrepancy might be']","['baseline 20 - hour ast system obtains a bleu score of 10. 3 ( table 1, first row ), 0. 5 bleu point lower than that reported by  #TAUTHOR_TAG.', 'this discrepancy might be due to differences in subsampling from the 160 - hour ast dataset to create the 20 - hour subset, or from kaldi parameters when computing the mfccs.', 'wers for our pre - trained models ( table 1 ) vary from 22. 5 for the large aishell dataset with romanized transcript to 80. 5 for portuguese globalphone.', 'these are considerably worse than stateof - the - art asr systems ( e. g., kaldi recipes can achieve wer of 7. 5 on aishell and 26. 5 on portuguese globalphone ), but we did not optimize our architecture or hyperparameters for the asr task since our main goal is to analyze the relationship between pretraining and ast performance ( and in order to use pretraining, we must use a seq2seq model with the architecture as for ast )']",4
"['by  #TAUTHOR_TAG when pretraining on 100 hours of english data, which is especially surprising given not only that chinese is very different from spanish,']","['by  #TAUTHOR_TAG when pretraining on 100 hours of english data, which is especially surprising given not only that chinese is very different from spanish,']","['by  #TAUTHOR_TAG when pretraining on 100 hours of english data, which is especially surprising given not only that chinese is very different from spanish,']","['results for our pre - trained models are given in table 1.', 'pretraining improves ast performance in every case, with improvements 4 https : / / github. com / 0xsameer / ast.', 'ranging from 0. 2 ( pt - gp ) to 4. 3 ( zh - ai - large ).', 'these results make it clear that language relatedness does not play a strong role in predicting ast improvements, since on the similar - sized globalphone datasets, the two languages most related to spanish ( french and portuguese ) yield the highest and lowest improvements, respectively.', 'moreover, pretraining on the large chinese dataset yields a bigger improvement than either of these - 4. 3 bleu points.', 'this is nearly as much as the 6 point improvement reported by  #TAUTHOR_TAG when pretraining on 100 hours of english data, which is especially surprising given not only that chinese is very different from spanish, but also that the spanish data contains some english words.', 'this finding seems to suggest that data size is more important than language relatedness for predicting the effects of pretraining.', 'however, there are big differences even amongst the languages with similar amounts of pretraining data.', 'analyzing our results further, we found a striking correlation between the wer of the initial asr model and the bleu score of the ast system pretrained using that model, as shown in figure 2.', 'therefore, although pretraining data size clearly influences ast performance, this appears to be mainly due to its effect on wer of the asr model.', 'we therefore hypothesize that wer is a better direct predictor of ast performance than either data size or language relatedness']",3
"['', ' #TAUTHOR_TAG identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling,']","['as tweets on twitter.', ' #TAUTHOR_TAG identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling,']","['', ' #TAUTHOR_TAG identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling,']","['a large body of work on neural ranking models for "" traditional "" ad hoc retrieval over web pages and newswire documents  #AUTHOR_TAG mc  #AUTHOR_TAG, there has been surprisingly little work on applying neural networks to searching short social media posts such as tweets on twitter.', ' #TAUTHOR_TAG identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling, and proposed a model specifically designed to handle these characteristics.', 'evaluation on a number of datasets from the trec microblog tracks demonstrates state - of - the - art effectiveness as well as the necessity of different model components to capture a multitude of relevance signals.', 'in this paper, we also examine the problem of modeling relevance for ranking short social media posts, but from a complementary perspective.', ' #AUTHOR_TAG argues, most figure 1 : our model architecture : a general sentence encoder is applied on query and post embeddings to generate g q and g p ; an attention encoder is applied on post embeddings to generate variable - length queryaware features h i.', '']",0
['8 are adopted from  #TAUTHOR_TAG'],['- 8 are adopted from  #TAUTHOR_TAG'],"['are adopted from  #TAUTHOR_TAG.', 'models']","['', 'results from 5 - 8 are adopted from  #TAUTHOR_TAG.', 'models denoted with ( + url ) represents utilizing the url information.', 'models denoted with + ql are interpolated with ql baseline.', 'bi - cnn denotes general sentence encoder architecture.', 'both superscripts and subscripts indicate the row indexes for which a metric difference is statistically significant at p < 0. 05.', 'cant margin.', 'to the best of our knowledge,  #TAUTHOR_TAG is the best neural model to date, and there are no neural models from trec evaluations for further comparison.', 'we also compared to mp - hcnn + ql, which is a linear interpolation to combine the raw mp - hcnn and ql scores.', 'table 2 shows our experiment results of all settings and the results of existing models.', 'model 1 is the effectiveness of bicnn model with kernel window size 2.', '1 comparing models 1 and 2, we observe that the models with query - aware kernels significantly improve the bicnn baselines, achieving competitive effectiveness as ql baseline, demonstrating the effectiveness of the queryaware encoder.', 'further capturing position information with the position - aware encoder, as shown with models 3, we obtain competitive effectiveness against mp - hcnn, even interpolated with ql.', 'noted that the mp - hcnn leverages extra url information, external term feature such as tf - idf and character - level modeling.', 'with simple interpolation ( model 4 ),']",0
"['', ' #TAUTHOR_TAG identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling,']","['as tweets on twitter.', ' #TAUTHOR_TAG identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling,']","['', ' #TAUTHOR_TAG identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling,']","['a large body of work on neural ranking models for "" traditional "" ad hoc retrieval over web pages and newswire documents  #AUTHOR_TAG mc  #AUTHOR_TAG, there has been surprisingly little work on applying neural networks to searching short social media posts such as tweets on twitter.', ' #TAUTHOR_TAG identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling, and proposed a model specifically designed to handle these characteristics.', 'evaluation on a number of datasets from the trec microblog tracks demonstrates state - of - the - art effectiveness as well as the necessity of different model components to capture a multitude of relevance signals.', 'in this paper, we also examine the problem of modeling relevance for ranking short social media posts, but from a complementary perspective.', ' #AUTHOR_TAG argues, most figure 1 : our model architecture : a general sentence encoder is applied on query and post embeddings to generate g q and g p ; an attention encoder is applied on post embeddings to generate variable - length queryaware features h i.', '']",3
"['1.', 'following  #TAUTHOR_TAG, we']","['1.', 'following  #TAUTHOR_TAG, we']","['around 50 queries and the more detailed statistics are shown in table 1.', 'following  #TAUTHOR_TAG, we evaluate our models in a reranking task, where the inputs are up to the top 1000 tweets']","['', 'the model is trained endto - end with stochastic gradient decent optimizer, and negative log - likelihood loss function is used.', '3 experiment experimental setup.', 'our models are evaluated on four tweets test collections from the trec 2011 - 2014 microblog ( mb ) tracks  #AUTHOR_TAG.', 'each dataset contains around 50 queries and the more detailed statistics are shown in table 1.', 'following  #TAUTHOR_TAG, we evaluate our models in a reranking task, where the inputs are up to the top 1000 tweets retrieved from the classical query likelihood ( ql ) language model  #AUTHOR_TAG.', ""we run four - fold cross - validation test split by year ( i. e., train on three year's data, test on one year's data ), and we randomly sample 10 queries from each year in the training sets ( in total 30 queries ) as our validation set."", '']",5
"['1.', 'following  #TAUTHOR_TAG, we']","['1.', 'following  #TAUTHOR_TAG, we']","['around 50 queries and the more detailed statistics are shown in table 1.', 'following  #TAUTHOR_TAG, we evaluate our models in a reranking task, where the inputs are up to the top 1000 tweets']","['', 'the model is trained endto - end with stochastic gradient decent optimizer, and negative log - likelihood loss function is used.', '3 experiment experimental setup.', 'our models are evaluated on four tweets test collections from the trec 2011 - 2014 microblog ( mb ) tracks  #AUTHOR_TAG.', 'each dataset contains around 50 queries and the more detailed statistics are shown in table 1.', 'following  #TAUTHOR_TAG, we evaluate our models in a reranking task, where the inputs are up to the top 1000 tweets retrieved from the classical query likelihood ( ql ) language model  #AUTHOR_TAG.', ""we run four - fold cross - validation test split by year ( i. e., train on three year's data, test on one year's data ), and we randomly sample 10 queries from each year in the training sets ( in total 30 queries ) as our validation set."", '']",5
['8 are adopted from  #TAUTHOR_TAG'],['- 8 are adopted from  #TAUTHOR_TAG'],"['are adopted from  #TAUTHOR_TAG.', 'models']","['', 'results from 5 - 8 are adopted from  #TAUTHOR_TAG.', 'models denoted with ( + url ) represents utilizing the url information.', 'models denoted with + ql are interpolated with ql baseline.', 'bi - cnn denotes general sentence encoder architecture.', 'both superscripts and subscripts indicate the row indexes for which a metric difference is statistically significant at p < 0. 05.', 'cant margin.', 'to the best of our knowledge,  #TAUTHOR_TAG is the best neural model to date, and there are no neural models from trec evaluations for further comparison.', 'we also compared to mp - hcnn + ql, which is a linear interpolation to combine the raw mp - hcnn and ql scores.', 'table 2 shows our experiment results of all settings and the results of existing models.', 'model 1 is the effectiveness of bicnn model with kernel window size 2.', '1 comparing models 1 and 2, we observe that the models with query - aware kernels significantly improve the bicnn baselines, achieving competitive effectiveness as ql baseline, demonstrating the effectiveness of the queryaware encoder.', 'further capturing position information with the position - aware encoder, as shown with models 3, we obtain competitive effectiveness against mp - hcnn, even interpolated with ql.', 'noted that the mp - hcnn leverages extra url information, external term feature such as tf - idf and character - level modeling.', 'with simple interpolation ( model 4 ),']",5
"['reader.', 'recently,  #TAUTHOR_TAG have introduced an']","['reader.', 'recently,  #TAUTHOR_TAG have introduced an']","['', 'recently,  #TAUTHOR_TAG have introduced an opinion spam dataset containing gold standard deceptive positive hotel reviews.', 'however, the complementary problem of negative deceptive opinion spam, intended']","['rising influence of user - generated online reviews  #AUTHOR_TAG has led to growing incentive for businesses to solicit and manufacture deceptive opinion spam - fictitious reviews that have been deliberately written to sound authentic and deceive the reader.', 'recently,  #TAUTHOR_TAG have introduced an opinion spam dataset containing gold standard deceptive positive hotel reviews.', 'however, the complementary problem of negative deceptive opinion spam, intended to slander competitive offerings, remains largely unstudied.', 'following an approach similar to  #TAUTHOR_TAG, in this work we create and study the first dataset of deceptive opinion spam with negative sentiment reviews.', 'based on this dataset, we find that standard n - gram text categorization techniques can detect negative deceptive opinion spam with performance far surpassing that of human judges.', 'finally, in conjunction with the aforementioned positive review dataset, we consider the possible interactions between sentiment and deception, and present initial results that encourage further exploration of this relationship']",1
"['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","[""' s purchase decisions are increasingly influenced by user - generated online reviews of products and services  #AUTHOR_TAG."", 'accordingly, there is a growing incentive for businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between 1 % and 6 % of positive hotel reviews appear to be deceptive, suggesting that some hotels may be posting fake positive reviews in order to hype their own offerings.', 'in this work we distinguish between two kinds of deceptive opinion spam, depending on the sentiment expressed in the review.', '']",1
"['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","[""' s purchase decisions are increasingly influenced by user - generated online reviews of products and services  #AUTHOR_TAG."", 'accordingly, there is a growing incentive for businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between 1 % and 6 % of positive hotel reviews appear to be deceptive, suggesting that some hotels may be posting fake positive reviews in order to hype their own offerings.', 'in this work we distinguish between two kinds of deceptive opinion spam, depending on the sentiment expressed in the review.', '']",1
"['of the biggest challenges facing studies of deception is obtaining labeled data.', 'recently,  #TAUTHOR_TAG have proposed an approach']","['of the biggest challenges facing studies of deception is obtaining labeled data.', 'recently,  #TAUTHOR_TAG have proposed an approach']","['of the biggest challenges facing studies of deception is obtaining labeled data.', 'recently,  #TAUTHOR_TAG have proposed an approach']","['of the biggest challenges facing studies of deception is obtaining labeled data.', ""recently,  #TAUTHOR_TAG have proposed an approach for generating positive deceptive opinion spam using amazon's popular mechanical turk crowdsourcing service."", ""in this section we discuss our efforts to extend  #TAUTHOR_TAG's dataset to additionally include negative deceptive opinion spam""]",1
"['reader.', 'recently,  #TAUTHOR_TAG have introduced an']","['reader.', 'recently,  #TAUTHOR_TAG have introduced an']","['', 'recently,  #TAUTHOR_TAG have introduced an opinion spam dataset containing gold standard deceptive positive hotel reviews.', 'however, the complementary problem of negative deceptive opinion spam, intended']","['rising influence of user - generated online reviews  #AUTHOR_TAG has led to growing incentive for businesses to solicit and manufacture deceptive opinion spam - fictitious reviews that have been deliberately written to sound authentic and deceive the reader.', 'recently,  #TAUTHOR_TAG have introduced an opinion spam dataset containing gold standard deceptive positive hotel reviews.', 'however, the complementary problem of negative deceptive opinion spam, intended to slander competitive offerings, remains largely unstudied.', 'following an approach similar to  #TAUTHOR_TAG, in this work we create and study the first dataset of deceptive opinion spam with negative sentiment reviews.', 'based on this dataset, we find that standard n - gram text categorization techniques can detect negative deceptive opinion spam with performance far surpassing that of human judges.', 'finally, in conjunction with the aforementioned positive review dataset, we consider the possible interactions between sentiment and deception, and present initial results that encourage further exploration of this relationship']",3
"['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","[""' s purchase decisions are increasingly influenced by user - generated online reviews of products and services  #AUTHOR_TAG."", 'accordingly, there is a growing incentive for businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between 1 % and 6 % of positive hotel reviews appear to be deceptive, suggesting that some hotels may be posting fake positive reviews in order to hype their own offerings.', 'in this work we distinguish between two kinds of deceptive opinion spam, depending on the sentiment expressed in the review.', '']",3
"['rates among travel review portals is reasonably small.', 'following  #TAUTHOR_TAG, we sample a subset of the available truthful reviews']","['deception rates among travel review portals is reasonably small.', 'following  #TAUTHOR_TAG, we sample a subset of the available truthful reviews']","['deception rates among travel review portals is reasonably small.', 'following  #TAUTHOR_TAG, we sample a subset of the available truthful reviews']","['( 1 - or 2 - star ) truthful reviews are mined from six popular online review communities : expedia, hotels. com, orbitz, priceline, tripadvisor, and yelp.', 'while reviews mined from these communities cannot be considered gold standard truthful, recent work  #AUTHOR_TAG suggests that deception rates among travel review portals is reasonably small.', 'following  #TAUTHOR_TAG, we sample a subset of the available truthful reviews so that we retain an equal number of truthful and deceptive reviews ( 20 each ) for each hotel.', 'however, because the truthful reviews are on average longer than our deceptive reviews, we sample the truthful reviews according to a log - normal distribution fit to the lengths of our deceptive reviews, similarly to  #TAUTHOR_TAG table 1 : deception detection performance, incl.', '( p ) recision, ( r ) ecall, and ( f ) 1 - score, for three human judges and two meta - judges on a set of 160 negative reviews.', 'the largest value in each column is indicated with boldface']",3
"['rates among travel review portals is reasonably small.', 'following  #TAUTHOR_TAG, we sample a subset of the available truthful reviews']","['deception rates among travel review portals is reasonably small.', 'following  #TAUTHOR_TAG, we sample a subset of the available truthful reviews']","['deception rates among travel review portals is reasonably small.', 'following  #TAUTHOR_TAG, we sample a subset of the available truthful reviews']","['( 1 - or 2 - star ) truthful reviews are mined from six popular online review communities : expedia, hotels. com, orbitz, priceline, tripadvisor, and yelp.', 'while reviews mined from these communities cannot be considered gold standard truthful, recent work  #AUTHOR_TAG suggests that deception rates among travel review portals is reasonably small.', 'following  #TAUTHOR_TAG, we sample a subset of the available truthful reviews so that we retain an equal number of truthful and deceptive reviews ( 20 each ) for each hotel.', 'however, because the truthful reviews are on average longer than our deceptive reviews, we sample the truthful reviews according to a log - normal distribution fit to the lengths of our deceptive reviews, similarly to  #TAUTHOR_TAG table 1 : deception detection performance, incl.', '( p ) recision, ( r ) ecall, and ( f ) 1 - score, for three human judges and two meta - judges on a set of 160 negative reviews.', 'the largest value in each column is indicated with boldface']",3
"['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['large - scale meta - analyses have shown human deception detection performance is low, with accuracies often not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG found that two out of three human judges were unable to perform statistically significantly better than chance ( at the p < 0. 05 level ) at detecting positive deceptive opinion spam.', 'nevertheless, it is important to subject our reviews to human judgments to validate their convincingness.', 'in particular, if human detection performance is found to be very high, then it would cast doubt on the usefulness of the mechanical turk approach for soliciting gold standard deceptive opinion spam.', '']",3
"['of  #TAUTHOR_TAG.', 'for example,']","['of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. )']","['of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. )']","['important question is how language features operate in our fake negative reviews compared with the fake positive reviews of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. ) because individuals who had not actually experienced the hotel simply had less spatial detail available for their review  #AUTHOR_TAG.', 'this was also the case for our negative reviews, with less spatial language observed for fake negative reviews relative to truthful.', 'likewise, our fake negative reviews had more verbs relative to nouns than truthful, suggesting a more narrative style that is indicative of imaginative writing  #AUTHOR_TAG, a pattern also observed by  #TAUTHOR_TAG.', 'there were, however, several important differences in the deceptive language of fake negative relative to fake positive reviews.', 'first, as might be expected, negative emotion terms were more fre - quent, according to liwc  #AUTHOR_TAG, in our fake negative reviews than in the fake positive reviews. but, importantly, the fake negative reviewers over - produced negative emotion terms ( e. g., terrible, disappointed ) relative to the truthful reviews in the same way that fake positive reviewers over - produced positive emotion terms ( e. g., elegant, luxurious ).', 'combined, these data suggest that the more frequent negative emotion terms in the present dataset are not the result of "" leakage cues "" that reveal the emotional distress of lying  #AUTHOR_TAG.', '']",3
"['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","[""' s purchase decisions are increasingly influenced by user - generated online reviews of products and services  #AUTHOR_TAG."", 'accordingly, there is a growing incentive for businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between 1 % and 6 % of positive hotel reviews appear to be deceptive, suggesting that some hotels may be posting fake positive reviews in order to hype their own offerings.', 'in this work we distinguish between two kinds of deceptive opinion spam, depending on the sentiment expressed in the review.', '']",5
"['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","['businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between']","[""' s purchase decisions are increasingly influenced by user - generated online reviews of products and services  #AUTHOR_TAG."", 'accordingly, there is a growing incentive for businesses to solicit and manufacture deceptive opinion spamfictitious reviews that have been deliberately written to sound authentic and deceive the reader  #TAUTHOR_TAG.', 'for example,  #AUTHOR_TAG has estimated that between 1 % and 6 % of positive hotel reviews appear to be deceptive, suggesting that some hotels may be posting fake positive reviews in order to hype their own offerings.', 'in this work we distinguish between two kinds of deceptive opinion spam, depending on the sentiment expressed in the review.', '']",5
"['procedure as  #TAUTHOR_TAG.', 'in particular, we create and divide 400 hits evenly across the 20 most popular hotels in chicago, such that we']","['procedure as  #TAUTHOR_TAG.', 'in particular, we create and divide 400 hits evenly across the 20 most popular hotels in chicago, such that we']","['##ptive negative reviews are gathered from mechanical turk using the same procedure as  #TAUTHOR_TAG.', 'in particular, we create and divide 400 hits evenly across the 20 most popular hotels in chicago, such that we obtain 20 reviews for each hotel.', 'we allow workers to complete only a single hit each,']","['##ptive negative reviews are gathered from mechanical turk using the same procedure as  #TAUTHOR_TAG.', 'in particular, we create and divide 400 hits evenly across the 20 most popular hotels in chicago, such that we obtain 20 reviews for each hotel.', 'we allow workers to complete only a single hit each, so that each review is written by a unique worker.', '2 we further require workers to be located in the united states and to have an average past approval rating of at least 90 %.', 'we allow a maximum of 30 minutes to complete the hit, and reward accepted submissions with one us dollar ( $ 1 ).', ""each hit instructs a worker to imagine that they work for the marketing department of a hotel, and that their manager has asked them to write a fake negative review of a competitor's hotel to be posted online."", 'accompanying each hit is the name and url of the hotel for which the fake negative review is to be written, and instructions that : ( 1 ) workers should not complete more than one similar hit, ( 2 ) submissions must be of sufficient quality, i. e., written for the correct hotel, legible, reasonable in length, 3 and not plagiarized, 4 and, ( 3 ) the hit is for academic research purposes.', 'submissions are manually inspected to ensure that they are written for the correct hotel and to ensure that they convey a generally negative sentiment.', '5 the average accepted review length was 178 words, higher than for the positive reviews gathered by  #TAUTHOR_TAG, who report an average review length of 116 words']",5
"['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['large - scale meta - analyses have shown human deception detection performance is low, with accuracies often not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG found that two out of three human judges were unable to perform statistically significantly better than chance ( at the p < 0. 05 level ) at detecting positive deceptive opinion spam.', 'nevertheless, it is important to subject our reviews to human judgments to validate their convincingness.', 'in particular, if human detection performance is found to be very high, then it would cast doubt on the usefulness of the mechanical turk approach for soliciting gold standard deceptive opinion spam.', '']",5
"['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the performance of linear support vector machine ( svm ) classifiers trained with unigram and bigram term - frequency features on our novel negative deceptive opinion spam dataset.', 'we employ']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the performance of linear support vector machine ( svm ) classifiers trained with unigram and bigram term - frequency features on our novel negative deceptive opinion spam dataset.', '']",5
"['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the performance of linear support vector machine ( svm ) classifiers trained with unigram and bigram term - frequency features on our novel negative deceptive opinion spam dataset.', 'we employ']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the performance of linear support vector machine ( svm ) classifiers trained with unigram and bigram term - frequency features on our novel negative deceptive opinion spam dataset.', '']",5
"[""sentiment and deception by utilizing  #TAUTHOR_TAG's positive deceptive opinion spam dataset in conjunction with our own."", 'in particular, we']","[""sentiment and deception by utilizing  #TAUTHOR_TAG's positive deceptive opinion spam dataset in conjunction with our own."", 'in particular, we']","[""sentiment and deception by utilizing  #TAUTHOR_TAG's positive deceptive opinion spam dataset in conjunction with our own."", 'in particular,']","['have created the first publicly - available corpus of gold standard negative deceptive opinion spam, containing 400 reviews of 20 chicago hotels, which we have used to compare the deception detection capabilities of untrained human judges and standard n - gram - based support vector machine classifiers.', 'our results demonstrate that while human deception detection performance is greater for negative rather than positive deceptive opinion spam, the best detection performance is still achieved through automated classifiers, with approximately 86 % accuracy.', ""we have additionally explored, albeit briefly, the relationship between sentiment and deception by utilizing  #TAUTHOR_TAG's positive deceptive opinion spam dataset in conjunction with our own."", 'in particular, we have identified several features of language that seem to remain consistent across sentiment, such as decreased awareness of spatial details and exaggerated language.', 'we have also identified other features that vary with the sentiment, such as first person singular use, although further work is required to determine if these differences may be exploited to improve deception detection performance.', 'indeed, future work may wish to jointly model sentiment and deception in order to better determine the effect each has on language use']",5
"['of the biggest challenges facing studies of deception is obtaining labeled data.', 'recently,  #TAUTHOR_TAG have proposed an approach']","['of the biggest challenges facing studies of deception is obtaining labeled data.', 'recently,  #TAUTHOR_TAG have proposed an approach']","['of the biggest challenges facing studies of deception is obtaining labeled data.', 'recently,  #TAUTHOR_TAG have proposed an approach']","['of the biggest challenges facing studies of deception is obtaining labeled data.', ""recently,  #TAUTHOR_TAG have proposed an approach for generating positive deceptive opinion spam using amazon's popular mechanical turk crowdsourcing service."", ""in this section we discuss our efforts to extend  #TAUTHOR_TAG's dataset to additionally include negative deceptive opinion spam""]",6
"['procedure as  #TAUTHOR_TAG.', 'in particular, we create and divide 400 hits evenly across the 20 most popular hotels in chicago, such that we']","['procedure as  #TAUTHOR_TAG.', 'in particular, we create and divide 400 hits evenly across the 20 most popular hotels in chicago, such that we']","['##ptive negative reviews are gathered from mechanical turk using the same procedure as  #TAUTHOR_TAG.', 'in particular, we create and divide 400 hits evenly across the 20 most popular hotels in chicago, such that we obtain 20 reviews for each hotel.', 'we allow workers to complete only a single hit each,']","['##ptive negative reviews are gathered from mechanical turk using the same procedure as  #TAUTHOR_TAG.', 'in particular, we create and divide 400 hits evenly across the 20 most popular hotels in chicago, such that we obtain 20 reviews for each hotel.', 'we allow workers to complete only a single hit each, so that each review is written by a unique worker.', '2 we further require workers to be located in the united states and to have an average past approval rating of at least 90 %.', 'we allow a maximum of 30 minutes to complete the hit, and reward accepted submissions with one us dollar ( $ 1 ).', ""each hit instructs a worker to imagine that they work for the marketing department of a hotel, and that their manager has asked them to write a fake negative review of a competitor's hotel to be posted online."", 'accompanying each hit is the name and url of the hotel for which the fake negative review is to be written, and instructions that : ( 1 ) workers should not complete more than one similar hit, ( 2 ) submissions must be of sufficient quality, i. e., written for the correct hotel, legible, reasonable in length, 3 and not plagiarized, 4 and, ( 3 ) the hit is for academic research purposes.', 'submissions are manually inspected to ensure that they are written for the correct hotel and to ensure that they convey a generally negative sentiment.', '5 the average accepted review length was 178 words, higher than for the positive reviews gathered by  #TAUTHOR_TAG, who report an average review length of 116 words']",4
"['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG']","['large - scale meta - analyses have shown human deception detection performance is low, with accuracies often not much better than chance ( bond and de  #AUTHOR_TAG.', 'indeed,  #TAUTHOR_TAG found that two out of three human judges were unable to perform statistically significantly better than chance ( at the p < 0. 05 level ) at detecting positive deceptive opinion spam.', 'nevertheless, it is important to subject our reviews to human judgments to validate their convincingness.', 'in particular, if human detection performance is found to be very high, then it would cast doubt on the usefulness of the mechanical turk approach for soliciting gold standard deceptive opinion spam.', '']",0
"['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the performance of linear support vector machine ( svm ) classifiers trained with unigram and bigram term - frequency features on our novel negative deceptive opinion spam dataset.', 'we employ']","['n - gram - based text categorization techniques have been shown to be effective at detecting deception in text  #TAUTHOR_TAG.', 'following  #TAUTHOR_TAG, we evaluate the performance of linear support vector machine ( svm ) classifiers trained with unigram and bigram term - frequency features on our novel negative deceptive opinion spam dataset.', '']",0
"['of  #TAUTHOR_TAG.', 'for example,']","['of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. )']","['of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. )']","['important question is how language features operate in our fake negative reviews compared with the fake positive reviews of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. ) because individuals who had not actually experienced the hotel simply had less spatial detail available for their review  #AUTHOR_TAG.', 'this was also the case for our negative reviews, with less spatial language observed for fake negative reviews relative to truthful.', 'likewise, our fake negative reviews had more verbs relative to nouns than truthful, suggesting a more narrative style that is indicative of imaginative writing  #AUTHOR_TAG, a pattern also observed by  #TAUTHOR_TAG.', 'there were, however, several important differences in the deceptive language of fake negative relative to fake positive reviews.', 'first, as might be expected, negative emotion terms were more fre - quent, according to liwc  #AUTHOR_TAG, in our fake negative reviews than in the fake positive reviews. but, importantly, the fake negative reviewers over - produced negative emotion terms ( e. g., terrible, disappointed ) relative to the truthful reviews in the same way that fake positive reviewers over - produced positive emotion terms ( e. g., elegant, luxurious ).', 'combined, these data suggest that the more frequent negative emotion terms in the present dataset are not the result of "" leakage cues "" that reveal the emotional distress of lying  #AUTHOR_TAG.', '']",0
"['of  #TAUTHOR_TAG.', 'for example,']","['of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. )']","['of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. )']","['important question is how language features operate in our fake negative reviews compared with the fake positive reviews of  #TAUTHOR_TAG.', 'for example, fake positive reviews included less spatial language ( e. g., floor, small, location, etc. ) because individuals who had not actually experienced the hotel simply had less spatial detail available for their review  #AUTHOR_TAG.', 'this was also the case for our negative reviews, with less spatial language observed for fake negative reviews relative to truthful.', 'likewise, our fake negative reviews had more verbs relative to nouns than truthful, suggesting a more narrative style that is indicative of imaginative writing  #AUTHOR_TAG, a pattern also observed by  #TAUTHOR_TAG.', 'there were, however, several important differences in the deceptive language of fake negative relative to fake positive reviews.', 'first, as might be expected, negative emotion terms were more fre - quent, according to liwc  #AUTHOR_TAG, in our fake negative reviews than in the fake positive reviews. but, importantly, the fake negative reviewers over - produced negative emotion terms ( e. g., terrible, disappointed ) relative to the truthful reviews in the same way that fake positive reviewers over - produced positive emotion terms ( e. g., elegant, luxurious ).', 'combined, these data suggest that the more frequent negative emotion terms in the present dataset are not the result of "" leakage cues "" that reveal the emotional distress of lying  #AUTHOR_TAG.', '']",7
"['.', ' #TAUTHOR_TAG formalized the problem as']","['contexts on dependency structure.', ' #TAUTHOR_TAG formalized the problem as']","['contexts on dependency structure.', ' #TAUTHOR_TAG formalized the problem as classifying each ip node ( roughly corresponds to s and sbar in penn treebank ) in the phrase structure.', 'in this paper, we propose a novel method']","['categories are phonetically null elements that are used for representing dropped pronouns ( "" pro "" or "" small pro "" ), controlled elements ( "" pro "" or "" big pro "" ) and traces of movement ( "" t "" or "" trace "" ), such as wh - questions and relative clauses.', 'they are important for pro - drop languages such as japanese, in particular, for the machine translation from pro - drop languages to nonpro - drop languages such as english.', ' #AUTHOR_TAG reported their recover of empty categories improved the accuracy of machine translation both in korean and in chinese.', ' #AUTHOR_TAG showed that generating zero subjects in japanese improved the accuracy of preorderingbased translation.', 'state - of - the - art statistical syntactic parsers had typically ignored empty categories.', 'although penn treebank  #AUTHOR_TAG has annotations on pro and trace, they provide only labeled bracketing.', ' #AUTHOR_TAG proposed a statistical pattern - matching algorithm for post - processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent.', ' #AUTHOR_TAG proposed a machine learning - based "" trace tagger "" as a preprocess of parsing.', ' #AUTHOR_TAG proposed a rule - based post - processing method based on linguistically motivated rules.', ' #AUTHOR_TAG replaced the rules with machine learning - based classifiers.', ' #AUTHOR_TAG and  #AUTHOR_TAG integrated empty category detection with the syntactic parsing.', 'empty category detection for pro ( dropped pronouns or zero pronoun ) has begun to receive attention as the chinese penn treebank  #AUTHOR_TAG has annotations for pro as well as pro and trace.', ' #AUTHOR_TAG formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure.', ' #AUTHOR_TAG proposed a joint embedding of empty categories and their contexts on dependency structure.', ' #TAUTHOR_TAG formalized the problem as classifying each ip node ( roughly corresponds to s and sbar in penn treebank ) in the phrase structure.', 'in this paper, we propose a novel method for empty category detection for japanese that uses conjunction features on phrase structure and word embeddings.', 'we use the keyaki treebank  #AUTHOR_TAG, which is a recent development.', 'as it has annotations for pro and trace, we show our method has substantial improvements over the state - of - the - art machine learning - based method  #TAUTHOR_TAG for chinese empty category detection as well as linguistically - motivated manually written rule - based method similar to  #AUTHOR_TAG']",0
"['', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","[', and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ']","['node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","['can uniquely decode them from the extended ip labels, the problem is to predict the labels for the input tree that has no empty nodes. let t = t 1 t 2 · · · t n be the sequence of nodes produced by the post - order traversal from root node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ is a weight vector to', 'φ and z is normalization factor : where e represents the set of all empty category types to be detected.  #TAUTHOR_TAG grouped their features into four types : tree label features, lexical features, empty category features and conjunction features as shown in table 1. as the features for', ' #TAUTHOR_TAG were developed for chinese penn treebank, we modify their features for keyaki treebank : first, the traversal order is changed from post - order ( bottom - up ) to pre - order', '']",0
"['', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","[', and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ']","['node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","['can uniquely decode them from the extended ip labels, the problem is to predict the labels for the input tree that has no empty nodes. let t = t 1 t 2 · · · t n be the sequence of nodes produced by the post - order traversal from root node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ is a weight vector to', 'φ and z is normalization factor : where e represents the set of all empty category types to be detected.  #TAUTHOR_TAG grouped their features into four types : tree label features, lexical features, empty category features and conjunction features as shown in table 1. as the features for', ' #TAUTHOR_TAG were developed for chinese penn treebank, we modify their features for keyaki treebank : first, the traversal order is changed from post - order ( bottom - up ) to pre - order', '']",0
"['.', ' #TAUTHOR_TAG formalized the problem as']","['contexts on dependency structure.', ' #TAUTHOR_TAG formalized the problem as']","['contexts on dependency structure.', ' #TAUTHOR_TAG formalized the problem as classifying each ip node ( roughly corresponds to s and sbar in penn treebank ) in the phrase structure.', 'in this paper, we propose a novel method']","['categories are phonetically null elements that are used for representing dropped pronouns ( "" pro "" or "" small pro "" ), controlled elements ( "" pro "" or "" big pro "" ) and traces of movement ( "" t "" or "" trace "" ), such as wh - questions and relative clauses.', 'they are important for pro - drop languages such as japanese, in particular, for the machine translation from pro - drop languages to nonpro - drop languages such as english.', ' #AUTHOR_TAG reported their recover of empty categories improved the accuracy of machine translation both in korean and in chinese.', ' #AUTHOR_TAG showed that generating zero subjects in japanese improved the accuracy of preorderingbased translation.', 'state - of - the - art statistical syntactic parsers had typically ignored empty categories.', 'although penn treebank  #AUTHOR_TAG has annotations on pro and trace, they provide only labeled bracketing.', ' #AUTHOR_TAG proposed a statistical pattern - matching algorithm for post - processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent.', ' #AUTHOR_TAG proposed a machine learning - based "" trace tagger "" as a preprocess of parsing.', ' #AUTHOR_TAG proposed a rule - based post - processing method based on linguistically motivated rules.', ' #AUTHOR_TAG replaced the rules with machine learning - based classifiers.', ' #AUTHOR_TAG and  #AUTHOR_TAG integrated empty category detection with the syntactic parsing.', 'empty category detection for pro ( dropped pronouns or zero pronoun ) has begun to receive attention as the chinese penn treebank  #AUTHOR_TAG has annotations for pro as well as pro and trace.', ' #AUTHOR_TAG formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure.', ' #AUTHOR_TAG proposed a joint embedding of empty categories and their contexts on dependency structure.', ' #TAUTHOR_TAG formalized the problem as classifying each ip node ( roughly corresponds to s and sbar in penn treebank ) in the phrase structure.', 'in this paper, we propose a novel method for empty category detection for japanese that uses conjunction features on phrase structure and word embeddings.', 'we use the keyaki treebank  #AUTHOR_TAG, which is a recent development.', 'as it has annotations for pro and trace, we show our method has substantial improvements over the state - of - the - art machine learning - based method  #TAUTHOR_TAG for chinese empty category detection as well as linguistically - motivated manually written rule - based method similar to  #AUTHOR_TAG']",4
"['- position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['', 'we evaluated them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', '']",4
"['', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","[', and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ']","['node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","['can uniquely decode them from the extended ip labels, the problem is to predict the labels for the input tree that has no empty nodes. let t = t 1 t 2 · · · t n be the sequence of nodes produced by the post - order traversal from root node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ is a weight vector to', 'φ and z is normalization factor : where e represents the set of all empty category types to be detected.  #TAUTHOR_TAG grouped their features into four types : tree label features, lexical features, empty category features and conjunction features as shown in table 1. as the features for', ' #TAUTHOR_TAG were developed for chinese penn treebank, we modify their features for keyaki treebank : first, the traversal order is changed from post - order ( bottom - up ) to pre - order', '']",5
"['', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","[', and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ']","['node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","['can uniquely decode them from the extended ip labels, the problem is to predict the labels for the input tree that has no empty nodes. let t = t 1 t 2 · · · t n be the sequence of nodes produced by the post - order traversal from root node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ is a weight vector to', 'φ and z is normalization factor : where e represents the set of all empty category types to be detected.  #TAUTHOR_TAG grouped their features into four types : tree label features, lexical features, empty category features and conjunction features as shown in table 1. as the features for', ' #TAUTHOR_TAG were developed for chinese penn treebank, we modify their features for keyaki treebank : first, the traversal order is changed from post - order ( bottom - up ) to pre - order', '']",5
"['- position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['', 'we evaluated them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', '']",5
"['- position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', 'it projects the predicted']","['', 'we evaluated them using the word - position - level identification metrics described in  #TAUTHOR_TAG.', '']",5
"['', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","[', and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ']","['node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a']","['can uniquely decode them from the extended ip labels, the problem is to predict the labels for the input tree that has no empty nodes. let t = t 1 t 2 · · · t n be the sequence of nodes produced by the post - order traversal from root node, and e', 'i be the empty category tag associated with t i. the probability model of  #TAUTHOR_TAG is formulated as maxent model : where φ is a feature vector, θ is a weight vector to', 'φ and z is normalization factor : where e represents the set of all empty category types to be detected.  #TAUTHOR_TAG grouped their features into four types : tree label features, lexical features, empty category features and conjunction features as shown in table 1. as the features for', ' #TAUTHOR_TAG were developed for chinese penn treebank, we modify their features for keyaki treebank : first, the traversal order is changed from post - order ( bottom - up ) to pre - order', '']",6
"['that uses two models in tandem  #TAUTHOR_TAG, by using one model for both bert pre - trainining and fine - tuning, our model provides an average relative wer reduction']","['that uses two models in tandem  #TAUTHOR_TAG, by using one model for both bert pre - trainining and fine - tuning, our model provides an average relative wer reduction']","['that uses two models in tandem  #TAUTHOR_TAG, by using one model for both bert pre - trainining and fine - tuning, our model provides an average relative wer reduction']","['present pre - training approaches for selfsupervised representation learning of speech data.', 'a bert, masked language model, loss on discrete features is compared with an infonce - based constrastive loss on continuous speech features.', 'the pre - trained models are then fine - tuned with a connectionist temporal classification ( ctc ) loss to predict target character sequences.', 'to study impact of stacking multiple feature learning modules trained using different self - supervised loss functions, we test the discrete and continuous bert pre - training approaches on spectral features and on learned acoustic representations, showing synergitic behaviour between acoustically motivated and masked language model loss functions.', 'in low - resource conditions using only 10 hours of labeled data, we achieve word error rates ( wer ) of 10. 2 % and 23. 5 % on the standard test "" clean "" and "" other "" benchmarks of the librispeech dataset, which is almost on bar with previously published work that uses 10 times more labeled data.', 'moreover, compared to previous work that uses two models in tandem  #TAUTHOR_TAG, by using one model for both bert pre - trainining and fine - tuning, our model provides an average relative wer reduction of 9 %.', '']",4
"[' #TAUTHOR_TAG.', 'self - supervised representation']","[' #TAUTHOR_TAG.', 'self - supervised representation']","['different downstream tasks, through self - supervised learning for text and speech  #AUTHOR_TAG a ; van den  #TAUTHOR_TAG.', 'self - supervised representation learning is done through tasks to predict masked parts of the input, reconstruct inputs through low bit - rate channels,']","['learning has been an active research area for more than 30 years  #AUTHOR_TAG, with the goal of learning high level representations which separates different explanatory factors of the phenomena represented by the input data ( le  #AUTHOR_TAG.', 'disentangled representations provide models with exponentially higher ability to generalize, using little amount of labels, to new conditions by combining multiple sources of variations.', '1 we will open source the code for our models.', 'building automatic speech recognition ( asr ) systems, for example, requires a large volume of training data to represent different factors contributing to the creation of speech signals, e. g. background noise, recording channel, speaker identity, accent, emotional state, topic under discussion, and the language used in communication.', 'the practical need for building asr systems for new conditions with limited resources spurred a lot of work focused on unsupervised speech recognition and representation learning  #AUTHOR_TAG glass ; et.', 'al., a, f ; van den  #AUTHOR_TAG in addition to semiand weakly - supervised learning techniques aiming at reducing the supervised data needed in realworld scenarios ( vesely et al. ; li et al., b ; krishnan parthasarathi and strom ; chrupała et al. ;  #AUTHOR_TAG.', 'recently impressive results have been reported for representation learning, that generalizes to different downstream tasks, through self - supervised learning for text and speech  #AUTHOR_TAG a ; van den  #TAUTHOR_TAG.', 'self - supervised representation learning is done through tasks to predict masked parts of the input, reconstruct inputs through low bit - rate channels, or contrast similar data points against different ones.', 'different from  #TAUTHOR_TAG where the a bert - like model is trained with the masked language model loss, frozen, and then used as a feature extractor in tandem with a final fully supervised convolutional asr model  #AUTHOR_TAG, in this work, our "" discrete bert "" approach achieves an average relative word error rate ( wer ) reduction of 9 % by pre - training and fine - tuning the same bert model using a connectionist temporal classification ( graves et al. ) loss.', 'in addition, we present a new approach for pre - training bi - directional transformer models on continuous speech data using the infonce loss ( van den  #AUTHOR_TAG - dubbed "" continuous bert "".', 'to understand the nature of their learned representations, we train models using the continuous and the discrete bert approaches on spectral features, e. g. mel - frequency cepstral coefficients ( mfcc ), as well as on pre - trained wav2vec features.', 'these comparisons provide insights on how complementary the acoustically motivated contrastive loss function is to']",4
"['we wanted to stay consistent with', 'the setup in  #TAUTHOR_TAG. the tandem model']","['we wanted to stay consistent with', 'the setup in  #TAUTHOR_TAG. the tandem model']","['we wanted to stay consistent with', 'the setup in  #TAUTHOR_TAG. the tandem model which uses the features extracted from the pre - trained bert models is a character - based wav2letter setup of  #AUTHOR_TAG which', 'uses seven consecutive blocks of convolutions ( kernel']","['librispeech splits. we use the publicly available wav2letter + +  #AUTHOR_TAG decoder integrated into the fairseq', 'framework with the official librispeech 4gram language model. we run a sweep on weights for language model score, word score and silence token weights for each model, where parameters are', 'chosen randomly and evaluated on the devother librispeech set. we use the weights', 'found by these sweeps to evaluate and report results for all other splits. the sweeps are run with beam size of 250, while the final decoding is done with beam size of 1500. the quantized bert', 'models have a limit of 2048 source tokens due to', 'their use of fixed positional embeddings. during training we discard longer examples and during evaluation we discard randomly chosen tokens from each example until they are', 'at most 2048 tokens long. we expect that increasing the size of the fixed positional embeddings, or switching to relative positional embeddings will improve', 'performance on longer examples, but in this work we wanted to stay consistent with', 'the setup in  #TAUTHOR_TAG. the tandem model which uses the features extracted from the pre - trained bert models is a character - based wav2letter setup of  #AUTHOR_TAG which', 'uses seven consecutive blocks of convolutions ( kernel size 5 with 1. 000 × 10 3 channels ), followed by a prelu nonlinearity and a dropout rate of 1 × 10 −1. the final representation is projected', 'to a 28 - dimensional probability over the vocabulary and decoded using the standard 4gram language model following the same protocol as for the fine - tuned models table 1 presents wers of different input features and pre - training methods on the standard', 'librispeech clean and other subsets using 10 hours and 1 hour of labeled data for fine - tuning. compared to the two - model tandem system proposed in  #TAUTHOR_TAG, which uses a the discrete', 'bert features to train another asr system from scratch, our discrete bert model provides an average of 13 % and 6 % of wer reduction on clean and other', 'subsets respectively, by pre - training and fine - tuning the same bert model on the 10h labeled set. the wav2vec inputs represent one level of unsupervised feature discovery, which provides', 'a better space for quantization compared to raw spectral features. the discrete bert training augments the wa', '##v2vec features with a higher level of representation that captures the sequential structure of the full utterance through the masked language', 'modeling loss. on the other hand, the continuous bert training, given its contrastive infornce loss', ', can be viewed as another level of acoustic representations that captures longer range regularities']",4
"[' #TAUTHOR_TAG.', 'self - supervised representation']","[' #TAUTHOR_TAG.', 'self - supervised representation']","['different downstream tasks, through self - supervised learning for text and speech  #AUTHOR_TAG a ; van den  #TAUTHOR_TAG.', 'self - supervised representation learning is done through tasks to predict masked parts of the input, reconstruct inputs through low bit - rate channels,']","['learning has been an active research area for more than 30 years  #AUTHOR_TAG, with the goal of learning high level representations which separates different explanatory factors of the phenomena represented by the input data ( le  #AUTHOR_TAG.', 'disentangled representations provide models with exponentially higher ability to generalize, using little amount of labels, to new conditions by combining multiple sources of variations.', '1 we will open source the code for our models.', 'building automatic speech recognition ( asr ) systems, for example, requires a large volume of training data to represent different factors contributing to the creation of speech signals, e. g. background noise, recording channel, speaker identity, accent, emotional state, topic under discussion, and the language used in communication.', 'the practical need for building asr systems for new conditions with limited resources spurred a lot of work focused on unsupervised speech recognition and representation learning  #AUTHOR_TAG glass ; et.', 'al., a, f ; van den  #AUTHOR_TAG in addition to semiand weakly - supervised learning techniques aiming at reducing the supervised data needed in realworld scenarios ( vesely et al. ; li et al., b ; krishnan parthasarathi and strom ; chrupała et al. ;  #AUTHOR_TAG.', 'recently impressive results have been reported for representation learning, that generalizes to different downstream tasks, through self - supervised learning for text and speech  #AUTHOR_TAG a ; van den  #TAUTHOR_TAG.', 'self - supervised representation learning is done through tasks to predict masked parts of the input, reconstruct inputs through low bit - rate channels, or contrast similar data points against different ones.', 'different from  #TAUTHOR_TAG where the a bert - like model is trained with the masked language model loss, frozen, and then used as a feature extractor in tandem with a final fully supervised convolutional asr model  #AUTHOR_TAG, in this work, our "" discrete bert "" approach achieves an average relative word error rate ( wer ) reduction of 9 % by pre - training and fine - tuning the same bert model using a connectionist temporal classification ( graves et al. ) loss.', 'in addition, we present a new approach for pre - training bi - directional transformer models on continuous speech data using the infonce loss ( van den  #AUTHOR_TAG - dubbed "" continuous bert "".', 'to understand the nature of their learned representations, we train models using the continuous and the discrete bert approaches on spectral features, e. g. mel - frequency cepstral coefficients ( mfcc ), as well as on pre - trained wav2vec features.', 'these comparisons provide insights on how complementary the acoustically motivated contrastive loss function is to']",0
['##2vec  #TAUTHOR_TAG learns vector'],['##q - wav2vec  #TAUTHOR_TAG learns vector'],['##2vec  #TAUTHOR_TAG learns vector'],"['##q - wav2vec  #TAUTHOR_TAG learns vector quantized ( vq ) representations of audio data using a future time - step prediction task.', 'similar to wav2vec, there is a convolutional encoder and decoder networks f : x → z and g : z → c for feature extraction and aggregation.', 'however, in between them there is a quantization module q : z →z to build discrete representations which are input to the aggregator.', 'first, 30ms segments of raw speech are mapped to a dense feature representation z at a stride of 10ms using the encoder f.', 'next, the quantizer ( q ) turns these dense representations into discrete indices which are mapped to a reconstructionz of the original representation z. thez is fed into the aggregator g and the model is optimized via the same context prediction task as wav2vec ( cf.', '§ 2. 2 ).', 'the quantization module replaces the original representation z byz = e i from a fixed size codebook e ∈ r v ×d which contains v representations of size d']",0
"['. ; van den  #TAUTHOR_TAG,']","['al. ; van den  #TAUTHOR_TAG,']","['. ; van den  #TAUTHOR_TAG,']","['the success of bert  #AUTHOR_TAG and word2vec  #AUTHOR_TAG for nlp tasks motivated more research on self - supervised approaches for acoustic word embedding and unsupervised acoustic feature representation ( bengio and heigold ; levin et al. ; chung et al., b ; he et al. ; van den  #TAUTHOR_TAG, either by predicting masked discrete or continuous input, or by contrastive prediction of neighboring or similarly sounding segments using distant supervision or proximity in the audio signal as an indication of similarity.', 'in ( kamper et al. ) a dynamic time warping alignment is used to discover similar segment pairs.', 'our work is inspired by the research efforts in reducing the dependence on labeled data for building asr systems through unsupervised unit discovery and acoustic representation leaning  #AUTHOR_TAG glass ; et.', 'al., a, f ), and through multiand cross - lingual transfer learning in low - resource conditions ( et.', 'al., c, d, b ; ghoshal et al. ; huang et al. ; et.', 'al., e ), and semi - supervised learning ( vesely et al. ; li et al., b ; krishnan parthasarathi and strom ; li et al., a )']",0
"['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wa']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wav2vec model with the same setup as described in  #TAUTHOR_TAG.', 'this model quantizes the librispeech dataset into 13. 5k unique codes.', 'to understand the impact of acoustic representations baked into the wav2vec features, as alternatives, we explore quantizing the standard melfrequency cepstral coefficients ( mfcc ) and logmel filterbanks coefficients ( fbank ), choosing a subset small enough to fit into gpu memory and running k - means with 13. 5k centroids ( to match the vq - wav2vec setup ) to convergence.', 'we then assign the index of the closest centroid to represent each time - step.', 'we train a standard bert model  #AUTHOR_TAG with only the masked language modeling task on each set of inputs in the same way as described in  #TAUTHOR_TAG, namely by choosing tokens for masking with probability of 0. 05, expanding each chosen token to a span of 10 masked tokens ( spans may overlap ) and then computing a cross - entropy loss which attempts to maximize the likelihood of predicting the true token for each one that was masked ( figure 1a )']",6
"['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wa']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wav2vec model with the same setup as described in  #TAUTHOR_TAG.', 'this model quantizes the librispeech dataset into 13. 5k unique codes.', 'to understand the impact of acoustic representations baked into the wav2vec features, as alternatives, we explore quantizing the standard melfrequency cepstral coefficients ( mfcc ) and logmel filterbanks coefficients ( fbank ), choosing a subset small enough to fit into gpu memory and running k - means with 13. 5k centroids ( to match the vq - wav2vec setup ) to convergence.', 'we then assign the index of the closest centroid to represent each time - step.', 'we train a standard bert model  #AUTHOR_TAG with only the masked language modeling task on each set of inputs in the same way as described in  #TAUTHOR_TAG, namely by choosing tokens for masking with probability of 0. 05, expanding each chosen token to a span of 10 masked tokens ( spans may overlap ) and then computing a cross - entropy loss which attempts to maximize the likelihood of predicting the true token for each one that was masked ( figure 1a )']",3
"['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wa']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wav2vec model with the same setup as described in  #TAUTHOR_TAG.', 'this model quantizes the librispeech dataset into 13. 5k unique codes.', 'to understand the impact of acoustic representations baked into the wav2vec features, as alternatives, we explore quantizing the standard melfrequency cepstral coefficients ( mfcc ) and logmel filterbanks coefficients ( fbank ), choosing a subset small enough to fit into gpu memory and running k - means with 13. 5k centroids ( to match the vq - wav2vec setup ) to convergence.', 'we then assign the index of the closest centroid to represent each time - step.', 'we train a standard bert model  #AUTHOR_TAG with only the masked language modeling task on each set of inputs in the same way as described in  #TAUTHOR_TAG, namely by choosing tokens for masking with probability of 0. 05, expanding each chosen token to a span of 10 masked tokens ( spans may overlap ) and then computing a cross - entropy loss which attempts to maximize the likelihood of predicting the true token for each one that was masked ( figure 1a )']",3
"['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wa']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wav2vec model with the same setup as described in  #TAUTHOR_TAG.', 'this model quantizes the librispeech dataset into 13. 5k unique codes.', 'to understand the impact of acoustic representations baked into the wav2vec features, as alternatives, we explore quantizing the standard melfrequency cepstral coefficients ( mfcc ) and logmel filterbanks coefficients ( fbank ), choosing a subset small enough to fit into gpu memory and running k - means with 13. 5k centroids ( to match the vq - wav2vec setup ) to convergence.', 'we then assign the index of the closest centroid to represent each time - step.', 'we train a standard bert model  #AUTHOR_TAG with only the masked language modeling task on each set of inputs in the same way as described in  #TAUTHOR_TAG, namely by choosing tokens for masking with probability of 0. 05, expanding each chosen token to a span of 10 masked tokens ( spans may overlap ) and then computing a cross - entropy loss which attempts to maximize the likelihood of predicting the true token for each one that was masked ( figure 1a )']",5
"['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wa']","['work builds on the recently proposed work in  #TAUTHOR_TAG where audio is quantized using a contrastive loss, then features learned on top by a bert model  #AUTHOR_TAG.', 'for the vq - wav2vec quantization, we use the gumbelsoftmax vq - wav2vec model with the same setup as described in  #TAUTHOR_TAG.', 'this model quantizes the librispeech dataset into 13. 5k unique codes.', 'to understand the impact of acoustic representations baked into the wav2vec features, as alternatives, we explore quantizing the standard melfrequency cepstral coefficients ( mfcc ) and logmel filterbanks coefficients ( fbank ), choosing a subset small enough to fit into gpu memory and running k - means with 13. 5k centroids ( to match the vq - wav2vec setup ) to convergence.', 'we then assign the index of the closest centroid to represent each time - step.', 'we train a standard bert model  #AUTHOR_TAG with only the masked language modeling task on each set of inputs in the same way as described in  #TAUTHOR_TAG, namely by choosing tokens for masking with probability of 0. 05, expanding each chosen token to a span of 10 masked tokens ( spans may overlap ) and then computing a cross - entropy loss which attempts to maximize the likelihood of predicting the true token for each one that was masked ( figure 1a )']",5
"['##2vec quantization model following the gumbel - softmax recipe described in  #TAUTHOR_TAG.', 'after training this model']","['the vq - wav2vec quantization model following the gumbel - softmax recipe described in  #TAUTHOR_TAG.', 'after training this model']","['the vq - wav2vec quantization model following the gumbel - softmax recipe described in  #TAUTHOR_TAG.', 'after training this model']","['first train the vq - wav2vec quantization model following the gumbel - softmax recipe described in  #TAUTHOR_TAG.', 'after training this model for quantizing mfcc and log - mel filterbanks we first compute dense features using the scripts from the kaldi ( povey ) toolkit.', 'we then compute 13. 5k k - means centroids, to match the number of unique tokens produced by the vq - wav2vec model, using 8 32gb volta gpus.', 'to fit into gpu memory, we subsample 50 % of mfcc features and 25 % of fbank features from the training set before running the k - means algorithm.', 'the model we use for the masked language modeling task is a standard bert model with 12 layers, model dimension 768, inner dimension ( ffn ) 3072 and 12 attention heads  #AUTHOR_TAG.', '']",5
"['##2vec quantization model following the gumbel - softmax recipe described in  #TAUTHOR_TAG.', 'after training this model']","['the vq - wav2vec quantization model following the gumbel - softmax recipe described in  #TAUTHOR_TAG.', 'after training this model']","['the vq - wav2vec quantization model following the gumbel - softmax recipe described in  #TAUTHOR_TAG.', 'after training this model']","['first train the vq - wav2vec quantization model following the gumbel - softmax recipe described in  #TAUTHOR_TAG.', 'after training this model for quantizing mfcc and log - mel filterbanks we first compute dense features using the scripts from the kaldi ( povey ) toolkit.', 'we then compute 13. 5k k - means centroids, to match the number of unique tokens produced by the vq - wav2vec model, using 8 32gb volta gpus.', 'to fit into gpu memory, we subsample 50 % of mfcc features and 25 % of fbank features from the training set before running the k - means algorithm.', 'the model we use for the masked language modeling task is a standard bert model with 12 layers, model dimension 768, inner dimension ( ffn ) 3072 and 12 attention heads  #AUTHOR_TAG.', '']",5
"['we wanted to stay consistent with', 'the setup in  #TAUTHOR_TAG. the tandem model']","['we wanted to stay consistent with', 'the setup in  #TAUTHOR_TAG. the tandem model']","['we wanted to stay consistent with', 'the setup in  #TAUTHOR_TAG. the tandem model which uses the features extracted from the pre - trained bert models is a character - based wav2letter setup of  #AUTHOR_TAG which', 'uses seven consecutive blocks of convolutions ( kernel']","['librispeech splits. we use the publicly available wav2letter + +  #AUTHOR_TAG decoder integrated into the fairseq', 'framework with the official librispeech 4gram language model. we run a sweep on weights for language model score, word score and silence token weights for each model, where parameters are', 'chosen randomly and evaluated on the devother librispeech set. we use the weights', 'found by these sweeps to evaluate and report results for all other splits. the sweeps are run with beam size of 250, while the final decoding is done with beam size of 1500. the quantized bert', 'models have a limit of 2048 source tokens due to', 'their use of fixed positional embeddings. during training we discard longer examples and during evaluation we discard randomly chosen tokens from each example until they are', 'at most 2048 tokens long. we expect that increasing the size of the fixed positional embeddings, or switching to relative positional embeddings will improve', 'performance on longer examples, but in this work we wanted to stay consistent with', 'the setup in  #TAUTHOR_TAG. the tandem model which uses the features extracted from the pre - trained bert models is a character - based wav2letter setup of  #AUTHOR_TAG which', 'uses seven consecutive blocks of convolutions ( kernel size 5 with 1. 000 × 10 3 channels ), followed by a prelu nonlinearity and a dropout rate of 1 × 10 −1. the final representation is projected', 'to a 28 - dimensional probability over the vocabulary and decoded using the standard 4gram language model following the same protocol as for the fine - tuned models table 1 presents wers of different input features and pre - training methods on the standard', 'librispeech clean and other subsets using 10 hours and 1 hour of labeled data for fine - tuning. compared to the two - model tandem system proposed in  #TAUTHOR_TAG, which uses a the discrete', 'bert features to train another asr system from scratch, our discrete bert model provides an average of 13 % and 6 % of wer reduction on clean and other', 'subsets respectively, by pre - training and fine - tuning the same bert model on the 10h labeled set. the wav2vec inputs represent one level of unsupervised feature discovery, which provides', 'a better space for quantization compared to raw spectral features. the discrete bert training augments the wa', '##v2vec features with a higher level of representation that captures the sequential structure of the full utterance through the masked language', 'modeling loss. on the other hand, the continuous bert training, given its contrastive infornce loss', ', can be viewed as another level of acoustic representations that captures longer range regularities']",5
"['in  #TAUTHOR_TAG,']","['in  #TAUTHOR_TAG,']","['in  #TAUTHOR_TAG,']","['', 'the first consists of learning sentence embedding with unsupervised learning, e. g., auto - encoder - based models  #AUTHOR_TAG, paragraph vector  #AUTHOR_TAG, skipthought vectors, fastsent  #AUTHOR_TAG, among others.', 'the second category consists of models trained with supervised learning, such as convolution neural networks ( cnn )  #AUTHOR_TAG, recurrent neural networks ( rnn )  #AUTHOR_TAG, and tree - structure recursive networks  #AUTHOR_TAG, just to name a few.', 'pooling is an essential component of a wide variety of sentence representation and embedding models.', 'for example, in recurrent - neural - network - based models, pooling is often used to aggregate hidden states at different time steps ( i. e., words in a sentence ) to obtain sentence embedding.', 'convolutional neural networks ( cnn ) also often uses max or mean pooling to obtain a fixed - size sentence embedding.', 'in this paper we explore generalized pooling methods to enhance sentence embedding.', 'specifically, by extending scalar self - attention models such as those proposed in  #TAUTHOR_TAG, we propose vectorbased multi - head attention, which includes the widely used max pooling, mean pooling, and scalar selfattention itself as special cases.', 'on one hand, the proposed method allows for extracting different aspects of the sentence into multiple vector representations through the multi - head mechanism.', 'on the other, it allows the models to focus on one of many possible interpretations of the words encoded in the context vector through the vector - based attention mechanism.', 'in the proposed model we design penalization terms to reduce redundancy in multi - head attention.', 'we evaluate the proposed model on three different tasks : natural language inference, author profiling, and sentiment classification.', 'the experiments show that the proposed model achieves significant improvement over strong sentence - encoding - based methods, resulting in state - of - the - art performances on four datasets.', 'the proposed approach can be easily implemented for more problems than we discuss in this paper']",3
"['in  #TAUTHOR_TAG,']","['in  #TAUTHOR_TAG,']","['in  #TAUTHOR_TAG,']","['', 'the first consists of learning sentence embedding with unsupervised learning, e. g., auto - encoder - based models  #AUTHOR_TAG, paragraph vector  #AUTHOR_TAG, skipthought vectors, fastsent  #AUTHOR_TAG, among others.', 'the second category consists of models trained with supervised learning, such as convolution neural networks ( cnn )  #AUTHOR_TAG, recurrent neural networks ( rnn )  #AUTHOR_TAG, and tree - structure recursive networks  #AUTHOR_TAG, just to name a few.', 'pooling is an essential component of a wide variety of sentence representation and embedding models.', 'for example, in recurrent - neural - network - based models, pooling is often used to aggregate hidden states at different time steps ( i. e., words in a sentence ) to obtain sentence embedding.', 'convolutional neural networks ( cnn ) also often uses max or mean pooling to obtain a fixed - size sentence embedding.', 'in this paper we explore generalized pooling methods to enhance sentence embedding.', 'specifically, by extending scalar self - attention models such as those proposed in  #TAUTHOR_TAG, we propose vectorbased multi - head attention, which includes the widely used max pooling, mean pooling, and scalar selfattention itself as special cases.', 'on one hand, the proposed method allows for extracting different aspects of the sentence into multiple vector representations through the multi - head mechanism.', 'on the other, it allows the models to focus on one of many possible interpretations of the words encoded in the context vector through the vector - based attention mechanism.', 'in the proposed model we design penalization terms to reduce redundancy in multi - head attention.', 'we evaluate the proposed model on three different tasks : natural language inference, author profiling, and sentiment classification.', 'the experiments show that the proposed model achieves significant improvement over strong sentence - encoding - based methods, resulting in state - of - the - art performances on four datasets.', 'the proposed approach can be easily implemented for more problems than we discuss in this paper']",1
"['', 'not use snli as an additional training / development set in our experiments. age dataset to compare our models with that of  #TAUTHOR_TAG, we use the same age dataset in our experiment', 'here, which is an author profiling']","['', 'not use snli as an additional training / development set in our experiments. age dataset to compare our models with that of  #TAUTHOR_TAG, we use the same age dataset in our experiment', 'here, which is an author profiling']","['', 'not use snli as an additional training / development set in our experiments. age dataset to compare our models with that of  #TAUTHOR_TAG, we use the same age dataset in our experiment', 'here, which is an author profiling']","['', '##li  #AUTHOR_TAG is another natural language inference dataset. the data are collected from a broader range of genres such as', 'fiction, letters, telephone speech, and 9 / 11 reports. half of these 10 genres are used in training while the rest are not, resulting in - domain and cross - domain development and test', 'sets used to test nli systems. we use the same data split as in  #AUTHOR_TAG, i. e., 392, 702 samples for training, 9, 815 / 9,', '832 samples for in - domain / cross - domain development', ', and 9, 796 / 9, 847 samples for in - domain / cross - domain testing. note that, we do', 'not use snli as an additional training / development set in our experiments. age dataset to compare our models with that of  #TAUTHOR_TAG, we use the same age dataset in our experiment', 'here, which is an author profiling dataset. the dataset are extracted from the author profiling dataset 1, which consists of tweets from english twitter. the task is to predict the age range of authors of input tweets. the age range are split into 5 classes : 18 - 24, 25 - 34, 35 - 49, 50 -', '64, 65 +. we use the same data split as in  #TAUTHOR_TAG, i. e.,', '68, 485 samples for training, 4, 000 for development, and 4, 000 for testing']",5
"['', 'not use snli as an additional training / development set in our experiments. age dataset to compare our models with that of  #TAUTHOR_TAG, we use the same age dataset in our experiment', 'here, which is an author profiling']","['', 'not use snli as an additional training / development set in our experiments. age dataset to compare our models with that of  #TAUTHOR_TAG, we use the same age dataset in our experiment', 'here, which is an author profiling']","['', 'not use snli as an additional training / development set in our experiments. age dataset to compare our models with that of  #TAUTHOR_TAG, we use the same age dataset in our experiment', 'here, which is an author profiling']","['', '##li  #AUTHOR_TAG is another natural language inference dataset. the data are collected from a broader range of genres such as', 'fiction, letters, telephone speech, and 9 / 11 reports. half of these 10 genres are used in training while the rest are not, resulting in - domain and cross - domain development and test', 'sets used to test nli systems. we use the same data split as in  #AUTHOR_TAG, i. e., 392, 702 samples for training, 9, 815 / 9,', '832 samples for in - domain / cross - domain development', ', and 9, 796 / 9, 847 samples for in - domain / cross - domain testing. note that, we do', 'not use snli as an additional training / development set in our experiments. age dataset to compare our models with that of  #TAUTHOR_TAG, we use the same age dataset in our experiment', 'here, which is an author profiling dataset. the dataset are extracted from the author profiling dataset 1, which consists of tweets from english twitter. the task is to predict the age range of authors of input tweets. the age range are split into 5 classes : 18 - 24, 25 - 34, 35 - 49, 50 -', '64, 65 +. we use the same data split as in  #TAUTHOR_TAG, i. e.,', '68, 485 samples for training, 4, 000 for development, and 4, 000 for testing']",5
"['positive.', 'we use the same data split as in  #TAUTHOR_TAG, i. e., 500,']","['positive.', 'we use the same data split as in  #TAUTHOR_TAG, i. e., 500, 000 samples for training, 2, 000 for development, and 2, 000 for testing']","['positive.', 'we use the same data split as in  #TAUTHOR_TAG, i. e., 500, 000 samples for training, 2, 000 for development, and 2, 000 for testing']","['yelp dataset 2 is a sentiment analysis task, which takes reviews as input and predicts the level of sentiment in terms of the number of stars, from 1 to 5 stars, where 5 - star means the most positive.', 'we use the same data split as in  #TAUTHOR_TAG, i. e., 500, 000 samples for training, 2, 000 for development, and 2, 000 for testing']",5
"['includes exploring more effective mlp to use the structures of multi - head vectors, inspired by the idea from  #TAUTHOR_TAG.', 'leveraging structure information from syntactic and semantic parses is another']","['includes exploring more effective mlp to use the structures of multi - head vectors, inspired by the idea from  #TAUTHOR_TAG.', 'leveraging structure information from syntactic and semantic parses is another']","['can be easily implemented for more problems than we discuss in this paper.', 'our future work includes exploring more effective mlp to use the structures of multi - head vectors, inspired by the idea from  #TAUTHOR_TAG.', 'leveraging structure information from syntactic and semantic parses is another direction interesting to us']","['this paper, we propose a generalized pooling method for sentence embedding through vector - based multi - head attention, which includes the widely used max pooling, mean pooling, and scalar selfattention as its special cases.', 'specifically the proposed model aims to use vectors to enrich the expressiveness of attention mechanism and leverage proper penalty terms to reduce redundancy in multi - head attention.', 'we evaluate the proposed approach on three different tasks : natural language inference, author profiling, and sentiment classification.', 'the experiments show that the proposed model achieves significant improvement over strong sentence - encoding - based methods, resulting in state - of - the - art performances on four datasets.', 'the proposed approach can be easily implemented for more problems than we discuss in this paper.', 'our future work includes exploring more effective mlp to use the structures of multi - head vectors, inspired by the idea from  #TAUTHOR_TAG.', 'leveraging structure information from syntactic and semantic parses is another direction interesting to us']",2
"[' #TAUTHOR_TAG.', 'the']","['movies or photo albums  #TAUTHOR_TAG.', 'the']","['movies or photo albums  #TAUTHOR_TAG.', 'the type of']","['we first developed language, humans have always told stories.', 'fashioning a good story is an act of creativity and developing algorithms to replicate this has been a long running challenge.', 'adding pictures as input can provide information for guiding story construction by offering visual illustrations of the storyline.', 'in the related task of image captioning, most methods try to generate descriptions only for individual images or for short videos depicting a single activity.', 'very recently, datasets have been introduced that extend this task to longer temporal sequences such as movies or photo albums  #TAUTHOR_TAG.', 'the type of data we consider in this paper provides input illustrations for story generation in the form of photo albums, sampled over a few minutes to a few days of time.', 'for this type of data, generating textual descriptions involves telling a temporally consistent story about the depicted visual information, where stories must be coherent and take into account the temporal context of the images.', 'applications of this include constructing visual and textual summaries of albums, or even enabling search through personal photo collections to find photos of life events.', 'previous visual storytelling works can be classified into two types, vision - based and languagebased, where image or language stories are constructed respectively.', 'among the vision - based approaches, unsupervised learning is commonly applied : e. g.,  #AUTHOR_TAG learns the latent temporal dynamics given a large amount of albums, and  #AUTHOR_TAG formulate the photo selection as a sparse time - varying directed graph.', 'however, these visual summaries tend to be difficult to evaluate and selected photos may not agree with human selections.', 'for languagebased approaches, a sequence of natural language sentences are generated to describe a set of photos.', 'to drive this work ( park and collected a dataset mined from blog posts.', 'however, this kind of data often contains contextual information or loosely related language.', 'a more direct dataset was recently released  #TAUTHOR_TAG, where multi - sentence stories are collected describing photo albums via amazon mechanical turk.', 'in this paper, we make use of the visual storytelling dataset  #TAUTHOR_TAG.', 'while the authors provide a seq2seq baseline, they only deal with the task of generating stories given 5 - representative ( summary ) photos hand - selected by people from an album.', 'instead, we focus on the more challenging and realistic problem of end - toend generation of stories from entire albums.', ""this requires us to either generate a story from all of the album's photos or to learn selection mechanisms to identify representative photos and then generate stories from those summary photos."", 'we evaluate each type of approach.', 'ultimately, we propose a model of']",0
"[' #TAUTHOR_TAG.', 'the']","['movies or photo albums  #TAUTHOR_TAG.', 'the']","['movies or photo albums  #TAUTHOR_TAG.', 'the type of']","['we first developed language, humans have always told stories.', 'fashioning a good story is an act of creativity and developing algorithms to replicate this has been a long running challenge.', 'adding pictures as input can provide information for guiding story construction by offering visual illustrations of the storyline.', 'in the related task of image captioning, most methods try to generate descriptions only for individual images or for short videos depicting a single activity.', 'very recently, datasets have been introduced that extend this task to longer temporal sequences such as movies or photo albums  #TAUTHOR_TAG.', 'the type of data we consider in this paper provides input illustrations for story generation in the form of photo albums, sampled over a few minutes to a few days of time.', 'for this type of data, generating textual descriptions involves telling a temporally consistent story about the depicted visual information, where stories must be coherent and take into account the temporal context of the images.', 'applications of this include constructing visual and textual summaries of albums, or even enabling search through personal photo collections to find photos of life events.', 'previous visual storytelling works can be classified into two types, vision - based and languagebased, where image or language stories are constructed respectively.', 'among the vision - based approaches, unsupervised learning is commonly applied : e. g.,  #AUTHOR_TAG learns the latent temporal dynamics given a large amount of albums, and  #AUTHOR_TAG formulate the photo selection as a sparse time - varying directed graph.', 'however, these visual summaries tend to be difficult to evaluate and selected photos may not agree with human selections.', 'for languagebased approaches, a sequence of natural language sentences are generated to describe a set of photos.', 'to drive this work ( park and collected a dataset mined from blog posts.', 'however, this kind of data often contains contextual information or loosely related language.', 'a more direct dataset was recently released  #TAUTHOR_TAG, where multi - sentence stories are collected describing photo albums via amazon mechanical turk.', 'in this paper, we make use of the visual storytelling dataset  #TAUTHOR_TAG.', 'while the authors provide a seq2seq baseline, they only deal with the task of generating stories given 5 - representative ( summary ) photos hand - selected by people from an album.', 'instead, we focus on the more challenging and realistic problem of end - toend generation of stories from entire albums.', ""this requires us to either generate a story from all of the album's photos or to learn selection mechanisms to identify representative photos and then generate stories from those summary photos."", 'we evaluate each type of approach.', 'ultimately, we propose a model of']",0
"['proposed textually customized summaries.', 'visual storytelling : visual storytelling tries to tell a coherent visual or textual story about an image set.', 'previous works include storyline graph modeling  #AUTHOR_TAG, unsupervised mining  #AUTHOR_TAG, blog - photo alignment, and language retelling  #TAUTHOR_TAG.', 'while ( park and collects data by mining blog posts,  #TAUTHOR_TAG collects stories using mechanical turk, providing more directly relevant stories']","['proposed textually customized summaries.', 'visual storytelling : visual storytelling tries to tell a coherent visual or textual story about an image set.', 'previous works include storyline graph modeling  #AUTHOR_TAG, unsupervised mining  #AUTHOR_TAG, blog - photo alignment, and language retelling  #TAUTHOR_TAG.', 'while ( park and collects data by mining blog posts,  #TAUTHOR_TAG collects stories using mechanical turk, providing more directly relevant stories']","['proposed textually customized summaries.', 'visual storytelling : visual storytelling tries to tell a coherent visual or textual story about an image set.', 'previous works include storyline graph modeling  #AUTHOR_TAG, unsupervised mining  #AUTHOR_TAG, blog - photo alignment, and language retelling  #TAUTHOR_TAG.', 'while ( park and collects data by mining blog posts,  #TAUTHOR_TAG collects stories using mechanical turk, providing more directly relevant stories']","['years have witnessed an explosion of interest in vision and language tasks, reviewed below.', 'visual captioning : most recent approaches to image captioning  #AUTHOR_TAG b ;  #AUTHOR_TAG have used cnn - lstm structures to generate descriptions.', 'for captioning video or movie content  #AUTHOR_TAG, sequence - to - sequence models are widely applied, where the first sequence encodes video frames and the second sequence decodes the description.', 'attention techniques  #AUTHOR_TAG are commonly incorporated for both tasks to localize salient temporal or spatial information.', 'video summarization : similar to documentation summarization  #AUTHOR_TAG which extracts key sentences and words, video summarization selects key frames or shots.', 'while some approaches use unsupervised learning  #AUTHOR_TAG or intuitive criteria to pick salient frames, recent models learn from human - created summaries  #AUTHOR_TAG b, a ;  #AUTHOR_TAG.', 'recently, to better exploit semantics,  #AUTHOR_TAG proposed textually customized summaries.', 'visual storytelling : visual storytelling tries to tell a coherent visual or textual story about an image set.', 'previous works include storyline graph modeling  #AUTHOR_TAG, unsupervised mining  #AUTHOR_TAG, blog - photo alignment, and language retelling  #TAUTHOR_TAG.', 'while ( park and collects data by mining blog posts,  #TAUTHOR_TAG collects stories using mechanical turk, providing more directly relevant stories']",0
"['proposed textually customized summaries.', 'visual storytelling : visual storytelling tries to tell a coherent visual or textual story about an image set.', 'previous works include storyline graph modeling  #AUTHOR_TAG, unsupervised mining  #AUTHOR_TAG, blog - photo alignment, and language retelling  #TAUTHOR_TAG.', 'while ( park and collects data by mining blog posts,  #TAUTHOR_TAG collects stories using mechanical turk, providing more directly relevant stories']","['proposed textually customized summaries.', 'visual storytelling : visual storytelling tries to tell a coherent visual or textual story about an image set.', 'previous works include storyline graph modeling  #AUTHOR_TAG, unsupervised mining  #AUTHOR_TAG, blog - photo alignment, and language retelling  #TAUTHOR_TAG.', 'while ( park and collects data by mining blog posts,  #TAUTHOR_TAG collects stories using mechanical turk, providing more directly relevant stories']","['proposed textually customized summaries.', 'visual storytelling : visual storytelling tries to tell a coherent visual or textual story about an image set.', 'previous works include storyline graph modeling  #AUTHOR_TAG, unsupervised mining  #AUTHOR_TAG, blog - photo alignment, and language retelling  #TAUTHOR_TAG.', 'while ( park and collects data by mining blog posts,  #TAUTHOR_TAG collects stories using mechanical turk, providing more directly relevant stories']","['years have witnessed an explosion of interest in vision and language tasks, reviewed below.', 'visual captioning : most recent approaches to image captioning  #AUTHOR_TAG b ;  #AUTHOR_TAG have used cnn - lstm structures to generate descriptions.', 'for captioning video or movie content  #AUTHOR_TAG, sequence - to - sequence models are widely applied, where the first sequence encodes video frames and the second sequence decodes the description.', 'attention techniques  #AUTHOR_TAG are commonly incorporated for both tasks to localize salient temporal or spatial information.', 'video summarization : similar to documentation summarization  #AUTHOR_TAG which extracts key sentences and words, video summarization selects key frames or shots.', 'while some approaches use unsupervised learning  #AUTHOR_TAG or intuitive criteria to pick salient frames, recent models learn from human - created summaries  #AUTHOR_TAG b, a ;  #AUTHOR_TAG.', 'recently, to better exploit semantics,  #AUTHOR_TAG proposed textually customized summaries.', 'visual storytelling : visual storytelling tries to tell a coherent visual or textual story about an image set.', 'previous works include storyline graph modeling  #AUTHOR_TAG, unsupervised mining  #AUTHOR_TAG, blog - photo alignment, and language retelling  #TAUTHOR_TAG.', 'while ( park and collects data by mining blog posts,  #TAUTHOR_TAG collects stories using mechanical turk, providing more directly relevant stories']",0
"[' #TAUTHOR_TAG.', 'the']","['movies or photo albums  #TAUTHOR_TAG.', 'the']","['movies or photo albums  #TAUTHOR_TAG.', 'the type of']","['we first developed language, humans have always told stories.', 'fashioning a good story is an act of creativity and developing algorithms to replicate this has been a long running challenge.', 'adding pictures as input can provide information for guiding story construction by offering visual illustrations of the storyline.', 'in the related task of image captioning, most methods try to generate descriptions only for individual images or for short videos depicting a single activity.', 'very recently, datasets have been introduced that extend this task to longer temporal sequences such as movies or photo albums  #TAUTHOR_TAG.', 'the type of data we consider in this paper provides input illustrations for story generation in the form of photo albums, sampled over a few minutes to a few days of time.', 'for this type of data, generating textual descriptions involves telling a temporally consistent story about the depicted visual information, where stories must be coherent and take into account the temporal context of the images.', 'applications of this include constructing visual and textual summaries of albums, or even enabling search through personal photo collections to find photos of life events.', 'previous visual storytelling works can be classified into two types, vision - based and languagebased, where image or language stories are constructed respectively.', 'among the vision - based approaches, unsupervised learning is commonly applied : e. g.,  #AUTHOR_TAG learns the latent temporal dynamics given a large amount of albums, and  #AUTHOR_TAG formulate the photo selection as a sparse time - varying directed graph.', 'however, these visual summaries tend to be difficult to evaluate and selected photos may not agree with human selections.', 'for languagebased approaches, a sequence of natural language sentences are generated to describe a set of photos.', 'to drive this work ( park and collected a dataset mined from blog posts.', 'however, this kind of data often contains contextual information or loosely related language.', 'a more direct dataset was recently released  #TAUTHOR_TAG, where multi - sentence stories are collected describing photo albums via amazon mechanical turk.', 'in this paper, we make use of the visual storytelling dataset  #TAUTHOR_TAG.', 'while the authors provide a seq2seq baseline, they only deal with the task of generating stories given 5 - representative ( summary ) photos hand - selected by people from an album.', 'instead, we focus on the more challenging and realistic problem of end - toend generation of stories from entire albums.', ""this requires us to either generate a story from all of the album's photos or to learn selection mechanisms to identify representative photos and then generate stories from those summary photos."", 'we evaluate each type of approach.', 'ultimately, we propose a model of']",5
"['', 'following  #TAUTHOR_TAG, we choose']","['', 'following  #TAUTHOR_TAG, we choose']","['', 'following  #TAUTHOR_TAG, we choose a gated recurrent unit ( gr']","['an album a = { a 1, a 2,..., a n }, composed of a set of photos, we use a bi - directional rnn to encode the local album context for each photo.', 'we first extract the 2048 - dimensional visual representation f i ∈ r k for each photo using resnet101, then a bi - directional rnn is applied to encode the full album.', 'following  #TAUTHOR_TAG, we choose a gated recurrent unit ( gru ) as the rnn unit to encode the photo sequence.', 'the sequence output at each time step encodes the local album context for each photo ( from both directions ).', 'fused with the visual representation followed by relu, our final photo representation is ( top module in fig. 1 )']",5
"['use the visual storytelling dataset  #TAUTHOR_TAG, consisting of']","['use the visual storytelling dataset  #TAUTHOR_TAG, consisting of 10, 000 albums with 200, 000 photos.', '']","['use the visual storytelling dataset  #TAUTHOR_TAG, consisting of']","['use the visual storytelling dataset  #TAUTHOR_TAG, consisting of 10, 000 albums with 200, 000 photos.', 'each album contains 10 - 50 photos taken within a 48 - hour span with two annotations : 1 ) 2 album summarizations, each with 5 selected representative photos, and 2 ) 5 stories describing the selected photos']",5
"['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation']","['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation']","['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation vae ( hr - va']","['', 'with vmf, the kl loss only depends on the concentration parameter which is fixed during training and testing, and hence results in a constant kl loss.', 'in a more recent work,  #AUTHOR_TAG avoided latent variable collapse by including skip connections in the generative model, where the skip connections enforce strong links between the latent variables and the likelihood function.', 'although the aforementioned works show effectiveness in addressing the latent variable collapse issue to some extent, they either require carefully engineering to balance the weight between the reconstruction loss and kl loss  #AUTHOR_TAG or resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation vae ( hr - vae ), which can effectively avoid latent variable collapse.', 'in contrast to existing vae - rnn models for text modelling which merely impose a standard normal distribution prior on the last hidden state of the rnn encoder, our hr - vae model imposes regularisation for all hidden states of the rnn encoder.', 'another advantage of our model is that it is generic and can be applied to any existing vae - rnn - based architectures.', 'we evaluate our model against several strong baselines which apply vae for text modelling  #TAUTHOR_TAG.', 'we conducted experiments based on two public benchmark datasets, namely, the penn']",0
['with a lstm encoder and a dilated cnn decoder  #TAUTHOR_TAG ; vm'],['with a lstm encoder and a dilated cnn decoder  #TAUTHOR_TAG ;'],['with a lstm encoder and a dilated cnn decoder  #TAUTHOR_TAG ; vm'],"['compare our hr - vae model with three strong baselines using vae for text modelling : vae - lstm - base 3 : a variational autoencoder model which uses lstm for both encoder and decoder.', 'kl annealing is used to tackled the latent variable collapse issue  #AUTHOR_TAG ; vae - cnn 4 : a variational autoencoder model with a lstm encoder and a dilated cnn decoder  #TAUTHOR_TAG ; vmf - vae 5 : a variational autoencoder model using lstm for both encoder and decoder where the prior distribution is the von mises - fisher ( vmf ) distribution rather than a gaussian distribution  #AUTHOR_TAG.', 'the decoder needs to predict the entire sequence with only the help of the given latent variable z.', 'in this way, a high - quality representation abstracting the information of the input sentence is much needed for the decoder, and hence enforcing z to learn the required information.', '']",0
"['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation']","['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation']","['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation vae ( hr - va']","['', 'with vmf, the kl loss only depends on the concentration parameter which is fixed during training and testing, and hence results in a constant kl loss.', 'in a more recent work,  #AUTHOR_TAG avoided latent variable collapse by including skip connections in the generative model, where the skip connections enforce strong links between the latent variables and the likelihood function.', 'although the aforementioned works show effectiveness in addressing the latent variable collapse issue to some extent, they either require carefully engineering to balance the weight between the reconstruction loss and kl loss  #AUTHOR_TAG or resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation vae ( hr - vae ), which can effectively avoid latent variable collapse.', 'in contrast to existing vae - rnn models for text modelling which merely impose a standard normal distribution prior on the last hidden state of the rnn encoder, our hr - vae model imposes regularisation for all hidden states of the rnn encoder.', 'another advantage of our model is that it is generic and can be applied to any existing vae - rnn - based architectures.', 'we evaluate our model against several strong baselines which apply vae for text modelling  #TAUTHOR_TAG.', 'we conducted experiments based on two public benchmark datasets, namely, the penn']",5
['with a lstm encoder and a dilated cnn decoder  #TAUTHOR_TAG ; vm'],['with a lstm encoder and a dilated cnn decoder  #TAUTHOR_TAG ;'],['with a lstm encoder and a dilated cnn decoder  #TAUTHOR_TAG ; vm'],"['compare our hr - vae model with three strong baselines using vae for text modelling : vae - lstm - base 3 : a variational autoencoder model which uses lstm for both encoder and decoder.', 'kl annealing is used to tackled the latent variable collapse issue  #AUTHOR_TAG ; vae - cnn 4 : a variational autoencoder model with a lstm encoder and a dilated cnn decoder  #TAUTHOR_TAG ; vmf - vae 5 : a variational autoencoder model using lstm for both encoder and decoder where the prior distribution is the von mises - fisher ( vmf ) distribution rather than a gaussian distribution  #AUTHOR_TAG.', 'the decoder needs to predict the entire sequence with only the help of the given latent variable z.', 'in this way, a high - quality representation abstracting the information of the input sentence is much needed for the decoder, and hence enforcing z to learn the required information.', '']",5
"['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation']","['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation']","['resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation vae ( hr - va']","['', 'with vmf, the kl loss only depends on the concentration parameter which is fixed during training and testing, and hence results in a constant kl loss.', 'in a more recent work,  #AUTHOR_TAG avoided latent variable collapse by including skip connections in the generative model, where the skip connections enforce strong links between the latent variables and the likelihood function.', 'although the aforementioned works show effectiveness in addressing the latent variable collapse issue to some extent, they either require carefully engineering to balance the weight between the reconstruction loss and kl loss  #AUTHOR_TAG or resort to designing more sophisticated model structures  #TAUTHOR_TAG.', 'in this paper, we present a simple architecture called holistic regularisation vae ( hr - vae ), which can effectively avoid latent variable collapse.', 'in contrast to existing vae - rnn models for text modelling which merely impose a standard normal distribution prior on the last hidden state of the rnn encoder, our hr - vae model imposes regularisation for all hidden states of the rnn encoder.', 'another advantage of our model is that it is generic and can be applied to any existing vae - rnn - based architectures.', 'we evaluate our model against several strong baselines which apply vae for text modelling  #TAUTHOR_TAG.', 'we conducted experiments based on two public benchmark datasets, namely, the penn']",4
"['based models in previous works  #TAUTHOR_TAG.', 'that is,']","['vanishing phenomenon.', 'our model design is motivated by one noticeable defect shared by the vae - rnn based models in previous works  #TAUTHOR_TAG.', 'that is,']","['mitigate the kl vanishing phenomenon.', 'our model design is motivated by one noticeable defect shared by the vae - rnn based models in previous works  #TAUTHOR_TAG.', 'that is,']","['this section, we discuss the technical details of the proposed holistic regularisation vae ( hr - vae ) model, a general architecture which can effectively mitigate the kl vanishing phenomenon.', 'our model design is motivated by one noticeable defect shared by the vae - rnn based models in previous works  #TAUTHOR_TAG.', 'that is, all these models, as shown in figure 1a, only impose a standard normal distribution prior on the last hidden state of the rnn encoder, which potentially leads to learning a suboptimal representation of the latent variable and results in model vulnerable to kl loss vanishing.', 'our hypothesis is that to learn a good representation of data and a good generative model, it is crucial to impose the standard normal prior on all the hidden states of the rnn - based encoder ( see figure 1b ), which allows a better regularisation of the model learning process.', 'we implement the hr - vae model using a twolayer lstm for both the encoder and decoder.', 'however, one should note that our architecture can be readily applied to other types of rnn such as gru.', '']",1
['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions'],"['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions. in this paper, we answer the above questions empirically']",['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions'],"['whether it is important at all. for another example, it would be interesting to', 'know whether a local, greedy, transition - based parser can be equipped with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions. in this paper, we answer the above questions empirically. first, we separate out global learning and beam - search, and study the effect of each technique by', 'comparison with a local greedy baseline. our results show that significant improvements are achieved only when the two are jointly applied. second, we show that the accuracies of a local', ', greedy transition - based parser cannot be improved by adding the rich features of  #TAUTHOR_TAG. our result suggests', 'that global learning with beam - search accommodates more complex models with richer features than a local model with greedy search and therefore enables higher accuracies. one interesting aspect of using a global model with beam -', 'search is that it narrows down the contrast between "" local, greedy, transition - based', '']",0
['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions'],"['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions. in this paper, we answer the above questions empirically']",['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions'],"['whether it is important at all. for another example, it would be interesting to', 'know whether a local, greedy, transition - based parser can be equipped with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions. in this paper, we answer the above questions empirically. first, we separate out global learning and beam - search, and study the effect of each technique by', 'comparison with a local greedy baseline. our results show that significant improvements are achieved only when the two are jointly applied. second, we show that the accuracies of a local', ', greedy transition - based parser cannot be improved by adding the rich features of  #TAUTHOR_TAG. our result suggests', 'that global learning with beam - search accommodates more complex models with richer features than a local model with greedy search and therefore enables higher accuracies. one interesting aspect of using a global model with beam -', 'search is that it narrows down the contrast between "" local, greedy, transition - based', '']",1
['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions'],"['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions. in this paper, we answer the above questions empirically']",['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions'],"['whether it is important at all. for another example, it would be interesting to', 'know whether a local, greedy, transition - based parser can be equipped with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions. in this paper, we answer the above questions empirically. first, we separate out global learning and beam - search, and study the effect of each technique by', 'comparison with a local greedy baseline. our results show that significant improvements are achieved only when the two are jointly applied. second, we show that the accuracies of a local', ', greedy transition - based parser cannot be improved by adding the rich features of  #TAUTHOR_TAG. our result suggests', 'that global learning with beam - search accommodates more complex models with richer features than a local model with greedy search and therefore enables higher accuracies. one interesting aspect of using a global model with beam -', 'search is that it narrows down the contrast between "" local, greedy, transition - based', '']",5
['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions'],"['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions. in this paper, we answer the above questions empirically']",['with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions'],"['whether it is important at all. for another example, it would be interesting to', 'know whether a local, greedy, transition - based parser can be equipped with the rich features of  #TAUTHOR_TAG by using the same range of rich feature definitions. in this paper, we answer the above questions empirically. first, we separate out global learning and beam - search, and study the effect of each technique by', 'comparison with a local greedy baseline. our results show that significant improvements are achieved only when the two are jointly applied. second, we show that the accuracies of a local', ', greedy transition - based parser cannot be improved by adding the rich features of  #TAUTHOR_TAG. our result suggests', 'that global learning with beam - search accommodates more complex models with richer features than a local model with greedy search and therefore enables higher accuracies. one interesting aspect of using a global model with beam -', 'search is that it narrows down the contrast between "" local, greedy, transition - based', '']",5
"[' #TAUTHOR_TAG, using']","[' #TAUTHOR_TAG, using']","[' #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],5
"[' #TAUTHOR_TAG, using']","[' #TAUTHOR_TAG, using']","[' #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],5
['increments as  #TAUTHOR_TAG to'],['increments as  #TAUTHOR_TAG to'],"['further evidence, we add rich non - local features in the same increments as  #TAUTHOR_TAG to']","['', 'the above fact shows that rich non - local features are more effective on a global model with a large beam - size.', 'this is a consequence of the interaction between learning and search : a large beam not only reduces search errors, but also enables a more complex model to be trained without overfitting.', 'in contrast to a globally trained model, a local model cannot benefit as much from the power of rich features.', 'with greedy local search, the uas of a local model improves from 89. 15 % with base features to 89. 28 % with all features.', 'beam - search does not bring additional improvements.', 'for further evidence, we add rich non - local features in the same increments as  #TAUTHOR_TAG to both zpar and maltparser, and evaluate uas on the same development data set.', 'original settings are applied to both parsers, with zpar using global learning and beam - search, and maltparser using local learning and greedy search.', ""table 2 shows that while zpar's accuracy consistently improves with the addition of each new set of features, there is very little impact on maltparser's accuracy and in some cases the effect is in fact negative, indicating that the locally trained greedy parser cannot benefit from the rich non - local features."", 'yet another evidence for the support of more complex models by global learning and beamsearch is the work of  #AUTHOR_TAG, where non - projective parsing using online reordering  #AUTHOR_TAG and rich features led to significant improvements over greedy search  #AUTHOR_TAG, achieving state - of - the - art on a range of typologically diverse languages.', '3 characterizing the']",5
"['', 'we derive character - level contextual embeddings from flair  #TAUTHOR_TAG,']","['trained at the character level, the effectiveness of such embeddings has not been studied.', 'we derive character - level contextual embeddings from flair  #TAUTHOR_TAG,']","['', 'we derive character - level contextual embeddings from flair  #TAUTHOR_TAG,']","['studies have shown that pre - trained contextual word embeddings, which assign the same word different vectors in different contexts, improve performance in many tasks. but while contextual embeddings can also be trained at the character level, the effectiveness of such embeddings has not been studied.', 'we derive character - level contextual embeddings from flair  #TAUTHOR_TAG, and apply them to a time normalization task, yielding major performance improvements over the previous state - of - the - art : 51 % error reduction in news and 33 % in clinical notes.', 'we analyze the sources of these improvements, and find that pre - trained contextual character embeddings are more robust to term variations, infrequent terms, and cross - domain changes.', 'we also quantify the size of context that pretrained contextual character embeddings take advantage of, and show that such embeddings capture features like part - of - speech and capitalization']",5
['named entity tagging  #TAUTHOR_TAG'],"['speech tagging and named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,']","['named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,']","['- the - art or competitive results on part - of - speech tagging and named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,  #AUTHOR_TAG similarly apply a bidirectional long short term memory network ( lstm ) layer on all characters of a', 'sentence and generate contextual word embeddings by concatenating the forward and backward lstm hidden states of the first and last character in each word. together with other techniques, they achieve state - of - the - art performance on part - of - speech and morphological tagging. however,', 'both  #TAUTHOR_TAG and  #AUTHOR_TAG discard all other contextual character embeddings, and no analyses of the models', ""are performed at the character - level. in the current paper, we derive pre - trained contextual character embeddings from flair's forwardbackward lm trained on a 1 - billion word corpus of english  #AUTHOR_TAG, and observe if these embeddings"", '']",0
['named entity tagging  #TAUTHOR_TAG'],"['speech tagging and named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,']","['named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,']","['- the - art or competitive results on part - of - speech tagging and named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,  #AUTHOR_TAG similarly apply a bidirectional long short term memory network ( lstm ) layer on all characters of a', 'sentence and generate contextual word embeddings by concatenating the forward and backward lstm hidden states of the first and last character in each word. together with other techniques, they achieve state - of - the - art performance on part - of - speech and morphological tagging. however,', 'both  #TAUTHOR_TAG and  #AUTHOR_TAG discard all other contextual character embeddings, and no analyses of the models', ""are performed at the character - level. in the current paper, we derive pre - trained contextual character embeddings from flair's forwardbackward lm trained on a 1 - billion word corpus of english  #AUTHOR_TAG, and observe if these embeddings"", '']",0
['named entity tagging  #TAUTHOR_TAG'],"['speech tagging and named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,']","['named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,']","['- the - art or competitive results on part - of - speech tagging and named entity tagging  #TAUTHOR_TAG. though they do not pre - train a lm,  #AUTHOR_TAG similarly apply a bidirectional long short term memory network ( lstm ) layer on all characters of a', 'sentence and generate contextual word embeddings by concatenating the forward and backward lstm hidden states of the first and last character in each word. together with other techniques, they achieve state - of - the - art performance on part - of - speech and morphological tagging. however,', 'both  #TAUTHOR_TAG and  #AUTHOR_TAG discard all other contextual character embeddings, and no analyses of the models', ""are performed at the character - level. in the current paper, we derive pre - trained contextual character embeddings from flair's forwardbackward lm trained on a 1 - billion word corpus of english  #AUTHOR_TAG, and observe if these embeddings"", '']",1
"[' #TAUTHOR_TAG.', 'table']","[' #TAUTHOR_TAG.', 'table']","['perform a feature ablation to see if pre - trained contextual character embeddings capture basic syntax ( e. g., part - of - speech ) like pre - trained contextual word embeddings do  #TAUTHOR_TAG.', 'table 5 shows that removing both part - of - speech and unicode category features from cont (']","['perform a feature ablation to see if pre - trained contextual character embeddings capture basic syntax ( e. g., part - of - speech ) like pre - trained contextual word embeddings do  #TAUTHOR_TAG.', 'table 5 shows that removing both part - of - speech and unicode category features from cont ( 4096 ) table 5 : effect of features on performance : performance ( f 1 ) with different feature sets, including characters ( c ), part - of - speech tags ( p ), and unicode character categories ( u ).', 'formance for both rand ( 128 ) and rand ( 4096 ) in all cases.', 'for example, rand ( 4096 ) with all features achieves 82. 7 f 1 on news dev, significantly better than the 80. 5 f 1 of using only characters ( p = 0. 0467 ).', 'we conclude that pre - trained contextual character embeddings encode a variety of word category information such as part - of - speech, capitalization, and punctuation']",7
['surface features  #TAUTHOR_TAG'],"['features, unless the dense vectors are combined with the hand - crafted surface features  #TAUTHOR_TAG']","['features, unless the dense vectors are combined with the hand - crafted surface features  #TAUTHOR_TAG.', 'in this work, we explore multiple neural architectures in an attempt to']","['', 'first, they can model the argument of an implicit discourse relation as dense vectors and suffer less from the data sparsity problem that is typical of the traditional feature engineering paradigm.', 'second, they should be easily extended to other languages as they do not require human - annotated lexicons.', 'however, despite the many nice properties of neural network models, it is not clear how well they will fare with a small dataset, typicalley found in discourse annotation projects.', 'moreover, it is not straightforward to construct a single vector that properly represents the "" semantics "" of the ar - guments.', 'as a result, neural network models that use dense vectors have been shown to have inferior performance against traditional systems that use manually crafted features, unless the dense vectors are combined with the hand - crafted surface features  #TAUTHOR_TAG.', 'in this work, we explore multiple neural architectures in an attempt to find the best distributed representation and neural network architecture suitable for this task in both english and chinese.', 'we do this by probing the different points on the spectrum of structurality from structureless bag - of - words']",0
"['require extensive feature selection to work well  #TAUTHOR_TAG.', 'the']","['require extensive feature selection to work well  #TAUTHOR_TAG.', 'the']","['require extensive feature selection to work well  #TAUTHOR_TAG.', 'the work we report here explores the use of the expressive power']","['prevailing approach for this task is to use surface features derived from various semantic lexicons  #AUTHOR_TAG, reducing the number of parameters by mapping raw word tokens in the arguments of discourse relations to a limited number of entries in a semantic lexicon such as polarity and verb classes.', 'along the same vein, brown cluster assignments have also been used as a general purpose lexicon that requires no human manual annotation  #AUTHOR_TAG.', 'however, these solutions still suffer from the data sparsity problem and almost always require extensive feature selection to work well  #TAUTHOR_TAG.', 'the work we report here explores the use of the expressive power of distributed representations to overcome the data sparsity problem found in the traditional feature engineering paradigm.', 'neural network modeling has attracted much attention in the nlp community recently and has been explored to some extent in the context of this task.', ' #AUTHOR_TAG tested various word vectors as features for implicit discourse relation classification and show that distributed features achieve the same level of accuracy as one - hot representations in some experimental settings.', ' #AUTHOR_TAG ; 2016 ) advance the state of the art for this task using recursive and recurrent neural networks.', '']",0
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],0
"['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing']","['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing']","['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing all tokenization is taken from']","['want to test the effectiveness of the interargument interaction and the three models described above on the fine - grained discourse relations in english.', 'the data split and the label set are exactly the same as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing all tokenization is taken from the gold standard tokenization in the ptb  #AUTHOR_TAG.', 'we use the berkeley parser to parse all of the data  #AUTHOR_TAG too little data, 50 - dimensional wsj - trained word vectors have previously been shown to be the most effective in this task  #TAUTHOR_TAG.', 'additionally, we also test the off - the - shelf word vectors trained on billions of tokens from google news data freely available with the word2vec tool.', 'all word vectors are trained on the skipgram architecture  #AUTHOR_TAG b ;  #AUTHOR_TAG a ).', 'other models such as glove and continuous bag - of - words seem to yield broadly similar results  #AUTHOR_TAG.', 'we keep the word vectors fixed, instead of fine - tuning during training']",0
"[' #TAUTHOR_TAG.', 'our model differs from their model in several ways']","[' #TAUTHOR_TAG.', 'our model differs from their model in several ways.', 'we use the lstm networks']","[' #TAUTHOR_TAG.', 'our model differs from their model in several ways.', 'we use the lstm networks']","['', 'the mathematical formulation is the same as  #AUTHOR_TAG.', 'this model is similar to the recursive neural networks proposed by  #TAUTHOR_TAG.', 'our model differs from their model in several ways.', 'we use the lstm networks instead of the "" vanilla "" rnn formula and expect better results due to less complication with vanishing and exploding gradients during training.', 'furthermore, our purpose is to compare the influence of the model structures.', 'therefore, we must use lstm cells in both sequential and tree lstm models for a fair and meaningful comparison.', 'the more indepth comparison of our work and recursive neural network model by  #TAUTHOR_TAG is provided in the discussion section']",3
"['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing']","['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing']","['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing all tokenization is taken from']","['want to test the effectiveness of the interargument interaction and the three models described above on the fine - grained discourse relations in english.', 'the data split and the label set are exactly the same as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing all tokenization is taken from the gold standard tokenization in the ptb  #AUTHOR_TAG.', 'we use the berkeley parser to parse all of the data  #AUTHOR_TAG too little data, 50 - dimensional wsj - trained word vectors have previously been shown to be the most effective in this task  #TAUTHOR_TAG.', 'additionally, we also test the off - the - shelf word vectors trained on billions of tokens from google news data freely available with the word2vec tool.', 'all word vectors are trained on the skipgram architecture  #AUTHOR_TAG b ;  #AUTHOR_TAG a ).', 'other models such as glove and continuous bag - of - words seem to yield broadly similar results  #AUTHOR_TAG.', 'we keep the word vectors fixed, instead of fine - tuning during training']",3
"[' #TAUTHOR_TAG.', 'our model differs from their model in several ways']","[' #TAUTHOR_TAG.', 'our model differs from their model in several ways.', 'we use the lstm networks']","[' #TAUTHOR_TAG.', 'our model differs from their model in several ways.', 'we use the lstm networks']","['', 'the mathematical formulation is the same as  #AUTHOR_TAG.', 'this model is similar to the recursive neural networks proposed by  #TAUTHOR_TAG.', 'our model differs from their model in several ways.', 'we use the lstm networks instead of the "" vanilla "" rnn formula and expect better results due to less complication with vanishing and exploding gradients during training.', 'furthermore, our purpose is to compare the influence of the model structures.', 'therefore, we must use lstm cells in both sequential and tree lstm models for a fair and meaningful comparison.', 'the more indepth comparison of our work and recursive neural network model by  #TAUTHOR_TAG is provided in the discussion section']",7
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', '']","['', 'word vectors are already trained to encode the words in their linguistic context especially information from word order.', 'our discussion would not be complete without explaining our results in relation to the recursive neural network model proposed by  #TAUTHOR_TAG.', 'why do sequential lstm models outperform recursive neural networks or tree lstm models?', 'although this first comes as a surprise to us, the results are consistent with recent works that use sequential lstm to encode syntactic information.', 'for example,  #AUTHOR_TAG use sequential lstm to encode the features for syntactic parse output.', 'tree lstm seems to show improvement when there is a need to model longdistance dependency in the data  #AUTHOR_TAG.', 'furthermore, the benefits of tree lstm are not readily apparent for a model that discards the syntactic categories in the intermediate nodes and makes no distinction between heads and their dependents, which are at the core of syntactic representations.', 'another point of contrast between our work and  #TAUTHOR_TAG is the modeling choice for inter - argument interaction.', 'our experimental results show that the hidden layers are an important contributor to the performance for all of our models.', 'we choose linear inter - argument interaction instead of bilinear interaction, and this decision gives us at least two advantages.', 'linear interaction allows us to stack up hidden layers without the exponential growth in the number of parameters.', 'secondly, using linear interaction allows us to use high dimensional word vectors, which we found to be another important component for the performance.', 'the recursive model by  #TAUTHOR_TAG is limited to 50 units due to the bilinear layer.', 'our choice of linear interargument interaction and high - dimensional word vectors turns out to be crucial to building a competitive neural network model for classifying implicit discourse relations.', '6 extending the results across label sets and languages', 'do our feedforward models perform well without surface features across different label sets and languages as well? we want to extend our results to another label set and language by evaluating our']",7
"['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing']","['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing']","['as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing all tokenization is taken from']","['want to test the effectiveness of the interargument interaction and the three models described above on the fine - grained discourse relations in english.', 'the data split and the label set are exactly the same as previous works that use this label set  #TAUTHOR_TAG.', 'preprocessing all tokenization is taken from the gold standard tokenization in the ptb  #AUTHOR_TAG.', 'we use the berkeley parser to parse all of the data  #AUTHOR_TAG too little data, 50 - dimensional wsj - trained word vectors have previously been shown to be the most effective in this task  #TAUTHOR_TAG.', 'additionally, we also test the off - the - shelf word vectors trained on billions of tokens from google news data freely available with the word2vec tool.', 'all word vectors are trained on the skipgram architecture  #AUTHOR_TAG b ;  #AUTHOR_TAG a ).', 'other models such as glove and continuous bag - of - words seem to yield broadly similar results  #AUTHOR_TAG.', 'we keep the word vectors fixed, instead of fine - tuning during training']",5
['layer introduced by  #TAUTHOR_TAG ( p < 0. 05 ; bootstrap test ) and performs comparably with'],['layer introduced by  #TAUTHOR_TAG ( p < 0. 05 ; bootstrap test ) and performs comparably with'],"['of the neural architectures we explore ( table 2 ).', 'it outperforms the recursive neural network with bilinear output layer introduced by  #TAUTHOR_TAG ( p < 0. 05 ; bootstrap test ) and performs comparably with the surface feature baseline  #AUTHOR_TAG, which uses various lexical and syntactic features and extensive feature selection.', 'tree lstm']","['feedforward model performs best overall among all of the neural architectures we explore ( table 2 ).', 'it outperforms the recursive neural network with bilinear output layer introduced by  #TAUTHOR_TAG ( p < 0. 05 ; bootstrap test ) and performs comparably with the surface feature baseline  #AUTHOR_TAG, which uses various lexical and syntactic features and extensive feature selection.', 'tree lstm achieves inferior accuracy than our best feedforward model.', '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', '']","['', 'word vectors are already trained to encode the words in their linguistic context especially information from word order.', 'our discussion would not be complete without explaining our results in relation to the recursive neural network model proposed by  #TAUTHOR_TAG.', 'why do sequential lstm models outperform recursive neural networks or tree lstm models?', 'although this first comes as a surprise to us, the results are consistent with recent works that use sequential lstm to encode syntactic information.', 'for example,  #AUTHOR_TAG use sequential lstm to encode the features for syntactic parse output.', 'tree lstm seems to show improvement when there is a need to model longdistance dependency in the data  #AUTHOR_TAG.', 'furthermore, the benefits of tree lstm are not readily apparent for a model that discards the syntactic categories in the intermediate nodes and makes no distinction between heads and their dependents, which are at the core of syntactic representations.', 'another point of contrast between our work and  #TAUTHOR_TAG is the modeling choice for inter - argument interaction.', 'our experimental results show that the hidden layers are an important contributor to the performance for all of our models.', 'we choose linear inter - argument interaction instead of bilinear interaction, and this decision gives us at least two advantages.', 'linear interaction allows us to stack up hidden layers without the exponential growth in the number of parameters.', 'secondly, using linear interaction allows us to use high dimensional word vectors, which we found to be another important component for the performance.', 'the recursive model by  #TAUTHOR_TAG is limited to 50 units due to the bilinear layer.', 'our choice of linear interargument interaction and high - dimensional word vectors turns out to be crucial to building a competitive neural network model for classifying implicit discourse relations.', '6 extending the results across label sets and languages', 'do our feedforward models perform well without surface features across different label sets and languages as well? we want to extend our results to another label set and language by evaluating our']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', '']","['', 'word vectors are already trained to encode the words in their linguistic context especially information from word order.', 'our discussion would not be complete without explaining our results in relation to the recursive neural network model proposed by  #TAUTHOR_TAG.', 'why do sequential lstm models outperform recursive neural networks or tree lstm models?', 'although this first comes as a surprise to us, the results are consistent with recent works that use sequential lstm to encode syntactic information.', 'for example,  #AUTHOR_TAG use sequential lstm to encode the features for syntactic parse output.', 'tree lstm seems to show improvement when there is a need to model longdistance dependency in the data  #AUTHOR_TAG.', 'furthermore, the benefits of tree lstm are not readily apparent for a model that discards the syntactic categories in the intermediate nodes and makes no distinction between heads and their dependents, which are at the core of syntactic representations.', 'another point of contrast between our work and  #TAUTHOR_TAG is the modeling choice for inter - argument interaction.', 'our experimental results show that the hidden layers are an important contributor to the performance for all of our models.', 'we choose linear inter - argument interaction instead of bilinear interaction, and this decision gives us at least two advantages.', 'linear interaction allows us to stack up hidden layers without the exponential growth in the number of parameters.', 'secondly, using linear interaction allows us to use high dimensional word vectors, which we found to be another important component for the performance.', 'the recursive model by  #TAUTHOR_TAG is limited to 50 units due to the bilinear layer.', 'our choice of linear interargument interaction and high - dimensional word vectors turns out to be crucial to building a competitive neural network model for classifying implicit discourse relations.', '6 extending the results across label sets and languages', 'do our feedforward models perform well without surface features across different label sets and languages as well? we want to extend our results to another label set and language by evaluating our']",4
"['process  #AUTHOR_TAG,  #TAUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural']","['process  #AUTHOR_TAG,  #TAUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural']","['deep models including hierarchical dirichlet process, chinese restaurant process  #AUTHOR_TAG,  #TAUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural network  #AUTHOR_TAG, long short - term memory  #AUTHOR_TAG sequence - to - sequence model  #AUTHOR_TAG, variational auto - encoder']","['tutorial introduces the advances in deep bayesian learning with abundant applications for natural language understanding ranging from speech recognition  #AUTHOR_TAG to document summarization  #AUTHOR_TAG, text classification  #AUTHOR_TAG, text segmentation  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, image caption generation  #AUTHOR_TAG, sentence generation  #AUTHOR_TAG b ), dialogue control  #AUTHOR_TAG a ), sentiment classification, recommendation system, question answering  #AUTHOR_TAG and machine translation, to name a few.', 'traditionally, "" deep learning "" is taken to be a learning process where the inference or optimization is based on the real - valued deterministic model.', 'the "" semantic structure "" in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs.', 'the "" distribution function "" in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated in model inference.', 'this tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced bayesian models and deep models including hierarchical dirichlet process, chinese restaurant process  #AUTHOR_TAG,  #TAUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural network  #AUTHOR_TAG, long short - term memory  #AUTHOR_TAG sequence - to - sequence model  #AUTHOR_TAG, variational auto - encoder  #AUTHOR_TAG, generative adversarial network  #AUTHOR_TAG, attention mechanism  #AUTHOR_TAG, memory - augmented neural network  #AUTHOR_TAG, stochastic neural network  #AUTHOR_TAG, predictive state neural network  #AUTHOR_TAG, policy gradient  #AUTHOR_TAG and reinforcement learning  #AUTHOR_TAG.', '']",5
"['process  #AUTHOR_TAG,  #TAUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural']","['process  #AUTHOR_TAG,  #TAUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural']","['deep models including hierarchical dirichlet process, chinese restaurant process  #AUTHOR_TAG,  #TAUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural network  #AUTHOR_TAG, long short - term memory  #AUTHOR_TAG sequence - to - sequence model  #AUTHOR_TAG, variational auto - encoder']","['tutorial introduces the advances in deep bayesian learning with abundant applications for natural language understanding ranging from speech recognition  #AUTHOR_TAG to document summarization  #AUTHOR_TAG, text classification  #AUTHOR_TAG, text segmentation  #AUTHOR_TAG, information extraction  #AUTHOR_TAG, image caption generation  #AUTHOR_TAG, sentence generation  #AUTHOR_TAG b ), dialogue control  #AUTHOR_TAG a ), sentiment classification, recommendation system, question answering  #AUTHOR_TAG and machine translation, to name a few.', 'traditionally, "" deep learning "" is taken to be a learning process where the inference or optimization is based on the real - valued deterministic model.', 'the "" semantic structure "" in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs.', 'the "" distribution function "" in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated in model inference.', 'this tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced bayesian models and deep models including hierarchical dirichlet process, chinese restaurant process  #AUTHOR_TAG,  #TAUTHOR_TAG, indian buffet process  #AUTHOR_TAG, recurrent neural network  #AUTHOR_TAG, long short - term memory  #AUTHOR_TAG sequence - to - sequence model  #AUTHOR_TAG, variational auto - encoder  #AUTHOR_TAG, generative adversarial network  #AUTHOR_TAG, attention mechanism  #AUTHOR_TAG, memory - augmented neural network  #AUTHOR_TAG, stochastic neural network  #AUTHOR_TAG, predictive state neural network  #AUTHOR_TAG, policy gradient  #AUTHOR_TAG and reinforcement learning  #AUTHOR_TAG.', '']",0
"['negative situation  #TAUTHOR_TAG, or discriminative n - grams  #AUTHOR_TAG a ;  #AUTHOR_TAG.', '']","['negative situation  #TAUTHOR_TAG, or discriminative n - grams  #AUTHOR_TAG a ;  #AUTHOR_TAG.', 'thus,']","['- based sentiment  #AUTHOR_TAG, a positive verb being followed by a negative situation  #TAUTHOR_TAG, or discriminative n - grams  #AUTHOR_TAG a ;  #AUTHOR_TAG.', '']","[""##asm is defined as'a cutting, often ironic remark intended to express contempt or ridicule'1."", 'sarcasm detection is the task of predicting a text as sarcastic or non - sarcastic.', 'the past work in sarcasm detection involves rule - based and statistical approaches using : ( a ) unigrams and pragmatic features ( such as emoticons, etc. ) ( gonzalez -  #AUTHOR_TAG, ( b ) extraction of common patterns, such as hashtag - based sentiment  #AUTHOR_TAG, a positive verb being followed by a negative situation  #TAUTHOR_TAG, or discriminative n - grams  #AUTHOR_TAG a ;  #AUTHOR_TAG.', 'thus, the past work detects sarcasm with specific indicators.', 'however, we believe that it is time that sarcasm detection is based on well - studied linguistic theories.', 'in this paper, we use one such linguistic theory : context incongruity.', 'although the past work exploits incongruity, it does so piecemeal ; we take a more well - rounded view of incongruity and place it center - stage for our work.', '1 source : the free dictionary', ""the features of our sarcasm detection system are based on two kinds of incongruity :'explicit'and'implicit '."", 'the contribution of this paper is :', '• we present a sarcasm detection system that is grounded on a linguistic theory, the theory of context incongruity in our case.', 'sarcasm detection research can push the frontiers by taking help of well - studied linguistic theories.', '• our sarcasm detection system outperforms two state - of - art sarcasm detection systems  #TAUTHOR_TAG.', ""our system shows an improvement for short'tweets'as well as long'discussion forum posts '."", ""• we introduce inter - sentential incongruity for sarcasm detection, that expands context of a discussion forum post by including the previous post ( also known as the'elicitor'post ) in the discussion thread."", 'rest of the paper is organized as follows.', '']",0
"['negative situation  #TAUTHOR_TAG, or discriminative n - grams  #AUTHOR_TAG a ;  #AUTHOR_TAG.', '']","['negative situation  #TAUTHOR_TAG, or discriminative n - grams  #AUTHOR_TAG a ;  #AUTHOR_TAG.', 'thus,']","['- based sentiment  #AUTHOR_TAG, a positive verb being followed by a negative situation  #TAUTHOR_TAG, or discriminative n - grams  #AUTHOR_TAG a ;  #AUTHOR_TAG.', '']","[""##asm is defined as'a cutting, often ironic remark intended to express contempt or ridicule'1."", 'sarcasm detection is the task of predicting a text as sarcastic or non - sarcastic.', 'the past work in sarcasm detection involves rule - based and statistical approaches using : ( a ) unigrams and pragmatic features ( such as emoticons, etc. ) ( gonzalez -  #AUTHOR_TAG, ( b ) extraction of common patterns, such as hashtag - based sentiment  #AUTHOR_TAG, a positive verb being followed by a negative situation  #TAUTHOR_TAG, or discriminative n - grams  #AUTHOR_TAG a ;  #AUTHOR_TAG.', 'thus, the past work detects sarcasm with specific indicators.', 'however, we believe that it is time that sarcasm detection is based on well - studied linguistic theories.', 'in this paper, we use one such linguistic theory : context incongruity.', 'although the past work exploits incongruity, it does so piecemeal ; we take a more well - rounded view of incongruity and place it center - stage for our work.', '1 source : the free dictionary', ""the features of our sarcasm detection system are based on two kinds of incongruity :'explicit'and'implicit '."", 'the contribution of this paper is :', '• we present a sarcasm detection system that is grounded on a linguistic theory, the theory of context incongruity in our case.', 'sarcasm detection research can push the frontiers by taking help of well - studied linguistic theories.', '• our sarcasm detection system outperforms two state - of - art sarcasm detection systems  #TAUTHOR_TAG.', ""our system shows an improvement for short'tweets'as well as long'discussion forum posts '."", ""• we introduce inter - sentential incongruity for sarcasm detection, that expands context of a discussion forum post by including the previous post ( also known as the'elicitor'post ) in the discussion thread."", 'rest of the paper is organized as follows.', '']",4
['in  #TAUTHOR_TAG in two ways : ( a ) they extract only positive verbs'],['in  #TAUTHOR_TAG in two ways : ( a ) they extract only positive verbs'],['in  #TAUTHOR_TAG in two ways : ( a ) they extract only positive verbs'],"['use phrases with implicit sentiment as the implicit incongruity features.', ""these phrases are sentiment - bearing verb and noun phrases, the latter being situations with implied sentiment ( e. g.'getting late for work')."", 'for this, we modify the algorithm given in  #TAUTHOR_TAG in two ways : ( a ) they extract only positive verbs and negative noun situation phrases.', '']",4
"['##6 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4']","['/ dev. twitter. com / ). a similar hashtagbased approach to create a sarcasm - annotated dataset was employed', 'in gonzalez -  #AUTHOR_TAG. as an additional quality check, a rough glance through the tweets is done, and the ones found to be wrong are removed. the hashtags mentioned above are removed from the text so that they act as labels but not as features. 2', '. tweet - b ( 2278 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4. 2, on a dataset of', '4000 tweets ( 50 % sarcastic ) ( also created using hashtag - based supervision ). the algorithm results', 'in a total of 79 verb phrases and 202 noun phrases. we train our classifiers for different feature combinations, using libsvm with rbf kernel  #AUTHOR_TAG, and report average 5 - fold cross - validation values. table 2 : comparative results for tweet - a using rule - based algorithm and statistical classifiers using our feature combinations 6 evaluation table 2 shows', '']",4
"['##6 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4']","['/ dev. twitter. com / ). a similar hashtagbased approach to create a sarcasm - annotated dataset was employed', 'in gonzalez -  #AUTHOR_TAG. as an additional quality check, a rough glance through the tweets is done, and the ones found to be wrong are removed. the hashtags mentioned above are removed from the text so that they act as labels but not as features. 2', '. tweet - b ( 2278 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4. 2, on a dataset of', '4000 tweets ( 50 % sarcastic ) ( also created using hashtag - based supervision ). the algorithm results', 'in a total of 79 verb phrases and 202 noun phrases. we train our classifiers for different feature combinations, using libsvm with rbf kernel  #AUTHOR_TAG, and report average 5 - fold cross - validation values. table 2 : comparative results for tweet - a using rule - based algorithm and statistical classifiers using our feature combinations 6 evaluation table 2 shows', '']",4
"['##6 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4']","['/ dev. twitter. com / ). a similar hashtagbased approach to create a sarcasm - annotated dataset was employed', 'in gonzalez -  #AUTHOR_TAG. as an additional quality check, a rough glance through the tweets is done, and the ones found to be wrong are removed. the hashtags mentioned above are removed from the text so that they act as labels but not as features. 2', '. tweet - b ( 2278 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4. 2, on a dataset of', '4000 tweets ( 50 % sarcastic ) ( also created using hashtag - based supervision ). the algorithm results', 'in a total of 79 verb phrases and 202 noun phrases. we train our classifiers for different feature combinations, using libsvm with rbf kernel  #AUTHOR_TAG, and report average 5 - fold cross - validation values. table 2 : comparative results for tweet - a using rule - based algorithm and statistical classifiers using our feature combinations 6 evaluation table 2 shows', '']",4
['past works  #TAUTHOR_TAG with'],['past works  #TAUTHOR_TAG with'],['also outperforms two past works  #TAUTHOR_TAG with'],[' #TAUTHOR_TAG'],4
"['.', 'our feature engineering is based on  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG state that sarcasm is a contrast between positive sentiment word and a negative situation.', 'they implement a rule - based system that uses phrases of positive verb phrases and negative situations']","['is architecturally similar to  #AUTHOR_TAG b ) who use a semi - supervised pattern acquisition followed by classification.', 'our feature engineering is based on  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG state that sarcasm is a contrast between positive sentiment word and a negative situation.', 'they implement a rule - based system that uses phrases of positive verb phrases and negative situations']","['.', 'our feature engineering is based on  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG state that sarcasm is a contrast between positive sentiment word and a negative situation.', 'they implement a rule - based system that uses phrases of positive verb phrases and negative situations']","['##asm / irony as a linguistic phenomenon has been extensively studied.', 'according to  #AUTHOR_TAG, sarcasm arises from situational disparity.', 'the relationship between context incongruity and sarcasm processing ( by humans ) has been studied in  #AUTHOR_TAG.', ' #AUTHOR_TAG use a dataset of dutch tweets that contain sarcasmrelated hashtags and implement a classifier to predict sarcasm.', 'a recent work by? ) takes the output of sarcasm detection as an input to sentiment classification.', 'they present a rule - based system that uses the pattern : if the sentiment of a tokenized hashtag does not agree with sentiment in rest of the tweet, the tweet is sarcastic, in addition to other rules.', 'our approach is architecturally similar to  #AUTHOR_TAG b ) who use a semi - supervised pattern acquisition followed by classification.', 'our feature engineering is based on  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG state that sarcasm is a contrast between positive sentiment word and a negative situation.', 'they implement a rule - based system that uses phrases of positive verb phrases and negative situations extracted from a corpus of sarcastic tweets.', ' #AUTHOR_TAG present a novel approach to detect thwarting : the phenomenon where sentiment in major portions of text is reversed by sentiment in smaller, conclusive portions']",3
"['##6 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4']","['/ dev. twitter. com / ). a similar hashtagbased approach to create a sarcasm - annotated dataset was employed', 'in gonzalez -  #AUTHOR_TAG. as an additional quality check, a rough glance through the tweets is done, and the ones found to be wrong are removed. the hashtags mentioned above are removed from the text so that they act as labels but not as features. 2', '. tweet - b ( 2278 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4. 2, on a dataset of', '4000 tweets ( 50 % sarcastic ) ( also created using hashtag - based supervision ). the algorithm results', 'in a total of 79 verb phrases and 202 noun phrases. we train our classifiers for different feature combinations, using libsvm with rbf kernel  #AUTHOR_TAG, and report average 5 - fold cross - validation values. table 2 : comparative results for tweet - a using rule - based algorithm and statistical classifiers using our feature combinations 6 evaluation table 2 shows', '']",3
"['.', 'our feature engineering is based on  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG state that sarcasm is a contrast between positive sentiment word and a negative situation.', 'they implement a rule - based system that uses phrases of positive verb phrases and negative situations']","['is architecturally similar to  #AUTHOR_TAG b ) who use a semi - supervised pattern acquisition followed by classification.', 'our feature engineering is based on  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG state that sarcasm is a contrast between positive sentiment word and a negative situation.', 'they implement a rule - based system that uses phrases of positive verb phrases and negative situations']","['.', 'our feature engineering is based on  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG state that sarcasm is a contrast between positive sentiment word and a negative situation.', 'they implement a rule - based system that uses phrases of positive verb phrases and negative situations']","['##asm / irony as a linguistic phenomenon has been extensively studied.', 'according to  #AUTHOR_TAG, sarcasm arises from situational disparity.', 'the relationship between context incongruity and sarcasm processing ( by humans ) has been studied in  #AUTHOR_TAG.', ' #AUTHOR_TAG use a dataset of dutch tweets that contain sarcasmrelated hashtags and implement a classifier to predict sarcasm.', 'a recent work by? ) takes the output of sarcasm detection as an input to sentiment classification.', 'they present a rule - based system that uses the pattern : if the sentiment of a tokenized hashtag does not agree with sentiment in rest of the tweet, the tweet is sarcastic, in addition to other rules.', 'our approach is architecturally similar to  #AUTHOR_TAG b ) who use a semi - supervised pattern acquisition followed by classification.', 'our feature engineering is based on  #TAUTHOR_TAG and  #AUTHOR_TAG.', ' #AUTHOR_TAG state that sarcasm is a contrast between positive sentiment word and a negative situation.', 'they implement a rule - based system that uses phrases of positive verb phrases and negative situations extracted from a corpus of sarcastic tweets.', ' #AUTHOR_TAG present a novel approach to detect thwarting : the phenomenon where sentiment in major portions of text is reversed by sentiment in smaller, conclusive portions']",5
"['##6 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4']","['/ dev. twitter. com / ). a similar hashtagbased approach to create a sarcasm - annotated dataset was employed', 'in gonzalez -  #AUTHOR_TAG. as an additional quality check, a rough glance through the tweets is done, and the ones found to be wrong are removed. the hashtags mentioned above are removed from the text so that they act as labels but not as features. 2', '. tweet - b ( 2278 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4. 2, on a dataset of', '4000 tweets ( 50 % sarcastic ) ( also created using hashtag - based supervision ). the algorithm results', 'in a total of 79 verb phrases and 202 noun phrases. we train our classifiers for different feature combinations, using libsvm with rbf kernel  #AUTHOR_TAG, and report average 5 - fold cross - validation values. table 2 : comparative results for tweet - a using rule - based algorithm and statistical classifiers using our feature combinations 6 evaluation table 2 shows', '']",5
['in  #TAUTHOR_TAG in two ways : ( a ) they extract only positive verbs'],['in  #TAUTHOR_TAG in two ways : ( a ) they extract only positive verbs'],['in  #TAUTHOR_TAG in two ways : ( a ) they extract only positive verbs'],"['use phrases with implicit sentiment as the implicit incongruity features.', ""these phrases are sentiment - bearing verb and noun phrases, the latter being situations with implied sentiment ( e. g.'getting late for work')."", 'for this, we modify the algorithm given in  #TAUTHOR_TAG in two ways : ( a ) they extract only positive verbs and negative noun situation phrases.', '']",6
"['##6 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run']","['##8 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4']","['/ dev. twitter. com / ). a similar hashtagbased approach to create a sarcasm - annotated dataset was employed', 'in gonzalez -  #AUTHOR_TAG. as an additional quality check, a rough glance through the tweets is done, and the ones found to be wrong are removed. the hashtags mentioned above are removed from the text so that they act as labels but not as features. 2', '. tweet - b ( 2278 tweets, 506 sarcastic ) : this dataset was manually labeled', 'for  #TAUTHOR_TAG to extract the implicit incongruity features, we run the iterative algorithm described in section 4. 2, on a dataset of', '4000 tweets ( 50 % sarcastic ) ( also created using hashtag - based supervision ). the algorithm results', 'in a total of 79 verb phrases and 202 noun phrases. we train our classifiers for different feature combinations, using libsvm with rbf kernel  #AUTHOR_TAG, and report average 5 - fold cross - validation values. table 2 : comparative results for tweet - a using rule - based algorithm and statistical classifiers using our feature combinations 6 evaluation table 2 shows', '']",6
"['when punctuation is included in both training and testing data  #TAUTHOR_TAG, and 20. 44']","['when punctuation is included in both training and testing data  #TAUTHOR_TAG, and 20. 44 % percent relative error reduction in f - score over']","['in edited detection when punctuation is included in both training and testing data  #TAUTHOR_TAG, and 20. 44 % percent relative error reduction in f - score over the latest best result where punctuation is excluded from the training and testing data [ johnson and charniak 2004 ]']","['paper describes our effort on the task of edited region identification for parsing disfluent sentences in the switchboard corpus.', 'we focus our attention on exploring feature spaces and selecting good features and start with analyzing the distributions of the edited regions and their components in the targeted corpus.', 'we explore new feature spaces of a partof - speech ( pos ) hierarchy and relaxed for rough copy in the experiments.', 'these steps result in an improvement of 43. 98 % percent relative error reduction in f - score over an earlier best result in edited detection when punctuation is included in both training and testing data  #TAUTHOR_TAG, and 20. 44 % percent relative error reduction in f - score over the latest best result where punctuation is excluded from the training and testing data [ johnson and charniak 2004 ]']",4
"['##fluent sentences  #TAUTHOR_TAG, johnson and charnia']","['disfluent sentences  #TAUTHOR_TAG, johnson and charniak']","['parsing disfluent sentences  #TAUTHOR_TAG, johnson and charnia']","['##s, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena.', 'processing speech repairs properly poses a challenge to spoken dialog systems.', 'early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [ young and matessa 1991, bear et al. 1992, heeman & allen 1994.', 'because of the availability of the switchboard corpus [ godfrey et al. 1992 ] and other conversational telephone speech ( cts ) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences  #TAUTHOR_TAG, johnson and charniak 2004, liu et al. 2005.', 'in this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the switchboard corpus.', 'a clear benefit of having accurate edited regions for parsing has been demonstrated by a concurrent effort on parsing conversational speech [ kahn et al 2005 ].', 'since different machine learning methods provide similar performances on many nlp tasks, in this paper, we focus our attention on exploring feature spaces and selecting good features for identifying edited regions.', 'we start by analyzing the distributions of the edited regions and their components in the targeted corpus.', 'we then design several feature spaces to cover the disfluent regions in the training data.', 'in addition, we also explore new feature spaces of a part - of - speech hierarchy and extend candidate pools in the experiments.', 'these steps result in a significant improvement in f - score over the earlier best result reported in  #TAUTHOR_TAG, where punctuation is included in both the training and testing data of the switchboard corpus, and a significant error reduction in f - score over the latest best result [ johnson and charniak 2004 ], where punctuation is ignored in both the training and testing data of the switchboard corpus.', 'in this paper, we follow the definition of [ shriberg 1994 ] and others for speech repairs : a speech repair is divided into three parts : the reparandum, the part that is repaired ; the interregnum, the part that can be either empty or fillers ; and the repair / repeat, the part that replaces or repeats the reparandum.', 'the definition can also be exemplified via the following utterance : repeat reparanda int erregnum,, this is a big problem']",4
"['all edits have both reparandum and repair, while the rough copy defined in  #TAUTHOR_TAG only covers 77. 66']","['all edits have both reparandum and repair, while the rough copy defined in  #TAUTHOR_TAG only covers 77. 66 % of such instances.', 'two methods are used to relax the rough copy definition.', 'the first one is']","['all edits have both reparandum and repair, while the rough copy defined in  #TAUTHOR_TAG only covers 77. 66']","['relax the definition for rough copy, because more than 94 % of all edits have both reparandum and repair, while the rough copy defined in  #TAUTHOR_TAG only covers 77. 66 % of such instances.', 'two methods are used to relax the rough copy definition.', 'the first one is to adopt a hierarchical pos tag set : all the switchboard pos tags are further classified into four major categories : n ( noun related ), v ( verb related ), adj ( noun modifiers ), adv ( verb modifiers ).', 'instead of requiring the exact match of two pos tag sequences, we also consider two sequences as a variables name short description x 1 w 0', '']",4
"['##fluent sentences  #TAUTHOR_TAG, johnson and charnia']","['disfluent sentences  #TAUTHOR_TAG, johnson and charniak']","['parsing disfluent sentences  #TAUTHOR_TAG, johnson and charnia']","['##s, hesitations, and restarts are common in spoken language, and understanding spoken language requires accurate methods for identifying such disfluent phenomena.', 'processing speech repairs properly poses a challenge to spoken dialog systems.', 'early work in this field is primarily based on small and proprietary corpora, which makes the comparison of the proposed methods difficult [ young and matessa 1991, bear et al. 1992, heeman & allen 1994.', 'because of the availability of the switchboard corpus [ godfrey et al. 1992 ] and other conversational telephone speech ( cts ) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences  #TAUTHOR_TAG, johnson and charniak 2004, liu et al. 2005.', 'in this paper we describe our effort towards the task of edited region identification with the intention of parsing disfluent sentences in the switchboard corpus.', 'a clear benefit of having accurate edited regions for parsing has been demonstrated by a concurrent effort on parsing conversational speech [ kahn et al 2005 ].', 'since different machine learning methods provide similar performances on many nlp tasks, in this paper, we focus our attention on exploring feature spaces and selecting good features for identifying edited regions.', 'we start by analyzing the distributions of the edited regions and their components in the targeted corpus.', 'we then design several feature spaces to cover the disfluent regions in the training data.', 'in addition, we also explore new feature spaces of a part - of - speech hierarchy and extend candidate pools in the experiments.', 'these steps result in a significant improvement in f - score over the earlier best result reported in  #TAUTHOR_TAG, where punctuation is included in both the training and testing data of the switchboard corpus, and a significant error reduction in f - score over the latest best result [ johnson and charniak 2004 ], where punctuation is ignored in both the training and testing data of the switchboard corpus.', 'in this paper, we follow the definition of [ shriberg 1994 ] and others for speech repairs : a speech repair is divided into three parts : the reparandum, the part that is repaired ; the interregnum, the part that can be either empty or fillers ; and the repair / repeat, the part that replaces or repeats the reparandum.', 'the definition can also be exemplified via the following utterance : repeat reparanda int erregnum,, this is a big problem']",0
"[' #TAUTHOR_TAG, identifying edited regions is considered as a classification problem, where each word is classified either as edited or normal.', 'the approach takes two steps.', 'the first step is to find rough copy']","[' #TAUTHOR_TAG, identifying edited regions is considered as a classification problem, where each word is classified either as edited or normal.', 'the approach takes two steps.', 'the first step is to find rough copy.', 'then, a number of variables']","[' #TAUTHOR_TAG, identifying edited regions is considered as a classification problem, where each word is classified either as edited or normal.', 'the approach takes two steps.', 'the first step is to find rough copy.', 'then, a number of variables']","[' #TAUTHOR_TAG, identifying edited regions is considered as a classification problem, where each word is classified either as edited or normal.', 'the approach takes two steps.', 'the first step is to find rough copy.', 'then, a number of variables are extracted for the boosting algorithm.', 'in particular, a total of 18 different conditioning variables are used to predict whether the current word is an edited word or a non - edited word.', 'the 18 different variables listed in table 1 the set of free final words includes all partial words and a small set of conjunctions, adverbs and miscellanea.', 'the set of interregnum strings consists of a small set of expressions such as uh, you know, i guess, i mean, etc']",0
"['in  #TAUTHOR_TAG, where punctuation is included to']","['in  #TAUTHOR_TAG, where punctuation is included to']","['in  #TAUTHOR_TAG, where punctuation is included to']","['start by analyzing the speech repairs in the switchboard corpus.', 'switchboard has over one million words, with telephone conversations on prescribed topics [ godfrey et al. 1992 ].', 'it is full of disfluent utterances, and [ shriberg 1994, shriberg 1996 gives a thorough analysis and categorization of them.', '[ engel et al. 2002 ] also showed detailed distributions of the interregnum, including interjections and parentheticals.', 'since the majority of the disfluencies involve all the three parts ( reparandum, interregnum, and repair / repeat ), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions.', 'for the reparandum and repair types, we include their distributions with and without punctuation.', 'we include the distributions with punctuation is to match with the baseline system reported in  #TAUTHOR_TAG, where punctuation is included to identify the edited regions.', 'resent research showed that certain punctuation / prosody marks can be produced when speech signals are available [ liu et al. 2003 ].', 'the interregnum type, by definition, does not include punctuation.', 'the length distributions of the reparanda in the training part of the switchboard data with and without punctuation are given in fig. 1.', '']",3
"['number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['conducted a number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['conducted a number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result of their baseline system described in section 3.', 'we used the exactly same training and testing data from the switchboard corpus as in  #TAUTHOR_TAG.', 'the training subset consists of all files in the sections 2 and 3 of the switchboard corpus.', 'section 4 is split into three approximately equal size subsets.', 'the first of the three, i. e., files sw4004. mrg to sw4153. mrg, is the testing corpus.', '']",3
"['number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['conducted a number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['conducted a number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result of their baseline system described in section 3.', 'we used the exactly same training and testing data from the switchboard corpus as in  #TAUTHOR_TAG.', 'the training subset consists of all files in the sections 2 and 3 of the switchboard corpus.', 'section 4 is split into three approximately equal size subsets.', 'the first of the three, i. e., files sw4004. mrg to sw4153. mrg, is the testing corpus.', '']",3
"['in  #TAUTHOR_TAG, where punctuation is included to']","['in  #TAUTHOR_TAG, where punctuation is included to']","['in  #TAUTHOR_TAG, where punctuation is included to']","['start by analyzing the speech repairs in the switchboard corpus.', 'switchboard has over one million words, with telephone conversations on prescribed topics [ godfrey et al. 1992 ].', 'it is full of disfluent utterances, and [ shriberg 1994, shriberg 1996 gives a thorough analysis and categorization of them.', '[ engel et al. 2002 ] also showed detailed distributions of the interregnum, including interjections and parentheticals.', 'since the majority of the disfluencies involve all the three parts ( reparandum, interregnum, and repair / repeat ), the distributions of all three parts will be very helpful in constructing patterns that are used to identify edited regions.', 'for the reparandum and repair types, we include their distributions with and without punctuation.', 'we include the distributions with punctuation is to match with the baseline system reported in  #TAUTHOR_TAG, where punctuation is included to identify the edited regions.', 'resent research showed that certain punctuation / prosody marks can be produced when speech signals are available [ liu et al. 2003 ].', 'the interregnum type, by definition, does not include punctuation.', 'the length distributions of the reparanda in the training part of the switchboard data with and without punctuation are given in fig. 1.', '']",1
"['number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['conducted a number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['conducted a number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result of their baseline system described in section 3.', 'we used the exactly same training and testing data from the switchboard corpus as in  #TAUTHOR_TAG.', 'the training subset consists of all files in the sections 2 and 3 of the switchboard corpus.', 'section 4 is split into three approximately equal size subsets.', 'the first of the three, i. e., files sw4004. mrg to sw4153. mrg, is the testing corpus.', '']",1
"['by  #TAUTHOR_TAG.', 'in their']","['by  #TAUTHOR_TAG.', 'in their approach, rough copy is defined to produce candidates']","['by  #TAUTHOR_TAG.', 'in their']","['take as our baseline system the work by  #TAUTHOR_TAG.', 'in their approach, rough copy is defined to produce candidates for any potential pairs of reparanda and repairs.', 'a boosting algorithm [ schapire and singer 1999 ] is used to detect whether a word is edited.', 'a total of 18 variables are used in the algorithm.', 'in the rest of the section, we first briefly introduce the boosting algorithm, then describe the method used in  #TAUTHOR_TAG, and finally we contrast our improvements with the baseline system']",5
"['reported by  #TAUTHOR_TAG', 'where α i is']","['reported by  #TAUTHOR_TAG', 'where α i is']","['higher.', 'the weighting factors of the learners are adjusted accordingly.', 'we re - implement the boosting algorithm reported by  #TAUTHOR_TAG', 'where α i is the weight to be estimated for feature φ i.', 'φ i is a set of variable - value pairs, and each f i has the form of :', ""with x's being conditioning variables and x's being values."", 'each component in the production for f i is defined as']","[', the boosting algorithm is to combine a set of simple learners iteratively based on their classification results on a set of training data.', 'different parts of the training data are scaled at each iteration so that the parts of the data previous classifiers performed poorly on are weighted higher.', 'the weighting factors of the learners are adjusted accordingly.', 'we re - implement the boosting algorithm reported by  #TAUTHOR_TAG', 'where α i is the weight to be estimated for feature φ i.', 'φ i is a set of variable - value pairs, and each f i has the form of :', ""with x's being conditioning variables and x's being values."", 'each component in the production for f i is defined as']",5
"['number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['conducted a number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result']","['conducted a number of experiments to test the effectiveness of our feature space exploration.', 'since the original code from  #TAUTHOR_TAG is not available, we conducted our first experiment to replicate the result of their baseline system described in section 3.', 'we used the exactly same training and testing data from the switchboard corpus as in  #TAUTHOR_TAG.', 'the training subset consists of all files in the sections 2 and 3 of the switchboard corpus.', 'section 4 is split into three approximately equal size subsets.', 'the first of the three, i. e., files sw4004. mrg to sw4153. mrg, is the testing corpus.', '']",5
"['by  #TAUTHOR_TAG.', 'in their']","['by  #TAUTHOR_TAG.', 'in their approach, rough copy is defined to produce candidates']","['by  #TAUTHOR_TAG.', 'in their']","['take as our baseline system the work by  #TAUTHOR_TAG.', 'in their approach, rough copy is defined to produce candidates for any potential pairs of reparanda and repairs.', 'a boosting algorithm [ schapire and singer 1999 ] is used to detect whether a word is edited.', 'a total of 18 variables are used in the algorithm.', 'in the rest of the section, we first briefly introduce the boosting algorithm, then describe the method used in  #TAUTHOR_TAG, and finally we contrast our improvements with the baseline system']",7
"['baseline with punctuation in both training and testing  #TAUTHOR_TAG.', 'compared with']","['baseline with punctuation in both training and testing  #TAUTHOR_TAG.', 'compared with']","['the baseline with punctuation in both training and testing  #TAUTHOR_TAG.', 'compared with']","['paper reports our work on identifying edited regions in the switchboard corpus.', 'in addition to a distributional analysis for the edited regions, a number of feature spaces have been explored and tested to show their effectiveness.', 'we observed a 43. 98 % relative error reduction on f - scores for the baseline with punctuation in both training and testing  #TAUTHOR_TAG.', 'compared with the reported best result, the same approach produced a 20. 44 % of relative error reduction on f - scores when punctuation is ignored in training and testing data [ johnson and charniak 2004 ].', 'the inclusion of both hierarchical pos tags and the relaxation for rough copy definition gives large additive improvements, and their combination has contributed to nearly half of the gain for the test set with punctuation and about 60 % of the gain for the data without punctuation.', 'future research would include the use of other features, such as prosody, and the integration of the edited region identification with parsing']",7
"['not scale to writings from other historic periodsor even just writings from another monastery or by another author.', 'bollmann and søgaard ( 2016 ) and  #TAUTHOR_TAG recently showed that we']","['not scale to writings from other historic periodsor even just writings from another monastery or by another author.', 'bollmann and søgaard ( 2016 ) and  #TAUTHOR_TAG recently showed that we']","['not scale to writings from other historic periodsor even just writings from another monastery or by another author.', 'bollmann and søgaard ( 2016 ) and  #TAUTHOR_TAG recently showed that we can obtain more robust historical text normalization models by exploiting synergies across historical text normalization datasets and with related tasks.', 'specifically,  #TAUTHOR_TAG showed that multitask learning with german grapheme - to - phoneme translation as an auxiliary task improves a stateof - the - art sequence - to - sequence model']","[""text normalization is the problem of translating historical documents written in the absence of modern spelling conventions and making them amenable to search by today's scholars, processable by natural language processing models, and readable to laypeople."", 'in other words, historical text normalization is a text - to - text generation, where the input is a text written centuries ago, and the output is a text that has the same contents, but uses the orthography of modern - day language.', 'in this paper, we limit ourselves to word - by - word normalization, ignoring the syntactic differences between modern - day languages and their historic predecessors.', 'resources for historical text normalization are scarce.', 'even for major languages like english and german, we have very little training data for inducing normalization models, and the models we induce may be very specific to these datasets and not scale to writings from other historic periodsor even just writings from another monastery or by another author.', 'bollmann and søgaard ( 2016 ) and  #TAUTHOR_TAG recently showed that we can obtain more robust historical text normalization models by exploiting synergies across historical text normalization datasets and with related tasks.', 'specifically,  #TAUTHOR_TAG showed that multitask learning with german grapheme - to - phoneme translation as an auxiliary task improves a stateof - the - art sequence - to - sequence model for historical text normalization of medieval german manuscripts']",0
"['not scale to writings from other historic periodsor even just writings from another monastery or by another author.', 'bollmann and søgaard ( 2016 ) and  #TAUTHOR_TAG recently showed that we']","['not scale to writings from other historic periodsor even just writings from another monastery or by another author.', 'bollmann and søgaard ( 2016 ) and  #TAUTHOR_TAG recently showed that we']","['not scale to writings from other historic periodsor even just writings from another monastery or by another author.', 'bollmann and søgaard ( 2016 ) and  #TAUTHOR_TAG recently showed that we can obtain more robust historical text normalization models by exploiting synergies across historical text normalization datasets and with related tasks.', 'specifically,  #TAUTHOR_TAG showed that multitask learning with german grapheme - to - phoneme translation as an auxiliary task improves a stateof - the - art sequence - to - sequence model']","[""text normalization is the problem of translating historical documents written in the absence of modern spelling conventions and making them amenable to search by today's scholars, processable by natural language processing models, and readable to laypeople."", 'in other words, historical text normalization is a text - to - text generation, where the input is a text written centuries ago, and the output is a text that has the same contents, but uses the orthography of modern - day language.', 'in this paper, we limit ourselves to word - by - word normalization, ignoring the syntactic differences between modern - day languages and their historic predecessors.', 'resources for historical text normalization are scarce.', 'even for major languages like english and german, we have very little training data for inducing normalization models, and the models we induce may be very specific to these datasets and not scale to writings from other historic periodsor even just writings from another monastery or by another author.', 'bollmann and søgaard ( 2016 ) and  #TAUTHOR_TAG recently showed that we can obtain more robust historical text normalization models by exploiting synergies across historical text normalization datasets and with related tasks.', 'specifically,  #TAUTHOR_TAG showed that multitask learning with german grapheme - to - phoneme translation as an auxiliary task improves a stateof - the - art sequence - to - sequence model for historical text normalization of medieval german manuscripts']",0
"['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and sloven']","['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and slovene ( gaj ).', ' #TAUTHOR_TAG also describe a multi - task']","['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and sloven']","['use the same hyperparameters across all our experiments : the dimensionality of the embedding layer is 60, the size of the lstm layers is set to 300, and we use a dropout rate of 0. 2.', 'we use the adam optimizer  #AUTHOR_TAG with a character - wise cross - entropy loss.', 'training is done on mini - batches of 50 samples with early stopping based on validation on the individual development sets.', 'the hyperparameters were set on a randomly selected subset of 50, 000 tokens from each of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and slovene ( gaj ).', ' #TAUTHOR_TAG also describe a multi - task learning ( mtl ) scenario where the encoder - decoder model is trained on two datasets in parallel.', 'we perform similar experiments on pairwise combinations of our datasets.', 'table 2 : examples of input tokens ( first line ) and reference normalization ( second line ) for each of the historical datasets']",0
['to historical text normalization  #TAUTHOR_TAG with'],['to historical text normalization  #TAUTHOR_TAG with'],['to historical text normalization  #TAUTHOR_TAG with'],"['study when multi - task learning leads to improvements in historical text normalization.', 'specifically, we evaluate a state - ofthe - art approach to historical text normalization  #TAUTHOR_TAG with and without various auxiliary tasks, across 10 historical text normalization datasets.', 'we also include an experiment in english historical text normalization using data from twitter and a grammatical error correction corpus ( fce ) as auxiliary datasets.', 'across the board, we find that, unlike what has been observed for other nlp tasks, multi - task learning only helps when target task data is scarce']",5
"['different languages : german, using the  #TAUTHOR_TAG to']","['different languages : german, using the  #TAUTHOR_TAG to']","['consider 10 datasets from 8 different languages : german, using the  #TAUTHOR_TAG to']","['consider 10 datasets from 8 different languages : german, using the  #TAUTHOR_TAG to obtain a single dataset.', 'for ridges, we use 16 texts and randomly sample 70 % of all sentences from each text for the training set, and 15 % for the dev / test sets.', 'the spanish and portuguese datasets consist of manually normalized subsets of the post scriptum corpus ; here, we randomly sample 80 % ( train ) and 10 % ( dev / test ) of all sentences per century represented in the corpus.', 'dataset splits for the other languages are taken from  #AUTHOR_TAG and ljubesic et al. ( 2016 ).', 'we preprocessed all datasets to remove punctuation, perform unicode normalization, replace digits that do not require normalization with a dummy symbol, and lowercase all tokens.', 'table 1 gives an overview of all historical datasets, the approximate time period of historical texts that they cover, as well as the size of the dataset splits.', 'note that, to the best of our knowledge, the spanish, portuguese, and german ridges datasets have not been used in the context of automatic historical text normalization before.', 'table 2 additionally gives some examples of historical word forms and their gold - standard normalizations from each of these datasets.', '']",5
"['decoder architecture with attention as described in  #TAUTHOR_TAG.', '4 this is a fairly standard model consisting of one bidirectional lstm']","['encoder - decoder architecture with attention as described in  #TAUTHOR_TAG.', '4 this is a fairly standard model consisting of one bidirectional lstm']","['we use the same encoder - decoder architecture with attention as described in  #TAUTHOR_TAG.', '4 this is a fairly standard model consisting of one bidirectional lstm unit in the encoder and one ( unidirectional ) lstm unit in the decoder.', 'the input for the encoder is a single historical word form represented as a sequence of characters and padded with word boundary symbols ; i. e., we only input single tokens in isolation, not full sentences.', ""the decoder attends over the encoder's outputs""]","['we use the same encoder - decoder architecture with attention as described in  #TAUTHOR_TAG.', '4 this is a fairly standard model consisting of one bidirectional lstm unit in the encoder and one ( unidirectional ) lstm unit in the decoder.', 'the input for the encoder is a single historical word form represented as a sequence of characters and padded with word boundary symbols ; i. e., we only input single tokens in isolation, not full sentences.', ""the decoder attends over the encoder's outputs and generates the normalized output characters""]",5
"['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and sloven']","['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and slovene ( gaj ).', ' #TAUTHOR_TAG also describe a multi - task']","['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and sloven']","['use the same hyperparameters across all our experiments : the dimensionality of the embedding layer is 60, the size of the lstm layers is set to 300, and we use a dropout rate of 0. 2.', 'we use the adam optimizer  #AUTHOR_TAG with a character - wise cross - entropy loss.', 'training is done on mini - batches of 50 samples with early stopping based on validation on the individual development sets.', 'the hyperparameters were set on a randomly selected subset of 50, 000 tokens from each of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and slovene ( gaj ).', ' #TAUTHOR_TAG also describe a multi - task learning ( mtl ) scenario where the encoder - decoder model is trained on two datasets in parallel.', 'we perform similar experiments on pairwise combinations of our datasets.', 'table 2 : examples of input tokens ( first line ) and reference normalization ( second line ) for each of the historical datasets']",5
['advocated in  #TAUTHOR_TAG'],"['advocated in  #TAUTHOR_TAG works.', 'our main']","['advocated in  #TAUTHOR_TAG works.', 'our main']","['has been considerable work on multitask sequence - to - sequence models for other tasks  #AUTHOR_TAG elliott and kadar, 2017 ).', 'there is a wide range of design questions and sharing strategies that we ignore here, focusing instead on under what circumstances the approach advocated in  #TAUTHOR_TAG works.', 'our main observation - that the size of the target dataset is most predictive of multi - task learning gains - runs counter previous findings for other nlp tasks ( martinez  #AUTHOR_TAG bingel and søgaard, 2017 ).', 'martinez  #AUTHOR_TAG find that the label entropy of the auxiliary dataset is more predictive ; bingel and sø - gaard ( 2017 ) find that the relative differences in the steepness of the two single - task loss curves is more predictive.', 'both papers consider sequence tagging problems with a small number of labels ; and it is probably not a surprise that their findings do not seem to scale to the case of historical text normalization']",5
['to historical text normalization  #TAUTHOR_TAG with'],['to historical text normalization  #TAUTHOR_TAG with'],['to historical text normalization  #TAUTHOR_TAG with'],"['study when multi - task learning leads to improvements in historical text normalization.', 'specifically, we evaluate a state - ofthe - art approach to historical text normalization  #TAUTHOR_TAG with and without various auxiliary tasks, across 10 historical text normalization datasets.', 'we also include an experiment in english historical text normalization using data from twitter and a grammatical error correction corpus ( fce ) as auxiliary datasets.', 'across the board, we find that, unlike what has been observed for other nlp tasks, multi - task learning only helps when target task data is scarce']",1
"['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and sloven']","['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and slovene ( gaj ).', ' #TAUTHOR_TAG also describe a multi - task']","['of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and sloven']","['use the same hyperparameters across all our experiments : the dimensionality of the embedding layer is 60, the size of the lstm layers is set to 300, and we use a dropout rate of 0. 2.', 'we use the adam optimizer  #AUTHOR_TAG with a character - wise cross - entropy loss.', 'training is done on mini - batches of 50 samples with early stopping based on validation on the individual development sets.', 'the hyperparameters were set on a randomly selected subset of 50, 000 tokens from each of the following datasets : english, german  #TAUTHOR_TAG, hungarian, icelandic, and slovene ( gaj ).', ' #TAUTHOR_TAG also describe a multi - task learning ( mtl ) scenario where the encoder - decoder model is trained on two datasets in parallel.', 'we perform similar experiments on pairwise combinations of our datasets.', 'table 2 : examples of input tokens ( first line ) and reference normalization ( second line ) for each of the historical datasets']",3
"['the projection.', ' #TAUTHOR_TAG use canonical']","['the projection.', ' #TAUTHOR_TAG use canonical']","['the projection.', ' #TAUTHOR_TAG use']","['word embeddings have attracted a lot of attention in recent times  #AUTHOR_TAG kocisky et al., 2014 ; chandar a p et al., 2014 ;  #AUTHOR_TAG gouws and søgaard, 2015 ;  #AUTHOR_TAG.', 'a common approach to obtain them is to train the embeddings in both languages independently and then learn a mapping that minimizes the distances between equivalences listed in a bilingual dictionary.', 'the learned transformation can also be applied to words missing in the dictionary, which can be used to induce new translations with a direct application in machine translation  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the first method to learn bilingual word embedding mappings was proposed by  #AUTHOR_TAG b ), who learn the linear transformation that minimizes the sum of squared euclidean distances for the dictionary entries.', 'subsequent work has proposed alternative optimization objectives to learn better mappings.', ' #AUTHOR_TAG incorporate length normalization in the training of word embeddings and try to maximize the cosine similarity instead, introducing an orthogonality constraint to preserve the length normalization after the projection.', ' #TAUTHOR_TAG use canonical correlation analysis to project the embeddings in both languages to a shared vector space.', 'beyond linear mappings,  #AUTHOR_TAG apply deep canonical correlation analysis to learn a nonlinear transformation for each language.', 'finally, additional techniques have been used to address the hubness problem in  #AUTHOR_TAG b ), both through the neighbor retrieval method and the training itself.', 'we leave the study of non - linear transformation and other additions for further work.', 'in this paper, we propose a general framework to learn bilingual word embeddings.', 'we start with a basic optimization objective  #AUTHOR_TAG b ) and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods  #TAUTHOR_TAG.', 'our framework provides a more general view of bilingual word embedding mappings, showing the underlying connection between the existing methods, revealing some flaws in their theoretical justification and providing an alternative theoretical interpretation for them.', 'our experiments on an existing english - italian word translation induction and an english word analogy task give strong empirical evidence in favor of our theoretical reasoning, while showing that one of our models clearly outperforms previous alternatives']",0
"['the projection.', ' #TAUTHOR_TAG use canonical']","['the projection.', ' #TAUTHOR_TAG use canonical']","['the projection.', ' #TAUTHOR_TAG use']","['word embeddings have attracted a lot of attention in recent times  #AUTHOR_TAG kocisky et al., 2014 ; chandar a p et al., 2014 ;  #AUTHOR_TAG gouws and søgaard, 2015 ;  #AUTHOR_TAG.', 'a common approach to obtain them is to train the embeddings in both languages independently and then learn a mapping that minimizes the distances between equivalences listed in a bilingual dictionary.', 'the learned transformation can also be applied to words missing in the dictionary, which can be used to induce new translations with a direct application in machine translation  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the first method to learn bilingual word embedding mappings was proposed by  #AUTHOR_TAG b ), who learn the linear transformation that minimizes the sum of squared euclidean distances for the dictionary entries.', 'subsequent work has proposed alternative optimization objectives to learn better mappings.', ' #AUTHOR_TAG incorporate length normalization in the training of word embeddings and try to maximize the cosine similarity instead, introducing an orthogonality constraint to preserve the length normalization after the projection.', ' #TAUTHOR_TAG use canonical correlation analysis to project the embeddings in both languages to a shared vector space.', 'beyond linear mappings,  #AUTHOR_TAG apply deep canonical correlation analysis to learn a nonlinear transformation for each language.', 'finally, additional techniques have been used to address the hubness problem in  #AUTHOR_TAG b ), both through the neighbor retrieval method and the training itself.', 'we leave the study of non - linear transformation and other additions for further work.', 'in this paper, we propose a general framework to learn bilingual word embeddings.', 'we start with a basic optimization objective  #AUTHOR_TAG b ) and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods  #TAUTHOR_TAG.', 'our framework provides a more general view of bilingual word embedding mappings, showing the underlying connection between the existing methods, revealing some flaws in their theoretical justification and providing an alternative theoretical interpretation for them.', 'our experiments on an existing english - italian word translation induction and an english word analogy task give strong empirical evidence in favor of our theoretical reasoning, while showing that one of our models clearly outperforms previous alternatives']",5
"['the method by  #TAUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where']","['the method by  #TAUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where']","['the method by  #TAUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where the dictionary contains more than one entry for', 'the same word']","[', while the 1. 6 billion word corpus itwac was used to train the italian 1', 'while cca is typically defined in terms of correlation ( thus its name ), correlation is invariant to the scaling of variables, so it is possible to constrain the canonical variables to have a fixed', 'variance, as we do, in which case correlation', 'and covariance become equivalent 2 http : / / clic. cimec. unitn. it', '/ [UNK]. dinu / down / 3 the context window was set to 5 words, the dimension of the embeddings to 300, the', 'sub - sampling to 1e - 05 and the number of negative samples to 10 embeddings. the dataset also contains a bilingual dictionary learned from europarl, split into a training set of 5, 000 word pairs and a test set of 1, 500 word pairs, both of them uniformly distributed in frequency bins. accuracy is the evaluation measure. apart from the performance of the projected embeddings in bilingual terms, we are also interested in the monolingual quality of the source language embeddings after the projection. for that purpose, we use the word analogy task proposed by  #AUTHOR_TAG', 'a ), which measures the accuracy on answering questions like "" what is the word that is similar to small in the same sense as biggest is similar to big? "" using simple word vector arithmetic. the dataset they', 'use consists of 8, 869 semantic and 10, 675 syntactic questions of this type, and is publicly available 4. in order to speed up the experiments, we follow the authors and perform an approximate evaluation by reducing', 'the vocabulary size according to a', 'frequency threshold of 30, 000  #AUTHOR_TAG a ). since the original embeddings are the same in all the cases and it is only the transformation that is applied', 'to them that changes, this affects all the methods in the exact same way, so the results are perfectly comparable among themselves. with these settings, we obtain a coverage of 64. 98 %. we implemented the proposed method in python using numpy, and make', 'it available as an open source project 5. the code for  #AUTHOR_TAG b ) and  #AUTHOR_TAG is not publicly available, so we implemented and tested them', 'as part of the proposed framework, which only differs from the original systems in the optimization method ( exact solution instead of gradient descent ) and the length normalization approach in the case of', ' #AUTHOR_TAG ( postprocessing instead of constrained training ). as for the method by  #TAUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where the dictionary contains more than one entry for', 'the same word']",5
"['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['it can be seen, the method by  #AUTHOR_TAG performs better than that of  #AUTHOR_TAG b ) in the translation induction task, which is in line with what they report in their paper.', 'moreover, thanks to the orthogonality constraint their monolingual performance in the word analogy task does not degrade, whereas the accuracy of  #AUTHOR_TAG b ) drops by 2. 86 % in absolute terms with respect to the original embeddings.', 'since  #TAUTHOR_TAG cca to perform dimensionality reduction, we tested several values for it and report the best ( 180 dimensions ).', 'this beats the method by  #AUTHOR_TAG in the bilingual task, although it comes at the price of a considerable degradation in monolingual quality.', 'in any case, it is our proposed method with the orthogonality constraint and a global preprocessing with length normalization followed by dimensionwise mean centering that achieves the best accuracy in the word translation induction task.', 'moreover, it does not suffer from any considerable degradation in monolingual quality, with an anecdotal drop of only 0. 07 % in contrast with 2. 86 % for  #AUTHOR_TAG b ) and 7. 02 % for  #TAUTHOR_TAG.', 'when compared to  #AUTHOR_TAG, our results in table 1 reinforce our theoretical interpretation for their method ( cf. section 2. 2 ), as it empirically shows that its improvement with respect to  #AUTHOR_TAG b ) comes solely from the orthogonality constraint, and not from solving any inconsistency.', 'it should be noted that the implementation by  #TAUTHOR_TAG also length - normalizes the word embeddings in a preprocessing step.', 'following the discussion in section 2. 3, this means that our best performing configuration is conceptually very close to the method by  #TAUTHOR_TAG, as they both coincide on maximizing the average dimension - wise covariance and length - normalize the embeddings in both languages first, the only difference being that our model enforces monolingual invariance after the normalization while theirs does change the monolingual embeddings to make different dimensions have the same variance and be uncorrelated among themselves.', 'however, our model performs considerably better than any configuration from  #TAUTHOR_TAG in both the monolingual and the bilingual task, supporting our hypothesis that these two constraints that are implicit in their method are not only conceptually confusing, 2292 but also have a negative impact']",5
"['the projection.', ' #TAUTHOR_TAG use canonical']","['the projection.', ' #TAUTHOR_TAG use canonical']","['the projection.', ' #TAUTHOR_TAG use']","['word embeddings have attracted a lot of attention in recent times  #AUTHOR_TAG kocisky et al., 2014 ; chandar a p et al., 2014 ;  #AUTHOR_TAG gouws and søgaard, 2015 ;  #AUTHOR_TAG.', 'a common approach to obtain them is to train the embeddings in both languages independently and then learn a mapping that minimizes the distances between equivalences listed in a bilingual dictionary.', 'the learned transformation can also be applied to words missing in the dictionary, which can be used to induce new translations with a direct application in machine translation  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'the first method to learn bilingual word embedding mappings was proposed by  #AUTHOR_TAG b ), who learn the linear transformation that minimizes the sum of squared euclidean distances for the dictionary entries.', 'subsequent work has proposed alternative optimization objectives to learn better mappings.', ' #AUTHOR_TAG incorporate length normalization in the training of word embeddings and try to maximize the cosine similarity instead, introducing an orthogonality constraint to preserve the length normalization after the projection.', ' #TAUTHOR_TAG use canonical correlation analysis to project the embeddings in both languages to a shared vector space.', 'beyond linear mappings,  #AUTHOR_TAG apply deep canonical correlation analysis to learn a nonlinear transformation for each language.', 'finally, additional techniques have been used to address the hubness problem in  #AUTHOR_TAG b ), both through the neighbor retrieval method and the training itself.', 'we leave the study of non - linear transformation and other additions for further work.', 'in this paper, we propose a general framework to learn bilingual word embeddings.', 'we start with a basic optimization objective  #AUTHOR_TAG b ) and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods  #TAUTHOR_TAG.', 'our framework provides a more general view of bilingual word embedding mappings, showing the underlying connection between the existing methods, revealing some flaws in their theoretical justification and providing an alternative theoretical interpretation for them.', 'our experiments on an existing english - italian word translation induction and an english word analogy task give strong empirical evidence in favor of our theoretical reasoning, while showing that one of our models clearly outperforms previous alternatives']",6
"['the method by  #TAUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where']","['the method by  #TAUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where']","['the method by  #TAUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where the dictionary contains more than one entry for', 'the same word']","[', while the 1. 6 billion word corpus itwac was used to train the italian 1', 'while cca is typically defined in terms of correlation ( thus its name ), correlation is invariant to the scaling of variables, so it is possible to constrain the canonical variables to have a fixed', 'variance, as we do, in which case correlation', 'and covariance become equivalent 2 http : / / clic. cimec. unitn. it', '/ [UNK]. dinu / down / 3 the context window was set to 5 words, the dimension of the embeddings to 300, the', 'sub - sampling to 1e - 05 and the number of negative samples to 10 embeddings. the dataset also contains a bilingual dictionary learned from europarl, split into a training set of 5, 000 word pairs and a test set of 1, 500 word pairs, both of them uniformly distributed in frequency bins. accuracy is the evaluation measure. apart from the performance of the projected embeddings in bilingual terms, we are also interested in the monolingual quality of the source language embeddings after the projection. for that purpose, we use the word analogy task proposed by  #AUTHOR_TAG', 'a ), which measures the accuracy on answering questions like "" what is the word that is similar to small in the same sense as biggest is similar to big? "" using simple word vector arithmetic. the dataset they', 'use consists of 8, 869 semantic and 10, 675 syntactic questions of this type, and is publicly available 4. in order to speed up the experiments, we follow the authors and perform an approximate evaluation by reducing', 'the vocabulary size according to a', 'frequency threshold of 30, 000  #AUTHOR_TAG a ). since the original embeddings are the same in all the cases and it is only the transformation that is applied', 'to them that changes, this affects all the methods in the exact same way, so the results are perfectly comparable among themselves. with these settings, we obtain a coverage of 64. 98 %. we implemented the proposed method in python using numpy, and make', 'it available as an open source project 5. the code for  #AUTHOR_TAG b ) and  #AUTHOR_TAG is not publicly available, so we implemented and tested them', 'as part of the proposed framework, which only differs from the original systems in the optimization method ( exact solution instead of gradient descent ) and the length normalization approach in the case of', ' #AUTHOR_TAG ( postprocessing instead of constrained training ). as for the method by  #TAUTHOR_TAG, we used their original implementation in python and mat - lab 6, which we extended to cover cases where the dictionary contains more than one entry for', 'the same word']",6
"['reveals that the method proposed by  #TAUTHOR_TAG is closely related to our framework.', 'more concrete']","['reveals that the method proposed by  #TAUTHOR_TAG is closely related to our framework.', 'more concretely,  #TAUTHOR_TAG use canonical']","['this equivalence reveals that the method proposed by  #TAUTHOR_TAG is closely related to our framework.', 'more concrete']","['- wise mean centering captures the intuition that two randomly taken words would not be expected to be semantically similar, ensuring that the expected product of two random embeddings in any dimension and, consequently, their cosine similarity, is zero.', 'as long as w is orthogonal, this is equivalent to maximizing the sum of dimensionwise covariance for the dictionary entries :', 'where c m denotes the centering matrix this equivalence reveals that the method proposed by  #TAUTHOR_TAG is closely related to our framework.', 'more concretely,  #TAUTHOR_TAG use canonical correlation analysis ( cca ) to project the word embeddings in both languages to a shared vector space.', 'cca maximizes the dimension - wise covariance of both projections ( which is equivalent to maximizing the covariance of a single projection if the transformations are constrained to be orthogonal, as in our case ) but adds an implicit restriction to the two mappings, making different dimensions have the same variance and be uncorrelated among themselves 1 :', 'therefore, the only fundamental difference between both methods is that, while our model enforces monolingual invariance,  #TAUTHOR_TAG do change the monolingual embeddings to meet this restriction.', 'in this regard, we think that the restriction they add could have a negative impact on the learning of the bilingual mapping, and it could also degrade the quality of the monolingual embeddings.', 'our experiments ( cf. section 3 ) show empirical evidence supporting this idea']",3
"['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['it can be seen, the method by  #AUTHOR_TAG performs better than that of  #AUTHOR_TAG b ) in the translation induction task, which is in line with what they report in their paper.', 'moreover, thanks to the orthogonality constraint their monolingual performance in the word analogy task does not degrade, whereas the accuracy of  #AUTHOR_TAG b ) drops by 2. 86 % in absolute terms with respect to the original embeddings.', 'since  #TAUTHOR_TAG cca to perform dimensionality reduction, we tested several values for it and report the best ( 180 dimensions ).', 'this beats the method by  #AUTHOR_TAG in the bilingual task, although it comes at the price of a considerable degradation in monolingual quality.', 'in any case, it is our proposed method with the orthogonality constraint and a global preprocessing with length normalization followed by dimensionwise mean centering that achieves the best accuracy in the word translation induction task.', 'moreover, it does not suffer from any considerable degradation in monolingual quality, with an anecdotal drop of only 0. 07 % in contrast with 2. 86 % for  #AUTHOR_TAG b ) and 7. 02 % for  #TAUTHOR_TAG.', 'when compared to  #AUTHOR_TAG, our results in table 1 reinforce our theoretical interpretation for their method ( cf. section 2. 2 ), as it empirically shows that its improvement with respect to  #AUTHOR_TAG b ) comes solely from the orthogonality constraint, and not from solving any inconsistency.', 'it should be noted that the implementation by  #TAUTHOR_TAG also length - normalizes the word embeddings in a preprocessing step.', 'following the discussion in section 2. 3, this means that our best performing configuration is conceptually very close to the method by  #TAUTHOR_TAG, as they both coincide on maximizing the average dimension - wise covariance and length - normalize the embeddings in both languages first, the only difference being that our model enforces monolingual invariance after the normalization while theirs does change the monolingual embeddings to make different dimensions have the same variance and be uncorrelated among themselves.', 'however, our model performs considerably better than any configuration from  #TAUTHOR_TAG in both the monolingual and the bilingual task, supporting our hypothesis that these two constraints that are implicit in their method are not only conceptually confusing, 2292 but also have a negative impact']",3
"['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['the original embeddings.', 'since  #TAUTHOR_TAG cca to perform']","['it can be seen, the method by  #AUTHOR_TAG performs better than that of  #AUTHOR_TAG b ) in the translation induction task, which is in line with what they report in their paper.', 'moreover, thanks to the orthogonality constraint their monolingual performance in the word analogy task does not degrade, whereas the accuracy of  #AUTHOR_TAG b ) drops by 2. 86 % in absolute terms with respect to the original embeddings.', 'since  #TAUTHOR_TAG cca to perform dimensionality reduction, we tested several values for it and report the best ( 180 dimensions ).', 'this beats the method by  #AUTHOR_TAG in the bilingual task, although it comes at the price of a considerable degradation in monolingual quality.', 'in any case, it is our proposed method with the orthogonality constraint and a global preprocessing with length normalization followed by dimensionwise mean centering that achieves the best accuracy in the word translation induction task.', 'moreover, it does not suffer from any considerable degradation in monolingual quality, with an anecdotal drop of only 0. 07 % in contrast with 2. 86 % for  #AUTHOR_TAG b ) and 7. 02 % for  #TAUTHOR_TAG.', 'when compared to  #AUTHOR_TAG, our results in table 1 reinforce our theoretical interpretation for their method ( cf. section 2. 2 ), as it empirically shows that its improvement with respect to  #AUTHOR_TAG b ) comes solely from the orthogonality constraint, and not from solving any inconsistency.', 'it should be noted that the implementation by  #TAUTHOR_TAG also length - normalizes the word embeddings in a preprocessing step.', 'following the discussion in section 2. 3, this means that our best performing configuration is conceptually very close to the method by  #TAUTHOR_TAG, as they both coincide on maximizing the average dimension - wise covariance and length - normalize the embeddings in both languages first, the only difference being that our model enforces monolingual invariance after the normalization while theirs does change the monolingual embeddings to make different dimensions have the same variance and be uncorrelated among themselves.', 'however, our model performs considerably better than any configuration from  #TAUTHOR_TAG in both the monolingual and the bilingual task, supporting our hypothesis that these two constraints that are implicit in their method are not only conceptually confusing, 2292 but also have a negative impact']",3
"['resource in k  #TAUTHOR_TAG.', 'a large']","['resource in k  #TAUTHOR_TAG.', 'a large']","['in k  #TAUTHOR_TAG.', 'a large number of challenges has to be addressed']","['', 'the goal of an el approach is as follows : given a piece of text, a reference knowledge base k and a set of entity mentions in that text, map each entity mention to the corresponding resource in k  #TAUTHOR_TAG.', 'a large number of challenges has to be addressed while performing a disambiguation.', 'for instance, a given resource can be referred to using different labels due to phenomena such as synonymy, acronyms or typos.', 'for example, new york city, ny and big apple are all labels for the same entity.', 'also, multiple entities can share the same name due to homonymy and ambiguity.', 'for example, both the state and the city of rio de janeiro are called rio de janeiro.', 'despite the complexity of the task, el approaches have recently achieved increasingly better results by relying on trained machine learning models [ 6 ].', '']",0
['##uation for a given mention  #TAUTHOR_TAG'],['of candidates is chosen as correct disambiguation for a given mention  #TAUTHOR_TAG'],"['', 'independently of the chosen graph algorithm, the highest candidate score among the set of candidates is chosen as correct disambiguation for a given mention  #TAUTHOR_TAG']","['', 'the goal of the candidate generation step is to retrieve a tractable number of candidates for each mention.', 'these candidates are later inserted into the disambiguation graph, which is used to determine the mapping between entities and mentions.', 'mag implements two graph - based algorithms to disambiguate entities, i. e., pagerank and hits.', 'independently of the chosen graph algorithm, the highest candidate score among the set of candidates is chosen as correct disambiguation for a given mention  #TAUTHOR_TAG']",0
"['search by context - this boolean parameter provides a search of candidates using a context index  #TAUTHOR_TAG.', '']","['disambiguating among the candidates per mentions.', 'the current implementation offers hits and pagerank as algorithms, algorithm = hits or algorithm = pagerank.', '- search by context - this boolean parameter provides a search of candidates using a context index  #TAUTHOR_TAG.', '- acronyms - this parameter']","['search by context - this boolean parameter provides a search of candidates using a context index  #TAUTHOR_TAG.', '']","['demonstration will show the capabilities of mag for different languages.', 'we provide a graphical, web - based user interface ( gui ).', 'in addition, users can choose to use the rest interface or a java snippet.', 'for research purposes, mag can be downloaded and deployed via maven or docker.', 'figure 1 illustrates an example of mag working on spanish.', 'the online demo can be accessed via http : / / agdistis. aksw.', 'org / mag - demo and its code can be downloaded from https : / / github. com / dice - group / agdistis _ demo / tree / v2.', 'we have set up a web service interface for each language version.', 'each of these interfaces understands two mandatory parameters : ( 1 ) text and ( 2 ) type.', '1. text accepts an utf - 8 and url encoded string with entities annotated with xml - tag < entity >. it is also capable of recognizing nif [ 3 ] or txt files.', '2. type accepts two different values.', ""first,'agdistis'to disambiguate the mentions using the graph - based algorithms, but also'candidates'which list all possible entities for a given mention through the depth - candidate selection of mag."", 'other parameters.', 'the user can also define more parameters to fine - tune the disambiguation.', 'these parameters have to be set up within the properties file 5 or via environment variables while deploying it locally.', 'below, we describe all the parameters.', '- popularity - the user can set it as popularity = false or popularity = true.', 'it allows mag to use either the page rank or the frequency of a candidate to sort while candidate retrieval.', '- graph - based algorithm - the user can choose which graph - based algorithm to use for disambiguating among the candidates per mentions.', 'the current implementation offers hits and pagerank as algorithms, algorithm = hits or algorithm = pagerank.', '- search by context - this boolean parameter provides a search of candidates using a context index  #TAUTHOR_TAG.', '- acronyms - this parameter enables a search by acronyms.', 'in this case, mag uses an additional index to filter the acronyms by expanding their labels and assigns them a high probability.', 'for example, psg equals paris saint - germain.', 'the parameter is acronym = false or acronym = true.', '- common entities - this boolean option supports finding common entities, in case, users desire to find more than organizations, places and persons as entity type.', 'knowledge - base agnosticism.', 'figure 2 shows']",0
"['resource in k  #TAUTHOR_TAG.', 'a large']","['resource in k  #TAUTHOR_TAG.', 'a large']","['in k  #TAUTHOR_TAG.', 'a large number of challenges has to be addressed']","['', 'the goal of an el approach is as follows : given a piece of text, a reference knowledge base k and a set of entity mentions in that text, map each entity mention to the corresponding resource in k  #TAUTHOR_TAG.', 'a large number of challenges has to be addressed while performing a disambiguation.', 'for instance, a given resource can be referred to using different labels due to phenomena such as synonymy, acronyms or typos.', 'for example, new york city, ny and big apple are all labels for the same entity.', 'also, multiple entities can share the same name due to homonymy and ambiguity.', 'for example, both the state and the city of rio de janeiro are called rio de janeiro.', 'despite the complexity of the task, el approaches have recently achieved increasingly better results by relying on trained machine learning models [ 6 ].', '']",1
"['underlying text corpus  #TAUTHOR_TAG ; caliskan, bry']","['underlying text corpus  #TAUTHOR_TAG ; caliskan, bryson, and']","['presumably, the underlying text corpus  #TAUTHOR_TAG ; caliskan, bryson, and nar']","['embeddings are widely used for their ability to capture the semantic meanings of terms within a corpus.', 'they are widely praised as useful tools for generating features for use in natural language processing systems, and recently, some researchers are attempting to study the structures of these embedding spaces to learn about the fundamental linguistic properties, or even the semantic content of a corpus.', 'while many of the properties of embedding spaces are useful and socially benign, a subset of these properties can reveal latent relationships between terms which could be socially problematic, and may be of interest to researchers for study, or possibly lead to risks of propagating the implicit biases of a corpus if these socially problematic term relationships are used in downstream machine learning applications which would ideally be free of such implicit biases.', 'qualitatively, when inspecting term - analogical relationships as is done in ( garg et al. 2018 ), it is difficult to deny the existence of these biases, but the task of quantitatively capturing them in a canonical measure has been a topic of recent study.', 'initial attempts have been made to develop metrics which seek to describe the geometric properties of the embedding space with respect to various axes of interest which are empirically determined to correspond to our intuitions of the hypothetical biases under study to quantify the degrees to which various biases exist within the embedding space, and presumably, the underlying text corpus  #TAUTHOR_TAG ; caliskan, bryson, and narayanan 2017 ; garg et al. 2018 ).', 'for instance, using such a bias measure,  #TAUTHOR_TAG concluded that "" word embeddings trained on google news articles exhibit female / male gender stereotypes to a disturbing extent "".', 'to the end of quantifying these biases, ( caliskan, bryson, and narayanan 2017 ) proposed and used a bias measure to report that "" text corpora contain recoverable and accurate imprints of our historic biases "".', 'the genesis of these biases via the underlying text corpus is explored in depth in ( brunet et al. 2018 ).', 'although this family of bias metrics is fairly new, initial attempts have been made to refine and explore their validity and robustness as explored in the metric significance research in ( caliskan, bryson, and narayanan 2017 ), which seeks to determine whether a bias score is significant, given the possibility of having selected various sets of metric - inducing terms']",0
"['underlying text corpus  #TAUTHOR_TAG ; caliskan, bry']","['underlying text corpus  #TAUTHOR_TAG ; caliskan, bryson, and']","['presumably, the underlying text corpus  #TAUTHOR_TAG ; caliskan, bryson, and nar']","['embeddings are widely used for their ability to capture the semantic meanings of terms within a corpus.', 'they are widely praised as useful tools for generating features for use in natural language processing systems, and recently, some researchers are attempting to study the structures of these embedding spaces to learn about the fundamental linguistic properties, or even the semantic content of a corpus.', 'while many of the properties of embedding spaces are useful and socially benign, a subset of these properties can reveal latent relationships between terms which could be socially problematic, and may be of interest to researchers for study, or possibly lead to risks of propagating the implicit biases of a corpus if these socially problematic term relationships are used in downstream machine learning applications which would ideally be free of such implicit biases.', 'qualitatively, when inspecting term - analogical relationships as is done in ( garg et al. 2018 ), it is difficult to deny the existence of these biases, but the task of quantitatively capturing them in a canonical measure has been a topic of recent study.', 'initial attempts have been made to develop metrics which seek to describe the geometric properties of the embedding space with respect to various axes of interest which are empirically determined to correspond to our intuitions of the hypothetical biases under study to quantify the degrees to which various biases exist within the embedding space, and presumably, the underlying text corpus  #TAUTHOR_TAG ; caliskan, bryson, and narayanan 2017 ; garg et al. 2018 ).', 'for instance, using such a bias measure,  #TAUTHOR_TAG concluded that "" word embeddings trained on google news articles exhibit female / male gender stereotypes to a disturbing extent "".', 'to the end of quantifying these biases, ( caliskan, bryson, and narayanan 2017 ) proposed and used a bias measure to report that "" text corpora contain recoverable and accurate imprints of our historic biases "".', 'the genesis of these biases via the underlying text corpus is explored in depth in ( brunet et al. 2018 ).', 'although this family of bias metrics is fairly new, initial attempts have been made to refine and explore their validity and robustness as explored in the metric significance research in ( caliskan, bryson, and narayanan 2017 ), which seeks to determine whether a bias score is significant, given the possibility of having selected various sets of metric - inducing terms']",0
"['as in  #TAUTHOR_TAG, have']","['as in  #TAUTHOR_TAG, have']","['as in  #TAUTHOR_TAG, have these term sets evaluated by a crowd, it is much more difficult to argue the canonic']","['', 'some degree of sensitivity of the proposed metric to the sample of terms used to induce', 'the axis onto which term vectors are projected to determine their bias. while it is not difficult to hypothesize various words which are supposed to be either ideally neutral terms w, or ideally bias - axis - aligned g', '1, g 2, or as in  #TAUTHOR_TAG, have these term sets evaluated by a crowd, it is much more difficult to argue the canonicity of a given term set w, g 1 or g 2. if it is not possible to defend the term set selections used to define the metric', 'as being canonical, it is better for them to be mathematically regarded as a sample of the canonical term set. in this light, it becomes critical to understand the sensitivity of the proposed metric to the particular term set sampled, and ideally, characterize the distribution of the', 'metric under many such samples as partially explored in ( antoniak and mimno 2018 ). in examining several online corpora, we observe that although the', '']",0
"['as in  #TAUTHOR_TAG, have']","['as in  #TAUTHOR_TAG, have']","['as in  #TAUTHOR_TAG, have these term sets evaluated by a crowd, it is much more difficult to argue the canonic']","['', 'some degree of sensitivity of the proposed metric to the sample of terms used to induce', 'the axis onto which term vectors are projected to determine their bias. while it is not difficult to hypothesize various words which are supposed to be either ideally neutral terms w, or ideally bias - axis - aligned g', '1, g 2, or as in  #TAUTHOR_TAG, have these term sets evaluated by a crowd, it is much more difficult to argue the canonicity of a given term set w, g 1 or g 2. if it is not possible to defend the term set selections used to define the metric', 'as being canonical, it is better for them to be mathematically regarded as a sample of the canonical term set. in this light, it becomes critical to understand the sensitivity of the proposed metric to the particular term set sampled, and ideally, characterize the distribution of the', 'metric under many such samples as partially explored in ( antoniak and mimno 2018 ). in examining several online corpora, we observe that although the', '']",0
"['as in  #TAUTHOR_TAG, have']","['as in  #TAUTHOR_TAG, have']","['as in  #TAUTHOR_TAG, have these term sets evaluated by a crowd, it is much more difficult to argue the canonic']","['', 'some degree of sensitivity of the proposed metric to the sample of terms used to induce', 'the axis onto which term vectors are projected to determine their bias. while it is not difficult to hypothesize various words which are supposed to be either ideally neutral terms w, or ideally bias - axis - aligned g', '1, g 2, or as in  #TAUTHOR_TAG, have these term sets evaluated by a crowd, it is much more difficult to argue the canonicity of a given term set w, g 1 or g 2. if it is not possible to defend the term set selections used to define the metric', 'as being canonical, it is better for them to be mathematically regarded as a sample of the canonical term set. in this light, it becomes critical to understand the sensitivity of the proposed metric to the particular term set sampled, and ideally, characterize the distribution of the', 'metric under many such samples as partially explored in ( antoniak and mimno 2018 ). in examining several online corpora, we observe that although the', '']",1
"['as in  #TAUTHOR_TAG, have']","['as in  #TAUTHOR_TAG, have']","['as in  #TAUTHOR_TAG, have these term sets evaluated by a crowd, it is much more difficult to argue the canonic']","['', 'some degree of sensitivity of the proposed metric to the sample of terms used to induce', 'the axis onto which term vectors are projected to determine their bias. while it is not difficult to hypothesize various words which are supposed to be either ideally neutral terms w, or ideally bias - axis - aligned g', '1, g 2, or as in  #TAUTHOR_TAG, have these term sets evaluated by a crowd, it is much more difficult to argue the canonicity of a given term set w, g 1 or g 2. if it is not possible to defend the term set selections used to define the metric', 'as being canonical, it is better for them to be mathematically regarded as a sample of the canonical term set. in this light, it becomes critical to understand the sensitivity of the proposed metric to the particular term set sampled, and ideally, characterize the distribution of the', 'metric under many such samples as partially explored in ( antoniak and mimno 2018 ). in examining several online corpora, we observe that although the', '']",7
"['.,  #TAUTHOR_TAG with 92']","['on deep learning syntactic parsing models has achieved notably good results, e. g.,  #TAUTHOR_TAG with 92. 4']","['work on deep learning syntactic parsing models has achieved notably good results, e. g.,  #TAUTHOR_TAG with 92']","['work on deep learning syntactic parsing models has achieved notably good results, e. g.,  #TAUTHOR_TAG with 92. 4 f 1 on penn treebank constituency parsing and  #AUTHOR_TAG with 92. 8 f 1.', 'in this paper we borrow from the approaches of both of these works and present a neural - net parse reranker that achieves very good results, 93. 8 f 1, with a comparatively simple architecture.', 'in the remainder of this section we outline the major difference between this and previous workviewing parsing as a language modeling problem.', 'section 2 looks more closely at three of the most relevant previous papers.', 'we then describe our exact model ( section 3 ), followed by the experimental setup and results ( sections 4 and 5 ).', 'there is a one - to - one mapping between a tree and its sequential form.', '( part - of - speech tags are not used.']",0
"['basic language modeling architecture that we have adopted, while the other two  #TAUTHOR_TAG are parsing models that have the current best results in nn parsing']","['basic language modeling architecture that we have adopted, while the other two  #TAUTHOR_TAG are parsing models that have the current best results in nn parsing']","['gives the basic language modeling architecture that we have adopted, while the other two  #TAUTHOR_TAG are parsing models that have the current best results in nn parsing']","['look here at three neural net ( nn ) models closest to our research along various dimensions.', 'the first  #AUTHOR_TAG gives the basic language modeling architecture that we have adopted, while the other two  #TAUTHOR_TAG are parsing models that have the current best results in nn parsing']",0
"['tree  #TAUTHOR_TAG :', 'where a is a sequence of actions']","['tree  #TAUTHOR_TAG :', 'where a is a sequence of actions']","['actions the model takes to generate the tree  #TAUTHOR_TAG :', 'where a is a sequence of actions']","['neural network grammars ( rnng ), a generative parsing model, defines a joint distribution over a tree in terms of actions the model takes to generate the tree  #TAUTHOR_TAG :', 'where a is a sequence of actions whose output precisely matches the sequence of symbols in z, which implies equation ( 3 ) is the same as equation ( 2 ).', ""rnng and our model differ in how they compute the conditioning event ( z 1, · · ·, z t−1 ) : rnng combines hidden states of three lstms that keep track of actions the model has taken, an incomplete tree the model has generated and words the model has generated whereas our model uses one lstm's hidden state as shown in the next section""]",0
"['mtps  #AUTHOR_TAG and rnng  #TAUTHOR_TAG, both of which are trained on the wsj only']","['mtps  #AUTHOR_TAG and rnng  #TAUTHOR_TAG, both of which are trained on the wsj only']","['6 f 1 lstm - lm ( g ) outperforms an ensemble of five mtps  #AUTHOR_TAG and rnng  #TAUTHOR_TAG, both of which are trained on the wsj only']","['shown in table 2, with 92. 6 f 1 lstm - lm ( g ) outperforms an ensemble of five mtps  #AUTHOR_TAG and rnng  #TAUTHOR_TAG, both of which are trained on the wsj only']",0
['y with lstm - lm as  #TAUTHOR_TAG'],['y with lstm - lm as  #TAUTHOR_TAG'],['y with lstm - lm as  #TAUTHOR_TAG'],"['use the wall street journal ( wsj ) of the penn treebank  #AUTHOR_TAG for training ( 2 - 21 ), development ( 24 ) and testing ( 23 ) and millions of auto - parsed "" silver "" trees ( mc  #AUTHOR_TAG for tritraining.', 'to obtain silver trees, we parse the entire section of the new york times ( nyt ) of the fifth gigaword  #AUTHOR_TAG with a product of eight berkeley parsers  #AUTHOR_TAG 2 and zpar  #AUTHOR_TAG and select 24 million trees on which both parsers agree  #AUTHOR_TAG.', 'we do not resample trees to match the sentence length distribution of the nyt to that of the wsj ( vinyals et 1 the code and trained models used for experiments are available at github. com / cdg720 / emnlp2016.', '2 we use the reimplementation by  #AUTHOR_TAG.', ' #AUTHOR_TAG performed better when trained on all of 24 million trees than when trained on resampled two million trees.', 'given x, we produce y ( x ), 50 - best trees, with charniak parser and find y with lstm - lm as  #TAUTHOR_TAG do with their discriminative and generative models.', '']",3
"['', 'in fact, we see that a generative parsing model, lstm - lm, is more effective than discriminative parsing models  #TAUTHOR_TAG.', '']","['generative parsing model we presented in this paper is very powerful.', 'in fact, we see that a generative parsing model, lstm - lm, is more effective than discriminative parsing models  #TAUTHOR_TAG.', '']","['', 'in fact, we see that a generative parsing model, lstm - lm, is more effective than discriminative parsing models  #TAUTHOR_TAG.', 'we suspect building large models with character embeddings would lead to further improvement as in language modeling  #AUTHOR_TAG.', '']","['generative parsing model we presented in this paper is very powerful.', 'in fact, we see that a generative parsing model, lstm - lm, is more effective than discriminative parsing models  #TAUTHOR_TAG.', 'we suspect building large models with character embeddings would lead to further improvement as in language modeling  #AUTHOR_TAG.', '']",4
"['on text - adventure games  #TAUTHOR_TAG,']","['on text - adventure games  #TAUTHOR_TAG,']","['on text - adventure games  #TAUTHOR_TAG,']","['adventure games, in which players must make sense of the world through text descriptions and declare actions through natural language, can provide a stepping stone toward more realworld environments where agents must communicate to understand the state of the world and affect change in the world.', 'despite the steadily increasing body of research on text - adventure games  #TAUTHOR_TAG, and in addition to the ubiquity of deep reinforcement learning applications  #AUTHOR_TAG, teaching an agent to play text - adventure games remains a challenging task.', 'learning a control policy for a text - adventure game requires a significant amount of exploration, resulting in training runs that take hundreds of thousands of simulations  #TAUTHOR_TAG.', 'one reason that text - adventure games require so much exploration is that most deep reinforcement learning algorithms are trained on a task without a real prior.', 'in essence, the agent must learn everything about the game from only its interactions with the environment.', 'yet, text - adventure games make ample use of commonsense knowledge ( e. g., an axe can be used to cut wood ) and genre themes ( e. g., in a horror or fantasy game, a coffin is likely to contain a vampire or other undead monster ).', 'this is in addition to the challenges innate to the text - adventure game itself - games are puzzleswhich results in inefficient training.', ' #AUTHOR_TAG developed a reinforcement learning agent that modeled the text environment as a knowledge graph and achieved state - of - the - art results on simple text - adventure games provided by the textworld environment.', 'they observed that a simple form of transfer from very similar games greatly improved policy training time.', 'however, games beyond the toy textworld environments are beyond the reach of state - of - the - art techniques.', 'in this paper, we explore the use of knowledge graphs and associated neural embeddings as a medium for domain transfer to improve training effectiveness on new text - adventure games.', 'specifically, we explore transfer learning at multiple levels and across different dimensions.', 'we first look at the effects of playing a text - adventure game given a strong prior in the form of a knowledge graph extracted from generalized textual walk - throughs of interactive fiction as well as those made specifically for a given game.', 'next, we explore the transfer of control policies in deep q - learning ( dqn ) by pre - training portions of a deep q - network using question - answering and by dqn - to - dqn parameter transfer between games.', 'we evaluate these techniques on two different sets of human authored and computer generated games']",0
"['on text - adventure games  #TAUTHOR_TAG,']","['on text - adventure games  #TAUTHOR_TAG,']","['on text - adventure games  #TAUTHOR_TAG,']","['adventure games, in which players must make sense of the world through text descriptions and declare actions through natural language, can provide a stepping stone toward more realworld environments where agents must communicate to understand the state of the world and affect change in the world.', 'despite the steadily increasing body of research on text - adventure games  #TAUTHOR_TAG, and in addition to the ubiquity of deep reinforcement learning applications  #AUTHOR_TAG, teaching an agent to play text - adventure games remains a challenging task.', 'learning a control policy for a text - adventure game requires a significant amount of exploration, resulting in training runs that take hundreds of thousands of simulations  #TAUTHOR_TAG.', 'one reason that text - adventure games require so much exploration is that most deep reinforcement learning algorithms are trained on a task without a real prior.', 'in essence, the agent must learn everything about the game from only its interactions with the environment.', 'yet, text - adventure games make ample use of commonsense knowledge ( e. g., an axe can be used to cut wood ) and genre themes ( e. g., in a horror or fantasy game, a coffin is likely to contain a vampire or other undead monster ).', 'this is in addition to the challenges innate to the text - adventure game itself - games are puzzleswhich results in inefficient training.', ' #AUTHOR_TAG developed a reinforcement learning agent that modeled the text environment as a knowledge graph and achieved state - of - the - art results on simple text - adventure games provided by the textworld environment.', 'they observed that a simple form of transfer from very similar games greatly improved policy training time.', 'however, games beyond the toy textworld environments are beyond the reach of state - of - the - art techniques.', 'in this paper, we explore the use of knowledge graphs and associated neural embeddings as a medium for domain transfer to improve training effectiveness on new text - adventure games.', 'specifically, we explore transfer learning at multiple levels and across different dimensions.', 'we first look at the effects of playing a text - adventure game given a strong prior in the form of a knowledge graph extracted from generalized textual walk - throughs of interactive fiction as well as those made specifically for a given game.', 'next, we explore the transfer of control policies in deep q - learning ( dqn ) by pre - training portions of a deep q - network using question - answering and by dqn - to - dqn parameter transfer between games.', 'we evaluate these techniques on two different sets of human authored and computer generated games']",0
['to solve  #TAUTHOR_TAG : ( 1'],['to solve  #TAUTHOR_TAG : ( 1 ) the agent'],"['- adventure games, in which an agent must interact with the world entirely through natural language, provide us with two challenges that have proven difficult for deep reinforcement learning to solve  #TAUTHOR_TAG : ( 1']","['- adventure games, in which an agent must interact with the world entirely through natural language, provide us with two challenges that have proven difficult for deep reinforcement learning to solve  #TAUTHOR_TAG : ( 1 ) the agent must act based only on potentially incomplete textual descriptions of the world around it.', 'the world is thus partially observable, as the agent does not have access to the state of the world at any stage.', '( 2 ) the action space is combinatorially large - a consequence of the agent having to declare commands in natural language.', 'these two problems together have kept commercial text adventure games out of the reach of existing deep reinforcement learning methods, especially given the fact that most of these methods attempt to train on a particular game from scratch.', 'text - adventure games can be treated as partially observable markov decision processes ( pomdps ).', 'this can be represented as a 7 - tuple of s, t, a, ω, o, r, γ : the set of environment states, conditional transition probabilities between states, words used to compose text commands, observations, conditional observation probabilities, the reward function, and the discount factor respectively.', 'multiple recent works have explored the challenges associated with these games  #TAUTHOR_TAG.', '']",0
['to solve  #TAUTHOR_TAG : ( 1'],['to solve  #TAUTHOR_TAG : ( 1 ) the agent'],"['- adventure games, in which an agent must interact with the world entirely through natural language, provide us with two challenges that have proven difficult for deep reinforcement learning to solve  #TAUTHOR_TAG : ( 1']","['- adventure games, in which an agent must interact with the world entirely through natural language, provide us with two challenges that have proven difficult for deep reinforcement learning to solve  #TAUTHOR_TAG : ( 1 ) the agent must act based only on potentially incomplete textual descriptions of the world around it.', 'the world is thus partially observable, as the agent does not have access to the state of the world at any stage.', '( 2 ) the action space is combinatorially large - a consequence of the agent having to declare commands in natural language.', 'these two problems together have kept commercial text adventure games out of the reach of existing deep reinforcement learning methods, especially given the fact that most of these methods attempt to train on a particular game from scratch.', 'text - adventure games can be treated as partially observable markov decision processes ( pomdps ).', 'this can be represented as a 7 - tuple of s, t, a, ω, o, r, γ : the set of environment states, conditional transition probabilities between states, words used to compose text commands, observations, conditional observation probabilities, the reward function, and the discount factor respectively.', 'multiple recent works have explored the challenges associated with these games  #TAUTHOR_TAG.', '']",0
['to solve  #TAUTHOR_TAG : ( 1'],['to solve  #TAUTHOR_TAG : ( 1 ) the agent'],"['- adventure games, in which an agent must interact with the world entirely through natural language, provide us with two challenges that have proven difficult for deep reinforcement learning to solve  #TAUTHOR_TAG : ( 1']","['- adventure games, in which an agent must interact with the world entirely through natural language, provide us with two challenges that have proven difficult for deep reinforcement learning to solve  #TAUTHOR_TAG : ( 1 ) the agent must act based only on potentially incomplete textual descriptions of the world around it.', 'the world is thus partially observable, as the agent does not have access to the state of the world at any stage.', '( 2 ) the action space is combinatorially large - a consequence of the agent having to declare commands in natural language.', 'these two problems together have kept commercial text adventure games out of the reach of existing deep reinforcement learning methods, especially given the fact that most of these methods attempt to train on a particular game from scratch.', 'text - adventure games can be treated as partially observable markov decision processes ( pomdps ).', 'this can be represented as a 7 - tuple of s, t, a, ω, o, r, γ : the set of environment states, conditional transition probabilities between states, words used to compose text commands, observations, conditional observation probabilities, the reward function, and the discount factor respectively.', 'multiple recent works have explored the challenges associated with these games  #TAUTHOR_TAG.', '']",0
['used in  #TAUTHOR_TAG to better'],"['used in  #TAUTHOR_TAG to better achieve such a graph in general interactive fiction environments. the', 'agent also has access']",['used in  #TAUTHOR_TAG to better'],"['', 'of openie  #AUTHOR_TAG in addition to a few rules to account for the regularities of text - adventure games', "". the graph itself is more or less a map of the world, with information about objects'affordances and attributes linked to the rooms that they are place in in a map. the graph also makes a distinction with respect to items that are in the agent's possession or in their immediate surrounding environment. we make"", 'minor modifications to the rules used in  #TAUTHOR_TAG to better achieve such a graph in general interactive fiction environments. the', ""agent also has access to all actions accepted by the game's parser, following  #AUTHOR_TAG. for general interactive fiction environments, we develop our own method to extract this information. this is done by extracting a set of templates accepted by the parser, with the"", 'objects or noun phrases in the actions replaces with a obj tag. an example of such', 'a template is "" place obj in obj "". these obj tags are then filled in by looking at all possible objects in the given vocabulary for the game. this action space is of the order of a = o ( | v | ×', '| o | 2 ) where v is the number of action verbs, and o is the number of distinct objects in the world that the agent can interact with. as this is', 'too large a space for a rl agent to effectively explore, the knowledge graph is used to prune this space by ranking actions', 'based on their presence in the current knowledge graph and the relations between the objects in the graph as in  #TAUTHOR_TAG the architecture', 'for the deep q - network consists of two separate neural networks - encoding state and action separately -', 'with the final q - value for a state - action pair being the result of a', 'pairwise interaction function between the two ( figure 1 ). we train with a standard dqn training loop ; the policy is determined by the q -', 'value of a particular state - action pair, which is updated using the', 'bellman equation  #AUTHOR_TAG : ( 1 ) where γ refers to the discount factor and r t + 1 is', 'the observed reward. the whole system is trained using prioritized experience replay  #AUTHOR_TAG, a modified version of - greedy learning, and a temporal difference loss that is computed as : where a k + 1 represents the action set at step k +', '1 and s t, a t refer to the encoded state and action representations respectively']",6
['used in  #TAUTHOR_TAG to better'],"['used in  #TAUTHOR_TAG to better achieve such a graph in general interactive fiction environments. the', 'agent also has access']",['used in  #TAUTHOR_TAG to better'],"['', 'of openie  #AUTHOR_TAG in addition to a few rules to account for the regularities of text - adventure games', "". the graph itself is more or less a map of the world, with information about objects'affordances and attributes linked to the rooms that they are place in in a map. the graph also makes a distinction with respect to items that are in the agent's possession or in their immediate surrounding environment. we make"", 'minor modifications to the rules used in  #TAUTHOR_TAG to better achieve such a graph in general interactive fiction environments. the', ""agent also has access to all actions accepted by the game's parser, following  #AUTHOR_TAG. for general interactive fiction environments, we develop our own method to extract this information. this is done by extracting a set of templates accepted by the parser, with the"", 'objects or noun phrases in the actions replaces with a obj tag. an example of such', 'a template is "" place obj in obj "". these obj tags are then filled in by looking at all possible objects in the given vocabulary for the game. this action space is of the order of a = o ( | v | ×', '| o | 2 ) where v is the number of action verbs, and o is the number of distinct objects in the world that the agent can interact with. as this is', 'too large a space for a rl agent to effectively explore, the knowledge graph is used to prune this space by ranking actions', 'based on their presence in the current knowledge graph and the relations between the objects in the graph as in  #TAUTHOR_TAG the architecture', 'for the deep q - network consists of two separate neural networks - encoding state and action separately -', 'with the final q - value for a state - action pair being the result of a', 'pairwise interaction function between the two ( figure 1 ). we train with a standard dqn training loop ; the policy is determined by the q -', 'value of a particular state - action pair, which is updated using the', 'bellman equation  #AUTHOR_TAG : ( 1 ) where γ refers to the discount factor and r t + 1 is', 'the observed reward. the whole system is trained using prioritized experience replay  #AUTHOR_TAG, a modified version of - greedy learning, and a temporal difference loss that is computed as : where a k + 1 represents the action set at step k +', '1 and s t, a t refer to the encoded state and action representations respectively']",5
"['architecture as in  #TAUTHOR_TAG.', 'this game is']","['architecture as in  #TAUTHOR_TAG.', 'this game is']","['of the architecture as in  #TAUTHOR_TAG.', 'this game is referred']","['', 'our system first trains a question - answering system  #AUTHOR_TAG using traces given by an oracle, as in section 4.', 'for commercial textadventure games, these traces take the form of state - action pairs generated using perfect walkthrough descriptions of the game found online as described in section 4.', 'we use the parameters of the questionanswering system to pre - train portions of the deep q - network for a different game within in the same domain.', 'the portions that are pre - trained are the same parts of the architecture as in  #TAUTHOR_TAG.', '']",5
"['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['', 'we perform ablation tests within each domain, mainly testing the effects of transfer from seeding, oracle - based question - answering, and sourceto - target parameter transfer.', 'additionally, there are a couple of extra dimensions of ablations that we study, specific to each of the domains and explained below.', 'all experiments are run three times using different random seeds.', 'for all the experiments we report metrics known to be important for transfer learning tasks  #AUTHOR_TAG : average reward collected in the first 50 episodes ( init. reward ), average reward collected for 50 episodes after convergence ( final reward ), and number of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG for training the kg - dqn with action pruning, with the main difference being that we use 100 dimensional word embeddings instead of 50 dimensions for the horror genre']",5
"['', 'following  #TAUTHOR_TAG, we use textworld\'s "" home "" theme to generate the games for']","['similar games.', 'following  #TAUTHOR_TAG, we use textworld\'s "" home "" theme to generate the games for']","['similar games.', 'following  #TAUTHOR_TAG, we use textworld\'s "" home "" theme to generate the games for']","['##world uses a grammar to generate similar games.', 'following  #TAUTHOR_TAG, we use textworld\'s "" home "" theme to generate the games for the question - answering system.', 'textworld is a framework that uses a grammar to randomly generate game worlds and quests.', 'this framework also gives us information such as instructions on how to finish the quest, and a list of actions that can be performed at each step based on the current world state.', 'we do not let our agent access this additional solution information or admissible actions list.', 'given the relatively small quest length for textworld games - games can be completed in as little as 5 steps - we generate 50 such games and partition them into train and test sets in a 4 : 1 ratio.', 'the traces are generated on the training set, and the question - answering system is evaluated on the test set.', 'we then pick a random game from the test set to train our source task deep q - network for this domain.', 'for this training, we use the reward function provided by textworld : + 1 for each action taken that moves the agent closer to finishing the quest ; - 1 for each action taken that extends the minimum number of steps needed to finish the quest from the current stage ; 0 for all other situations.', 'we choose the game, 9 : 05 3 as our target task game due to similarities in structure in addition to the vocabulary overlap.', 'note that there are multiple possible endings to this game and we pick the simplest one for the purpose of training our agent']",5
['used in  #TAUTHOR_TAG to better'],"['used in  #TAUTHOR_TAG to better achieve such a graph in general interactive fiction environments. the', 'agent also has access']",['used in  #TAUTHOR_TAG to better'],"['', 'of openie  #AUTHOR_TAG in addition to a few rules to account for the regularities of text - adventure games', "". the graph itself is more or less a map of the world, with information about objects'affordances and attributes linked to the rooms that they are place in in a map. the graph also makes a distinction with respect to items that are in the agent's possession or in their immediate surrounding environment. we make"", 'minor modifications to the rules used in  #TAUTHOR_TAG to better achieve such a graph in general interactive fiction environments. the', ""agent also has access to all actions accepted by the game's parser, following  #AUTHOR_TAG. for general interactive fiction environments, we develop our own method to extract this information. this is done by extracting a set of templates accepted by the parser, with the"", 'objects or noun phrases in the actions replaces with a obj tag. an example of such', 'a template is "" place obj in obj "". these obj tags are then filled in by looking at all possible objects in the given vocabulary for the game. this action space is of the order of a = o ( | v | ×', '| o | 2 ) where v is the number of action verbs, and o is the number of distinct objects in the world that the agent can interact with. as this is', 'too large a space for a rl agent to effectively explore, the knowledge graph is used to prune this space by ranking actions', 'based on their presence in the current knowledge graph and the relations between the objects in the graph as in  #TAUTHOR_TAG the architecture', 'for the deep q - network consists of two separate neural networks - encoding state and action separately -', 'with the final q - value for a state - action pair being the result of a', 'pairwise interaction function between the two ( figure 1 ). we train with a standard dqn training loop ; the policy is determined by the q -', 'value of a particular state - action pair, which is updated using the', 'bellman equation  #AUTHOR_TAG : ( 1 ) where γ refers to the discount factor and r t + 1 is', 'the observed reward. the whole system is trained using prioritized experience replay  #AUTHOR_TAG, a modified version of - greedy learning, and a temporal difference loss that is computed as : where a k + 1 represents the action set at step k +', '1 and s t, a t refer to the encoded state and action representations respectively']",3
"['architecture as in  #TAUTHOR_TAG.', 'this game is']","['architecture as in  #TAUTHOR_TAG.', 'this game is']","['of the architecture as in  #TAUTHOR_TAG.', 'this game is referred']","['', 'our system first trains a question - answering system  #AUTHOR_TAG using traces given by an oracle, as in section 4.', 'for commercial textadventure games, these traces take the form of state - action pairs generated using perfect walkthrough descriptions of the game found online as described in section 4.', 'we use the parameters of the questionanswering system to pre - train portions of the deep q - network for a different game within in the same domain.', 'the portions that are pre - trained are the same parts of the architecture as in  #TAUTHOR_TAG.', '']",3
"['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['', 'we perform ablation tests within each domain, mainly testing the effects of transfer from seeding, oracle - based question - answering, and sourceto - target parameter transfer.', 'additionally, there are a couple of extra dimensions of ablations that we study, specific to each of the domains and explained below.', 'all experiments are run three times using different random seeds.', 'for all the experiments we report metrics known to be important for transfer learning tasks  #AUTHOR_TAG : average reward collected in the first 50 episodes ( init. reward ), average reward collected for 50 episodes after convergence ( final reward ), and number of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG for training the kg - dqn with action pruning, with the main difference being that we use 100 dimensional word embeddings instead of 50 dimensions for the horror genre']",3
"['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG']","['', 'we perform ablation tests within each domain, mainly testing the effects of transfer from seeding, oracle - based question - answering, and sourceto - target parameter transfer.', 'additionally, there are a couple of extra dimensions of ablations that we study, specific to each of the domains and explained below.', 'all experiments are run three times using different random seeds.', 'for all the experiments we report metrics known to be important for transfer learning tasks  #AUTHOR_TAG : average reward collected in the first 50 episodes ( init. reward ), average reward collected for 50 episodes after convergence ( final reward ), and number of steps taken to finish the game for 50 episodes after convergence ( steps ).', 'for the metrics tested after convergence, we set = 0. 1 following both  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we use similar hyperparameters to those reported in  #TAUTHOR_TAG for training the kg - dqn with action pruning, with the main difference being that we use 100 dimensional word embeddings instead of 50 dimensions for the horror genre']",4
[' #TAUTHOR_TAG and discover that it cannot reliably tell whether'],[' #TAUTHOR_TAG and discover that it cannot reliably tell whether'],[' #TAUTHOR_TAG and discover that it cannot reliably tell whether'],"['paragraph embedding models are remarkably effective for downstream classification tasks, what they learn and encode into a single vector remains opaque.', 'in this paper, we investigate a state - of - the - art paragraph embedding method proposed by  #TAUTHOR_TAG and discover that it cannot reliably tell whether a given sentence occurs in the input paragraph or not.', 'we formulate a sentence content task to probe for this basic linguistic property and find that even a much simpler bag - of - words method has no trouble solving it.', 'this result motivates us to replace the reconstructionbased objective of  #TAUTHOR_TAG with our sentence content probe objective in a semisupervised setting.', 'despite its simplicity, our objective improves over paragraph reconstruction in terms of ( 1 ) downstream classification accuracies on benchmark datasets, ( 2 ) faster training, and ( 3 ) better generalization ability']",1
[' #TAUTHOR_TAG and discover that it cannot reliably tell whether'],[' #TAUTHOR_TAG and discover that it cannot reliably tell whether'],[' #TAUTHOR_TAG and discover that it cannot reliably tell whether'],"['paragraph embedding models are remarkably effective for downstream classification tasks, what they learn and encode into a single vector remains opaque.', 'in this paper, we investigate a state - of - the - art paragraph embedding method proposed by  #TAUTHOR_TAG and discover that it cannot reliably tell whether a given sentence occurs in the input paragraph or not.', 'we formulate a sentence content task to probe for this basic linguistic property and find that even a much simpler bag - of - words method has no trouble solving it.', 'this result motivates us to replace the reconstructionbased objective of  #TAUTHOR_TAG with our sentence content probe objective in a semisupervised setting.', 'despite its simplicity, our objective improves over paragraph reconstruction in terms of ( 1 ) downstream classification accuracies on benchmark datasets, ( 2 ) faster training, and ( 3 ) better generalization ability']",1
"['text classification  #TAUTHOR_TAG, document']","['text classification  #TAUTHOR_TAG, document']","['text classification  #TAUTHOR_TAG, document retrieval  #AUTHOR_TAG,']","['that embed a paragraph into a single vector have been successfully integrated into many nlp applications, including text classification  #TAUTHOR_TAG, document retrieval  #AUTHOR_TAG, and semantic similarity and relatedness  #AUTHOR_TAG.', 'however, downstream performance provides little insight into the kinds of linguistic properties that are encoded by these embeddings.', 'inspired by the growing body of work on sentence - level linguistic probe tasks  #AUTHOR_TAG, we set out to evaluate a state - of - the - art paragraph embedding method using a probe task to measure how well it encodes the identity of the sentences within a paragraph.', 'we discover that the method falls short of capturing this basic property, and that implementing a simple objective to fix this issue improves classification performance, training speed, and generalization ability.', 'we specifically investigate the paragraph embedding method of  #TAUTHOR_TAG, which consists of a cnn - based encoder - decoder model paired with a reconstruction objective to learn powerful paragraph embeddings that are capable of accurately reconstructing long paragraphs.', 'this model significantly improves downstream classification accuracies, outperforming lstm - based alternatives  #AUTHOR_TAG.', '']",0
"['of paragraph embeddings  #TAUTHOR_TAG.', 'we only consider paragraphs that have at least two sentences']","['of paragraph embeddings  #TAUTHOR_TAG.', 'we only consider paragraphs that have at least two sentences.', 'our dataset has 346, 033 training paragraphs,']","['evaluating the quality of paragraph embeddings  #TAUTHOR_TAG.', 'we only consider paragraphs that have at least two sentences.', 'our dataset has 346,']","['to train our classifiers are extracted from the hotel reviews corpus  #AUTHOR_TAG, which has previously been used for evaluating the quality of paragraph embeddings  #TAUTHOR_TAG.', 'we only consider paragraphs that have at least two sentences.', '']",0
"[',  #TAUTHOR_TAG to analyze']","[', sentences ( e. g.,  #AUTHOR_TAG, and larger bodies of text ( e. g.,  #TAUTHOR_TAG to analyze']","[',  #TAUTHOR_TAG to analyze']","['embeddings and probe tasks a variety of methods exist for obtaining fixed - length dense vector representations of words ( e. g.,  #AUTHOR_TAG, sentences ( e. g.,  #AUTHOR_TAG, and larger bodies of text ( e. g.,  #TAUTHOR_TAG to analyze word and sentence embeddings, recent work has studied classification tasks that probe them for various linguistic properties  #AUTHOR_TAG a, b ;  #AUTHOR_TAG.', 'in this paper, we extend the notion of probe tasks to the paragraph level.', 'transfer learning another line of related work is transfer learning, which has been the driver of recent successes in nlp.', 'recently - proposed objectives for transfer learning include surrounding sentence prediction  #AUTHOR_TAG, paraphrasing  #AUTHOR_TAG, entailment  #AUTHOR_TAG, machine translation ( mc  #AUTHOR_TAG, discourse  #AUTHOR_TAG, and language modeling  #AUTHOR_TAG']",0
"['text classification  #TAUTHOR_TAG, document']","['text classification  #TAUTHOR_TAG, document']","['text classification  #TAUTHOR_TAG, document retrieval  #AUTHOR_TAG,']","['that embed a paragraph into a single vector have been successfully integrated into many nlp applications, including text classification  #TAUTHOR_TAG, document retrieval  #AUTHOR_TAG, and semantic similarity and relatedness  #AUTHOR_TAG.', 'however, downstream performance provides little insight into the kinds of linguistic properties that are encoded by these embeddings.', 'inspired by the growing body of work on sentence - level linguistic probe tasks  #AUTHOR_TAG, we set out to evaluate a state - of - the - art paragraph embedding method using a probe task to measure how well it encodes the identity of the sentences within a paragraph.', 'we discover that the method falls short of capturing this basic property, and that implementing a simple objective to fix this issue improves classification performance, training speed, and generalization ability.', 'we specifically investigate the paragraph embedding method of  #TAUTHOR_TAG, which consists of a cnn - based encoder - decoder model paired with a reconstruction objective to learn powerful paragraph embeddings that are capable of accurately reconstructing long paragraphs.', 'this model significantly improves downstream classification accuracies, outperforming lstm - based alternatives  #AUTHOR_TAG.', '']",5
['r model in  #TAUTHOR_TAG'],['- r model in  #TAUTHOR_TAG'],"['we create a pair of examples from every sentence in the paragraph to maximize the training data. for each task, we compare against', 'the original cnn - r model in  #TAUTHOR_TAG']","['we create a pair of examples from every sentence in the paragraph to maximize the training data. for each task, we compare against', 'the original cnn - r model in  #TAUTHOR_TAG. figure 3 shows the model performance with fine - tuning on 0. 1 % to 100 % of the training set of each dataset', '. one interesting result is that cnn - sc', 'relies on very few training examples to achieve comparable accuracy to the purely supervised cnn model. for instance, fine - tuning cnn - sc using just 500 labeled', 'training examples surpasses the accuracy of training from scratch on 100, 000 labeled examples, indicating that the sentence content encoder generalizes well. cnn - sc also outperforms cnn - r by large margins when only small amounts of labeled training data are available. finally', ', when all labeled training data is used,', '']",5
"['text classification  #TAUTHOR_TAG, document']","['text classification  #TAUTHOR_TAG, document']","['text classification  #TAUTHOR_TAG, document retrieval  #AUTHOR_TAG,']","['that embed a paragraph into a single vector have been successfully integrated into many nlp applications, including text classification  #TAUTHOR_TAG, document retrieval  #AUTHOR_TAG, and semantic similarity and relatedness  #AUTHOR_TAG.', 'however, downstream performance provides little insight into the kinds of linguistic properties that are encoded by these embeddings.', 'inspired by the growing body of work on sentence - level linguistic probe tasks  #AUTHOR_TAG, we set out to evaluate a state - of - the - art paragraph embedding method using a probe task to measure how well it encodes the identity of the sentences within a paragraph.', 'we discover that the method falls short of capturing this basic property, and that implementing a simple objective to fix this issue improves classification performance, training speed, and generalization ability.', 'we specifically investigate the paragraph embedding method of  #TAUTHOR_TAG, which consists of a cnn - based encoder - decoder model paired with a reconstruction objective to learn powerful paragraph embeddings that are capable of accurately reconstructing long paragraphs.', 'this model significantly improves downstream classification accuracies, outperforming lstm - based alternatives  #AUTHOR_TAG.', '']",7
['r model in  #TAUTHOR_TAG'],['- r model in  #TAUTHOR_TAG'],"['we create a pair of examples from every sentence in the paragraph to maximize the training data. for each task, we compare against', 'the original cnn - r model in  #TAUTHOR_TAG']","['we create a pair of examples from every sentence in the paragraph to maximize the training data. for each task, we compare against', 'the original cnn - r model in  #TAUTHOR_TAG. figure 3 shows the model performance with fine - tuning on 0. 1 % to 100 % of the training set of each dataset', '. one interesting result is that cnn - sc', 'relies on very few training examples to achieve comparable accuracy to the purely supervised cnn model. for instance, fine - tuning cnn - sc using just 500 labeled', 'training examples surpasses the accuracy of training from scratch on 100, 000 labeled examples, indicating that the sentence content encoder generalizes well. cnn - sc also outperforms cnn - r by large margins when only small amounts of labeled training data are available. finally', ', when all labeled training data is used,', '']",7
"['this section, we first fully specify our probe task before comparing the model of  #TAUTHOR_TAG']","['this section, we first fully specify our probe task before comparing the model of  #TAUTHOR_TAG']","['this section, we first fully specify our probe task before comparing the model of  #TAUTHOR_TAG']","['this section, we first fully specify our probe task before comparing the model of  #TAUTHOR_TAG to a simple bag - of - words model.', 'somewhat surprisingly, the latter substantially outperforms the former despite its relative simplicity']",4
"['of external parsers nor manually extracted features ( see  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii']","['of external parsers nor manually extracted features ( see  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii )']","['uses automatically extracted features without the need of external parsers nor manually extracted features ( see  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii']","['', 'previously proposed models ( summarized in section 2 ) exhibit several issues that the neural network - based baseline approach ( detailed in section 3. 1 ) overcomes : ( i ) our model uses automatically extracted features without the need of external parsers nor manually extracted features ( see  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii ) all entities and the corresponding relations within the sentence are extracted at once, instead of examining one pair of entities at a time ( see adel and schutze ( 2017 ) ), and ( iii ) we model relation extraction in a multi - label setting, allowing multiple relations per entity ( see  #AUTHOR_TAG ;  #AUTHOR_TAG a ) ).', 'the core contribution of the paper is the use of at as an extension in the training procedure for the joint extraction task ( section 3. 2 ).', 'to evaluate the proposed at method, we perform a large scale experimental study in this joint task ( see section 4 ), using datasets from different contexts ( i. e., news, biomedical, real estate ) and languages ( i. e., english, dutch ).', 'we use a strong baseline that outperforms all previous models that rely on automatically extracted features, achieving state - of - the - art performance ( section 5 ).', 'compared to the baseline model, applying at during training leads to a consistent additional increase in joint extraction effectiveness']",0
"['', ' #TAUTHOR_TAG propose the']","['bidirectional tree - structured rnns for different contexts ( i. e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #TAUTHOR_TAG propose the']","['e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #TAUTHOR_TAG propose the use of various manually extracted features along with rnns']","['entity and relation extraction : joint models  #AUTHOR_TAG that are based on manually extracted features have been proposed for performing both the named entity recognition ( ner ) and relation extraction subtasks at once.', 'these methods rely on the availability of nlp tools ( e. g., pos taggers ) or manually designed features leading to additional complexity.', 'neural network methods have been exploited to overcome this feature design issue and usually involve rnns and cnns  #AUTHOR_TAG.', ' #AUTHOR_TAG as well as  #AUTHOR_TAG apply bidirectional tree - structured rnns for different contexts ( i. e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #TAUTHOR_TAG propose the use of various manually extracted features along with rnns.', 'adel and schutze ( 2017 ) solve the simpler problem of entity classification ( ec, assuming entity boundaries are given ), instead of ner, and they replicate the context around the entities, feeding entity pairs to the relation extraction layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', ' #AUTHOR_TAG a ) use lstms in a joint model for extracting just one relation at a time, but increase the complexity of the ner part.', '']",0
"['of external parsers nor manually extracted features ( see  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii']","['of external parsers nor manually extracted features ( see  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii )']","['uses automatically extracted features without the need of external parsers nor manually extracted features ( see  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii']","['', 'previously proposed models ( summarized in section 2 ) exhibit several issues that the neural network - based baseline approach ( detailed in section 3. 1 ) overcomes : ( i ) our model uses automatically extracted features without the need of external parsers nor manually extracted features ( see  #TAUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii ) all entities and the corresponding relations within the sentence are extracted at once, instead of examining one pair of entities at a time ( see adel and schutze ( 2017 ) ), and ( iii ) we model relation extraction in a multi - label setting, allowing multiple relations per entity ( see  #AUTHOR_TAG ;  #AUTHOR_TAG a ) ).', 'the core contribution of the paper is the use of at as an extension in the training procedure for the joint extraction task ( section 3. 2 ).', 'to evaluate the proposed at method, we perform a large scale experimental study in this joint task ( see section 4 ), using datasets from different contexts ( i. e., news, biomedical, real estate ) and languages ( i. e., english, dutch ).', 'we use a strong baseline that outperforms all previous models that rely on automatically extracted features, achieving state - of - the - art performance ( section 5 ).', 'compared to the baseline model, applying at during training leads to a consistent additional increase in joint extraction effectiveness']",1
"['', ' #TAUTHOR_TAG propose the']","['bidirectional tree - structured rnns for different contexts ( i. e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #TAUTHOR_TAG propose the']","['e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #TAUTHOR_TAG propose the use of various manually extracted features along with rnns']","['entity and relation extraction : joint models  #AUTHOR_TAG that are based on manually extracted features have been proposed for performing both the named entity recognition ( ner ) and relation extraction subtasks at once.', 'these methods rely on the availability of nlp tools ( e. g., pos taggers ) or manually designed features leading to additional complexity.', 'neural network methods have been exploited to overcome this feature design issue and usually involve rnns and cnns  #AUTHOR_TAG.', ' #AUTHOR_TAG as well as  #AUTHOR_TAG apply bidirectional tree - structured rnns for different contexts ( i. e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #TAUTHOR_TAG propose the use of various manually extracted features along with rnns.', 'adel and schutze ( 2017 ) solve the simpler problem of entity classification ( ec, assuming entity boundaries are given ), instead of ner, and they replicate the context around the entities, feeding entity pairs to the relation extraction layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', ' #AUTHOR_TAG a ) use lstms in a joint model for extracting just one relation at a time, but increase the complexity of the ner part.', '']",1
"['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutz']","['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on the ec']","['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on']","['crf - layer and ( iii ) character level embeddings. compared to  #AUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less than 1 % ) on the joint task. on', 'the other hand,  #AUTHOR_TAG use the same model for the ade biomedical dataset, where we report a 2. 5 % overall improvement. this indicates that nlp tools are', 'not always accurate for various contexts. for the conll04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on the ec task. the baseline model outperforms the', '']",5
"['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutz']","['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on the ec']","['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on']","['crf - layer and ( iii ) character level embeddings. compared to  #AUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less than 1 % ) on the joint task. on', 'the other hand,  #AUTHOR_TAG use the same model for the ade biomedical dataset, where we report a 2. 5 % overall improvement. this indicates that nlp tools are', 'not always accurate for various contexts. for the conll04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on the ec task. the baseline model outperforms the', '']",5
"['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutz']","['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on the ec']","['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on']","['crf - layer and ( iii ) character level embeddings. compared to  #AUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less than 1 % ) on the joint task. on', 'the other hand,  #AUTHOR_TAG use the same model for the ade biomedical dataset, where we report a 2. 5 % overall improvement. this indicates that nlp tools are', 'not always accurate for various contexts. for the conll04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on the ec task. the baseline model outperforms the', '']",4
"['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutz']","['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on the ec']","['##04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on']","['crf - layer and ( iii ) character level embeddings. compared to  #AUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less than 1 % ) on the joint task. on', 'the other hand,  #AUTHOR_TAG use the same model for the ade biomedical dataset, where we report a 2. 5 % overall improvement. this indicates that nlp tools are', 'not always accurate for various contexts. for the conll04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #TAUTHOR_TAG ; adel and schutze ( 2017 ) on the ec task. the baseline model outperforms the', '']",7
,,,,3
,,,,3
,,,,0
"['.', 'al.  #TAUTHOR_TAG.', 'however, our previous']","['( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous']","['( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous work focuses on product reviews and consider cer as a special kind of aspect extraction problem  #AUTHOR_TAG.', 'determining the polarities of compatibility is reduced to a traditional sentiment classification problem.', 'this paper focuses on']","['problem of complementary entity recognition ( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous work focuses on product reviews and consider cer as a special kind of aspect extraction problem  #AUTHOR_TAG.', 'determining the polarities of compatibility is reduced to a traditional sentiment classification problem.', '']",0
"['.', 'al.  #TAUTHOR_TAG.', 'however, our previous']","['( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous']","['( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous work focuses on product reviews and consider cer as a special kind of aspect extraction problem  #AUTHOR_TAG.', 'determining the polarities of compatibility is reduced to a traditional sentiment classification problem.', 'this paper focuses on']","['problem of complementary entity recognition ( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous work focuses on product reviews and consider cer as a special kind of aspect extraction problem  #AUTHOR_TAG.', 'determining the polarities of compatibility is reduced to a traditional sentiment classification problem.', '']",0
,,,,5
,,,,5
"['.', 'al.  #TAUTHOR_TAG.', 'however, our previous']","['( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous']","['( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous work focuses on product reviews and consider cer as a special kind of aspect extraction problem  #AUTHOR_TAG.', 'determining the polarities of compatibility is reduced to a traditional sentiment classification problem.', 'this paper focuses on']","['problem of complementary entity recognition ( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous work focuses on product reviews and consider cer as a special kind of aspect extraction problem  #AUTHOR_TAG.', 'determining the polarities of compatibility is reduced to a traditional sentiment classification problem.', '']",5
['the method for cer in  #TAUTHOR_TAG'],['the method for cer in  #TAUTHOR_TAG'],"['the two - stage framework of the proposed method.', 'then we briefly introduce the method for cer in  #TAUTHOR_TAG']","['this section, we first introduce the two - stage framework of the proposed method.', 'then we briefly introduce the method for cer in  #TAUTHOR_TAG']",5
['as in  #TAUTHOR_TAG'],['as in  #TAUTHOR_TAG'],"['as in  #TAUTHOR_TAG.', 'it utilizes a large amount']","['complementary entities are mentioned in yes / no questions and their polarities of compatibility information are in answers, the proposed method naturally has a two - stage framework : complementary entity recognition : we extract complementary entities from questions using dependency paths almost the same as in  #TAUTHOR_TAG.', '']",5
['briefly introduce the method used in  #TAUTHOR_TAG and how the'],['briefly introduce the method used in  #TAUTHOR_TAG and how the'],['briefly introduce the method used in  #TAUTHOR_TAG and how the dependency paths'],"['briefly introduce the method used in  #TAUTHOR_TAG and how the dependency paths can be used in questions of pcqa ( details of dependency paths can be found in the original paper ).', 'the basic idea is to use dependency paths to identify the context of complementary relations around complementary entities.', '']",5
"['product similar as in  #TAUTHOR_TAG.', 'we also select']","['product similar as in  #TAUTHOR_TAG.', 'we also select']","['domainspecific verbs, we use 6000 reviews for each product similar as in  #TAUTHOR_TAG.', 'we also select']","['', 'the 4 products are "" stylus "", "" micro sd card "", "" mouse "" and "" tablet stand "".', 'we label complementary entities mentioned in each question and the answers as yes, no or neutral.', 'the whole test dataset is labeled by 3 annotators independently.', 'the initial agreement is 93 %.', 'then disagreements are discussed and final agreements are reached among all annotators.', 'to obtain knowledge about domainspecific verbs, we use 6000 reviews for each product similar as in  #TAUTHOR_TAG.', 'we also select about 220 reviews for each product and label them in a similar way to show the difference between product qa community and reviews.', 'the agreement for reviews is 82 %.', 'the statistics of the datasets 2 can be found in table 1.', 'we observe that pcqa has higher densities ( complementary products per sentence ) of mentions of complementary entities.', '']",5
"['', 'cer6k : this method is the method proposed in  #TAUTHOR_TAG.', 'specifically,']","['"" mouse "".', 'cer6k : this method is the method proposed in  #TAUTHOR_TAG.', 'specifically,']","['', 'cer6k : this method is the method proposed in  #TAUTHOR_TAG.', 'specifically, it uses 6000 reviews to expand domain - specific verbs.', 'next, we perform a separate evaluation on']","['', 'cer6k : this method is the method proposed in  #TAUTHOR_TAG.', 'specifically, it uses 6000 reviews to expand domain - specific verbs.', '']",5
"['.', 'al.  #TAUTHOR_TAG.', 'however, our previous']","['( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous']","['( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous work focuses on product reviews and consider cer as a special kind of aspect extraction problem  #AUTHOR_TAG.', 'determining the polarities of compatibility is reduced to a traditional sentiment classification problem.', 'this paper focuses on']","['problem of complementary entity recognition ( cer ) is first proposed by xu et.', 'al.  #TAUTHOR_TAG.', 'however, our previous work focuses on product reviews and consider cer as a special kind of aspect extraction problem  #AUTHOR_TAG.', 'determining the polarities of compatibility is reduced to a traditional sentiment classification problem.', '']",1
['briefly introduce the method used in  #TAUTHOR_TAG and how the'],['briefly introduce the method used in  #TAUTHOR_TAG and how the'],['briefly introduce the method used in  #TAUTHOR_TAG and how the dependency paths'],"['briefly introduce the method used in  #TAUTHOR_TAG and how the dependency paths can be used in questions of pcqa ( details of dependency paths can be found in the original paper ).', 'the basic idea is to use dependency paths to identify the context of complementary relations around complementary entities.', '']",6
"['tested on.', 'recently,  #TAUTHOR_TAG have shown that']","['tested on.', 'recently,  #TAUTHOR_TAG have shown that state - of - the - art nli systems break considerably easily']","['tested on.', 'recently,  #TAUTHOR_TAG have shown that']","['language inference ( nli ) has attracted considerable interest in the nlp community and, recently, a large number of neural network - based systems have been proposed to deal with the task.', 'these approaches can be usually categorized into : a ) sentence encoding models, and b ) other neural network models.', 'both of them have been very successful, with the state of the art on the snli and multinli datasets being 90. 1 %  #AUTHOR_TAG and 86. 7 %  #AUTHOR_TAG respectively.', 'however, a big question w. r. t to these systems is their ability to generalize outside the specific datasets they are trained and tested on.', 'recently,  #TAUTHOR_TAG have shown that state - of - the - art nli systems break considerably easily when instead of tested on the original snli test set, they are tested on a test set which preprint.', 'work in progress. is constructed by taking premises from the training set and creating several hypotheses from them by changing at most one word within the premise.', 'the results show a very significant drop in accuracy for three of the four systems.', 'the system that was more difficult to break and had the less loss in accuracy was the system by  #AUTHOR_TAG which utilizes external knowledge taken from wordnet  #AUTHOR_TAG.', 'in this paper we show that nli systems that have been very successful in specific nli benchmarks, fail to generalize when trained on a specific nli datset and then tested across different nli benchmarks.', 'the results we get are in line with  #TAUTHOR_TAG, breaks in the experiments we have conducted as well']",1
['has been raised in a recent paper by  #TAUTHOR_TAG'],['and related skepticism has been raised in a recent paper by  #TAUTHOR_TAG'],"['and related skepticism has been raised in a recent paper by  #TAUTHOR_TAG.', 'there, the authors show that the generalization capabilities of']","['ability of nli systems to generalize and related skepticism has been raised in a recent paper by  #TAUTHOR_TAG.', 'there, the authors show that the generalization capabilities of stateof - the - art nli systems, in cases where some kind of external lexical knowledge is needed, drops dramatically when the snli test set is replaced by a test set where the premise and the hypothesis are otherwise identical except for at most one word.', 'the results show a very significant drop in accuracy. recognize the generalization problem that comes with training on datasets like snli, which tend to be homogeneous with linguistic variation.', 'in this context, they propose to better train nli models by making use of adversarial examples.', ' #AUTHOR_TAG  #AUTHOR_TAG present an overview of the most standard datasets for nli and show that the definitions of inference in each of them are actually quite different']",1
"['tested on.', 'recently,  #TAUTHOR_TAG have shown that']","['tested on.', 'recently,  #TAUTHOR_TAG have shown that state - of - the - art nli systems break considerably easily']","['tested on.', 'recently,  #TAUTHOR_TAG have shown that']","['language inference ( nli ) has attracted considerable interest in the nlp community and, recently, a large number of neural network - based systems have been proposed to deal with the task.', 'these approaches can be usually categorized into : a ) sentence encoding models, and b ) other neural network models.', 'both of them have been very successful, with the state of the art on the snli and multinli datasets being 90. 1 %  #AUTHOR_TAG and 86. 7 %  #AUTHOR_TAG respectively.', 'however, a big question w. r. t to these systems is their ability to generalize outside the specific datasets they are trained and tested on.', 'recently,  #TAUTHOR_TAG have shown that state - of - the - art nli systems break considerably easily when instead of tested on the original snli test set, they are tested on a test set which preprint.', 'work in progress. is constructed by taking premises from the training set and creating several hypotheses from them by changing at most one word within the premise.', 'the results show a very significant drop in accuracy for three of the four systems.', 'the system that was more difficult to break and had the less loss in accuracy was the system by  #AUTHOR_TAG which utilizes external knowledge taken from wordnet  #AUTHOR_TAG.', 'in this paper we show that nli systems that have been very successful in specific nli benchmarks, fail to generalize when trained on a specific nli datset and then tested across different nli benchmarks.', 'the results we get are in line with  #TAUTHOR_TAG, breaks in the experiments we have conducted as well']",3
"['previous negative findings e. g. by  #TAUTHOR_TAG and  #AUTHOR_TAG, indicate that the current']","['previous negative findings e. g. by  #TAUTHOR_TAG and  #AUTHOR_TAG, indicate that the current state - of - the - art neural']","['the test and training data are splits from the same corpus.', 'our findings, together with the previous negative findings e. g. by  #TAUTHOR_TAG and  #AUTHOR_TAG, indicate that the current state - of - the - art neural network models']","['this paper we have shown that neural network models for nli fail to generalize across different nli benchmarks.', 'we experimented with five state - of - the - art models covering both sentence encoding approaches and cross - sentence attention models.', 'for all the systems, the accuracy drops between 7. 9 - 33. 7 points ( the average drop being 25. 4 points ), when testing with a test set drawn from a separate corpus from that of the training data, as compared to when the test and training data are splits from the same corpus.', 'our findings, together with the previous negative findings e. g. by  #TAUTHOR_TAG and  #AUTHOR_TAG, indicate that the current state - of - the - art neural network models fail to capture the semantics of nli in a way that will enable them to generalize across different nli situations.', 'the results indicate two issues to be taken into consideration : a ) using datasets involving a fraction of what nli is, will fail when tested in datasets that are testing for a slightly different definition.', 'this is evident when we move from the snli to the sick dataset.', 'b ) nli is to some extent also genre / context dependent.', 'training on snli and testing on multinli gives worse results than vice versa.', 'this can be seen as an indication that training on multiple genres helps.', 'however, this is still not enough given that, even in case of training on multinli and testing on snli, accuracy drops significantly.', 'further work is required on better data resources as well as on better neural network models to tackle these issues']",3
"['tested on.', 'recently,  #TAUTHOR_TAG have shown that']","['tested on.', 'recently,  #TAUTHOR_TAG have shown that state - of - the - art nli systems break considerably easily']","['tested on.', 'recently,  #TAUTHOR_TAG have shown that']","['language inference ( nli ) has attracted considerable interest in the nlp community and, recently, a large number of neural network - based systems have been proposed to deal with the task.', 'these approaches can be usually categorized into : a ) sentence encoding models, and b ) other neural network models.', 'both of them have been very successful, with the state of the art on the snli and multinli datasets being 90. 1 %  #AUTHOR_TAG and 86. 7 %  #AUTHOR_TAG respectively.', 'however, a big question w. r. t to these systems is their ability to generalize outside the specific datasets they are trained and tested on.', 'recently,  #TAUTHOR_TAG have shown that state - of - the - art nli systems break considerably easily when instead of tested on the original snli test set, they are tested on a test set which preprint.', 'work in progress. is constructed by taking premises from the training set and creating several hypotheses from them by changing at most one word within the premise.', 'the results show a very significant drop in accuracy for three of the four systems.', 'the system that was more difficult to break and had the less loss in accuracy was the system by  #AUTHOR_TAG which utilizes external knowledge taken from wordnet  #AUTHOR_TAG.', 'in this paper we show that nli systems that have been very successful in specific nli benchmarks, fail to generalize when trained on a specific nli datset and then tested across different nli benchmarks.', 'the results we get are in line with  #TAUTHOR_TAG, breaks in the experiments we have conducted as well']",4
"[""of  #TAUTHOR_TAG, utilizing external knowledge did not improve the model's generalization capability, as kim performed equally poorly across""]","[""of  #TAUTHOR_TAG, utilizing external knowledge did not improve the model's generalization capability, as kim performed equally poorly across""]","[""of  #TAUTHOR_TAG, utilizing external knowledge did not improve the model's generalization capability, as kim performed equally poorly across all dataset combinations."", 'also including a pretrained language model did not improve the results significantly']","['accuracy drops the most when a model is tested on sick.', 'the drop in this case is between 19. 0 - 28. 9 points when trained on multinli, between 31. 6 - 33. 7 points when trained on snli and between 31. 1 - 33. 0 when trained on snli + multinli.', 'this result was somewhat expected, as the method of constructing the sentence pairs was different, and therefore there is too much difference in the kind of sentence pairs between the training and test sets for the models to be able to transfer what it has learned to the test examples.', 'however, the drop in accuracy was not expected to be that dramatic.', 'the most surprising result was that the accuracy of all models drops significantly even in the set - up where the models were trained on multinli and tested on snli ( 7. 9 - 11. 1 points ).', 'this is surprising as both of these datasets have been constructed with a similar data collection method using the same definition of inference ( i. e. same definition of entailment, contradiction and neutral ).', 'the sentences included in snli are also much simpler compared to those in multinli.', 'this might also explain why the drop in accuracy for all of the four models is lowest when the models are trained on multinli and tested on snli.', 'it is also very surprising that the model with biggest drop in accuracy was esim + elmo which includes a pretrained elmo language model.', 'esim + elmo did, however, get the highest accuracy of 69. 1 % in this experiment.', 'all the models perform almost equally poorly across all the experiments.', 'both bilstm - max and hbmp have an average drop in accuracy of 24. 4 points, while the average for kim is 25. 5 and for esim + elmo 25. 6.', 'esim has the highest average drop of 27. 0 points.', ""in contrast to the findings of  #TAUTHOR_TAG, utilizing external knowledge did not improve the model's generalization capability, as kim performed equally poorly across all dataset combinations."", 'also including a pretrained language model did not improve the results significantly']",4
"['tested on.', 'recently,  #TAUTHOR_TAG have shown that']","['tested on.', 'recently,  #TAUTHOR_TAG have shown that state - of - the - art nli systems break considerably easily']","['tested on.', 'recently,  #TAUTHOR_TAG have shown that']","['language inference ( nli ) has attracted considerable interest in the nlp community and, recently, a large number of neural network - based systems have been proposed to deal with the task.', 'these approaches can be usually categorized into : a ) sentence encoding models, and b ) other neural network models.', 'both of them have been very successful, with the state of the art on the snli and multinli datasets being 90. 1 %  #AUTHOR_TAG and 86. 7 %  #AUTHOR_TAG respectively.', 'however, a big question w. r. t to these systems is their ability to generalize outside the specific datasets they are trained and tested on.', 'recently,  #TAUTHOR_TAG have shown that state - of - the - art nli systems break considerably easily when instead of tested on the original snli test set, they are tested on a test set which preprint.', 'work in progress. is constructed by taking premises from the training set and creating several hypotheses from them by changing at most one word within the premise.', 'the results show a very significant drop in accuracy for three of the four systems.', 'the system that was more difficult to break and had the less loss in accuracy was the system by  #AUTHOR_TAG which utilizes external knowledge taken from wordnet  #AUTHOR_TAG.', 'in this paper we show that nli systems that have been very successful in specific nli benchmarks, fail to generalize when trained on a specific nli datset and then tested across different nli benchmarks.', 'the results we get are in line with  #TAUTHOR_TAG, breaks in the experiments we have conducted as well']",6
['has been raised in a recent paper by  #TAUTHOR_TAG'],['and related skepticism has been raised in a recent paper by  #TAUTHOR_TAG'],"['and related skepticism has been raised in a recent paper by  #TAUTHOR_TAG.', 'there, the authors show that the generalization capabilities of']","['ability of nli systems to generalize and related skepticism has been raised in a recent paper by  #TAUTHOR_TAG.', 'there, the authors show that the generalization capabilities of stateof - the - art nli systems, in cases where some kind of external lexical knowledge is needed, drops dramatically when the snli test set is replaced by a test set where the premise and the hypothesis are otherwise identical except for at most one word.', 'the results show a very significant drop in accuracy. recognize the generalization problem that comes with training on datasets like snli, which tend to be homogeneous with linguistic variation.', 'in this context, they propose to better train nli models by making use of adversarial examples.', ' #AUTHOR_TAG  #AUTHOR_TAG present an overview of the most standard datasets for nli and show that the definitions of inference in each of them are actually quite different']",0
"['the other category respectively.', 'kim is particularly interesting in this context as it performed significantly better than other models in the breaking nli experiment conducted by  #TAUTHOR_TAG.', 'for bil']","['the other category respectively.', 'kim is particularly interesting in this context as it performed significantly better than other models in the breaking nli experiment conducted by  #TAUTHOR_TAG.', 'for bilstm - max we used the adam optimizer  #AUTHOR_TAG and a']","['the other category respectively.', 'kim is particularly interesting in this context as it performed significantly better than other models in the breaking nli experiment conducted by  #TAUTHOR_TAG.', 'for bil']","['', 'sentence attention and utilizes external knowledge.', 'we also selected one model involving a pretrained language model, namely esim + elmo.', 'all of the models perform well on the snli dataset, reaching near stateof - the - art accuracy in the sentence encoding and the other category respectively.', 'kim is particularly interesting in this context as it performed significantly better than other models in the breaking nli experiment conducted by  #TAUTHOR_TAG.', 'for bilstm - max we used the adam optimizer  #AUTHOR_TAG and a learning rate of 5e - 4.', '']",0
"['previous negative findings e. g. by  #TAUTHOR_TAG and  #AUTHOR_TAG, indicate that the current']","['previous negative findings e. g. by  #TAUTHOR_TAG and  #AUTHOR_TAG, indicate that the current state - of - the - art neural']","['the test and training data are splits from the same corpus.', 'our findings, together with the previous negative findings e. g. by  #TAUTHOR_TAG and  #AUTHOR_TAG, indicate that the current state - of - the - art neural network models']","['this paper we have shown that neural network models for nli fail to generalize across different nli benchmarks.', 'we experimented with five state - of - the - art models covering both sentence encoding approaches and cross - sentence attention models.', 'for all the systems, the accuracy drops between 7. 9 - 33. 7 points ( the average drop being 25. 4 points ), when testing with a test set drawn from a separate corpus from that of the training data, as compared to when the test and training data are splits from the same corpus.', 'our findings, together with the previous negative findings e. g. by  #TAUTHOR_TAG and  #AUTHOR_TAG, indicate that the current state - of - the - art neural network models fail to capture the semantics of nli in a way that will enable them to generalize across different nli situations.', 'the results indicate two issues to be taken into consideration : a ) using datasets involving a fraction of what nli is, will fail when tested in datasets that are testing for a slightly different definition.', 'this is evident when we move from the snli to the sick dataset.', 'b ) nli is to some extent also genre / context dependent.', 'training on snli and testing on multinli gives worse results than vice versa.', 'this can be seen as an indication that training on multiple genres helps.', 'however, this is still not enough given that, even in case of training on multinli and testing on snli, accuracy drops significantly.', 'further work is required on better data resources as well as on better neural network models to tackle these issues']",2
"[' #TAUTHOR_TAG.', 'this expansion consists of the addition of a new family of constraints']","[' #TAUTHOR_TAG.', 'this expansion consists of the addition of a new family of constraints - - existential implicational constraints, which allow']","['of primitive constraints available within the primitive optimality theory framework  #TAUTHOR_TAG.', 'this expansion consists of the addition of a new family of constraints']","['paper proposes an expansion of set of primitive constraints available within the primitive optimality theory framework  #TAUTHOR_TAG.', 'this expansion consists of the addition of a new family of constraints - - existential implicational constraints, which allow the specification of faithfulness constraints that can be satisfied at a distance - - and the definition of two ways to combine simple constraints into com : plex constraints, that is, constraint disjunction  #AUTHOR_TAG and local constraint conjunction  #AUTHOR_TAG']",5
"['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented and evaluated.', 'however, for certain types of constraints, translation into the primitives of otp (  #AUTHOR_TAG b ) ) can only be accomplished by adding to the grammar a number of ad hoc phonological tiers.', 'because these tiers serve no phonological purpose other than to allow calculation of the constraints without adding new primitives, and because the addition of phonological tiers to an otp grammar can have a dramatic negative impact on the efficiency of otp implementations 1, it is preferable to avoid the addition of ad hoc tiers by adding new primitives to the system.', 'this paper looks at three types of constraints employed throughout the optimality theoretic literature that cannot be translated in to the 1the computation time for an optimality theoretic derivation within the implementation of  #AUTHOR_TAG increases exponentially with the number of tiers.', 'the same is true for the implementation described in  #TAUTHOR_TAG, although a proposal is given there for a method that might improve the situation.', 'primitives of otp without reference to ad hoc tiers, and proposes a formalization of these constraints that is compatible with the finite state model described in  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'these are constraints of existential implication ( that is, of faithfulness without the requirement of alignment ), constraint disjunction, and local constraint conjunction.', '2 existential implication 2. 1 motivation owp as described in  #TAUTHOR_TAG provides some support for correspondence constraints ( input - output only ).', 'these may be defined by means of implication constraints of the form p - - 4 p or p - - + p, which can be interpreted as requiring, in the first case, that each surface constituent representing property p be aligned with an underlying constituent representing that property, and in the second case that every underlying constituent representing property p be aligned with a surface constituent representing that property.', 'constraints of this type may be employed to require correspondence between the underlying representation and the surface representation where corresponding constituents must be aligned with one another.', 'however, natural languages also seem to follow weaker constraints requiring only that for each underlying constituent there be a corresponding surface constituent, regardless of the position of that constituent relative to its position in the underlying representation.', 'for example, in sanskrit roots with at least two voiced stops, where the root ends in a voiced aspirated stop, the underlying aspiration of the root - final stop can be realized upon that stop in the surface representation only when the root is followed by a suffix beginning with a vocoid']",5
"['3j occurs.', 'using the fst notation of  #TAUTHOR_TAG, the implementation for this constraint would be']","['oq occurs, but no / 3j occurs.', 'using the fst notation of  #TAUTHOR_TAG, the implementation for this constraint would be']","['3j occurs.', 'using the fst notation of  #TAUTHOR_TAG, the implementation for this constraint would be the following fst :', '[ represents']","['implication constraints can be used to drive correspondence effects such as the above.', ""these constraints take represented by this notation outputs a violation for each domain 9,, where 9'represents the intersection of the domains 9, k, in which the time slice represented by the oq occurs, but no / 3j occurs."", 'using the fst notation of  #TAUTHOR_TAG, the implementation for this constraint would be the following fst :', '[ represents "" ( ( in or begin all 9, k ) - ( in all 9, k ) ), "" and ] represents "" ( ( in or end all 9, k ) - ( in all 9, k ) ). "" that is, the machine moves from state s to state 1 if the domain 9, is entered.', 'it moves from there back to state s if the end of the domain appears before cv does, or if any / 3 appears.', 'if a appears, the machine moves from state 1 to state 2.', 'from state 2, if / 3 appears, the machine returns to the start state without outputting a violation, but if the end of the domain appears without any / 3 having appeared, the machine outputs a violation']",5
"[' #TAUTHOR_TAG.', 'this expansion consists of the addition of a new family of constraints']","[' #TAUTHOR_TAG.', 'this expansion consists of the addition of a new family of constraints - - existential implicational constraints, which allow']","['of primitive constraints available within the primitive optimality theory framework  #TAUTHOR_TAG.', 'this expansion consists of the addition of a new family of constraints']","['paper proposes an expansion of set of primitive constraints available within the primitive optimality theory framework  #TAUTHOR_TAG.', 'this expansion consists of the addition of a new family of constraints - - existential implicational constraints, which allow the specification of faithfulness constraints that can be satisfied at a distance - - and the definition of two ways to combine simple constraints into com : plex constraints, that is, constraint disjunction  #AUTHOR_TAG and local constraint conjunction  #AUTHOR_TAG']",6
"['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented and evaluated.', 'however, for certain types of constraints, translation into the primitives of otp (  #AUTHOR_TAG b ) ) can only be accomplished by adding to the grammar a number of ad hoc phonological tiers.', 'because these tiers serve no phonological purpose other than to allow calculation of the constraints without adding new primitives, and because the addition of phonological tiers to an otp grammar can have a dramatic negative impact on the efficiency of otp implementations 1, it is preferable to avoid the addition of ad hoc tiers by adding new primitives to the system.', 'this paper looks at three types of constraints employed throughout the optimality theoretic literature that cannot be translated in to the 1the computation time for an optimality theoretic derivation within the implementation of  #AUTHOR_TAG increases exponentially with the number of tiers.', 'the same is true for the implementation described in  #TAUTHOR_TAG, although a proposal is given there for a method that might improve the situation.', 'primitives of otp without reference to ad hoc tiers, and proposes a formalization of these constraints that is compatible with the finite state model described in  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'these are constraints of existential implication ( that is, of faithfulness without the requirement of alignment ), constraint disjunction, and local constraint conjunction.', '2 existential implication 2. 1 motivation owp as described in  #TAUTHOR_TAG provides some support for correspondence constraints ( input - output only ).', 'these may be defined by means of implication constraints of the form p - - 4 p or p - - + p, which can be interpreted as requiring, in the first case, that each surface constituent representing property p be aligned with an underlying constituent representing that property, and in the second case that every underlying constituent representing property p be aligned with a surface constituent representing that property.', 'constraints of this type may be employed to require correspondence between the underlying representation and the surface representation where corresponding constituents must be aligned with one another.', 'however, natural languages also seem to follow weaker constraints requiring only that for each underlying constituent there be a corresponding surface constituent, regardless of the position of that constituent relative to its position in the underlying representation.', 'for example, in sanskrit roots with at least two voiced stops, where the root ends in a voiced aspirated stop, the underlying aspiration of the root - final stop can be realized upon that stop in the surface representation only when the root is followed by a suffix beginning with a vocoid']",0
"['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented and evaluated.', 'however, for certain types of constraints, translation into the primitives of otp (  #AUTHOR_TAG b ) ) can only be accomplished by adding to the grammar a number of ad hoc phonological tiers.', 'because these tiers serve no phonological purpose other than to allow calculation of the constraints without adding new primitives, and because the addition of phonological tiers to an otp grammar can have a dramatic negative impact on the efficiency of otp implementations 1, it is preferable to avoid the addition of ad hoc tiers by adding new primitives to the system.', 'this paper looks at three types of constraints employed throughout the optimality theoretic literature that cannot be translated in to the 1the computation time for an optimality theoretic derivation within the implementation of  #AUTHOR_TAG increases exponentially with the number of tiers.', 'the same is true for the implementation described in  #TAUTHOR_TAG, although a proposal is given there for a method that might improve the situation.', 'primitives of otp without reference to ad hoc tiers, and proposes a formalization of these constraints that is compatible with the finite state model described in  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'these are constraints of existential implication ( that is, of faithfulness without the requirement of alignment ), constraint disjunction, and local constraint conjunction.', '2 existential implication 2. 1 motivation owp as described in  #TAUTHOR_TAG provides some support for correspondence constraints ( input - output only ).', 'these may be defined by means of implication constraints of the form p - - 4 p or p - - + p, which can be interpreted as requiring, in the first case, that each surface constituent representing property p be aligned with an underlying constituent representing that property, and in the second case that every underlying constituent representing property p be aligned with a surface constituent representing that property.', 'constraints of this type may be employed to require correspondence between the underlying representation and the surface representation where corresponding constituents must be aligned with one another.', 'however, natural languages also seem to follow weaker constraints requiring only that for each underlying constituent there be a corresponding surface constituent, regardless of the position of that constituent relative to its position in the underlying representation.', 'for example, in sanskrit roots with at least two voiced stops, where the root ends in a voiced aspirated stop, the underlying aspiration of the root - final stop can be realized upon that stop in the surface representation only when the root is followed by a suffix beginning with a vocoid']",0
"['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented and evaluated.', 'however, for certain types of constraints, translation into the primitives of otp (  #AUTHOR_TAG b ) ) can only be accomplished by adding to the grammar a number of ad hoc phonological tiers.', 'because these tiers serve no phonological purpose other than to allow calculation of the constraints without adding new primitives, and because the addition of phonological tiers to an otp grammar can have a dramatic negative impact on the efficiency of otp implementations 1, it is preferable to avoid the addition of ad hoc tiers by adding new primitives to the system.', 'this paper looks at three types of constraints employed throughout the optimality theoretic literature that cannot be translated in to the 1the computation time for an optimality theoretic derivation within the implementation of  #AUTHOR_TAG increases exponentially with the number of tiers.', 'the same is true for the implementation described in  #TAUTHOR_TAG, although a proposal is given there for a method that might improve the situation.', 'primitives of otp without reference to ad hoc tiers, and proposes a formalization of these constraints that is compatible with the finite state model described in  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'these are constraints of existential implication ( that is, of faithfulness without the requirement of alignment ), constraint disjunction, and local constraint conjunction.', '2 existential implication 2. 1 motivation owp as described in  #TAUTHOR_TAG provides some support for correspondence constraints ( input - output only ).', 'these may be defined by means of implication constraints of the form p - - 4 p or p - - + p, which can be interpreted as requiring, in the first case, that each surface constituent representing property p be aligned with an underlying constituent representing that property, and in the second case that every underlying constituent representing property p be aligned with a surface constituent representing that property.', 'constraints of this type may be employed to require correspondence between the underlying representation and the surface representation where corresponding constituents must be aligned with one another.', 'however, natural languages also seem to follow weaker constraints requiring only that for each underlying constituent there be a corresponding surface constituent, regardless of the position of that constituent relative to its position in the underlying representation.', 'for example, in sanskrit roots with at least two voiced stops, where the root ends in a voiced aspirated stop, the underlying aspiration of the root - final stop can be realized upon that stop in the surface representation only when the root is followed by a suffix beginning with a vocoid']",0
"['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented and evaluated.', 'however, for certain types of constraints, translation into the primitives of otp (  #AUTHOR_TAG b ) ) can only be accomplished by adding to the grammar a number of ad hoc phonological tiers.', 'because these tiers serve no phonological purpose other than to allow calculation of the constraints without adding new primitives, and because the addition of phonological tiers to an otp grammar can have a dramatic negative impact on the efficiency of otp implementations 1, it is preferable to avoid the addition of ad hoc tiers by adding new primitives to the system.', 'this paper looks at three types of constraints employed throughout the optimality theoretic literature that cannot be translated in to the 1the computation time for an optimality theoretic derivation within the implementation of  #AUTHOR_TAG increases exponentially with the number of tiers.', 'the same is true for the implementation described in  #TAUTHOR_TAG, although a proposal is given there for a method that might improve the situation.', 'primitives of otp without reference to ad hoc tiers, and proposes a formalization of these constraints that is compatible with the finite state model described in  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'these are constraints of existential implication ( that is, of faithfulness without the requirement of alignment ), constraint disjunction, and local constraint conjunction.', '2 existential implication 2. 1 motivation owp as described in  #TAUTHOR_TAG provides some support for correspondence constraints ( input - output only ).', 'these may be defined by means of implication constraints of the form p - - 4 p or p - - + p, which can be interpreted as requiring, in the first case, that each surface constituent representing property p be aligned with an underlying constituent representing that property, and in the second case that every underlying constituent representing property p be aligned with a surface constituent representing that property.', 'constraints of this type may be employed to require correspondence between the underlying representation and the surface representation where corresponding constituents must be aligned with one another.', 'however, natural languages also seem to follow weaker constraints requiring only that for each underlying constituent there be a corresponding surface constituent, regardless of the position of that constituent relative to its position in the underlying representation.', 'for example, in sanskrit roots with at least two voiced stops, where the root ends in a voiced aspirated stop, the underlying aspiration of the root - final stop can be realized upon that stop in the surface representation only when the root is followed by a suffix beginning with a vocoid']",1
"['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ),']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented']","['optimality theory ( otp )  #TAUTHOR_TAG, and extensions to it ( e. g.,  #AUTHOR_TAG ), can be useful as a formal system in which phonological analyses can be implemented and evaluated.', 'however, for certain types of constraints, translation into the primitives of otp (  #AUTHOR_TAG b ) ) can only be accomplished by adding to the grammar a number of ad hoc phonological tiers.', 'because these tiers serve no phonological purpose other than to allow calculation of the constraints without adding new primitives, and because the addition of phonological tiers to an otp grammar can have a dramatic negative impact on the efficiency of otp implementations 1, it is preferable to avoid the addition of ad hoc tiers by adding new primitives to the system.', 'this paper looks at three types of constraints employed throughout the optimality theoretic literature that cannot be translated in to the 1the computation time for an optimality theoretic derivation within the implementation of  #AUTHOR_TAG increases exponentially with the number of tiers.', 'the same is true for the implementation described in  #TAUTHOR_TAG, although a proposal is given there for a method that might improve the situation.', 'primitives of otp without reference to ad hoc tiers, and proposes a formalization of these constraints that is compatible with the finite state model described in  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'these are constraints of existential implication ( that is, of faithfulness without the requirement of alignment ), constraint disjunction, and local constraint conjunction.', '2 existential implication 2. 1 motivation owp as described in  #TAUTHOR_TAG provides some support for correspondence constraints ( input - output only ).', 'these may be defined by means of implication constraints of the form p - - 4 p or p - - + p, which can be interpreted as requiring, in the first case, that each surface constituent representing property p be aligned with an underlying constituent representing that property, and in the second case that every underlying constituent representing property p be aligned with a surface constituent representing that property.', 'constraints of this type may be employed to require correspondence between the underlying representation and the surface representation where corresponding constituents must be aligned with one another.', 'however, natural languages also seem to follow weaker constraints requiring only that for each underlying constituent there be a corresponding surface constituent, regardless of the position of that constituent relative to its position in the underlying representation.', 'for example, in sanskrit roots with at least two voiced stops, where the root ends in a voiced aspirated stop, the underlying aspiration of the root - final stop can be realized upon that stop in the surface representation only when the root is followed by a suffix beginning with a vocoid']",1
"[', instead of examining one pair of entities at a time ( see  #TAUTHOR_TAG, and ( iii )']","['once, instead of examining one pair of entities at a time ( see  #TAUTHOR_TAG, and ( iii )']","[', instead of examining one pair of entities at a time ( see  #TAUTHOR_TAG, and ( iii ) we model']","['', 'previously proposed models ( summarized in section 2 ) exhibit several issues that the neural network - based baseline approach ( detailed in section 3. 1 ) overcomes : ( i ) our model uses automatically extracted features without the need of external parsers nor manually extracted features ( see  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG ), ( ii ) all entities and the corresponding relations within the sentence are extracted at once, instead of examining one pair of entities at a time ( see  #TAUTHOR_TAG, and ( iii ) we model relation extraction in a multi - label setting, allowing multiple relations per entity ( see  #AUTHOR_TAG ;  #AUTHOR_TAG a ) ).', 'the core contribution of the paper is the use of at as an extension in the training procedure for the joint extraction task ( section 3. 2 ).', 'to evaluate the proposed at method, we perform a large scale experimental study in this joint task ( see section 4 ), using datasets from different contexts ( i. e., news, biomedical, real estate ) and languages ( i. e., english, dutch ).', 'we use a strong baseline that outperforms all previous models that rely on automatically extracted features, achieving state - of - the - art performance ( section 5 ).', 'compared to the baseline model, applying at during training leads to a consistent additional increase in joint extraction effectiveness']",4
"['along with rnns.', ' #TAUTHOR_TAG']","['along with rnns.', ' #TAUTHOR_TAG']","['various manually extracted features along with rnns.', ' #TAUTHOR_TAG']","['', 'these methods rely on the availability of nlp tools ( e. g., pos taggers ) or manually designed features leading to additional complexity.', 'neural network methods have been exploited to overcome this feature design issue and usually involve rnns and cnns  #AUTHOR_TAG.', ' #AUTHOR_TAG as well as  #AUTHOR_TAG apply bidirectional tree - structured rnns for different contexts ( i. e., news, biomedical ) to capture syntactic information ( using external dependency parsers ).', ' #AUTHOR_TAG propose the use of various manually extracted features along with rnns.', ' #TAUTHOR_TAG solve the simpler problem of entity classification ( ec, assuming entity boundaries are given ), instead of ner, and they replicate the context around the entities, feeding entity pairs to the relation extraction layer.', ' #AUTHOR_TAG investigate rnns with attention without taking into account that relation labels are not mutually exclusive.', ' #AUTHOR_TAG a ) use lstms in a joint model for extracting just one relation at a time, but increase the complexity of the ner part.', '']",0
"['##04 dataset, we use two evaluation settings. we use the relaxed evaluation similar to  #AUTHOR_TAG ;  #TAUTHOR_TAG on']","['##04 dataset, we use two evaluation settings. we use the relaxed evaluation similar to  #AUTHOR_TAG ;  #TAUTHOR_TAG on']","['overall improvement. this indicates that nlp tools are not always accurate for various contexts.', 'for the conll04 dataset, we use two evaluation settings. we use the relaxed evaluation similar to  #AUTHOR_TAG ;  #TAUTHOR_TAG on the', 'ec']","['', 'report a 2. 5 % overall improvement. this indicates that nlp tools are not always accurate for various contexts.', 'for the conll04 dataset, we use two evaluation settings. we use the relaxed evaluation similar to  #AUTHOR_TAG ;  #TAUTHOR_TAG on the', '']",5
"['##04 dataset, we use two evaluation settings. we use the relaxed evaluation similar to  #AUTHOR_TAG ;  #TAUTHOR_TAG on']","['##04 dataset, we use two evaluation settings. we use the relaxed evaluation similar to  #AUTHOR_TAG ;  #TAUTHOR_TAG on']","['overall improvement. this indicates that nlp tools are not always accurate for various contexts.', 'for the conll04 dataset, we use two evaluation settings. we use the relaxed evaluation similar to  #AUTHOR_TAG ;  #TAUTHOR_TAG on the', 'ec']","['', 'report a 2. 5 % overall improvement. this indicates that nlp tools are not always accurate for various contexts.', 'for the conll04 dataset, we use two evaluation settings. we use the relaxed evaluation similar to  #AUTHOR_TAG ;  #TAUTHOR_TAG on the', '']",3
"['12 ].', 'furthermore, the wta principle is applied in several studies [ 13, 14,  #TAUTHOR_TAG for increase activation sparseness in neural networks.', 'the simplest way to implement the wta mechanism is to organize neurons into groups or clusters,']","['mechanism which has shown high biological plausibility [ 12 ].', 'furthermore, the wta principle is applied in several studies [ 13, 14,  #TAUTHOR_TAG for increase activation sparseness in neural networks.', 'the simplest way to implement the wta mechanism is to organize neurons into groups or clusters,']","[') mechanism which has shown high biological plausibility [ 12 ].', 'furthermore, the wta principle is applied in several studies [ 13, 14,  #TAUTHOR_TAG for increase activation sparseness in neural networks.', 'the simplest way to implement the wta mechanism is to organize neurons into groups or clusters,']","[', large pretrained lms such as elmo [ 1 ] or bert [ 2 ] on large corpora achieved state - of - theart performance on several downstream tasks in nlp.', 'these models are trained to predict the next word given a sequence of words or a masked word given it surrounding words in the same sentence.', 'these architectures are capable to incorporate into latent distributed representations the contextual information from different timescales.', 'from the biological point of view, there are strong evidences that hierarchical cortical structures implement a similar mechanism, where the spatiotemporal pattern completion process is done recursively in order to extract the relevant information [ 3, 4 ].', 'when it comes to performing wsd, literature indicates several supervised techniques, where different types of classifiers can learn based on annotated datasets.', 'a particularly interesting approach to address this task is the cognitive one, where the phenomenon of wsd is treated by modeling the cognitive process through act ( adaptive control of thought ) [ 5 ] combined with race / a ( retrieval by accumulating evidence in an architecture ) [ 6 ], and such a modeling allows the outperforming of many systems for the task at hand [ 7 ].', 'the ideas that are presented in this paper with a particular application to contextual word representations are inspired by recent studies about physicochemical properties of the brain.', 'as explained in [ 8 ], the brain is a very noisy medium.', 'more precisely, according to [ 9 ] and [ 10 ] respectively, neurons are subject to high erasure effects on their inputs ( neurotransmitters are temporarily unavailable in a synapse to respond properly to an incoming spike ) and are also the source of numerous spurious ( non stimulated ) spikes.', 'because of this fluctuating behaviour it is difficult to accept that mental pieces of information could be borne by precise levels of neuronal activity.', 'a way to overcome noise and inconstancies is to make information be expressed by assemblies of neurons instead of individual neurons.', 'associative memories can be regarded as a good means to store pieces of information with high robustness towards erasures [ 3 ].', 'a strategy to combat uncertainty about neuronal activity is to materialize information by relative values instead of absolute ones.', 'for instance, this is the way that sparse associative memories based on neural cliques [ 11 ] are recovered through the winner - takes - all ( wta ) mechanism which has shown high biological plausibility [ 12 ].', 'furthermore, the wta principle is applied in several studies [ 13, 14,  #TAUTHOR_TAG for increase activation sparseness in neural networks.', 'the simplest way to implement the wta mechanism is to organize neurons into groups or clusters,']",0
"['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['from the biological perspective, by the comprehension of brain access schemes, it can be infered that the combination of binary synaptic weights, sparsely encoded memory patterns and local learning rules is one way of producing good representation [ 17, 18 ].', 'and as fast information retrieval remains a critical point to the real world applications, such a method proves again its power as the computation made is basically a vector - matrix product ( in the binary case this can still be considered just counting ), followed by an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in order to mitigate such an issue,  #TAUTHOR_TAG proposed a method that learns multi - codebook.', 'therefore, each word is now represented by a hash code of discrete numbers, that have to be defined in a way that similar words will have similar representations as well as a factor of difference, to capture nuances.', 'presenting a different use for the previous work done by the field of codebooks compression based source coding, known as product quantization ( pq ) [ 21 ] and additive quantization [ 22 ], they show that by minimizing the squared distance between both distributions ( baseline and composed embeddings ), and using a direct learning approach for the codes in an end - to - end neural network, with a gumbel - softmax layer [ 23 ] to encourage the discreteness  #TAUTHOR_TAG, it is possible to construct the word embeddings radically reducing the number of parameters without hurting performance.', 'these word codebooks are learned using a local wta rule in the hidden layer of an autoencoder neural network.', 'other works have also focused in accomplishing the task of modeling complex characteristics of word use, and its variations across different contexts.', '[ 1 ] presented a new type of word representation, where word vectors are learned functions of the internal states of a deep bidirectional language model ( bilm ), which is pretrained on a large text corpus [ 1 ].', 'all those aspects allow richer word representations, and also the capture of important context dependant aspects.', 'and as the computation is made based on the internal states of the baseline architecture, such approach can be easily integrated to existing models.', ""results have shown elmo's capacity to boost performance in many nlp tasks, including wsd, using the approach of the 1 - nearest neighbor, similarly to [ 24 ] and accordingly to the framework of evaluation from [ 25 ]."", 'as stated above, when the vocabulary is limited, the problem of compressing word embedding representations by contextual compositional']",0
"['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['from the biological perspective, by the comprehension of brain access schemes, it can be infered that the combination of binary synaptic weights, sparsely encoded memory patterns and local learning rules is one way of producing good representation [ 17, 18 ].', 'and as fast information retrieval remains a critical point to the real world applications, such a method proves again its power as the computation made is basically a vector - matrix product ( in the binary case this can still be considered just counting ), followed by an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in order to mitigate such an issue,  #TAUTHOR_TAG proposed a method that learns multi - codebook.', 'therefore, each word is now represented by a hash code of discrete numbers, that have to be defined in a way that similar words will have similar representations as well as a factor of difference, to capture nuances.', 'presenting a different use for the previous work done by the field of codebooks compression based source coding, known as product quantization ( pq ) [ 21 ] and additive quantization [ 22 ], they show that by minimizing the squared distance between both distributions ( baseline and composed embeddings ), and using a direct learning approach for the codes in an end - to - end neural network, with a gumbel - softmax layer [ 23 ] to encourage the discreteness  #TAUTHOR_TAG, it is possible to construct the word embeddings radically reducing the number of parameters without hurting performance.', 'these word codebooks are learned using a local wta rule in the hidden layer of an autoencoder neural network.', 'other works have also focused in accomplishing the task of modeling complex characteristics of word use, and its variations across different contexts.', '[ 1 ] presented a new type of word representation, where word vectors are learned functions of the internal states of a deep bidirectional language model ( bilm ), which is pretrained on a large text corpus [ 1 ].', 'all those aspects allow richer word representations, and also the capture of important context dependant aspects.', 'and as the computation is made based on the internal states of the baseline architecture, such approach can be easily integrated to existing models.', ""results have shown elmo's capacity to boost performance in many nlp tasks, including wsd, using the approach of the 1 - nearest neighbor, similarly to [ 24 ] and accordingly to the framework of evaluation from [ 25 ]."", 'as stated above, when the vocabulary is limited, the problem of compressing word embedding representations by contextual compositional']",0
"['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['from the biological perspective, by the comprehension of brain access schemes, it can be infered that the combination of binary synaptic weights, sparsely encoded memory patterns and local learning rules is one way of producing good representation [ 17, 18 ].', 'and as fast information retrieval remains a critical point to the real world applications, such a method proves again its power as the computation made is basically a vector - matrix product ( in the binary case this can still be considered just counting ), followed by an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in order to mitigate such an issue,  #TAUTHOR_TAG proposed a method that learns multi - codebook.', 'therefore, each word is now represented by a hash code of discrete numbers, that have to be defined in a way that similar words will have similar representations as well as a factor of difference, to capture nuances.', 'presenting a different use for the previous work done by the field of codebooks compression based source coding, known as product quantization ( pq ) [ 21 ] and additive quantization [ 22 ], they show that by minimizing the squared distance between both distributions ( baseline and composed embeddings ), and using a direct learning approach for the codes in an end - to - end neural network, with a gumbel - softmax layer [ 23 ] to encourage the discreteness  #TAUTHOR_TAG, it is possible to construct the word embeddings radically reducing the number of parameters without hurting performance.', 'these word codebooks are learned using a local wta rule in the hidden layer of an autoencoder neural network.', 'other works have also focused in accomplishing the task of modeling complex characteristics of word use, and its variations across different contexts.', '[ 1 ] presented a new type of word representation, where word vectors are learned functions of the internal states of a deep bidirectional language model ( bilm ), which is pretrained on a large text corpus [ 1 ].', 'all those aspects allow richer word representations, and also the capture of important context dependant aspects.', 'and as the computation is made based on the internal states of the baseline architecture, such approach can be easily integrated to existing models.', ""results have shown elmo's capacity to boost performance in many nlp tasks, including wsd, using the approach of the 1 - nearest neighbor, similarly to [ 24 ] and accordingly to the framework of evaluation from [ 25 ]."", 'as stated above, when the vocabulary is limited, the problem of compressing word embedding representations by contextual compositional']",0
"['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['from the biological perspective, by the comprehension of brain access schemes, it can be infered that the combination of binary synaptic weights, sparsely encoded memory patterns and local learning rules is one way of producing good representation [ 17, 18 ].', 'and as fast information retrieval remains a critical point to the real world applications, such a method proves again its power as the computation made is basically a vector - matrix product ( in the binary case this can still be considered just counting ), followed by an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in order to mitigate such an issue,  #TAUTHOR_TAG proposed a method that learns multi - codebook.', 'therefore, each word is now represented by a hash code of discrete numbers, that have to be defined in a way that similar words will have similar representations as well as a factor of difference, to capture nuances.', 'presenting a different use for the previous work done by the field of codebooks compression based source coding, known as product quantization ( pq ) [ 21 ] and additive quantization [ 22 ], they show that by minimizing the squared distance between both distributions ( baseline and composed embeddings ), and using a direct learning approach for the codes in an end - to - end neural network, with a gumbel - softmax layer [ 23 ] to encourage the discreteness  #TAUTHOR_TAG, it is possible to construct the word embeddings radically reducing the number of parameters without hurting performance.', 'these word codebooks are learned using a local wta rule in the hidden layer of an autoencoder neural network.', 'other works have also focused in accomplishing the task of modeling complex characteristics of word use, and its variations across different contexts.', '[ 1 ] presented a new type of word representation, where word vectors are learned functions of the internal states of a deep bidirectional language model ( bilm ), which is pretrained on a large text corpus [ 1 ].', 'all those aspects allow richer word representations, and also the capture of important context dependant aspects.', 'and as the computation is made based on the internal states of the baseline architecture, such approach can be easily integrated to existing models.', ""results have shown elmo's capacity to boost performance in many nlp tasks, including wsd, using the approach of the 1 - nearest neighbor, similarly to [ 24 ] and accordingly to the framework of evaluation from [ 25 ]."", 'as stated above, when the vocabulary is limited, the problem of compressing word embedding representations by contextual compositional']",1
"['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in']","['from the biological perspective, by the comprehension of brain access schemes, it can be infered that the combination of binary synaptic weights, sparsely encoded memory patterns and local learning rules is one way of producing good representation [ 17, 18 ].', 'and as fast information retrieval remains a critical point to the real world applications, such a method proves again its power as the computation made is basically a vector - matrix product ( in the binary case this can still be considered just counting ), followed by an operation of threshold [ 19 ].', 'recent work has started to address as well the problematic of memory footprint when learning word embeddings [ 20,  #TAUTHOR_TAG.', 'in order to mitigate such an issue,  #TAUTHOR_TAG proposed a method that learns multi - codebook.', 'therefore, each word is now represented by a hash code of discrete numbers, that have to be defined in a way that similar words will have similar representations as well as a factor of difference, to capture nuances.', 'presenting a different use for the previous work done by the field of codebooks compression based source coding, known as product quantization ( pq ) [ 21 ] and additive quantization [ 22 ], they show that by minimizing the squared distance between both distributions ( baseline and composed embeddings ), and using a direct learning approach for the codes in an end - to - end neural network, with a gumbel - softmax layer [ 23 ] to encourage the discreteness  #TAUTHOR_TAG, it is possible to construct the word embeddings radically reducing the number of parameters without hurting performance.', 'these word codebooks are learned using a local wta rule in the hidden layer of an autoencoder neural network.', 'other works have also focused in accomplishing the task of modeling complex characteristics of word use, and its variations across different contexts.', '[ 1 ] presented a new type of word representation, where word vectors are learned functions of the internal states of a deep bidirectional language model ( bilm ), which is pretrained on a large text corpus [ 1 ].', 'all those aspects allow richer word representations, and also the capture of important context dependant aspects.', 'and as the computation is made based on the internal states of the baseline architecture, such approach can be easily integrated to existing models.', ""results have shown elmo's capacity to boost performance in many nlp tasks, including wsd, using the approach of the 1 - nearest neighbor, similarly to [ 24 ] and accordingly to the framework of evaluation from [ 25 ]."", 'as stated above, when the vocabulary is limited, the problem of compressing word embedding representations by contextual compositional']",2
"['as  #TAUTHOR_TAG, as shown in']","['as  #TAUTHOR_TAG, as shown in fig. 2.', 'the third step relies on sparse']","['as  #TAUTHOR_TAG, as shown in']","['proposed method is divided into three different steps.', 'in the first step, the features corresponding to the ambiguous word are extracted from the second layer of the elmo model as pictured in fig. 1.', 'experimental results from [ 1 ] indicate that performing such extraction on the last layer of the lm ( concatenating the representations from both directions ) increase performance in comparison with doing it on the first one.', 'for the case of composed words ( i. e. mother - in - law ), the average embedding is taken, in order to create a more robust representation.', 'in the second step, a deep autoencoder neural network model is optimized to reduce the mean squared error of reconstructed contextual features extracted from first step.', 'this model implements the gumbel softmax reparametrization function [ 23 ] to obtain discrete activations in the last intermediate layer.', 'for the sake of simplicity, we adopted the same architecture as  #TAUTHOR_TAG, as shown in fig. 2.', 'the third step relies on sparse associative memories ( sam ), neural networks able to store and retrieve sparse patterns from incomplete inputs.', ""our choice to this technique comes from the fact the sparse projections produced by sam's have been shown to be sufficient to uniquely encode a neural pattern [ 26 ]."", 'the connections in sparse associative memories are completely binary ( they either exist or not ).', 'at the beginning of training procedure, the graph that models the sam is initialized without any connection.', '']",5
['is an extension of  #TAUTHOR_TAG'],['is an extension of  #TAUTHOR_TAG'],"['is an extension of  #TAUTHOR_TAG work to deal with latent representations of contextual pretrained lm.', 'for future work, we intend to explore other lm recent architectures such as bert [ 2 ], and also aggregate information from knowledge - based corpus such']","['have presented a technique of transfer learning of contextual lm representations based on neuroinspired sparse binary associative memories.', 'we have confirmed by our results that such a framework can dramatically mitigate the memory footprint problem and enhance the interpretability while it is still capable of increasing performance in the focused task, wsd.', 'our framework is an extension of  #TAUTHOR_TAG work to deal with latent representations of contextual pretrained lm.', 'for future work, we intend to explore other lm recent architectures such as bert [ 2 ], and also aggregate information from knowledge - based corpus such as wordnet [ 29 ]']",6
"['', 'for instance, both  #AUTHOR_TAG and  #TAUTHOR_TAG propose']","['also come with the benefit of not requiring difficult feature engineering.', 'for instance, both  #AUTHOR_TAG and  #TAUTHOR_TAG propose']","['also come with the benefit of not requiring difficult feature engineering.', 'for instance, both  #AUTHOR_TAG and  #TAUTHOR_TAG propose']","['neural networks have been proven to be a powerful framework for natural language processing, and have demonstrated strong performance on a number of challenging tasks, ranging from machine translation  #AUTHOR_TAG b, a ), to text categorisation  #AUTHOR_TAG b ).', 'not only do such deep models outperform traditional machine learning methods, they also come with the benefit of not requiring difficult feature engineering.', 'for instance, both  #AUTHOR_TAG and  #TAUTHOR_TAG propose end - to - end models for sequence labelling task and achieve state - of - the - art results.', '']",0
"['', 'for instance, both  #AUTHOR_TAG and  #TAUTHOR_TAG propose']","['also come with the benefit of not requiring difficult feature engineering.', 'for instance, both  #AUTHOR_TAG and  #TAUTHOR_TAG propose']","['also come with the benefit of not requiring difficult feature engineering.', 'for instance, both  #AUTHOR_TAG and  #TAUTHOR_TAG propose']","['neural networks have been proven to be a powerful framework for natural language processing, and have demonstrated strong performance on a number of challenging tasks, ranging from machine translation  #AUTHOR_TAG b, a ), to text categorisation  #AUTHOR_TAG b ).', 'not only do such deep models outperform traditional machine learning methods, they also come with the benefit of not requiring difficult feature engineering.', 'for instance, both  #AUTHOR_TAG and  #TAUTHOR_TAG propose end - to - end models for sequence labelling task and achieve state - of - the - art results.', '']",0
"['cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is capable of tagging each input with a predicted labely, resulting in a sequence ofy = { y 1, y 2,..., y t } closely matching the gold label sequence y = { y 1, y 2,..., y t }.', 'here, we extend the model by incorporating an auto - encoder loss taking hand - crafted features as in / output, thereby forcing the model to preserve crucial information stored in such features and allowing us to evaluate the impacts of each feature on model performance.', 'specifically, our model, referred to as neural - crf + ae, consists of four major components : ( 1 ) a character - level cnn ( char - cnn ) ; ( 2 ) a word - level bi - directional lstm ( bi - lstm ) ; ( 3 ) a conditional random field ( crf ) ; and ( 4 ) an auto - encoder auxiliary loss.', 'an illustration of the model architecture is presented in figure 1.', ' #TAUTHOR_TAG have demonstrated that cnns are highly capable of capturing character - level features.', 'here, our character - level cnn is similar to that used in  #TAUTHOR_TAG but differs in that we use a relu activation  #AUTHOR_TAG.', '']",0
"['cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is capable of tagging each input with a predicted labely, resulting in a sequence ofy = { y 1, y 2,..., y t } closely matching the gold label sequence y = { y 1, y 2,..., y t }.', 'here, we extend the model by incorporating an auto - encoder loss taking hand - crafted features as in / output, thereby forcing the model to preserve crucial information stored in such features and allowing us to evaluate the impacts of each feature on model performance.', 'specifically, our model, referred to as neural - crf + ae, consists of four major components : ( 1 ) a character - level cnn ( char - cnn ) ; ( 2 ) a word - level bi - directional lstm ( bi - lstm ) ; ( 3 ) a conditional random field ( crf ) ; and ( 4 ) an auto - encoder auxiliary loss.', 'an illustration of the model architecture is presented in figure 1.', ' #TAUTHOR_TAG have demonstrated that cnns are highly capable of capturing character - level features.', 'here, our character - level cnn is similar to that used in  #TAUTHOR_TAG but differs in that we use a relu activation  #AUTHOR_TAG.', '']",3
"['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['##s news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional,']","['.', 'we use the conll 2003 ner shared task dataset, consisting of 14, 041 / 3, 250 / 3, 453 sentences in the training / development / test set respectively, all extracted from reuters news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional, trained on a 6b - token corpus ).', 'character embeddings are 30 - dimensional and randomly initialised with a uniform distribution in', 'parameters are optimised with stochastic gradient descent ( sgd ) with an initial learning rate of η = 0. 015 and momentum of 0. 9.', 'exponential learning rate decay is applied every 5 epochs with a factor of 0. 8.', 'to reduce the impact of exploding gradients, we employ gradient clipping at 5. 0  #AUTHOR_TAG.', 'we train our models on a single geforce gtx titan x gpu.', 'with the above hyper - parameter setting, training takes approximately 8 hours for a full run of 40 epochs.', 'evaluation.', 'we measure model performance with the official conll evaluation script and report span - level named entity f - score on the test set using early stopping based on the performance on the validation set.', 'we report average f - scores and standard deviation over 5 runs for our model.', 'baseline.', 'in addition to reporting a number of prior results of competitive baseline models, as listed in table 2, we also re - implement the bi - lstm - cnn - crf model by  #TAUTHOR_TAG ( referred to as neural - crf in table 2 ) and report its average performance']",3
"['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['##s news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional,']","['.', 'we use the conll 2003 ner shared task dataset, consisting of 14, 041 / 3, 250 / 3, 453 sentences in the training / development / test set respectively, all extracted from reuters news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional, trained on a 6b - token corpus ).', 'character embeddings are 30 - dimensional and randomly initialised with a uniform distribution in', 'parameters are optimised with stochastic gradient descent ( sgd ) with an initial learning rate of η = 0. 015 and momentum of 0. 9.', 'exponential learning rate decay is applied every 5 epochs with a factor of 0. 8.', 'to reduce the impact of exploding gradients, we employ gradient clipping at 5. 0  #AUTHOR_TAG.', 'we train our models on a single geforce gtx titan x gpu.', 'with the above hyper - parameter setting, training takes approximately 8 hours for a full run of 40 epochs.', 'evaluation.', 'we measure model performance with the official conll evaluation script and report span - level named entity f - score on the test set using early stopping based on the performance on the validation set.', 'we report average f - scores and standard deviation over 5 runs for our model.', 'baseline.', 'in addition to reporting a number of prior results of competitive baseline models, as listed in table 2, we also re - implement the bi - lstm - cnn - crf model by  #TAUTHOR_TAG ( referred to as neural - crf in table 2 ) and report its average performance']",3
"['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['##s news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional,']","['.', 'we use the conll 2003 ner shared task dataset, consisting of 14, 041 / 3, 250 / 3, 453 sentences in the training / development / test set respectively, all extracted from reuters news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional, trained on a 6b - token corpus ).', 'character embeddings are 30 - dimensional and randomly initialised with a uniform distribution in', 'parameters are optimised with stochastic gradient descent ( sgd ) with an initial learning rate of η = 0. 015 and momentum of 0. 9.', 'exponential learning rate decay is applied every 5 epochs with a factor of 0. 8.', 'to reduce the impact of exploding gradients, we employ gradient clipping at 5. 0  #AUTHOR_TAG.', 'we train our models on a single geforce gtx titan x gpu.', 'with the above hyper - parameter setting, training takes approximately 8 hours for a full run of 40 epochs.', 'evaluation.', 'we measure model performance with the official conll evaluation script and report span - level named entity f - score on the test set using early stopping based on the performance on the validation set.', 'we report average f - scores and standard deviation over 5 runs for our model.', 'baseline.', 'in addition to reporting a number of prior results of competitive baseline models, as listed in table 2, we also re - implement the bi - lstm - cnn - crf model by  #TAUTHOR_TAG ( referred to as neural - crf in table 2 ) and report its average performance']",3
"['cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is capable of tagging each input with a predicted labely, resulting in a sequence ofy = { y 1, y 2,..., y t } closely matching the gold label sequence y = { y 1, y 2,..., y t }.', 'here, we extend the model by incorporating an auto - encoder loss taking hand - crafted features as in / output, thereby forcing the model to preserve crucial information stored in such features and allowing us to evaluate the impacts of each feature on model performance.', 'specifically, our model, referred to as neural - crf + ae, consists of four major components : ( 1 ) a character - level cnn ( char - cnn ) ; ( 2 ) a word - level bi - directional lstm ( bi - lstm ) ; ( 3 ) a conditional random field ( crf ) ; and ( 4 ) an auto - encoder auxiliary loss.', 'an illustration of the model architecture is presented in figure 1.', ' #TAUTHOR_TAG have demonstrated that cnns are highly capable of capturing character - level features.', 'here, our character - level cnn is similar to that used in  #TAUTHOR_TAG but differs in that we use a relu activation  #AUTHOR_TAG.', '']",5
"['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['##s news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional,']","['.', 'we use the conll 2003 ner shared task dataset, consisting of 14, 041 / 3, 250 / 3, 453 sentences in the training / development / test set respectively, all extracted from reuters news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional, trained on a 6b - token corpus ).', 'character embeddings are 30 - dimensional and randomly initialised with a uniform distribution in', 'parameters are optimised with stochastic gradient descent ( sgd ) with an initial learning rate of η = 0. 015 and momentum of 0. 9.', 'exponential learning rate decay is applied every 5 epochs with a factor of 0. 8.', 'to reduce the impact of exploding gradients, we employ gradient clipping at 5. 0  #AUTHOR_TAG.', 'we train our models on a single geforce gtx titan x gpu.', 'with the above hyper - parameter setting, training takes approximately 8 hours for a full run of 40 epochs.', 'evaluation.', 'we measure model performance with the official conll evaluation script and report span - level named entity f - score on the test set using early stopping based on the performance on the validation set.', 'we report average f - scores and standard deviation over 5 runs for our model.', 'baseline.', 'in addition to reporting a number of prior results of competitive baseline models, as listed in table 2, we also re - implement the bi - lstm - cnn - crf model by  #TAUTHOR_TAG ( referred to as neural - crf in table 2 ) and report its average performance']",5
"['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the']","['##s news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional,']","['.', 'we use the conll 2003 ner shared task dataset, consisting of 14, 041 / 3, 250 / 3, 453 sentences in the training / development / test set respectively, all extracted from reuters news articles during the period from 1996 to 1997.', 'the dataset is annotated with four categories of name entities : person, location, organization and misc.', 'we use the iobes tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance  #TAUTHOR_TAG.', 'model configuration.', 'following the work of  #TAUTHOR_TAG, we initialise word embeddings with glove  #AUTHOR_TAG ( 300 - dimensional, trained on a 6b - token corpus ).', 'character embeddings are 30 - dimensional and randomly initialised with a uniform distribution in', 'parameters are optimised with stochastic gradient descent ( sgd ) with an initial learning rate of η = 0. 015 and momentum of 0. 9.', 'exponential learning rate decay is applied every 5 epochs with a factor of 0. 8.', 'to reduce the impact of exploding gradients, we employ gradient clipping at 5. 0  #AUTHOR_TAG.', 'we train our models on a single geforce gtx titan x gpu.', 'with the above hyper - parameter setting, training takes approximately 8 hours for a full run of 40 epochs.', 'evaluation.', 'we measure model performance with the official conll evaluation script and report span - level named entity f - score on the test set using early stopping based on the performance on the validation set.', 'we report average f - scores and standard deviation over 5 runs for our model.', 'baseline.', 'in addition to reporting a number of prior results of competitive baseline models, as listed in table 2, we also re - implement the bi - lstm - cnn - crf model by  #TAUTHOR_TAG ( referred to as neural - crf in table 2 ) and report its average performance']",5
"['cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is capable of tagging each input with a predicted labely, resulting in a sequence ofy = { y 1, y 2,..., y t } closely matching the gold label sequence y = { y 1, y 2,..., y t }.', 'here, we extend the model by incorporating an auto - encoder loss taking hand - crafted features as in / output, thereby forcing the model to preserve crucial information stored in such features and allowing us to evaluate the impacts of each feature on model performance.', 'specifically, our model, referred to as neural - crf + ae, consists of four major components : ( 1 ) a character - level cnn ( char - cnn ) ; ( 2 ) a word - level bi - directional lstm ( bi - lstm ) ; ( 3 ) a conditional random field ( crf ) ; and ( 4 ) an auto - encoder auxiliary loss.', 'an illustration of the model architecture is presented in figure 1.', ' #TAUTHOR_TAG have demonstrated that cnns are highly capable of capturing character - level features.', 'here, our character - level cnn is similar to that used in  #TAUTHOR_TAG but differs in that we use a relu activation  #AUTHOR_TAG.', '']",1
"['cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is capable of tagging each input with a predicted labely, resulting in a sequence ofy = { y 1, y 2,..., y t } closely matching the gold label sequence y = { y 1, y 2,..., y t }.', 'here, we extend the model by incorporating an auto - encoder loss taking hand - crafted features as in / output, thereby forcing the model to preserve crucial information stored in such features and allowing us to evaluate the impacts of each feature on model performance.', 'specifically, our model, referred to as neural - crf + ae, consists of four major components : ( 1 ) a character - level cnn ( char - cnn ) ; ( 2 ) a word - level bi - directional lstm ( bi - lstm ) ; ( 3 ) a conditional random field ( crf ) ; and ( 4 ) an auto - encoder auxiliary loss.', 'an illustration of the model architecture is presented in figure 1.', ' #TAUTHOR_TAG have demonstrated that cnns are highly capable of capturing character - level features.', 'here, our character - level cnn is similar to that used in  #TAUTHOR_TAG but differs in that we use a relu activation  #AUTHOR_TAG.', '']",4
"['cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is']","['build on a highly competitive sequence labelling model, namely bi - lstm - cnn - crf, first introduced by  #TAUTHOR_TAG.', 'given an input sequence of x = { x 1, x 2,..., x t } of length t, the model is capable of tagging each input with a predicted labely, resulting in a sequence ofy = { y 1, y 2,..., y t } closely matching the gold label sequence y = { y 1, y 2,..., y t }.', 'here, we extend the model by incorporating an auto - encoder loss taking hand - crafted features as in / output, thereby forcing the model to preserve crucial information stored in such features and allowing us to evaluate the impacts of each feature on model performance.', 'specifically, our model, referred to as neural - crf + ae, consists of four major components : ( 1 ) a character - level cnn ( char - cnn ) ; ( 2 ) a word - level bi - directional lstm ( bi - lstm ) ; ( 3 ) a conditional random field ( crf ) ; and ( 4 ) an auto - encoder auxiliary loss.', 'an illustration of the model architecture is presented in figure 1.', ' #TAUTHOR_TAG have demonstrated that cnns are highly capable of capturing character - level features.', 'here, our character - level cnn is similar to that used in  #TAUTHOR_TAG but differs in that we use a relu activation  #AUTHOR_TAG.', '']",6
"['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG.', '']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG.', '']",0
"['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG.', '']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG.', '']",0
"['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG.', '']","['from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches  #AUTHOR_TAG and more recently using neural models  #TAUTHOR_TAG.', '']",1
"['is also done in  #TAUTHOR_TAG.', 'the']","['is also done in  #TAUTHOR_TAG.', 'the']","['is the number of nodes.', '1 this procedure is also done in  #TAUTHOR_TAG.', '']","['pointed out by  #AUTHOR_TAG, ggnns can suffer from parameter explosion when the edge label space is large, as the number of parameters is proportional to the set of edge labels.', 'this is a problem for lattices, since most of the information is encoded on the edges.', 'we tackle this problem by transforming the lattices into their corresponding line graphs, which swaps nodes and edges.', '1 after this transformation, we also add start and end symbols, which enable the encoder to propagate information through all possible paths in the lattice.', 'importantly, we also remove node scores from the lattice in most of our experiments, but we do revisit this idea in § 3. 3.', 'having lattices as inputs allow us to incorporate additional steps of textual transformations.', 'to showcase this, in this work we perform subword segmentation on the lattice nodes using bpe.', 'if a node is not present in the subword vocabulary, we split it into subwords and connect them in a leftto - right manner.', 'the bpe segmentation can lead to redundant nodes in the lattice.', 'our next transformation step is a minimisation procedure, where such nodes are joined into a single node in the graph.', 'to perform this step, we leverage an efficient algorithm for automata minimisation  #AUTHOR_TAG, which traverses the graph detecting redundant nodes by using equivalence classes, running in o ( n log n ) time, where n is the number of nodes.', '1 this procedure is also done in  #TAUTHOR_TAG.', 'the final step adds reverse and self - loop edges to the lattice, where these new edges have specific parameters in the encoder.', 'this eases propagation of information and is standard practice when using graph networks as encoders  #AUTHOR_TAG.', 'we show an example of all the transformation steps on figure 1.', 'in figure 2 we show the architecture of our system, using the final lattice from figure 1 as an example.', 'nodes are represented as embeddings that are updated according to the lattice structure, resulting in a set of hidden states as the output.', 'other components follow a standard seq2seq model, using a bilinear attention module  #AUTHOR_TAG and a 2 - layer lstm  #AUTHOR_TAG as the decoder']",3
"['use the original splits provided with the datasets.', 'following previous work  #TAUTHOR_TAG, we lowercase']","['use the original splits provided with the datasets.', 'following previous work  #TAUTHOR_TAG, we lowercase']","['for each spanish utterance.', '2 the fisher corpus contain 150k instances and we use the original splits provided with the datasets.', 'following previous work  #TAUTHOR_TAG, we lowercase']","['we perform experiments using the fisher / callhome speech translation corpus, composed of spanish telephone conversations with their corresponding english translations.', 'we use the original release by  #AUTHOR_TAG, containing both 1 - best and pruned lattice outputs from an asr system for each spanish utterance.', '2 the fisher corpus contain 150k instances and we use the original splits provided with the datasets.', 'following previous work  #TAUTHOR_TAG, we lowercase and remove punctuation from the english translations.', 'to build the bpe models, we extract the vocabulary from the spanish training lattices, using 8k split operations.', 'models and evaluation all our models are trained on the fisher training set.', 'for the 1 - best baseline we use a standard seq2seq architecture and for the ggnn models, we use the same setup as  #AUTHOR_TAG.', 'our implementation is based on the sockeye toolkit  #AUTHOR_TAG and we use default values for most hyperparameters, except for batch size ( 16 ) and ggnn layers ( 8 ). 3 for regularisation, we apply 0. 5 dropout on the input embeddings and perform early stopping on the corresponding fisher dev set.', 'table 1 : out - of - the - box scenario results, in bleu scores. "" l "" corresponds to word lattice inputs, "" l + s "" and "" l + s + m "" correspond to lattices after subword segmentation and after minimisation, respectively.', 'each model is trained using 5 different seeds and we report bleu  #AUTHOR_TAG results using the median performance according to the dev set and an ensemble of the 5 models.', 'for the word - based models, we remove any tokens with frequency lower than 2 ( as in  #TAUTHOR_TAG, while for subword models we do not perform any threshold pruning.', 'we report all results on the fisher "" dev2 "" set.', '']",5
"['use the original splits provided with the datasets.', 'following previous work  #TAUTHOR_TAG, we lowercase']","['use the original splits provided with the datasets.', 'following previous work  #TAUTHOR_TAG, we lowercase']","['for each spanish utterance.', '2 the fisher corpus contain 150k instances and we use the original splits provided with the datasets.', 'following previous work  #TAUTHOR_TAG, we lowercase']","['we perform experiments using the fisher / callhome speech translation corpus, composed of spanish telephone conversations with their corresponding english translations.', 'we use the original release by  #AUTHOR_TAG, containing both 1 - best and pruned lattice outputs from an asr system for each spanish utterance.', '2 the fisher corpus contain 150k instances and we use the original splits provided with the datasets.', 'following previous work  #TAUTHOR_TAG, we lowercase and remove punctuation from the english translations.', 'to build the bpe models, we extract the vocabulary from the spanish training lattices, using 8k split operations.', 'models and evaluation all our models are trained on the fisher training set.', 'for the 1 - best baseline we use a standard seq2seq architecture and for the ggnn models, we use the same setup as  #AUTHOR_TAG.', 'our implementation is based on the sockeye toolkit  #AUTHOR_TAG and we use default values for most hyperparameters, except for batch size ( 16 ) and ggnn layers ( 8 ). 3 for regularisation, we apply 0. 5 dropout on the input embeddings and perform early stopping on the corresponding fisher dev set.', 'table 1 : out - of - the - box scenario results, in bleu scores. "" l "" corresponds to word lattice inputs, "" l + s "" and "" l + s + m "" correspond to lattices after subword segmentation and after minimisation, respectively.', 'each model is trained using 5 different seeds and we report bleu  #AUTHOR_TAG results using the median performance according to the dev set and an ensemble of the 5 models.', 'for the word - based models, we remove any tokens with frequency lower than 2 ( as in  #TAUTHOR_TAG, while for subword models we do not perform any threshold pruning.', 'we report all results on the fisher "" dev2 "" set.', '']",5
"['', 'the approaches used by  #TAUTHOR_TAG can provide a starting']","['to investigate better approaches to incorporate scores in the lattices.', 'the approaches used by  #TAUTHOR_TAG can provide a starting']","['we plan to investigate better approaches to incorporate scores in the lattices.', 'the approaches used by  #TAUTHOR_TAG can provide a starting point in']","['this work we proposed an architecture for lattice - to - string translation by treating lattices as general graphs and leveraging on recent advances in neural networks for graphs.', '5 compared to previous similar work, our model permits easy minibatching and allows one to freely enrich the lattices with additional information, which we exploit by incorporating bpe segmentation and lattice minimisation.', 'we show promising results and outperform baselines in speech translation, particularly in out - of - the - box asr scenarios, when one has no access to transcriptions.', 'for future work, we plan to investigate better approaches to incorporate scores in the lattices.', 'the approaches used by  #TAUTHOR_TAG can provide a starting point in this direction.', 'the same minimisation procedures we employ can be adapted to weighted lattices  #AUTHOR_TAG.', 'another important avenue is to explore this approach in low - resource scenarios such as ones involving endangered languages  #AUTHOR_TAG.', 'workshop on speech and language technologies, hosted at carnegie mellon university and sponsored by johns hopkins university with unrestricted gifts from amazon, apple, facebook, google, and microsoft']",5
"[' #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our']","[' #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our approach.', 'most importantly, we are able to reach those results while being two']","['', 'we also slightly outperform  #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our']","['out - of - the - box results in § 3. 1 are arguably more general in terms of applicability in real scenarios.', 'however, in order to compare with the state - of - the - art, we also experiment with a scenario where we have access to the original spanish transcriptions.', 'to incorporate transcriptions into our model, we convert them into a linear chain graph, after segmenting using bpe.', 'with this, we can simply take the union of transcriptions and lattices into a single training set.', 'we keep the dev and test sets with lattices only, as this emulates test time conditions.', 'the results shown in table 2 are consistent with previous work : adding transcriptions further enhance the system performance.', 'we also slightly outperform  #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our approach.', 'most importantly, we are able to reach those results while being two orders of magnitude faster at training time :  #TAUTHOR_TAG report taking 1. 5 days for each epoch while our architecture can process each epoch in 15min.', 'the reason is because  #TAUTHOR_TAG relies on the cpu while our ggnn - based model can be easily batched and computed in a gpu.', 'given those differences in training time, it is worth mentioning that the best model in  #TAUTHOR_TAG is surpassed by our best ensemble using lattices only.', 'this means that we can obtain state - of - the - art performance even in an out - of - thebox scenario, under the same training speed constraints.', 'while there are other constraints that may be considered ( such as parameter budget ), we nevertheless believe this is an encouraging result for real world scenarios']",4
"[' #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our']","[' #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our approach.', 'most importantly, we are able to reach those results while being two']","['', 'we also slightly outperform  #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our']","['out - of - the - box results in § 3. 1 are arguably more general in terms of applicability in real scenarios.', 'however, in order to compare with the state - of - the - art, we also experiment with a scenario where we have access to the original spanish transcriptions.', 'to incorporate transcriptions into our model, we convert them into a linear chain graph, after segmenting using bpe.', 'with this, we can simply take the union of transcriptions and lattices into a single training set.', 'we keep the dev and test sets with lattices only, as this emulates test time conditions.', 'the results shown in table 2 are consistent with previous work : adding transcriptions further enhance the system performance.', 'we also slightly outperform  #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our approach.', 'most importantly, we are able to reach those results while being two orders of magnitude faster at training time :  #TAUTHOR_TAG report taking 1. 5 days for each epoch while our architecture can process each epoch in 15min.', 'the reason is because  #TAUTHOR_TAG relies on the cpu while our ggnn - based model can be easily batched and computed in a gpu.', 'given those differences in training time, it is worth mentioning that the best model in  #TAUTHOR_TAG is surpassed by our best ensemble using lattices only.', 'this means that we can obtain state - of - the - art performance even in an out - of - thebox scenario, under the same training speed constraints.', 'while there are other constraints that may be considered ( such as parameter budget ), we nevertheless believe this is an encouraging result for real world scenarios']",4
"[' #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our']","[' #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our approach.', 'most importantly, we are able to reach those results while being two']","['', 'we also slightly outperform  #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our']","['out - of - the - box results in § 3. 1 are arguably more general in terms of applicability in real scenarios.', 'however, in order to compare with the state - of - the - art, we also experiment with a scenario where we have access to the original spanish transcriptions.', 'to incorporate transcriptions into our model, we convert them into a linear chain graph, after segmenting using bpe.', 'with this, we can simply take the union of transcriptions and lattices into a single training set.', 'we keep the dev and test sets with lattices only, as this emulates test time conditions.', 'the results shown in table 2 are consistent with previous work : adding transcriptions further enhance the system performance.', 'we also slightly outperform  #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our approach.', 'most importantly, we are able to reach those results while being two orders of magnitude faster at training time :  #TAUTHOR_TAG report taking 1. 5 days for each epoch while our architecture can process each epoch in 15min.', 'the reason is because  #TAUTHOR_TAG relies on the cpu while our ggnn - based model can be easily batched and computed in a gpu.', 'given those differences in training time, it is worth mentioning that the best model in  #TAUTHOR_TAG is surpassed by our best ensemble using lattices only.', 'this means that we can obtain state - of - the - art performance even in an out - of - thebox scenario, under the same training speed constraints.', 'while there are other constraints that may be considered ( such as parameter budget ), we nevertheless believe this is an encouraging result for real world scenarios']",4
"[' #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our']","[' #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our approach.', 'most importantly, we are able to reach those results while being two']","['', 'we also slightly outperform  #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our']","['out - of - the - box results in § 3. 1 are arguably more general in terms of applicability in real scenarios.', 'however, in order to compare with the state - of - the - art, we also experiment with a scenario where we have access to the original spanish transcriptions.', 'to incorporate transcriptions into our model, we convert them into a linear chain graph, after segmenting using bpe.', 'with this, we can simply take the union of transcriptions and lattices into a single training set.', 'we keep the dev and test sets with lattices only, as this emulates test time conditions.', 'the results shown in table 2 are consistent with previous work : adding transcriptions further enhance the system performance.', 'we also slightly outperform  #TAUTHOR_TAG in the setting where they ignore lattice scores, as in our approach.', 'most importantly, we are able to reach those results while being two orders of magnitude faster at training time :  #TAUTHOR_TAG report taking 1. 5 days for each epoch while our architecture can process each epoch in 15min.', 'the reason is because  #TAUTHOR_TAG relies on the cpu while our ggnn - based model can be easily batched and computed in a gpu.', 'given those differences in training time, it is worth mentioning that the best model in  #TAUTHOR_TAG is surpassed by our best ensemble using lattices only.', 'this means that we can obtain state - of - the - art performance even in an out - of - thebox scenario, under the same training speed constraints.', 'while there are other constraints that may be considered ( such as parameter budget ), we nevertheless believe this is an encouraging result for real world scenarios']",4
"['ensemble.', 'it is worth noticing that  #TAUTHOR_TAG has a more principled approach to incorporate scores : by modifying']","['ensemble.', 'it is worth noticing that  #TAUTHOR_TAG has a more principled approach to incorporate scores : by modifying']","['the ensemble.', 'it is worth noticing that  #TAUTHOR_TAG has a more principled approach to incorporate scores : by modifying the attention module.', 'this is arguably a better choice,']","['approach is not without limitations.', 'in particular, the ggnn encoder ignores lattice scores, which can help the model disambiguate between different paths in the lattice.', 'as a simple first approach to incorporate scores, we embed them using a multilayer perceptron, using the score as the input.', 'this however did not produce good results : performance dropped to 32. 9 bleu in the single model setting and 38. 4 for the ensemble.', 'it is worth noticing that  #TAUTHOR_TAG has a more principled approach to incorporate scores : by modifying the attention module.', 'this is arguably a better choice, since the scores can directly inform the decoder about the ambiguity in the lattice.', 'since this approach does not affect the encoder, it is theoretically possible to combine our ggnn encoder with their attention module, we leave this avenue for future work']",4
"['', 'the approaches used by  #TAUTHOR_TAG can provide a starting']","['to investigate better approaches to incorporate scores in the lattices.', 'the approaches used by  #TAUTHOR_TAG can provide a starting']","['we plan to investigate better approaches to incorporate scores in the lattices.', 'the approaches used by  #TAUTHOR_TAG can provide a starting point in']","['this work we proposed an architecture for lattice - to - string translation by treating lattices as general graphs and leveraging on recent advances in neural networks for graphs.', '5 compared to previous similar work, our model permits easy minibatching and allows one to freely enrich the lattices with additional information, which we exploit by incorporating bpe segmentation and lattice minimisation.', 'we show promising results and outperform baselines in speech translation, particularly in out - of - the - box asr scenarios, when one has no access to transcriptions.', 'for future work, we plan to investigate better approaches to incorporate scores in the lattices.', 'the approaches used by  #TAUTHOR_TAG can provide a starting point in this direction.', 'the same minimisation procedures we employ can be adapted to weighted lattices  #AUTHOR_TAG.', 'another important avenue is to explore this approach in low - resource scenarios such as ones involving endangered languages  #AUTHOR_TAG.', 'workshop on speech and language technologies, hosted at carnegie mellon university and sponsored by johns hopkins university with unrestricted gifts from amazon, apple, facebook, google, and microsoft']",2
"['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns']","['lexicon can be considered the most dynamic part of all linguistic knowledge sources over time.', 'there are two innovative change strategies typical for lexical systems : the creation of entirely new lexical items, commonly reflecting the emergence of novel ideas, technologies or artifacts, on the one hand, and, on the other hand, shifts in the meaning of already existing lexical items, a process which usually takes place over larger periods of time.', 'tracing semantic changes of the latter type is the main focus of our research.', 'meaning shift has recently been investigated with emphasis on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns can be reduced to the measurement of lexical similarity between lexical items.', 'neural language models, originating from the word2vec algorithm  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG c ), are currently considered as state - of - the - art solutions for implementing this assumption  #AUTHOR_TAG.', 'within this approach, changes in similarity relations between lexical items at two different points of time are interpreted as a signal for meaning shift.', 'accordingly, lexical items which are very similar to the lexical item under scrutiny can be considered as approximating its meaning at a given point in time.', 'both techniques were already combined in prior work to show, e. g., the increasing association of the lexical item "" gay "" with the meaning dimension of "" homosexuality ""  #TAUTHOR_TAG.', 'we here investigate the accuracy and reliability of such similarity judgments derived from different training protocols dependent on word frequency, word ambiguity and the number of training epochs ( i. e., iterations over all training material ).', 'accuracy renders a judgment of the overall model quality, whereas reliability between repeated experiments ensures that qualitative judgments can indeed be transferred between experiments.', 'based on the identification of critical conditions in the experimental set - up of previously employed protocols, we recommend improved training strategies for more adequate neural language models dealing with diachronic lexical change patterns.', 'our results concerning reliability also cast doubt on the reproducibility of experiments where semantic similarity between lexical items is taken as a computationally valid indicator for properly capturing lexical meaning ( and, consequently, meaning shifts ) under a diachronic perspective']",0
"['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns']","['lexicon can be considered the most dynamic part of all linguistic knowledge sources over time.', 'there are two innovative change strategies typical for lexical systems : the creation of entirely new lexical items, commonly reflecting the emergence of novel ideas, technologies or artifacts, on the one hand, and, on the other hand, shifts in the meaning of already existing lexical items, a process which usually takes place over larger periods of time.', 'tracing semantic changes of the latter type is the main focus of our research.', 'meaning shift has recently been investigated with emphasis on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns can be reduced to the measurement of lexical similarity between lexical items.', 'neural language models, originating from the word2vec algorithm  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG c ), are currently considered as state - of - the - art solutions for implementing this assumption  #AUTHOR_TAG.', 'within this approach, changes in similarity relations between lexical items at two different points of time are interpreted as a signal for meaning shift.', 'accordingly, lexical items which are very similar to the lexical item under scrutiny can be considered as approximating its meaning at a given point in time.', 'both techniques were already combined in prior work to show, e. g., the increasing association of the lexical item "" gay "" with the meaning dimension of "" homosexuality ""  #TAUTHOR_TAG.', 'we here investigate the accuracy and reliability of such similarity judgments derived from different training protocols dependent on word frequency, word ambiguity and the number of training epochs ( i. e., iterations over all training material ).', 'accuracy renders a judgment of the overall model quality, whereas reliability between repeated experiments ensures that qualitative judgments can indeed be transferred between experiments.', 'based on the identification of critical conditions in the experimental set - up of previously employed protocols, we recommend improved training strategies for more adequate neural language models dealing with diachronic lexical change patterns.', 'our results concerning reliability also cast doubt on the reproducibility of experiments where semantic similarity between lexical items is taken as a computationally valid indicator for properly capturing lexical meaning ( and, consequently, meaning shifts ) under a diachronic perspective']",0
['tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #TAUTHOR_TAG where the model for each time span is initialized with the embeddings of'],['tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #TAUTHOR_TAG where the model for each time span is initialized with the embeddings of'],['tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #TAUTHOR_TAG where the model for each time span is initialized with the embeddings of'],"['language models for tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #TAUTHOR_TAG where the model for each time span is initialized with the embeddings of its predecessor, and, alternatively, independent training with a mapping between models for different points in time  #AUTHOR_TAG.', 'a comparison between these two protocols, such as the one proposed in this paper, has not been carried out before.', 'also, the application of such protocols to non - english corpora is lacking, with the exception of our own work relating to german data  #AUTHOR_TAG b ;  #AUTHOR_TAG a ).', 'the word2vec algorithm is a heavily trimmed version of an artificial neural network used to generate low - dimensional vector space representations of a lexicon.', 'we focus on its skip - gram variant, trained to predict plausible contexts for a given word that was shown to be superior over other settings for modeling semantic information  #AUTHOR_TAG a ).', 'there are several parameters to choose for training - learning rate, downsampling factor for frequent words, number of training epochs and choice between two strategies for managing the huge number of potential contexts.', 'one strategy, hierarchical softmax, uses a binary tree to efficiently represent the vocabulary, while the other, negative sampling, works by updating only a limited number of word vectors during each training step.', 'furthermore, artificial neural networks, in general, are known for a large number of local optima encountered during optimization.', 'while these commonly lead to very similar performance ( le  #AUTHOR_TAG, they cause different representations in the course of repeated experiments.', 'approaches to modelling changes of lexical semantics not using neural language models, e. g.,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG or  #AUTHOR_TAG are, intentionally, out of the scope of this paper.', 'in the same way, we here refrain from comparison with computational studies dealing with literary discussions related to the romantic period ( e. g.,  #AUTHOR_TAG )']",0
"['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less affected by sampling irregularities than other parts  #AUTHOR_TAG.', ""due to the opaque nature of google's corpus acquisition strategy, the influence of ocr errors on our results cannot be reasonably estimated, yet we assume that they will affect all experiments in an equal manner."", ""the wide range of experimental parameters described in section 2 makes it virtually impossible to test all their possible combinations, especially as repeated experiments are necessary to probe a method's reliability."", 'we thus concentrate on two experimental protocols - the one described by  #TAUTHOR_TAG ( referred to as kim protocol ) and the one from  #AUTHOR_TAG ( referred to as kulkarni protocol ), including close variations thereof.', ""kulkarni's protocol operates on all 5 - grams occurring during five consecutive years ( e. g., [ 1900 ] [ 1901 ] [ 1902 ] [ 1903 ] [ 1904 ] and trains models independently of each other."", ""kim's protocol operates on uniformly sized samples of 10m 5 - grams for each year from 1850 onwards in a continuous fashion ( years before 1900 are used for initialization only )."", 'its constant sampling sizes result in both oversampling and undersampling as is evident from figure 1.', 'we use the python - based gensim 1 implementation of word2vec for our experiments ; the relevant code is made available via github.', '2 due to the 5 - gram nature of the corpus, a context window covering four neighboring words is used for all experiments.', 'only words with at least 10 occurrences in a sample are modeled.', 'training for each sample is repeated until convergence 3 is achieved or 10 epochs have passed.', 'following both protocols, we use word vectors with 200 table 1 : accuracy and reliability among top n words for threefold application of different training protocols.', 'reliability is given as fraction of the maximum for n. standard deviation for accuracy ±0, if not noted otherwise ; reliability is based on the evaluation of all lexical items, thus no standard deviation.', 'dimensions for all experiments, as well as an initial learning rate of 0. 01 for experiments based on 10m samples, and one of 0. 025 for systems trained on unsampled texts ; the threshold for downsampling frequent words was 10 −3 for sample - based experiments and 10 −5 for unsampled ones.', ""we tested both negative sampling and hierarchical softmax training strategies, the latter being canonical for kulkarni's protocol, whereas kim's""]",0
"['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this']","['on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns']","['lexicon can be considered the most dynamic part of all linguistic knowledge sources over time.', 'there are two innovative change strategies typical for lexical systems : the creation of entirely new lexical items, commonly reflecting the emergence of novel ideas, technologies or artifacts, on the one hand, and, on the other hand, shifts in the meaning of already existing lexical items, a process which usually takes place over larger periods of time.', 'tracing semantic changes of the latter type is the main focus of our research.', 'meaning shift has recently been investigated with emphasis on neural language models  #TAUTHOR_TAG.', 'this work is based on the assumption that the measurement of semantic change patterns can be reduced to the measurement of lexical similarity between lexical items.', 'neural language models, originating from the word2vec algorithm  #AUTHOR_TAG a ;  #AUTHOR_TAG b ;  #AUTHOR_TAG c ), are currently considered as state - of - the - art solutions for implementing this assumption  #AUTHOR_TAG.', 'within this approach, changes in similarity relations between lexical items at two different points of time are interpreted as a signal for meaning shift.', 'accordingly, lexical items which are very similar to the lexical item under scrutiny can be considered as approximating its meaning at a given point in time.', 'both techniques were already combined in prior work to show, e. g., the increasing association of the lexical item "" gay "" with the meaning dimension of "" homosexuality ""  #TAUTHOR_TAG.', 'we here investigate the accuracy and reliability of such similarity judgments derived from different training protocols dependent on word frequency, word ambiguity and the number of training epochs ( i. e., iterations over all training material ).', 'accuracy renders a judgment of the overall model quality, whereas reliability between repeated experiments ensures that qualitative judgments can indeed be transferred between experiments.', 'based on the identification of critical conditions in the experimental set - up of previously employed protocols, we recommend improved training strategies for more adequate neural language models dealing with diachronic lexical change patterns.', 'our results concerning reliability also cast doubt on the reproducibility of experiments where semantic similarity between lexical items is taken as a computationally valid indicator for properly capturing lexical meaning ( and, consequently, meaning shifts ) under a diachronic perspective']",1
['tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #TAUTHOR_TAG where the model for each time span is initialized with the embeddings of'],['tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #TAUTHOR_TAG where the model for each time span is initialized with the embeddings of'],['tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #TAUTHOR_TAG where the model for each time span is initialized with the embeddings of'],"['language models for tracking semantic changes over time typically distinguish between two different training protocols - continuous training of models  #TAUTHOR_TAG where the model for each time span is initialized with the embeddings of its predecessor, and, alternatively, independent training with a mapping between models for different points in time  #AUTHOR_TAG.', 'a comparison between these two protocols, such as the one proposed in this paper, has not been carried out before.', 'also, the application of such protocols to non - english corpora is lacking, with the exception of our own work relating to german data  #AUTHOR_TAG b ;  #AUTHOR_TAG a ).', 'the word2vec algorithm is a heavily trimmed version of an artificial neural network used to generate low - dimensional vector space representations of a lexicon.', 'we focus on its skip - gram variant, trained to predict plausible contexts for a given word that was shown to be superior over other settings for modeling semantic information  #AUTHOR_TAG a ).', 'there are several parameters to choose for training - learning rate, downsampling factor for frequent words, number of training epochs and choice between two strategies for managing the huge number of potential contexts.', 'one strategy, hierarchical softmax, uses a binary tree to efficiently represent the vocabulary, while the other, negative sampling, works by updating only a limited number of word vectors during each training step.', 'furthermore, artificial neural networks, in general, are known for a large number of local optima encountered during optimization.', 'while these commonly lead to very similar performance ( le  #AUTHOR_TAG, they cause different representations in the course of repeated experiments.', 'approaches to modelling changes of lexical semantics not using neural language models, e. g.,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG,  #AUTHOR_TAG or  #AUTHOR_TAG are, intentionally, out of the scope of this paper.', 'in the same way, we here refrain from comparison with computational studies dealing with literary discussions related to the romantic period ( e. g.,  #AUTHOR_TAG )']",1
"['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less affected by sampling irregularities than other parts  #AUTHOR_TAG.', ""due to the opaque nature of google's corpus acquisition strategy, the influence of ocr errors on our results cannot be reasonably estimated, yet we assume that they will affect all experiments in an equal manner."", ""the wide range of experimental parameters described in section 2 makes it virtually impossible to test all their possible combinations, especially as repeated experiments are necessary to probe a method's reliability."", 'we thus concentrate on two experimental protocols - the one described by  #TAUTHOR_TAG ( referred to as kim protocol ) and the one from  #AUTHOR_TAG ( referred to as kulkarni protocol ), including close variations thereof.', ""kulkarni's protocol operates on all 5 - grams occurring during five consecutive years ( e. g., [ 1900 ] [ 1901 ] [ 1902 ] [ 1903 ] [ 1904 ] and trains models independently of each other."", ""kim's protocol operates on uniformly sized samples of 10m 5 - grams for each year from 1850 onwards in a continuous fashion ( years before 1900 are used for initialization only )."", 'its constant sampling sizes result in both oversampling and undersampling as is evident from figure 1.', 'we use the python - based gensim 1 implementation of word2vec for our experiments ; the relevant code is made available via github.', '2 due to the 5 - gram nature of the corpus, a context window covering four neighboring words is used for all experiments.', 'only words with at least 10 occurrences in a sample are modeled.', 'training for each sample is repeated until convergence 3 is achieved or 10 epochs have passed.', 'following both protocols, we use word vectors with 200 table 1 : accuracy and reliability among top n words for threefold application of different training protocols.', 'reliability is given as fraction of the maximum for n. standard deviation for accuracy ±0, if not noted otherwise ; reliability is based on the evaluation of all lexical items, thus no standard deviation.', 'dimensions for all experiments, as well as an initial learning rate of 0. 01 for experiments based on 10m samples, and one of 0. 025 for systems trained on unsampled texts ; the threshold for downsampling frequent words was 10 −3 for sample - based experiments and 10 −5 for unsampled ones.', ""we tested both negative sampling and hierarchical softmax training strategies, the latter being canonical for kulkarni's protocol, whereas kim's""]",5
"['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less']","['comparability with earlier studies  #TAUTHOR_TAG, we use the fiction part of the google books ngram corpus  #AUTHOR_TAG.', 'this part of the corpus is also less affected by sampling irregularities than other parts  #AUTHOR_TAG.', ""due to the opaque nature of google's corpus acquisition strategy, the influence of ocr errors on our results cannot be reasonably estimated, yet we assume that they will affect all experiments in an equal manner."", ""the wide range of experimental parameters described in section 2 makes it virtually impossible to test all their possible combinations, especially as repeated experiments are necessary to probe a method's reliability."", 'we thus concentrate on two experimental protocols - the one described by  #TAUTHOR_TAG ( referred to as kim protocol ) and the one from  #AUTHOR_TAG ( referred to as kulkarni protocol ), including close variations thereof.', ""kulkarni's protocol operates on all 5 - grams occurring during five consecutive years ( e. g., [ 1900 ] [ 1901 ] [ 1902 ] [ 1903 ] [ 1904 ] and trains models independently of each other."", ""kim's protocol operates on uniformly sized samples of 10m 5 - grams for each year from 1850 onwards in a continuous fashion ( years before 1900 are used for initialization only )."", 'its constant sampling sizes result in both oversampling and undersampling as is evident from figure 1.', 'we use the python - based gensim 1 implementation of word2vec for our experiments ; the relevant code is made available via github.', '2 due to the 5 - gram nature of the corpus, a context window covering four neighboring words is used for all experiments.', 'only words with at least 10 occurrences in a sample are modeled.', 'training for each sample is repeated until convergence 3 is achieved or 10 epochs have passed.', 'following both protocols, we use word vectors with 200 table 1 : accuracy and reliability among top n words for threefold application of different training protocols.', 'reliability is given as fraction of the maximum for n. standard deviation for accuracy ±0, if not noted otherwise ; reliability is based on the evaluation of all lexical items, thus no standard deviation.', 'dimensions for all experiments, as well as an initial learning rate of 0. 01 for experiments based on 10m samples, and one of 0. 025 for systems trained on unsampled texts ; the threshold for downsampling frequent words was 10 −3 for sample - based experiments and 10 −5 for unsampled ones.', ""we tested both negative sampling and hierarchical softmax training strategies, the latter being canonical for kulkarni's protocol, whereas kim's""]",5
"['of  #TAUTHOR_TAG. 1, 000 bnc sentences are manually annotated']","['of  #TAUTHOR_TAG. 1, 000 bnc sentences are manually annotated']","['reranking parser of  #TAUTHOR_TAG. 1, 000 bnc sentences are manually annotated for constituent structure, resulting in the first gold standard set for this corpus. the gold standard set is split', 'into a development set of 500']","['', 'wsj data for seed training. in contrast, we report successful in - domain 1 self - training experiments with the bnc data as self - training and test material, and with the wsj - trained reranking parser used by mc  #AUTHOR_TAG a ; 2006b ). we parse the bnc  #AUTHOR_TAG in its', 'entirety using the reranking parser of  #TAUTHOR_TAG. 1, 000 bnc sentences are manually annotated for constituent structure, resulting in the first gold standard set for this corpus. the gold standard set is split', ""into a development set of 500 parse trees and a test set of 500 parse trees and used in a series of self - training experiments : charniak and johnson's parser is retrained on combinations of wsj treebank data and its"", 'own parses of bnc sentences. these combinations are tested on the bnc development set and section 00 of the wsj. an optimal combination is chosen which achieves a parseval labelled bracketing f', '']",0
"['of  #TAUTHOR_TAG. 1, 000 bnc sentences are manually annotated']","['of  #TAUTHOR_TAG. 1, 000 bnc sentences are manually annotated']","['reranking parser of  #TAUTHOR_TAG. 1, 000 bnc sentences are manually annotated for constituent structure, resulting in the first gold standard set for this corpus. the gold standard set is split', 'into a development set of 500']","['', 'wsj data for seed training. in contrast, we report successful in - domain 1 self - training experiments with the bnc data as self - training and test material, and with the wsj - trained reranking parser used by mc  #AUTHOR_TAG a ; 2006b ). we parse the bnc  #AUTHOR_TAG in its', 'entirety using the reranking parser of  #TAUTHOR_TAG. 1, 000 bnc sentences are manually annotated for constituent structure, resulting in the first gold standard set for this corpus. the gold standard set is split', ""into a development set of 500 parse trees and a test set of 500 parse trees and used in a series of self - training experiments : charniak and johnson's parser is retrained on combinations of wsj treebank data and its"", 'own parses of bnc sentences. these combinations are tested on the bnc development set and section 00 of the wsj. an optimal combination is chosen which achieves a parseval labelled bracketing f', '']",5
['of  #TAUTHOR_TAG was used to'],['of  #TAUTHOR_TAG was used to'],['of  #TAUTHOR_TAG was used to'],"['bnc is a 100 - million - word balanced part - ofspeech - tagged corpus of written and transcribed spoken english.', 'written text comprises 90 % of the bnc : 75 % non - fictional and 25 % fictional.', 'to facilitate parsing with a wsj - trained parser, some reversible transformations were applied to the bnc data, e. g. british english spellings were converted to american english and neutral quotes disambiguated.', 'the reranking parser of  #TAUTHOR_TAG was used to parse the bnc.', '99. 8 % of the 6 million bnc sentences obtained a parse, with an average parsing speed of 1. 4s per sentence.', ""a gold standard set of 1, 000 bnc sentences was constructed by one annotator by correcting the output of the first stage of charniak and johnson's reranking parser."", 'the sentences included in the gold standard were chosen at random from the bnc, subject to the condition that they contain a verb which does not occur in the training sections of the wsj section of the ptb  #AUTHOR_TAG.', 'a decision was made to select sentences for the gold standard set which differ from the sentences in the wsj training sections, and one way of finding different sentences is to focus on verbs which are not attested in the wsj sections 2 - 21.', 'it is expected that these gold standard parse trees can be used as training data although they are used only as test and development data in this work.', ""because they contain verbs which do not occur in the parser's training set, they are likely to represent a hard test for wsj - trained parsers."", 'the ptb bracketing guidelines  #AUTHOR_TAG and the ptb itself were used as references by the bnc annotator.', 'functional tags and traces were not annotated.', 'the annotator noticed that the ptb parse trees sometimes violate the ptb bracketing guidelines, and in these cases, the annotator chose the analysis set out in the guidelines.', 'it took approximately 60 hours to build the gold standard set']",5
"['of  #TAUTHOR_TAG, but adapt']","['of  #TAUTHOR_TAG, but adapt']","['we build on previous work on sentiment detection algorithms for the more formal news genre, notably the work of  #TAUTHOR_TAG, but adapt']","['', 'in this paper we develop a sentiment detection algorithm for social media that classifies the polarity of sentence phrases as positive, negative, or neutral and test its performance in twitter through the participation in the expression level task ( subtask a ) of the semeval - 2013 task 2 : sentiment analysis in twitter  #AUTHOR_TAG which the authors helped organize.', 'to do so, we build on previous work on sentiment detection algorithms for the more formal news genre, notably the work of  #TAUTHOR_TAG, but adapt it for the language of social media, in particular twitter.', 'we show that exploiting lexical - stylistic features and dictionaries geared toward social media are useful in detecting sentiment.', 'in this rest of this paper, we discuss related work, including the state of the art sentiment system  #TAUTHOR_TAG our method is based on, the lexicons we used, our method, and experiments and results']",6
"['of  #TAUTHOR_TAG, but adapt']","['of  #TAUTHOR_TAG, but adapt']","['we build on previous work on sentiment detection algorithms for the more formal news genre, notably the work of  #TAUTHOR_TAG, but adapt']","['', 'in this paper we develop a sentiment detection algorithm for social media that classifies the polarity of sentence phrases as positive, negative, or neutral and test its performance in twitter through the participation in the expression level task ( subtask a ) of the semeval - 2013 task 2 : sentiment analysis in twitter  #AUTHOR_TAG which the authors helped organize.', 'to do so, we build on previous work on sentiment detection algorithms for the more formal news genre, notably the work of  #TAUTHOR_TAG, but adapt it for the language of social media, in particular twitter.', 'we show that exploiting lexical - stylistic features and dictionaries geared toward social media are useful in detecting sentiment.', 'in this rest of this paper, we discuss related work, including the state of the art sentiment system  #TAUTHOR_TAG our method is based on, the lexicons we used, our method, and experiments and results']",6
"['original work  #TAUTHOR_TAG, and expand']","['original work  #TAUTHOR_TAG, and expand']","['the original work  #TAUTHOR_TAG, and expand']","['lexicons are used in our system.', 'we use the dal and expand it with wordnet, as it was used in the original work  #TAUTHOR_TAG, and expand it further to use wiktionary and an emoticon lexicon.', 'we consider proper nouns that are not in the dal to be objective.', 'we also shorten words that are lengthened to see if we can find the shortened version in the lexicons ( e. g. sweeeet → sweet ).', 'the coverage of the lexicons for each corpus is shown in table 1']",6
"['original work  #TAUTHOR_TAG, and expand']","['original work  #TAUTHOR_TAG, and expand']","['the original work  #TAUTHOR_TAG, and expand']","['lexicons are used in our system.', 'we use the dal and expand it with wordnet, as it was used in the original work  #TAUTHOR_TAG, and expand it further to use wiktionary and an emoticon lexicon.', 'we consider proper nouns that are not in the dal to be objective.', 'we also shorten words that are lengthened to see if we can find the shortened version in the lexicons ( e. g. sweeeet → sweet ).', 'the coverage of the lexicons for each corpus is shown in table 1']",3
"['as the original work  #TAUTHOR_TAG, using the sum of the ae space score']","[""as the original work  #TAUTHOR_TAG, using the sum of the ae space score's ( | √""]","[""as the original work  #TAUTHOR_TAG, using the sum of the ae space score's ( | √""]","['dictionary of affect and language ( dal )  #AUTHOR_TAG is an english language dictionary of 8742 words built to measure the emotional meaning of texts.', ""in addition to using newswire, it was also built from individual sources such as interviews on abuse, students'retelling of a story, and adolescent's descriptions of emotions."", 'it therefore covers a broad set of words.', 'each word is given three scores ( pleasantness - also called evaluation ( ee ), activeness ( aa ), and imagery ( ii ) ) on a scale of 1 ( low ) to 3 ( high ).', ""we compute the polarity of a chunk in the same manner as the original work  #TAUTHOR_TAG, using the sum of the ae space score's ( | √ ee 2 + aa 2 | ) of each word within the chunk""]",3
"['n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries']","['n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries']","['include pos tags and the top 500 n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries are used along with a negation state machine  #TAUTHOR_TAG']","['include pos tags and the top 500 n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries are used along with a negation state machine  #TAUTHOR_TAG to determine the polarity for each word in the sentence.', 'we include all the features described in the original system  #TAUTHOR_TAG']",3
"['original work  #TAUTHOR_TAG, and expand']","['original work  #TAUTHOR_TAG, and expand']","['the original work  #TAUTHOR_TAG, and expand']","['lexicons are used in our system.', 'we use the dal and expand it with wordnet, as it was used in the original work  #TAUTHOR_TAG, and expand it further to use wiktionary and an emoticon lexicon.', 'we consider proper nouns that are not in the dal to be objective.', 'we also shorten words that are lengthened to see if we can find the shortened version in the lexicons ( e. g. sweeeet → sweet ).', 'the coverage of the lexicons for each corpus is shown in table 1']",5
"['as the original work  #TAUTHOR_TAG, using the sum of the ae space score']","[""as the original work  #TAUTHOR_TAG, using the sum of the ae space score's ( | √""]","[""as the original work  #TAUTHOR_TAG, using the sum of the ae space score's ( | √""]","['dictionary of affect and language ( dal )  #AUTHOR_TAG is an english language dictionary of 8742 words built to measure the emotional meaning of texts.', ""in addition to using newswire, it was also built from individual sources such as interviews on abuse, students'retelling of a story, and adolescent's descriptions of emotions."", 'it therefore covers a broad set of words.', 'each word is given three scores ( pleasantness - also called evaluation ( ee ), activeness ( aa ), and imagery ( ii ) ) on a scale of 1 ( low ) to 3 ( high ).', ""we compute the polarity of a chunk in the same manner as the original work  #TAUTHOR_TAG, using the sum of the ae space score's ( | √ ee 2 + aa 2 | ) of each word within the chunk""]",5
"['n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries']","['n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries']","['include pos tags and the top 500 n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries are used along with a negation state machine  #TAUTHOR_TAG']","['include pos tags and the top 500 n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries are used along with a negation state machine  #TAUTHOR_TAG to determine the polarity for each word in the sentence.', 'we include all the features described in the original system  #TAUTHOR_TAG']",5
"['n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries']","['n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries']","['include pos tags and the top 500 n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries are used along with a negation state machine  #TAUTHOR_TAG']","['include pos tags and the top 500 n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries are used along with a negation state machine  #TAUTHOR_TAG to determine the polarity for each word in the sentence.', 'we include all the features described in the original system  #TAUTHOR_TAG']",5
"['n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries']","['n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries']","['include pos tags and the top 500 n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries are used along with a negation state machine  #TAUTHOR_TAG']","['include pos tags and the top 500 n - gram features  #TAUTHOR_TAG.', 'we experimented with different amounts of n - grams and found that more than 500 n - grams reduced performance.', 'the dal and other dictionaries are used along with a negation state machine  #TAUTHOR_TAG to determine the polarity for each word in the sentence.', 'we include all the features described in the original system  #TAUTHOR_TAG']",5
"['is trained on the combination of all source languages.', 'furthermore, we reproduce  #TAUTHOR_TAG, in which dependency trees of multiple sources']","['is trained on the combination of all source languages.', 'furthermore, we reproduce  #TAUTHOR_TAG, in which dependency trees of multiple sources']","['is trained on the combination of all source languages.', 'furthermore, we reproduce  #TAUTHOR_TAG, in which dependency trees of multiple sources']","['- lingual dependency parsing involves transferring syntactic knowledge from one language to another.', 'it is a crucial component for inducing dependency parsers in low - resource scenarios where no training data for a language exists.', 'using faroese as the target language, we compare two approaches using annotation projection : first, projecting from multiple monolingual source models ; second, projecting from a single polyglot model which is trained on the combination of all source languages.', 'furthermore, we reproduce  #TAUTHOR_TAG, in which dependency trees of multiple sources are combined.', 'finally, we apply multi - treebank modelling to the projected treebanks, in addition to or alternatively to polyglot modelling on the source side.', 'we find that polyglot training on the source languages produces an overall trend of better results on the target language but the single best result for the target language is obtained by projecting from monolingual source parsing models and then training multi - treebank pos tagging and parsing models on the target side']",5
"['by  #TAUTHOR_TAG - was', '']","['by  #TAUTHOR_TAG - was', '']","['over the result reported by  #TAUTHOR_TAG - was', 'achieved with multi - tree']","['is still available and training data is not reduced to cases where all source languages provide a projection. in other words, we aim to investigate whether the current state - of - the - art approach for faroese, which relies on cross - lingual transfer, can be improved upon by adopting an approach based on source - side polyglot learning', 'and / or target - side multi - treebank learning. we hypothesize that a polyglot model can exploit similarities in', 'morphology and syntax across the included source languages, which will result in a better model to provide annotations for projection. on the target side, we expect that combining different sources of information will result in a more robust target model. we evaluated our various models on the faroese test set and experienced considerable gains for', 'three of the four source languages ( danish, norwegian bokmal and swedish ) by adopting a polyglot model. however, for norwegian nynorsk, a', 'stronger monolingual model was able to outperform the polyglot approach. when we extended multi - treebank learning to the target side, we experienced additional gains for all cases. our best result of 71. 5 - an absolute improvement of 7. 2 points over the result reported by  #TAUTHOR_TAG - was', 'achieved with multi - treebank target learning over the monolingual projections.  #TAUTHOR_TAG describe a method for creating synthetic treebanks for faroese based on previous work which uses machine translation and word alignments to transfer trees from source language ( s ) to the target language.', 'sentences from faroese are translated into the four source languages danish, swedish, norwegian nynorsk', 'and norwegian bokmal. the translated sentences are then tokenized, pos tagged and parsed using the relevant source language model trained on the source language treebank. the resulting trees are projected back to the faroese sentences using word alignments. the four trees for each sentence are combined into a', 'graph with edge scores one to four ( the number of trees that support them ), from which a single tree per sentence is produced using the chu - liu - edmonds algorithm  #AUTHOR_TAG', '. the resulting trees make up a synthetic treebank for faroese which is then used to train a faroe', '##se parsing model. the parser output is evaluated using the gold - standard faroese test treebank developed by  #TAUTHOR_TAG. the approach is', 'compared to a delexicalized baseline, which it outperforms by a large margin. it is also shown that, for faroese', ', a combination of the four source languages ( multi - source projection ) is superior to individual language projection']",5
"['segmented versions of the source translations 4 as  #TAUTHOR_TAG.', '5 in this']","['segmented versions of the source translations 4 as  #TAUTHOR_TAG.', '5 in this way, the experimental pipeline is the']","['segmented versions of the source translations 4 as  #TAUTHOR_TAG.', '5 in this way, the experimental pipeline is the']","['outline the process used for creating a synthetic treebank for cross - lingual dependency parsing.', 'we use the following resources : raw faroese sentences taken from wikipedia, a machine translation system to translate these sentences into all source languages ( danish, swedish, norwegian nynorsk and norwegian bokmal ), a word - aligner to provide word alignments between the words in the target and source sentences, treebanks for the four source languages on which to train parsing models, pos tagging and parsing tools, and, lastly a target language test set.', 'we use the same raw corpus, alignments and tokenized and segmented versions of the source translations 4 as  #TAUTHOR_TAG.', '5 in this way, the experimental pipeline is the same as  #TAUTHOR_TAG but we predict pos tags and dependency annotations using our own models']",5
"['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were extracted']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were extracted from faroese wikipedia dumps 6 using the wikiextractor script 7 and further pre - processed to remove any non - faroese texts and other forms of unsuitable sentences.', 'machine translation as noted by  #TAUTHOR_TAG, popular repositories for developing machine translation systems such as opus  #AUTHOR_TAG contain an inadequate amount of sentences to train a data - driven machine translation system for faroese.', 'for instance, there are fewer than 7, 000 sentence pairs between faroese and danish, faroese and english, faroese and norwegian and faroese and swedish.', 'consequently, to create parallel source sentences,  #TAUTHOR_TAG use a rule - based machine translation system available in apertium 8 to translate from faroese to norwegian bokmal.', 'there also exists translation systems from norwegian bokmal to norwegian nynorsk, swedish and danish in apertium.', 'as a result, the authors use pivot translation from norwegian bokmal into the other source languages.', 'the process is illustrated in fig. 1.', 'for a more thorough description of the machine translation process and for resource creation in general, see the work of  #TAUTHOR_TAG']",5
"['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between']","['the translations are parsed, the annotations are then projected from the source translations to the target language using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between the target index and the source index. there are also cases where', 'there is a mismatch in length between the source and target sentences and some dependency structures cannot be projected to the target language.  #TAUTHOR_TAG removes unsuitable projected trees containing e. g. more than one root token, a token that is its own head or a token with a head outside the range', 'of the sentence. multi - source projection for multi - source projection, the four source - language dependency trees for a faroese sentence are projected into a single graph, scoring edges', 'according to the number of trees that contain them  #AUTHOR_TAG. the dependency structure is', 'first built by voting over the directed edges. afterward, dependency labels and pos tags are decided using the same voting procedure. the process is illustrated in fig. 3. target tagging and parsing models at this stage we have', 'faroese treebanks to train our pos tagging and parsing models. the faroese treebanks come in two variants : the result of projection from source trees produced by either', '1 ) a monolingual, or 2 ) the polyglot model. for', 'each case, we train our pos tagging and parsing models directly on these synthetic treebanks and do', 'not make use of word embeddings as we do not have them for faroese. multi - treebank target parsing since', 'we have several synthetic faroese treebanks, we have the option of training on a single treebank or using a multi', '- treebank approach where we train on all target treebank', '##s in the same way as we did for inducing the polyglot source model. the process is illustrated in fig. 4. when training a multi - treebank target model', ', for each target treebank, we', 'add a treebank embedding denoting the source model used to project annotations to the target treebank. at predict', 'time, we must include one of these treebank embeddings as input to the model. as we do not have real faroese data in our target training treebanks, we must choose the treebank embedding of one of', 'the synthetic target treebanks. introduce the term "" proxy treebank "" to refer to cases where the test treebank is not', 'in the training set and a treebank embedding from the training set must', 'be used instead']",5
"['this section, we describe our experiments, which include a replication of the main findings of  #TAUTHOR_TAG, using allennlp']","['this section, we describe our experiments, which include a replication of the main findings of  #TAUTHOR_TAG, using allennlp']","['this section, we describe our experiments, which include a replication of the main findings of  #TAUTHOR_TAG, using allennlp']","['this section, we describe our experiments, which include a replication of the main findings of  #TAUTHOR_TAG, using allennlp for pos tagging and parsing instead of udpipe ( straka and strakova, 2017 figure 3 : multi - source projection.', 'the source language is listed in brackets']",5
['4  #TAUTHOR_TAG our best model 71'],"['version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large number of sentences. however, norwegian nynorsk still outperforms the multi - source model for the monolingual setting and both norwegian models perform better than the multi -', 'source model in the polyglot setting, suggesting that size alone does not explain the under - performance of the', 'multi - source model. it is also worth noting that polyg']","[', we see that las scores tend to be slightly lower than', 'on the version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large']","['table 5. comparing the results in tables 4 and 5, we see that las scores tend to be slightly lower than', 'on the version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large number of sentences. however, norwegian nynorsk still outperforms the multi - source model for the monolingual setting and both norwegian models perform better than the multi -', 'source model in the polyglot setting, suggesting that size alone does not explain the under - performance of the', 'multi - source model. it is also worth noting that polyglot training is superior to all monolingual models which hints that for', 'no nynorsk ( the previously better performing model ), the monolingual model was not able to achieve its full potential with the reduced data while the polyglot model was able to provide richer annotations. another reason', 'why the multi - source model does not work as well in our experiments as', 'it does in those of  #TAUTHOR_TAG do not. in this way, our monolingual models are stronger and likely do not', 'benefit as much from voting. the second result column ( multi ) of table 4 shows the effect of training a multi - treebank pos tagger and parser on', '']",5
"['by  #TAUTHOR_TAG - was', '']","['by  #TAUTHOR_TAG - was', '']","['over the result reported by  #TAUTHOR_TAG - was', 'achieved with multi - tree']","['is still available and training data is not reduced to cases where all source languages provide a projection. in other words, we aim to investigate whether the current state - of - the - art approach for faroese, which relies on cross - lingual transfer, can be improved upon by adopting an approach based on source - side polyglot learning', 'and / or target - side multi - treebank learning. we hypothesize that a polyglot model can exploit similarities in', 'morphology and syntax across the included source languages, which will result in a better model to provide annotations for projection. on the target side, we expect that combining different sources of information will result in a more robust target model. we evaluated our various models on the faroese test set and experienced considerable gains for', 'three of the four source languages ( danish, norwegian bokmal and swedish ) by adopting a polyglot model. however, for norwegian nynorsk, a', 'stronger monolingual model was able to outperform the polyglot approach. when we extended multi - treebank learning to the target side, we experienced additional gains for all cases. our best result of 71. 5 - an absolute improvement of 7. 2 points over the result reported by  #TAUTHOR_TAG - was', 'achieved with multi - treebank target learning over the monolingual projections.  #TAUTHOR_TAG describe a method for creating synthetic treebanks for faroese based on previous work which uses machine translation and word alignments to transfer trees from source language ( s ) to the target language.', 'sentences from faroese are translated into the four source languages danish, swedish, norwegian nynorsk', 'and norwegian bokmal. the translated sentences are then tokenized, pos tagged and parsed using the relevant source language model trained on the source language treebank. the resulting trees are projected back to the faroese sentences using word alignments. the four trees for each sentence are combined into a', 'graph with edge scores one to four ( the number of trees that support them ), from which a single tree per sentence is produced using the chu - liu - edmonds algorithm  #AUTHOR_TAG', '. the resulting trees make up a synthetic treebank for faroese which is then used to train a faroe', '##se parsing model. the parser output is evaluated using the gold - standard faroese test treebank developed by  #TAUTHOR_TAG. the approach is', 'compared to a delexicalized baseline, which it outperforms by a large margin. it is also shown that, for faroese', ', a combination of the four source languages ( multi - source projection ) is superior to individual language projection']",6
"['by  #TAUTHOR_TAG - was', '']","['by  #TAUTHOR_TAG - was', '']","['over the result reported by  #TAUTHOR_TAG - was', 'achieved with multi - tree']","['is still available and training data is not reduced to cases where all source languages provide a projection. in other words, we aim to investigate whether the current state - of - the - art approach for faroese, which relies on cross - lingual transfer, can be improved upon by adopting an approach based on source - side polyglot learning', 'and / or target - side multi - treebank learning. we hypothesize that a polyglot model can exploit similarities in', 'morphology and syntax across the included source languages, which will result in a better model to provide annotations for projection. on the target side, we expect that combining different sources of information will result in a more robust target model. we evaluated our various models on the faroese test set and experienced considerable gains for', 'three of the four source languages ( danish, norwegian bokmal and swedish ) by adopting a polyglot model. however, for norwegian nynorsk, a', 'stronger monolingual model was able to outperform the polyglot approach. when we extended multi - treebank learning to the target side, we experienced additional gains for all cases. our best result of 71. 5 - an absolute improvement of 7. 2 points over the result reported by  #TAUTHOR_TAG - was', 'achieved with multi - treebank target learning over the monolingual projections.  #TAUTHOR_TAG describe a method for creating synthetic treebanks for faroese based on previous work which uses machine translation and word alignments to transfer trees from source language ( s ) to the target language.', 'sentences from faroese are translated into the four source languages danish, swedish, norwegian nynorsk', 'and norwegian bokmal. the translated sentences are then tokenized, pos tagged and parsed using the relevant source language model trained on the source language treebank. the resulting trees are projected back to the faroese sentences using word alignments. the four trees for each sentence are combined into a', 'graph with edge scores one to four ( the number of trees that support them ), from which a single tree per sentence is produced using the chu - liu - edmonds algorithm  #AUTHOR_TAG', '. the resulting trees make up a synthetic treebank for faroese which is then used to train a faroe', '##se parsing model. the parser output is evaluated using the gold - standard faroese test treebank developed by  #TAUTHOR_TAG. the approach is', 'compared to a delexicalized baseline, which it outperforms by a large margin. it is also shown that, for faroese', ', a combination of the four source languages ( multi - source projection ) is superior to individual language projection']",3
"['segmented versions of the source translations 4 as  #TAUTHOR_TAG.', '5 in this']","['segmented versions of the source translations 4 as  #TAUTHOR_TAG.', '5 in this way, the experimental pipeline is the']","['segmented versions of the source translations 4 as  #TAUTHOR_TAG.', '5 in this way, the experimental pipeline is the']","['outline the process used for creating a synthetic treebank for cross - lingual dependency parsing.', 'we use the following resources : raw faroese sentences taken from wikipedia, a machine translation system to translate these sentences into all source languages ( danish, swedish, norwegian nynorsk and norwegian bokmal ), a word - aligner to provide word alignments between the words in the target and source sentences, treebanks for the four source languages on which to train parsing models, pos tagging and parsing tools, and, lastly a target language test set.', 'we use the same raw corpus, alignments and tokenized and segmented versions of the source translations 4 as  #TAUTHOR_TAG.', '5 in this way, the experimental pipeline is the same as  #TAUTHOR_TAG but we predict pos tags and dependency annotations using our own models']",3
['4  #TAUTHOR_TAG our best model 71'],"['version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large number of sentences. however, norwegian nynorsk still outperforms the multi - source model for the monolingual setting and both norwegian models perform better than the multi -', 'source model in the polyglot setting, suggesting that size alone does not explain the under - performance of the', 'multi - source model. it is also worth noting that polyg']","[', we see that las scores tend to be slightly lower than', 'on the version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large']","['table 5. comparing the results in tables 4 and 5, we see that las scores tend to be slightly lower than', 'on the version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large number of sentences. however, norwegian nynorsk still outperforms the multi - source model for the monolingual setting and both norwegian models perform better than the multi -', 'source model in the polyglot setting, suggesting that size alone does not explain the under - performance of the', 'multi - source model. it is also worth noting that polyglot training is superior to all monolingual models which hints that for', 'no nynorsk ( the previously better performing model ), the monolingual model was not able to achieve its full potential with the reduced data while the polyglot model was able to provide richer annotations. another reason', 'why the multi - source model does not work as well in our experiments as', 'it does in those of  #TAUTHOR_TAG do not. in this way, our monolingual models are stronger and likely do not', 'benefit as much from voting. the second result column ( multi ) of table 4 shows the effect of training a multi - treebank pos tagger and parser on', '']",3
"['by  #TAUTHOR_TAG - was', '']","['by  #TAUTHOR_TAG - was', '']","['over the result reported by  #TAUTHOR_TAG - was', 'achieved with multi - tree']","['is still available and training data is not reduced to cases where all source languages provide a projection. in other words, we aim to investigate whether the current state - of - the - art approach for faroese, which relies on cross - lingual transfer, can be improved upon by adopting an approach based on source - side polyglot learning', 'and / or target - side multi - treebank learning. we hypothesize that a polyglot model can exploit similarities in', 'morphology and syntax across the included source languages, which will result in a better model to provide annotations for projection. on the target side, we expect that combining different sources of information will result in a more robust target model. we evaluated our various models on the faroese test set and experienced considerable gains for', 'three of the four source languages ( danish, norwegian bokmal and swedish ) by adopting a polyglot model. however, for norwegian nynorsk, a', 'stronger monolingual model was able to outperform the polyglot approach. when we extended multi - treebank learning to the target side, we experienced additional gains for all cases. our best result of 71. 5 - an absolute improvement of 7. 2 points over the result reported by  #TAUTHOR_TAG - was', 'achieved with multi - treebank target learning over the monolingual projections.  #TAUTHOR_TAG describe a method for creating synthetic treebanks for faroese based on previous work which uses machine translation and word alignments to transfer trees from source language ( s ) to the target language.', 'sentences from faroese are translated into the four source languages danish, swedish, norwegian nynorsk', 'and norwegian bokmal. the translated sentences are then tokenized, pos tagged and parsed using the relevant source language model trained on the source language treebank. the resulting trees are projected back to the faroese sentences using word alignments. the four trees for each sentence are combined into a', 'graph with edge scores one to four ( the number of trees that support them ), from which a single tree per sentence is produced using the chu - liu - edmonds algorithm  #AUTHOR_TAG', '. the resulting trees make up a synthetic treebank for faroese which is then used to train a faroe', '##se parsing model. the parser output is evaluated using the gold - standard faroese test treebank developed by  #TAUTHOR_TAG. the approach is', 'compared to a delexicalized baseline, which it outperforms by a large margin. it is also shown that, for faroese', ', a combination of the four source languages ( multi - source projection ) is superior to individual language projection']",0
"['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were extracted']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were extracted from faroese wikipedia dumps 6 using the wikiextractor script 7 and further pre - processed to remove any non - faroese texts and other forms of unsuitable sentences.', 'machine translation as noted by  #TAUTHOR_TAG, popular repositories for developing machine translation systems such as opus  #AUTHOR_TAG contain an inadequate amount of sentences to train a data - driven machine translation system for faroese.', 'for instance, there are fewer than 7, 000 sentence pairs between faroese and danish, faroese and english, faroese and norwegian and faroese and swedish.', 'consequently, to create parallel source sentences,  #TAUTHOR_TAG use a rule - based machine translation system available in apertium 8 to translate from faroese to norwegian bokmal.', 'there also exists translation systems from norwegian bokmal to norwegian nynorsk, swedish and danish in apertium.', 'as a result, the authors use pivot translation from norwegian bokmal into the other source languages.', 'the process is illustrated in fig. 1.', 'for a more thorough description of the machine translation process and for resource creation in general, see the work of  #TAUTHOR_TAG']",0
"['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were extracted']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were extracted from faroese wikipedia dumps 6 using the wikiextractor script 7 and further pre - processed to remove any non - faroese texts and other forms of unsuitable sentences.', 'machine translation as noted by  #TAUTHOR_TAG, popular repositories for developing machine translation systems such as opus  #AUTHOR_TAG contain an inadequate amount of sentences to train a data - driven machine translation system for faroese.', 'for instance, there are fewer than 7, 000 sentence pairs between faroese and danish, faroese and english, faroese and norwegian and faroese and swedish.', 'consequently, to create parallel source sentences,  #TAUTHOR_TAG use a rule - based machine translation system available in apertium 8 to translate from faroese to norwegian bokmal.', 'there also exists translation systems from norwegian bokmal to norwegian nynorsk, swedish and danish in apertium.', 'as a result, the authors use pivot translation from norwegian bokmal into the other source languages.', 'the process is illustrated in fig. 1.', 'for a more thorough description of the machine translation process and for resource creation in general, see the work of  #TAUTHOR_TAG']",0
"['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were extracted']","['use the target corpus built by  #TAUTHOR_TAG which comprises 28, 862 sentences which were extracted from faroese wikipedia dumps 6 using the wikiextractor script 7 and further pre - processed to remove any non - faroese texts and other forms of unsuitable sentences.', 'machine translation as noted by  #TAUTHOR_TAG, popular repositories for developing machine translation systems such as opus  #AUTHOR_TAG contain an inadequate amount of sentences to train a data - driven machine translation system for faroese.', 'for instance, there are fewer than 7, 000 sentence pairs between faroese and danish, faroese and english, faroese and norwegian and faroese and swedish.', 'consequently, to create parallel source sentences,  #TAUTHOR_TAG use a rule - based machine translation system available in apertium 8 to translate from faroese to norwegian bokmal.', 'there also exists translation systems from norwegian bokmal to norwegian nynorsk, swedish and danish in apertium.', 'as a result, the authors use pivot translation from norwegian bokmal into the other source languages.', 'the process is illustrated in fig. 1.', 'for a more thorough description of the machine translation process and for resource creation in general, see the work of  #TAUTHOR_TAG']",0
"['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between']","['the translations are parsed, the annotations are then projected from the source translations to the target language using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between the target index and the source index. there are also cases where', 'there is a mismatch in length between the source and target sentences and some dependency structures cannot be projected to the target language.  #TAUTHOR_TAG removes unsuitable projected trees containing e. g. more than one root token, a token that is its own head or a token with a head outside the range', 'of the sentence. multi - source projection for multi - source projection, the four source - language dependency trees for a faroese sentence are projected into a single graph, scoring edges', 'according to the number of trees that contain them  #AUTHOR_TAG. the dependency structure is', 'first built by voting over the directed edges. afterward, dependency labels and pos tags are decided using the same voting procedure. the process is illustrated in fig. 3. target tagging and parsing models at this stage we have', 'faroese treebanks to train our pos tagging and parsing models. the faroese treebanks come in two variants : the result of projection from source trees produced by either', '1 ) a monolingual, or 2 ) the polyglot model. for', 'each case, we train our pos tagging and parsing models directly on these synthetic treebanks and do', 'not make use of word embeddings as we do not have them for faroese. multi - treebank target parsing since', 'we have several synthetic faroese treebanks, we have the option of training on a single treebank or using a multi', '- treebank approach where we train on all target treebank', '##s in the same way as we did for inducing the polyglot source model. the process is illustrated in fig. 4. when training a multi - treebank target model', ', for each target treebank, we', 'add a treebank embedding denoting the source model used to project annotations to the target treebank. at predict', 'time, we must include one of these treebank embeddings as input to the model. as we do not have real faroese data in our target training treebanks, we must choose the treebank embedding of one of', 'the synthetic target treebanks. introduce the term "" proxy treebank "" to refer to cases where the test treebank is not', 'in the training set and a treebank embedding from the training set must', 'be used instead']",0
"['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between']","['the translations are parsed, the annotations are then projected from the source translations to the target language using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between the target index and the source index. there are also cases where', 'there is a mismatch in length between the source and target sentences and some dependency structures cannot be projected to the target language.  #TAUTHOR_TAG removes unsuitable projected trees containing e. g. more than one root token, a token that is its own head or a token with a head outside the range', 'of the sentence. multi - source projection for multi - source projection, the four source - language dependency trees for a faroese sentence are projected into a single graph, scoring edges', 'according to the number of trees that contain them  #AUTHOR_TAG. the dependency structure is', 'first built by voting over the directed edges. afterward, dependency labels and pos tags are decided using the same voting procedure. the process is illustrated in fig. 3. target tagging and parsing models at this stage we have', 'faroese treebanks to train our pos tagging and parsing models. the faroese treebanks come in two variants : the result of projection from source trees produced by either', '1 ) a monolingual, or 2 ) the polyglot model. for', 'each case, we train our pos tagging and parsing models directly on these synthetic treebanks and do', 'not make use of word embeddings as we do not have them for faroese. multi - treebank target parsing since', 'we have several synthetic faroese treebanks, we have the option of training on a single treebank or using a multi', '- treebank approach where we train on all target treebank', '##s in the same way as we did for inducing the polyglot source model. the process is illustrated in fig. 4. when training a multi - treebank target model', ', for each target treebank, we', 'add a treebank embedding denoting the source model used to project annotations to the target treebank. at predict', 'time, we must include one of these treebank embeddings as input to the model. as we do not have real faroese data in our target training treebanks, we must choose the treebank embedding of one of', 'the synthetic target treebanks. introduce the term "" proxy treebank "" to refer to cases where the test treebank is not', 'in the training set and a treebank embedding from the training set must', 'be used instead']",0
"['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between']","['the translations are parsed, the annotations are then projected from the source translations to the target language using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between the target index and the source index. there are also cases where', 'there is a mismatch in length between the source and target sentences and some dependency structures cannot be projected to the target language.  #TAUTHOR_TAG removes unsuitable projected trees containing e. g. more than one root token, a token that is its own head or a token with a head outside the range', 'of the sentence. multi - source projection for multi - source projection, the four source - language dependency trees for a faroese sentence are projected into a single graph, scoring edges', 'according to the number of trees that contain them  #AUTHOR_TAG. the dependency structure is', 'first built by voting over the directed edges. afterward, dependency labels and pos tags are decided using the same voting procedure. the process is illustrated in fig. 3. target tagging and parsing models at this stage we have', 'faroese treebanks to train our pos tagging and parsing models. the faroese treebanks come in two variants : the result of projection from source trees produced by either', '1 ) a monolingual, or 2 ) the polyglot model. for', 'each case, we train our pos tagging and parsing models directly on these synthetic treebanks and do', 'not make use of word embeddings as we do not have them for faroese. multi - treebank target parsing since', 'we have several synthetic faroese treebanks, we have the option of training on a single treebank or using a multi', '- treebank approach where we train on all target treebank', '##s in the same way as we did for inducing the polyglot source model. the process is illustrated in fig. 4. when training a multi - treebank target model', ', for each target treebank, we', 'add a treebank embedding denoting the source model used to project annotations to the target treebank. at predict', 'time, we must include one of these treebank embeddings as input to the model. as we do not have real faroese data in our target training treebanks, we must choose the treebank embedding of one of', 'the synthetic target treebanks. introduce the term "" proxy treebank "" to refer to cases where the test treebank is not', 'in the training set and a treebank embedding from the training set must', 'be used instead']",0
"['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a']","['using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between']","['the translations are parsed, the annotations are then projected from the source translations to the target language using the word alignments and  #TAUTHOR_TAG, resulting in a faroe', '##se', 'treebank. in some cases, not all tokens are aligned and  #TAUTHOR_TAG work around this by falling back to a 1', ': 1 mapping between the target index and the source index. there are also cases where', 'there is a mismatch in length between the source and target sentences and some dependency structures cannot be projected to the target language.  #TAUTHOR_TAG removes unsuitable projected trees containing e. g. more than one root token, a token that is its own head or a token with a head outside the range', 'of the sentence. multi - source projection for multi - source projection, the four source - language dependency trees for a faroese sentence are projected into a single graph, scoring edges', 'according to the number of trees that contain them  #AUTHOR_TAG. the dependency structure is', 'first built by voting over the directed edges. afterward, dependency labels and pos tags are decided using the same voting procedure. the process is illustrated in fig. 3. target tagging and parsing models at this stage we have', 'faroese treebanks to train our pos tagging and parsing models. the faroese treebanks come in two variants : the result of projection from source trees produced by either', '1 ) a monolingual, or 2 ) the polyglot model. for', 'each case, we train our pos tagging and parsing models directly on these synthetic treebanks and do', 'not make use of word embeddings as we do not have them for faroese. multi - treebank target parsing since', 'we have several synthetic faroese treebanks, we have the option of training on a single treebank or using a multi', '- treebank approach where we train on all target treebank', '##s in the same way as we did for inducing the polyglot source model. the process is illustrated in fig. 4. when training a multi - treebank target model', ', for each target treebank, we', 'add a treebank embedding denoting the source model used to project annotations to the target treebank. at predict', 'time, we must include one of these treebank embeddings as input to the model. as we do not have real faroese data in our target training treebanks, we must choose the treebank embedding of one of', 'the synthetic target treebanks. introduce the term "" proxy treebank "" to refer to cases where the test treebank is not', 'in the training set and a treebank embedding from the training set must', 'be used instead']",0
['4  #TAUTHOR_TAG our best model 71'],"['version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large number of sentences. however, norwegian nynorsk still outperforms the multi - source model for the monolingual setting and both norwegian models perform better than the multi -', 'source model in the polyglot setting, suggesting that size alone does not explain the under - performance of the', 'multi - source model. it is also worth noting that polyg']","[', we see that las scores tend to be slightly lower than', 'on the version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large']","['table 5. comparing the results in tables 4 and 5, we see that las scores tend to be slightly lower than', 'on the version which included all target sen - work result rosa and marecek ( 2018 ) 49. 4  #TAUTHOR_TAG our best model 71. 5 tences, indicating that we did lose some information by filtering out a large number of sentences. however, norwegian nynorsk still outperforms the multi - source model for the monolingual setting and both norwegian models perform better than the multi -', 'source model in the polyglot setting, suggesting that size alone does not explain the under - performance of the', 'multi - source model. it is also worth noting that polyglot training is superior to all monolingual models which hints that for', 'no nynorsk ( the previously better performing model ), the monolingual model was not able to achieve its full potential with the reduced data while the polyglot model was able to provide richer annotations. another reason', 'why the multi - source model does not work as well in our experiments as', 'it does in those of  #TAUTHOR_TAG do not. in this way, our monolingual models are stronger and likely do not', 'benefit as much from voting. the second result column ( multi ) of table 4 shows the effect of training a multi - treebank pos tagger and parser on', '']",0
['year  #TAUTHOR_TAG for english -'],"['year  #TAUTHOR_TAG for english - to - hindi machine transliteration.', 'compared']",['last year  #TAUTHOR_TAG for english -'],"['focus of significant previous work in machine transliteration, including that presented at past news shared tasks  #AUTHOR_TAG b ), has been on single transliteration tasks in isolation of other other languages.', 'this is despite the fact that the various languages provided represent a significant quantity of potentially useful data that is being ignored.', 'in this news 2011 shared task submission, we present a method which beneficially applies supplemental transliterations from other languages to english - to - hindi transliteration.', 'in practice, this is a realistic situation in which transliterations from other languages can help.', 'for example, wikipedia contains articles on guitarist john petrucci in english and japanese, but not in hindi.', 'if we wanted to automatically generate a stub ( skeleton ) article in hindi, we would need to transliterate his name into hindi.', 'since a japanese version already exists, we could extract from it additional information to help with the transliteration process.', 'importantly, since our article is about an american guitarist, we would explicitly want to start with the english ( original ) version of the name, and treat other languages as extra data, rather than vice versa.', 'in order to effectively incorporate the otherlanguage data, we apply svm re - ranking in a manner that has previously been shown to provide significant improvement for grapheme - to - phoneme conversion  #AUTHOR_TAG.', 'this method is flexible enough to incorporate multiple languages ; it employs features based on character alignments between potential outputs and existing transliterations from other languages, as well as scores of these alignments, which serve as a measure of similarity.', 'we apply this approach on top of the same directl + system as submitted last year  #TAUTHOR_TAG for english - to - hindi machine transliteration.', 'compared to the base di - rectl + performance, we are able to achieve significantly better results, with a relative performance increase of over 10 %.', ""we also achieve improvements without supplemental transliterations by simply apply the same approach with another system's output as extra data."", 'we furthermore experiment with romanization for hindi data as well as different alignment length settings for english - tochinese transliteration.', 'this paper presents methods, methodology, and results for the above experiments']",0
"['on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - rank']","['on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of unseen']","['shared task on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of']","['principal base system that generates the n - best output lists is directl +, which has produced excellent results in the news 2010 shared task on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of unseen data so that the re - ranker does not simply learn to follow the base system ; we therefore split the training data into ten folds and perform a sort - of cross validation with directl +.', 'this provides us with usable training data for reranking.', ""we tune the svm's hyperparameter based on performance on the provided development data, and use the best directl + settings established in the news 2010 shared task  #TAUTHOR_TAG."", 'armed with optimal parameter settings, we combine the training and development data into a single set used to train our final directl + system.', 'we also repeat the cross - validation process for training the re - ranker.', 'we also apply the svm re - ranking approach to system combination.', 'in this case, we additionally train another system - here we use se - quitur  #AUTHOR_TAG - for english - tohindi transliteration.', 'during test time, we feed the input into both directl + and sequitur, and use the top sequitur output as supplemental data.', 'we expect that sometimes sequitur will provide a correct answer where directl + does not ; the hope is that the svm re - ranking approach will be able to learn when this is the case based on the n - gram and score features']",0
"['produced excellent results for machine transliteration  #TAUTHOR_TAG,']","['produced excellent results for machine transliteration  #TAUTHOR_TAG,']","['##honeme conversion, it produced excellent results for machine transliteration  #TAUTHOR_TAG,']","['are three lines of research that are relevant to the work we have presented in this paper : ( 1 ) di - rectl + and sequitur for machine transliteration ; ( 2 ) applying multiple languages ; and ( 3 ) system combination.', 'for the news 2009 and 2010 shared tasks, the discriminative directl + system that incorporates many - to - many alignments, online maxmargin training and a phrasal decoder was shown to function well as a general string transduction tool ; while originally designed for grapheme - tophoneme conversion, it produced excellent results for machine transliteration  #TAUTHOR_TAG, leading us to re - use it here.', ' #AUTHOR_TAG also submitted a top - performing system that was based in part on sequitur, which is a generative system based on joint n - gram modelling  #AUTHOR_TAG.', 'in this paper, we applied multiple transliteration languages to a single transliteration task.', 'while our method is based on svm re - ranking with similar features as to those used in the base system  #AUTHOR_TAG, there have been other explorations into incorporating other language data, particularly when data are scarce.', ' #AUTHOR_TAG, for example, apply a pivoting approach to machine transliteration, and similarly  #AUTHOR_TAG propose to transliterate through "" bridge "" languages.', 'along similar lines,  #AUTHOR_TAG a ) find increases in accuracy using a linear - combination - of - scores system that combined the outputs of a direct transliteration system with a system that transliterated through a third language.', 'for statistical machine translation,  #AUTHOR_TAG also explore the use of a third language.', ""finally, we also touched briefly on system combination : we applied the svm re - ranking method to combining the outputs of both directl + and sequitur, in particular treating directl + as the base system and using sequitur's best outputs to re - rank directl +'s output lists."", "" #AUTHOR_TAG, in contrast, combine sequitur's output with that of a phrase - based statistical machine translation system, achieving excellent results."", 'where our approach is based on svm reranking, theirs merged the outputs of the two systems together and then used a linear combination of the system scores to re - rank the combined list']",0
"['on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - rank']","['on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of unseen']","['shared task on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of']","['principal base system that generates the n - best output lists is directl +, which has produced excellent results in the news 2010 shared task on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of unseen data so that the re - ranker does not simply learn to follow the base system ; we therefore split the training data into ten folds and perform a sort - of cross validation with directl +.', 'this provides us with usable training data for reranking.', ""we tune the svm's hyperparameter based on performance on the provided development data, and use the best directl + settings established in the news 2010 shared task  #TAUTHOR_TAG."", 'armed with optimal parameter settings, we combine the training and development data into a single set used to train our final directl + system.', 'we also repeat the cross - validation process for training the re - ranker.', 'we also apply the svm re - ranking approach to system combination.', 'in this case, we additionally train another system - here we use se - quitur  #AUTHOR_TAG - for english - tohindi transliteration.', 'during test time, we feed the input into both directl + and sequitur, and use the top sequitur output as supplemental data.', 'we expect that sometimes sequitur will provide a correct answer where directl + does not ; the hope is that the svm re - ranking approach will be able to learn when this is the case based on the n - gram and score features']",5
"['produced excellent results for machine transliteration  #TAUTHOR_TAG,']","['produced excellent results for machine transliteration  #TAUTHOR_TAG,']","['##honeme conversion, it produced excellent results for machine transliteration  #TAUTHOR_TAG,']","['are three lines of research that are relevant to the work we have presented in this paper : ( 1 ) di - rectl + and sequitur for machine transliteration ; ( 2 ) applying multiple languages ; and ( 3 ) system combination.', 'for the news 2009 and 2010 shared tasks, the discriminative directl + system that incorporates many - to - many alignments, online maxmargin training and a phrasal decoder was shown to function well as a general string transduction tool ; while originally designed for grapheme - tophoneme conversion, it produced excellent results for machine transliteration  #TAUTHOR_TAG, leading us to re - use it here.', ' #AUTHOR_TAG also submitted a top - performing system that was based in part on sequitur, which is a generative system based on joint n - gram modelling  #AUTHOR_TAG.', 'in this paper, we applied multiple transliteration languages to a single transliteration task.', 'while our method is based on svm re - ranking with similar features as to those used in the base system  #AUTHOR_TAG, there have been other explorations into incorporating other language data, particularly when data are scarce.', ' #AUTHOR_TAG, for example, apply a pivoting approach to machine transliteration, and similarly  #AUTHOR_TAG propose to transliterate through "" bridge "" languages.', 'along similar lines,  #AUTHOR_TAG a ) find increases in accuracy using a linear - combination - of - scores system that combined the outputs of a direct transliteration system with a system that transliterated through a third language.', 'for statistical machine translation,  #AUTHOR_TAG also explore the use of a third language.', ""finally, we also touched briefly on system combination : we applied the svm re - ranking method to combining the outputs of both directl + and sequitur, in particular treating directl + as the base system and using sequitur's best outputs to re - rank directl +'s output lists."", "" #AUTHOR_TAG, in contrast, combine sequitur's output with that of a phrase - based statistical machine translation system, achieving excellent results."", 'where our approach is based on svm reranking, theirs merged the outputs of the two systems together and then used a linear combination of the system scores to re - rank the combined list']",5
"['on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - rank']","['on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of unseen']","['shared task on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of']","['principal base system that generates the n - best output lists is directl +, which has produced excellent results in the news 2010 shared task on transliteration  #TAUTHOR_TAG.', 'for re - ranking, note that training a re - ranker requires training data where the base system scores are representative of unseen data so that the re - ranker does not simply learn to follow the base system ; we therefore split the training data into ten folds and perform a sort - of cross validation with directl +.', 'this provides us with usable training data for reranking.', ""we tune the svm's hyperparameter based on performance on the provided development data, and use the best directl + settings established in the news 2010 shared task  #TAUTHOR_TAG."", 'armed with optimal parameter settings, we combine the training and development data into a single set used to train our final directl + system.', 'we also repeat the cross - validation process for training the re - ranker.', 'we also apply the svm re - ranking approach to system combination.', 'in this case, we additionally train another system - here we use se - quitur  #AUTHOR_TAG - for english - tohindi transliteration.', 'during test time, we feed the input into both directl + and sequitur, and use the top sequitur output as supplemental data.', 'we expect that sometimes sequitur will provide a correct answer where directl + does not ; the hope is that the svm re - ranking approach will be able to learn when this is the case based on the n - gram and score features']",6
"['of romanization to japanese  #TAUTHOR_TAG, demonstrating that it is not always possible to transfer an idea from one language to another']","['of romanization to japanese  #TAUTHOR_TAG, demonstrating that it is not always possible to transfer an idea from one language to another']","['', 'this differs from the results of the successful application of romanization to japanese  #TAUTHOR_TAG, demonstrating that it is not always possible to transfer an idea from one language to another']","['addition to the above re - ranking approach, we experimented with a romanization method for the hindi data.', 'since consonant characters in the devanagari alphabet have vowels included by default, we romanize the text in order to provide directl + with direct individual control over the consonant and vowel components of the hindi characters.', 'the default vowel is changed by means of diacriticlike characters, which in turn deletes the default vowel ; this requires a context - sensitive ( but still rule - based ) romanization method, which we construct manually.', 'we then train directl + on the romanized data ; during testing, we take the romanized output and convert it back into devanagari unicode characters, again using a manuallyconstructed context - sensitive rule - based converter.', 'table 2 shows that svm re - ranking significantly improves the english - to - hindi transliteration accuracy in comparison with the base system.', 'leveraging all of the english - source transliteration corpora as supplemental data yields an increase of over 10 %.', 'when applied using sequitur\'s output as "" supplemental "" data, we see almost a 5 % ( relative ) increase in word accuracy.', 'in contrast, our hindi romanization approach decreases the accuracy.', 'this differs from the results of the successful application of romanization to japanese  #TAUTHOR_TAG, demonstrating that it is not always possible to transfer an idea from one language to another']",4
"[', "" and di  #TAUTHOR_TAG relate reliability to']","['to "" assess labelling accuracy, "" and di  #TAUTHOR_TAG relate reliability to "" the']","[', "" and di  #TAUTHOR_TAG relate reliability to']","['', 'for example, the coding manual for the switchboard damsl dialogue act annotation scheme ( jurafsky, shriberg, and biasca 1997, page 2 ) states that kappa is used to "" assess labelling accuracy, "" and di  #TAUTHOR_TAG relate reliability to "" the objectivity of decisions, "" whereas  #AUTHOR_TAG regards reliability as the degree to which we understand the judgments that annotators are asked to make.', 'although most researchers recognize that reporting agreement statistics is an important part of evaluating coding schemes, there is frequently a lack of understanding of what the figures actually mean.', '']",0
"['coding scheme.', 'di  #TAUTHOR_TAG identify three general classes of agreement statistics']","['coding scheme.', 'di  #TAUTHOR_TAG identify three general classes of agreement statistics']","['the reliability of the coding scheme.', 'di  #TAUTHOR_TAG identify three general classes of agreement statistics']","['are many ways in which the level of agreement between coders can be evaluated, and the choice of which to apply in order to assess reliability is the source of much confusion.', 'an appropriate statistic for this purpose must measure agreement as a function of the coding process and not of the coders, data, or categories.', 'only if the results of a test are solely dependent on the degree to which there is a shared understanding of how the phenomena to be described are mapped to the given categories can we infer the reliability of the resulting data.', 'some agreement measures do not behave in this manner and are therefore unsuitable for evaluating reliability.', 'a great deal of importance is placed on domain specificity in discourse and dialogue studies and as such, researchers are often encouraged to evaluate schemes using corpora from more than one domain.', 'concerning agreement, this encouragement is misplaced.', 'since an appropriate agreement measure is a function of only the coding process, if the original agreement test is performed in a scientifically sound manner, little more can be proved by applying it again to different data.', 'any differences in the results between corpora are a function of the variance between samples and not of the reliability of the coding scheme.', 'di  #TAUTHOR_TAG identify three general classes of agreement statistics and suggest that all three should be used in conjunction in order to accurately evaluate coding schemes.', 'however, this suggestion is founded on some misunderstandings of the role of agreement measure in reliability studies.', 'we shall now rectify these and conclude that only one class of agreement measure is suitable']",0
['di  #TAUTHOR_TAG referred to'],['di  #TAUTHOR_TAG referred to'],['di  #TAUTHOR_TAG referred to'],"['first of the recommended agreement tests, percentage agreement, measures the proportion of agreements between coders.', 'this is an unsuitable measure for inferring reliability, and it was the use of this measure that prompted  #AUTHOR_TAG to recommend chance - corrected measures.', 'percentage agreement is inappropriate for inferring reliability because it excludes any notion of the level of agreement that we could expect to achieve by chance.', 'reliability should be inferred by locating the achieved level of agreement on a scale between the best possible ( coders agree perfectly ) and the worst possible ( coders do not understand or cannot perform the mapping and behave randomly ).', 'without any indication of the agreement that coders would achieve by behaving randomly, any deviation from perfect agreement is uninterpretable ( krippendorff 2004b ).', 'the justification given for using percentage agreement is that it does not suffer from what di  #TAUTHOR_TAG referred to as the "" prevalence problem.', '"" prevalence refers to the unequal distribution of label use by coders.', 'for example, table 1 shows an example taken from di  #TAUTHOR_TAG showing the classification of the utterance okay as an acceptance or acknowledgment.', 'it represents a confusion matrix describing the number of occasions that coders used pairs of labels for a given turn.', 'this table shows that the two coders favored the use of accept strongly over acknowledge.', 'they correctly state that this skew in the distribution of categories increases the expected chance agreement, thus lowering the overall agreement in chance - corrected tests.', ""the reason for this is that since one category is more popular than others, the likelihood of coders'agreeing by chance by choosing this category increases."", 'we therefore require a comparable increase in observed agreement to accommodate this.', 'di  #TAUTHOR_TAG perceive this as an "" unpleasant behavior "" of chancecorrected tests, one that prevents us from concluding that the example given in table 1 shows satisfactory levels of agreement.', 'instead they use percentage agreement to arrive at this conclusion.', 'by examining the data, it is clear that this conclusion would be false.', 'in table 1, the coders agree 90 out of 100 times, but all agreements occur when both coders choose accept.', ""there is not a single case in which they agree on okay's being used as an acknowledgment."", 'the only conclusion one may justifiably draw is that the coders cannot distinguish the use of okay as an acceptance from its use as an acknowledgment.', 'rather than being an unpleasant behavior, accounting for prevalence in the data is']",0
"['second class of agreement measure recommended in di  #TAUTHOR_TAG is that of chance - corrected tests that do not assume an equal distribution of categories between coders.', 'chance - corrected tests compute agreement according to']","['second class of agreement measure recommended in di  #TAUTHOR_TAG is that of chance - corrected tests that do not assume an equal distribution of categories between coders.', 'chance - corrected tests compute agreement according to']","['second class of agreement measure recommended in di  #TAUTHOR_TAG is that of chance - corrected tests that do not assume an equal distribution of categories between coders.', 'chance - corrected tests compute agreement according to the ratio of observed ( dis ) agreement to']","['second class of agreement measure recommended in di  #TAUTHOR_TAG is that of chance - corrected tests that do not assume an equal distribution of categories between coders.', 'chance - corrected tests compute agreement according to the ratio of observed ( dis ) agreement to that which we could expect by chance, estimated from the data.', 'the measures differ in the way in which this expected ( dis ) agreement is estimated.', 'those that do not assume an equal distribution between coders calculate expected ( dis ) agreement based on the individual distribution of each coder.', 'the concern that in discourse and dialogue coding, coders will differ in the frequency with which they apply labels leads di eugenio and glass to conclude that  #AUTHOR_TAG kappa is the best chance - corrected test to apply.', 'to clarify, by unequal distribution of categories, we do not refer to the disparity in the frequency with which categories occur ( e. g., verbs are more common than pronouns ) but rather to the difference in proclivity between coders ( e. g., coder a is more likely to label something a noun than coder b ).', ""cohen's kappa calculates expected chance agreement, based on the individual coders'distributions, in a manner similar to association measures, such as chi - square."", 'this means that its results are dependent on the preferences of the individual coders taking part in the tests.', 'this violates the condition set out at the beginning of this section whereby agreement must be a function of the coding process, with coders being viewed as interchangeable.', 'the purpose of assessing the reliability of coding schemes is not to judge the performance of the small number of individuals participating in the trial, but rather to predict the performance of the schemes in general.', ""the proposal that in most discourse and dialogue studies, the assumption of equal distribution between coders does not hold is, in fact, an argument against the use of cohen's kappa."", 'assessing the agreement between coders and accounting for their idiosyncratic proclivity toward or against certain labels tells us little about how the coding scheme will perform when applied by others.', 'the solution is not to apply a test that panders to individual differences, but rather to increase the number of coders so that the influence of any individual on the final result becomes less pronounced']",0
"['ratio values, among others.', 'di  #TAUTHOR_TAG conclude with the proposal that these']","['ratio values, among others.', 'di  #TAUTHOR_TAG conclude with the proposal that these']","['ratio values, among others.', 'di  #TAUTHOR_TAG conclude with the proposal that these three forms of agreement measure']","['remaining class of agreement measure assumes an equal distribution of categories for all coders.', 'once we have accepted that this assumption is necessary in order to predict the performance of the scheme in general, there appears to be no objection to using this type of statistical test for assessing agreement in discourse and dialogue work.', 'tests that fall into this class include  #AUTHOR_TAG extension of  #AUTHOR_TAG pi, confusingly called kappa, and  #AUTHOR_TAG a ) alpha.', 'both of these measures calculate expected ( dis ) agreement based on the frequency with which each category is used, estimated from the overall usage by the coders.', 'kappa is more frequently described in statistics textbooks and more commonly implemented in statistical software.', 'in circumstances in which mechanisms other than nominal labels are used to annotate data, alpha has the benefit of being able to deal with different degrees of disagreement between pairs of interval, ordinal, and ratio values, among others.', 'di  #TAUTHOR_TAG conclude with the proposal that these three forms of agreement measure collectively provide better means with which to judge agreement than any individual test.', 'we would argue, to the contrary, that applying three different metrics to measure the same property suggests a lack of confidence in any of them.', ""percentage agreement and cohen's kappa do not provide an insight into a scheme's reliability, so reporting their results is potentially misleading""]",0
['carletta 1996 ;  #TAUTHOR_TAG ; krippendo'],['suitable for all studies ( carletta 1996 ;  #TAUTHOR_TAG ; krippendorff 2004a ) is probably'],['carletta 1996 ;  #TAUTHOR_TAG ; krippendo'],"['', 'the prevalent use of this criterion despite repeated advice that it is unlikely to be suitable for all studies ( carletta 1996 ;  #TAUTHOR_TAG ; krippendorff 2004a ) is probably due to a desire for a simple system that can be easily applied to a scheme.', 'unfortunately, because of the diversity of both the phenomena being coded and the applications of the results, it is impossible to prescribe a scale against which all coding schemes can be judged.', '']",0
['di  #TAUTHOR_TAG referred to'],['di  #TAUTHOR_TAG referred to'],['di  #TAUTHOR_TAG referred to'],"['first of the recommended agreement tests, percentage agreement, measures the proportion of agreements between coders.', 'this is an unsuitable measure for inferring reliability, and it was the use of this measure that prompted  #AUTHOR_TAG to recommend chance - corrected measures.', 'percentage agreement is inappropriate for inferring reliability because it excludes any notion of the level of agreement that we could expect to achieve by chance.', 'reliability should be inferred by locating the achieved level of agreement on a scale between the best possible ( coders agree perfectly ) and the worst possible ( coders do not understand or cannot perform the mapping and behave randomly ).', 'without any indication of the agreement that coders would achieve by behaving randomly, any deviation from perfect agreement is uninterpretable ( krippendorff 2004b ).', 'the justification given for using percentage agreement is that it does not suffer from what di  #TAUTHOR_TAG referred to as the "" prevalence problem.', '"" prevalence refers to the unequal distribution of label use by coders.', 'for example, table 1 shows an example taken from di  #TAUTHOR_TAG showing the classification of the utterance okay as an acceptance or acknowledgment.', 'it represents a confusion matrix describing the number of occasions that coders used pairs of labels for a given turn.', 'this table shows that the two coders favored the use of accept strongly over acknowledge.', 'they correctly state that this skew in the distribution of categories increases the expected chance agreement, thus lowering the overall agreement in chance - corrected tests.', ""the reason for this is that since one category is more popular than others, the likelihood of coders'agreeing by chance by choosing this category increases."", 'we therefore require a comparable increase in observed agreement to accommodate this.', 'di  #TAUTHOR_TAG perceive this as an "" unpleasant behavior "" of chancecorrected tests, one that prevents us from concluding that the example given in table 1 shows satisfactory levels of agreement.', 'instead they use percentage agreement to arrive at this conclusion.', 'by examining the data, it is clear that this conclusion would be false.', 'in table 1, the coders agree 90 out of 100 times, but all agreements occur when both coders choose accept.', ""there is not a single case in which they agree on okay's being used as an acknowledgment."", 'the only conclusion one may justifiably draw is that the coders cannot distinguish the use of okay as an acceptance from its use as an acknowledgment.', 'rather than being an unpleasant behavior, accounting for prevalence in the data is']",4
['di  #TAUTHOR_TAG referred to'],['di  #TAUTHOR_TAG referred to'],['di  #TAUTHOR_TAG referred to'],"['first of the recommended agreement tests, percentage agreement, measures the proportion of agreements between coders.', 'this is an unsuitable measure for inferring reliability, and it was the use of this measure that prompted  #AUTHOR_TAG to recommend chance - corrected measures.', 'percentage agreement is inappropriate for inferring reliability because it excludes any notion of the level of agreement that we could expect to achieve by chance.', 'reliability should be inferred by locating the achieved level of agreement on a scale between the best possible ( coders agree perfectly ) and the worst possible ( coders do not understand or cannot perform the mapping and behave randomly ).', 'without any indication of the agreement that coders would achieve by behaving randomly, any deviation from perfect agreement is uninterpretable ( krippendorff 2004b ).', 'the justification given for using percentage agreement is that it does not suffer from what di  #TAUTHOR_TAG referred to as the "" prevalence problem.', '"" prevalence refers to the unequal distribution of label use by coders.', 'for example, table 1 shows an example taken from di  #TAUTHOR_TAG showing the classification of the utterance okay as an acceptance or acknowledgment.', 'it represents a confusion matrix describing the number of occasions that coders used pairs of labels for a given turn.', 'this table shows that the two coders favored the use of accept strongly over acknowledge.', 'they correctly state that this skew in the distribution of categories increases the expected chance agreement, thus lowering the overall agreement in chance - corrected tests.', ""the reason for this is that since one category is more popular than others, the likelihood of coders'agreeing by chance by choosing this category increases."", 'we therefore require a comparable increase in observed agreement to accommodate this.', 'di  #TAUTHOR_TAG perceive this as an "" unpleasant behavior "" of chancecorrected tests, one that prevents us from concluding that the example given in table 1 shows satisfactory levels of agreement.', 'instead they use percentage agreement to arrive at this conclusion.', 'by examining the data, it is clear that this conclusion would be false.', 'in table 1, the coders agree 90 out of 100 times, but all agreements occur when both coders choose accept.', ""there is not a single case in which they agree on okay's being used as an acknowledgment."", 'the only conclusion one may justifiably draw is that the coders cannot distinguish the use of okay as an acceptance from its use as an acknowledgment.', 'rather than being an unpleasant behavior, accounting for prevalence in the data is']",4
"['', 'with many recent results [ 9, 10, 11, 12,  #TAUTHOR_TAG approaching']","['time step.', 'with many recent results [ 9, 10, 11, 12,  #TAUTHOR_TAG approaching']","['every time step.', 'with many recent results [ 9, 10, 11, 12,  #TAUTHOR_TAG approaching']","['the fast advances of deep learning technologies, converting the well matured multi - module speech recognition processes [ 1 ] into a single speech - to - text model [ 2 ] becomes highly attractive.', 'such end - to - end speech recognition approaches are primarily based on two distinct models : connectionist temporal classification ( ctc ) [ 3, 4, 5 ] and sequenceto - sequence ( seq2seq ) [ 6, 7, 8 ] models.', 'by introducing an additional blank symbol and a specially defined loss function aggregating many allowed paths within a graph, ctc model can be optimized to generate the correct character sequences from the speech signals regardless of the blank symbols interspersed among.', 'the seq2seq models, on the other hand, simply maximized the likelihood of observing the decoded sequence given the ground truth at every time step.', 'with many recent results [ 9, 10, 11, 12,  #TAUTHOR_TAG approaching the stateof - the - art, end - to - end deep learning has definitely been a very important direction for speech recognition.', '']",0
"['', 'with many recent results [ 9, 10, 11, 12,  #TAUTHOR_TAG approaching']","['time step.', 'with many recent results [ 9, 10, 11, 12,  #TAUTHOR_TAG approaching']","['every time step.', 'with many recent results [ 9, 10, 11, 12,  #TAUTHOR_TAG approaching']","['the fast advances of deep learning technologies, converting the well matured multi - module speech recognition processes [ 1 ] into a single speech - to - text model [ 2 ] becomes highly attractive.', 'such end - to - end speech recognition approaches are primarily based on two distinct models : connectionist temporal classification ( ctc ) [ 3, 4, 5 ] and sequenceto - sequence ( seq2seq ) [ 6, 7, 8 ] models.', 'by introducing an additional blank symbol and a specially defined loss function aggregating many allowed paths within a graph, ctc model can be optimized to generate the correct character sequences from the speech signals regardless of the blank symbols interspersed among.', 'the seq2seq models, on the other hand, simply maximized the likelihood of observing the decoded sequence given the ground truth at every time step.', 'with many recent results [ 9, 10, 11, 12,  #TAUTHOR_TAG approaching the stateof - the - art, end - to - end deep learning has definitely been a very important direction for speech recognition.', '']",0
['- lm  #TAUTHOR_TAG can also be'],['rnn - lm  #TAUTHOR_TAG can also be'],['- lm  #TAUTHOR_TAG can also be used'],"['architecture.', 'clm takes either real text or asr transcriptions as input and outputs a scalar s as the quality score.', 'the real text is represented as a sequence of one - hot vectors y = y 1, y 2,..., y l, while for asr transcriptions this is a sequence of vectors for distributionsy = y 1, y 2, y 3,....', 'fig. 2 illustrates an example architecture of clm used in this work.', 'the input vector sequence y ( ory ) is first projected to a lower dimensional space through a single layer neural net.', 'next, two layers of one - dimensional convolution neural net - work extracts features for each time index.', 'finally, average pooling over the time axis is applied to get a single representative feature, which is then transformed to a scalar s ( the quality score ) with linear projection.', 'the reason a convolution - based network instead of a recurrent network is used in fig 2 is twofold.', 'convolution with small window size captures local relation features, which can then be averaged over time.', 'also, cnn based network is relatively more computationally efficient, which is important in adversarial training.', 'but other network architectures such as rnn - lm  #TAUTHOR_TAG can also be used here.', 'loss function.', 'a major problem here is that soft distribution vectors produced by the asr model is very different from one - hot vectors for real text data, making the task of clm trivial, and the asr model almost always fail to compete against it.', 'thanks to wasserstein gan ( wgan ) [ 24 ] which addressed the above problem to some good extent.', 'based on the concept of wgan, clm is designed to estimate the earth - mover ( wasserstein - 1 ) [ 25 ] distance between sequences from real data and asr output.', 'the loss function of clm is the weighted sum of a loss l d and a gradient penalty gp as follows,', 'in which λ clm, λ gp are wieghts and l d and gp are respectively in eq ( 2 ) and eq ( 3 ) below.', 'where clm ( y ) is the quality score for y given by clm, p a the distribution of asr outputy and p d the distribution of real text y. y can be sampled from asr with greedy search and y can be sampled directly from data.', 'the 1 - lipschtiz restriction is imposed for clm by applying the gradient penalty [ 26 ] as below,', 'wherey are samples generated by randomly interpolating betweeny and y,']",0
[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG'],0
['- lm )  #TAUTHOR_TAG 20 ] and'],"['( rnn - lm )  #TAUTHOR_TAG 20 ] and "" + at "" refers to']",['- lm )  #TAUTHOR_TAG 20 ] and'],"['the experiments, the asr model was trained on the 100 hours speech data but combined with different amount of unpaired text utilized in different ways.', 'the results are listed in table 1, where "" baseline "" refers to the plain end - toend speech recognition framework as described in sec. 2. 3, "" + lm "" refers to the shallow fusion decoding with a separately trained rnn language model ( rnn - lm )  #TAUTHOR_TAG 20 ] and "" + at "" refers to the adversarial training proposed here.', 'at is actually compatible with any existing end - to - end speech recognition decoding approach, so "" + both "" refers to training with at while jointly decoding with rnn - lm.', 'we ran all experiments three times with random initialization and reported the averaged error rate with decoding beam size set to 20.', 'part ( a ) lists the results without extra text data.', '']",0
"[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features']","[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features']","[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features o =']","['', 'any network architecture for end - toend speech recognition can be used here, while fig. 3 gives the one used in this work, following the previous work  #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features o = o 1, o 2,..., o n with length n as the input.', '']",3
"[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features']","[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features']","[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features o =']","['', 'any network architecture for end - toend speech recognition can be used here, while fig. 3 gives the one used in this work, following the previous work  #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features o = o 1, o 2,..., o n with length n as the input.', '']",3
[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG'],3
[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG'],3
"[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features']","[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features']","[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features o =']","['', 'any network architecture for end - toend speech recognition can be used here, while fig. 3 gives the one used in this work, following the previous work  #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features o = o 1, o 2,..., o n with length n as the input.', '']",5
"[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features']","[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features']","[' #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features o =']","['', 'any network architecture for end - toend speech recognition can be used here, while fig. 3 gives the one used in this work, following the previous work  #TAUTHOR_TAG of integrating attentioned seq2seq with ctc.', 'the model takes a sequence of speech features o = o 1, o 2,..., o n with length n as the input.', '']",5
[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG'],5
[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG 21 ]'],[' #TAUTHOR_TAG'],5
"['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']",[' #TAUTHOR_TAG'],0
"['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']",[' #TAUTHOR_TAG'],0
"['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']",[' #TAUTHOR_TAG'],0
"['key observation made in  #TAUTHOR_TAG is that nuisance factors,']","['key observation made in  #TAUTHOR_TAG is that nuisance factors,']","['key observation made in  #TAUTHOR_TAG is that nuisance factors,']","['key observation made in  #TAUTHOR_TAG is that nuisance factors, such as speaker identity and room acoustics, are generally constant over segments within an utterance, while linguistic content changes from segment to segment.', 'in other words, latent nuisance vectors zn are relatively consistent within an utterance, while the distribution of z conditioned on an utterance can be assumed to have the same distribution as the prior.', 'therefore, suppose the prior is a diagonal gaussian with zero mean.', 'given an utterance', 'of n segments, we have :', 'that is to say, the latent nuisance vector would stand out, and the rest would cancel out, when we take the average of latent vectors over segments within an utterance.', 'this approach shows great success in transforming clean read speech into noisy read speech.', 'however, in a conversational scenario, the portion of short utterances are much larger than that in a reading scenario.', 'for instance, in the wall street journal corpus [ 20 ], a read speech corpus, the average duration on the training set is 7. 6s ( ±2. 9s ), with no utterance shorter than 1s.', 'on the other hand, in the ami corpus [ 16 ], the distant conversational speech meeting corpus, the average duration on the training set is 2. 6s ( ±2. 7s ), with over 35 % of the utterances being shorter than 1s.', 'the small number of segments in a conversational scenario can lead to unreliable estimation of latent nuisance vectors, because the sampled mean of latent linguistic vectors would exhibit large variance from the population mean.', 'the estimation under such a condition can contain information about not only nuisance factors, but also linguistic factors.', 'indeed, we illustrate in figure 1 that modifying the estimated latent nuisance vector of a short utterance can result in undesirable changes to its linguistic content']",0
"['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']",[' #TAUTHOR_TAG'],6
"['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']","['by synthesis [ 11, 12,  #TAUTHOR_TAG.', 'among']",[' #TAUTHOR_TAG'],1
"['proposed in  #TAUTHOR_TAG, named nuisance']","['proposed in  #TAUTHOR_TAG, named nuisance']","['proposed in  #TAUTHOR_TAG, named nuisance factor replacement and nuisance factor perturbation']","['a trained fhvae, we are able to infer disentangled latent representations that capture linguistic factors z1 and nuisance factors z2.', 'to transform nuisance factors of an utterance x without changing the corresponding transcript, one only needs to perturb z2.', 'furthermore, since each z2 within an utterance is generated conditioned on a gaussian whose mean is [UNK], we can regard [UNK] as the representation of nuisance factors of an utterance.', 'we now derive two data augmentation methods similar to those proposed in  #TAUTHOR_TAG, named nuisance factor replacement and nuisance factor perturbation']",3
"['soft perturbation scheme as in  #TAUTHOR_TAG.', 'first,']","['soft perturbation scheme as in  #TAUTHOR_TAG.', 'first, { [UNK] } m i = 1 for']","['utterances.', 'therefore, we adopt a similar soft perturbation scheme as in  #TAUTHOR_TAG.', 'first, { [UNK] } m i = 1 for all m utterances are estimated with the approximated map.', 'principle component analysis is performed to']","[', we are also interested in synthesizing an utterance conditioned on unseen nuisance factors, for example, the interpolation of nuisance factors between two utterances.', 'we propose to draw a random perturbation vector p and compute z2, out = z2, out + p for each segment in an utterance, in order to synthesize an utterance with perturbed nuisance factors.', 'naively, we may want to sample p from a centered isotropic gaussian.', 'however, in practice, vae - type of models suffer from an over - pruning issue [ 21 ] in that some latent variables become inactive, which we do not want to perturb.', 'instead, we only want to perturb the linear subspace which models the variation of nuisance factors between utterances.', 'therefore, we adopt a similar soft perturbation scheme as in  #TAUTHOR_TAG.', 'first, { [UNK] } m i = 1 for all m utterances are estimated with the approximated map.', 'principle component analysis is performed to obtain d pairs of eigenvalue σ d and eigenvectors e d, where d is the dimension of [UNK].', 'lastly, one random perturbation vector p is drawn for each utterance to perturb as follows :', 'where γ is used to control the perturbation scale']",3
['- da  #TAUTHOR_TAG results with nu'],"['by 6 % absolute.', 'vae - da  #TAUTHOR_TAG results with nuisance']",['- da  #TAUTHOR_TAG results with nu'],"['first establish baseline results and report the sdm ( indomain ) and ihm ( out - of - domain ) development set word error rates ( wers ) in table 1.', 'to avoid constantly querying the test set results, we only report wers on the development set.', 'if not otherwise mentioned, the data augmentation - based systems are evaluated on reconstructed features, and trained on a transformed ihm set, where each utterance is only transformed once, without the original copy of data.', 'the first two rows of results show that the wer gap between the unadapted model and the model trained on in - domain data is 24 %.', 'the third row reports the results of training with domain invariant feature, z1, extracted with a fhvae as is done in [ 10 ].', 'it improves over the baseline by 6 % absolute.', 'vae - da  #TAUTHOR_TAG results with nuisance factor replacement ( repl ) and latent nuisance perturbation ( p ) are shown in the last three rows.', '']",3
['- da  #TAUTHOR_TAG results with nu'],"['by 6 % absolute.', 'vae - da  #TAUTHOR_TAG results with nuisance']",['- da  #TAUTHOR_TAG results with nu'],"['first establish baseline results and report the sdm ( indomain ) and ihm ( out - of - domain ) development set word error rates ( wers ) in table 1.', 'to avoid constantly querying the test set results, we only report wers on the development set.', 'if not otherwise mentioned, the data augmentation - based systems are evaluated on reconstructed features, and trained on a transformed ihm set, where each utterance is only transformed once, without the original copy of data.', 'the first two rows of results show that the wer gap between the unadapted model and the model trained on in - domain data is 24 %.', 'the third row reports the results of training with domain invariant feature, z1, extracted with a fhvae as is done in [ 10 ].', 'it improves over the baseline by 6 % absolute.', 'vae - da  #TAUTHOR_TAG results with nuisance factor replacement ( repl ) and latent nuisance perturbation ( p ) are shown in the last three rows.', '']",5
['of  #TAUTHOR_TAG vary widely in'],['of  #TAUTHOR_TAG vary widely in'],['show that the automatically induced latent variable grammars of  #TAUTHOR_TAG vary widely in'],"['show that the automatically induced latent variable grammars of  #TAUTHOR_TAG vary widely in their underlying representations, depending on their em initialization point.', 'we use this to our advantage, combining multiple automatically learned grammars into an unweighted product model, which gives significantly improved performance over state - ofthe - art individual grammars.', 'in our model, the probability of a constituent is estimated as a product of posteriors obtained from multiple grammars that differ only in the random seed used for initialization, without any learning or tuning of combination weights.', '']",7
"[' #TAUTHOR_TAG.', 'the constraints serve the purpose of weakening the independence assumptions, and']","[' #TAUTHOR_TAG.', 'the constraints serve the purpose of weakening the independence assumptions, and']","[' #TAUTHOR_TAG.', 'the constraints serve the purpose of weakening the independence assumptions, and']","['a context - free grammar for parsing requires the estimation of a more highly articulated model than the one embodied by the observed treebank.', 'this is because the naive treebank grammar  #AUTHOR_TAG is too permissive, making unrealistic context - freedom assumptions.', 'for example, it postulates that there is only one type of noun phrase ( np ), which can appear in all positions ( subject, object, etc. ), regardless of case, number or gender.', 'as a result, the grammar can generate millions of ( incorrect ) parse trees for a given sentence, and has a flat posterior distribution.', 'high accuracy grammars therefore add soft constraints on the way categories can be combined, and enrich the label set with additional information.', 'these constraints can be lexicalized  #AUTHOR_TAG, unlexicalized  #AUTHOR_TAG b ) or automatically learned  #TAUTHOR_TAG.', 'the constraints serve the purpose of weakening the independence assumptions, and reduce the number of possible ( but incorrect ) parses.', 'here, we focus on the latent variable approach of  #TAUTHOR_TAG, where an expectation maximization ( em ) algorithm is used to induce a hierarchy of increasingly more refined grammars.', '']",7
['to  #AUTHOR_TAG and  #TAUTHOR_TAG'],['to  #AUTHOR_TAG and  #TAUTHOR_TAG'],"['giving the details of our model, we briefly review the basic properties of latent variable grammars.', 'learning latent variable grammars consists of two tasks : ( 1 ) determining the data representation ( the set of context - free productions to be used in the grammar ), and ( 2 ) estimating the parameters of the model ( the production probabilities ).', 'we focus on the randomness introduced by the em algorithm and refer the reader to  #AUTHOR_TAG and  #TAUTHOR_TAG']","['giving the details of our model, we briefly review the basic properties of latent variable grammars.', 'learning latent variable grammars consists of two tasks : ( 1 ) determining the data representation ( the set of context - free productions to be used in the grammar ), and ( 2 ) estimating the parameters of the model ( the production probabilities ).', 'we focus on the randomness introduced by the em algorithm and refer the reader to  #AUTHOR_TAG and  #TAUTHOR_TAG for a more general introduction']",7
"[' #TAUTHOR_TAG.', 'the constraints serve the purpose of weakening the independence assumptions, and']","[' #TAUTHOR_TAG.', 'the constraints serve the purpose of weakening the independence assumptions, and']","[' #TAUTHOR_TAG.', 'the constraints serve the purpose of weakening the independence assumptions, and']","['a context - free grammar for parsing requires the estimation of a more highly articulated model than the one embodied by the observed treebank.', 'this is because the naive treebank grammar  #AUTHOR_TAG is too permissive, making unrealistic context - freedom assumptions.', 'for example, it postulates that there is only one type of noun phrase ( np ), which can appear in all positions ( subject, object, etc. ), regardless of case, number or gender.', 'as a result, the grammar can generate millions of ( incorrect ) parse trees for a given sentence, and has a flat posterior distribution.', 'high accuracy grammars therefore add soft constraints on the way categories can be combined, and enrich the label set with additional information.', 'these constraints can be lexicalized  #AUTHOR_TAG, unlexicalized  #AUTHOR_TAG b ) or automatically learned  #TAUTHOR_TAG.', 'the constraints serve the purpose of weakening the independence assumptions, and reduce the number of possible ( but incorrect ) parses.', 'here, we focus on the latent variable approach of  #TAUTHOR_TAG, where an expectation maximization ( em ) algorithm is used to induce a hierarchy of increasingly more refined grammars.', '']",0
"[', and  #TAUTHOR_TAG extend this algorithm to use a']","['maximizing the joint likelihood, and  #TAUTHOR_TAG extend this algorithm to use a']","['maximizing the joint likelihood, and  #TAUTHOR_TAG extend this algorithm to use a split & merge procedure']","['variable grammars split the coarse ( but observed ) grammar categories of a treebank into more fine - grained ( but hidden ) subcategories, which are better suited for modeling the syntax of natural languages ( e. g. np becomes np 1 through np k ).', 'accordingly, each grammar production a→bc over observed categories a, b, c is split into a set of productions a x →b y c z over hidden categories a x, b y, c z.', 'computing the joint likelihood of the observed parse trees t and sentences w requires summing over all derivations t over split subcategories :  #AUTHOR_TAG derive an em algorithm for maximizing the joint likelihood, and  #TAUTHOR_TAG extend this algorithm to use a split & merge procedure to adaptively determine the optimal number of subcategories for each observed category.', 'starting from a completely markovized x - bar grammar, each category is split in two, generating eight new productions for each original binary production.', 'to break symmetries, the production probabilities are perturbed by 1 % of random noise.', 'em is then initialized with this starting point and used to climb the highly non - convex objective function given in eq. 1.', 'each splitting step is followed by a merging step, which uses a likelihood ratio test to reverse the least useful half of the splits.', 'learning proceeds by iterating between those two steps for six rounds.', 'to prevent overfitting, the production probabilities are linearly smoothed by shrinking them towards their common base category']",0
['merge procedure described above is shown in  #TAUTHOR_TAG to'],['split & merge procedure described above is shown in  #TAUTHOR_TAG to'],['the split & merge procedure described above is shown in  #TAUTHOR_TAG to'],"['the split & merge procedure described above is shown in  #TAUTHOR_TAG to reduce the variance in final performance, we found after closer examination that there are substantial differences in the patterns learned by the grammars.', 'since the initialization is not systematically biased in any way, one can obtain different grammars by simply changing the seed of the random number generator.', 'we trained 16 different grammars by initializing the random number generator with seed values 1 through 16, but without biasing the initialization in any other way.', 'figure 1 shows that the number of subcategories allocated to each observed category varies significantly between the different initialization points, especially for the phrasal categories.', 'figure 2 shows posteriors over the most frequent subcategories given their base category for the first four grammars.', 'clearly, em is allocating the latent variables in very different ways in each case.', 'as a more quantitative measure of difference, 1 we evaluated all 16 grammars on sections 22 and 24 of the penn treebank.', 'figure 3 shows the performance on those two sets, and reveals that there is no single grammar that achieves the best score on both.', 'while the parsing accuracies are consistently high, 2 there is only a weak correlation between the accuracies on the two evaluation sets ( pearson coefficient 0. 34 ).', 'this suggests that no single grammar should be preferred over the others.', 'in previous work  #TAUTHOR_TAG the final grammar was chosen based on its performance on a held - out set ( section 22 ), and corresponds to the second best grammar in figure 3 ( because only 8 different grammars were trained ).', 'a more detailed error analysis is given in figure 4, where we show a breakdown of f 1 scores for selected phrasal categories in addition to the overall f 1 score and exact match ( on the wsj development set ).', 'while grammar g 2 has the highest overall f 1 score, its exact match is not particularly high, and it turns out to be the weakest at predicting quantifier phrases ( qp ).', 'similarly, the performance of the other grammars varies between the different error measures, indicating again that no single grammar dominates the others']",0
"['rescoring 50 - best lists from  #AUTHOR_TAG and  #TAUTHOR_TAG, they obtain']","['rescoring 50 - best lists from  #AUTHOR_TAG and  #TAUTHOR_TAG, they obtain']","['rescoring 50 - best lists from  #AUTHOR_TAG and  #TAUTHOR_TAG, they obtain']","['', 'the individual grammars had parsing accuracies ( f 1 ) of 91. 2 and 90. 7 respectively, and their product ( 91. 7 ) clearly outperformed their sum ( 91. 3 ).', 'when more grammars are added, the gap widens even further, and the trends persist independently of whether the models use tree - level or constituent - level inference.', 'at least for the case of unweighted combinations, the product distribution seems to be superior.', 'in related work,  #AUTHOR_TAG achieve excellent results with a weighted sum model.', 'using weights learned on a held - out set and rescoring 50 - best lists from  #AUTHOR_TAG and  #TAUTHOR_TAG, they obtain an f 1 score of 91. 0 ( which they further improve to 91. 4 using a voting scheme ).', 'we replicated their experiment, but used an unweighted product of the two model scores.', '']",0
"['the case here as well.', 'the parameters of each latent variable grammar are typically smoothed in a linear fashion to prevent excessive overfitting  #TAUTHOR_TAG.', 'while']","['the case here as well.', 'the parameters of each latent variable grammar are typically smoothed in a linear fashion to prevent excessive overfitting  #TAUTHOR_TAG.', 'while']","['the case here as well.', 'the parameters of each latent variable grammar are typically smoothed in a linear fashion to prevent excessive overfitting  #TAUTHOR_TAG.', 'while all the experiments so far used smoothed grammars, we reran the experiments also with a set of unsmo']","['too surprisingly, we find this to be the case here as well.', 'the parameters of each latent variable grammar are typically smoothed in a linear fashion to prevent excessive overfitting  #TAUTHOR_TAG.', 'while all the experiments so far used smoothed grammars, we reran the experiments also with a set of unsmoothed grammars.', 'the individual unsmoothed grammars have on average an 1. 2 % lower accuracy.', 'even though our product model is able to increase accuracy by combining multiple grammars, the gap to the smoothed models remains consistent.', 'this suggests that the product model is doing more than just smoothing.', 'in fact, because the product distribution is more peaked, it seems to be doing the opposite of smoothing']",0
['of  #TAUTHOR_TAG with'],['of  #TAUTHOR_TAG with'],"['to note that the best results in  #AUTHOR_TAG are achieved by combining kbest lists from a latent variable grammar of  #TAUTHOR_TAG with the self - trained reranking parser of mc  #AUTHOR_TAG.', 'clearly, replacing the single latent variable grammar with a product of latent variable grammars ought to improve performance']","['', 'we did not attempt this experiment, but we expect that those methods would stack well with our model, because they use primarily non - local features that are not available in a context - free grammar.', 'techniques like self - training ( self ) and system combinations ( combo ) can further improve parsing accuracies, but are also orthogonal to our work.', 'in particular the combo methods seem related to our work, but are very different in their nature.', 'while we use multiple grammars in our work, all grammars are from the same model class for us.', 'in contrast, those methods rely on a diverse set of individual parsers, each of which requires a significant effort to build.', 'furthermore, those techniques have largely relied on different voting schemes in the past  #AUTHOR_TAG, and only more recently have started using actual posteriors from the underlying models  #AUTHOR_TAG.', 'even then, those methods operate only over k - best lists, and we are the first to work directly with parse forests from multiple grammars.', 'it is also interesting to note that the best results in  #AUTHOR_TAG are achieved by combining kbest lists from a latent variable grammar of  #TAUTHOR_TAG with the self - trained reranking parser of mc  #AUTHOR_TAG.', 'clearly, replacing the single latent variable grammar with a product of latent variable grammars ought to improve performance.', 'the results on the other two corpora are similar.', 'a product of latent variable grammars very significantly outperforms a single latent variable grammar and sets new standards for the state - of - the - art.', 'we also analyzed the errors of the product models.', 'in addition to the illustrative example in figure 5, we computed detailed error metrics for different']",0
['merge procedure described above is shown in  #TAUTHOR_TAG to'],['split & merge procedure described above is shown in  #TAUTHOR_TAG to'],['the split & merge procedure described above is shown in  #TAUTHOR_TAG to'],"['the split & merge procedure described above is shown in  #TAUTHOR_TAG to reduce the variance in final performance, we found after closer examination that there are substantial differences in the patterns learned by the grammars.', 'since the initialization is not systematically biased in any way, one can obtain different grammars by simply changing the seed of the random number generator.', 'we trained 16 different grammars by initializing the random number generator with seed values 1 through 16, but without biasing the initialization in any other way.', 'figure 1 shows that the number of subcategories allocated to each observed category varies significantly between the different initialization points, especially for the phrasal categories.', 'figure 2 shows posteriors over the most frequent subcategories given their base category for the first four grammars.', 'clearly, em is allocating the latent variables in very different ways in each case.', 'as a more quantitative measure of difference, 1 we evaluated all 16 grammars on sections 22 and 24 of the penn treebank.', 'figure 3 shows the performance on those two sets, and reveals that there is no single grammar that achieves the best score on both.', 'while the parsing accuracies are consistently high, 2 there is only a weak correlation between the accuracies on the two evaluation sets ( pearson coefficient 0. 34 ).', 'this suggests that no single grammar should be preferred over the others.', 'in previous work  #TAUTHOR_TAG the final grammar was chosen based on its performance on a held - out set ( section 22 ), and corresponds to the second best grammar in figure 3 ( because only 8 different grammars were trained ).', 'a more detailed error analysis is given in figure 4, where we show a breakdown of f 1 scores for selected phrasal categories in addition to the overall f 1 score and exact match ( on the wsj development set ).', 'while grammar g 2 has the highest overall f 1 score, its exact match is not particularly high, and it turns out to be the weakest at predicting quantifier phrases ( qp ).', 'similarly, the performance of the other grammars varies between the different error measures, indicating again that no single grammar dominates the others']",4
[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],"[')  #TAUTHOR_TAG. the current state - of - the - art approach for efp has involved deep learning models  #TAUTHOR_TAG that examine both syntactic and semantic information in the modeling process. however, in', 'these models, the syntactic and semantic information are only employed separately in the different deep learning architectures to generate syntactic and', '']",0
[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],"[')  #TAUTHOR_TAG. the current state - of - the - art approach for efp has involved deep learning models  #TAUTHOR_TAG that examine both syntactic and semantic information in the modeling process. however, in', 'these models, the syntactic and semantic information are only employed separately in the different deep learning architectures to generate syntactic and', '']",0
[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],"[')  #TAUTHOR_TAG. the current state - of - the - art approach for efp has involved deep learning models  #TAUTHOR_TAG that examine both syntactic and semantic information in the modeling process. however, in', 'these models, the syntactic and semantic information are only employed separately in the different deep learning architectures to generate syntactic and', '']",0
[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],"[')  #TAUTHOR_TAG. the current state - of - the - art approach for efp has involved deep learning models  #TAUTHOR_TAG that examine both syntactic and semantic information in the modeling process. however, in', 'these models, the syntactic and semantic information are only employed separately in the different deep learning architectures to generate syntactic and', '']",0
['while  #TAUTHOR_TAG utilize ls'],['efp while  #TAUTHOR_TAG utilize lstms'],['while  #TAUTHOR_TAG utilize ls'],"['##p is one of the fundamental tasks in information extraction.', 'the early work on this problem has employed the rule - based approaches  #AUTHOR_TAG sauri, 2008 ;  #AUTHOR_TAG or the machine learning approaches ( with manually designed features )  #AUTHOR_TAG, or the hybrid approaches of both ( sauri and  #AUTHOR_TAG.', 'recently, deep learning has been applied to solve efp.', ' #AUTHOR_TAG employ generative adversarial networks ( gans ) for efp while  #TAUTHOR_TAG utilize lstms for both sequential and dependency representations of the input sentences.', 'finally, deep learning has also been considered for the related tasks of efp, including event detection  #AUTHOR_TAG b ;  #AUTHOR_TAG b ;  #AUTHOR_TAG, event realis classification  #AUTHOR_TAG g ), uncertainty detection ( adel and schutze, 2017 ), modal sense classification  #AUTHOR_TAG and entity detection  #AUTHOR_TAG d ).', 'the current event mention has happened.', 'there are three major components in the efp model proposed in this work, i. e., ( i ) sentence encoding, ( ii ) structure induction, and ( iii ) prediction']",0
"['with linguistic features  #AUTHOR_TAG and deep learning  #TAUTHOR_TAG.', '']","['with linguistic features  #AUTHOR_TAG and deep learning  #TAUTHOR_TAG.', '']","['with linguistic features  #AUTHOR_TAG and deep learning  #TAUTHOR_TAG.', '']","['section evaluates the effectiveness of the proposed model for efp on the benchmark datasets.', 'we compare the proposed model with the best reported systems in the literature with linguistic features  #AUTHOR_TAG and deep learning  #TAUTHOR_TAG.', 'table 1 shows the performance.', 'importantly, to achieve a fair comparison, we obtain the actual implementation of the current state - of - the - art efp models from  #TAUTHOR_TAG, introduce the bert embeddings as the inputs for those models and compare them with the proposed models ( i. e., the rows with "" + bert "" ).', '']",0
[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],[')  #TAUTHOR_TAG. the current'],"[')  #TAUTHOR_TAG. the current state - of - the - art approach for efp has involved deep learning models  #TAUTHOR_TAG that examine both syntactic and semantic information in the modeling process. however, in', 'these models, the syntactic and semantic information are only employed separately in the different deep learning architectures to generate syntactic and', '']",1
"['of bidirectional lstms ( as in  #TAUTHOR_TAG.', 'this']","['of bidirectional lstms ( as in  #TAUTHOR_TAG.', 'this']","['into two layers of bidirectional lstms ( as in  #TAUTHOR_TAG.', 'this']","['', 'in the next step, we further abstract ( e 1, e 2,..., e n ) for efp by feeding them into two layers of bidirectional lstms ( as in  #TAUTHOR_TAG.', '']",5
"[', similar to  #TAUTHOR_TAG, the']","['for efp.', 'finally, similar to  #TAUTHOR_TAG, the']","[', similar to  #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],5
"[', similar to  #TAUTHOR_TAG, the']","['for efp.', 'finally, similar to  #TAUTHOR_TAG, the']","[', similar to  #TAUTHOR_TAG,']",[' #TAUTHOR_TAG'],5
"['previous work  #TAUTHOR_TAG.', 'the first']","['previous work  #TAUTHOR_TAG.', 'the first']","['the previous work  #TAUTHOR_TAG.', 'the first three datasets (']","['the previous work  #TAUTHOR_TAG.', 'the first three datasets ( i. e., factback, uw, and meantime ) are the unified versions described in  #AUTHOR_TAG where the original annotations for these datasets are scaled to a number in [ - 3, + 3 ].', 'for the fourth dataset ( i. e., uds - ih2 ), we follow the instructions in  #TAUTHOR_TAG to scale the scores to the range of [ - 3, + 3 ].', 'each dataset comes with its own training data, test data and development data.', 'table 2 shows the numbers of examples in all data splits for each dataset used in this paper.', 'we tune the parameters for the proposed model on the development datasets.', 'the best values we find in the tuning process include : 300 for the number of hidden units in the bidirectional lstm layers, 1024 for the dimension of the projected vector h ′ i in the structure induction component, 300 for the number of feature maps for the gcn layers, 600 for the dimention of the transformed vectors for attention based on ( w a 1, w a 2, w a 3 ), and 300 for the number of hidden units in the two layers of the final regression model.', 'for the tradeoff parameter λ between the semantic and syntactic structures, the best value for the datasets factback, uw and meantime is λ = 0. 6 while this value for uds - ih2 is λ = 0. 8']",5
"['previous work  #TAUTHOR_TAG.', 'the first']","['previous work  #TAUTHOR_TAG.', 'the first']","['the previous work  #TAUTHOR_TAG.', 'the first three datasets (']","['the previous work  #TAUTHOR_TAG.', 'the first three datasets ( i. e., factback, uw, and meantime ) are the unified versions described in  #AUTHOR_TAG where the original annotations for these datasets are scaled to a number in [ - 3, + 3 ].', 'for the fourth dataset ( i. e., uds - ih2 ), we follow the instructions in  #TAUTHOR_TAG to scale the scores to the range of [ - 3, + 3 ].', 'each dataset comes with its own training data, test data and development data.', 'table 2 shows the numbers of examples in all data splits for each dataset used in this paper.', 'we tune the parameters for the proposed model on the development datasets.', 'the best values we find in the tuning process include : 300 for the number of hidden units in the bidirectional lstm layers, 1024 for the dimension of the projected vector h ′ i in the structure induction component, 300 for the number of feature maps for the gcn layers, 600 for the dimention of the transformed vectors for attention based on ( w a 1, w a 2, w a 3 ), and 300 for the number of hidden units in the two layers of the final regression model.', 'for the tradeoff parameter λ between the semantic and syntactic structures, the best value for the datasets factback, uw and meantime is λ = 0. 6 while this value for uds - ih2 is λ = 0. 8']",5
['prediction ( as done in  #TAUTHOR_TAG'],['perform factuality prediction ( as done in  #TAUTHOR_TAG'],"['perform factuality prediction ( as done in  #TAUTHOR_TAG.', 'however, despite']","['the hidden representation ( h 1, h 2,..., h n ), it is possible to use the hidden vector corresponding to the anchor word h k as the features to perform factuality prediction ( as done in  #TAUTHOR_TAG.', 'however, despite the rich context information over the whole sentence, the features in h k are not directly designed to focus on the import context words for factuality prediction.', '']",4
"['with linguistic features  #AUTHOR_TAG and deep learning  #TAUTHOR_TAG.', '']","['with linguistic features  #AUTHOR_TAG and deep learning  #TAUTHOR_TAG.', '']","['with linguistic features  #AUTHOR_TAG and deep learning  #TAUTHOR_TAG.', '']","['section evaluates the effectiveness of the proposed model for efp on the benchmark datasets.', 'we compare the proposed model with the best reported systems in the literature with linguistic features  #AUTHOR_TAG and deep learning  #TAUTHOR_TAG.', 'table 1 shows the performance.', 'importantly, to achieve a fair comparison, we obtain the actual implementation of the current state - of - the - art efp models from  #TAUTHOR_TAG, introduce the bert embeddings as the inputs for those models and compare them with the proposed models ( i. e., the rows with "" + bert "" ).', '']",6
"['cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extract']","['cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extractive']","[', especially on the cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extract']","['summarization has been an active area of research, especially on the cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extractive summarization seem to be less challenging because new words are not generated, identifying salient parts of the document without any guide in the form of a query, is a substantial problem to tackle.', 'earlier approaches for extractive summarization use manual - feature engineering implemented with graphs  #AUTHOR_TAG, integer linear programming ( ilp )  #AUTHOR_TAG.', 'more recent approaches are data - driven and implement a variety of neural networks  #AUTHOR_TAG majorly with an encoder - decoder framework  #AUTHOR_TAG.', '']",1
"['cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extract']","['cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extractive']","[', especially on the cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extract']","['summarization has been an active area of research, especially on the cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extractive summarization seem to be less challenging because new words are not generated, identifying salient parts of the document without any guide in the form of a query, is a substantial problem to tackle.', 'earlier approaches for extractive summarization use manual - feature engineering implemented with graphs  #AUTHOR_TAG, integer linear programming ( ilp )  #AUTHOR_TAG.', 'more recent approaches are data - driven and implement a variety of neural networks  #AUTHOR_TAG majorly with an encoder - decoder framework  #AUTHOR_TAG.', '']",0
"[""score, our approach is more similar to  #TAUTHOR_TAG's model""]","[""score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the individual reference sentence - level""]","[""score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the""]","['', "". the goal is to identify the most - likely document sentence. different from  #AUTHOR_TAG's"", 'approach to greedily add sentences to the summary that maximizes the ro', ""##uge score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the individual reference sentence - level score as per its similarity with each sentence in the corresponding document. however, our sentence"", '- level similarity score is based on its bigram overlap :', ""for each t th sentence in the reference summary, r j, per i th sentence in document d j, in contrast to  #TAUTHOR_TAG's that uses rouge - l"", 'recall score. additionally, for every time both words in the set of bigrams - overlap are stopwords, we decrement the similarity score by 1, for example, ( on, the ) is', 'an invalid bigram - overlap while ( the, president ) is valid. we do this, to capture more', ""important similarities instead of trivial ones. for statistical purposes, we evaluate our extractive trainer for tuning the document's sentences to 0's and 1's against  #AUTHOR_TAG table 2 : rouge - f1 ("", '']",0
"['cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extract']","['cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extractive']","[', especially on the cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extract']","['summarization has been an active area of research, especially on the cnn / dailymail dataset.', 'even with recent progress  #TAUTHOR_TAG, there is still some work to be done in the field.', 'although extractive summarization seem to be less challenging because new words are not generated, identifying salient parts of the document without any guide in the form of a query, is a substantial problem to tackle.', 'earlier approaches for extractive summarization use manual - feature engineering implemented with graphs  #AUTHOR_TAG, integer linear programming ( ilp )  #AUTHOR_TAG.', 'more recent approaches are data - driven and implement a variety of neural networks  #AUTHOR_TAG majorly with an encoder - decoder framework  #AUTHOR_TAG.', '']",5
"[""score, our approach is more similar to  #TAUTHOR_TAG's model""]","[""score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the individual reference sentence - level""]","[""score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the""]","['', "". the goal is to identify the most - likely document sentence. different from  #AUTHOR_TAG's"", 'approach to greedily add sentences to the summary that maximizes the ro', ""##uge score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the individual reference sentence - level score as per its similarity with each sentence in the corresponding document. however, our sentence"", '- level similarity score is based on its bigram overlap :', ""for each t th sentence in the reference summary, r j, per i th sentence in document d j, in contrast to  #TAUTHOR_TAG's that uses rouge - l"", 'recall score. additionally, for every time both words in the set of bigrams - overlap are stopwords, we decrement the similarity score by 1, for example, ( on, the ) is', 'an invalid bigram - overlap while ( the, president ) is valid. we do this, to capture more', ""important similarities instead of trivial ones. for statistical purposes, we evaluate our extractive trainer for tuning the document's sentences to 0's and 1's against  #AUTHOR_TAG table 2 : rouge - f1 ("", '']",5
['fast  #TAUTHOR_TAG'],['fast  #TAUTHOR_TAG 40. 88 17. 80'],['. 95 17. 12 35. 68 fast  #TAUTHOR_TAG'],"['##ive model r - 1 r - 2 r - l rl + intra - att  #AUTHOR_TAG 41. 16 15. 75 39. 08 kign + pred  #AUTHOR_TAG 38. 95 17. 12 35. 68 fast  #TAUTHOR_TAG 40. 88 17. 80 38. 54 bottom - up  #AUTHOR_TAG  #AUTHOR_TAG corpus contains over 1. 3m news articles together with various metadata information such as the title, summary, coverage and compression ratio.', 'cnn / dm summaries are twice as long as newsroom summaries with average word lengths of 66 and 26 respectively']",5
"['previous works  #TAUTHOR_TAG, we evaluate both datasets on standard rouge']","['previous works  #TAUTHOR_TAG, we evaluate both datasets on standard rouge - 1,']","['previous works  #TAUTHOR_TAG, we evaluate both datasets on standard rouge - 1, rouge - 2 and rouge']","['previous works  #TAUTHOR_TAG, we evaluate both datasets on standard rouge - 1, rouge - 2 and rouge - l  #AUTHOR_TAG.', 'it calculates the appropriate n - gram word - overlap between the reference and system summaries']",5
"[""score, our approach is more similar to  #TAUTHOR_TAG's model""]","[""score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the individual reference sentence - level""]","[""score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the""]","['', "". the goal is to identify the most - likely document sentence. different from  #AUTHOR_TAG's"", 'approach to greedily add sentences to the summary that maximizes the ro', ""##uge score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the individual reference sentence - level score as per its similarity with each sentence in the corresponding document. however, our sentence"", '- level similarity score is based on its bigram overlap :', ""for each t th sentence in the reference summary, r j, per i th sentence in document d j, in contrast to  #TAUTHOR_TAG's that uses rouge - l"", 'recall score. additionally, for every time both words in the set of bigrams - overlap are stopwords, we decrement the similarity score by 1, for example, ( on, the ) is', 'an invalid bigram - overlap while ( the, president ) is valid. we do this, to capture more', ""important similarities instead of trivial ones. for statistical purposes, we evaluate our extractive trainer for tuning the document's sentences to 0's and 1's against  #AUTHOR_TAG table 2 : rouge - f1 ("", '']",3
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['- binary classification  #TAUTHOR_TAG.', 'to the']","['', 'hence berg -  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG learn to extract and compress at sentence - level.', 'identifying the likely most salient part of the text as summary - worthy is very crucial.', 'some authors have employed integer linear programming  #AUTHOR_TAG, graph concepts  #AUTHOR_TAG ranking with reinforcement learning  #AUTHOR_TAG and mostly related to our work - binary classification  #TAUTHOR_TAG.', 'to the best of our knowledge, our utilization of the transformer encoder model as a building block for binary classification is novel, although the transformer has been successfully used for language understanding  #AUTHOR_TAG, machine translation ( mt )  #AUTHOR_TAG and paraphrase generation.', '']",3
"[""score, our approach is more similar to  #TAUTHOR_TAG's model""]","[""score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the individual reference sentence - level""]","[""score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the""]","['', "". the goal is to identify the most - likely document sentence. different from  #AUTHOR_TAG's"", 'approach to greedily add sentences to the summary that maximizes the ro', ""##uge score, our approach is more similar to  #TAUTHOR_TAG's model that calculates the individual reference sentence - level score as per its similarity with each sentence in the corresponding document. however, our sentence"", '- level similarity score is based on its bigram overlap :', ""for each t th sentence in the reference summary, r j, per i th sentence in document d j, in contrast to  #TAUTHOR_TAG's that uses rouge - l"", 'recall score. additionally, for every time both words in the set of bigrams - overlap are stopwords, we decrement the similarity score by 1, for example, ( on, the ) is', 'an invalid bigram - overlap while ( the, president ) is valid. we do this, to capture more', ""important similarities instead of trivial ones. for statistical purposes, we evaluate our extractive trainer for tuning the document's sentences to 0's and 1's against  #AUTHOR_TAG table 2 : rouge - f1 ("", '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['- binary classification  #TAUTHOR_TAG.', 'to the']","['', 'hence berg -  #AUTHOR_TAG ;  #AUTHOR_TAG ;  #AUTHOR_TAG learn to extract and compress at sentence - level.', 'identifying the likely most salient part of the text as summary - worthy is very crucial.', 'some authors have employed integer linear programming  #AUTHOR_TAG, graph concepts  #AUTHOR_TAG ranking with reinforcement learning  #AUTHOR_TAG and mostly related to our work - binary classification  #TAUTHOR_TAG.', 'to the best of our knowledge, our utilization of the transformer encoder model as a building block for binary classification is novel, although the transformer has been successfully used for language understanding  #AUTHOR_TAG, machine translation ( mt )  #AUTHOR_TAG and paraphrase generation.', '']",4
['fast  #TAUTHOR_TAG'],['fast  #TAUTHOR_TAG 40. 88 17. 80'],['. 95 17. 12 35. 68 fast  #TAUTHOR_TAG'],"['##ive model r - 1 r - 2 r - l rl + intra - att  #AUTHOR_TAG 41. 16 15. 75 39. 08 kign + pred  #AUTHOR_TAG 38. 95 17. 12 35. 68 fast  #TAUTHOR_TAG 40. 88 17. 80 38. 54 bottom - up  #AUTHOR_TAG  #AUTHOR_TAG corpus contains over 1. 3m news articles together with various metadata information such as the title, summary, coverage and compression ratio.', 'cnn / dm summaries are twice as long as newsroom summaries with average word lengths of 66 and 26 respectively']",7
"[' #TAUTHOR_TAG.', '']","[' #TAUTHOR_TAG.', '']","['level  #TAUTHOR_TAG.', '']","['##anda detection is a process of determining whether a news article or a sentence is misleading.', 'several research works have been proposed to detect propaganda on document - level  #AUTHOR_TAG barron - cedeno et al., 2019b ), sentencelevel and fragment - level  #TAUTHOR_TAG.', '']",0
"['classifications.', 'a fine - grained propaganda corpus was proposed in da san  #TAUTHOR_TAG which includes both sentencelevel and fragment - level information.', 'based on this corpus and the pretrained bert which is']","['twoway and four - way classifications.', 'a fine - grained propaganda corpus was proposed in da san  #TAUTHOR_TAG which includes both sentencelevel and fragment - level information.', 'based on this corpus and the pretrained bert which is']","['and four - way classifications.', 'a fine - grained propaganda corpus was proposed in da san  #TAUTHOR_TAG which includes both sentencelevel and fragment - level information.', 'based on this corpus and the pretrained bert which is']","['methods have been proposed for propaganda detection.', ' #AUTHOR_TAG proposed to use lstm and other machine learning methods for deception detection in different types of news, including trusted, satire, hoax and propaganda.', 'barron - cedeno et al. ( 2019b ) proposed to use maximum entropy classifier  #AUTHOR_TAG with different features replicating the same experimental setup of  #AUTHOR_TAG for twoway and four - way classifications.', 'a fine - grained propaganda corpus was proposed in da san  #TAUTHOR_TAG which includes both sentencelevel and fragment - level information.', 'based on this corpus and the pretrained bert which is one of the most powerful pretrained language model, a multi - granularity bert was proposed and it outperformed several strong bert - based baselines']",0
"['non - propaganda sentences as negative samples.', 'more details of the dataset could be found in da san  #TAUTHOR_TAG']","['non - propaganda sentences as negative samples.', 'more details of the dataset could be found in da san  #TAUTHOR_TAG']","['non - propaganda sentences as negative samples.', 'more details of the dataset could be found in da san  #TAUTHOR_TAG']","['dataset is provided by nlp4if 2019 shared task ( barron - cedeno et al., 2019a ), and the training set, the development set, and the test set contain approximately 16, 000, 2, 000 and 3, 400 sentences respectively.', 'according to the statistics, only 29 % of the training sentences are labeled as propaganda, and thus in this paper, we treat propaganda sentences as positive samples and non - propaganda sentences as negative samples.', 'more details of the dataset could be found in da san  #TAUTHOR_TAG']",0
"[':', 'as described in da san  #TAUTHOR_TAG, the source of the dataset']","['pair :', 'as described in da san  #TAUTHOR_TAG, the source of the dataset']","['title pair :', 'as described in da san  #TAUTHOR_TAG, the source of the dataset']","['', 'as described in da san  #TAUTHOR_TAG, the source of the dataset that we use is news articles, and since the title is usually the summarization of a news article, we use the title as supplementary information.', 'sentence - context pair : in addition to setting the title as the supplementary information, we construct the sentence - context pair which also includes preceding sentences as additional context, since preceding sentences usually convey the same or related events and this historical content is closely related to the current sentence.', 'figure 1. shows the details of this kind of input pair in which the preceding sentence and the title are directly concatenated']",0
"[' #TAUTHOR_TAG.', '']","[' #TAUTHOR_TAG.', '']","['level  #TAUTHOR_TAG.', '']","['##anda detection is a process of determining whether a news article or a sentence is misleading.', 'several research works have been proposed to detect propaganda on document - level  #AUTHOR_TAG barron - cedeno et al., 2019b ), sentencelevel and fragment - level  #TAUTHOR_TAG.', '']",4
"[':', 'as described in da san  #TAUTHOR_TAG, the source of the dataset']","['pair :', 'as described in da san  #TAUTHOR_TAG, the source of the dataset']","['title pair :', 'as described in da san  #TAUTHOR_TAG, the source of the dataset']","['', 'as described in da san  #TAUTHOR_TAG, the source of the dataset that we use is news articles, and since the title is usually the summarization of a news article, we use the title as supplementary information.', 'sentence - context pair : in addition to setting the title as the supplementary information, we construct the sentence - context pair which also includes preceding sentences as additional context, since preceding sentences usually convey the same or related events and this historical content is closely related to the current sentence.', 'figure 1. shows the details of this kind of input pair in which the preceding sentence and the title are directly concatenated']",5
"['mentioned in da san  #TAUTHOR_TAG or introducing other kinds of tasks, such as sentiment']","['mentioned in da san  #TAUTHOR_TAG or introducing other kinds of tasks, such as sentiment']","['mentioned in da san  #TAUTHOR_TAG or introducing other kinds of tasks, such as sentiment analysis']","['', 'in the future, we plan to apply multi - task learning to this context - dependent bert, similar to the method mentioned in da san  #TAUTHOR_TAG or introducing other kinds of tasks, such as sentiment analysis or domain classification']",3
"['mentioned in da san  #TAUTHOR_TAG or introducing other kinds of tasks, such as sentiment']","['mentioned in da san  #TAUTHOR_TAG or introducing other kinds of tasks, such as sentiment']","['mentioned in da san  #TAUTHOR_TAG or introducing other kinds of tasks, such as sentiment analysis']","['', 'in the future, we plan to apply multi - task learning to this context - dependent bert, similar to the method mentioned in da san  #TAUTHOR_TAG or introducing other kinds of tasks, such as sentiment analysis or domain classification']",2
['with self - attention has achieved great'],['with self - attention has achieved great'],['with self - attention has achieved great success in'],"['with self - attention has achieved great success in the area of nature language processing.', 'recently, there have been a few studies on  #TAUTHOR_TAG for end - to - end speech recognition, while its application for hybrid acoustic model is still very limited.', 'in this paper, we revisit the  #TAUTHOR_TAG - based hybrid acoustic model, and propose a model structure with interleaved self - attention and 1d convolution, which is proven to have faster convergence and higher recognition accuracy.', 'we also study several aspects of the  #TAUTHOR_TAG, including the impact of the positional encoding feature, dropout regularization, as well as training with and without time restriction.', 'we show competitive recognition results on the public librispeech dataset when compared to the kaldi baseline at both cross entropy training and sequence training stages.', 'for reproducible research, we release our source code and recipe within the pykaldi2 toolbox']",0
"['', ' #TAUTHOR_TAG, language modeling']","['inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as']","['inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as']","['neural networks ( rnns ) with long short - term memory ( lstm ) [ 1 ] units have defined the state - of - the - art large - scale speech recognition since 2014 [ 2 ].', 'while there have been new types of sequence modeling approaches which are proposed and explored for speech recognition recently, such as sequence - to - sequence with attention [ 3, 4, 5 ], connectionist temporal classification [ 6 ] and recurrent neural network transducer [ 6 ], lstm - rnns remains the most popular neural network architectures for learning speech feature representations, although convolutional neural networks ( cnns ) with different variants have shown competitive recognition results for some tasks.', 'the key behind the success of rnns is their capacity to learn temporal correlations in sequential signals through the recurrent connections when the networks are trained with the back - propagation through time ( bptt ) [ 7 ] algorithm.', 'however, a well - known weakness of rnns is the gradient vanishing or explosion problem due to bptt, and the recurrent connections in rnns make it challenging to parallelize the computations in both training and inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as end - to - end speech recognition [ 10, 11 ].', 'self - attention is appealing for sequence modeling in the sense that it can learn long - term correlations by one step of attention operation, while for rnns, it would take multiple steps in the time space for both forward and backward computation, and noise may accumulate during the process.', 'cnns, on the other hand, require multiple layers to capture the correlations between the two features which are very distant in the time space, although dilation that uses large strides can reduce the number of layers that is required.', 'while there have been many studies on end - to - end speech recognition using  #TAUTHOR_TAG [ 10, 11, 12, 13, 14 ], their applications for hybrid acoustic models are less well understood.', 'in this paper, we study the more standard  #TAUTHOR_TAG for speech recognition within the hybrid framework, and provide further insight to this model through experiments on the librispeech public dataset']",0
['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the']",['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system', '']",0
['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the']",['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system', '']",0
['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the']",['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system', '']",0
['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the']",['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system', '']",0
['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the']",['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system', '']",0
['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],"['attention mechanism in  #TAUTHOR_TAG is technically the same as in the original rnn - based attention model [ 19 ].', 'the key difference is that the query used to compute the attention probability is also from the source sequence, instead of using the decoder hidden state as in the rnn - based attention model [ 19 ].', '']",0
['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],"['attention mechanism in  #TAUTHOR_TAG is technically the same as in the original rnn - based attention model [ 19 ].', 'the key difference is that the query used to compute the attention probability is also from the source sequence, instead of using the decoder hidden state as in the rnn - based attention model [ 19 ].', '']",0
['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],"['attention mechanism in  #TAUTHOR_TAG is technically the same as in the original rnn - based attention model [ 19 ].', 'the key difference is that the query used to compute the attention probability is also from the source sequence, instead of using the decoder hidden state as in the rnn - based attention model [ 19 ].', '']",0
['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],"['attention mechanism in  #TAUTHOR_TAG is technically the same as in the original rnn - based attention model [ 19 ].', 'the key difference is that the query used to compute the attention probability is also from the source sequence, instead of using the decoder hidden state as in the rnn - based attention model [ 19 ].', '']",0
"['2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in']","['3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in']","['first evaluated the positional encoding discussed in section 3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in table 2.', 'unlike the observations in']","['first evaluated the positional encoding discussed in section 3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in table 2.', 'unlike the observations in the area of machine translation, positional encoding did not make a big difference in terms of recognition accuracies for our  #TAUTHOR_TAG.', 'one possible reason is that we have used 1d convolution, which has encoded some sequential information in to the model.', '']",0
['with self - attention has achieved great'],['with self - attention has achieved great'],['with self - attention has achieved great success in'],"['with self - attention has achieved great success in the area of nature language processing.', 'recently, there have been a few studies on  #TAUTHOR_TAG for end - to - end speech recognition, while its application for hybrid acoustic model is still very limited.', 'in this paper, we revisit the  #TAUTHOR_TAG - based hybrid acoustic model, and propose a model structure with interleaved self - attention and 1d convolution, which is proven to have faster convergence and higher recognition accuracy.', 'we also study several aspects of the  #TAUTHOR_TAG, including the impact of the positional encoding feature, dropout regularization, as well as training with and without time restriction.', 'we show competitive recognition results on the public librispeech dataset when compared to the kaldi baseline at both cross entropy training and sequence training stages.', 'for reproducible research, we release our source code and recipe within the pykaldi2 toolbox']",1
"['', ' #TAUTHOR_TAG, language modeling']","['inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as']","['inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as']","['neural networks ( rnns ) with long short - term memory ( lstm ) [ 1 ] units have defined the state - of - the - art large - scale speech recognition since 2014 [ 2 ].', 'while there have been new types of sequence modeling approaches which are proposed and explored for speech recognition recently, such as sequence - to - sequence with attention [ 3, 4, 5 ], connectionist temporal classification [ 6 ] and recurrent neural network transducer [ 6 ], lstm - rnns remains the most popular neural network architectures for learning speech feature representations, although convolutional neural networks ( cnns ) with different variants have shown competitive recognition results for some tasks.', 'the key behind the success of rnns is their capacity to learn temporal correlations in sequential signals through the recurrent connections when the networks are trained with the back - propagation through time ( bptt ) [ 7 ] algorithm.', 'however, a well - known weakness of rnns is the gradient vanishing or explosion problem due to bptt, and the recurrent connections in rnns make it challenging to parallelize the computations in both training and inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as end - to - end speech recognition [ 10, 11 ].', 'self - attention is appealing for sequence modeling in the sense that it can learn long - term correlations by one step of attention operation, while for rnns, it would take multiple steps in the time space for both forward and backward computation, and noise may accumulate during the process.', 'cnns, on the other hand, require multiple layers to capture the correlations between the two features which are very distant in the time space, although dilation that uses large strides can reduce the number of layers that is required.', 'while there have been many studies on end - to - end speech recognition using  #TAUTHOR_TAG [ 10, 11, 12, 13, 14 ], their applications for hybrid acoustic models are less well understood.', 'in this paper, we study the more standard  #TAUTHOR_TAG for speech recognition within the hybrid framework, and provide further insight to this model through experiments on the librispeech public dataset']",1
['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the']",['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system', '']",1
['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the']",['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system', '']",1
['- sequence model based on  #TAUTHOR_TAG'],['sequenceto - sequence model based on  #TAUTHOR_TAG'],['- sequence model based on  #TAUTHOR_TAG'],"['', 'however, this is very challenging for sequenceto - sequence model based on  #TAUTHOR_TAG as the boundary for each output token is unclear.', 'for hybrid models, the latency is controllable by adjusting the size of the time restriction window.', '']",1
[' #TAUTHOR_TAG has been very'],[' #TAUTHOR_TAG has been very'],[' #TAUTHOR_TAG has been very'],"[' #TAUTHOR_TAG has been very successful in the area of nature language processing, its application to speech recognition is mostly within the end - to - end architecture.', 'we are more interested in  #TAUTHOR_TAG for hybrid acoustic models as there is no theoretical issues for online streaming speech recognition.', 'in this paper, we have presented a  #TAUTHOR_TAG model with interleaved self - attention and convolution for hybrid acoustic modeling, although this structure may be also applicable to end - to - end models.', 'we have showed that the convolutional layers can improve the recognition accuracy with faster convergence compared to the model with self - attention layers only.', 'we have also investigated several other aspects of the model including the impact of the positional encoding feature, dropout regularization as well training with and without the time restriction.', 'our work is an addition to the current study of self - attention for hybrid models with a sequential tdnn and self - attention architecture trained with time restriction only.', 'for our future works, we shall study training much deeper  #TAUTHOR_TAG with low frame rate to get rid of the gpu memory constraint, as well as evaluate the model in the setting with a very large amount of training data']",1
['with self - attention has achieved great'],['with self - attention has achieved great'],['with self - attention has achieved great success in'],"['with self - attention has achieved great success in the area of nature language processing.', 'recently, there have been a few studies on  #TAUTHOR_TAG for end - to - end speech recognition, while its application for hybrid acoustic model is still very limited.', 'in this paper, we revisit the  #TAUTHOR_TAG - based hybrid acoustic model, and propose a model structure with interleaved self - attention and 1d convolution, which is proven to have faster convergence and higher recognition accuracy.', 'we also study several aspects of the  #TAUTHOR_TAG, including the impact of the positional encoding feature, dropout regularization, as well as training with and without time restriction.', 'we show competitive recognition results on the public librispeech dataset when compared to the kaldi baseline at both cross entropy training and sequence training stages.', 'for reproducible research, we release our source code and recipe within the pykaldi2 toolbox']",6
"['', ' #TAUTHOR_TAG, language modeling']","['inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as']","['inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as']","['neural networks ( rnns ) with long short - term memory ( lstm ) [ 1 ] units have defined the state - of - the - art large - scale speech recognition since 2014 [ 2 ].', 'while there have been new types of sequence modeling approaches which are proposed and explored for speech recognition recently, such as sequence - to - sequence with attention [ 3, 4, 5 ], connectionist temporal classification [ 6 ] and recurrent neural network transducer [ 6 ], lstm - rnns remains the most popular neural network architectures for learning speech feature representations, although convolutional neural networks ( cnns ) with different variants have shown competitive recognition results for some tasks.', 'the key behind the success of rnns is their capacity to learn temporal correlations in sequential signals through the recurrent connections when the networks are trained with the back - propagation through time ( bptt ) [ 7 ] algorithm.', 'however, a well - known weakness of rnns is the gradient vanishing or explosion problem due to bptt, and the recurrent connections in rnns make it challenging to parallelize the computations in both training and inference stages.', ' #TAUTHOR_TAG, language modeling [ 9 ], as well as end - to - end speech recognition [ 10, 11 ].', 'self - attention is appealing for sequence modeling in the sense that it can learn long - term correlations by one step of attention operation, while for rnns, it would take multiple steps in the time space for both forward and backward computation, and noise may accumulate during the process.', 'cnns, on the other hand, require multiple layers to capture the correlations between the two features which are very distant in the time space, although dilation that uses large strides can reduce the number of layers that is required.', 'while there have been many studies on end - to - end speech recognition using  #TAUTHOR_TAG [ 10, 11, 12, 13, 14 ], their applications for hybrid acoustic models are less well understood.', 'in this paper, we study the more standard  #TAUTHOR_TAG for speech recognition within the hybrid framework, and provide further insight to this model through experiments on the librispeech public dataset']",6
['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the']",['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model'],"['boundary for chunk - wise self - attention.  #TAUTHOR_TAG based transducer [ 13 ] and ctc model [ 14 ] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system', '']",6
['with self - attention has achieved great'],['with self - attention has achieved great'],['with self - attention has achieved great success in'],"['with self - attention has achieved great success in the area of nature language processing.', 'recently, there have been a few studies on  #TAUTHOR_TAG for end - to - end speech recognition, while its application for hybrid acoustic model is still very limited.', 'in this paper, we revisit the  #TAUTHOR_TAG - based hybrid acoustic model, and propose a model structure with interleaved self - attention and 1d convolution, which is proven to have faster convergence and higher recognition accuracy.', 'we also study several aspects of the  #TAUTHOR_TAG, including the impact of the positional encoding feature, dropout regularization, as well as training with and without time restriction.', 'we show competitive recognition results on the public librispeech dataset when compared to the kaldi baseline at both cross entropy training and sequence training stages.', 'for reproducible research, we release our source code and recipe within the pykaldi2 toolbox']",5
"['each component in the standard  #TAUTHOR_TAG, and discuss a model structure that is mainly investigated']","['each component in the standard  #TAUTHOR_TAG, and discuss a model structure that is mainly investigated']","['this section, we review each component in the standard  #TAUTHOR_TAG, and discuss a model structure that is mainly investigated']","['this section, we review each component in the standard  #TAUTHOR_TAG, and discuss a model structure that is mainly investigated for speech recognition in this work']",5
"['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diver']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.', 'we hypothesize that this is']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diver']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.', 'we hypothesize that this is due to the nature of hybrid models, which are expected to predict the frame - level labels.', 'hence, they are more sensitive to any reordering or shifting of the acoustic information in the time space compared with sequence - to - sequence models.', 'the positional encoding along may not be able to provide sufficient information to maintain the sequential information in the acoustic sequence ( cf. section 4. 1 ).', 'in this paper, we propose a  #TAUTHOR_TAG model with interleaved 1d convolution and self - attention, with the motivation that the convolution layer can maintain the sequential information of the input sequence, while at the same time, it can learn the local correlations.', 'self - attention, on the other hand, is expected to capture the global information as the attention is performed as the entire sequence level.', 'the model with interleaved convolution and self - attention has the flexibility to tradeoff the model capacity for learning both local and global information from the input sequence.', 'same as the standard  #TAUTHOR_TAG, we also insert the feedforward layer after the multi - head attention.', 'the final model structure is shown in figure 1.', '']",5
"['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diver']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.', 'we hypothesize that this is']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diver']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.', 'we hypothesize that this is due to the nature of hybrid models, which are expected to predict the frame - level labels.', 'hence, they are more sensitive to any reordering or shifting of the acoustic information in the time space compared with sequence - to - sequence models.', 'the positional encoding along may not be able to provide sufficient information to maintain the sequential information in the acoustic sequence ( cf. section 4. 1 ).', 'in this paper, we propose a  #TAUTHOR_TAG model with interleaved 1d convolution and self - attention, with the motivation that the convolution layer can maintain the sequential information of the input sequence, while at the same time, it can learn the local correlations.', 'self - attention, on the other hand, is expected to capture the global information as the attention is performed as the entire sequence level.', 'the model with interleaved convolution and self - attention has the flexibility to tradeoff the model capacity for learning both local and global information from the input sequence.', 'same as the standard  #TAUTHOR_TAG, we also insert the feedforward layer after the multi - head attention.', 'the final model structure is shown in figure 1.', '']",5
"['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diver']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.', 'we hypothesize that this is']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diver']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.', 'we hypothesize that this is due to the nature of hybrid models, which are expected to predict the frame - level labels.', 'hence, they are more sensitive to any reordering or shifting of the acoustic information in the time space compared with sequence - to - sequence models.', 'the positional encoding along may not be able to provide sufficient information to maintain the sequential information in the acoustic sequence ( cf. section 4. 1 ).', 'in this paper, we propose a  #TAUTHOR_TAG model with interleaved 1d convolution and self - attention, with the motivation that the convolution layer can maintain the sequential information of the input sequence, while at the same time, it can learn the local correlations.', 'self - attention, on the other hand, is expected to capture the global information as the attention is performed as the entire sequence level.', 'the model with interleaved convolution and self - attention has the flexibility to tradeoff the model capacity for learning both local and global information from the input sequence.', 'same as the standard  #TAUTHOR_TAG, we also insert the feedforward layer after the multi - head attention.', 'the final model structure is shown in figure 1.', '']",5
"['of the  #TAUTHOR_TAG to be 6 layers, and the']","['of the  #TAUTHOR_TAG to be 6 layers, and the']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in the feedforward layer is 2048.', 'the kernel size for each convolution layer is 3 without stride.', 'the total number of parameters is around 26. 6 million.', 'we did some experiments using a smaller model, and the results are worse than what we reported here.', 'we did not train deeper  #TAUTHOR_TAG due to the memory constraint.', 'in our experiments, we used a high frame rate as 100 hz, i. e., extracting one acoustic frame in every 10 millisecond.', 'this led to long acoustic sequences.', 'as the memory cost of self - attention is in the order of o ( t 2 ), where t is the length of the acoustic sequence, lower frame rate would significantly cut down the memory cost, and enable the training of much deeper  #TAUTHOR_TAG that will studied in our future work.', 'in terms of acoustic features, we used 80 - dimensional raw logmel filter - banks ( fbanks ), and we did not perform any form of speaker - level feature normalization.', 'instead, we only applied the utterance - level mean and variance normalization.', 'we used a 4 - gram language model for decoding that is released as the part of the corpus, and we used kaldi [ 15 ] to build a gaussian mixture model ( gmm ) system for bootstrapping.', 'our  #TAUTHOR_TAG acoustic models were trained using the pykaldi2 toolbox [ 22 ], which is built on top of kaldi and pytorch through the pykaldi [ 23 ] wrapper.', 'we used the adam optimizer [ 24 ] cross entropy ( ce ) training, and the same learning rate scheduler as in  #TAUTHOR_TAG.', 'for sequence training, we used the vanilla stochastic gradient decent ( sgd ) with fixed learning rate']",5
"['of the  #TAUTHOR_TAG to be 6 layers, and the']","['of the  #TAUTHOR_TAG to be 6 layers, and the']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in the feedforward layer is 2048.', 'the kernel size for each convolution layer is 3 without stride.', 'the total number of parameters is around 26. 6 million.', 'we did some experiments using a smaller model, and the results are worse than what we reported here.', 'we did not train deeper  #TAUTHOR_TAG due to the memory constraint.', 'in our experiments, we used a high frame rate as 100 hz, i. e., extracting one acoustic frame in every 10 millisecond.', 'this led to long acoustic sequences.', 'as the memory cost of self - attention is in the order of o ( t 2 ), where t is the length of the acoustic sequence, lower frame rate would significantly cut down the memory cost, and enable the training of much deeper  #TAUTHOR_TAG that will studied in our future work.', 'in terms of acoustic features, we used 80 - dimensional raw logmel filter - banks ( fbanks ), and we did not perform any form of speaker - level feature normalization.', 'instead, we only applied the utterance - level mean and variance normalization.', 'we used a 4 - gram language model for decoding that is released as the part of the corpus, and we used kaldi [ 15 ] to build a gaussian mixture model ( gmm ) system for bootstrapping.', 'our  #TAUTHOR_TAG acoustic models were trained using the pykaldi2 toolbox [ 22 ], which is built on top of kaldi and pytorch through the pykaldi [ 23 ] wrapper.', 'we used the adam optimizer [ 24 ] cross entropy ( ce ) training, and the same learning rate scheduler as in  #TAUTHOR_TAG.', 'for sequence training, we used the vanilla stochastic gradient decent ( sgd ) with fixed learning rate']",5
"['2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in']","['3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in']","['first evaluated the positional encoding discussed in section 3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in table 2.', 'unlike the observations in']","['first evaluated the positional encoding discussed in section 3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in table 2.', 'unlike the observations in the area of machine translation, positional encoding did not make a big difference in terms of recognition accuracies for our  #TAUTHOR_TAG.', 'one possible reason is that we have used 1d convolution, which has encoded some sequential information in to the model.', '']",5
"['2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in']","['3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in']","['first evaluated the positional encoding discussed in section 3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in table 2.', 'unlike the observations in']","['first evaluated the positional encoding discussed in section 3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in table 2.', 'unlike the observations in the area of machine translation, positional encoding did not make a big difference in terms of recognition accuracies for our  #TAUTHOR_TAG.', 'one possible reason is that we have used 1d convolution, which has encoded some sequential information in to the model.', '']",5
"['2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in']","['3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in']","['first evaluated the positional encoding discussed in section 3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in table 2.', 'unlike the observations in']","['first evaluated the positional encoding discussed in section 3. 2 and dropout training for the  #TAUTHOR_TAG.', 'results are given in table 2.', 'unlike the observations in the area of machine translation, positional encoding did not make a big difference in terms of recognition accuracies for our  #TAUTHOR_TAG.', 'one possible reason is that we have used 1d convolution, which has encoded some sequential information in to the model.', '']",5
"['convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', 'we still added the positional encoding feature to the inputs since the sequential information from the convolution layers is no longer available.', '']",5
"['convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', 'we still added the positional encoding feature to the inputs since the sequential information from the convolution layers is no longer available.', '']",5
['- sequence model based on  #TAUTHOR_TAG'],['sequenceto - sequence model based on  #TAUTHOR_TAG'],['- sequence model based on  #TAUTHOR_TAG'],"['', 'however, this is very challenging for sequenceto - sequence model based on  #TAUTHOR_TAG as the boundary for each output token is unclear.', 'for hybrid models, the latency is controllable by adjusting the size of the time restriction window.', '']",5
"['of the  #TAUTHOR_TAG model trained with the maximum mutual information ( mmi ) criterion.', '']","['of the  #TAUTHOR_TAG model trained with the maximum mutual information ( mmi ) criterion.', '']","['table 5, we show the sequence training results of the  #TAUTHOR_TAG model trained with the maximum mutual information ( mmi ) criterion.', 'we followed the traditional lattice - based sequence training approach, and the lattices were generated on - the - fly as implemented in pykaldi2.', 'we used a ce trained model as the seed model,']","['table 5, we show the sequence training results of the  #TAUTHOR_TAG model trained with the maximum mutual information ( mmi ) criterion.', 'we followed the traditional lattice - based sequence training approach, and the lattices were generated on - the - fly as implemented in pykaldi2.', 'we used a ce trained model as the seed model, and then trained the model with mmi using the vanilla sgd optimizer.', 'we fixed learning rate as 5 × 10 −5, and to avoid overfitting, we applied the ce regularization with weight as 0. 2.', 'the model was converged in less than 1 epoch.', 'table 5 shows that we obtained larger improvements on the noisy test sets ( dev - other, test - other ).', 'our results are comparable to the results of the tdnn system in kaldi 1, which is a well - tuned hybrid system.', 'in fact, the tdnn system applied the speed perturbation [ 25 ] for data argumentation and ivector based speaker adaptive training, while in our system, we only used the raw log - mel filterbank features without using any speakerlevel information.', 'from that sense, our results are very competitive.', 'han et al. [ 17, 18 ] achieved better results by using multi - stream and multi - stride features on top of the tdnn system, which are also applicable to our system, and will be investigated in the future']",5
[' #TAUTHOR_TAG has been very'],[' #TAUTHOR_TAG has been very'],[' #TAUTHOR_TAG has been very'],"[' #TAUTHOR_TAG has been very successful in the area of nature language processing, its application to speech recognition is mostly within the end - to - end architecture.', 'we are more interested in  #TAUTHOR_TAG for hybrid acoustic models as there is no theoretical issues for online streaming speech recognition.', 'in this paper, we have presented a  #TAUTHOR_TAG model with interleaved self - attention and convolution for hybrid acoustic modeling, although this structure may be also applicable to end - to - end models.', 'we have showed that the convolutional layers can improve the recognition accuracy with faster convergence compared to the model with self - attention layers only.', 'we have also investigated several other aspects of the model including the impact of the positional encoding feature, dropout regularization as well training with and without the time restriction.', 'our work is an addition to the current study of self - attention for hybrid models with a sequential tdnn and self - attention architecture trained with time restriction only.', 'for our future works, we shall study training much deeper  #TAUTHOR_TAG with low frame rate to get rid of the gpu memory constraint, as well as evaluate the model in the setting with a very large amount of training data']",5
[' #TAUTHOR_TAG has been very'],[' #TAUTHOR_TAG has been very'],[' #TAUTHOR_TAG has been very'],"[' #TAUTHOR_TAG has been very successful in the area of nature language processing, its application to speech recognition is mostly within the end - to - end architecture.', 'we are more interested in  #TAUTHOR_TAG for hybrid acoustic models as there is no theoretical issues for online streaming speech recognition.', 'in this paper, we have presented a  #TAUTHOR_TAG model with interleaved self - attention and convolution for hybrid acoustic modeling, although this structure may be also applicable to end - to - end models.', 'we have showed that the convolutional layers can improve the recognition accuracy with faster convergence compared to the model with self - attention layers only.', 'we have also investigated several other aspects of the model including the impact of the positional encoding feature, dropout regularization as well training with and without the time restriction.', 'our work is an addition to the current study of self - attention for hybrid models with a sequential tdnn and self - attention architecture trained with time restriction only.', 'for our future works, we shall study training much deeper  #TAUTHOR_TAG with low frame rate to get rid of the gpu memory constraint, as well as evaluate the model in the setting with a very large amount of training data']",5
['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],['attention mechanism in  #TAUTHOR_TAG is technically the'],"['attention mechanism in  #TAUTHOR_TAG is technically the same as in the original rnn - based attention model [ 19 ].', 'the key difference is that the query used to compute the attention probability is also from the source sequence, instead of using the decoder hidden state as in the rnn - based attention model [ 19 ].', '']",4
"['of the  #TAUTHOR_TAG to be 6 layers, and the']","['of the  #TAUTHOR_TAG to be 6 layers, and the']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in the feedforward layer is 2048.', 'the kernel size for each convolution layer is 3 without stride.', 'the total number of parameters is around 26. 6 million.', 'we did some experiments using a smaller model, and the results are worse than what we reported here.', 'we did not train deeper  #TAUTHOR_TAG due to the memory constraint.', 'in our experiments, we used a high frame rate as 100 hz, i. e., extracting one acoustic frame in every 10 millisecond.', 'this led to long acoustic sequences.', 'as the memory cost of self - attention is in the order of o ( t 2 ), where t is the length of the acoustic sequence, lower frame rate would significantly cut down the memory cost, and enable the training of much deeper  #TAUTHOR_TAG that will studied in our future work.', 'in terms of acoustic features, we used 80 - dimensional raw logmel filter - banks ( fbanks ), and we did not perform any form of speaker - level feature normalization.', 'instead, we only applied the utterance - level mean and variance normalization.', 'we used a 4 - gram language model for decoding that is released as the part of the corpus, and we used kaldi [ 15 ] to build a gaussian mixture model ( gmm ) system for bootstrapping.', 'our  #TAUTHOR_TAG acoustic models were trained using the pykaldi2 toolbox [ 22 ], which is built on top of kaldi and pytorch through the pykaldi [ 23 ] wrapper.', 'we used the adam optimizer [ 24 ] cross entropy ( ce ) training, and the same learning rate scheduler as in  #TAUTHOR_TAG.', 'for sequence training, we used the vanilla stochastic gradient decent ( sgd ) with fixed learning rate']",4
['- sequence model based on  #TAUTHOR_TAG'],['sequenceto - sequence model based on  #TAUTHOR_TAG'],['- sequence model based on  #TAUTHOR_TAG'],"['', 'however, this is very challenging for sequenceto - sequence model based on  #TAUTHOR_TAG as the boundary for each output token is unclear.', 'for hybrid models, the latency is controllable by adjusting the size of the time restriction window.', '']",4
['- sequence model based on  #TAUTHOR_TAG'],['sequenceto - sequence model based on  #TAUTHOR_TAG'],['- sequence model based on  #TAUTHOR_TAG'],"['', 'however, this is very challenging for sequenceto - sequence model based on  #TAUTHOR_TAG as the boundary for each output token is unclear.', 'for hybrid models, the latency is controllable by adjusting the size of the time restriction window.', '']",4
"['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diver']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.', 'we hypothesize that this is']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diver']","['hybrid models, our preliminary experiments show that  #TAUTHOR_TAG with multiple self - attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.', 'we hypothesize that this is due to the nature of hybrid models, which are expected to predict the frame - level labels.', 'hence, they are more sensitive to any reordering or shifting of the acoustic information in the time space compared with sequence - to - sequence models.', 'the positional encoding along may not be able to provide sufficient information to maintain the sequential information in the acoustic sequence ( cf. section 4. 1 ).', 'in this paper, we propose a  #TAUTHOR_TAG model with interleaved 1d convolution and self - attention, with the motivation that the convolution layer can maintain the sequential information of the input sequence, while at the same time, it can learn the local correlations.', 'self - attention, on the other hand, is expected to capture the global information as the attention is performed as the entire sequence level.', 'the model with interleaved convolution and self - attention has the flexibility to tradeoff the model capacity for learning both local and global information from the input sequence.', 'same as the standard  #TAUTHOR_TAG, we also insert the feedforward layer after the multi - head attention.', 'the final model structure is shown in figure 1.', '']",3
"['of the  #TAUTHOR_TAG to be 6 layers, and the']","['of the  #TAUTHOR_TAG to be 6 layers, and the']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in the feedforward layer is 2048.', 'the kernel size for each convolution layer is 3 without stride.', 'the total number of parameters is around 26. 6 million.', 'we did some experiments using a smaller model, and the results are worse than what we reported here.', 'we did not train deeper  #TAUTHOR_TAG due to the memory constraint.', 'in our experiments, we used a high frame rate as 100 hz, i. e., extracting one acoustic frame in every 10 millisecond.', 'this led to long acoustic sequences.', 'as the memory cost of self - attention is in the order of o ( t 2 ), where t is the length of the acoustic sequence, lower frame rate would significantly cut down the memory cost, and enable the training of much deeper  #TAUTHOR_TAG that will studied in our future work.', 'in terms of acoustic features, we used 80 - dimensional raw logmel filter - banks ( fbanks ), and we did not perform any form of speaker - level feature normalization.', 'instead, we only applied the utterance - level mean and variance normalization.', 'we used a 4 - gram language model for decoding that is released as the part of the corpus, and we used kaldi [ 15 ] to build a gaussian mixture model ( gmm ) system for bootstrapping.', 'our  #TAUTHOR_TAG acoustic models were trained using the pykaldi2 toolbox [ 22 ], which is built on top of kaldi and pytorch through the pykaldi [ 23 ] wrapper.', 'we used the adam optimizer [ 24 ] cross entropy ( ce ) training, and the same learning rate scheduler as in  #TAUTHOR_TAG.', 'for sequence training, we used the vanilla stochastic gradient decent ( sgd ) with fixed learning rate']",3
"['convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', '']","['then evaluated the impact of the 1d convolution layers in our  #TAUTHOR_TAG model by removing all the convolution layers.', 'this corresponds to a vanilla  #TAUTHOR_TAG.', 'we still added the positional encoding feature to the inputs since the sequential information from the convolution layers is no longer available.', '']",3
"['of the  #TAUTHOR_TAG to be 6 layers, and the']","['of the  #TAUTHOR_TAG to be 6 layers, and the']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in']","['performed the experiments using the publicly available librispeech corpus [ 21 ], which contains around 960 hours of training data in total.', 'to constrain our research scope, we fixed the depth of the  #TAUTHOR_TAG to be 6 layers, and the dimension of the model d k in eq ( 1 ) to be 512.', 'the number of hidden units in the feedforward layer is 2048.', 'the kernel size for each convolution layer is 3 without stride.', 'the total number of parameters is around 26. 6 million.', 'we did some experiments using a smaller model, and the results are worse than what we reported here.', 'we did not train deeper  #TAUTHOR_TAG due to the memory constraint.', 'in our experiments, we used a high frame rate as 100 hz, i. e., extracting one acoustic frame in every 10 millisecond.', 'this led to long acoustic sequences.', 'as the memory cost of self - attention is in the order of o ( t 2 ), where t is the length of the acoustic sequence, lower frame rate would significantly cut down the memory cost, and enable the training of much deeper  #TAUTHOR_TAG that will studied in our future work.', 'in terms of acoustic features, we used 80 - dimensional raw logmel filter - banks ( fbanks ), and we did not perform any form of speaker - level feature normalization.', 'instead, we only applied the utterance - level mean and variance normalization.', 'we used a 4 - gram language model for decoding that is released as the part of the corpus, and we used kaldi [ 15 ] to build a gaussian mixture model ( gmm ) system for bootstrapping.', 'our  #TAUTHOR_TAG acoustic models were trained using the pykaldi2 toolbox [ 22 ], which is built on top of kaldi and pytorch through the pykaldi [ 23 ] wrapper.', 'we used the adam optimizer [ 24 ] cross entropy ( ce ) training, and the same learning rate scheduler as in  #TAUTHOR_TAG.', 'for sequence training, we used the vanilla stochastic gradient decent ( sgd ) with fixed learning rate']",2
[' #TAUTHOR_TAG has been very'],[' #TAUTHOR_TAG has been very'],[' #TAUTHOR_TAG has been very'],"[' #TAUTHOR_TAG has been very successful in the area of nature language processing, its application to speech recognition is mostly within the end - to - end architecture.', 'we are more interested in  #TAUTHOR_TAG for hybrid acoustic models as there is no theoretical issues for online streaming speech recognition.', 'in this paper, we have presented a  #TAUTHOR_TAG model with interleaved self - attention and convolution for hybrid acoustic modeling, although this structure may be also applicable to end - to - end models.', 'we have showed that the convolutional layers can improve the recognition accuracy with faster convergence compared to the model with self - attention layers only.', 'we have also investigated several other aspects of the model including the impact of the positional encoding feature, dropout regularization as well training with and without the time restriction.', 'our work is an addition to the current study of self - attention for hybrid models with a sequential tdnn and self - attention architecture trained with time restriction only.', 'for our future works, we shall study training much deeper  #TAUTHOR_TAG with low frame rate to get rid of the gpu memory constraint, as well as evaluate the model in the setting with a very large amount of training data']",2
"['predicting text quality seems rather limited  #AUTHOR_TAG. very recently, however', ',  #AUTHOR_TAG and  #TAUTHOR_TAG even if these results were']","['predicting text quality seems rather limited  #AUTHOR_TAG. very recently, however', ',  #AUTHOR_TAG and  #TAUTHOR_TAG even if these results were']","['predicting text quality seems rather limited  #AUTHOR_TAG. very recently, however', ',  #AUTHOR_TAG and  #TAUTHOR_TAG even if these results were']",[' #TAUTHOR_TAG'],1
"['median,  #AUTHOR_TAG and  #TAUTHOR_TAG used a standard procedure in descriptive statistics and automatic information']","['median,  #AUTHOR_TAG and  #TAUTHOR_TAG used a standard procedure in descriptive statistics and automatic information']","['the median,  #AUTHOR_TAG and  #TAUTHOR_TAG used a standard procedure in descriptive statistics and automatic information processing known as discretization, binning or quantization  #AUTHOR_TAG.', 'it divides a continuous variable into bins and counts the proportion of scores that fall into each bin.', 'in their analyses, the boundaries of the bins were manually and arbitrarily defined.', 'this approach can be used for any as, but it makes the comparison of the effectiveness of them difficult']","['', 'mutual rank ratio ( mrr,  #AUTHOR_TAG, a nonparametric measure that has been successful in detecting collocation errors in efl texts  #AUTHOR_TAG, 6. logdice  #AUTHOR_TAG, a logarithmic transformation of the dice coefficient used in the sketch engine  #AUTHOR_TAG.', 'in order to extract more information from the distribution of the ass in each text than the mean or the median,  #AUTHOR_TAG and  #TAUTHOR_TAG used a standard procedure in descriptive statistics and automatic information processing known as discretization, binning or quantization  #AUTHOR_TAG.', 'it divides a continuous variable into bins and counts the proportion of scores that fall into each bin.', 'in their analyses, the boundaries of the bins were manually and arbitrarily defined.', 'this approach can be used for any as, but it makes the comparison of the effectiveness of them difficult because a weaker performance may come from a less effective as or from poorly chosen bin boundaries.', 'to reduce the potential impact of the choice of boundaries, a very simple and completely automatic discretization procedure was used : the equal frequency discretizer, which divides the sorted values into k intervals so that each interval contains approximately the same number of values  #AUTHOR_TAG.', 'it is unsupervised and depends on only one parameter ( i. e., the number of bins ).', ""in the present study, it was applied separately for each as, to every bigram present in the learners'texts and consists of two steps :"", '1. partitioning the distribution of scores in bins containing the same number of bigrams, 2']",0
['##al features : the global statistical features in  #TAUTHOR_TAG and were used : the mean'],"['an overall mark has been assigned.', 'as in  #AUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #TAUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and']","['##al features : the global statistical features in  #TAUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams']","[': the analyses were conducted on the first certificate in english ( fce ) esol examination scripts described in  #AUTHOR_TAG yannakoudakis et al. (, 2012.', 'extracted from the cambridge learner corpus, this dataset consists of 1238 texts of between 200 and 400 words, to which an overall mark has been assigned.', 'as in  #AUTHOR_TAG, the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.', 'collocational features : the global statistical features in  #TAUTHOR_TAG and were used : the mean, the median, the maximum and the minimum of the ass, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.', 'because the best number of bins for discretizing the distributions was not known, the following ones were compared : 3, 5, 8, 10, 15, 20, 25, 33, 50, 75 and 100. to get all these features, each learner text was tokenized and pos - tagged by means of claws7 2 and all bigrams were extracted.', 'punctuation marks and any sequence of characters that did not correspond to a word interrupt the bigram extraction.', 'each bigram was then looked up in the 100 million word british national corpus ( bnc 3 ) and, if found, assigned its ass.', 'the collocational features were then computed on the basis of all the different bigrams present in each text ( types ) to give more weight to their diversity  #AUTHOR_TAG.', 'lexical features : as a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset  #AUTHOR_TAG were chosen.', 'they consist of the frequency of the word unigrams and bigrams.', 'this baseline is particularly relevant because it includes the lexical bigrams that are the basis of the collocational features.', 'these features were extracted as described in  #AUTHOR_TAG ; the only difference is that they used the rasp tagger and not the claws tagger.', 'supervised learning approach and evaluation : as in  #AUTHOR_TAG, the automated scoring task was treated as a rankpreference learning problem by means of the svm - rank package  #AUTHOR_TAG, which is a much faster version of the svm - light package used by  #AUTHOR_TAG.', 'the procedure was identical to that described in their study.', ""since the quality ratings are distributed on a zero to 40 scale, i chose pearson's correlation coefficient, also used by  #AUTHOR_TAG, as the measure of performance""]",5
"['discretizing the ass is at least as effective as the bin boundaries manually set by  #TAUTHOR_TAG, i used them instead of the automatic bins for the model with eight bins based on mi.', 'the']","['discretizing the ass is at least as effective as the bin boundaries manually set by  #TAUTHOR_TAG, i used them instead of the automatic bins for the model with eight bins based on mi.', 'the']","['discretizing the ass is at least as effective as the bin boundaries manually set by  #TAUTHOR_TAG, i used them instead of the automatic bins for the model with eight bins based on mi.', 'the correlation obtained was 0. 60, a value slightly lower than']","['no discretization procedure was used ( the 0 row ), fisher was far more effective than the other ass, followed by mi.', 'adding the discretized features led to far better performances ( except for logdice ), as shown by the mean row.', 'for a small number of bins, fisher remained the best, but for an intermediate number, the best were t and simple - ll, and for a large number, z became competitive.', 'still, the differences between the best ass were quite small.', 'from eight bins and beyond, using all the ass gave the best result, but the gain was relatively small.', 'regarding the number of bins, at least five seems necessary, but using many more did not harm performance.', 'it is noteworthy that all the correlations reported in table 1 are much larger that the correlation of a baseline system based purely on length ( r = 0. 27 ).', 'to determine if the automatic procedure for discretizing the ass is at least as effective as the bin boundaries manually set by  #TAUTHOR_TAG, i used them instead of the automatic bins for the model with eight bins based on mi.', 'the correlation obtained was 0. 60, a value slightly lower than that reported in table 1 ( 0. 61 )']",5
"['mentioning.', ""unlike  #TAUTHOR_TAG, i only used bigrams'collocational features."", '']","['mentioning.', ""unlike  #TAUTHOR_TAG, i only used bigrams'collocational features."", '']","['.', 'further developments are worth mentioning.', ""unlike  #TAUTHOR_TAG, i only used bigrams'collocational features."", '']","['on from  #AUTHOR_TAG,  #AUTHOR_TAG and, this study confirms the benefits conferred by collocational features for the automated scoring of efl texts.', 'it also shows that these features improve a competitive baseline, based among other factors on the bigram frequenprocedure, the difference probably comes from the svmrank / svm - light parameters.', 'the svm - rank default settings were used except for the squared slacks for the l - norm ( i. e., - p 2 ) because it provided a high performance without having to optimize other parameters such as c. cies in the texts.', 'as proposed by  #AUTHOR_TAG, binning the as distributions improves the efficiency and, as proposed by  #AUTHOR_TAG, considering several ass also gives extra efficiency.', 'compared to, the binning allows t to be as effective as the mi.', 'this result suggests that it might be interesting to analyse more thoroughly the complex relationship between the as distributions in a text and its quality.', 'it must be kept in mind that these observations result from the analysis of a single dataset and replications are more than desirable.', 'it is also necessary to determine whether the collocational features can improve not only the baseline used here, but also a predictive model that includes many other features known for their effectiveness.', 'further developments are worth mentioning.', ""unlike  #TAUTHOR_TAG, i only used bigrams'collocational features."", 'whether adding trigrams would further improve the performance is an open question.', 'trying to answer it requires a thorough study of the association measures for ngrams longer than two words since they have received much less attention  #AUTHOR_TAG.', 'it might also be interesting to evaluate other techniques to discretize the as distributions, since this study rests on one of the simplest techniques.', 'further studies are also needed to better understand the impact of the combination of ass.', 'on the one hand, it is likely that some ass are partially redundant and that keeping only one might be enough.', 'on the other hand, it would be interesting to determine whether, rather than combining the as bin proportions independently, it would be better to create the bins on the simultaneous basis of two or more ass, such as one bin for the bigrams with high mi scores and medium t - scores']",4
"['gender bias, in those representation  #TAUTHOR_TAG']","['gender bias, in those representation  #TAUTHOR_TAG']","['gender bias, in those representation  #TAUTHOR_TAG.', 'this can affect downstream applications  #AUTHOR_TAG a ) and']","['is one of the most interesting and complex skills used in our daily life, and may even be taken for granted on our ability to communicate.', 'however, the understanding of meanings between lines in natural languages is not straightforward for the logic rules of programming languages.', 'natural language processing ( nlp ) is a sub - field of artificial intelligence that focuses on making natural languages understandable to computers.', 'similarly, the translation between different natural languages is a task for machine translation ( mt ).', 'neural machine translation ( nmt ) is a recent approach in mt which learns patterns between source and target language corpora to produce text translations using deep neural networks  #AUTHOR_TAG.', 'one downside of models trained with human generated corpora is that social biases present in the data are learned.', 'this is shown when training word embeddings, a vector representation of words, in news sets with crowd - sourcing evaluation to quantify the presence of biases, such as gender bias, in those representation  #TAUTHOR_TAG.', 'this can affect downstream applications  #AUTHOR_TAG a ) and are at risk of being amplified  #AUTHOR_TAG.', 'the objective of this work is to study the presence of gender bias in mt and give insight on the impact of debiasing in such systems.', '']",0
"['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method for debiasing previously generated embeddings  #TAUTHOR_TAG.', 'gn - glove is a method for generating gender neutral embeddings  #AUTHOR_TAG b ).', 'the main ideas behind these algorithms are described next.', 'debiaswe  #TAUTHOR_TAG is a postprocess method for debiasing word embeddings.', '']",0
"['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method for debiasing previously generated embeddings  #TAUTHOR_TAG.', 'gn - glove is a method for generating gender neutral embeddings  #AUTHOR_TAG b ).', 'the main ideas behind these algorithms are described next.', 'debiaswe  #TAUTHOR_TAG is a postprocess method for debiasing word embeddings.', '']",0
"['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method']","['presence of biases in word embeddings has aroused as a topic of discussion about fairness.', 'more specifically, gender stereotypes are learned from human generated corpora as shown by  #TAUTHOR_TAG.', 'several debiasing approaches have been proposed.', 'debiaswe is a postprocess method for debiasing previously generated embeddings  #TAUTHOR_TAG.', 'gn - glove is a method for generating gender neutral embeddings  #AUTHOR_TAG b ).', 'the main ideas behind these algorithms are described next.', 'debiaswe  #TAUTHOR_TAG is a postprocess method for debiasing word embeddings.', '']",0
['##we  #TAUTHOR_TAG is a debiasing post - process'],"['3.', 'debiaswe  #TAUTHOR_TAG is a debiasing post - process']",['##we  #TAUTHOR_TAG is a debiasing post - process'],"['word embeddings are trained from the same corpus, using glove  #AUTHOR_TAG and gn - glove  #AUTHOR_TAG b ).', 'the dimension of the vectors is settled to 512 as standard and kept through all the experiments in this study.', 'the parameter values for training the word embedding models with glove and gn - glove methods are listed in table 3.', 'debiaswe  #TAUTHOR_TAG is a debiasing post - process performed on trained embeddings.', 'instead of having parameters for learning the representation it uses a set of words to define the gender direction and to neutralize and equalize the bias from the word vectors.', 'three set of words are used in the debiaswe algorithm.', 'one set of ten pairs of words such as woman - man, girl - boy, she - he... are used to define the gender direction.', 'another set of 218 genderspecific words such as aunt, uncle, wife, husband... are used for learning a larger set of genderspecific words.', 'finally, a set of crowd - sourced male - female equalization pairs such as dad - mom, boy - girl, granpa - grandma... that represent gender direction are equalized in the algorithm.', 'for the spanish side, the sets are adapted for the task and slightly modified to avoid unclear words from the english language or unnecessary repetitions.', 'the sets from gn - glove are similarly adapted to the spanish language.', 'the architecture to train the models for the translation task is the transformer  #AUTHOR_TAG.', 'the evaluation of the performance of the model is obtained by its bleu score  #AUTHOR_TAG.', 'the parameter values used in the transformer are the same as proposed in the baseline provided by the toolkit opennmt 4 and listed in table 4.', 'opennmt has built - in tools for training with pre - trained embeddings.', 'these pre - trained embeddings have been implemented with the cor']",0
['the embeddings using debiaswe  #TAUTHOR_TAG and also trained'],['debiased the embeddings using debiaswe  #TAUTHOR_TAG and also trained'],"['machine translation, studies quantifying gender bias present in news corpora and proposing debiasing approaches for word embedding models have shown improvements on this matter.', 'we studied the impact of gender debiasing on neural machine translation.', 'we trained sets of word embeddings with the standard glove algorithm.', 'then, we debiased the embeddings using debiaswe  #TAUTHOR_TAG and also trained']","['learned from human generated corpora in natural language processing applications is a topic that has been gaining relevance over the last few years.', 'specifically, for machine translation, studies quantifying gender bias present in news corpora and proposing debiasing approaches for word embedding models have shown improvements on this matter.', 'we studied the impact of gender debiasing on neural machine translation.', 'we trained sets of word embeddings with the standard glove algorithm.', 'then, we debiased the embeddings using debiaswe  #TAUTHOR_TAG and also trained its gender neutral version with gn - glove  #AUTHOR_TAG b ).', 'we used all these different models on the transformer  #AUTHOR_TAG.', 'experiments were reported on using these word embeddings on both the encoder and decoder sides, or only the encoder side.', 'the models were evaluated using the bleu metric on the standard task of the wmt newstest2013 test set.', 'bleu performance was similar when using bias and debiased models and even improved when using the latter.', 'to study of the bias for the translations of the models, we developed a specific test set.', 'this set consists of sentences that includes context of the gender of the ambiguous "" friend "" in the english - to - spanish translation.', 'this word can be translated to feminine or masculine and the proper translation has to be derived from context.', '']",5
"['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer']","['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than']","['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer']","[', either between individuals or entities, are ubiquitous in everyday human interactions ranging from sales to legal proceedings.', ""being a good negotiator is a complex skill, requiring the ability to understand the partner's motives, ability to reason and to communicate effectively, making it a challenging task for an automated system."", 'while research in building automatically negotiating agents has primarily focused on agent - agent negotiations  #AUTHOR_TAG, there is a recent interest in agent - human negotiations  #AUTHOR_TAG as well.', 'such agents may act as mediators or can be helpful for pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than previously studied game environments  #AUTHOR_TAG.', 'lack of a well - defined structure in such negotiations allows humans or agents to express themselves more freely, which better emulates a realistic scenario.', 'interestingly, this also provides an exciting research opportunity : how can an agent leverage the behavioral cues in natural language to direct its negotiation strategies? understanding the impact of natural language on negotiation outcomes through a data - driven neural framework is the primary objective of this work.', 'we focus on buyer - seller negotiations  #TAUTHOR_TAG where two individuals negotiate the price of a given product.', 'leveraging the recent advancements  #AUTHOR_TAG in pre - trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data - driven manner ( figure 1 ).', 'early prediction of outcomes is essential for effective planning of an automatically negotiating agent.', 'although there have been attempts to gain insights into negotiations  #AUTHOR_TAG, to the best of our knowledge, we are the first to study early natural language cues through a datadriven neural system ( section 3 ).', 'our evaluations show that natural language allows the models to make better predictions by looking at only a fraction of the negotiation.', 'rather than just realizing the strategy in natural language, our empirical results suggest that language can be crucial in the planning as well.', 'we provide a sample negotiation from the test set  #TAUTHOR_TAG along with our model predictions in table 1']",0
"['planning of a negotiating agent.', 'this can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning  #TAUTHOR_TAG']","['the planning of a negotiating agent.', 'this can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning  #TAUTHOR_TAG']","['a negotiating agent.', 'this can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning  #TAUTHOR_TAG']","['', 'as more information about the final price is revealed. paired bootstrap resampling  #AUTHOR_TAG with 10, 000 bootstraps shows that for a given f, bert - gru is better than its prices - only counterpart with 95 % statistical significance.', 'the prices discussed during the negotiation still play a crucial role in making the predictions. in fact, in only 65 % of the negotiations, the first price is quoted within the first 0', '. 4 fraction of the events. this is visible in higher performance as more events', 'are seen after this point. this number is lower than average for housing, bike and car, resulting in relative better performance of price', '##only model for these categories over others. the models also show evidence of capturing', 'buyer interest. by constructing artificial negotiations, we observe that the model predictions at f = 0. 2 increase when the buyer shows more interest in the', 'product, indicating more willingness to pay. with the', 'capability to incorporate cues from natural language, such a framework can be used in the future to get negotiation feedback, in order to guide the planning of a negotiating agent.', 'this can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning  #TAUTHOR_TAG']",0
"['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer']","['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than']","['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer']","[', either between individuals or entities, are ubiquitous in everyday human interactions ranging from sales to legal proceedings.', ""being a good negotiator is a complex skill, requiring the ability to understand the partner's motives, ability to reason and to communicate effectively, making it a challenging task for an automated system."", 'while research in building automatically negotiating agents has primarily focused on agent - agent negotiations  #AUTHOR_TAG, there is a recent interest in agent - human negotiations  #AUTHOR_TAG as well.', 'such agents may act as mediators or can be helpful for pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than previously studied game environments  #AUTHOR_TAG.', 'lack of a well - defined structure in such negotiations allows humans or agents to express themselves more freely, which better emulates a realistic scenario.', 'interestingly, this also provides an exciting research opportunity : how can an agent leverage the behavioral cues in natural language to direct its negotiation strategies? understanding the impact of natural language on negotiation outcomes through a data - driven neural framework is the primary objective of this work.', 'we focus on buyer - seller negotiations  #TAUTHOR_TAG where two individuals negotiate the price of a given product.', 'leveraging the recent advancements  #AUTHOR_TAG in pre - trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data - driven manner ( figure 1 ).', 'early prediction of outcomes is essential for effective planning of an automatically negotiating agent.', 'although there have been attempts to gain insights into negotiations  #AUTHOR_TAG, to the best of our knowledge, we are the first to study early natural language cues through a datadriven neural system ( section 3 ).', 'our evaluations show that natural language allows the models to make better predictions by looking at only a fraction of the negotiation.', 'rather than just realizing the strategy in natural language, our empirical results suggest that language can be crucial in the planning as well.', 'we provide a sample negotiation from the test set  #TAUTHOR_TAG along with our model predictions in table 1']",1
"['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer']","['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than']","['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer']","[', either between individuals or entities, are ubiquitous in everyday human interactions ranging from sales to legal proceedings.', ""being a good negotiator is a complex skill, requiring the ability to understand the partner's motives, ability to reason and to communicate effectively, making it a challenging task for an automated system."", 'while research in building automatically negotiating agents has primarily focused on agent - agent negotiations  #AUTHOR_TAG, there is a recent interest in agent - human negotiations  #AUTHOR_TAG as well.', 'such agents may act as mediators or can be helpful for pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than previously studied game environments  #AUTHOR_TAG.', 'lack of a well - defined structure in such negotiations allows humans or agents to express themselves more freely, which better emulates a realistic scenario.', 'interestingly, this also provides an exciting research opportunity : how can an agent leverage the behavioral cues in natural language to direct its negotiation strategies? understanding the impact of natural language on negotiation outcomes through a data - driven neural framework is the primary objective of this work.', 'we focus on buyer - seller negotiations  #TAUTHOR_TAG where two individuals negotiate the price of a given product.', 'leveraging the recent advancements  #AUTHOR_TAG in pre - trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data - driven manner ( figure 1 ).', 'early prediction of outcomes is essential for effective planning of an automatically negotiating agent.', 'although there have been attempts to gain insights into negotiations  #AUTHOR_TAG, to the best of our knowledge, we are the first to study early natural language cues through a datadriven neural system ( section 3 ).', 'our evaluations show that natural language allows the models to make better predictions by looking at only a fraction of the negotiation.', 'rather than just realizing the strategy in natural language, our empirical results suggest that language can be crucial in the planning as well.', 'we provide a sample negotiation from the test set  #TAUTHOR_TAG along with our model predictions in table 1']",5
"['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer']","['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than']","['pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer']","[', either between individuals or entities, are ubiquitous in everyday human interactions ranging from sales to legal proceedings.', ""being a good negotiator is a complex skill, requiring the ability to understand the partner's motives, ability to reason and to communicate effectively, making it a challenging task for an automated system."", 'while research in building automatically negotiating agents has primarily focused on agent - agent negotiations  #AUTHOR_TAG, there is a recent interest in agent - human negotiations  #AUTHOR_TAG as well.', 'such agents may act as mediators or can be helpful for pedagogical purposes  #AUTHOR_TAG.', 'efforts in agent - human negotiations involving free - form natural language as a means of communication are rather sparse.', 'researchers  #TAUTHOR_TAG recently studied natural language negotiations in buyer - seller bargaining setup, which is comparatively less restricted than previously studied game environments  #AUTHOR_TAG.', 'lack of a well - defined structure in such negotiations allows humans or agents to express themselves more freely, which better emulates a realistic scenario.', 'interestingly, this also provides an exciting research opportunity : how can an agent leverage the behavioral cues in natural language to direct its negotiation strategies? understanding the impact of natural language on negotiation outcomes through a data - driven neural framework is the primary objective of this work.', 'we focus on buyer - seller negotiations  #TAUTHOR_TAG where two individuals negotiate the price of a given product.', 'leveraging the recent advancements  #AUTHOR_TAG in pre - trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data - driven manner ( figure 1 ).', 'early prediction of outcomes is essential for effective planning of an automatically negotiating agent.', 'although there have been attempts to gain insights into negotiations  #AUTHOR_TAG, to the best of our knowledge, we are the first to study early natural language cues through a datadriven neural system ( section 3 ).', 'our evaluations show that natural language allows the models to make better predictions by looking at only a fraction of the negotiation.', 'rather than just realizing the strategy in natural language, our empirical results suggest that language can be crucial in the planning as well.', 'we provide a sample negotiation from the test set  #TAUTHOR_TAG along with our model predictions in table 1']",5
"[' #TAUTHOR_TAG.', 'instead of focusing on the']","[' #TAUTHOR_TAG.', 'instead of focusing on the']","[' #TAUTHOR_TAG.', 'instead of focusing on the']","['study human - human negotiations in the buyerseller bargaining scenario, which has been a key research area in the literature  #AUTHOR_TAG.', 'in this section, we first describe our problem setup and key terminologies by discussing the dataset used.', 'later, we formalize our problem definition.', 'dataset : for our explorations, we use the craigslist bargaining dataset ( cb ) introduced by  #TAUTHOR_TAG.', 'instead of focusing on the previously studied game environments  #AUTHOR_TAG, the dataset considers a more realistic setup : negotiating the price of products listed on craigslist 1.', 'the dataset consists of 6682 dialogues between a buyer and a seller who converse in natural language to negotiate the price of a given product ( sample in table 1 ).', 'in total, 1402 product ad postings were scraped from craigslist, belonging to six categories : phones, bikes, housing, furniture, car and electronics.', 'each ad posting contains details such as product title, category type and a listing price.', 'moreover, a secret target price is also pre - decided for the buyer.', '']",5
"['planning of a negotiating agent.', 'this can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning  #TAUTHOR_TAG']","['the planning of a negotiating agent.', 'this can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning  #TAUTHOR_TAG']","['a negotiating agent.', 'this can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning  #TAUTHOR_TAG']","['', 'as more information about the final price is revealed. paired bootstrap resampling  #AUTHOR_TAG with 10, 000 bootstraps shows that for a given f, bert - gru is better than its prices - only counterpart with 95 % statistical significance.', 'the prices discussed during the negotiation still play a crucial role in making the predictions. in fact, in only 65 % of the negotiations, the first price is quoted within the first 0', '. 4 fraction of the events. this is visible in higher performance as more events', 'are seen after this point. this number is lower than average for housing, bike and car, resulting in relative better performance of price', '##only model for these categories over others. the models also show evidence of capturing', 'buyer interest. by constructing artificial negotiations, we observe that the model predictions at f = 0. 2 increase when the buyer shows more interest in the', 'product, indicating more willingness to pay. with the', 'capability to incorporate cues from natural language, such a framework can be used in the future to get negotiation feedback, in order to guide the planning of a negotiating agent.', 'this can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning  #TAUTHOR_TAG']",2
"['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation']","['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation of network topology along a text is able to']","['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation']","['occurrence networks can be seen as simplified versions of syntactic networks [ 18 ]. several patterns have been identified in co - occurrence networks formed from large corpora, such as the power - law regimes for degrees distribution [ 2 ]', 'and core - periphery structure [ 20 ] resulting from the complex organization of the lexicon. the overall structure and dynamics of networks representing texts have been modeled to describe their mechanism of growth and', ""attachment [ 21, 22 ], while nuances in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation of network topology along a text is able to identify an author's style. writing style is more subjective than other text characteristics ( e. g"", '. topic ), making authorship recognition one of the most challenging text mining tasks [ 26, 27 ]. it is crucial for practical applications such', 'as text classification  #TAUTHOR_TAG, copyright resolution [ 28 ], identification of terrorist messages [ 29 ] and of plagiarism [ 26 ]. early studies using stylometry were conducted by mosteller', 'and wallace to identify authorship of the so - called federalist papers [ 30 ]. a myriad of methods to tackle', 'the problem have been developed since then, typically using statistical properties of words ( e. g. mean length, frequency, burstiness and vocabulary', 'richness ) and characters ( e. g. character counts and long - range correlations ) [ 26 ], in addition to syntactic and semantic information [ 26 ]. methods from statistical physics have also been used for authorship recognition [ 31', ', 32 ], which in recent years included text modeling with co - occurrence networks [ 33, 34, 35, 36, 37, 38 ]. the adequacy of co - occurrence networks for the task was confirmed for the first time with the correlation between network topology', ""and authors'styles  #TAUTHOR_TAG. despite this relative success, some issues concerning the applicability of network methods remain unsolved. a major issue in network representation is that regular"", 'patterns among concepts only emerge when large pieces of texts are available. furthermore, rigorous network - based similarity estimators usually assume that the networks comprise the same number of nodes and edges', ', since most measurements are affected by the network size [ 39 ]. unfortunately, such strong assumption often does not hold for written texts ranging from small tales to long novels,', 'which may hinder the applicability of models to real situations. as we shall show, the method presented here obviates these issues with a', 'simple approach based on network dynamics']",0
"['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation']","['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation of network topology along a text is able to']","['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation']","['occurrence networks can be seen as simplified versions of syntactic networks [ 18 ]. several patterns have been identified in co - occurrence networks formed from large corpora, such as the power - law regimes for degrees distribution [ 2 ]', 'and core - periphery structure [ 20 ] resulting from the complex organization of the lexicon. the overall structure and dynamics of networks representing texts have been modeled to describe their mechanism of growth and', ""attachment [ 21, 22 ], while nuances in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation of network topology along a text is able to identify an author's style. writing style is more subjective than other text characteristics ( e. g"", '. topic ), making authorship recognition one of the most challenging text mining tasks [ 26, 27 ]. it is crucial for practical applications such', 'as text classification  #TAUTHOR_TAG, copyright resolution [ 28 ], identification of terrorist messages [ 29 ] and of plagiarism [ 26 ]. early studies using stylometry were conducted by mosteller', 'and wallace to identify authorship of the so - called federalist papers [ 30 ]. a myriad of methods to tackle', 'the problem have been developed since then, typically using statistical properties of words ( e. g. mean length, frequency, burstiness and vocabulary', 'richness ) and characters ( e. g. character counts and long - range correlations ) [ 26 ], in addition to syntactic and semantic information [ 26 ]. methods from statistical physics have also been used for authorship recognition [ 31', ', 32 ], which in recent years included text modeling with co - occurrence networks [ 33, 34, 35, 36, 37, 38 ]. the adequacy of co - occurrence networks for the task was confirmed for the first time with the correlation between network topology', ""and authors'styles  #TAUTHOR_TAG. despite this relative success, some issues concerning the applicability of network methods remain unsolved. a major issue in network representation is that regular"", 'patterns among concepts only emerge when large pieces of texts are available. furthermore, rigorous network - based similarity estimators usually assume that the networks comprise the same number of nodes and edges', ', since most measurements are affected by the network size [ 39 ]. unfortunately, such strong assumption often does not hold for written texts ranging from small tales to long novels,', 'which may hinder the applicability of models to real situations. as we shall show, the method presented here obviates these issues with a', 'simple approach based on network dynamics']",0
"['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation']","['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation of network topology along a text is able to']","['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation']","['occurrence networks can be seen as simplified versions of syntactic networks [ 18 ]. several patterns have been identified in co - occurrence networks formed from large corpora, such as the power - law regimes for degrees distribution [ 2 ]', 'and core - periphery structure [ 20 ] resulting from the complex organization of the lexicon. the overall structure and dynamics of networks representing texts have been modeled to describe their mechanism of growth and', ""attachment [ 21, 22 ], while nuances in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation of network topology along a text is able to identify an author's style. writing style is more subjective than other text characteristics ( e. g"", '. topic ), making authorship recognition one of the most challenging text mining tasks [ 26, 27 ]. it is crucial for practical applications such', 'as text classification  #TAUTHOR_TAG, copyright resolution [ 28 ], identification of terrorist messages [ 29 ] and of plagiarism [ 26 ]. early studies using stylometry were conducted by mosteller', 'and wallace to identify authorship of the so - called federalist papers [ 30 ]. a myriad of methods to tackle', 'the problem have been developed since then, typically using statistical properties of words ( e. g. mean length, frequency, burstiness and vocabulary', 'richness ) and characters ( e. g. character counts and long - range correlations ) [ 26 ], in addition to syntactic and semantic information [ 26 ]. methods from statistical physics have also been used for authorship recognition [ 31', ', 32 ], which in recent years included text modeling with co - occurrence networks [ 33, 34, 35, 36, 37, 38 ]. the adequacy of co - occurrence networks for the task was confirmed for the first time with the correlation between network topology', ""and authors'styles  #TAUTHOR_TAG. despite this relative success, some issues concerning the applicability of network methods remain unsolved. a major issue in network representation is that regular"", 'patterns among concepts only emerge when large pieces of texts are available. furthermore, rigorous network - based similarity estimators usually assume that the networks comprise the same number of nodes and edges', ', since most measurements are affected by the network size [ 39 ]. unfortunately, such strong assumption often does not hold for written texts ranging from small tales to long novels,', 'which may hinder the applicability of models to real situations. as we shall show, the method presented here obviates these issues with a', 'simple approach based on network dynamics']",0
"['analyzing text styles  #TAUTHOR_TAG.', 'the metrics']","['analyzing text styles  #TAUTHOR_TAG.', 'the metrics d, r, c q, t, n and e are scalar values for a network, while the other measurements are']","['analyzing text styles  #TAUTHOR_TAG.', 'the metrics d, r, c q, t, n and e are scalar values for a network, while the other measurements are computed for each node individually.', 'in order to have an overall picture of each partition, we computed the average values of c, l, b, s, k']","['proposed method for authorship attribution is based on the evolution of the topology of networks, i. e. we exploit the network dynamics.', 'therefore, unlike previous approaches ( see e. g. [ 3, 4, 42 ] ), we do not construct one single network from the whole book.', 'instead, a piece of text is divided into shorter parts comprising the same number of tokens.', 'then, a co - occurrence network is constructed for each part, which generates a series of independent networks for each book.', 'the last partition is disregarded from the analysis because it is shorter than the previous ones.', 'since distinct books have different numbers of tokens, the series length varies from book to book.', 'each partition is described by the following topological network measurements : clustering coefficient c, which gives the fraction of possible triangles that exist for a particular node ; network diameter d, which is the largest of all shortest paths ( max { s ij } ) ; network radius r, which is the smallest of all shortest paths ( min { s ij } ) ; number of cliques ( complete subgraphs ) c q ; load centrality l, similar to betweenness centrality but considering weights on edges ; network transitivity t, which measures the fraction of all connected triples which are in fact triangles, t = 3 × triangles / triads ; betweenness centrality b, which measures how many shortest paths pass through a given node ; shortest path length s, which is the shortest number of edges between two nodes ; degree k or connectivity ( number of edges ) of a node ; intermittency i, which measures how periodically a word is repeated [ 43 ] ; total number of nodes n ( i. e. vocabulary size ) ; and total number of edges e. even though intermittency is not a traditional network measurement, we considered it because of its strong relationship with the concept of cycle length in networks.', 'moreover, this measurement has been proven useful for analyzing text styles  #TAUTHOR_TAG.', 'the metrics d, r, c q, t, n and e are scalar values for a network, while the other measurements are computed for each node individually.', 'in order to have an overall picture of each partition, we computed the average values of c, l, b, s, k and i. as such, each partition is characterized by a set of twelve global topological measurements.', 'the total number of tokens w ( equal to the total weight among links ), in each partition, was selected in a simple optimization procedure, with a compromise between having a long but noisy series ( many small networks ) and a shorter,']",0
"['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation']","['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation of network topology along a text is able to']","['in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation']","['occurrence networks can be seen as simplified versions of syntactic networks [ 18 ]. several patterns have been identified in co - occurrence networks formed from large corpora, such as the power - law regimes for degrees distribution [ 2 ]', 'and core - periphery structure [ 20 ] resulting from the complex organization of the lexicon. the overall structure and dynamics of networks representing texts have been modeled to describe their mechanism of growth and', ""attachment [ 21, 22 ], while nuances in the topology of real networks were exploited in practical problems, including natural language processing [ 23, 24,  #TAUTHOR_TAG. in this study, we use the co - occurrence representation to probe how the variation of network topology along a text is able to identify an author's style. writing style is more subjective than other text characteristics ( e. g"", '. topic ), making authorship recognition one of the most challenging text mining tasks [ 26, 27 ]. it is crucial for practical applications such', 'as text classification  #TAUTHOR_TAG, copyright resolution [ 28 ], identification of terrorist messages [ 29 ] and of plagiarism [ 26 ]. early studies using stylometry were conducted by mosteller', 'and wallace to identify authorship of the so - called federalist papers [ 30 ]. a myriad of methods to tackle', 'the problem have been developed since then, typically using statistical properties of words ( e. g. mean length, frequency, burstiness and vocabulary', 'richness ) and characters ( e. g. character counts and long - range correlations ) [ 26 ], in addition to syntactic and semantic information [ 26 ]. methods from statistical physics have also been used for authorship recognition [ 31', ', 32 ], which in recent years included text modeling with co - occurrence networks [ 33, 34, 35, 36, 37, 38 ]. the adequacy of co - occurrence networks for the task was confirmed for the first time with the correlation between network topology', ""and authors'styles  #TAUTHOR_TAG. despite this relative success, some issues concerning the applicability of network methods remain unsolved. a major issue in network representation is that regular"", 'patterns among concepts only emerge when large pieces of texts are available. furthermore, rigorous network - based similarity estimators usually assume that the networks comprise the same number of nodes and edges', ', since most measurements are affected by the network size [ 39 ]. unfortunately, such strong assumption often does not hold for written texts ranging from small tales to long novels,', 'which may hinder the applicability of models to real situations. as we shall show, the method presented here obviates these issues with a', 'simple approach based on network dynamics']",1
"['becoming a node and two words being linked if they were adjacent in the pre - processed text  #TAUTHOR_TAG.', 'the link is directed from the']","['becoming a node and two words being linked if they were adjacent in the pre - processed text  #TAUTHOR_TAG.', 'the link is directed from the']","['41 ].', 'the co - occurrence networks were constructed with each distinct word becoming a node and two words being linked if they were adjacent in the pre - processed text  #TAUTHOR_TAG.', 'the link is directed from the word appearing first to the second word and is weighted by the number of times the pair is found in the text']","['texts used for classification come from a collection of novels and tales in english whose details are provided in the supporting information.', 'the collection comprising 8 authors with 10 texts per author was selected to simulate a real case where the text lengths are varied in a range from 2, 853 to 267, 012 tokens with an average of 53, 532 tokens.', 'the approach introduced requires a pre - processing step before transforming texts into networks, which consists in the removal of stopwords and lemmatization.', 'because we are mostly interested in the relationship between content words, stopwords such as function words conveying low semantic information were removed as in many studies of this type [ 40 ].', 'the remaining words were lemmatized so that nouns and verbs were mapped to their singular and infinitive forms, and therefore words related to the same concept were mapped into the same node ( also referred to as one single token ).', 'since lemmatization requires part - of - speech ( pos ) tagging, we used the maximum - entropy approach described in [ 41 ].', 'the co - occurrence networks were constructed with each distinct word becoming a node and two words being linked if they were adjacent in the pre - processed text  #TAUTHOR_TAG.', 'the link is directed from the word appearing first to the second word and is weighted by the number of times the pair is found in the text']",5
"['analyzing text styles  #TAUTHOR_TAG.', 'the metrics']","['analyzing text styles  #TAUTHOR_TAG.', 'the metrics d, r, c q, t, n and e are scalar values for a network, while the other measurements are']","['analyzing text styles  #TAUTHOR_TAG.', 'the metrics d, r, c q, t, n and e are scalar values for a network, while the other measurements are computed for each node individually.', 'in order to have an overall picture of each partition, we computed the average values of c, l, b, s, k']","['proposed method for authorship attribution is based on the evolution of the topology of networks, i. e. we exploit the network dynamics.', 'therefore, unlike previous approaches ( see e. g. [ 3, 4, 42 ] ), we do not construct one single network from the whole book.', 'instead, a piece of text is divided into shorter parts comprising the same number of tokens.', 'then, a co - occurrence network is constructed for each part, which generates a series of independent networks for each book.', 'the last partition is disregarded from the analysis because it is shorter than the previous ones.', 'since distinct books have different numbers of tokens, the series length varies from book to book.', 'each partition is described by the following topological network measurements : clustering coefficient c, which gives the fraction of possible triangles that exist for a particular node ; network diameter d, which is the largest of all shortest paths ( max { s ij } ) ; network radius r, which is the smallest of all shortest paths ( min { s ij } ) ; number of cliques ( complete subgraphs ) c q ; load centrality l, similar to betweenness centrality but considering weights on edges ; network transitivity t, which measures the fraction of all connected triples which are in fact triangles, t = 3 × triangles / triads ; betweenness centrality b, which measures how many shortest paths pass through a given node ; shortest path length s, which is the shortest number of edges between two nodes ; degree k or connectivity ( number of edges ) of a node ; intermittency i, which measures how periodically a word is repeated [ 43 ] ; total number of nodes n ( i. e. vocabulary size ) ; and total number of edges e. even though intermittency is not a traditional network measurement, we considered it because of its strong relationship with the concept of cycle length in networks.', 'moreover, this measurement has been proven useful for analyzing text styles  #TAUTHOR_TAG.', 'the metrics d, r, c q, t, n and e are scalar values for a network, while the other measurements are computed for each node individually.', 'in order to have an overall picture of each partition, we computed the average values of c, l, b, s, k and i. as such, each partition is characterized by a set of twelve global topological measurements.', 'the total number of tokens w ( equal to the total weight among links ), in each partition, was selected in a simple optimization procedure, with a compromise between having a long but noisy series ( many small networks ) and a shorter,']",5
['task  #TAUTHOR_TAG analyzed'],['mentioning. a similar study for the same task  #TAUTHOR_TAG analyzed'],['task  #TAUTHOR_TAG analyzed'],"['', 'and rbfn. for visualization purposes isomap was also applied to reduce the number of attributes to a two - dimensional space using the projection explorer software [ 50 ] as shown', 'in figure 4 ( a ). for some authors the texts are clearly grouped and separated from the rest ( e. g. texts from a.', 'c. doyle and b. shaw ) while for other authors the separation is not as clear. a common trend exists nevertheless,', 'with texts by the same author located in preferential regions in the attribute space. even though a direct comparison to related works', 'requires using the same text collection, two examples using collections with similar characteristics which use static network metrics', 'are worth mentioning. a similar study for the same task  #TAUTHOR_TAG analyzed 40 texts from 8 authors in english reaching a success score of 65 %. in another', 'work, 36 persian books from 5 authors were classified with an accuracy rate of 77. 8 % [ 51', ']. a myriad of other metrics for authorship identification have been proposed. argamo', '##n and juola [ 52 ] collected the results of the pan 2011 competition where 3001 electronic messages from 26 authors were classified using diverse metrics for which the best micro - averaged recall ( i. e. success score ) was 0. 71', '##7. these collections have characteristics different to ours such as the number of texts, authors, and', 'the sizes of messages compared to books']",5
['task  #TAUTHOR_TAG analyzed'],['mentioning. a similar study for the same task  #TAUTHOR_TAG analyzed'],['task  #TAUTHOR_TAG analyzed'],"['', 'and rbfn. for visualization purposes isomap was also applied to reduce the number of attributes to a two - dimensional space using the projection explorer software [ 50 ] as shown', 'in figure 4 ( a ). for some authors the texts are clearly grouped and separated from the rest ( e. g. texts from a.', 'c. doyle and b. shaw ) while for other authors the separation is not as clear. a common trend exists nevertheless,', 'with texts by the same author located in preferential regions in the attribute space. even though a direct comparison to related works', 'requires using the same text collection, two examples using collections with similar characteristics which use static network metrics', 'are worth mentioning. a similar study for the same task  #TAUTHOR_TAG analyzed 40 texts from 8 authors in english reaching a success score of 65 %. in another', 'work, 36 persian books from 5 authors were classified with an accuracy rate of 77. 8 % [ 51', ']. a myriad of other metrics for authorship identification have been proposed. argamo', '##n and juola [ 52 ] collected the results of the pan 2011 competition where 3001 electronic messages from 26 authors were classified using diverse metrics for which the best micro - averaged recall ( i. e. success score ) was 0. 71', '##7. these collections have characteristics different to ours such as the number of texts, authors, and', 'the sizes of messages compared to books']",3
"['the user asking questions.', ' #TAUTHOR_TAG developed algorithms']","['the user asking questions.', ' #TAUTHOR_TAG developed algorithms']","['the user asking questions.', ' #TAUTHOR_TAG developed algorithms']","['of the effort in creating a dialogue system is devoted to the collection of training data, to allow the system to process, understand, and react to input coming from real users.', 'if a comparable system is available for a different language, it would be helpful to use some of the existing foreign language resources in order to cut down the development time and cost - an issue known as language portability.', 'recent efforts have shown machine translation to be an effective tool for porting dialogue system resources from french into italian  #AUTHOR_TAG ; this system used concept - based language understanding, and the findings were that machine translation of the target language inputs yielded better results than using translation to train an understanding component directly for the target language.', 'here we report similar findings on more challenging data, by exploring a dialogue system with a less structured understanding component, using off - the - shelf rather than domainadapted machine translation, and with languages that are not as closely related.', 'question - answering characters are designed to sustain a conversation driven primarily by the user asking questions.', ' #TAUTHOR_TAG developed algorithms for training such characters using linked questions and responses in the form of unstructured natural language text.', 'given a novel user question, the character finds an appropriate response from a list of available responses, and when a direct answer is not available, the character selects an "" off - topic "" response according to a set policy, ensuring that the conversation remains coherent even with a finite number of responses.', 'the response selection algorithms are languageindependent, also allowing the questions and responses to be in separate languages.', 'these algorithms have been incorporated into a tool which has been used to create characters for a variety of applications ( e. g.  #TAUTHOR_TAG.', 'to date, most characters created using these principles understood and spoke only english ; one fairly limited character spoke pashto, a language of afghanistan  #AUTHOR_TAG.', 'to test language portability we chose tamil, a dravidian language spoken primarily in southern india.', 'tamil has close to 70 million speakers worldwide  #AUTHOR_TAG, is the official language of tamil nadu and puducherry in india  #AUTHOR_TAG, and an official language in sri lanka and singapore.', 'there is active development of language processing tools in tamil such as stemmers  #AUTHOR_TAG, pos taggers  #AUTHOR_TAG, constituent and dependency parsers  #AUTHOR_TAG ramasamy andzabokrtsky, 2011 ), sentence generators  #AUTHOR_TAG the main questions we want to answer in this paper are : ( q1 ) how good is a dialogue system created using translation between english and tamil? ( q2 ) is there a difference between']",0
"['the user asking questions.', ' #TAUTHOR_TAG developed algorithms']","['the user asking questions.', ' #TAUTHOR_TAG developed algorithms']","['the user asking questions.', ' #TAUTHOR_TAG developed algorithms']","['of the effort in creating a dialogue system is devoted to the collection of training data, to allow the system to process, understand, and react to input coming from real users.', 'if a comparable system is available for a different language, it would be helpful to use some of the existing foreign language resources in order to cut down the development time and cost - an issue known as language portability.', 'recent efforts have shown machine translation to be an effective tool for porting dialogue system resources from french into italian  #AUTHOR_TAG ; this system used concept - based language understanding, and the findings were that machine translation of the target language inputs yielded better results than using translation to train an understanding component directly for the target language.', 'here we report similar findings on more challenging data, by exploring a dialogue system with a less structured understanding component, using off - the - shelf rather than domainadapted machine translation, and with languages that are not as closely related.', 'question - answering characters are designed to sustain a conversation driven primarily by the user asking questions.', ' #TAUTHOR_TAG developed algorithms for training such characters using linked questions and responses in the form of unstructured natural language text.', 'given a novel user question, the character finds an appropriate response from a list of available responses, and when a direct answer is not available, the character selects an "" off - topic "" response according to a set policy, ensuring that the conversation remains coherent even with a finite number of responses.', 'the response selection algorithms are languageindependent, also allowing the questions and responses to be in separate languages.', 'these algorithms have been incorporated into a tool which has been used to create characters for a variety of applications ( e. g.  #TAUTHOR_TAG.', 'to date, most characters created using these principles understood and spoke only english ; one fairly limited character spoke pashto, a language of afghanistan  #AUTHOR_TAG.', 'to test language portability we chose tamil, a dravidian language spoken primarily in southern india.', 'tamil has close to 70 million speakers worldwide  #AUTHOR_TAG, is the official language of tamil nadu and puducherry in india  #AUTHOR_TAG, and an official language in sri lanka and singapore.', 'there is active development of language processing tools in tamil such as stemmers  #AUTHOR_TAG, pos taggers  #AUTHOR_TAG, constituent and dependency parsers  #AUTHOR_TAG ramasamy andzabokrtsky, 2011 ), sentence generators  #AUTHOR_TAG the main questions we want to answer in this paper are : ( q1 ) how good is a dialogue system created using translation between english and tamil? ( q2 ) is there a difference between']",0
"[""classifier's determination that the best response is not good enough  #TAUTHOR_TAG, since this capability was not implemented ; however, since""]","[""classifier's determination that the best response is not good enough  #TAUTHOR_TAG, since this capability was not implemented ; however, since""]","[').', ""this measure does not take into account non - understanding, that is the classifier's determination that the best response is not good enough  #TAUTHOR_TAG, since this capability was not implemented ; however, since""]","['use accuracy as our success measure : the top ranked response to a test question is considered correct if it is identified as a correct response in the linked test data ( there are up to 4 correct responses per question ).', ""this measure does not take into account non - understanding, that is the classifier's determination that the best response is not good enough  #TAUTHOR_TAG, since this capability was not implemented ; however, since all of our test questions are known to have at least one appropriate response, any non - understanding of a question would necessarily count against accuracy anyway""]",0
"['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including both the language modeling ( lm )']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including both the language modeling ( lm ) and cross - language modeling ( clm ) approaches.', 'the lm approach constructs language models for both questions and responses using the question vocabulary.', 'for each training question s, a language model is estimated as the frequency distribution of tokens in s, smoothed by the distribution of tokens in the entire question corpus ( eq. 1 ).', 'the language model of a novel question q is estimated as the probability of each token in the vocabulary coinciding with q ( eq. 2 ).', '']",4
"['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including both the language modeling ( lm )']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including both the language modeling ( lm ) and cross - language modeling ( clm ) approaches.', 'the lm approach constructs language models for both questions and responses using the question vocabulary.', 'for each training question s, a language model is estimated as the frequency distribution of tokens in s, smoothed by the distribution of tokens in the entire question corpus ( eq. 1 ).', 'the language model of a novel question q is estimated as the probability of each token in the vocabulary coinciding with q ( eq. 2 ).', '']",4
"['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including both the language modeling ( lm )']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including both the language modeling ( lm ) and cross - language modeling ( clm ) approaches.', 'the lm approach constructs language models for both questions and responses using the question vocabulary.', 'for each training question s, a language model is estimated as the frequency distribution of tokens in s, smoothed by the distribution of tokens in the entire question corpus ( eq. 1 ).', 'the language model of a novel question q is estimated as the probability of each token in the vocabulary coinciding with q ( eq. 2 ).', '']",4
"[""classifier's determination that the best response is not good enough  #TAUTHOR_TAG, since this capability was not implemented ; however, since""]","[""classifier's determination that the best response is not good enough  #TAUTHOR_TAG, since this capability was not implemented ; however, since""]","[').', ""this measure does not take into account non - understanding, that is the classifier's determination that the best response is not good enough  #TAUTHOR_TAG, since this capability was not implemented ; however, since""]","['use accuracy as our success measure : the top ranked response to a test question is considered correct if it is identified as a correct response in the linked test data ( there are up to 4 correct responses per question ).', ""this measure does not take into account non - understanding, that is the classifier's determination that the best response is not good enough  #TAUTHOR_TAG, since this capability was not implemented ; however, since all of our test questions are known to have at least one appropriate response, any non - understanding of a question would necessarily count against accuracy anyway""]",4
"['of  #TAUTHOR_TAG, where clm fared consistently better.', 'in']","['of  #TAUTHOR_TAG, where clm fared consistently better.', 'in']","['of  #TAUTHOR_TAG, where clm fared consistently better.', 'in']","['results of the experiments with matched question and response languages are reported in table 1.', 'the lm approach almost invariably produced better results than the clm approach ; this is the opposite of the findings of  #TAUTHOR_TAG, where clm fared consistently better.', 'in most cases, the errors produced by the clm approach were a superset of those of the lm approach ; the only exceptions were tamil with stemming.', 'accuracy of response selection on the tamil data is about 10 % lower than that of english, or twice the errors ( 6 errors rather than 3 ).', 'the errors of automatically translated tamil are a superset of the english errors ; however, manually translated tamil did get right some of the errors of english.', '']",4
"['clm approach, contra  #TAUTHOR_TAG.', 'our data may not be quite natural : while the english data are well tested, our sampling method may introduce biases that']","['clm approach, contra  #TAUTHOR_TAG.', 'our data may not be quite natural : while the english data are well tested, our sampling method may introduce biases that']","['the clm approach, contra  #TAUTHOR_TAG.', 'our data may not be quite natural : while the english data are well tested, our sampling method may introduce biases that']","['', 'one possibility is to improve the machine translation itself, for example by adapting it to the domain.', 'another alternative is to use both languages together for classification ; the fact that the manual tamil translation identified some responses missed by the english classifier suggests that there may be benefit to this approach.', 'another direction for future work is identifying bad responses by using the distance between question and response to plot the tradeoff curve between errors and return rates  #AUTHOR_TAG.', 'in our experiments the lm approach consistently outperforms the clm approach, contra  #TAUTHOR_TAG.', 'our data may not be quite natural : while the english data are well tested, our sampling method may introduce biases that affect the results. but even if we achieved full english - like performance using machine translation, the questions that tamil speakers want to ask will likely be somewhat different than those of english speakers.', 'a translated dialogue system is therefore only an initial step towards tailoring a system to a new population']",4
"['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including both the language modeling ( lm )']","['reimplemented parts of the response ranking algorithms of  #TAUTHOR_TAG, including both the language modeling ( lm ) and cross - language modeling ( clm ) approaches.', 'the lm approach constructs language models for both questions and responses using the question vocabulary.', 'for each training question s, a language model is estimated as the frequency distribution of tokens in s, smoothed by the distribution of tokens in the entire question corpus ( eq. 1 ).', 'the language model of a novel question q is estimated as the probability of each token in the vocabulary coinciding with q ( eq. 2 ).', '']",6
['over a perceptron - based edit model  #TAUTHOR_TAG'],['2 % over a perceptron - based edit model  #TAUTHOR_TAG'],"['a statistical machine translation ( smt )', 'system  #AUTHOR_TAG and of 2. 2 % over a perceptron - based edit model  #TAUTHOR_TAG']","['', 'a baseline only trained with 1 - best transliterations. this is especially helpful when machine transliteration', 'is part of a larger machine translation or information retrieval pipeline since additional sentence context can be used to choose the best among', 'top - k transliterations. second, our training procedure accounts for noise and non - separability in the data. therefore, our transliteration system', 'would work well in cases where', 'person names were misspelled or in cases in which a single name had many reasonable translations in the foreign language. the training', 'algorithm we propose in this paper is based on the k - best mira algorithm which has been used', 'earlier in structured prediction problems ( mc  #AUTHOR_TAG a ; mc  #AUTHOR_TAG b ). our results demonstrate a significant improvement in accuracy of 7. 2', '% over a statistical machine translation ( smt )', 'system  #AUTHOR_TAG and of 2. 2 % over a perceptron - based edit model  #TAUTHOR_TAG']",4
['over a perceptron - based edit model  #TAUTHOR_TAG'],['2 % over a perceptron - based edit model  #TAUTHOR_TAG'],"['a statistical machine translation ( smt )', 'system  #AUTHOR_TAG and of 2. 2 % over a perceptron - based edit model  #TAUTHOR_TAG']","['', 'a baseline only trained with 1 - best transliterations. this is especially helpful when machine transliteration', 'is part of a larger machine translation or information retrieval pipeline since additional sentence context can be used to choose the best among', 'top - k transliterations. second, our training procedure accounts for noise and non - separability in the data. therefore, our transliteration system', 'would work well in cases where', 'person names were misspelled or in cases in which a single name had many reasonable translations in the foreign language. the training', 'algorithm we propose in this paper is based on the k - best mira algorithm which has been used', 'earlier in structured prediction problems ( mc  #AUTHOR_TAG a ; mc  #AUTHOR_TAG b ). our results demonstrate a significant improvement in accuracy of 7. 2', '% over a statistical machine translation ( smt )', 'system  #AUTHOR_TAG and of 2. 2 % over a perceptron - based edit model  #TAUTHOR_TAG']",0
"['possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","['possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","[') among all possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","['', 'for fixed sequences e and f the function s ( e, f ) can be efficiently computed using a dynamic programming algorithm,', 'given a source sequence f computing the best scoring target sequence e = arg max e ′ s ( e ′, f ) among all possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure can also be used to produce k - best target sequences', '. in this paper, we employ the same features as those used by  #TAUTHOR_TAG.', 'all local feature functions φ ( a k, e, i, f, j ) are conjunctions of the alignment operation a k and forward or backward - looking character m - grams in sequences e and f at positions i and j respectively.', 'for the source sequence f both forward and backwardlooking m - gram features are included.', 'we restrict the m - gram features in our target sequence e to only be backward - looking since we do not have access to forward - looking m - grams during beam - search.', 'an order m model is one that uses m - gram features where m = 0, 1,...', 'm.', 'our training algorithm takes']",0
"['possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","['possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","[') among all possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","['', 'for fixed sequences e and f the function s ( e, f ) can be efficiently computed using a dynamic programming algorithm,', 'given a source sequence f computing the best scoring target sequence e = arg max e ′ s ( e ′, f ) among all possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure can also be used to produce k - best target sequences', '. in this paper, we employ the same features as those used by  #TAUTHOR_TAG.', 'all local feature functions φ ( a k, e, i, f, j ) are conjunctions of the alignment operation a k and forward or backward - looking character m - grams in sequences e and f at positions i and j respectively.', 'for the source sequence f both forward and backwardlooking m - gram features are included.', 'we restrict the m - gram features in our target sequence e to only be backward - looking since we do not have access to forward - looking m - grams during beam - search.', 'an order m model is one that uses m - gram features where m = 0, 1,...', 'm.', 'our training algorithm takes']",5
"['possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","['possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","[') among all possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure']","['', 'for fixed sequences e and f the function s ( e, f ) can be efficiently computed using a dynamic programming algorithm,', 'given a source sequence f computing the best scoring target sequence e = arg max e ′ s ( e ′, f ) among all possible sequences e * requires a beam search procedure  #TAUTHOR_TAG.', 'this procedure can also be used to produce k - best target sequences', '. in this paper, we employ the same features as those used by  #TAUTHOR_TAG.', 'all local feature functions φ ( a k, e, i, f, j ) are conjunctions of the alignment operation a k and forward or backward - looking character m - grams in sequences e and f at positions i and j respectively.', 'for the source sequence f both forward and backwardlooking m - gram features are included.', 'we restrict the m - gram features in our target sequence e to only be backward - looking since we do not have access to forward - looking m - grams during beam - search.', 'an order m model is one that uses m - gram features where m = 0, 1,...', 'm.', 'our training algorithm takes']",5
"['benchmark study  #TAUTHOR_TAG.', 'the development and testing data were']","['benchmark study  #TAUTHOR_TAG.', 'the development and testing data were']","['a previous benchmark study  #TAUTHOR_TAG.', 'the development and testing data were obtained by randomly removing entries from the training data.', 'the absence of short vowels (']","['apply our model to the real - world arabicenglish name transliteration task on a data set of 10, 084 arabic names from the ldc.', 'the data set consists of arabic names in an ascii - based alphabet and its english rendering.', 'table 1 shows a few examples of arabic - english pairs in our data set.', 'we use the same training / development / testing ( 8084 / 1000 / 1000 ) set as the one used in a previous benchmark study  #TAUTHOR_TAG.', 'the development and testing data were obtained by randomly removing entries from the training data.', 'the absence of short vowels ( e. g. "" a "" in nb "" i, nab\'i ), doubled consonants ( e. g. "" ww "" in fwal, fawwal ) and other diacritics in arabic make the transliteration a hard problem.', 'therefore, it is hard to achieve perfect accuracy on this data set.', 'for training, we set k = 20 best hypotheses']",5
"['edit model ( ptem ) with identical features  #TAUTHOR_TAG.', 'the sm']","['averaged perceptron edit model ( ptem ) with identical features  #TAUTHOR_TAG.', 'the smt']","[') system  #AUTHOR_TAG and an averaged perceptron edit model ( ptem ) with identical features  #TAUTHOR_TAG.', '']","['data d complexity parameter c > 0 number of epochs t initialize w 0 = 0 ( zero vector ) ; τ = 0 ; u = 0 repeat t times : for each ( e, f ) ∈ d :', '1. a = arg maxa w τ · φ ( a, e, f ) ( find best scoring alignment between e and f using dynamic programming ) 2. generate a list of k - best target hypotheses { e', 'k } given the current parameters w τ.', 'let the corresponding alignments for the targets be { a', '3. set w τ + 1 to be the solution of : c = 1. 0 and run the algorithm for t = 10 epochs.', 'to evaluate our algorithm, we generate 1 - best ( or 5 - best ) hypotheses using the beam search procedure and measure accuracy as the percentage of instances in which the target sequence e is one of the 1 - best ( or 5 - best ) targets.', 'the input features are based on character m - grams for m = 1, 2, 3.', 'unlike previ - ous generative transliteration models, no additional language model feature is used.', 'we compare our model against a state - of - the - art statistical machine translation ( smt ) system  #AUTHOR_TAG and an averaged perceptron edit model ( ptem ) with identical features  #TAUTHOR_TAG.', 'the smt system directly models the posterior probability p r ( e | f ) using a log - linear combination of several sub - models : a characterbased phrase translation model, a character - based lexicon model, a character penalty and a phrase penalty.', 'in the ptem model, the update rule only considers the best target sequence and modifies the parameters w τ + 1 = w τ + φ ( a, e, f ) − φ ( a ′, e ′, f ) if the score s ( e ′, f ) ≥ s ( e, f ).', 'table 2 shows the 1 - best and 5 - best accuracy of each model trained on the combined train + dev data set.', 'all the models are evaluated on the same test set.', '']",5
[' #TAUTHOR_TAG used recursive neural networks'],[' #TAUTHOR_TAG used recursive neural networks'],['recent work  #TAUTHOR_TAG used recursive neural networks'],"['at https : / / goo. gl / s2t1go is very different from that in tweets.  #AUTHOR_TAG analysed the differences between the overall and target - dependent sentiment of tweets for', 'three events containing 30 targets, showing many significant differences between the corresponding overall and target - dependent sentiment', 'labels, thus confirming that these are distinct tasks. early work tackling target - dependent sentiment in tweets  #AUTHOR_TAG designed targetdependent features manually, relying on the syntactic parse tree and a set of grammar - based rules,', 'and incorporating the sentiment labels of related tweets to improve the classification performance. recent work  #TAUTHOR_TAG used recursive neural networks and adaptively chose composition functions to', 'combine child feature vectors according to their dependency type, to reflect sentiment signal propagation to the target. their datadriven composition selection approach replies on the dependency types as features and', 'a small set of rules for constructing', 'target - dependent trees. their manually annotated dataset contains only one target per tweet and has since been used for benchmarking by several subsequent studies  #AUTHOR_TAG a ;  #AUTHOR_TAG.  #AUTHOR_TAG exploit the', 'left and right context around a target in a tweet and', 'combine low - dimensional embedding features from both contexts and the full tweet using a number of different pooling functions. despite not fully capturing semantic and syntactic information given the target entity, they show a much better performance than  #TAUTHOR_TAG, indicating useful signals in relation to the target can be drawn from such context representation.  #AUTHOR_TAG a ) and  #AUTHOR_TAG', 'adopt and integrate left - right target - dependent context into their recurrent neural network ( rnn ) respectively.  #AUTHOR_TAG a )', 'propose two long shortterm memory ( lstm ) models showing competitive performance to  #AUTHOR_TAG', ',  #AUTHOR_TAG design a gated neural network layer between the left and right context in a deep neural network structure but require a combination of three corpora for training and evaluation. results show that conventional neural network models like lstm are incapable of explicitly capturing important context information of a target  #AUTHOR_TAG b ).  #AUTHOR_TAG a ) also experiment with adding', 'attention layers for lstm but fail to achieve competitive results possibly due to the small training corpus. going beyond the existing work we study the more challenging task of classifying sentiment towards multiple target', 'entities within a tweet. using the syntactic information drawn from tweetspecific parsing, in conjunction with the left - right contexts, we show the state - of - the - art performance in both single and multi - target classification tasks. we', 'also show that the tweet level approach that many sentiment systems adopted in both semeval challenges, fail to capture all target - sentiments in', 'a multi - target scenario ( section 5. 1 )']",5
,,,,5
"['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with']","['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with']","['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with three model categories :']","[""report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with three model categories : 1 ) tweet - level target - independent models, 2 ) targetdependent models without considering the'sametarget - multi - appearance'scenario and 3 ) targetdependent models incorporating the'same - targetmulti - appearance'scenario."", 'we include the models presented in the previous section as well as models for target specific sentiment from the literature where possible.', 'among the target - independent baseline models target - ind  #AUTHOR_TAG and semevalbest have shown strong performance compared with sswe and svm - ind  #AUTHOR_TAG as they use more features, especially rich automatic features using the embeddings of  #AUTHOR_TAG.', 'interestingly they also perform better than some of the targetdependent baseline systems, namely svm - dep  #AUTHOR_TAG, recursive nn and adarnn  #TAUTHOR_TAG, showing the difficulty of fully extracting and incorporating target information in tweets.', 'basic lstm models  #AUTHOR_TAG a ) completely ignore such target information and as a result do not perform as well.', 'among the target - dependent systems neural network baselines have shown varying results.', '']",5
[' #TAUTHOR_TAG used recursive neural networks'],[' #TAUTHOR_TAG used recursive neural networks'],['recent work  #TAUTHOR_TAG used recursive neural networks'],"['at https : / / goo. gl / s2t1go is very different from that in tweets.  #AUTHOR_TAG analysed the differences between the overall and target - dependent sentiment of tweets for', 'three events containing 30 targets, showing many significant differences between the corresponding overall and target - dependent sentiment', 'labels, thus confirming that these are distinct tasks. early work tackling target - dependent sentiment in tweets  #AUTHOR_TAG designed targetdependent features manually, relying on the syntactic parse tree and a set of grammar - based rules,', 'and incorporating the sentiment labels of related tweets to improve the classification performance. recent work  #TAUTHOR_TAG used recursive neural networks and adaptively chose composition functions to', 'combine child feature vectors according to their dependency type, to reflect sentiment signal propagation to the target. their datadriven composition selection approach replies on the dependency types as features and', 'a small set of rules for constructing', 'target - dependent trees. their manually annotated dataset contains only one target per tweet and has since been used for benchmarking by several subsequent studies  #AUTHOR_TAG a ;  #AUTHOR_TAG.  #AUTHOR_TAG exploit the', 'left and right context around a target in a tweet and', 'combine low - dimensional embedding features from both contexts and the full tweet using a number of different pooling functions. despite not fully capturing semantic and syntactic information given the target entity, they show a much better performance than  #TAUTHOR_TAG, indicating useful signals in relation to the target can be drawn from such context representation.  #AUTHOR_TAG a ) and  #AUTHOR_TAG', 'adopt and integrate left - right target - dependent context into their recurrent neural network ( rnn ) respectively.  #AUTHOR_TAG a )', 'propose two long shortterm memory ( lstm ) models showing competitive performance to  #AUTHOR_TAG', ',  #AUTHOR_TAG design a gated neural network layer between the left and right context in a deep neural network structure but require a combination of three corpora for training and evaluation. results show that conventional neural network models like lstm are incapable of explicitly capturing important context information of a target  #AUTHOR_TAG b ).  #AUTHOR_TAG a ) also experiment with adding', 'attention layers for lstm but fail to achieve competitive results possibly due to the small training corpus. going beyond the existing work we study the more challenging task of classifying sentiment towards multiple target', 'entities within a tweet. using the syntactic information drawn from tweetspecific parsing, in conjunction with the left - right contexts, we show the state - of - the - art performance in both single and multi - target classification tasks. we', 'also show that the tweet level approach that many sentiment systems adopted in both semeval challenges, fail to capture all target - sentiments in', 'a multi - target scenario ( section 5. 1 )']",0
[' #TAUTHOR_TAG used recursive neural networks'],[' #TAUTHOR_TAG used recursive neural networks'],['recent work  #TAUTHOR_TAG used recursive neural networks'],"['at https : / / goo. gl / s2t1go is very different from that in tweets.  #AUTHOR_TAG analysed the differences between the overall and target - dependent sentiment of tweets for', 'three events containing 30 targets, showing many significant differences between the corresponding overall and target - dependent sentiment', 'labels, thus confirming that these are distinct tasks. early work tackling target - dependent sentiment in tweets  #AUTHOR_TAG designed targetdependent features manually, relying on the syntactic parse tree and a set of grammar - based rules,', 'and incorporating the sentiment labels of related tweets to improve the classification performance. recent work  #TAUTHOR_TAG used recursive neural networks and adaptively chose composition functions to', 'combine child feature vectors according to their dependency type, to reflect sentiment signal propagation to the target. their datadriven composition selection approach replies on the dependency types as features and', 'a small set of rules for constructing', 'target - dependent trees. their manually annotated dataset contains only one target per tweet and has since been used for benchmarking by several subsequent studies  #AUTHOR_TAG a ;  #AUTHOR_TAG.  #AUTHOR_TAG exploit the', 'left and right context around a target in a tweet and', 'combine low - dimensional embedding features from both contexts and the full tweet using a number of different pooling functions. despite not fully capturing semantic and syntactic information given the target entity, they show a much better performance than  #TAUTHOR_TAG, indicating useful signals in relation to the target can be drawn from such context representation.  #AUTHOR_TAG a ) and  #AUTHOR_TAG', 'adopt and integrate left - right target - dependent context into their recurrent neural network ( rnn ) respectively.  #AUTHOR_TAG a )', 'propose two long shortterm memory ( lstm ) models showing competitive performance to  #AUTHOR_TAG', ',  #AUTHOR_TAG design a gated neural network layer between the left and right context in a deep neural network structure but require a combination of three corpora for training and evaluation. results show that conventional neural network models like lstm are incapable of explicitly capturing important context information of a target  #AUTHOR_TAG b ).  #AUTHOR_TAG a ) also experiment with adding', 'attention layers for lstm but fail to achieve competitive results possibly due to the small training corpus. going beyond the existing work we study the more challenging task of classifying sentiment towards multiple target', 'entities within a tweet. using the syntactic information drawn from tweetspecific parsing, in conjunction with the left - right contexts, we show the state - of - the - art performance in both single and multi - target classification tasks. we', 'also show that the tweet level approach that many sentiment systems adopted in both semeval challenges, fail to capture all target - sentiments in', 'a multi - target scenario ( section 5. 1 )']",0
"['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with']","['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with']","['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with three model categories :']","[""report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with three model categories : 1 ) tweet - level target - independent models, 2 ) targetdependent models without considering the'sametarget - multi - appearance'scenario and 3 ) targetdependent models incorporating the'same - targetmulti - appearance'scenario."", 'we include the models presented in the previous section as well as models for target specific sentiment from the literature where possible.', 'among the target - independent baseline models target - ind  #AUTHOR_TAG and semevalbest have shown strong performance compared with sswe and svm - ind  #AUTHOR_TAG as they use more features, especially rich automatic features using the embeddings of  #AUTHOR_TAG.', 'interestingly they also perform better than some of the targetdependent baseline systems, namely svm - dep  #AUTHOR_TAG, recursive nn and adarnn  #TAUTHOR_TAG, showing the difficulty of fully extracting and incorporating target information in tweets.', 'basic lstm models  #AUTHOR_TAG a ) completely ignore such target information and as a result do not perform as well.', 'among the target - dependent systems neural network baselines have shown varying results.', '']",0
"['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with']","['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with']","['report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with three model categories :']","[""report our experimental results in table 2 on the single - target benchmarking corpus  #TAUTHOR_TAG, with three model categories : 1 ) tweet - level target - independent models, 2 ) targetdependent models without considering the'sametarget - multi - appearance'scenario and 3 ) targetdependent models incorporating the'same - targetmulti - appearance'scenario."", 'we include the models presented in the previous section as well as models for target specific sentiment from the literature where possible.', 'among the target - independent baseline models target - ind  #AUTHOR_TAG and semevalbest have shown strong performance compared with sswe and svm - ind  #AUTHOR_TAG as they use more features, especially rich automatic features using the embeddings of  #AUTHOR_TAG.', 'interestingly they also perform better than some of the targetdependent baseline systems, namely svm - dep  #AUTHOR_TAG, recursive nn and adarnn  #TAUTHOR_TAG, showing the difficulty of fully extracting and incorporating target information in tweets.', 'basic lstm models  #AUTHOR_TAG a ) completely ignore such target information and as a result do not perform as well.', 'among the target - dependent systems neural network baselines have shown varying results.', '']",0
,,,,4
,,,,7
"['contains all the concepts identified in the first stage.', 'later work by  #TAUTHOR_TAG adopted a different strategy based on the similarity between']","['contains all the concepts identified in the first stage.', 'later work by  #TAUTHOR_TAG adopted a different strategy based on the similarity between']","['contains all the concepts identified in the first stage.', 'later work by  #TAUTHOR_TAG adopted a different strategy based on the similarity between']","['abstract meaning representation parsing  #AUTHOR_TAG, the goal is to parse natural language in a domain - independent graph - based meaning representation ( amr ).', 'in the first amr parsing work,  #AUTHOR_TAG split the task into two sub - tasks ; concept identification and graph creation.', 'the sub - tasks are learned independently, and exact inference is used to find highest - scoring maximum spanning connected acyclic graph that contains all the concepts identified in the first stage.', 'later work by  #TAUTHOR_TAG adopted a different strategy based on the similarity between the dependency parse of a sentence and the semantic amr graph.', '']",6
"['2, largely based on  #TAUTHOR_TAG.', 'all are']","['2, largely based on  #TAUTHOR_TAG.', 'all are 0 - 1 indicator functions.', 'inserted is 1 if']","['2, largely based on  #TAUTHOR_TAG.', 'all are']","['features used are detailed in table 2, largely based on  #TAUTHOR_TAG.', 'all are 0 - 1 indicator functions.', 'inserted is 1 if the node was inserted by the parser ; dl is the dependency label in the original dependency tree ; ner the named entity tag ; pos the part - of - speech tag ; prefix is the string before the hyphen if word is hyphenated ; suffix is the string after the hyphen ; brown is the 100 - class brown cluster id with cuts at 4, 6, 10 and 20 2 ; deleted is the lemma of any child node previously deleted by the parser ; merged is the lemma of any node merged into this node by a replacehead action ; distance is the distance between the tokens in the sentence ; path concatenates lemmas and dls between the tokens in the dependency tree ; pospath concatenates pos tags between the tokens ; nerpath concatenates ner tags between the tokens.', 'the key differences to  #TAUTHOR_TAG are the inclusion of the brown, pospath, nerpath, prefix and suffix feature types']",6
"['contains all the concepts identified in the first stage.', 'later work by  #TAUTHOR_TAG adopted a different strategy based on the similarity between']","['contains all the concepts identified in the first stage.', 'later work by  #TAUTHOR_TAG adopted a different strategy based on the similarity between']","['contains all the concepts identified in the first stage.', 'later work by  #TAUTHOR_TAG adopted a different strategy based on the similarity between']","['abstract meaning representation parsing  #AUTHOR_TAG, the goal is to parse natural language in a domain - independent graph - based meaning representation ( amr ).', 'in the first amr parsing work,  #AUTHOR_TAG split the task into two sub - tasks ; concept identification and graph creation.', 'the sub - tasks are learned independently, and exact inference is used to find highest - scoring maximum spanning connected acyclic graph that contains all the concepts identified in the first stage.', 'later work by  #TAUTHOR_TAG adopted a different strategy based on the similarity between the dependency parse of a sentence and the semantic amr graph.', '']",4
['previous work and in particular that of  #TAUTHOR_TAG who introduced the transitionbased dependency -'],"['previous work and in particular that of  #TAUTHOR_TAG who introduced the transitionbased dependency - to - amr paradigm we follow.', 'we initialise the main algorithm with a stack of the nodes in']","['previous work and in particular that of  #TAUTHOR_TAG who introduced the transitionbased dependency - to - amr paradigm we follow.', 'we initialise the main algorithm with a stack of the nodes in']","['the following subsections we focus on the differences from previous work and in particular that of  #TAUTHOR_TAG who introduced the transitionbased dependency - to - amr paradigm we follow.', 'we initialise the main algorithm with a stack of the nodes in the dependency tree, root node first.', 'this stack is termed σ.', 'a second stack, β is initialised with all children of the top node in σ.', 'the state at any time is described by σ, β, and the current graph ( which starts as the dependency tree ).', 'each action manipulates the top nodes in each stack, σ 0 and β 0.', 'we reach a terminal state when σ is empty.', '']",4
"['', ' #TAUTHOR_TAG use']","['( strike - 01 ).', ' #TAUTHOR_TAG use']","['( strike - 01 ).', ' #TAUTHOR_TAG use all amr concepts and relations']","['', 'sentence fragment. the current σ 0 node is shown dashed and in red. from the top the actions are insert', '( dateentity ) ; nextnode ( word ) ; nextedge ( year ) ; second diagram', '; nextnode ( word ) ; replacehead to remove "" in ""', '; third diagram ; nextnode ( word ) ; nextedge ( mod ) ; reattach to move "" date - entity "" ; fourth diagram ; nextnode ( verb ) ; replace', '##head to remove "" by "" ; nextedge ( arg0 ) ; nextedge (', 'time ) ; nextnode ( strike - 01 ).', ' #TAUTHOR_TAG']",4
"['', ' #TAUTHOR_TAG use']","['( strike - 01 ).', ' #TAUTHOR_TAG use']","['( strike - 01 ).', ' #TAUTHOR_TAG use all amr concepts and relations']","['', 'sentence fragment. the current σ 0 node is shown dashed and in red. from the top the actions are insert', '( dateentity ) ; nextnode ( word ) ; nextedge ( year ) ; second diagram', '; nextnode ( word ) ; replacehead to remove "" in ""', '; third diagram ; nextnode ( word ) ; nextedge ( mod ) ; reattach to move "" date - entity "" ; fourth diagram ; nextnode ( verb ) ; replace', '##head to remove "" by "" ; nextedge ( arg0 ) ; nextedge (', 'time ) ; nextnode ( strike - 01 ).', ' #TAUTHOR_TAG']",4
"['', ' #TAUTHOR_TAG use']","['( strike - 01 ).', ' #TAUTHOR_TAG use']","['( strike - 01 ).', ' #TAUTHOR_TAG use all amr concepts and relations']","['', 'sentence fragment. the current σ 0 node is shown dashed and in red. from the top the actions are insert', '( dateentity ) ; nextnode ( word ) ; nextedge ( year ) ; second diagram', '; nextnode ( word ) ; replacehead to remove "" in ""', '; third diagram ; nextnode ( word ) ; nextedge ( mod ) ; reattach to move "" date - entity "" ; fourth diagram ; nextnode ( verb ) ; replace', '##head to remove "" by "" ; nextedge ( arg0 ) ; nextedge (', 'time ) ; nextnode ( strike - 01 ).', ' #TAUTHOR_TAG']",4
"['2, largely based on  #TAUTHOR_TAG.', 'all are']","['2, largely based on  #TAUTHOR_TAG.', 'all are 0 - 1 indicator functions.', 'inserted is 1 if']","['2, largely based on  #TAUTHOR_TAG.', 'all are']","['features used are detailed in table 2, largely based on  #TAUTHOR_TAG.', 'all are 0 - 1 indicator functions.', 'inserted is 1 if the node was inserted by the parser ; dl is the dependency label in the original dependency tree ; ner the named entity tag ; pos the part - of - speech tag ; prefix is the string before the hyphen if word is hyphenated ; suffix is the string after the hyphen ; brown is the 100 - class brown cluster id with cuts at 4, 6, 10 and 20 2 ; deleted is the lemma of any child node previously deleted by the parser ; merged is the lemma of any node merged into this node by a replacehead action ; distance is the distance between the tokens in the sentence ; path concatenates lemmas and dls between the tokens in the dependency tree ; pospath concatenates pos tags between the tokens ; nerpath concatenates ner tags between the tokens.', 'the key differences to  #TAUTHOR_TAG are the inclusion of the brown, pospath, nerpath, prefix and suffix feature types']",4
"['2, largely based on  #TAUTHOR_TAG.', 'all are']","['2, largely based on  #TAUTHOR_TAG.', 'all are 0 - 1 indicator functions.', 'inserted is 1 if']","['2, largely based on  #TAUTHOR_TAG.', 'all are']","['features used are detailed in table 2, largely based on  #TAUTHOR_TAG.', 'all are 0 - 1 indicator functions.', 'inserted is 1 if the node was inserted by the parser ; dl is the dependency label in the original dependency tree ; ner the named entity tag ; pos the part - of - speech tag ; prefix is the string before the hyphen if word is hyphenated ; suffix is the string after the hyphen ; brown is the 100 - class brown cluster id with cuts at 4, 6, 10 and 20 2 ; deleted is the lemma of any child node previously deleted by the parser ; merged is the lemma of any node merged into this node by a replacehead action ; distance is the distance between the tokens in the sentence ; path concatenates lemmas and dls between the tokens in the dependency tree ; pospath concatenates pos tags between the tokens ; nerpath concatenates ner tags between the tokens.', 'the key differences to  #TAUTHOR_TAG are the inclusion of the brown, pospath, nerpath, prefix and suffix feature types']",3
"['2, largely based on  #TAUTHOR_TAG.', 'all are']","['2, largely based on  #TAUTHOR_TAG.', 'all are 0 - 1 indicator functions.', 'inserted is 1 if']","['2, largely based on  #TAUTHOR_TAG.', 'all are']","['features used are detailed in table 2, largely based on  #TAUTHOR_TAG.', 'all are 0 - 1 indicator functions.', 'inserted is 1 if the node was inserted by the parser ; dl is the dependency label in the original dependency tree ; ner the named entity tag ; pos the part - of - speech tag ; prefix is the string before the hyphen if word is hyphenated ; suffix is the string after the hyphen ; brown is the 100 - class brown cluster id with cuts at 4, 6, 10 and 20 2 ; deleted is the lemma of any child node previously deleted by the parser ; merged is the lemma of any node merged into this node by a replacehead action ; distance is the distance between the tokens in the sentence ; path concatenates lemmas and dls between the tokens in the dependency tree ; pospath concatenates pos tags between the tokens ; nerpath concatenates ner tags between the tokens.', 'the key differences to  #TAUTHOR_TAG are the inclusion of the brown, pospath, nerpath, prefix and suffix feature types']",5
"[', has been widely studied in recent years  #TAUTHOR_TAG.', '']","['answering, has been widely studied in recent years  #TAUTHOR_TAG.', '']","['has been widely studied in recent years  #TAUTHOR_TAG.', '']",[' #TAUTHOR_TAG'],0
['of the recent approaches  #TAUTHOR_TAG are based on automatically extracted features of terms ; thanks to the prominent'],['of the recent approaches  #TAUTHOR_TAG are based on automatically extracted features of terms ; thanks to the prominent'],"['of the recent approaches  #TAUTHOR_TAG are based on automatically extracted features of terms ; thanks to the prominent performance of neural network on representation learning  #AUTHOR_TAG a, b ).', 'from another point of view, two mainstreams']","['paradigm in proposed approaches for relation extraction in kbqa is based on semantic parsing in which questions were parsed and turned into logical forms in order to query the knowledge base  #AUTHOR_TAG.', 'however, most of the recent approaches  #TAUTHOR_TAG are based on automatically extracted features of terms ; thanks to the prominent performance of neural network on representation learning  #AUTHOR_TAG a, b ).', 'from another point of view, two mainstreams for extracting relations in kbqa are studied : ( a ) using a classifier which chooses the most probable relation among all  #AUTHOR_TAG ; ( b ) matching questions and relations through learning of an embedding space for representing all relations and question words  #TAUTHOR_TAG, in which each relation is considered either as a meaningful sequence of words or as a unique entity.', ' #AUTHOR_TAG considered the relation prediction, as well as the whole kbqa problem, as a conditional probability task in which the goal is finding the most probable relation given the question mention.', 'to this aim, they']",0
['of the recent approaches  #TAUTHOR_TAG are based on automatically extracted features of terms ; thanks to the prominent'],['of the recent approaches  #TAUTHOR_TAG are based on automatically extracted features of terms ; thanks to the prominent'],"['of the recent approaches  #TAUTHOR_TAG are based on automatically extracted features of terms ; thanks to the prominent performance of neural network on representation learning  #AUTHOR_TAG a, b ).', 'from another point of view, two mainstreams']","['paradigm in proposed approaches for relation extraction in kbqa is based on semantic parsing in which questions were parsed and turned into logical forms in order to query the knowledge base  #AUTHOR_TAG.', 'however, most of the recent approaches  #TAUTHOR_TAG are based on automatically extracted features of terms ; thanks to the prominent performance of neural network on representation learning  #AUTHOR_TAG a, b ).', 'from another point of view, two mainstreams for extracting relations in kbqa are studied : ( a ) using a classifier which chooses the most probable relation among all  #AUTHOR_TAG ; ( b ) matching questions and relations through learning of an embedding space for representing all relations and question words  #TAUTHOR_TAG, in which each relation is considered either as a meaningful sequence of words or as a unique entity.', ' #AUTHOR_TAG considered the relation prediction, as well as the whole kbqa problem, as a conditional probability task in which the goal is finding the most probable relation given the question mention.', 'to this aim, they']",0
"['. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bic']","['. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks']","['compare them with the available methods in this task. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks']","['', ""q'- r model 93. 41 are not originally evaluated on relation prediction of simple questions. in fact, the authors of ampcnn  #AUTHOR_TAG, conducted the corresponding experiments on a one - way -"", 'attention adaptation of these two models to compare them with the available methods in this task. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks for matching a question', 'with relations. the model is reimplemented for simplequestions by  #TAUTHOR_TAG. as', 'it is shown, our proposed model outperforms the state - of - the -', 'art models in relation extraction for simplequestions dataset by', 'a margin of 0. 11 percentage. we', 'believe that this improvement is an', 'effect of the two contributions that we had in this paper, namely proposing a combined', ""q'- q + q'- r network and the two - channel text matching model in the q'- q network"", '']",0
"[', has been widely studied in recent years  #TAUTHOR_TAG.', '']","['answering, has been widely studied in recent years  #TAUTHOR_TAG.', '']","['has been widely studied in recent years  #TAUTHOR_TAG.', '']",[' #TAUTHOR_TAG'],3
"['works by  #AUTHOR_TAG and  #TAUTHOR_TAG, we use the common benchmark']","['works by  #AUTHOR_TAG and  #TAUTHOR_TAG, we use the common benchmark']","['by  #AUTHOR_TAG and  #TAUTHOR_TAG, we use the common benchmark dataset of the simple question answering, namely simplequestions,']","['the previous works by  #AUTHOR_TAG and  #TAUTHOR_TAG, we use the common benchmark dataset of the simple question answering, namely simplequestions, which was originally introduced by  #AUTHOR_TAG.', 'this dataset contains 108442 questions gathered with the help of english - speaking annotators.', ' #AUTHOR_TAG proposed a new benchmark for evaluating relation extraction task on simplequestion.', 'in this benchmark, every question, whose entity is replaced by a unique token, is labeled with its ground truth relation as its positive label, and all other relation of the gold entity that is mentioned in the question are considered as negative labels.', 'we use the same dataset which contains 72239, 10310 and 20610 question samples as train, validation, and test sets respectively']",3
"['. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bic']","['. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks']","['compare them with the available methods in this task. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks']","['', ""q'- r model 93. 41 are not originally evaluated on relation prediction of simple questions. in fact, the authors of ampcnn  #AUTHOR_TAG, conducted the corresponding experiments on a one - way -"", 'attention adaptation of these two models to compare them with the available methods in this task. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks for matching a question', 'with relations. the model is reimplemented for simplequestions by  #TAUTHOR_TAG. as', 'it is shown, our proposed model outperforms the state - of - the -', 'art models in relation extraction for simplequestions dataset by', 'a margin of 0. 11 percentage. we', 'believe that this improvement is an', 'effect of the two contributions that we had in this paper, namely proposing a combined', ""q'- q + q'- r network and the two - channel text matching model in the q'- q network"", '']",3
"['', 'additionally, following  #TAUTHOR_TAG,']","[""( q'with q )."", 'additionally, following  #TAUTHOR_TAG,']","['', ""additionally, following  #TAUTHOR_TAG, we add another neural network ( q'- r ), the right part of the architecture,""]","['', ""in this sense, we are using an instance - based method by computing the relatedness of each new q'to all train questions."", 'the architecture of our model is depicted in figure 1.', ""as can be seen, represents the similarity of two questions ( q'with q )."", ""additionally, following  #TAUTHOR_TAG, we add another neural network ( q'- r ), the right part of the architecture, to compute the matching score of q'with the relation of q ( r )."", ""by doing so, we are enhancing the matching signals between q'and q to estimate the overall score."", 'in the first step, our proposed model projects the input question as well as the available questions and relations of training data into an embedding space.', ""to do so, each sequence of words ( q ', q and r ) are fed to an embedding layer and all of their corresponding vectors are fetched."", '']",4
"['', 'additionally, following  #TAUTHOR_TAG,']","[""( q'with q )."", 'additionally, following  #TAUTHOR_TAG,']","['', ""additionally, following  #TAUTHOR_TAG, we add another neural network ( q'- r ), the right part of the architecture,""]","['', ""in this sense, we are using an instance - based method by computing the relatedness of each new q'to all train questions."", 'the architecture of our model is depicted in figure 1.', ""as can be seen, represents the similarity of two questions ( q'with q )."", ""additionally, following  #TAUTHOR_TAG, we add another neural network ( q'- r ), the right part of the architecture, to compute the matching score of q'with the relation of q ( r )."", ""by doing so, we are enhancing the matching signals between q'and q to estimate the overall score."", 'in the first step, our proposed model projects the input question as well as the available questions and relations of training data into an embedding space.', ""to do so, each sequence of words ( q ', q and r ) are fed to an embedding layer and all of their corresponding vectors are fetched."", '']",6
"['works by  #AUTHOR_TAG and  #TAUTHOR_TAG, we use the common benchmark']","['works by  #AUTHOR_TAG and  #TAUTHOR_TAG, we use the common benchmark']","['by  #AUTHOR_TAG and  #TAUTHOR_TAG, we use the common benchmark dataset of the simple question answering, namely simplequestions,']","['the previous works by  #AUTHOR_TAG and  #TAUTHOR_TAG, we use the common benchmark dataset of the simple question answering, namely simplequestions, which was originally introduced by  #AUTHOR_TAG.', 'this dataset contains 108442 questions gathered with the help of english - speaking annotators.', ' #AUTHOR_TAG proposed a new benchmark for evaluating relation extraction task on simplequestion.', 'in this benchmark, every question, whose entity is replaced by a unique token, is labeled with its ground truth relation as its positive label, and all other relation of the gold entity that is mentioned in the question are considered as negative labels.', 'we use the same dataset which contains 72239, 10310 and 20610 question samples as train, validation, and test sets respectively']",5
"['. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bic']","['. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks']","['compare them with the available methods in this task. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks']","['', ""q'- r model 93. 41 are not originally evaluated on relation prediction of simple questions. in fact, the authors of ampcnn  #AUTHOR_TAG, conducted the corresponding experiments on a one - way -"", 'attention adaptation of these two models to compare them with the available methods in this task. hier - res - bilstm  #TAUTHOR_TAG uses', 'hierarchical residual connections to ease the training procedure of bil - stm. bicnn  #AUTHOR_TAG uses convolutional neural networks for matching a question', 'with relations. the model is reimplemented for simplequestions by  #TAUTHOR_TAG. as', 'it is shown, our proposed model outperforms the state - of - the -', 'art models in relation extraction for simplequestions dataset by', 'a margin of 0. 11 percentage. we', 'believe that this improvement is an', 'effect of the two contributions that we had in this paper, namely proposing a combined', ""q'- q + q'- r network and the two - channel text matching model in the q'- q network"", '']",5
"['to targets specified in reviews.', 'at  #TAUTHOR_TAG, a chinese dataset for aspectbased']","['to targets specified in reviews.', 'at  #TAUTHOR_TAG, a chinese dataset for aspectbased']","['to targets specified in reviews.', 'at  #TAUTHOR_TAG, a chinese dataset for aspect']","['neutral negative laptop train 980 454 858 test 340 171 128 restaurant train 2159 632 800 test 730 196 195 twitter train 1567 3127 1563 test 174 346 174 table 1 - number of data samples for each sentiment polarity of 3 english datasets sentence level, at  #AUTHOR_TAG proposed spersent, a persian dataset consisting of 150, 000 sentences from product reviews of digikala website.', 'each sentence is associated with two types of labels, binary ( positive and negative ) and five - star rating and is labeled automatically based on the majority voting of three different lexicons.', 'in last decade, in aspect - based sentiment analysis, most of the data resources and systems built so far are tailored to english and other languages like chinese and arabic.', 'there are three datasets for english which are mainly used by researchers to compare the performance of their systems.', 'these three datasets are restaurants and laptops  #AUTHOR_TAG and twitter  #AUTHOR_TAG.', 'first and second datasets are annotated data samples from comments and reviews about laptops and restaurants from semeval - 2014 task 4 : aspectbased sentiment analysis and the last one is collected tweets from twitter.', 'the number of data samples in each dataset is given in table 1.', 'at  #AUTHOR_TAG, sentihood is presented, which consists of annotated data from a qa platform in the domain of neighborhoods of a city.', 'along with this dataset, the task of targeted aspectbased sentiment analysis is introduced which is different from general aspect - based sentiment analysis, in extracting fine - grained information with respect to targets specified in reviews.', 'at  #TAUTHOR_TAG, a chinese dataset for aspectbased sentiment analysis from comments about the news with 6365 positive, 9457 neutral and 6839 negative annotated data samples was proposed']",0
"['', 'ram  #TAUTHOR_TAG : this method makes a memory from']","['a series of customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from']","['customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from the input and with using multiple attention mechanism, it extracts important']","['test pars - absa dataset, 6 recent systems available for aspect - based sentiment analysis with a focus on deep learning methods and a typical long short - term memory network model were used.', 'table 3 compares the performance of these models on english datasets based on f1 score macro and accuracy metrics.', 'these methods are : aoa : an attention over attention neural network which captures the interaction between aspects and context sentences.', 'cabasc  #AUTHOR_TAG : this method utilizes two attention mechanisms : sentence - level content attention mechanism which captures the important information about given aspects from a global perspective, while the context attention mechanism is responsible for simultaneously taking the order of the words and their correlations into account, by embedding them into a series of customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from the input and with using multiple attention mechanism, it extracts important information from memory and for prediction it uses a combination of the extracted features of different attentions non - linearly.', 'ian  #AUTHOR_TAG : it learns the attentions inside the document and targets interactively, and originates the representations for targets and the document separately.', 'atae - lstm  #AUTHOR_TAG : it uses attention mechanism along with long short - term memory network.', 'td - lstm  #AUTHOR_TAG table 4.', 'performance of models on pars - absa.', 'but among the models, the result of td - lstm  #AUTHOR_TAG was quite surprising.', 'because the other models were proposed after td - lstm  #AUTHOR_TAG and their performances on english datasets were better than td - lstm  #AUTHOR_TAG, so it was expected from them to perform better on pars - absa dataset too.', 'the authors of ram  #TAUTHOR_TAG claimed that their model is language insensitive, which mean it can perform on all languages and, compared to td - lstm  #AUTHOR_TAG which might lose feature if the opinion word is far from the target, they employed the recurrent attention to solving this problem.', ""but by comparing results, it's obvious that td - lstm  #AUTHOR_TAG outperforms their method in persian."", 'pars - absa dataset is available through : https : / / github. com / titowak / pars - abs']",0
"['', 'ram  #TAUTHOR_TAG : this method makes a memory from']","['a series of customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from']","['customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from the input and with using multiple attention mechanism, it extracts important']","['test pars - absa dataset, 6 recent systems available for aspect - based sentiment analysis with a focus on deep learning methods and a typical long short - term memory network model were used.', 'table 3 compares the performance of these models on english datasets based on f1 score macro and accuracy metrics.', 'these methods are : aoa : an attention over attention neural network which captures the interaction between aspects and context sentences.', 'cabasc  #AUTHOR_TAG : this method utilizes two attention mechanisms : sentence - level content attention mechanism which captures the important information about given aspects from a global perspective, while the context attention mechanism is responsible for simultaneously taking the order of the words and their correlations into account, by embedding them into a series of customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from the input and with using multiple attention mechanism, it extracts important information from memory and for prediction it uses a combination of the extracted features of different attentions non - linearly.', 'ian  #AUTHOR_TAG : it learns the attentions inside the document and targets interactively, and originates the representations for targets and the document separately.', 'atae - lstm  #AUTHOR_TAG : it uses attention mechanism along with long short - term memory network.', 'td - lstm  #AUTHOR_TAG table 4.', 'performance of models on pars - absa.', 'but among the models, the result of td - lstm  #AUTHOR_TAG was quite surprising.', 'because the other models were proposed after td - lstm  #AUTHOR_TAG and their performances on english datasets were better than td - lstm  #AUTHOR_TAG, so it was expected from them to perform better on pars - absa dataset too.', 'the authors of ram  #TAUTHOR_TAG claimed that their model is language insensitive, which mean it can perform on all languages and, compared to td - lstm  #AUTHOR_TAG which might lose feature if the opinion word is far from the target, they employed the recurrent attention to solving this problem.', ""but by comparing results, it's obvious that td - lstm  #AUTHOR_TAG outperforms their method in persian."", 'pars - absa dataset is available through : https : / / github. com / titowak / pars - abs']",0
"['', 'ram  #TAUTHOR_TAG : this method makes a memory from']","['a series of customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from']","['customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from the input and with using multiple attention mechanism, it extracts important']","['test pars - absa dataset, 6 recent systems available for aspect - based sentiment analysis with a focus on deep learning methods and a typical long short - term memory network model were used.', 'table 3 compares the performance of these models on english datasets based on f1 score macro and accuracy metrics.', 'these methods are : aoa : an attention over attention neural network which captures the interaction between aspects and context sentences.', 'cabasc  #AUTHOR_TAG : this method utilizes two attention mechanisms : sentence - level content attention mechanism which captures the important information about given aspects from a global perspective, while the context attention mechanism is responsible for simultaneously taking the order of the words and their correlations into account, by embedding them into a series of customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from the input and with using multiple attention mechanism, it extracts important information from memory and for prediction it uses a combination of the extracted features of different attentions non - linearly.', 'ian  #AUTHOR_TAG : it learns the attentions inside the document and targets interactively, and originates the representations for targets and the document separately.', 'atae - lstm  #AUTHOR_TAG : it uses attention mechanism along with long short - term memory network.', 'td - lstm  #AUTHOR_TAG table 4.', 'performance of models on pars - absa.', 'but among the models, the result of td - lstm  #AUTHOR_TAG was quite surprising.', 'because the other models were proposed after td - lstm  #AUTHOR_TAG and their performances on english datasets were better than td - lstm  #AUTHOR_TAG, so it was expected from them to perform better on pars - absa dataset too.', 'the authors of ram  #TAUTHOR_TAG claimed that their model is language insensitive, which mean it can perform on all languages and, compared to td - lstm  #AUTHOR_TAG which might lose feature if the opinion word is far from the target, they employed the recurrent attention to solving this problem.', ""but by comparing results, it's obvious that td - lstm  #AUTHOR_TAG outperforms their method in persian."", 'pars - absa dataset is available through : https : / / github. com / titowak / pars - abs']",5
"['', 'ram  #TAUTHOR_TAG : this method makes a memory from']","['a series of customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from']","['customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from the input and with using multiple attention mechanism, it extracts important']","['test pars - absa dataset, 6 recent systems available for aspect - based sentiment analysis with a focus on deep learning methods and a typical long short - term memory network model were used.', 'table 3 compares the performance of these models on english datasets based on f1 score macro and accuracy metrics.', 'these methods are : aoa : an attention over attention neural network which captures the interaction between aspects and context sentences.', 'cabasc  #AUTHOR_TAG : this method utilizes two attention mechanisms : sentence - level content attention mechanism which captures the important information about given aspects from a global perspective, while the context attention mechanism is responsible for simultaneously taking the order of the words and their correlations into account, by embedding them into a series of customized memories.', 'ram  #TAUTHOR_TAG : this method makes a memory from the input and with using multiple attention mechanism, it extracts important information from memory and for prediction it uses a combination of the extracted features of different attentions non - linearly.', 'ian  #AUTHOR_TAG : it learns the attentions inside the document and targets interactively, and originates the representations for targets and the document separately.', 'atae - lstm  #AUTHOR_TAG : it uses attention mechanism along with long short - term memory network.', 'td - lstm  #AUTHOR_TAG table 4.', 'performance of models on pars - absa.', 'but among the models, the result of td - lstm  #AUTHOR_TAG was quite surprising.', 'because the other models were proposed after td - lstm  #AUTHOR_TAG and their performances on english datasets were better than td - lstm  #AUTHOR_TAG, so it was expected from them to perform better on pars - absa dataset too.', 'the authors of ram  #TAUTHOR_TAG claimed that their model is language insensitive, which mean it can perform on all languages and, compared to td - lstm  #AUTHOR_TAG which might lose feature if the opinion word is far from the target, they employed the recurrent attention to solving this problem.', ""but by comparing results, it's obvious that td - lstm  #AUTHOR_TAG outperforms their method in persian."", 'pars - absa dataset is available through : https : / / github. com / titowak / pars - abs']",4
,,,,0
"['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['argument component identification where textual inputs are typically sentences or clauses  #TAUTHOR_TAG, textual inputs of argumentative relation mining vary from clauses  #AUTHOR_TAG b ;  #AUTHOR_TAG to multiple - sentences  #AUTHOR_TAG boltuzic and  #AUTHOR_TAG.', 'studying claim justification between user comments,  #AUTHOR_TAG proposed that the argumentation in justification of a claim can be characterized with discourse structure in the justification.', 'they however only considered discourse markers but not discourse relations.', ' #AUTHOR_TAG conducted a corpus analysis and found certain similarity between penn discourse treebank relations  #AUTHOR_TAG and argumentation schemes  #AUTHOR_TAG.', 'however they did not discuss how such similarity could be applied to argument mining.', 'motivated by these findings, we propose to use features extracted from discourse relations be - tween sentences for argumentative relation mining.', 'moreover, to enable discourse relation features when the textual inputs are only sentences / clauses, we group the inputs with their context sentences.', ' #AUTHOR_TAG used the term "" context sentence "" to refer to sentences surrounding a citation that contained information about the cited source but did not explicitly cite it.', 'in our study, we only require that the context sentences of an argument component must be in the same paragraph and adjacent to the component.', '']",0
"['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['argument component identification where textual inputs are typically sentences or clauses  #TAUTHOR_TAG, textual inputs of argumentative relation mining vary from clauses  #AUTHOR_TAG b ;  #AUTHOR_TAG to multiple - sentences  #AUTHOR_TAG boltuzic and  #AUTHOR_TAG.', 'studying claim justification between user comments,  #AUTHOR_TAG proposed that the argumentation in justification of a claim can be characterized with discourse structure in the justification.', 'they however only considered discourse markers but not discourse relations.', ' #AUTHOR_TAG conducted a corpus analysis and found certain similarity between penn discourse treebank relations  #AUTHOR_TAG and argumentation schemes  #AUTHOR_TAG.', 'however they did not discuss how such similarity could be applied to argument mining.', 'motivated by these findings, we propose to use features extracted from discourse relations be - tween sentences for argumentative relation mining.', 'moreover, to enable discourse relation features when the textual inputs are only sentences / clauses, we group the inputs with their context sentences.', ' #AUTHOR_TAG used the term "" context sentence "" to refer to sentences surrounding a citation that contained information about the cited source but did not explicitly cite it.', 'in our study, we only require that the context sentences of an argument component must be in the same paragraph and adjacent to the component.', '']",0
"['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g']","['adapt  #AUTHOR_TAG b ) to use as a baseline for evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g., word pairs, first words ), and grammatical production rules ( e. g., s→np, vp ).', '']",0
"['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g']","['adapt  #AUTHOR_TAG b ) to use as a baseline for evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g., word pairs, first words ), and grammatical production rules ( e. g., s→np, vp ).', '']",0
"['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['argument component identification where textual inputs are typically sentences or clauses  #TAUTHOR_TAG, textual inputs of argumentative relation mining vary from clauses  #AUTHOR_TAG b ;  #AUTHOR_TAG to multiple - sentences  #AUTHOR_TAG boltuzic and  #AUTHOR_TAG.', 'studying claim justification between user comments,  #AUTHOR_TAG proposed that the argumentation in justification of a claim can be characterized with discourse structure in the justification.', 'they however only considered discourse markers but not discourse relations.', ' #AUTHOR_TAG conducted a corpus analysis and found certain similarity between penn discourse treebank relations  #AUTHOR_TAG and argumentation schemes  #AUTHOR_TAG.', 'however they did not discuss how such similarity could be applied to argument mining.', 'motivated by these findings, we propose to use features extracted from discourse relations be - tween sentences for argumentative relation mining.', 'moreover, to enable discourse relation features when the textual inputs are only sentences / clauses, we group the inputs with their context sentences.', ' #AUTHOR_TAG used the term "" context sentence "" to refer to sentences surrounding a citation that contained information about the cited source but did not explicitly cite it.', 'in our study, we only require that the context sentences of an argument component must be in the same paragraph and adjacent to the component.', '']",5
['by  #TAUTHOR_TAG to serve as the baseline'],['by  #TAUTHOR_TAG to serve as the baseline'],['by  #TAUTHOR_TAG to serve as the baseline'],"['a ) compiled the persuasive essay corpus consisting of 90 student argumentative essays and made it publicly available.', '3 because the corpus has been utilized for different argument mining tasks  #AUTHOR_TAG b ;  #AUTHOR_TAG, we use this corpus to demonstrate our context - aware argumentative relation mining approach, and adapt the model developed by  #TAUTHOR_TAG to serve as the baseline for evaluating our proposed approach.', ""three experts identified possible argument components of three types within each sentence in the corpus ( majorclaim - writer's stance toward the writing topic, claim - controversial statements that support or attack majorclaim, and premiseevidence used to underpin the validity of claim ), and also connected the argument components using two argumentative relations ( support and attack )."", 'according to the annotation manual, each essay has exactly one majorclaim.', '']",5
"['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g']","['adapt  #AUTHOR_TAG b ) to use as a baseline for evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g., word pairs, first words ), and grammatical production rules ( e. g., s→np, vp ).', '']",5
"['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g']","['adapt  #AUTHOR_TAG b ) to use as a baseline for evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g., word pairs, first words ), and grammatical production rules ( e. g., s→np, vp ).', '']",5
"['argument mining tasks  #TAUTHOR_TAG, we exclude them here']","['argument mining tasks  #TAUTHOR_TAG, we exclude them here. discourse marker : while the baseline model only considers discourse markers within the argument components, we define', 'a boolean feature for']","['argument mining tasks  #TAUTHOR_TAG, we exclude them here']","['', 'available given the discourse parser we use. thus, we use relations at type - level', 'as features. for rst - dt', '##b relations, we use only relation labels, but ignore the nucleus and satellite labels of components as they do not provide more information given the component order in the pair. because temporal relations were', 'shown not helpful for argument mining tasks  #TAUTHOR_TAG, we exclude them here. discourse marker : while the baseline model only considers discourse markers within the argument components, we define', 'a boolean feature for each discourse marker classifying whether the marker is present before the covering sentence of the source and target components or not. this implementation aims to characterize the discourse of the preceding and following text', 'segments of each argument component separately. finally, we include the', 'common feature set']",5
"['.', 'we use the training set as determined in  #TAUTHOR_TAG to']","['validation.', 'we use the training set as determined in  #TAUTHOR_TAG to']","['- fold cross validation.', 'we use the training set as determined in  #TAUTHOR_TAG to']","[', the full model includes all features in baseline and combined models.', 'that is, the full model is the combined model plus word pairs and production rules.', 'a summary of all models is shown in figure 3.', 'window - size in range [ 0, 8 ] 8 that yields the best f1 score in 10 - fold cross validation.', 'we use the training set as determined in  #TAUTHOR_TAG to train / test 9 the models using liblinear algorithm  #AUTHOR_TAG without parameter or feature optimization.', 'cross - validations are conducted using weka  #AUTHOR_TAG.', 'we use stanford parser  #AUTHOR_TAG to perform text processing.', 'as shown in figure 4, while increasing the window - size from 2 to 3 improves performance ( significantly ), using window - sizes greater than 3 does not gain further improvement.', 'we hypothesize that after a certain limit, larger context windows will produce more noise than helpful information for the prediction.', 'therefore, we set the window - size to 3 in all of our experiments involving window - context model ( all with a separate test set )']",5
"['. non - support classification in  #TAUTHOR_TAG.', 'the learning algorithm with parameters are kept']","['support vs. non - support classification in  #TAUTHOR_TAG.', 'the learning algorithm with parameters are kept']","['. non - support classification in  #TAUTHOR_TAG.', 'the learning algorithm with parameters are kept']","['train all models using the training set and report their performances on the test set in table 2.', 'we also compare our baseline to the reported performance ( report ) for support vs. non - support classification in  #TAUTHOR_TAG.', 'the learning algorithm with parameters are kept the same as in the window - size tuning experiment.', '']",5
"['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['argument component identification where textual inputs are typically sentences or clauses  #TAUTHOR_TAG, textual inputs of argumentative relation mining vary from clauses  #AUTHOR_TAG b ;  #AUTHOR_TAG to multiple - sentences  #AUTHOR_TAG boltuzic and  #AUTHOR_TAG.', 'studying claim justification between user comments,  #AUTHOR_TAG proposed that the argumentation in justification of a claim can be characterized with discourse structure in the justification.', 'they however only considered discourse markers but not discourse relations.', ' #AUTHOR_TAG conducted a corpus analysis and found certain similarity between penn discourse treebank relations  #AUTHOR_TAG and argumentation schemes  #AUTHOR_TAG.', 'however they did not discuss how such similarity could be applied to argument mining.', 'motivated by these findings, we propose to use features extracted from discourse relations be - tween sentences for argumentative relation mining.', 'moreover, to enable discourse relation features when the textual inputs are only sentences / clauses, we group the inputs with their context sentences.', ' #AUTHOR_TAG used the term "" context sentence "" to refer to sentences surrounding a citation that contained information about the cited source but did not explicitly cite it.', 'in our study, we only require that the context sentences of an argument component must be in the same paragraph and adjacent to the component.', '']",4
"['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['or clauses  #TAUTHOR_TAG, textual inputs of']","['argument component identification where textual inputs are typically sentences or clauses  #TAUTHOR_TAG, textual inputs of argumentative relation mining vary from clauses  #AUTHOR_TAG b ;  #AUTHOR_TAG to multiple - sentences  #AUTHOR_TAG boltuzic and  #AUTHOR_TAG.', 'studying claim justification between user comments,  #AUTHOR_TAG proposed that the argumentation in justification of a claim can be characterized with discourse structure in the justification.', 'they however only considered discourse markers but not discourse relations.', ' #AUTHOR_TAG conducted a corpus analysis and found certain similarity between penn discourse treebank relations  #AUTHOR_TAG and argumentation schemes  #AUTHOR_TAG.', 'however they did not discuss how such similarity could be applied to argument mining.', 'motivated by these findings, we propose to use features extracted from discourse relations be - tween sentences for argumentative relation mining.', 'moreover, to enable discourse relation features when the textual inputs are only sentences / clauses, we group the inputs with their context sentences.', ' #AUTHOR_TAG used the term "" context sentence "" to refer to sentences surrounding a citation that contained information about the cited source but did not explicitly cite it.', 'in our study, we only require that the context sentences of an argument component must be in the same paragraph and adjacent to the component.', '']",3
['by  #TAUTHOR_TAG to serve as the baseline'],['by  #TAUTHOR_TAG to serve as the baseline'],['by  #TAUTHOR_TAG to serve as the baseline'],"['a ) compiled the persuasive essay corpus consisting of 90 student argumentative essays and made it publicly available.', '3 because the corpus has been utilized for different argument mining tasks  #AUTHOR_TAG b ;  #AUTHOR_TAG, we use this corpus to demonstrate our context - aware argumentative relation mining approach, and adapt the model developed by  #TAUTHOR_TAG to serve as the baseline for evaluating our proposed approach.', ""three experts identified possible argument components of three types within each sentence in the corpus ( majorclaim - writer's stance toward the writing topic, claim - controversial statements that support or attack majorclaim, and premiseevidence used to underpin the validity of claim ), and also connected the argument components using two argumentative relations ( support and attack )."", 'according to the annotation manual, each essay has exactly one majorclaim.', '']",6
"['.', ""because this task was not studied in  #TAUTHOR_TAG, we adapt stab and gurevych's model to use as the baseline""]","['( 11 % ) attack relations.', ""because this task was not studied in  #TAUTHOR_TAG, we adapt stab and gurevych's model to use as the baseline""]","['', ""because this task was not studied in  #TAUTHOR_TAG, we adapt stab and gurevych's model to use as the baseline""]","['further evaluate the effectiveness of our approach, we conduct an additional task that classifies an argumentative relation as support or attack.', 'for this task, we assume that the relation ( i. e., attachment  #AUTHOR_TAG ) between two components is given, and aim at identifying the argumentative function of the relation.', 'because we remove the paragraph constraint in this task, we obtain more support relations than in task 1.', 'as shown in table 1, of the total 1473 relations, we have 1312 ( 89 % ) support and 161 ( 11 % ) attack relations.', ""because this task was not studied in  #TAUTHOR_TAG, we adapt stab and gurevych's model to use as the baseline""]",6
"['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g']","['adapt  #AUTHOR_TAG b ) to use as a baseline for evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g., word pairs, first words ), and grammatical production rules ( e. g., s→np, vp ).', '']",6
"['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts,']","['evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g']","['adapt  #AUTHOR_TAG b ) to use as a baseline for evaluating our approach.', 'given a pair of argument components, we follow  #TAUTHOR_TAG by first extracting 3 feature sets : structural ( e. g., word counts, sentence position ), lexical ( e. g., word pairs, first words ), and grammatical production rules ( e. g., s→np, vp ).', '']",7
"['of the parameters in the best single model in  #TAUTHOR_TAG.', 'when incorporated into a strong arabic']","['of the parameters in the best single model in  #TAUTHOR_TAG.', 'when incorporated into a strong arabic - english machine']","['of the parameters in the best single model in  #TAUTHOR_TAG.', 'when incorporated into a strong arabic - english machine translation system they give a strong boost in translation quality.', 'we release a toolkit so that others may also train large - scale, large vocabulary lstm language models with nce, parallelizing computation across multiple gpus']","['present a simple algorithm to efficiently train language models with noise - contrastive estimation ( nce ) on graphics processing units ( gpus ).', 'our nce - trained language models achieve significantly lower perplexity on the one billion word benchmark language modeling challenge, and contain one sixth of the parameters in the best single model in  #TAUTHOR_TAG.', 'when incorporated into a strong arabic - english machine translation system they give a strong boost in translation quality.', 'we release a toolkit so that others may also train large - scale, large vocabulary lstm language models with nce, parallelizing computation across multiple gpus']",4
['based counterparts  #TAUTHOR_TAG. rn'],['based counterparts  #TAUTHOR_TAG. rn'],"['based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models,']","[', and spelling correction. they can be classified', 'into two categories : count - based and continuous - space language models. the language modeling literature abounds with', 'successful approaches for learning - count based language models : modified kneser - ney smoothing,', 'jelinekmercer smoothing, etc. in recent years, continuousspace language models such as feed - forward neural probabilistic language models ( nplms ) and recurrent neural', 'network language models ( rnns ) 1 * equal contribution. 1 henceforth we will use terms like "" rnn "" and "" lstm "" with the understanding that we are referring to', 'language models that use these formalisms have outperformed their count - based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models, as they can exploit longer word contexts to predict words. long short', '- term memory language models ( lstms ) are a class of rnns that have been designed to model long', 'histories and are easier to train than standard rnns. lstms are currently the best performing language models on the penn treebank ( ptb ) dataset  #AUTHOR_TAG. the most common', 'method for training lstms, maximum likelihood estimation ( mle ), is prohibitively expensive for large vocab', '##ularies, as it involves time - intensive matrix - matrix multiplications. noise - contrastive estimation ( nce ) has been a successful alternative to train continuous space language models with large vocabularies', ' #AUTHOR_TAG. however, nce in its standard form is not suitable for gpus, as the computations are not amenable to dense matrix operations', '. in this paper, we present a natural modification to the nce objective function for language modeling that allows a very efficient gpu implementation', '. using our new objective, we train large multi - layer lstms on the one billion word benchmark  #TAUTHOR_TAG, with its full', '780k word vocabulary. we achieve significantly lower perplexities with a single model, while using only a sixth of the parameters of a very strong baseline', 'model  #TAUTHOR_TAG. we release our toolkit 2 to allow researchers to train large - scale, large - vocabulary lstms with nce. the', 'contributions in this paper are the following : 2 www. github. com / isi - nlp / zoph', '_ rnn • a fast and simple approach for handling large vocabularies effectively on the gpu. • significantly improved perplexities ( 43', '. 2 ) on the one billion word benchmark over  #TAUTHOR_TAG • extrinsic machine translation improvement over', 'a strong baseline. • fast decoding times because in practice there is no need to normalize']",4
['based counterparts  #TAUTHOR_TAG. rn'],['based counterparts  #TAUTHOR_TAG. rn'],"['based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models,']","[', and spelling correction. they can be classified', 'into two categories : count - based and continuous - space language models. the language modeling literature abounds with', 'successful approaches for learning - count based language models : modified kneser - ney smoothing,', 'jelinekmercer smoothing, etc. in recent years, continuousspace language models such as feed - forward neural probabilistic language models ( nplms ) and recurrent neural', 'network language models ( rnns ) 1 * equal contribution. 1 henceforth we will use terms like "" rnn "" and "" lstm "" with the understanding that we are referring to', 'language models that use these formalisms have outperformed their count - based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models, as they can exploit longer word contexts to predict words. long short', '- term memory language models ( lstms ) are a class of rnns that have been designed to model long', 'histories and are easier to train than standard rnns. lstms are currently the best performing language models on the penn treebank ( ptb ) dataset  #AUTHOR_TAG. the most common', 'method for training lstms, maximum likelihood estimation ( mle ), is prohibitively expensive for large vocab', '##ularies, as it involves time - intensive matrix - matrix multiplications. noise - contrastive estimation ( nce ) has been a successful alternative to train continuous space language models with large vocabularies', ' #AUTHOR_TAG. however, nce in its standard form is not suitable for gpus, as the computations are not amenable to dense matrix operations', '. in this paper, we present a natural modification to the nce objective function for language modeling that allows a very efficient gpu implementation', '. using our new objective, we train large multi - layer lstms on the one billion word benchmark  #TAUTHOR_TAG, with its full', '780k word vocabulary. we achieve significantly lower perplexities with a single model, while using only a sixth of the parameters of a very strong baseline', 'model  #TAUTHOR_TAG. we release our toolkit 2 to allow researchers to train large - scale, large - vocabulary lstms with nce. the', 'contributions in this paper are the following : 2 www. github. com / isi - nlp / zoph', '_ rnn • a fast and simple approach for handling large vocabularies effectively on the gpu. • significantly improved perplexities ( 43', '. 2 ) on the one billion word benchmark over  #TAUTHOR_TAG • extrinsic machine translation improvement over', 'a strong baseline. • fast decoding times because in practice there is no need to normalize']",4
['based counterparts  #TAUTHOR_TAG. rn'],['based counterparts  #TAUTHOR_TAG. rn'],"['based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models,']","[', and spelling correction. they can be classified', 'into two categories : count - based and continuous - space language models. the language modeling literature abounds with', 'successful approaches for learning - count based language models : modified kneser - ney smoothing,', 'jelinekmercer smoothing, etc. in recent years, continuousspace language models such as feed - forward neural probabilistic language models ( nplms ) and recurrent neural', 'network language models ( rnns ) 1 * equal contribution. 1 henceforth we will use terms like "" rnn "" and "" lstm "" with the understanding that we are referring to', 'language models that use these formalisms have outperformed their count - based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models, as they can exploit longer word contexts to predict words. long short', '- term memory language models ( lstms ) are a class of rnns that have been designed to model long', 'histories and are easier to train than standard rnns. lstms are currently the best performing language models on the penn treebank ( ptb ) dataset  #AUTHOR_TAG. the most common', 'method for training lstms, maximum likelihood estimation ( mle ), is prohibitively expensive for large vocab', '##ularies, as it involves time - intensive matrix - matrix multiplications. noise - contrastive estimation ( nce ) has been a successful alternative to train continuous space language models with large vocabularies', ' #AUTHOR_TAG. however, nce in its standard form is not suitable for gpus, as the computations are not amenable to dense matrix operations', '. in this paper, we present a natural modification to the nce objective function for language modeling that allows a very efficient gpu implementation', '. using our new objective, we train large multi - layer lstms on the one billion word benchmark  #TAUTHOR_TAG, with its full', '780k word vocabulary. we achieve significantly lower perplexities with a single model, while using only a sixth of the parameters of a very strong baseline', 'model  #TAUTHOR_TAG. we release our toolkit 2 to allow researchers to train large - scale, large - vocabulary lstms with nce. the', 'contributions in this paper are the following : 2 www. github. com / isi - nlp / zoph', '_ rnn • a fast and simple approach for handling large vocabularies effectively on the gpu. • significantly improved perplexities ( 43', '. 2 ) on the one billion word benchmark over  #TAUTHOR_TAG • extrinsic machine translation improvement over', 'a strong baseline. • fast decoding times because in practice there is no need to normalize']",4
"['single model from  #TAUTHOR_TAG, while having almost 6 times fewer parameters.', 'we also']","['single model from  #TAUTHOR_TAG, while having almost 6 times fewer parameters.', 'we also']","['from  #TAUTHOR_TAG, while having almost 6 times fewer parameters.', 'we also']","['two experiments with lstms trained with our modification of nce show strong results in their corresponding tasks.', 'our perplexity results are shown in table 1, where we get significantly lower perplexities than the best single model from  #TAUTHOR_TAG, while having almost 6 times fewer parameters.', 'we also compute the partition function values, log z ( u ), for our development set and we find that the mean is 0. 058 and the variance is 0. 139, indicating that training has encouraged self - normalization']",4
['perplexity  #TAUTHOR_TAG 20m 51'],['perplexity  #TAUTHOR_TAG 20m 51. 3 nce ( ours )'],['perplexity  #TAUTHOR_TAG 20m 51. 3 nce ( ours )'],"['perplexity  #TAUTHOR_TAG 20m 51. 3 nce ( ours ) 3. 4m 43. 2 recently, ( jozefowicz et al., 2016 ) achieved stateof - the - art language modeling perplexities ( 30. 0 ) on the billion word dataset with a single model, using importance sampling to approximate the normalization constant, z ( u ).', 'independent of our work, they also share noise samples across the minibatch.', 'however, they use 8192 noise samples, while we achieve strong perplexities with 100 noise samples.', 'we also show significant improvements in machine translation, exploiting self - normalization for fast decoding, in addition to releasing a efficient toolkit that practitioners can use.', 'arabic - to - english n - best lists.', 'the baseline is a state - of - theart, statistical string - to - tree system.', 'bolt is a 208m - word, indomain english corpus ; "" 1b "" refers to the one billion word benchmark corpus.', 'these re - scoring experiments we simply use the unnormalized numerator p ( w | u ) as our word score, which means we never have to compute the costly partition function, z ( u ).', 'this is because the partition function is so close to 1 that the un - normalized scores are very close to the normalized ones']",4
['based counterparts  #TAUTHOR_TAG. rn'],['based counterparts  #TAUTHOR_TAG. rn'],"['based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models,']","[', and spelling correction. they can be classified', 'into two categories : count - based and continuous - space language models. the language modeling literature abounds with', 'successful approaches for learning - count based language models : modified kneser - ney smoothing,', 'jelinekmercer smoothing, etc. in recent years, continuousspace language models such as feed - forward neural probabilistic language models ( nplms ) and recurrent neural', 'network language models ( rnns ) 1 * equal contribution. 1 henceforth we will use terms like "" rnn "" and "" lstm "" with the understanding that we are referring to', 'language models that use these formalisms have outperformed their count - based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models, as they can exploit longer word contexts to predict words. long short', '- term memory language models ( lstms ) are a class of rnns that have been designed to model long', 'histories and are easier to train than standard rnns. lstms are currently the best performing language models on the penn treebank ( ptb ) dataset  #AUTHOR_TAG. the most common', 'method for training lstms, maximum likelihood estimation ( mle ), is prohibitively expensive for large vocab', '##ularies, as it involves time - intensive matrix - matrix multiplications. noise - contrastive estimation ( nce ) has been a successful alternative to train continuous space language models with large vocabularies', ' #AUTHOR_TAG. however, nce in its standard form is not suitable for gpus, as the computations are not amenable to dense matrix operations', '. in this paper, we present a natural modification to the nce objective function for language modeling that allows a very efficient gpu implementation', '. using our new objective, we train large multi - layer lstms on the one billion word benchmark  #TAUTHOR_TAG, with its full', '780k word vocabulary. we achieve significantly lower perplexities with a single model, while using only a sixth of the parameters of a very strong baseline', 'model  #TAUTHOR_TAG. we release our toolkit 2 to allow researchers to train large - scale, large - vocabulary lstms with nce. the', 'contributions in this paper are the following : 2 www. github. com / isi - nlp / zoph', '_ rnn • a fast and simple approach for handling large vocabularies effectively on the gpu. • significantly improved perplexities ( 43', '. 2 ) on the one billion word benchmark over  #TAUTHOR_TAG • extrinsic machine translation improvement over', 'a strong baseline. • fast decoding times because in practice there is no need to normalize']",5
['of language model perplexity using the standard one billion word benchmark  #TAUTHOR_TAG and'],['of language model perplexity using the standard one billion word benchmark  #TAUTHOR_TAG and'],['of language model perplexity using the standard one billion word benchmark  #TAUTHOR_TAG and an extrinsic end - to - end statistical machine translation task'],"['conducted two series of experiments to validate the efficiency of our approach and the quality of the models we learned using it : an intrinsic study of language model perplexity using the standard one billion word benchmark  #TAUTHOR_TAG and an extrinsic end - to - end statistical machine translation task that uses an lstm as one of several feature functions in re - ranking.', 'both experiments achieve excellent results']",5
"[' #TAUTHOR_TAG.', 'in this task there are roughly 0']","[' #TAUTHOR_TAG.', 'in this task there are roughly']","[' #TAUTHOR_TAG.', 'in this task there are roughly 0']","['our language modeling experiment we use the one billion word benchmark proposed by  #TAUTHOR_TAG.', 'in this task there are roughly 0. 8 billion words of training data.', 'we use perplexity to evaluate the quality of language models we train on this data.', 'we train an lstm with 4 layers, where each layer has 2048 hidden units, with a target vocabulary size of 793, 471.', 'for training, we also use dropout to prevent overfitting.', 'we follow  #AUTHOR_TAG for dropout locations, and we use a dropout rate of 0. 2.', 'the training is parallelized across 4 gpus, such that each layer lies on its own gpu and communicates its activations to the next layer once it finishes its computation']",5
['based counterparts  #TAUTHOR_TAG. rn'],['based counterparts  #TAUTHOR_TAG. rn'],"['based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models,']","[', and spelling correction. they can be classified', 'into two categories : count - based and continuous - space language models. the language modeling literature abounds with', 'successful approaches for learning - count based language models : modified kneser - ney smoothing,', 'jelinekmercer smoothing, etc. in recent years, continuousspace language models such as feed - forward neural probabilistic language models ( nplms ) and recurrent neural', 'network language models ( rnns ) 1 * equal contribution. 1 henceforth we will use terms like "" rnn "" and "" lstm "" with the understanding that we are referring to', 'language models that use these formalisms have outperformed their count - based counterparts  #TAUTHOR_TAG. rnns are more powerful than n - gram language models, as they can exploit longer word contexts to predict words. long short', '- term memory language models ( lstms ) are a class of rnns that have been designed to model long', 'histories and are easier to train than standard rnns. lstms are currently the best performing language models on the penn treebank ( ptb ) dataset  #AUTHOR_TAG. the most common', 'method for training lstms, maximum likelihood estimation ( mle ), is prohibitively expensive for large vocab', '##ularies, as it involves time - intensive matrix - matrix multiplications. noise - contrastive estimation ( nce ) has been a successful alternative to train continuous space language models with large vocabularies', ' #AUTHOR_TAG. however, nce in its standard form is not suitable for gpus, as the computations are not amenable to dense matrix operations', '. in this paper, we present a natural modification to the nce objective function for language modeling that allows a very efficient gpu implementation', '. using our new objective, we train large multi - layer lstms on the one billion word benchmark  #TAUTHOR_TAG, with its full', '780k word vocabulary. we achieve significantly lower perplexities with a single model, while using only a sixth of the parameters of a very strong baseline', 'model  #TAUTHOR_TAG. we release our toolkit 2 to allow researchers to train large - scale, large - vocabulary lstms with nce. the', 'contributions in this paper are the following : 2 www. github. com / isi - nlp / zoph', '_ rnn • a fast and simple approach for handling large vocabularies effectively on the gpu. • significantly improved perplexities ( 43', '. 2 ) on the one billion word benchmark over  #TAUTHOR_TAG • extrinsic machine translation improvement over', 'a strong baseline. • fast decoding times because in practice there is no need to normalize']",6
"['.', 'all our models are based on encoder - decoder model introduced by  #TAUTHOR_TAG for the morphological inflection task.', 'we trained our models on all the data sizes and tested on the test datasets provided by the']","['low ( 100 ) examples.', 'this paper described the three systems that we submitted to the inflection track in the sigmorphon shared task.', 'all our models are based on encoder - decoder model introduced by  #TAUTHOR_TAG for the morphological inflection task.', 'we trained our models on all the data sizes and tested on the test datasets provided by the']","['.', 'all our models are based on encoder - decoder model introduced by  #TAUTHOR_TAG for the morphological inflection task.', 'we trained our models on all the data sizes and tested on the test datasets provided by the organizers']","['inflection is the task of predicting the target inflected form from a lemma and a bundle of inflectional features.', 'for instance, given the norwegian lemma hus "" house "" and the morphological features n, def, pl the task is to predict husene "" houses "".', 'the sigmorphon shared task for 2018  #AUTHOR_TAG provided three data scenarios consisting of high ( 10000 ), medium ( 1000 ), and low ( 100 ) examples.', 'this paper described the three systems that we submitted to the inflection track in the sigmorphon shared task.', 'all our models are based on encoder - decoder model introduced by  #TAUTHOR_TAG for the morphological inflection task.', 'we trained our models on all the data sizes and tested on the test datasets provided by the organizers']",5
"['by  #TAUTHOR_TAG to morphological reinflection.', 'the']","['by  #TAUTHOR_TAG to morphological reinflection.', 'the']","['by  #TAUTHOR_TAG to morphological reinflection.', 'the input to the model is']","['morphological ( re ) inflection task has been studied mainly in last two sigmorphon shared tasks  #AUTHOR_TAG ( cotterell et al.,, 2017.', 'most of the morphological inflection models are variants of sequence to sequence models applied by  #TAUTHOR_TAG to morphological reinflection.', 'the input to the model is the source word prepended with relevant morphological tags, the output of the model is the target word for the inflection task.', 'for re - inflection task, the input includes the target tags as well.', ""the success of the system seems to depend highly on'training data enhancement '."", 'for different tracks ( with different restrictions on data used ) of the 2016 shared task, kann and schutze ( 2016 ) developed new techniques to increase the number of training instances.', 'the methods used mostly work well for re - inflection task, since the re - inflection task is symmetric, and one can invert the source and target forms.', ""in the subsequent year's shared task for 2017  #AUTHOR_TAG, multiple authors explored new data enhancement techniques  #AUTHOR_TAG to improve the performance of the seq2seq models in medium and low resource scenarios."", 'the work presented in this paper is based on the work of the simple encoder - decoder system of  #TAUTHOR_TAG']",5
"['by  #TAUTHOR_TAG to morphological reinflection.', 'the']","['by  #TAUTHOR_TAG to morphological reinflection.', 'the']","['by  #TAUTHOR_TAG to morphological reinflection.', 'the input to the model is']","['morphological ( re ) inflection task has been studied mainly in last two sigmorphon shared tasks  #AUTHOR_TAG ( cotterell et al.,, 2017.', 'most of the morphological inflection models are variants of sequence to sequence models applied by  #TAUTHOR_TAG to morphological reinflection.', 'the input to the model is the source word prepended with relevant morphological tags, the output of the model is the target word for the inflection task.', 'for re - inflection task, the input includes the target tags as well.', ""the success of the system seems to depend highly on'training data enhancement '."", 'for different tracks ( with different restrictions on data used ) of the 2016 shared task, kann and schutze ( 2016 ) developed new techniques to increase the number of training instances.', 'the methods used mostly work well for re - inflection task, since the re - inflection task is symmetric, and one can invert the source and target forms.', ""in the subsequent year's shared task for 2017  #AUTHOR_TAG, multiple authors explored new data enhancement techniques  #AUTHOR_TAG to improve the performance of the seq2seq models in medium and low resource scenarios."", 'the work presented in this paper is based on the work of the simple encoder - decoder system of  #TAUTHOR_TAG']",0
"['irony detection  #TAUTHOR_TAG. the problem of emoji prediction, albeit recent, has already seen important developments. for']","['##y detection  #TAUTHOR_TAG. the problem of emoji prediction, albeit recent, has already seen important developments. for']","['irony detection  #TAUTHOR_TAG. the problem of emoji prediction, albeit recent, has already seen important developments. for example,  #AUTHOR_TAG describe an']","['sharing pictures online. it has furthermore proven to be useful for sentiment analysis, emotion', 'recognition and irony detection  #TAUTHOR_TAG. the problem of emoji prediction, albeit recent, has already seen important developments. for example,  #AUTHOR_TAG describe an lstm model which outperforms a logistic regression baseline based on word', '']",0
"['deepmoji model  #TAUTHOR_TAG, which is based on two stacked']","['deepmoji model  #TAUTHOR_TAG, which is based on two stacked']","['base architecture is the deepmoji model  #TAUTHOR_TAG, which is based on two stacked word - based bi - directional lstm recurrent neural networks with skip connections between']","['base architecture is the deepmoji model  #TAUTHOR_TAG, which is based on two stacked word - based bi - directional lstm recurrent neural networks with skip connections between the first and the second lstm.', 'the model also includes an attention module to increase its sensitivity to individual words during prediction.', 'in general, attention mechanisms allow the model to focus on specific words of the input  #AUTHOR_TAG, instead of having to memorize all the important features in a fixed - length vector.', 'the main architectural difference with respect to the typical attention is illustrated in figure 1.', 'in  #TAUTHOR_TAG, attention is computed as follows :', 'here h i ∈ r d is the hidden representation of the lstm corresponding to the i th word, with n the total number of words in the sentence.', 'the weight vector w a ∈ r d and bias term b a ∈ r map this hidden representation to a value that reflects the importance of this state for the considered classification problem.', 'the values z 1,..., z n are then normalized using a softmax function, yielding the attention weights α i.', 'the sentence representation s is defined as a weighted average of the vectors h i.', 'the final prediction distribution is then defined as follows :', 'where w f, l ∈ r d and b f, l define a label - specific linear transformation, with β l reflecting our confidence in the l th label and l is the total number of labels.', 'the confidence scores β l are then normalized to probabilities using another softmax operation.', 'however, while the above design has contributed to better emoji prediction, in our case we are interested in understanding the contribution of the words of a sentence for each label ( i. e., emoji ), and not in the whole distribution of the target labels.', 'to this end, we propose a label - wise attention mechanism.', 'specifically, we apply the same type of attention, but repeating it | l | ( number of labels ) times, where each attention module is reserved for a specific label l']",0
"['irony detection  #TAUTHOR_TAG. the problem of emoji prediction, albeit recent, has already seen important developments. for']","['##y detection  #TAUTHOR_TAG. the problem of emoji prediction, albeit recent, has already seen important developments. for']","['irony detection  #TAUTHOR_TAG. the problem of emoji prediction, albeit recent, has already seen important developments. for example,  #AUTHOR_TAG describe an']","['sharing pictures online. it has furthermore proven to be useful for sentiment analysis, emotion', 'recognition and irony detection  #TAUTHOR_TAG. the problem of emoji prediction, albeit recent, has already seen important developments. for example,  #AUTHOR_TAG describe an lstm model which outperforms a logistic regression baseline based on word', '']",4
"['deepmoji model  #TAUTHOR_TAG, which is based on two stacked']","['deepmoji model  #TAUTHOR_TAG, which is based on two stacked']","['base architecture is the deepmoji model  #TAUTHOR_TAG, which is based on two stacked word - based bi - directional lstm recurrent neural networks with skip connections between']","['base architecture is the deepmoji model  #TAUTHOR_TAG, which is based on two stacked word - based bi - directional lstm recurrent neural networks with skip connections between the first and the second lstm.', 'the model also includes an attention module to increase its sensitivity to individual words during prediction.', 'in general, attention mechanisms allow the model to focus on specific words of the input  #AUTHOR_TAG, instead of having to memorize all the important features in a fixed - length vector.', 'the main architectural difference with respect to the typical attention is illustrated in figure 1.', 'in  #TAUTHOR_TAG, attention is computed as follows :', 'here h i ∈ r d is the hidden representation of the lstm corresponding to the i th word, with n the total number of words in the sentence.', 'the weight vector w a ∈ r d and bias term b a ∈ r map this hidden representation to a value that reflects the importance of this state for the considered classification problem.', 'the values z 1,..., z n are then normalized using a softmax function, yielding the attention weights α i.', 'the sentence representation s is defined as a weighted average of the vectors h i.', 'the final prediction distribution is then defined as follows :', 'where w f, l ∈ r d and b f, l define a label - specific linear transformation, with β l reflecting our confidence in the l th label and l is the total number of labels.', 'the confidence scores β l are then normalized to probabilities using another softmax operation.', 'however, while the above design has contributed to better emoji prediction, in our case we are interested in understanding the contribution of the words of a sentence for each label ( i. e., emoji ), and not in the whole distribution of the target labels.', 'to this end, we propose a label - wise attention mechanism.', 'specifically, we apply the same type of attention, but repeating it | l | ( number of labels ) times, where each attention module is reserved for a specific label l']",5
"['deepmoji model  #TAUTHOR_TAG, which is based on two stacked']","['deepmoji model  #TAUTHOR_TAG, which is based on two stacked']","['base architecture is the deepmoji model  #TAUTHOR_TAG, which is based on two stacked word - based bi - directional lstm recurrent neural networks with skip connections between']","['base architecture is the deepmoji model  #TAUTHOR_TAG, which is based on two stacked word - based bi - directional lstm recurrent neural networks with skip connections between the first and the second lstm.', 'the model also includes an attention module to increase its sensitivity to individual words during prediction.', 'in general, attention mechanisms allow the model to focus on specific words of the input  #AUTHOR_TAG, instead of having to memorize all the important features in a fixed - length vector.', 'the main architectural difference with respect to the typical attention is illustrated in figure 1.', 'in  #TAUTHOR_TAG, attention is computed as follows :', 'here h i ∈ r d is the hidden representation of the lstm corresponding to the i th word, with n the total number of words in the sentence.', 'the weight vector w a ∈ r d and bias term b a ∈ r map this hidden representation to a value that reflects the importance of this state for the considered classification problem.', 'the values z 1,..., z n are then normalized using a softmax function, yielding the attention weights α i.', 'the sentence representation s is defined as a weighted average of the vectors h i.', 'the final prediction distribution is then defined as follows :', 'where w f, l ∈ r d and b f, l define a label - specific linear transformation, with β l reflecting our confidence in the l th label and l is the total number of labels.', 'the confidence scores β l are then normalized to probabilities using another softmax operation.', 'however, while the above design has contributed to better emoji prediction, in our case we are interested in understanding the contribution of the words of a sentence for each label ( i. e., emoji ), and not in the whole distribution of the target labels.', 'to this end, we propose a label - wise attention mechanism.', 'specifically, we apply the same type of attention, but repeating it | l | ( number of labels ) times, where each attention module is reserved for a specific label l']",5
"['baselines : ( 1  #TAUTHOR_TAG.', '']","['baselines : ( 1  #TAUTHOR_TAG.', 'finally, we']","['baselines : ( 1  #TAUTHOR_TAG.', '']","['section describes the main experiment w. r. t the performance of our proposed attention mechanism, in comparison with existing emoji prediction systems.', 'we use the data made available in the context of the semeval 2018 shared task on emoji prediction  #AUTHOR_TAG.', 'given a tweet, the task consists of predicting an associated emoji from a predefined set of 20 emoji labels.', 'we evaluate our model on the english split of the official task dataset.', 'we also show results from additional experiments in which the label space ranged from 20 to 200 emojis.', 'these extended experiments are performed on a corpus of around 100m tweets geolocalized in the united states and posted between october 2015 and may 2018.', 'models.', 'in order to put our proposed labelwise attention mechanism in context, we compare its performance with a set of baselines : ( 1  #TAUTHOR_TAG.', 'finally, we denote as 2 - bilstms l our proposed label - wise attentive bi - lstm architecture.', 'results.', 'table 1 shows the results of our model and the baselines in the emoji prediction task for the different evaluation splits.', 'the evaluation metrics used are : f1, accuracy @ k ( a @ k, where k ∈ { 1, 5 } ), and coverage error ( ce 1 )  #AUTHOR_TAG.', 'we note that the latter metric is not normally used in emoji prediction settings.', 'however, with many emojis being "" near synonyms "" ( in the sense of being often used almost interchangeably ), it seems natural to evaluate the performance of an emoji prediction system in terms of how far we would need to go through the predicted emojis to recover the true label.', 'the results show that our proposed 2 - bilstms l method outperforms all baselines for f1 in three out of four settings, and for ce in all of them.', 'in the following section we shed light on the reasons behind this performance, and we try to understand how these predictions were made']",5
['linear segmentation  #TAUTHOR_TAG or hierarchical segmentation  #AUTHOR_TAG'],['linear segmentation  #TAUTHOR_TAG or hierarchical segmentation  #AUTHOR_TAG'],"['either linear segmentation  #TAUTHOR_TAG or hierarchical segmentation  #AUTHOR_TAG.', 'the essential idea behind the lexical cohesion approaches is that different topics will have']","['', 'there have been essentially two approaches to topic segmentation in the past.', 'the first of these, lexical cohesion, may be used for either linear segmentation  #TAUTHOR_TAG or hierarchical segmentation  #AUTHOR_TAG.', 'the essential idea behind the lexical cohesion approaches is that different topics will have different vocabularies.', 'therefore the lexical cohesion within topics will be higher than the lexical cohesion between topics, and gaps in cohesion may mark topic boundaries.', 'the second major approach to topic segmentation looks for distinctive textual or acoustic markers of topic boundaries, e. g. referential noun phrases or pauses  #AUTHOR_TAG.', 'by using multiple markers and machine learning methods, topic segmentation algorithms may be developed using this second approach that have a higher accuracy than methods using a single marker alone  #AUTHOR_TAG.', 'the primary technique used in previous studies, lexical cohesion, is no stranger to the educational nlp community.', '']",0
"['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on how text units are defined and on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', ""on how text units are defined and on how to interpret the results of a comparison. the text unit's definition in  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG is generally"", 'task dependent, depending on what size gives the best results. for example, when measuring comprehension', ', use the unit of the sentence, as opposed to the more standard unit of the proposition, because lsa', 'is most correlated with comprehension at that level. however, when using lsa to segment text,  #AUTHOR_TAG use the', 'paragraph as the unit, to "" smooth out "" the local changes in cohesion and become more sensitive to more global changes of cohesion', '. hearst likewise chooses a large unit, 6 token - sequences of 20 tokens  #AUTHOR_TAG, but varies these parameters dependent on the characteristics of the text to be segmented, e. g.', 'paragraph size. under a vector space model, comparisons are performed by calculating the cosine of vectors representing text. as stated previously, these comparisons reflect the cohesion between units of text. in order to use', 'these comparisons to segment text, however, one must have a criterion in place.  #AUTHOR_TAG, noting mean cosines of. 16 for boundaries and. 43 for non - boundaries, choose a threshold criterion', '']",0
"['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on how text units are defined and on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', ""on how text units are defined and on how to interpret the results of a comparison. the text unit's definition in  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG is generally"", 'task dependent, depending on what size gives the best results. for example, when measuring comprehension', ', use the unit of the sentence, as opposed to the more standard unit of the proposition, because lsa', 'is most correlated with comprehension at that level. however, when using lsa to segment text,  #AUTHOR_TAG use the', 'paragraph as the unit, to "" smooth out "" the local changes in cohesion and become more sensitive to more global changes of cohesion', '. hearst likewise chooses a large unit, 6 token - sequences of 20 tokens  #AUTHOR_TAG, but varies these parameters dependent on the characteristics of the text to be segmented, e. g.', 'paragraph size. under a vector space model, comparisons are performed by calculating the cosine of vectors representing text. as stated previously, these comparisons reflect the cohesion between units of text. in order to use', 'these comparisons to segment text, however, one must have a criterion in place.  #AUTHOR_TAG, noting mean cosines of. 16 for boundaries and. 43 for non - boundaries, choose a threshold criterion', '']",0
"['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on how text units are defined and on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', ""on how text units are defined and on how to interpret the results of a comparison. the text unit's definition in  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG is generally"", 'task dependent, depending on what size gives the best results. for example, when measuring comprehension', ', use the unit of the sentence, as opposed to the more standard unit of the proposition, because lsa', 'is most correlated with comprehension at that level. however, when using lsa to segment text,  #AUTHOR_TAG use the', 'paragraph as the unit, to "" smooth out "" the local changes in cohesion and become more sensitive to more global changes of cohesion', '. hearst likewise chooses a large unit, 6 token - sequences of 20 tokens  #AUTHOR_TAG, but varies these parameters dependent on the characteristics of the text to be segmented, e. g.', 'paragraph size. under a vector space model, comparisons are performed by calculating the cosine of vectors representing text. as stated previously, these comparisons reflect the cohesion between units of text. in order to use', 'these comparisons to segment text, however, one must have a criterion in place.  #AUTHOR_TAG, noting mean cosines of. 16 for boundaries and. 43 for non - boundaries, choose a threshold criterion', '']",0
"['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on how text units are defined and on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', ""on how text units are defined and on how to interpret the results of a comparison. the text unit's definition in  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG is generally"", 'task dependent, depending on what size gives the best results. for example, when measuring comprehension', ', use the unit of the sentence, as opposed to the more standard unit of the proposition, because lsa', 'is most correlated with comprehension at that level. however, when using lsa to segment text,  #AUTHOR_TAG use the', 'paragraph as the unit, to "" smooth out "" the local changes in cohesion and become more sensitive to more global changes of cohesion', '. hearst likewise chooses a large unit, 6 token - sequences of 20 tokens  #AUTHOR_TAG, but varies these parameters dependent on the characteristics of the text to be segmented, e. g.', 'paragraph size. under a vector space model, comparisons are performed by calculating the cosine of vectors representing text. as stated previously, these comparisons reflect the cohesion between units of text. in order to use', 'these comparisons to segment text, however, one must have a criterion in place.  #AUTHOR_TAG, noting mean cosines of. 16 for boundaries and. 43 for non - boundaries, choose a threshold criterion', '']",0
"['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on how text units are defined and on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', ""on how text units are defined and on how to interpret the results of a comparison. the text unit's definition in  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG is generally"", 'task dependent, depending on what size gives the best results. for example, when measuring comprehension', ', use the unit of the sentence, as opposed to the more standard unit of the proposition, because lsa', 'is most correlated with comprehension at that level. however, when using lsa to segment text,  #AUTHOR_TAG use the', 'paragraph as the unit, to "" smooth out "" the local changes in cohesion and become more sensitive to more global changes of cohesion', '. hearst likewise chooses a large unit, 6 token - sequences of 20 tokens  #AUTHOR_TAG, but varies these parameters dependent on the characteristics of the text to be segmented, e. g.', 'paragraph size. under a vector space model, comparisons are performed by calculating the cosine of vectors representing text. as stated previously, these comparisons reflect the cohesion between units of text. in order to use', 'these comparisons to segment text, however, one must have a criterion in place.  #AUTHOR_TAG, noting mean cosines of. 16 for boundaries and. 43 for non - boundaries, choose a threshold criterion', '']",0
"['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on how text units are defined and on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', ""on how text units are defined and on how to interpret the results of a comparison. the text unit's definition in  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG is generally"", 'task dependent, depending on what size gives the best results. for example, when measuring comprehension', ', use the unit of the sentence, as opposed to the more standard unit of the proposition, because lsa', 'is most correlated with comprehension at that level. however, when using lsa to segment text,  #AUTHOR_TAG use the', 'paragraph as the unit, to "" smooth out "" the local changes in cohesion and become more sensitive to more global changes of cohesion', '. hearst likewise chooses a large unit, 6 token - sequences of 20 tokens  #AUTHOR_TAG, but varies these parameters dependent on the characteristics of the text to be segmented, e. g.', 'paragraph size. under a vector space model, comparisons are performed by calculating the cosine of vectors representing text. as stated previously, these comparisons reflect the cohesion between units of text. in order to use', 'these comparisons to segment text, however, one must have a criterion in place.  #AUTHOR_TAG, noting mean cosines of. 16 for boundaries and. 43 for non - boundaries, choose a threshold criterion', '']",0
"['. recall that', 'in monologue,  #TAUTHOR_TAG reports']","['+ lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports a much']","['+ lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports']","['expectation has been put to the test recently by  #AUTHOR_TAG, who find that an orthonormal basis can significantly predict entailment on test data', 'supplied by the pascal textual entailment challenge ( pascal, 2004 ).', 'beyond relative performance rankings, more support for the above reasoning can be found in the difference between hearst and hearst + lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports a much larger f - measure than  #AUTHOR_TAG,. 70 vs.. 33,', 'albeit on different data sets. in the present dialogue corpus, these roles are reversed,. 14 vs.. 52.', 'possible reasons for this reversal are the segmentation criterion, the vector space method, or the fact that foltz has been trained on similar data via regression and hearst has not. however,', 'comparing the hearst algorithm with the hearst + ls', '##a algorithm indicates that a 57 % improvement stems from the addition of lsa, keeping all other factors constant. while this result is not statistically significant, the direction of', '']",0
"['. recall that', 'in monologue,  #TAUTHOR_TAG reports']","['+ lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports a much']","['+ lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports']","['expectation has been put to the test recently by  #AUTHOR_TAG, who find that an orthonormal basis can significantly predict entailment on test data', 'supplied by the pascal textual entailment challenge ( pascal, 2004 ).', 'beyond relative performance rankings, more support for the above reasoning can be found in the difference between hearst and hearst + lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports a much larger f - measure than  #AUTHOR_TAG,. 70 vs.. 33,', 'albeit on different data sets. in the present dialogue corpus, these roles are reversed,. 14 vs.. 52.', 'possible reasons for this reversal are the segmentation criterion, the vector space method, or the fact that foltz has been trained on similar data via regression and hearst has not. however,', 'comparing the hearst algorithm with the hearst + ls', '##a algorithm indicates that a 57 % improvement stems from the addition of lsa, keeping all other factors constant. while this result is not statistically significant, the direction of', '']",0
"['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', 'on how text units are defined and on']","['be characterized by a moving window, where successive overlapping comparisons are advanced by one unit of text.  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG differ', ""on how text units are defined and on how to interpret the results of a comparison. the text unit's definition in  #AUTHOR_TAG  #TAUTHOR_TAG and  #AUTHOR_TAG is generally"", 'task dependent, depending on what size gives the best results. for example, when measuring comprehension', ', use the unit of the sentence, as opposed to the more standard unit of the proposition, because lsa', 'is most correlated with comprehension at that level. however, when using lsa to segment text,  #AUTHOR_TAG use the', 'paragraph as the unit, to "" smooth out "" the local changes in cohesion and become more sensitive to more global changes of cohesion', '. hearst likewise chooses a large unit, 6 token - sequences of 20 tokens  #AUTHOR_TAG, but varies these parameters dependent on the characteristics of the text to be segmented, e. g.', 'paragraph size. under a vector space model, comparisons are performed by calculating the cosine of vectors representing text. as stated previously, these comparisons reflect the cohesion between units of text. in order to use', 'these comparisons to segment text, however, one must have a criterion in place.  #AUTHOR_TAG, noting mean cosines of. 16 for boundaries and. 43 for non - boundaries, choose a threshold criterion', '']",4
"['by  #TAUTHOR_TAG,. 70.', 'for dialogue, the algorithm is 20 % as effective as']","['by  #TAUTHOR_TAG,. 70.', 'for dialogue, the algorithm is 20 % as effective as']","['by  #TAUTHOR_TAG,. 70.', 'for dialogue, the algorithm is 20 % as effective as it is for monologue.', 'it is unclear, however,']","['jtexttile software was used to implement  #AUTHOR_TAG on dialogue.', 'as with  #AUTHOR_TAG, a text unit and window size had to be determined for dialogue.', ' #AUTHOR_TAG recommends using the average paragraph size as the window size.', ""using the development corpus's average topic length of 16 utterances as a reference point, f - measures were calculated for the combinations of window size and text unit size in table 1."", 'the optimal combination of parameters ( fmeasure =. 17 ) is a unit size of 16 words and a window size of 16 units.', ""this combination matches  #AUTHOR_TAG's heuristic of choosing the window size to be the average paragraph length."", 'on the test set, this combination of parameters yielded an f - measure of. 14 as opposed to the fmeasure for monologue reported by  #TAUTHOR_TAG,. 70.', 'for dialogue, the algorithm is 20 % as effective as it is for monologue.', 'it is unclear, however, exactly what part of the algorithm contributes to this poor performance.', 'the two most obvious possibilities are the segmentation criterion, i. e. depth scores, or the standard vector space method.', 'to further explore these possibilities, the hearst method was augmented with lsa.', 'again, the unit size and window size had to be calculated.', 'as with foltz, the unit size was taken to be the utterance.', 'the window size was determined by computing f - measures on the development corpus for all sizes between 1 and 16.', 'the optimal window size is 9, f - measure =. 22.', 'given the smaller number of test cases, 22, this f - measure of. 22 is not significantly different from. 17.', 'however, the foltz method is significantly higher than both of these, p <. 10']",4
"['. recall that', 'in monologue,  #TAUTHOR_TAG reports']","['+ lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports a much']","['+ lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports']","['expectation has been put to the test recently by  #AUTHOR_TAG, who find that an orthonormal basis can significantly predict entailment on test data', 'supplied by the pascal textual entailment challenge ( pascal, 2004 ).', 'beyond relative performance rankings, more support for the above reasoning can be found in the difference between hearst and hearst + lsa. recall that', 'in monologue,  #TAUTHOR_TAG reports a much larger f - measure than  #AUTHOR_TAG,. 70 vs.. 33,', 'albeit on different data sets. in the present dialogue corpus, these roles are reversed,. 14 vs.. 52.', 'possible reasons for this reversal are the segmentation criterion, the vector space method, or the fact that foltz has been trained on similar data via regression and hearst has not. however,', 'comparing the hearst algorithm with the hearst + ls', '##a algorithm indicates that a 57 % improvement stems from the addition of lsa, keeping all other factors constant. while this result is not statistically significant, the direction of', '']",4
"['of users  #TAUTHOR_TAG or dialectology  #AUTHOR_TAG.', 'in these methods, a user is often represented by the concatenation of their tweets, and the geolocation model is trained on a very small percentage of explicitly']","['geolocation of users  #TAUTHOR_TAG or dialectology  #AUTHOR_TAG.', 'in these methods, a user is often represented by the concatenation of their tweets, and the geolocation model is trained on a very small percentage of explicitly geotagged tweets, noting the potential biases implicit in geotagged tweets  #AUTHOR_TAG.', 'lexical dialectology is ( in part )']","['of users  #TAUTHOR_TAG or dialectology  #AUTHOR_TAG.', 'in these methods, a user is often represented by the concatenation of their tweets, and the geolocation model is trained on a very small percentage of explicitly']","['', 'explicit user geolocation metadata ( e. g. gps tags, wifi footprint, ip address ) is not usually available to third - party consumers, giving rise to the need for geolocation based on profile data, text content, friendship graphs  #AUTHOR_TAG or some combination of these  #AUTHOR_TAG b, a ).', 'the strong geographical bias, most obviously at the language level ( e. g. finland vs. japan ), and more subtly at the dialect level ( e. g. in english used in north - west england vs. north - east usa vs. texas, usa ), clearly reflected in language use in social media services such as twitter, has been used extensively either for geolocation of users  #TAUTHOR_TAG or dialectology  #AUTHOR_TAG.', 'in these methods, a user is often represented by the concatenation of their tweets, and the geolocation model is trained on a very small percentage of explicitly geotagged tweets, noting the potential biases implicit in geotagged tweets  #AUTHOR_TAG.', 'lexical dialectology is ( in part ) the converse of user geolocation  #AUTHOR_TAG : given text associated with a variety of regions, the task is to identify terms that are distinctive of particular regions.', 'the complexity of the task is two - fold : ( 1 ) localised named entities ( e. g. sporting team names ) are not of interest ; and ( 2 ) without semantic knowledge it is difficult to detect terms that are in general use but have a special meaning in a region.', 'in this paper we propose a text - based geolocation method based on neural networks.', ""our contributions are as follows : ( 1 ) we achieve state - of - the - art results on benchmark twitter geolocation datasets ; ( 2 ) we show that the model is less sensitive to the specific location discretisation method ; ( 3 ) we release the first broad - coverage dataset for evaluation of lexical dialectology models ; ( 4 ) we incorporate our text - based model into a network - based model  #AUTHOR_TAG a ) and improve the performance utilising both network and text ; and ( 5 ) we use the model's embeddings for extraction of local terms and show that it outperforms two baselines""]",0
"['##ers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #TAUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG,']","['of gazetteers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #TAUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG,']","['##ers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #TAUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG,']","['work on twitter user geolocation falls into two categories : text - based and network - based methods.', 'text - based methods make use of the geographical biases of language use, and networkbased methods rely on the geospatial homophily of user - user interactions.', 'in both cases, the assumption is that users who live in the same geographic area share similar features ( linguistic or interactional ).', 'three main text - based approaches are : ( 1 ) the use of gazetteers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #TAUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG, which unlike gazetteers can be applied to informal text and compared to topic models, scales better.', 'the classification models often rely on less than 1 % of geotagged tweets for supervision and discretise real - valued coordinates into equalsized grids  #AUTHOR_TAG, administrative regions  #AUTHOR_TAG or flat  #AUTHOR_TAG or hierarchical k - d tree clusters  #AUTHOR_TAG.', 'network - based methods also use either real - valued coordinates  #AUTHOR_TAG or discretised regions  #AUTHOR_TAG a ) as labels, and use label propagation over the interaction graph ( e. g. @ - mentions ).', 'more recent methods have focused on representation learning by using sparse coding  #AUTHOR_TAG or neural networks  #AUTHOR_TAG, utilising both text and network information  #AUTHOR_TAG a ).', 'dialect is a variety of language shared by a group of speakers  #AUTHOR_TAG.', 'our focus here is on geographical dialects which are spoken ( and written in social media ) by people from particular areas.', 'the traditional approach to dialectology is to find the geographical distribution of known lexical alternatives ( e. g. you, yall and yinz :  #AUTHOR_TAG goncalves and sanchez, 2014 ;  #AUTHOR_TAG ), the shortcoming of which is that the alternative lexical variables must be known beforehand.', 'there have also been attempts to automatically identify such words from geotagged documents  #TAUTHOR_TAG.', 'the main idea is to find lexical variables that are disproportionately distributed in different locations either via model - based or statistical methods  #AUTHOR_TAG.', 'there is a research gap in evaluating the geolocation models in terms of their usability in retrieving dialect terms given a geographic region.', 'we use a text - based neural approach trained on geotagged twitter messages that : ( a ) given a geographical region, identifies the associated lexical terms ; and ( b ) given a text, predicts its location']",0
"['##ers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #TAUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG,']","['of gazetteers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #TAUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG,']","['##ers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #TAUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG,']","['work on twitter user geolocation falls into two categories : text - based and network - based methods.', 'text - based methods make use of the geographical biases of language use, and networkbased methods rely on the geospatial homophily of user - user interactions.', 'in both cases, the assumption is that users who live in the same geographic area share similar features ( linguistic or interactional ).', 'three main text - based approaches are : ( 1 ) the use of gazetteers  #AUTHOR_TAG ; ( 2 ) unsupervised text clustering based on topic models or similar  #TAUTHOR_TAG ; and ( 3 ) supervised classification  #AUTHOR_TAG, which unlike gazetteers can be applied to informal text and compared to topic models, scales better.', 'the classification models often rely on less than 1 % of geotagged tweets for supervision and discretise real - valued coordinates into equalsized grids  #AUTHOR_TAG, administrative regions  #AUTHOR_TAG or flat  #AUTHOR_TAG or hierarchical k - d tree clusters  #AUTHOR_TAG.', 'network - based methods also use either real - valued coordinates  #AUTHOR_TAG or discretised regions  #AUTHOR_TAG a ) as labels, and use label propagation over the interaction graph ( e. g. @ - mentions ).', 'more recent methods have focused on representation learning by using sparse coding  #AUTHOR_TAG or neural networks  #AUTHOR_TAG, utilising both text and network information  #AUTHOR_TAG a ).', 'dialect is a variety of language shared by a group of speakers  #AUTHOR_TAG.', 'our focus here is on geographical dialects which are spoken ( and written in social media ) by people from particular areas.', 'the traditional approach to dialectology is to find the geographical distribution of known lexical alternatives ( e. g. you, yall and yinz :  #AUTHOR_TAG goncalves and sanchez, 2014 ;  #AUTHOR_TAG ), the shortcoming of which is that the alternative lexical variables must be known beforehand.', 'there have also been attempts to automatically identify such words from geotagged documents  #TAUTHOR_TAG.', 'the main idea is to find lexical variables that are disproportionately distributed in different locations either via model - based or statistical methods  #AUTHOR_TAG.', 'there is a research gap in evaluating the geolocation models in terms of their usability in retrieving dialect terms given a geographic region.', 'we use a text - based neural approach trained on geotagged twitter messages that : ( a ) given a geographical region, identifies the associated lexical terms ; and ( b ) given a text, predicts its location']",0
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['use three existing twitter user geolocation datasets : ( 1 ) geotext  #TAUTHOR_TAG, ( 2 ) twitter - us  #AUTHOR_TAG, and ( 3 ) twitter - world  #AUTHOR_TAG.', 'these datasets have been used widely for training and evaluation of geolocation models.', 'they are all prepartitioned into training, development and test sets.', 'each user is represented by the concatenation of their tweets, and labeled with the latitude / longitude of the first collected geotagged tweet in the case of geotext and twitter - us, and the centre of the closest city in the case of twitter - world.', '1 geotext and twitter - us cover the continental us, and twitter - world covers the whole world, with 9k, 449k and 1. 3m users, respectively as shown in figure 1.', '2 dareds is a dialect - term dataset novel to this research, created from the dictionary of american regional english ( dare )  #AUTHOR_TAG.', 'dare consists of dialect regions, their terms and meaning.', '3 it is based on dialectal surveys from different regions of the u. s., which are then postprocessed to identify dialect regions and terms.', 'in order to construct a dataset based on dare, we downloaded the web version of dare, cleaned it, and removed multiword expressions and highly - frequent words ( any word which occurred in the top 50k most frequent words, based on a word frequency list  #AUTHOR_TAG.', ""for dialect regions that don't correspond to a single state or set of cities ( e. g. south ), we mapped it to the most populous cities within each region."", 'for example, within the pacific northwest dialect region, we manually extracted the most populous cities ( seattle, tacoma, portland, salem, eugene ) and added those cities to dareds as subregions.', 'the resulting dataset ( dareds ) consists of around 4. 3k dialect terms from 99 u. s. dialect regions.', 'dareds is the largest standardised dialectology dataset']",5
"['optimised using adamx  #AUTHOR_TAG using lasagne / theano  #AUTHOR_TAG.', ' #AUTHOR_TAG and  #TAUTHOR_TAG,']","['optimised using adamx  #AUTHOR_TAG using lasagne / theano  #AUTHOR_TAG.', ' #AUTHOR_TAG and  #TAUTHOR_TAG,']","['- world, respectively.', 'the parameters are optimised using adamx  #AUTHOR_TAG using lasagne / theano  #AUTHOR_TAG.', ' #AUTHOR_TAG and  #TAUTHOR_TAG, we evaluated']",[' #TAUTHOR_TAG'],5
['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ('],"['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ( yi−1, yi, oi ) = exp ( wy i−1, y i', 'oi + ay i−1, y i ) as the potential']",['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ('],"['we briefly review their blstm - cnn - crf model. let w t be the t - th word in an input sentence and c t =', 'c ( 1 ) t,..., c ( k ) t be the character', 'sequence of w t. blstm - cnn - crf uses both word - level embedding w t ∈ r d word', 'and character - level embedding c t ∈ r d char. given a word sequence x = w 1,..., w n, the model outputs a score vector o t as follows. where cnn char is', 'the character - level cnn function, ⊕ is the concatenation of two vectors', ', lstm f is the forward lstm function, lstm b is the backward lstm function, bi - lstm is the bi - lstm function, respectively. then, w t g ∈ r | t | ×d hidden is the weight matrix to learn, b t g ∈ r | t | is the bias vector', 'to learn, | t | is the size of tag set t, d hidden is the size of hidden layer of bi - lstm, and o t ∈ r | t |', 'is the score vector in which each element is the probability of a possible tag. in blstm - cnn - crf,', 'crf is applied to the output layer. the conditional probability of crf is defined as follows : i is the j - th element of the vector o i. then, a ∈ r | t | × | t | is a transition score matrix, a y i−1, y i is a transition 1 while  #TAUTHOR_TAG define [UNK] ( yi−1, yi, oi ) = exp ( wy i−1, y i', 'oi + ay i−1, y i ) as the potential function where w is the weight vector', 'corresponding to label pair ( yi−1, yi ), we use the simple potential function here. score for jumping from tag y i−1 to y i, and y indicates all', 'possible paths. at test time, the predicted sequence is obtained by finding the highest score in a all possible paths using vit', '##erbi algorithm as follows : 3 segment - level neural crf in this', 'section, we describe our proposed method. our segment - level neural crf consists of the following two steps : ( i ) a segment lattice is constructed from a sequence of words by pruning unlikely bio tags to', 'reduce a search space. this is because it is difficult to consider all possible variable length segments in practice. ( ii ) we use a linear chain crf', 'to find the highest score path on the segment lattice']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG, we use bioes tagging scheme in the wordlevel tagging']","['evaluate our method on two segment - level sequence tagging tasks : ner and text chunking 3.', 'for ner, we use conll 2003 english ner shared task  #AUTHOR_TAG.', 'following previous work  #TAUTHOR_TAG, we use bioes tagging scheme in the wordlevel tagging model.', 'for text chunking, we use the conll 2000 english text chunking shared task  #AUTHOR_TAG.', 'following previous work ( søgaard and  #AUTHOR_TAG, the section 19 of wsj corpus is used as the development set.', 'we use bioes tagging scheme in the word - level tagging model and measure performance using f1 score in all experiments']",5
['hyper - parameters used in  #TAUTHOR_TAG'],['hyper - parameters used in  #TAUTHOR_TAG'],"['- level blstm - cnn with the same hyper - parameters used in  #TAUTHOR_TAG level cnn, and 100 dimentional pre - trained word embedding of glove  #AUTHOR_TAG.', '']","['generate a segment lattice, we train word - level blstm - cnn with the same hyper - parameters used in  #TAUTHOR_TAG level cnn, and 100 dimentional pre - trained word embedding of glove  #AUTHOR_TAG.', '']",5
['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ('],"['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ( yi−1, yi, oi ) = exp ( wy i−1, y i', 'oi + ay i−1, y i ) as the potential']",['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ('],"['we briefly review their blstm - cnn - crf model. let w t be the t - th word in an input sentence and c t =', 'c ( 1 ) t,..., c ( k ) t be the character', 'sequence of w t. blstm - cnn - crf uses both word - level embedding w t ∈ r d word', 'and character - level embedding c t ∈ r d char. given a word sequence x = w 1,..., w n, the model outputs a score vector o t as follows. where cnn char is', 'the character - level cnn function, ⊕ is the concatenation of two vectors', ', lstm f is the forward lstm function, lstm b is the backward lstm function, bi - lstm is the bi - lstm function, respectively. then, w t g ∈ r | t | ×d hidden is the weight matrix to learn, b t g ∈ r | t | is the bias vector', 'to learn, | t | is the size of tag set t, d hidden is the size of hidden layer of bi - lstm, and o t ∈ r | t |', 'is the score vector in which each element is the probability of a possible tag. in blstm - cnn - crf,', 'crf is applied to the output layer. the conditional probability of crf is defined as follows : i is the j - th element of the vector o i. then, a ∈ r | t | × | t | is a transition score matrix, a y i−1, y i is a transition 1 while  #TAUTHOR_TAG define [UNK] ( yi−1, yi, oi ) = exp ( wy i−1, y i', 'oi + ay i−1, y i ) as the potential function where w is the weight vector', 'corresponding to label pair ( yi−1, yi ), we use the simple potential function here. score for jumping from tag y i−1 to y i, and y indicates all', 'possible paths. at test time, the predicted sequence is obtained by finding the highest score in a all possible paths using vit', '##erbi algorithm as follows : 3 segment - level neural crf in this', 'section, we describe our proposed method. our segment - level neural crf consists of the following two steps : ( i ) a segment lattice is constructed from a sequence of words by pruning unlikely bio tags to', 'reduce a search space. this is because it is difficult to consider all possible variable length segments in practice. ( ii ) we use a linear chain crf', 'to find the highest score path on the segment lattice']",1
['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ('],"['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ( yi−1, yi, oi ) = exp ( wy i−1, y i', 'oi + ay i−1, y i ) as the potential']",['i is a transition 1 while  #TAUTHOR_TAG define [UNK] ('],"['we briefly review their blstm - cnn - crf model. let w t be the t - th word in an input sentence and c t =', 'c ( 1 ) t,..., c ( k ) t be the character', 'sequence of w t. blstm - cnn - crf uses both word - level embedding w t ∈ r d word', 'and character - level embedding c t ∈ r d char. given a word sequence x = w 1,..., w n, the model outputs a score vector o t as follows. where cnn char is', 'the character - level cnn function, ⊕ is the concatenation of two vectors', ', lstm f is the forward lstm function, lstm b is the backward lstm function, bi - lstm is the bi - lstm function, respectively. then, w t g ∈ r | t | ×d hidden is the weight matrix to learn, b t g ∈ r | t | is the bias vector', 'to learn, | t | is the size of tag set t, d hidden is the size of hidden layer of bi - lstm, and o t ∈ r | t |', 'is the score vector in which each element is the probability of a possible tag. in blstm - cnn - crf,', 'crf is applied to the output layer. the conditional probability of crf is defined as follows : i is the j - th element of the vector o i. then, a ∈ r | t | × | t | is a transition score matrix, a y i−1, y i is a transition 1 while  #TAUTHOR_TAG define [UNK] ( yi−1, yi, oi ) = exp ( wy i−1, y i', 'oi + ay i−1, y i ) as the potential function where w is the weight vector', 'corresponding to label pair ( yi−1, yi ), we use the simple potential function here. score for jumping from tag y i−1 to y i, and y indicates all', 'possible paths. at test time, the predicted sequence is obtained by finding the highest score in a all possible paths using vit', '##erbi algorithm as follows : 3 segment - level neural crf in this', 'section, we describe our proposed method. our segment - level neural crf consists of the following two steps : ( i ) a segment lattice is constructed from a sequence of words by pruning unlikely bio tags to', 'reduce a search space. this is because it is difficult to consider all possible variable length segments in practice. ( ii ) we use a linear chain crf', 'to find the highest score path on the segment lattice']",4
"['in  #TAUTHOR_TAG, we observe that the crf has no significant effect on the final performance for the lattice construction.', 'therefore, we use blstm - cnn ( without crf ) as the word - level tagging model in this paper']","['in  #TAUTHOR_TAG, we observe that the crf has no significant effect on the final performance for the lattice construction.', 'therefore, we use blstm - cnn ( without crf ) as the word - level tagging model in this paper']","['the state - ofthe - art performance in  #TAUTHOR_TAG, we observe that the crf has no significant effect on the final performance for the lattice construction.', 'therefore, we use blstm - cnn ( without crf ) as the word - level tagging model in this paper']","['', 'then, we generate the candidate bio tags whose scores are greater than the threshold t.', 'after that, we construct the segment lattice by generating admissible segments from the candidate bio tags.', 'for example, we generate the person segment from the candidate bio tags { b - per, i - per, e - per }. the threshold t is a hyper - parameter for our model.', 'we describe how to choose the threshold t in section 4. 3.', 'while it has been shown that the crf layer is required to achieve the state - ofthe - art performance in  #TAUTHOR_TAG, we observe that the crf has no significant effect on the final performance for the lattice construction.', 'therefore, we use blstm - cnn ( without crf ) as the word - level tagging model in this paper']",4
['hyper - parameters used in  #TAUTHOR_TAG'],['hyper - parameters used in  #TAUTHOR_TAG'],"['- level blstm - cnn with the same hyper - parameters used in  #TAUTHOR_TAG level cnn, and 100 dimentional pre - trained word embedding of glove  #AUTHOR_TAG.', '']","['generate a segment lattice, we train word - level blstm - cnn with the same hyper - parameters used in  #TAUTHOR_TAG level cnn, and 100 dimentional pre - trained word embedding of glove  #AUTHOR_TAG.', '']",3
"['. 72 to 90. 96.', 'this result is consistent with the result of  #TAUTHOR_TAG in both experiments,']","['f1 score from 89. 72 to 90. 96.', 'this result is consistent with the result of  #TAUTHOR_TAG in both experiments,']","['. 72 to 90. 96.', 'this result is consistent with the result of  #TAUTHOR_TAG in both experiments,']","['results of conll 2003 ner is shown in table 2.', 'by adding a crf layer to blstm - cnn, it improves the f1 score from 89. 72 to 90. 96.', 'this result is consistent with the result of  #TAUTHOR_TAG in both experiments, it improves the f1 score by using segment - level crf.', 'on the ner experiment, the additional dictionary features help to obtain further improvement']",3
"['16,  #TAUTHOR_TAG 18 ]']","['have aligned objectives [ 16,  #TAUTHOR_TAG 18 ]']","['16,  #TAUTHOR_TAG 18 ].', 'learning features']",[' #TAUTHOR_TAG'],0
"['of domain invariance than traditional acoustic features [ 16, 7,  #TAUTHOR_TAG.', 'another']","['of domain invariance than traditional acoustic features [ 16, 7,  #TAUTHOR_TAG.', 'another']","['acoustic features with a greater degree of domain invariance than traditional acoustic features [ 16, 7,  #TAUTHOR_TAG.', 'another line of']","['learning has a long history in the field of machine learning [ 19 ].', 'more recently, deep neural network models have been shown to be extremely effective for learning representations of data with a high degree of re - usability across many different tasks and domains.', 'perhaps the most well - known example of this is the use of the imagenet [ 30 ] image classification database to pre - train convolutional neural network models for other downstream computer vision tasks [ 31, 32, 33 ].', 'other sub - fields have also developed similarly techniques.', 'for example, in natural language processing, dense word vector models such as word2vec [ 34 ] and glove [ 35 ], or more advanced ones like elmo [ 36 ] and bert [ 37 ] have quickly replaced one - hot word representations in many tasks and pushed the state - of - theart forward on a variety of language understanding tasks.', 'more recently, there is also an increasing interest in learning from multimodal data [ 38 ] and transfer learned representations from such tasks [ 39 ] in the field of speech recognition, low - resource speech recognition is a scenario which heavily benefits from transfer learning, for example in the form of training on multilingual datasets [ 40 ].', 'other models capable of disentangling phonetic and domain information have recently been shown to learn acoustic features with a greater degree of domain invariance than traditional acoustic features [ 16, 7,  #TAUTHOR_TAG.', 'another line of work has studied the use of the visual modality as a form of weak supervision using semantic information for acoustic modeling [ 20, 41, 42 ], followed up with analysis on representations learned from such models [ 27, 43, 25 ].', 'in this paper, we build upon this prior work and quantify the degree to which these representations can be used to build robust asr']",0
['extracting domain invariant asr features  #TAUTHOR_TAG'],['extracting domain invariant asr features  #TAUTHOR_TAG. while'],"['learns to encode sequence - level and segment - level information into separate latent variables', 'without supervision by optimizing an evidence lower bound derived from a factorized graphical model, and has been shown effective for extracting domain invariant asr features  #TAUTHOR_TAG']","['', ') [ 16 ]. fhvae learns to encode sequence - level and segment - level information into separate latent variables', 'without supervision by optimizing an evidence lower bound derived from a factorized graphical model, and has been shown effective for extracting domain invariant asr features  #TAUTHOR_TAG. while previous work investigated usage of fhvae for asr by training fhvae models on all domains of the target task (', 'e. g., aurora - 4 with all four conditions )  #TAUTHOR_TAG 8 ], we also evaluate fhvae models trained on placesaudcap to test cross - dataset transferability, and', 'on the subset of domains used for asr training. we use fhvae models with two lstm layers, each with 256 cells, for both the encoders and decoder. a discriminative weight of', 'α = 10 is applied for all models, and the scalable training algorithm proposed in [ 51 ] is used for training on placesaudcap dataset with', 'a sequence batch size k = 5000, because the original algorithm cannot', 'handle large - scale datasets. tables 1 and 2 present the testing word error rates ( wers ) on both in - domain', 'and out - of - domain conditions for asr systems trained with different features. fe train set denotes the data used for training feature extractors,', 'and a / i following places represents the audio and image portion of the placesaudcap dataset, respectively']",0
['extracting domain invariant asr features  #TAUTHOR_TAG'],['extracting domain invariant asr features  #TAUTHOR_TAG. while'],"['learns to encode sequence - level and segment - level information into separate latent variables', 'without supervision by optimizing an evidence lower bound derived from a factorized graphical model, and has been shown effective for extracting domain invariant asr features  #TAUTHOR_TAG']","['', ') [ 16 ]. fhvae learns to encode sequence - level and segment - level information into separate latent variables', 'without supervision by optimizing an evidence lower bound derived from a factorized graphical model, and has been shown effective for extracting domain invariant asr features  #TAUTHOR_TAG. while previous work investigated usage of fhvae for asr by training fhvae models on all domains of the target task (', 'e. g., aurora - 4 with all four conditions )  #TAUTHOR_TAG 8 ], we also evaluate fhvae models trained on placesaudcap to test cross - dataset transferability, and', 'on the subset of domains used for asr training. we use fhvae models with two lstm layers, each with 256 cells, for both the encoders and decoder. a discriminative weight of', 'α = 10 is applied for all models, and the scalable training algorithm proposed in [ 51 ] is used for training on placesaudcap dataset with', 'a sequence batch size k = 5000, because the original algorithm cannot', 'handle large - scale datasets. tables 1 and 2 present the testing word error rates ( wers ) on both in - domain', 'and out - of - domain conditions for asr systems trained with different features. fe train set denotes the data used for training feature extractors,', 'and a / i following places represents the audio and image portion of the placesaudcap dataset, respectively']",0
"['using a protocol similar to  #TAUTHOR_TAG, where']","['using a protocol similar to  #TAUTHOR_TAG, where']","[') exclusion of nuisance factors, and ( 3 ) transferrability across datasets.', 'the first two are evaluated using a protocol similar to  #TAUTHOR_TAG, where an asr model is trained on']","['evaluate transfer learning performance, we consider three criteria : ( 1 ) inclusion of phonetic content, ( 2 ) exclusion of nuisance factors, and ( 3 ) transferrability across datasets.', 'the first two are evaluated using a protocol similar to  #TAUTHOR_TAG, where an asr model is trained on a set of domains, and evaluated on both in - domain and out - of - domain speech ( relative to the training data ).', 'performance on in - domain data characterizes an upper bound for the amount of phonetic information that can be inferred from the input.', 'the performance gap between in - domain and out - of - domain data quantifies the invariance of the features to nuisance factors : the smaller this gap, the more invariant the features are.', 'to test the third criteria, instead of training the source task on a dataset that includes speech used for the target task, a separate dataset collected through a different process ( i. e., placesaudcap ) is used.', 'we emphasize here that this is a more practical setting to consider than training one feature extractor for each target task']",3
['extracting domain invariant asr features  #TAUTHOR_TAG'],['extracting domain invariant asr features  #TAUTHOR_TAG. while'],"['learns to encode sequence - level and segment - level information into separate latent variables', 'without supervision by optimizing an evidence lower bound derived from a factorized graphical model, and has been shown effective for extracting domain invariant asr features  #TAUTHOR_TAG']","['', ') [ 16 ]. fhvae learns to encode sequence - level and segment - level information into separate latent variables', 'without supervision by optimizing an evidence lower bound derived from a factorized graphical model, and has been shown effective for extracting domain invariant asr features  #TAUTHOR_TAG. while previous work investigated usage of fhvae for asr by training fhvae models on all domains of the target task (', 'e. g., aurora - 4 with all four conditions )  #TAUTHOR_TAG 8 ], we also evaluate fhvae models trained on placesaudcap to test cross - dataset transferability, and', 'on the subset of domains used for asr training. we use fhvae models with two lstm layers, each with 256 cells, for both the encoders and decoder. a discriminative weight of', 'α = 10 is applied for all models, and the scalable training algorithm proposed in [ 51 ] is used for training on placesaudcap dataset with', 'a sequence batch size k = 5000, because the original algorithm cannot', 'handle large - scale datasets. tables 1 and 2 present the testing word error rates ( wers ) on both in - domain', 'and out - of - domain conditions for asr systems trained with different features. fe train set denotes the data used for training feature extractors,', 'and a / i following places represents the audio and image portion of the placesaudcap dataset, respectively']",3
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', 'later we use the model to']","['##ability classification, is a task of mapping text onto a scale of readability levels.', 'we explore the task of automatically classifying documents based on their different readability levels.', 'as an input, this function operates on various statistics relating to different text features.', 'in this paper, we train a readability classification model using a corpus compiled from textbooks and features inherited from our previous works  #AUTHOR_TAG ; and features from  #TAUTHOR_TAG.', 'later we use the model to classify bangla news articles for children from different well - known news sources from bangladesh and west bengal.', 'the paper is organized as follows : section 2 discusses related work.', 'section 3 describes cognitive model of children in terms of readability followed by an introduction of the training corpus and news articles in section 4.', 'the features used for classification are described in section 5, and our experiments and results in section 6 are followed by a discussion in section 7.', '']",5
"[' #AUTHOR_TAG ; and  #TAUTHOR_TAG, these features']","['we have inherited features from  #AUTHOR_TAG ; and  #TAUTHOR_TAG, these features']","['of the linguistically motivated', ""features. we have inherited features from  #AUTHOR_TAG ; and  #TAUTHOR_TAG, these features achieve reasonable classification accuracy. children '"", 's reading skills is influenced by their cognitive ability. the following section describes children']","['', 'user experiment to identify important structural parameters of bangla texts. these measures are based on the average word length ( wl', '), the number of poly - syllabic words and the number of consonantconjuncts.', 'according to their experimental results, consonant - conjuncts plays an important role in texts in terms of readability. from the beginning of research on', 'text readability, researchers proposed different measures for english  #AUTHOR_TAG mc  #AUTHOR_TAG. many commercial readability tools use traditional measures.  #AUTHOR_TAG', 'stated that the smog ( mc  #AUTHOR_TAG readability measure should be preferred to assess the read', '##ability of texts on health care. due to recent achievements in linguistic data', 'processing, different linguistic features are now in the focus of readability studies. islam et al', '. ( 2012 ) summarizes related work regarding language model - based features  #AUTHOR_TAG,', 'pos - related features  #AUTHOR_TAG, syntactic features  #AUTHOR_TAG, and semantic features  #AUTHOR_TAG.  #AUTHOR_TAG found that morphological features influence the readability of german texts.', 'due to unavailability of linguistic resources for bangla, we did not explore any of the linguistically motivated', ""features. we have inherited features from  #AUTHOR_TAG ; and  #TAUTHOR_TAG, these features achieve reasonable classification accuracy. children '"", ""s reading skills is influenced by their cognitive ability. the following section describes children's"", 'cognitive model and text readability']",5
"[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was performed to']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was performed to evaluate their performance.', 'we also inherited two of their best performing models :', 'in their models, they use structural parameters such as average wl, number of jukta - akshars ( juk ) or consonant - conjuncts, number of polysyllabic words ( psw ).', 'the psw30 shows that normalized value of psw over 30 sentences.', 'table 3 : performance of bangla readability models proposed by  #TAUTHOR_TAG.', 'in this paper, we use 20 features to generate feature vectors for the classifier.', 'the following section describes our experiments and results on training corpus and news articles']",5
"[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was performed to']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was performed to evaluate their performance.', 'we also inherited two of their best performing models :', 'in their models, they use structural parameters such as average wl, number of jukta - akshars ( juk ) or consonant - conjuncts, number of polysyllabic words ( psw ).', 'the psw30 shows that normalized value of psw over 30 sentences.', 'table 3 : performance of bangla readability models proposed by  #TAUTHOR_TAG.', 'in this paper, we use 20 features to generate feature vectors for the classifier.', 'the following section describes our experiments and results on training corpus and news articles']",5
"['order to find the best performing training model, we use 20 features from  #AUTHOR_TAG ; and  #TAUTHOR_TAG.', 'note that hundred data sets were randomly generated where']","['order to find the best performing training model, we use 20 features from  #AUTHOR_TAG ; and  #TAUTHOR_TAG.', 'note that hundred data sets were randomly generated where']","['order to find the best performing training model, we use 20 features from  #AUTHOR_TAG ; and  #TAUTHOR_TAG.', 'note that hundred data sets were randomly generated where']","['order to find the best performing training model, we use 20 features from  #AUTHOR_TAG ; and  #TAUTHOR_TAG.', 'note that hundred data sets were randomly generated where 80 % of the corpus was used for training and remaining 20 % for evaluation.', 'the weighted average of accuracy and f - score is computed by considering results of all data sets.', 'we use the smo  #AUTHOR_TAG classifier model implemented in weka  #AUTHOR_TAG together with the pearson vii function - based universal kernel puk ( ustun et al., 2006 )']",5
"['not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['traditional readability formulas that were proposed for english texts do not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['traditional readability formulas that were proposed for english texts do not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', 'at first we build a classifier using two readability models from  #TAUTHOR_TAG.', 'the output of these models are used as input for the readability classifier.', '']",5
"['not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['traditional readability formulas that were proposed for english texts do not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['traditional readability formulas that were proposed for english texts do not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', 'at first we build a classifier using two readability models from  #TAUTHOR_TAG.', 'the output of these models are used as input for the readability classifier.', '']",5
"[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was performed to']","[',  #TAUTHOR_TAG proposed few computational models that are similar to the traditional english readability formulas.', 'a user study was performed to evaluate their performance.', 'we also inherited two of their best performing models :', 'in their models, they use structural parameters such as average wl, number of jukta - akshars ( juk ) or consonant - conjuncts, number of polysyllabic words ( psw ).', 'the psw30 shows that normalized value of psw over 30 sentences.', 'table 3 : performance of bangla readability models proposed by  #TAUTHOR_TAG.', 'in this paper, we use 20 features to generate feature vectors for the classifier.', 'the following section describes our experiments and results on training corpus and news articles']",0
"['not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['traditional readability formulas that were proposed for english texts do not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', '']","['traditional readability formulas that were proposed for english texts do not work for bangla texts  #TAUTHOR_TAG.', 'that is why, we did not explore any of the traditional formulas.', 'at first we build a classifier using two readability models from  #TAUTHOR_TAG.', 'the output of these models are used as input for the readability classifier.', '']",0
[' #AUTHOR_TAG and features proposed by  #TAUTHOR_TAG'],[' #AUTHOR_TAG and features proposed by  #TAUTHOR_TAG'],[' #AUTHOR_TAG and features proposed by  #TAUTHOR_TAG'],"['this paper, our goals was to examine the difficulty levels of news articles targeting children.', 'therefore we build a readability classifier that is able to classify the corresponding news articles into different difficulty levels.', 'children news articles are cognitively and linguistically different than articles for adult readers.', 'a readability classifier trained on a textbooks corpus is able to classify these articles.', 'although linguistically motivated features could capture linguistic properties of news articles.', 'lexical features and features related to information density also have good predictive power to identify text difficulties.', 'the classification results show that candidate articles are appropriate for children.', 'this study also validate that features in our previous study  #AUTHOR_TAG and features proposed by  #TAUTHOR_TAG are useful for bangla text readability analysis.', 'there are many languages in the world which lack a readability measurement tool.', 'a readability classifier for these language could be built by using the features proposed in our previous study islam et al']",3
"['attention heads of bert  #AUTHOR_TAG b, a ;  #TAUTHOR_TAG']","['attention heads of bert  #AUTHOR_TAG b, a ;  #TAUTHOR_TAG']","['attention heads of bert  #AUTHOR_TAG b, a ;  #TAUTHOR_TAG.', 'bert and']","['', 'to that end, researchers have investigated the linguistic knowledge that these models learn by analyzing bert  #AUTHOR_TAG directly or training probing classifiers on the contextualized embeddings or attention heads of bert  #AUTHOR_TAG b, a ;  #TAUTHOR_TAG.', 'bert and roberta, as transformer models  #AUTHOR_TAG, compute the hidden representation of all the attention heads at each layer for each token by attending to all the token representations in the preceding layer.', 'in this work, we investigate the hypothesis that bertstyle models use at least some of their attention heads to track syntactic dependency relationships between words.', '']",0
"['show that bert encodes syntax more than semantics.', ' #TAUTHOR_TAG train a structural probing model']","['show that bert encodes syntax more than semantics.', ' #TAUTHOR_TAG train a structural probing model']","['show that bert encodes syntax more than semantics.', ' #TAUTHOR_TAG train a structural probing model']","['works have proposed methods for extracting dependency relations and trees from the attention heads of the transformer - based neural machine translation ( nmt ) models.', 'in their preliminary work, marecek and  #AUTHOR_TAG aggregate the attention weights across the self - attention layers and heads to form a single attention weight matrix.', 'using this matrix, they propose a method to extract constituency and ( undirected ) dependency trees by recursively splitting and constructing the maximum spanning trees respectively.', 'in contrast,  #AUTHOR_TAG train a transformer - based machine translation model on different language pairs and extract the maximum spanning tree algorithm from the attention weights of the encoder for each layer and head individually.', 'they find that the best dependency score is not significantly higher than a right - branching tree baseline.', ' #AUTHOR_TAG find the most confident attention heads of the transformer nmt encoder based on a heuristic of the concentration of attention weights on a single token, and find that these heads mostly attend to relative positions, syntactic relations, and rare words.', 'additionally, researchers have investigated the syntactic knowledge that bert learns by analyzing the contextualized embeddings  #AUTHOR_TAG a ) and attention heads of bert  #AUTHOR_TAG.', ' #AUTHOR_TAG analyzes the contextualized embeddings of bert by computing language model surprisal on subject - verb agreement and shows that bert learns significant knowledge of syntax.', ' #AUTHOR_TAG b ) introduce a probing classifier for evaluating syntactic knowledge in bert and show that bert encodes syntax more than semantics.', ' #TAUTHOR_TAG train a structural probing model that maps the hidden representations of each token to an inner - product space that corresponds to syntax tree distance.', 'they show that the learned spaces of strong models such as bert and elmo  #AUTHOR_TAG are better for reconstructing dependency trees compared to baselines.', "" #AUTHOR_TAG train a probing classifier on the attentionheads of bert and show that bert's attention heads capture substantial syntactic information."", 'while there has been prior work on analysis of the attention heads of bert, we believe we are the first to analyze the dependency relations learned by the attention heads of fine - tuned bert models and roberta']",0
"[', though we follow  #TAUTHOR_TAG in']","['tree, though we follow  #TAUTHOR_TAG in']","[', though we follow  #TAUTHOR_TAG in']","['', '( using the gold root as the starting point in mst may artificially improve our results slightly, but this bias is applied evenly across all the models we compare. ) the resulting tree is a valid directed dependency tree, though we follow  #TAUTHOR_TAG in evaluating it as undirected, for easier comparison with our max method.', ' #AUTHOR_TAG, we exclude the sentence demarcation tokens ( [CLS], [SEP], < s >, < / s > ) from the attention matrices.', 'this allows us to focus on inter - word attention.', '']",5
"[', though we follow  #TAUTHOR_TAG in']","['tree, though we follow  #TAUTHOR_TAG in']","[', though we follow  #TAUTHOR_TAG in']","['', '( using the gold root as the starting point in mst may artificially improve our results slightly, but this bias is applied evenly across all the models we compare. ) the resulting tree is a valid directed dependency tree, though we follow  #TAUTHOR_TAG in evaluating it as undirected, for easier comparison with our max method.', ' #AUTHOR_TAG, we exclude the sentence demarcation tokens ( [CLS], [SEP], < s >, < / s > ) from the attention matrices.', 'this allows us to focus on inter - word attention.', '']",3
['syntactic probing work  #AUTHOR_TAG b ;  #TAUTHOR_TAG'],['syntactic probing work  #AUTHOR_TAG b ;  #TAUTHOR_TAG'],"['reflect the full extent of the significant amount of syntactic knowledge bert and roberta are known to learn as shown in previous syntactic probing work  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'additionally, we find that fine - tuning on the semantics - oriented mnli dataset']","[', the results of both analysis methods suggest that, although some attention heads of bert capture specific dependency relation types, they do not reflect the full extent of the significant amount of syntactic knowledge bert and roberta are known to learn as shown in previous syntactic probing work  #AUTHOR_TAG b ;  #TAUTHOR_TAG.', 'additionally, we find that fine - tuning on the semantics - oriented mnli dataset improves long term dependencies while slightly degrading the performance for other dependency types.', 'the overall performance of bert and the fine - tuned berts over the nonrandom baselines are not substantial, and finetuning on cola and mnli also does not have a large impact on uuas']",4
"[' #TAUTHOR_TAG.', 'pdt']","[' #TAUTHOR_TAG.', 'pdtb adopts non - hierarchical binary view on discourse relations :']","['were developed  #TAUTHOR_TAG.', 'pdt']",[' #TAUTHOR_TAG'],0
"[' #TAUTHOR_TAG.', 'pdt']","[' #TAUTHOR_TAG.', 'pdtb adopts non - hierarchical binary view on discourse relations :']","['were developed  #TAUTHOR_TAG.', 'pdt']",[' #TAUTHOR_TAG'],0
"[' #TAUTHOR_TAG.', 'pdt']","[' #TAUTHOR_TAG.', 'pdtb adopts non - hierarchical binary view on discourse relations :']","['were developed  #TAUTHOR_TAG.', 'pdt']",[' #TAUTHOR_TAG'],0
"['', 'crf - based discourse parser of  #TAUTHOR_TAG, which processes ss and ps cases with the same model, uses ±2 sentence window as a hypothesis space ( 5 sentences : 1']","['', 'crf - based discourse parser of  #TAUTHOR_TAG, which processes ss and ps cases with the same model, uses ±2 sentence window as a hypothesis space ( 5 sentences : 1']","['', 'crf - based discourse parser of  #TAUTHOR_TAG, which processes ss and ps cases with the same model, uses ±2 sentence window as a hypothesis space ( 5 sentences : 1 sentence containing the connective, 2 preceding and 2 following sentences ).', 'the window size is motivated by the observation that']","['', 'crf - based discourse parser of  #TAUTHOR_TAG, which processes ss and ps cases with the same model, uses ±2 sentence window as a hypothesis space ( 5 sentences : 1 sentence containing the connective, 2 preceding and 2 following sentences ).', 'the window size is motivated by the observation that it entirely covers arguments of 94 % of all explicit relations.', 'the authors also report that the performance of the parser on inter - sentential relations ( i. e. mainly ps case ) has f - measure of 36. 0.', 'however, since in 44. 2 % of inter - sentential explicit discourse relations arg1 fully covers the sentence immediately preceding arg2 ( see table 1 partially copied from  #AUTHOR_TAG ), the heuristic that selects the immediately previous sentence and tags all of its tokens as arg1 already yields f - measure of 44. 2 over all pdtb ( the performance on the test set may vary ).', 'the same heuristic is mentioned in  #AUTHOR_TAG and  #AUTHOR_TAG as a majority classifier for the relations with arg1 in previous sentences.', '']",0
"['arg2 and arg1 argument span extraction', 'in  #TAUTHOR_TAG which is an additional motivation to process intra - and inter - sentential relations separately']","['arg2 and arg1 argument span extraction', 'in  #TAUTHOR_TAG which is an additional motivation to process intra - and inter - sentential relations separately']","['arg2 and arg1 argument span extraction', 'in  #TAUTHOR_TAG which is an additional motivation to process intra - and inter - sentential relations separately']","['', '##ordinating conjunction if.. then in the same sentence. others, such as sentence - medial adverbials however and meanwhile mainly require', 'their arg1 in the previous sentence. even though low, there is still an ambiguity : e. g. for sentence - medial adverbials also,', 'therefore, still, instead, in fact, etc. arg1 appears in ss and ps cases evenly. consequently, assigning the position of the arg1 considering the discourse connective, together with its syntactic category', 'and its position in the sentence, for pdtb will be correct in more than 95 % of instances. in the', 'literature, the task of argument position classification was addressed by several researchers ( e. g.  #AUTHOR_TAG,  #AUTHOR_TAG ).  #AUTHOR_TAG, for instance, report f 1 of 97.', '94 % for a classifier trained on pdtb sections', '02 - 21, and tested on section 23. the task has a very high baseline and even higher performance on supervised machine learning, table 3 : feature sets for arg2 and arg1 argument span extraction', 'in  #TAUTHOR_TAG which is an additional motivation to process intra - and inter - sentential relations separately']",0
['connective  #TAUTHOR_TAG'],['connective  #TAUTHOR_TAG'],['connective  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
['connective  #TAUTHOR_TAG'],['connective  #TAUTHOR_TAG'],['connective  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],0
['discourse parser of  #TAUTHOR_TAG is a'],['discourse parser of  #TAUTHOR_TAG is a'],['discourse parser of  #TAUTHOR_TAG is a cascade of crf models'],"['discourse parser of  #TAUTHOR_TAG is a cascade of crf models to sequentially label arg2 and arg1 spans ( since arg2 label is a feature for arg1 model ) ( see figure 1 ).', 'there is no distinction between intra - and inter - sentential relations, rather the single model jointly decides on the position and the span of an argument ( either arg1 or arg2, not both together ) in the window of ±2 sentences ( the parser will be further abbreviated as w5p - window 5 parser ).', '']",0
['report using con'],"['report using conll - based evaluation script.', 'however,']",['report using con'],"['report using conll - based evaluation script.', 'however, it is not well suited for the evaluation of argument spans because the unit of evaluation is a chunk - a segment delimited by any outof - chunk token or a sentence boundary.', 'however, in pdtb arguments can ( 1 ) span over several sentences, ( 2 ) be non - contiguous in the same sentence.', 'thus, conll - based evaluation yields incorrect number of test instances :  #TAUTHOR_TAG report 1, 028 ss and 617 ps test instances for pdtb sections 23 - 24 ( see caption of table 7 in the original paper ), which is 1, 645 in total ; whereas there is only 1, 595 explicit relations in these sections.', 'in this paper, the evaluation is string - based ; i. e. an argument span is correct, if it matches the whole reference string.', 'following  #TAUTHOR_TAG and  #AUTHOR_TAG, argument initial and final punctuation marks are removed ; and precision ( p ), recall ( r ) and f 1 score are computed using the equations 1 - 3.', 'in the equations, exact match is the count of correctly tagged argument spans ; no match is the count of argument spans that do not match the reference string exactly ( even one token difference is counted as an error ) ; and references in gold is the total number of arguments in the reference.', 'string - based evaluation of the single model discourse parser with gold features reduces f 1 for arg2 from 81. 7 to 77. 8 and for arg1 from 60. 33 to 55. 33']",0
['report using con'],"['report using conll - based evaluation script.', 'however,']",['report using con'],"['report using conll - based evaluation script.', 'however, it is not well suited for the evaluation of argument spans because the unit of evaluation is a chunk - a segment delimited by any outof - chunk token or a sentence boundary.', 'however, in pdtb arguments can ( 1 ) span over several sentences, ( 2 ) be non - contiguous in the same sentence.', 'thus, conll - based evaluation yields incorrect number of test instances :  #TAUTHOR_TAG report 1, 028 ss and 617 ps test instances for pdtb sections 23 - 24 ( see caption of table 7 in the original paper ), which is 1, 645 in total ; whereas there is only 1, 595 explicit relations in these sections.', 'in this paper, the evaluation is string - based ; i. e. an argument span is correct, if it matches the whole reference string.', 'following  #TAUTHOR_TAG and  #AUTHOR_TAG, argument initial and final punctuation marks are removed ; and precision ( p ), recall ( r ) and f 1 score are computed using the equations 1 - 3.', 'in the equations, exact match is the count of correctly tagged argument spans ; no match is the count of argument spans that do not match the reference string exactly ( even one token difference is counted as an error ) ; and references in gold is the total number of arguments in the reference.', 'string - based evaluation of the single model discourse parser with gold features reduces f 1 for arg2 from 81. 7 to 77. 8 and for arg1 from 60. 33 to 55. 33']",0
[' #TAUTHOR_TAG  #AUTHOR_TAG ) ; and distribution of arg2 with respect to extent in inter - sentential explicit discourse'],"[' #TAUTHOR_TAG  #AUTHOR_TAG ) ; and distribution of arg2 with respect to extent in inter - sentential explicit discourse relations.', 'ss = same']","[' #TAUTHOR_TAG  #AUTHOR_TAG ) ; and distribution of arg2 with respect to extent in inter - sentential explicit discourse relations.', 'ss = same sentence as the connective ; ips = immediately previous sentence ; naps = non - adjacent previous sentence ; fs = some sentence following']","['applied machine learning methods using lexical and syntactic features and achieved high classification performance on discourse connective detection task ( f 1 : 94. 19 %, 10 fold crossvalidation on pdtb sections 02 - 22 ).', ' #AUTHOR_TAG achieved an improvement with additional lexico - syntactic and path features ( f 1 : 95. 76 % ).', 'after a discourse connective is identified as such, it is classified into relation senses annotated in pdtb.', ' #AUTHOR_TAG classify discourse connectives into 4 top level senses - comparison, contingency, expansion, and temporal - and achieve accuracy of 94. 15 %, which is slightly above the interannotator agreement.', 'in this paper we focus on the parsing steps after discourse connective detection ; thus, we use gold reference connectives and their senses as features.', 'the approaches used for the argument position classification even though useful, are incomplete as they do not make decision on argument spans.', ' #AUTHOR_TAG and  #AUTHOR_TAG, following them, used machine learning methods to identify head words of the arguments of explicit relations expressed by discourse connectives.', ' #AUTHOR_TAG, on the other hand, addressed a more difficult task of identification of sentences that contain arg1 for cases when arguments are located in different sentences.', ' #AUTHOR_TAG and  #AUTHOR_TAG approach the problem of argument span extraction on syntactic tree node - level.', 'in the former, it is a rule based system that covers limited set of connectives ; whereas in the latter it is a machine learning approach with full pdtb coverage.', 'both apply syntactic tree subtraction to get argument spans.', ' #AUTHOR_TAG approach the problem on a constituent - level : authors first decide whether a constituent is a valid argument and then whether it is arg1, arg2, or neither.', ' #AUTHOR_TAG ( and further  #AUTHOR_TAG a  #AUTHOR_TAG b ) ), on the other hand, cast the problem as tokenlevel sequence labeling.', 'in this paper we follows the approach of  #TAUTHOR_TAG  #AUTHOR_TAG ) ; and distribution of arg2 with respect to extent in inter - sentential explicit discourse relations.', 'ss = same sentence as the connective ; ips = immediately previous sentence ; naps = non - adjacent previous sentence ; fs = some sentence following the sentence containing the connective ; singfull = single full sentence ; singpart = part of single sentence ; multfull = multiple full sentences ; multpart = parts of multiple sentences']",5
"['evaluation.', 'first, in this paper it is different from  #TAUTHOR_TAG ; thus, we first describe it and evaluate the difference.', 'second, in order to compare']","['evaluation.', 'first, in this paper it is different from  #TAUTHOR_TAG ; thus, we first describe it and evaluate the difference.', 'second, in order to compare']","['are two important aspects regarding the evaluation.', 'first, in this paper it is different from  #TAUTHOR_TAG ; thus, we first describe it and evaluate the difference.', 'second, in order to compare the baseline single']","['are two important aspects regarding the evaluation.', 'first, in this paper it is different from  #TAUTHOR_TAG ; thus, we first describe it and evaluate the difference.', 'second, in order to compare the baseline single and separate model parsers, the error from argument position classification has to be propagated for the latter one ; and the process is described in 6. 1. 2.', 'since both versions of the parser are affected by automatic features, the evaluation is on gold features only.', 'the exception is for arg2 label ; since it is generated within the segment of the pipeline we are in - terested in.', 'unless stated otherwise, all the results for arg1 are reported for automatic arg2 labels as a feature.', 'following  #TAUTHOR_TAG pdtb is split as sections 02 - 22 for training, 00 - 01 for development, and 23 - 24 for testing']",5
['report using con'],"['report using conll - based evaluation script.', 'however,']",['report using con'],"['report using conll - based evaluation script.', 'however, it is not well suited for the evaluation of argument spans because the unit of evaluation is a chunk - a segment delimited by any outof - chunk token or a sentence boundary.', 'however, in pdtb arguments can ( 1 ) span over several sentences, ( 2 ) be non - contiguous in the same sentence.', 'thus, conll - based evaluation yields incorrect number of test instances :  #TAUTHOR_TAG report 1, 028 ss and 617 ps test instances for pdtb sections 23 - 24 ( see caption of table 7 in the original paper ), which is 1, 645 in total ; whereas there is only 1, 595 explicit relations in these sections.', 'in this paper, the evaluation is string - based ; i. e. an argument span is correct, if it matches the whole reference string.', 'following  #TAUTHOR_TAG and  #AUTHOR_TAG, argument initial and final punctuation marks are removed ; and precision ( p ), recall ( r ) and f 1 score are computed using the equations 1 - 3.', 'in the equations, exact match is the count of correctly tagged argument spans ; no match is the count of argument spans that do not match the reference string exactly ( even one token difference is counted as an error ) ; and references in gold is the total number of arguments in the reference.', 'string - based evaluation of the single model discourse parser with gold features reduces f 1 for arg2 from 81. 7 to 77. 8 and for arg1 from 60. 33 to 55. 33']",5
['discourse parser of  #TAUTHOR_TAG is a'],['discourse parser of  #TAUTHOR_TAG is a'],['discourse parser of  #TAUTHOR_TAG is a cascade of crf models'],"['discourse parser of  #TAUTHOR_TAG is a cascade of crf models to sequentially label arg2 and arg1 spans ( since arg2 label is a feature for arg1 model ) ( see figure 1 ).', 'there is no distinction between intra - and inter - sentential relations, rather the single model jointly decides on the position and the span of an argument ( either arg1 or arg2, not both together ) in the window of ±2 sentences ( the parser will be further abbreviated as w5p - window 5 parser ).', '']",4
"['evaluation.', 'first, in this paper it is different from  #TAUTHOR_TAG ; thus, we first describe it and evaluate the difference.', 'second, in order to compare']","['evaluation.', 'first, in this paper it is different from  #TAUTHOR_TAG ; thus, we first describe it and evaluate the difference.', 'second, in order to compare']","['are two important aspects regarding the evaluation.', 'first, in this paper it is different from  #TAUTHOR_TAG ; thus, we first describe it and evaluate the difference.', 'second, in order to compare the baseline single']","['are two important aspects regarding the evaluation.', 'first, in this paper it is different from  #TAUTHOR_TAG ; thus, we first describe it and evaluate the difference.', 'second, in order to compare the baseline single and separate model parsers, the error from argument position classification has to be propagated for the latter one ; and the process is described in 6. 1. 2.', 'since both versions of the parser are affected by automatic features, the evaluation is on gold features only.', 'the exception is for arg2 label ; since it is generated within the segment of the pipeline we are in - terested in.', 'unless stated otherwise, all the results for arg1 are reported for automatic arg2 labels as a feature.', 'following  #TAUTHOR_TAG pdtb is split as sections 02 - 22 for training, 00 - 01 for development, and 23 - 24 for testing']",4
"[', before or after ) extraction  #TAUTHOR_TAG ning et']","['uz  #AUTHOR_TAG bethard et al.,, 2017.', 'a crucial component is temporal relation ( temprel ; e. g., before or after ) extraction  #TAUTHOR_TAG ning et al.,, 2018a.', 'the temprels in a']","['uz  #AUTHOR_TAG bethard et al.,, 2017.', 'a crucial component is temporal relation ( temprel ; e. g., before or after ) extraction  #TAUTHOR_TAG ning et']","['the temporal information in natural language text is an important nlp task  #AUTHOR_TAG ( verhagen et al.,, 2010 uz  #AUTHOR_TAG bethard et al.,, 2017.', 'a crucial component is temporal relation ( temprel ; e. g., before or after ) extraction  #TAUTHOR_TAG ning et al.,, 2018a.', 'the temprels in a document or a sentence can be conveniently modeled as a graph, where the nodes are events, and the edges are labeled by temprels.', 'given all the events in an instance, temprel annotation is the process of manually labeling all the edges - a highly labor intensive task due to two reasons.', 'one is that many edges require extensive reasoning over multiple sentences and labeling them is time - consuming.', 'perhaps more importantly, the other reason is that # edges is quadratic in # nodes.', 'if labeling an edge takes 30 seconds ( already an optimistic estimation ), a typical document with 50 nodes would take more than 10 hours to annotate.', 'even if existing annotation schemes make a compromise by only annotating edges whose nodes are from a same sentence or adjacent sentences, it still takes more than 2 hours to fully annotate a typical document.', 'consequently, the only fully annotated dataset, tb - dense, contains only 36 documents, which is rather small compared with datasets for other nlp tasks.', 'a small number of documents may indicate that the annotated data provide a limited coverage of various lexical and semantic phenomena, since a document is usually "" homogeneous "" within itself.', 'in contrast to the scarcity of fully annotated datasets ( denoted by f as in full ), there are actually some partially annotated datasets as well ( denoted by p as in partial ) ; for example, timebank  #AUTHOR_TAG and aquaint  #AUTHOR_TAG cover in total more than 250 documents.', 'since annotators are not required to label all the edges in these datasets, it is less labor intensive to collect p than to collect f. however, existing temprel extraction methods only work on one type of datasets ( i. e., either f or p ), without taking advantage of both.', 'no one, as far as we know, has explored ways to combine both types of datasets in learning and whether it is helpful.', 'this work is a case study in exploring various usages of p in the temprel extraction task.', 'we empirically show that p is indeed useful within a ( constrained ) bootstrapping type of learning approach.', 'this case study is interesting from two perspectives.', 'first, incidental supervision  #AUTHOR_TAG.', 'in practice, supervision signals may not always be perfect : they may be noisy,']",0
"['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['', '( 1, 3 ) is missing. however, ( 1, 3 ) cannot be after because it leads to ( 2, 3 ) = af ter', ', conflicting with their current annotation ; similarly, ( 1, 3', ') cannot be equal, either. a standard way to perform global inference is to formulate it as an integer linear programming ( ilp ) problem  #AUTHOR_TAG and enforce', 'transitivity rules as constraints. let r be the temp', '##rel label set 2, i r ( ij ) ∈ { 0, 1 } be the indicator function of', '( i, j ) = r, and f r ( ij ) ∈ [ 0, 1 ] be the corresponding soft - max score obtained via s f', '+ p. then the ilp objective is formulated as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is performed by ignoring "" transitivity constraints "". ( ii ) global inference can be performed by', 'adding annotated edges in p as additional constraints. note that algorithm 1 is only for the learning step of temp', '##rel extraction ; as for the inference step of this task, we consistently adopt the standard method by solving eq. ( 1 ), as was', 'done by  #TAUTHOR_TAG']",0
"['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['', '( 1, 3 ) is missing. however, ( 1, 3 ) cannot be after because it leads to ( 2, 3 ) = af ter', ', conflicting with their current annotation ; similarly, ( 1, 3', ') cannot be equal, either. a standard way to perform global inference is to formulate it as an integer linear programming ( ilp ) problem  #AUTHOR_TAG and enforce', 'transitivity rules as constraints. let r be the temp', '##rel label set 2, i r ( ij ) ∈ { 0, 1 } be the indicator function of', '( i, j ) = r, and f r ( ij ) ∈ [ 0, 1 ] be the corresponding soft - max score obtained via s f', '+ p. then the ilp objective is formulated as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is performed by ignoring "" transitivity constraints "". ( ii ) global inference can be performed by', 'adding annotated edges in p as additional constraints. note that algorithm 1 is only for the learning step of temp', '##rel extraction ; as for the inference step of this task, we consistently adopt the standard method by solving eq. ( 1 ), as was', 'done by  #TAUTHOR_TAG']",0
"['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['', '( 1, 3 ) is missing. however, ( 1, 3 ) cannot be after because it leads to ( 2, 3 ) = af ter', ', conflicting with their current annotation ; similarly, ( 1, 3', ') cannot be equal, either. a standard way to perform global inference is to formulate it as an integer linear programming ( ilp ) problem  #AUTHOR_TAG and enforce', 'transitivity rules as constraints. let r be the temp', '##rel label set 2, i r ( ij ) ∈ { 0, 1 } be the indicator function of', '( i, j ) = r, and f r ( ij ) ∈ [ 0, 1 ] be the corresponding soft - max score obtained via s f', '+ p. then the ilp objective is formulated as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is performed by ignoring "" transitivity constraints "". ( ii ) global inference can be performed by', 'adding annotated edges in p as additional constraints. note that algorithm 1 is only for the learning step of temp', '##rel extraction ; as for the inference step of this task, we consistently adopt the standard method by solving eq. ( 1 ), as was', 'done by  #TAUTHOR_TAG']",0
"['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this work is motivated differently']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this work is motivated differently and is set to achieve a different goal :  #TAUTHOR_TAG tried to enforce the transitivity structure, while the current work attempts to use imperfect signals ( e. g., partially annotated ) taken from additional data, and learn in the incidental supervision framework.', 'the p used in this work is tbaq, where only 12 % of the edges are annotated.', 'in practice, every annotation comes at a cost, either time or the expenses paid to annotators, and as more edges are annotated, the marginal "" benefit "" of one edge is going down ( an extreme case is that an edge is of no value if it can be inferred from existing edges ).', 'therefore, a more general question is to find out the optimal ratio of graph annotations.', 'moreover, partial annotation is only one type of annotation imperfection.', 'if the annotation is noisy, we can alter the hard constraints derived from p and use soft regularization terms ; if the annotation is for a different but relevant task, we can formulate corresponding constraints to connect that different task to the task at hand.', 'being able to learn from these "" indirect "" signals is appealing because indirect signals are usually order of magnitudes larger than datasets dedicated to a single task']",0
"['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['', '( 1, 3 ) is missing. however, ( 1, 3 ) cannot be after because it leads to ( 2, 3 ) = af ter', ', conflicting with their current annotation ; similarly, ( 1, 3', ') cannot be equal, either. a standard way to perform global inference is to formulate it as an integer linear programming ( ilp ) problem  #AUTHOR_TAG and enforce', 'transitivity rules as constraints. let r be the temp', '##rel label set 2, i r ( ij ) ∈ { 0, 1 } be the indicator function of', '( i, j ) = r, and f r ( ij ) ∈ [ 0, 1 ] be the corresponding soft - max score obtained via s f', '+ p. then the ilp objective is formulated as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is performed by ignoring "" transitivity constraints "". ( ii ) global inference can be performed by', 'adding annotated edges in p as additional constraints. note that algorithm 1 is only for the learning step of temp', '##rel extraction ; as for the inference step of this task, we consistently adopt the standard method by solving eq. ( 1 ), as was', 'done by  #TAUTHOR_TAG']",1
"['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['', '( 1, 3 ) is missing. however, ( 1, 3 ) cannot be after because it leads to ( 2, 3 ) = af ter', ', conflicting with their current annotation ; similarly, ( 1, 3', ') cannot be equal, either. a standard way to perform global inference is to formulate it as an integer linear programming ( ilp ) problem  #AUTHOR_TAG and enforce', 'transitivity rules as constraints. let r be the temp', '##rel label set 2, i r ( ij ) ∈ { 0, 1 } be the indicator function of', '( i, j ) = r, and f r ( ij ) ∈ [ 0, 1 ] be the corresponding soft - max score obtained via s f', '+ p. then the ilp objective is formulated as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is performed by ignoring "" transitivity constraints "". ( ii ) global inference can be performed by', 'adding annotated edges in p as additional constraints. note that algorithm 1 is only for the learning step of temp', '##rel extraction ; as for the inference step of this task, we consistently adopt the standard method by solving eq. ( 1 ), as was', 'done by  #TAUTHOR_TAG']",1
"['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['', '( 1, 3 ) is missing. however, ( 1, 3 ) cannot be after because it leads to ( 2, 3 ) = af ter', ', conflicting with their current annotation ; similarly, ( 1, 3', ') cannot be equal, either. a standard way to perform global inference is to formulate it as an integer linear programming ( ilp ) problem  #AUTHOR_TAG and enforce', 'transitivity rules as constraints. let r be the temp', '##rel label set 2, i r ( ij ) ∈ { 0, 1 } be the indicator function of', '( i, j ) = r, and f r ( ij ) ∈ [ 0, 1 ] be the corresponding soft - max score obtained via s f', '+ p. then the ilp objective is formulated as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is performed by ignoring "" transitivity constraints "". ( ii ) global inference can be performed by', 'adding annotated edges in p as additional constraints. note that algorithm 1 is only for the learning step of temp', '##rel extraction ; as for the inference step of this task, we consistently adopt the standard method by solving eq. ( 1 ), as was', 'done by  #TAUTHOR_TAG']",5
"['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is']","['', '( 1, 3 ) is missing. however, ( 1, 3 ) cannot be after because it leads to ( 2, 3 ) = af ter', ', conflicting with their current annotation ; similarly, ( 1, 3', ') cannot be equal, either. a standard way to perform global inference is to formulate it as an integer linear programming ( ilp ) problem  #AUTHOR_TAG and enforce', 'transitivity rules as constraints. let r be the temp', '##rel label set 2, i r ( ij ) ∈ { 0, 1 } be the indicator function of', '( i, j ) = r, and f r ( ij ) ∈ [ 0, 1 ] be the corresponding soft - max score obtained via s f', '+ p. then the ilp objective is formulated as where { r m 3 }', 'is selected based on the general transitivity proposed in  #TAUTHOR_TAG. with eq. ( 1 ), different implementations of line 6 in algorithm 1 can be described concisely as', 'follows : ( i ) local inference is performed by ignoring "" transitivity constraints "". ( ii ) global inference can be performed by', 'adding annotated edges in p as additional constraints. note that algorithm 1 is only for the learning step of temp', '##rel extraction ; as for the inference step of this task, we consistently adopt the standard method by solving eq. ( 1 ), as was', 'done by  #TAUTHOR_TAG']",5
"['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this work is motivated differently']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this work is motivated differently and is set to achieve a different goal :  #TAUTHOR_TAG tried to enforce the transitivity structure, while the current work attempts to use imperfect signals ( e. g., partially annotated ) taken from additional data, and learn in the incidental supervision framework.', 'the p used in this work is tbaq, where only 12 % of the edges are annotated.', 'in practice, every annotation comes at a cost, either time or the expenses paid to annotators, and as more edges are annotated, the marginal "" benefit "" of one edge is going down ( an extreme case is that an edge is of no value if it can be inferred from existing edges ).', 'therefore, a more general question is to find out the optimal ratio of graph annotations.', 'moreover, partial annotation is only one type of annotation imperfection.', 'if the annotation is noisy, we can alter the hard constraints derived from p and use soft regularization terms ; if the annotation is for a different but relevant task, we can formulate corresponding constraints to connect that different task to the task at hand.', 'being able to learn from these "" indirect "" signals is appealing because indirect signals are usually order of magnitudes larger than datasets dedicated to a single task']",5
['also be considered as a reproduction of  #TAUTHOR_TAG ( see the discussion in'],"['also be considered as a reproduction of  #TAUTHOR_TAG ( see the discussion in sec. 5 for details ).', 'two bootstrapping algorithms ( standard and constrained ) are analyzed and the benefit of p, although with missing annotations, is shown on a benchmark dataset.', 'this']",['also be considered as a reproduction of  #TAUTHOR_TAG ( see the discussion in'],"['relation ( temprel ) extraction is important but temprel annotation is labor intensive.', 'while fully annotated datasets ( f ) are relatively small, there exist more datasets with partial annotations ( p ).', 'this work provides the first investigation of learning from both types of datasets, and this preliminary study already shows promise.', 'table 2 : performance of various usages of the partially annotated data in training.', 'f : fully annotated data.', 'p : partially annotated data.', 'p f ull : p with missing annotations filled by vague.', 'p empty : p with all annotations removed.', 'bootstrap : referring to specific implementations of line 6 in algorithm 1, i. e., local or global.', 'same / nearby sentence : edges whose nodes appear in the same / nearby sentences in text.', 'overall : all edges.', 'awareness : the temporal awareness metric used in the tempeval3 workshop, measuring how useful the predicted graphs are ( uz  #AUTHOR_TAG.', 'system 7 can also be considered as a reproduction of  #TAUTHOR_TAG ( see the discussion in sec. 5 for details ).', 'two bootstrapping algorithms ( standard and constrained ) are analyzed and the benefit of p, although with missing annotations, is shown on a benchmark dataset.', 'this work may be a good starting point for further investigations of incidental supervision and data collection schemes of the temprel extraction task']",5
['as a reproduction of  #TAUTHOR_TAG on'],['as a reproduction of  #TAUTHOR_TAG on all metrics.'],['can be regarded as a reproduction of  #TAUTHOR_TAG on'],"['', ', it is surprising because the annotated edges in p are correct and should have helped. this unexpected observation suggests that simply adding the annotated edges from p into f is not a proper approach to learn from both. the', 'second part ( systems 6 - 7 ) serves as an ablation study showing the effect of', 'bootstrapping only. p empty is another variant of p we get by removing all the annotated', 'edges ( that is, only nodes are kept ). thus, they did not get any information from the annotated edges in p and any improvement came', 'from bootstrapping alone. specifically, system 6 is the standard bootstrapping and system 7 is the constrained bootstrapping', '. built on top of systems 6 - 7, systems 8 - 9 further took advantage of the annotations of p, which resulted in additional improvements. compared to', 'system 1 ( trained on f only ) and system 5 ( simply adding p into f ), the proposed system 9 achieved', ""much better performance, which is also statistically significant with p < 0. 005 ( mcnemar's"", 'test ). while system 7 can be regarded as a reproduction of  #TAUTHOR_TAG on all metrics.']",4
"['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this work is motivated differently']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this work is motivated differently and is set to achieve a different goal :  #TAUTHOR_TAG tried to enforce the transitivity structure, while the current work attempts to use imperfect signals ( e. g., partially annotated ) taken from additional data, and learn in the incidental supervision framework.', 'the p used in this work is tbaq, where only 12 % of the edges are annotated.', 'in practice, every annotation comes at a cost, either time or the expenses paid to annotators, and as more edges are annotated, the marginal "" benefit "" of one edge is going down ( an extreme case is that an edge is of no value if it can be inferred from existing edges ).', 'therefore, a more general question is to find out the optimal ratio of graph annotations.', 'moreover, partial annotation is only one type of annotation imperfection.', 'if the annotation is noisy, we can alter the hard constraints derived from p and use soft regularization terms ; if the annotation is for a different but relevant task, we can formulate corresponding constraints to connect that different task to the task at hand.', 'being able to learn from these "" indirect "" signals is appealing because indirect signals are usually order of magnitudes larger than datasets dedicated to a single task']",4
"['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this work is motivated differently']","['incorporating transitivity constraints in inference is widely used,  #TAUTHOR_TAG proposed to incorporate these constraints in the learning phase as well.', 'one of the algorithms proposed in  #TAUTHOR_TAG.', 'despite the technical similarity, this work is motivated differently and is set to achieve a different goal :  #TAUTHOR_TAG tried to enforce the transitivity structure, while the current work attempts to use imperfect signals ( e. g., partially annotated ) taken from additional data, and learn in the incidental supervision framework.', 'the p used in this work is tbaq, where only 12 % of the edges are annotated.', 'in practice, every annotation comes at a cost, either time or the expenses paid to annotators, and as more edges are annotated, the marginal "" benefit "" of one edge is going down ( an extreme case is that an edge is of no value if it can be inferred from existing edges ).', 'therefore, a more general question is to find out the optimal ratio of graph annotations.', 'moreover, partial annotation is only one type of annotation imperfection.', 'if the annotation is noisy, we can alter the hard constraints derived from p and use soft regularization terms ; if the annotation is for a different but relevant task, we can formulate corresponding constraints to connect that different task to the task at hand.', 'being able to learn from these "" indirect "" signals is appealing because indirect signals are usually order of magnitudes larger than datasets dedicated to a single task']",3
"['by  #TAUTHOR_TAG ;', '• we design a special graph which encodes our assumptions for rating - inference problems ( section 2 ), and present the associated optimization problem in']","['by  #TAUTHOR_TAG ;', '• we design a special graph which encodes our assumptions for rating - inference problems ( section 2 ), and present the associated optimization problem in']","['past supervised learning work by  #TAUTHOR_TAG ;', '• we design a special graph which encodes our assumptions for rating - inference problems ( section 2 ), and present the associated optimization problem in section 3 ;', '• we show the benefit of semi - supervised learning']","['', 'standard supervised machine learning algorithms cannot learn from unlabeled data.', 'assigning labels can be a slow and expensive process because manual inspection and domain expertise are needed.', 'often only a small portion of the documents can be labeled within resource constraints, so most documents remain unlabeled.', 'supervised learning algorithms trained on small labeled sets suffer in performance.', 'can one use the unlabeled reviews to improve rating - inference?', ' #AUTHOR_TAG suggested that doing so should be useful.', ""we demonstrate that the answer is'yes.'our approach is graph - based semi - supervised learning."", 'semi - supervised learning is an active research area in machine learning.', 'it builds better classifiers or regressors using both labeled and unlabeled data, under appropriate assumptions  #AUTHOR_TAG.', 'this paper contains three contributions :', '• we present a novel adaptation of graph - based semi - supervised learning  #AUTHOR_TAG to the sentiment analysis domain, extending past supervised learning work by  #TAUTHOR_TAG ;', '• we design a special graph which encodes our assumptions for rating - inference problems ( section 2 ), and present the associated optimization problem in section 3 ;', '• we show the benefit of semi - supervised learning for rating inference with extensive experimental results in section 4']",6
"['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated']","['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated word - vector cosine similarity.', 'details']","['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated']","['', 'we experiment with positive - sentence percentage ( psp ) based similarity which is proposed in  #TAUTHOR_TAG, and mutual - information modulated word - vector cosine similarity.', '']",5
"['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated']","['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated word - vector cosine similarity.', 'details']","['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated']","['', 'we experiment with positive - sentence percentage ( psp ) based similarity which is proposed in  #TAUTHOR_TAG, and mutual - information modulated word - vector cosine similarity.', '']",5
"['and first used in  #TAUTHOR_TAG.', 'we chose 4']","['movie - review - data / and first used in  #TAUTHOR_TAG.', 'we chose 4 - class instead of 3 - class labeling']","['and first used in  #TAUTHOR_TAG.', 'we chose 4']","['performed experiments using the movie review documents and accompanying 4 - class ( c = { 0, 1, 2, 3 } ) labels found in the "" scale dataset v1. 0 "" available at http : / / www. cs. cornell. edu / people / pabo / movie - review - data / and first used in  #TAUTHOR_TAG.', 'we chose 4 - class instead of 3 - class labeling because it is harder.', 'the dataset is divided into four author - specific corpora, containing 1770, 902, 1307, and 1027 documents.', 'we ran experiments individually for each author.', 'each document is represented as a { 0, 1 } word - presence vector, normalized to sum to 1.', 'we systematically vary labeled set size | l | ∈ { 0. 9n, 800, 400, 200, 100, 50, 25, 12, 6 } to observe the effect of semi - supervised learning.', '| l | = 0. 9n is included to match 10 - fold cross validation used by  #TAUTHOR_TAG.', 'for each | l | we run 20 trials where we randomly split the corpus into labeled and test ( unlabeled ) sets.', 'we ensure that all four classes are represented in each labeled set.', 'the same random splits are used for all methods, allowing paired t - tests for statistical significance.', 'all reported results are average test set accuracy.', 'we compare our graph - based semi - supervised method with two previously studied methods : regression and metric labeling as in  #TAUTHOR_TAG']",5
"['and first used in  #TAUTHOR_TAG.', 'we chose 4']","['movie - review - data / and first used in  #TAUTHOR_TAG.', 'we chose 4 - class instead of 3 - class labeling']","['and first used in  #TAUTHOR_TAG.', 'we chose 4']","['performed experiments using the movie review documents and accompanying 4 - class ( c = { 0, 1, 2, 3 } ) labels found in the "" scale dataset v1. 0 "" available at http : / / www. cs. cornell. edu / people / pabo / movie - review - data / and first used in  #TAUTHOR_TAG.', 'we chose 4 - class instead of 3 - class labeling because it is harder.', 'the dataset is divided into four author - specific corpora, containing 1770, 902, 1307, and 1027 documents.', 'we ran experiments individually for each author.', 'each document is represented as a { 0, 1 } word - presence vector, normalized to sum to 1.', 'we systematically vary labeled set size | l | ∈ { 0. 9n, 800, 400, 200, 100, 50, 25, 12, 6 } to observe the effect of semi - supervised learning.', '| l | = 0. 9n is included to match 10 - fold cross validation used by  #TAUTHOR_TAG.', 'for each | l | we run 20 trials where we randomly split the corpus into labeled and test ( unlabeled ) sets.', 'we ensure that all four classes are represented in each labeled set.', 'the same random splits are used for all methods, allowing paired t - tests for statistical significance.', 'all reported results are average test set accuracy.', 'we compare our graph - based semi - supervised method with two previously studied methods : regression and metric labeling as in  #TAUTHOR_TAG']",5
"['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we tuned c, α', 'with cross validation. tuning ranges']","[', since we varied labeled set size, it is convenient to tune c = k / | l |, the fraction', 'of labeled reviews used as neighbors, instead of k. we then used the same c, α', 'for all authors at all labeled set sizes in experiments involving psp', '. because c is fixed, k varies directly with | l | ( i. e., when', 'less labeled data is available, our algorithm considers fewer nearby labeled examples', '). in an attempt to reproduce the findings in  #TAUTHOR_TAG, we tuned c, α', '']",5
"['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated']","['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated word - vector cosine similarity.', 'details']","['which is proposed in  #TAUTHOR_TAG, and mutual - information modulated']","['', 'we experiment with positive - sentence percentage ( psp ) based similarity which is proposed in  #TAUTHOR_TAG, and mutual - information modulated word - vector cosine similarity.', '']",1
"['follows', '. before moving on to experiments, we note an interesting connection to the supervised learning method in', ' #TAUTHOR_TAG, which formulates rating']","['follows', '. before moving on to experiments, we note an interesting connection to the supervised learning method in', ' #TAUTHOR_TAG, which formulates rating']","['##f = 0,', 'we find the minimum loss function cy.', 'because c has strictly positive eigenvalues, the inverse is well defined. all our semi - supervised learning', 'experiments use ( 7 ) in what follows', '. before moving on to experiments, we note an interesting connection to the supervised learning method in', ' #TAUTHOR_TAG, which formulates rating']","['', 'we find the minimum loss function cy.', 'because c has strictly positive eigenvalues, the inverse is well defined. all our semi - supervised learning', 'experiments use ( 7 ) in what follows', '. before moving on to experiments, we note an interesting connection to the supervised learning method in', ' #TAUTHOR_TAG, which formulates rating inference as a metric labeling problem', ' #AUTHOR_TAG. consider a special case of our loss function', '( 1 ) when b = 0 and', 'm → ∞. it is easy to show for labeled nodes j ∈ l, the optimal value is the given label', ': f', '( x j ) = y j. then the optimization problem decou', '##ples into a set of onedimensional problems, one for each unlabeled node the', 'above problem is easy to solve. it corresponds exactly to the supervised, non - transductive version of metric labeling, except we use squared difference while  #TAUTHOR_TAG used', 'absolute difference. indeed in experiments comparing the two ( not reported here ), their differences are not statistically significant. from this perspective, our semisupervised learning method is an extension with interacting terms among unlabeled data']",3
"['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we tuned c, α', 'with cross validation. tuning ranges']","[', since we varied labeled set size, it is convenient to tune c = k / | l |, the fraction', 'of labeled reviews used as neighbors, instead of k. we then used the same c, α', 'for all authors at all labeled set sizes in experiments involving psp', '. because c is fixed, k varies directly with | l | ( i. e., when', 'less labeled data is available, our algorithm considers fewer nearby labeled examples', '). in an attempt to reproduce the findings in  #TAUTHOR_TAG, we tuned c, α', '']",3
"['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we tuned c, α', 'with cross validation. tuning ranges']","[', since we varied labeled set size, it is convenient to tune c = k / | l |, the fraction', 'of labeled reviews used as neighbors, instead of k. we then used the same c, α', 'for all authors at all labeled set sizes in experiments involving psp', '. because c is fixed, k varies directly with | l | ( i. e., when', 'less labeled data is available, our algorithm considers fewer nearby labeled examples', '). in an attempt to reproduce the findings in  #TAUTHOR_TAG, we tuned c, α', '']",3
"['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we tuned c, α', 'with cross validation. tuning ranges']","[', since we varied labeled set size, it is convenient to tune c = k / | l |, the fraction', 'of labeled reviews used as neighbors, instead of k. we then used the same c, α', 'for all authors at all labeled set sizes in experiments involving psp', '. because c is fixed, k varies directly with | l | ( i. e., when', 'less labeled data is available, our algorithm considers fewer nearby labeled examples', '). in an attempt to reproduce the findings in  #TAUTHOR_TAG, we tuned c, α', '']",3
"['follows', '. before moving on to experiments, we note an interesting connection to the supervised learning method in', ' #TAUTHOR_TAG, which formulates rating']","['follows', '. before moving on to experiments, we note an interesting connection to the supervised learning method in', ' #TAUTHOR_TAG, which formulates rating']","['##f = 0,', 'we find the minimum loss function cy.', 'because c has strictly positive eigenvalues, the inverse is well defined. all our semi - supervised learning', 'experiments use ( 7 ) in what follows', '. before moving on to experiments, we note an interesting connection to the supervised learning method in', ' #TAUTHOR_TAG, which formulates rating']","['', 'we find the minimum loss function cy.', 'because c has strictly positive eigenvalues, the inverse is well defined. all our semi - supervised learning', 'experiments use ( 7 ) in what follows', '. before moving on to experiments, we note an interesting connection to the supervised learning method in', ' #TAUTHOR_TAG, which formulates rating inference as a metric labeling problem', ' #AUTHOR_TAG. consider a special case of our loss function', '( 1 ) when b = 0 and', 'm → ∞. it is easy to show for labeled nodes j ∈ l, the optimal value is the given label', ': f', '( x j ) = y j. then the optimization problem decou', '##ples into a set of onedimensional problems, one for each unlabeled node the', 'above problem is easy to solve. it corresponds exactly to the supervised, non - transductive version of metric labeling, except we use squared difference while  #TAUTHOR_TAG used', 'absolute difference. indeed in experiments comparing the two ( not reported here ), their differences are not statistically significant. from this perspective, our semisupervised learning method is an extension with interacting terms among unlabeled data']",4
"['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we tuned c, α', 'with cross validation. tuning ranges']","[', since we varied labeled set size, it is convenient to tune c = k / | l |, the fraction', 'of labeled reviews used as neighbors, instead of k. we then used the same c, α', 'for all authors at all labeled set sizes in experiments involving psp', '. because c is fixed, k varies directly with | l | ( i. e., when', 'less labeled data is available, our algorithm considers fewer nearby labeled examples', '). in an attempt to reproduce the findings in  #TAUTHOR_TAG, we tuned c, α', '']",4
"['and first used in  #TAUTHOR_TAG.', 'we chose 4']","['movie - review - data / and first used in  #TAUTHOR_TAG.', 'we chose 4 - class instead of 3 - class labeling']","['and first used in  #TAUTHOR_TAG.', 'we chose 4']","['performed experiments using the movie review documents and accompanying 4 - class ( c = { 0, 1, 2, 3 } ) labels found in the "" scale dataset v1. 0 "" available at http : / / www. cs. cornell. edu / people / pabo / movie - review - data / and first used in  #TAUTHOR_TAG.', 'we chose 4 - class instead of 3 - class labeling because it is harder.', 'the dataset is divided into four author - specific corpora, containing 1770, 902, 1307, and 1027 documents.', 'we ran experiments individually for each author.', 'each document is represented as a { 0, 1 } word - presence vector, normalized to sum to 1.', 'we systematically vary labeled set size | l | ∈ { 0. 9n, 800, 400, 200, 100, 50, 25, 12, 6 } to observe the effect of semi - supervised learning.', '| l | = 0. 9n is included to match 10 - fold cross validation used by  #TAUTHOR_TAG.', 'for each | l | we run 20 trials where we randomly split the corpus into labeled and test ( unlabeled ) sets.', 'we ensure that all four classes are represented in each labeled set.', 'the same random splits are used for all methods, allowing paired t - tests for statistical significance.', 'all reported results are average test set accuracy.', 'we compare our graph - based semi - supervised method with two previously studied methods : regression and metric labeling as in  #TAUTHOR_TAG']",7
"['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we']","['in  #TAUTHOR_TAG, we tuned c, α', 'with cross validation. tuning ranges']","[', since we varied labeled set size, it is convenient to tune c = k / | l |, the fraction', 'of labeled reviews used as neighbors, instead of k. we then used the same c, α', 'for all authors at all labeled set sizes in experiments involving psp', '. because c is fixed, k varies directly with | l | ( i. e., when', 'less labeled data is available, our algorithm considers fewer nearby labeled examples', '). in an attempt to reproduce the findings in  #TAUTHOR_TAG, we tuned c, α', '']",0
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['have demonstrated the benefit of using unlabeled data for rating inference.', ""there are several directions to improve the work : 1. we will investigate better document representations and similarity measures based on parsing and other linguistic knowledge, as well as reviews'sentiment patterns."", 'for example, several positive sentences followed by a few concluding negative sentences could indicate an overall negative review, as observed in prior work  #TAUTHOR_TAG.', '2.', 'our method is transductive : new reviews must be added to the graph before they can be classified.', 'we will extend it to the inductive learning setting based on.', '3. we plan to experiment with cross - reviewer and cross - domain analysis, such as using a model learned on movie reviews to help classify product reviews']",0
"['a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we']","['a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we']","[': ccg parsing  #AUTHOR_TAG a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we characterize semantic parsing']","['', 'language understanding is modeled as the task of converting natural language questions into queries through intermediate logical forms, with the popular two approaches including : ccg parsing  #AUTHOR_TAG a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', '']",0
"['a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we']","['a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we']","[': ccg parsing  #AUTHOR_TAG a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we characterize semantic parsing']","['', 'language understanding is modeled as the task of converting natural language questions into queries through intermediate logical forms, with the popular two approaches including : ccg parsing  #AUTHOR_TAG a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', '']",0
['by  #TAUTHOR_TAG'],"['training semantic parsers, that has been utilized to train a semantic parser against freebase by  #TAUTHOR_TAG']","['by  #TAUTHOR_TAG.', 'sempre maps nl utterances to logical forms by performing bottom - up parsing.', 'first, a lexicon is used to map nl phrases to kb predicates, and then predicates are combined to form a full logical form by a context - free grammar.', 'since logical forms can be derived in multiple ways from the grammar, a log - linear model is used to rank possible derivations.', 'the parameters of the model are trained from']","['', 'in this way the association between the question and answer type is enforced.', 'thus during decoding, for instance, if there is a who question, the nodes with a person property would be ranked higher as the answer candidate.', 'sempre 3 is an open - source system for training semantic parsers, that has been utilized to train a semantic parser against freebase by  #TAUTHOR_TAG.', 'sempre maps nl utterances to logical forms by performing bottom - up parsing.', 'first, a lexicon is used to map nl phrases to kb predicates, and then predicates are combined to form a full logical form by a context - free grammar.', 'since logical forms can be derived in multiple ways from the grammar, a log - linear model is used to rank possible derivations.', 'the parameters of the model are trained from question - answer pairs']",0
[' #TAUTHOR_TAG and  #AUTHOR_TAG tested'],[' #TAUTHOR_TAG and  #AUTHOR_TAG tested'],[' #TAUTHOR_TAG and  #AUTHOR_TAG tested'],"[' #TAUTHOR_TAG and  #AUTHOR_TAG tested their systems on the webquestions dataset, which contains 3778 training questions and 2032 test questions collected from the google suggest api.', 'each question came with a standard answer from freebase annotated by amazon mechanical turk.', ' #AUTHOR_TAG reported a score of 31. 4 % in terms of accuracy ( with partial credit if inexact match ) on the test set and later in  #AUTHOR_TAG revised it to 35. 7 %.', 'berant et al. focused on accuracy - how many questions were correctly answered by the system.', '']",0
"['a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we']","['a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we']","[': ccg parsing  #AUTHOR_TAG a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we characterize semantic parsing']","['', 'language understanding is modeled as the task of converting natural language questions into queries through intermediate logical forms, with the popular two approaches including : ccg parsing  #AUTHOR_TAG a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', '']",5
"['a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we']","['a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we']","[': ccg parsing  #AUTHOR_TAG a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', 'we characterize semantic parsing']","['', 'language understanding is modeled as the task of converting natural language questions into queries through intermediate logical forms, with the popular two approaches including : ccg parsing  #AUTHOR_TAG a ), and dependencybased compositional semantics  #TAUTHOR_TAG.', '']",5
['( sptree ) by  #TAUTHOR_TAG and show that our model'],['( sptree ) by  #TAUTHOR_TAG and show that our model'],['( sptree ) by  #TAUTHOR_TAG and show that our model performs within 1'],"['', 'we also compare our model with an end - toend tree - based lstm model ( sptree ) by  #TAUTHOR_TAG and show that our model performs within 1 % on entity mentions and 2 % on relations.', 'our finegrained analysis also shows that our model performs significantly better on agent - artifact relations, while sptree performs better on physical and part - whole relations']",3
"['of  #TAUTHOR_TAG, our model']","['of  #TAUTHOR_TAG, our model']","['model of  #TAUTHOR_TAG, our model']",[' #TAUTHOR_TAG'],3
['formulate entity detection as a sequence labeling task using bilou scheme similar to  #AUTHOR_TAG and  #TAUTHOR_TAG'],['formulate entity detection as a sequence labeling task using bilou scheme similar to  #AUTHOR_TAG and  #TAUTHOR_TAG'],"['formulate entity detection as a sequence labeling task using bilou scheme similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we assign each token in the entity with the tag b appended with the entity type if it is the beginning of the entity, i for inside of an entity, l for the end of the entity or u if there is only one token in']","['formulate entity detection as a sequence labeling task using bilou scheme similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'we assign each token in the entity with the tag b appended with the entity type if it is the beginning of the entity, i for inside of an entity, l for the end of the entity or u if there is only one token in the entity.', 'figure 1 shows an example of the entity tag sequence assigned to the sentence.', 'for each token in the sequence, we perform a softmax over all candidate tags to output the most likely tag :', '']",3
"['select the positive and more confident label similar to  #TAUTHOR_TAG.', 'multiple relations our']","['select the positive and more confident label similar to  #TAUTHOR_TAG.', 'multiple relations our']","['', 'we select the positive and more confident label similar to  #TAUTHOR_TAG.', 'multiple relations our']","['', 'we select the positive and more confident label similar to  #TAUTHOR_TAG.', 'multiple relations our approach to relation extraction is different from  #TAUTHOR_TAG.', ' #TAUTHOR_TAG present each pair of entities to their model for relation classification.', 'in our approach, we use pointer networks to identify the related entities.', 'thus, for our approach described so far if we only compute the argmax on our objective then we limit our model to output only one relation label per token.', 'however, from our analysis of the dataset, an entity may be related to more than one entity in the sentence.', 'hence, we modify our objective to include multiple relations.', 'in figure 2, token "" safwan "" is related to both tokens "" martin "" and "" geissler "" of the entity "" martin geissler "", hence we assign probability of 0. 5 to both these tokens.', 'this can be easily expanded to include tokens from other related entities, such that we assign equal probability 1 n to all tokens 3 depending on the number n of these related tokens.', 'the log - probability for the entity part remain the same as in our objective discussed in section 4, however we modify the relation log - probability as below :', '| j']",3
"['entity head phrase similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'also, there are']","['entity head phrase similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'also, there are']","['use the entity head phrase similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'also, there are relation types namely physical ( phys ), person - social ( per']","['evaluate our proposed model on the two datasets from the automatic content extraction ( ace ) program - ace05 and ace04.', 'there are 7 main entity types namely person ( per ), organization ( org ), geographical entities ( gpe ), location ( loc ), facility ( fac ), weapon ( wea ) and vehicle ( veh ).', 'for each entity, both entity mentions and its head phrase are annotated.', 'for the scope of this paper, we only use the entity head phrase similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'also, there are relation types namely physical ( phys ), person - social ( per - soc ), organization - affiliation ( org - aff ), agent - artifact ( art ), gpe - affiliation ( gpe - aff ).', 'ace05 has a total of 6 relation types including part - whole.', 'we use the same data splits as  #AUTHOR_TAG and  #TAUTHOR_TAG such that there are 351 documents for training, 80 for development and the remaining 80 documents for the test set.', 'ace04 has 7 relation types with an additional discourse ( disc ) type and split org - aff relation type into org - aff and other - aff.', 'we perform 5 - fold cross validation similar to  #AUTHOR_TAG for fair comparison with the state - of - theart']",3
"['and relations similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'an']","['and relations similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'an']","['and relations similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'an entity is considered']","['order to compare our system with the previous systems, we report micro f1 - scores, precision and recall on both entities and relations similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'an entity is considered correct if we can identify its head and the entity type correctly.', 'a relation is considered correct if we can identify the head of the argument entities and also the relation type.', 'we also report a combined score when both argument entities and relations are correct']",3
['lstm model by  #TAUTHOR_TAG which comprises of'],['lstm model by  #TAUTHOR_TAG which comprises of'],['by  #TAUTHOR_TAG which comprises of'],[' #TAUTHOR_TAG'],3
['( sptree ) by  #TAUTHOR_TAG and show that our model'],['( sptree ) by  #TAUTHOR_TAG and show that our model'],['( sptree ) by  #TAUTHOR_TAG and show that our model performs within 1'],"['', 'we also compare our model with an end - toend tree - based lstm model ( sptree ) by  #TAUTHOR_TAG and show that our model performs within 1 % on entity mentions and 2 % on relations.', 'our finegrained analysis also shows that our model performs significantly better on agent - artifact relations, while sptree performs better on physical and part - whole relations']",5
"['entity head phrase similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'also, there are']","['entity head phrase similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'also, there are']","['use the entity head phrase similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'also, there are relation types namely physical ( phys ), person - social ( per']","['evaluate our proposed model on the two datasets from the automatic content extraction ( ace ) program - ace05 and ace04.', 'there are 7 main entity types namely person ( per ), organization ( org ), geographical entities ( gpe ), location ( loc ), facility ( fac ), weapon ( wea ) and vehicle ( veh ).', 'for each entity, both entity mentions and its head phrase are annotated.', 'for the scope of this paper, we only use the entity head phrase similar to  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'also, there are relation types namely physical ( phys ), person - social ( per - soc ), organization - affiliation ( org - aff ), agent - artifact ( art ), gpe - affiliation ( gpe - aff ).', 'ace05 has a total of 6 relation types including part - whole.', 'we use the same data splits as  #AUTHOR_TAG and  #TAUTHOR_TAG such that there are 351 documents for training, 80 for development and the remaining 80 documents for the test set.', 'ace04 has 7 relation types with an additional discourse ( disc ) type and split org - aff relation type into org - aff and other - aff.', 'we perform 5 - fold cross validation similar to  #AUTHOR_TAG for fair comparison with the state - of - theart']",5
"['.', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG.', '1 we ran the system made publicly available by  #TAUTHOR_TAG, on ace']","['test dataset.', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG.', '1 we ran the system made publicly available by  #TAUTHOR_TAG, on ace05 dataset']","['', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG.', '1 we ran the system made publicly available by  #TAUTHOR_TAG, on ace05 dataset']","['', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG.', '1 we ran the system made publicly available by  #TAUTHOR_TAG, on ace05 dataset for filling in the missing values and comparing our system with theirs at fine - grained level.', 'table 2 : performance of different encoding methods on ace05 dataset.', 'with 300 - dimensional word2vec  #AUTHOR_TAG word embeddings trained on google news dataset.', 'we have 3 hidden layers in our network and the dimensionality of the hidden units is 100.', 'all the weights in the network are initialized from small random uniform noise.', 'we tune our hyperparameters based on ace05 development set and use them for training on ace04 dataset.', 'table 1 compares the performance of our system with respect to the baselines on ace05 dataset.', 'we find that our joint model significantly outperforms the joint structured perceptron model  #AUTHOR_TAG on both entities and relations, despite the unavailability of features such as dependency trees, pos tags, etc.', 'however, if we compare our model to the sptree models, then we find that their model has better recall on both entities and relations.', 'in section 7, we perform error analysis to understand the difference in the performance of the two models in detail']",5
"['sptree  #TAUTHOR_TAG model.', 'we compare the']","['sptree  #TAUTHOR_TAG model.', 'we compare the']","['to the sptree  #TAUTHOR_TAG model.', 'we compare the performance of the two models with']","['this section, we perform a fine - grained comparison of our model with respect to the sptree  #TAUTHOR_TAG model.', 'we compare the performance of the two models with respect to entities, relation types and the distance between the relation arguments and provide examples from the test set in table 6.', 'table 3 : performance on ace04 test dataset.', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG']",5
['lstm model by  #TAUTHOR_TAG which comprises of'],['lstm model by  #TAUTHOR_TAG which comprises of'],['by  #TAUTHOR_TAG which comprises of'],[' #TAUTHOR_TAG'],5
"['of  #TAUTHOR_TAG, our model']","['of  #TAUTHOR_TAG, our model']","['model of  #TAUTHOR_TAG, our model']",[' #TAUTHOR_TAG'],0
"['', 'recently,  #TAUTHOR_TAG proposed an']","['as part of speech ( pos ) tags, dependency trees, etc.', 'recently,  #TAUTHOR_TAG proposed an']","['pos ) tags, dependency trees, etc.', 'recently,  #TAUTHOR_TAG proposed']",[' #TAUTHOR_TAG'],0
"['1.', ' #TAUTHOR_TAG, in one of the ablation tests on']","['1.', ' #TAUTHOR_TAG, in one of the ablation tests on ace05 development set, show that their model can gain upto 2 %']","['than sptree as shown in table 1.', ' #TAUTHOR_TAG, in one of the ablation tests on']","['find that our model has lower recall on entity extraction than sptree as shown in table 1.', ' #TAUTHOR_TAG, in one of the ablation tests on ace05 development set, show that their model can gain upto 2 % improvement in recall by entity pretraining.', 'since we propose a jointmodel, we cannot directly apply their pretraining trick on entities separately.', '']",0
"['1.', ' #TAUTHOR_TAG, in one of the ablation tests on']","['1.', ' #TAUTHOR_TAG, in one of the ablation tests on ace05 development set, show that their model can gain upto 2 %']","['than sptree as shown in table 1.', ' #TAUTHOR_TAG, in one of the ablation tests on']","['find that our model has lower recall on entity extraction than sptree as shown in table 1.', ' #TAUTHOR_TAG, in one of the ablation tests on ace05 development set, show that their model can gain upto 2 % improvement in recall by entity pretraining.', 'since we propose a jointmodel, we cannot directly apply their pretraining trick on entities separately.', '']",0
"['', 'recently,  #TAUTHOR_TAG proposed an']","['as part of speech ( pos ) tags, dependency trees, etc.', 'recently,  #TAUTHOR_TAG proposed an']","['pos ) tags, dependency trees, etc.', 'recently,  #TAUTHOR_TAG proposed']",[' #TAUTHOR_TAG'],1
"['.', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG.', '1 we ran the system made publicly available by  #TAUTHOR_TAG, on ace']","['test dataset.', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG.', '1 we ran the system made publicly available by  #TAUTHOR_TAG, on ace05 dataset']","['', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG.', '1 we ran the system made publicly available by  #TAUTHOR_TAG, on ace05 dataset']","['', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG.', '1 we ran the system made publicly available by  #TAUTHOR_TAG, on ace05 dataset for filling in the missing values and comparing our system with theirs at fine - grained level.', 'table 2 : performance of different encoding methods on ace05 dataset.', 'with 300 - dimensional word2vec  #AUTHOR_TAG word embeddings trained on google news dataset.', 'we have 3 hidden layers in our network and the dimensionality of the hidden units is 100.', 'all the weights in the network are initialized from small random uniform noise.', 'we tune our hyperparameters based on ace05 development set and use them for training on ace04 dataset.', 'table 1 compares the performance of our system with respect to the baselines on ace05 dataset.', 'we find that our joint model significantly outperforms the joint structured perceptron model  #AUTHOR_TAG on both entities and relations, despite the unavailability of features such as dependency trees, pos tags, etc.', 'however, if we compare our model to the sptree models, then we find that their model has better recall on both entities and relations.', 'in section 7, we perform error analysis to understand the difference in the performance of the two models in detail']",7
"['sptree  #TAUTHOR_TAG model.', 'we compare the']","['sptree  #TAUTHOR_TAG model.', 'we compare the']","['to the sptree  #TAUTHOR_TAG model.', 'we compare the performance of the two models with']","['this section, we perform a fine - grained comparison of our model with respect to the sptree  #TAUTHOR_TAG model.', 'we compare the performance of the two models with respect to entities, relation types and the distance between the relation arguments and provide examples from the test set in table 6.', 'table 3 : performance on ace04 test dataset.', 'the dashed ( "" - "" ) performance numbers were missing in the original paper  #TAUTHOR_TAG']",7
"['1.', ' #TAUTHOR_TAG, in one of the ablation tests on']","['1.', ' #TAUTHOR_TAG, in one of the ablation tests on ace05 development set, show that their model can gain upto 2 %']","['than sptree as shown in table 1.', ' #TAUTHOR_TAG, in one of the ablation tests on']","['find that our model has lower recall on entity extraction than sptree as shown in table 1.', ' #TAUTHOR_TAG, in one of the ablation tests on ace05 development set, show that their model can gain upto 2 % improvement in recall by entity pretraining.', 'since we propose a jointmodel, we cannot directly apply their pretraining trick on entities separately.', '']",2
['lstm model by  #TAUTHOR_TAG which comprises of'],['lstm model by  #TAUTHOR_TAG which comprises of'],['by  #TAUTHOR_TAG which comprises of'],[' #TAUTHOR_TAG'],2
"['unsupervised  #TAUTHOR_TAG using a metric', 'that captures varying degrees of graph similarity. eigenvalues are compact representations of global properties of graphs, and we introduce a spectral metric based on laplacian eigenvalues  #AUTHOR_TAG that quantifies the extent to which']","['unsupervised  #TAUTHOR_TAG using a metric', 'that captures varying degrees of graph similarity. eigenvalues are compact representations of global properties of graphs, and we introduce a spectral metric based on laplacian eigenvalues  #AUTHOR_TAG that quantifies the extent to which']","['unsupervised  #TAUTHOR_TAG using a metric', 'that captures varying degrees of graph similarity. eigenvalues are compact representations of global properties of graphs, and we introduce a spectral metric based on laplacian eigenvalues  #AUTHOR_TAG that quantifies the extent to']","['', 'word embeddings are particularly good at capturing relations between nouns, but even if we consider the top k most frequent english nouns and', 'their translations, the graphs are not isomorphic ; see figure 1c - d. we take this as evidence that word embeddings are not approximately isomorphic across languages. we also ran graph isomorphism checks on 10 random samples of frequent english nouns and their translations into spanish, and', 'only in 1 / 10 of the samples were the corresponding nearest neighbor graphs isomorphic. eigenvector similarity since the nearest neighbor graphs are not isomorphic, even for frequent translation pairs in neighboring languages, we want to quantify the potential', 'for unsupervised  #TAUTHOR_TAG using a metric', 'that captures varying degrees of graph similarity. eigenvalues are compact representations of global properties of graphs, and we introduce a spectral metric based on laplacian eigenvalues  #AUTHOR_TAG that quantifies the extent to which the nearest neighbor graphs are isospectral. note that ( approximately ) isospectral graphs need not be ( approximately ) isomorphic, but (', 'approximately ) isomorphic graphs are always ( approximately ) isospectral  #AUTHOR_TAG. let a 1 and a 2 be the adjacency', '']",4
"['a better understanding of the limitations of unsupervised  #TAUTHOR_TAG, we correlate the graph']","['a better understanding of the limitations of unsupervised  #TAUTHOR_TAG, we correlate the graph']","['a better understanding of the limitations of unsupervised  #TAUTHOR_TAG, we correlate the graph similarity metric described in § 2 ( right column of table 2 ) with performance']","[', in order to get a better understanding of the limitations of unsupervised  #TAUTHOR_TAG, we correlate the graph similarity metric described in § 2 ( right column of table 2 ) with performance across languages ( left column ).', 'since we already established that the monolingual word embeddings are far from isomorphic - in contrast with the intuitions motivating previous work  #AUTHOR_TAG b ;  #TAUTHOR_TAG is likely to work.', 'differences in morphology, domain, or embedding parameters seem to be predictive of poor performance, but a metric that is independent of linguistic categorizations and the characteristics of the monolingual corpora would be more widely applicable.', 'we plot the values in table 2 in figure 4.', 'recall that our graph similarity metric returns a value in the half - open interval [ 0, ∞ ).', 'the correlation between  #TAUTHOR_TAG performance and graph similarity is strong ( ρ ∼ 0. 89 )']",4
"['now introduce the method of  #TAUTHOR_TAG.', '4  #TAUTHOR_TAG builds on existing work on learning a mapping between monolingual word embeddings  #AUTHOR_TAG b ;  #AUTHOR_TAG and consists of the following steps : 1']","['now introduce the method of  #TAUTHOR_TAG.', '4  #TAUTHOR_TAG builds on existing work on learning a mapping between monolingual word embeddings  #AUTHOR_TAG b ;  #AUTHOR_TAG and consists of the following steps : 1 ) monolingual word embeddings : an off - the - shelf word embedding algorithm  #AUTHOR_TAG is used to']","['now introduce the method of  #TAUTHOR_TAG.', '4  #TAUTHOR_TAG builds on existing work on learning a mapping between monolingual word embeddings  #AUTHOR_TAG b ;  #AUTHOR_TAG and consists of the following steps : 1 ) monolingual word embeddings : an off - the - shelf word embedding algorithm  #AUTHOR_TAG is used to']","['now introduce the method of  #TAUTHOR_TAG.', '4  #TAUTHOR_TAG builds on existing work on learning a mapping between monolingual word embeddings  #AUTHOR_TAG b ;  #AUTHOR_TAG and consists of the following steps : 1 ) monolingual word embeddings : an off - the - shelf word embedding algorithm  #AUTHOR_TAG is used to learn source and target language spaces x and y.', '2 ) adversarial mapping : a translation matrix w is learned between the spaces x and y using adversarial techniques  #AUTHOR_TAG.', 'a discriminator is trained to discriminate samples from the translated source space w x from the target space y, while w is trained to prevent this.', 'this, again, is motivated by the assumption that source and target language word embeddings are approximately isomorphic.', '3 ) refinement ( procrustes analysis ) : w is used to build a small bilingual dictionary of frequent words, which is pruned such that only bidirectional translations are kept.', 'a new translation matrix w that translates between the spaces x and y of these frequent word pairs is then induced by solving the orthogonal procrustes problem :', 'this step can be used iteratively by using the new matrix w to create new seed translation pairs.', 'it requires frequent words to serve as reliable anchors for learning a translation matrix.', 'in the experiments in  #TAUTHOR_TAG, as well as in ours, the iterative procrustes refinement improves performance across the board.', '4 ) cross - domain similarity local scaling ( csls ) is used to expand high - density areas and condense low - density ones, for more accurate nearest neighbor calculation, csls reduces the hubness problem in high - dimensional spaces ( radovanovic et al., 2010 ;  #AUTHOR_TAG.', 'it relies on the mean similarity of a source language embedding x to its k target language nearest neighbours ( k = 10 suggested ) nn 1,..., nn k :', 'where cos is the cosine similarity.', 'mnn s ( y ) is defined in an analogous manner for any target language embedding y. csls ( x, y ) is then calculated as follows :', '3. 3 a simple supervised method', 'instead of learning cross - lingual embeddings completely without supervision, we can extract inexpensive supervision signals by harvesting identically spelled words as in, e. g.  #AUTHOR_TAG.', 'specifically, we use identically spelled words that occur in the vocabularies of both languages as bilingual seeds, without employing any additional transliteration or lemmatization / normalization methods.', 'using this seed dictionary, we then run the refinement step using  #TAUTHOR_TAG']",3
"['##inative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised  #TAUTHOR_TAG is challenged']","['##inative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised  #TAUTHOR_TAG is challenged']","['##inative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised  #TAUTHOR_TAG is challenged']","['##inative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised  #TAUTHOR_TAG is challenged by this kind of morphological complexity.', 'to evaluate this, we experiment with estonian and finnish, and we include greek, hungarian, polish, and turkish to see how their approach fares on combinations of these two morphological traits.', 'we show results in the left column of table 2.', 'the results are quite dramatic.', 'the approach achieves impressive performance for spanish, one of the languages  #TAUTHOR_TAG paper.', 'for the languages we add here, performance is less impressive.', 'for the languages with dependent marking ( hungarian, polish, and turkish ), p @ 1 scores are still reasonable, with turkish being slightly lower ( 0. 327 ) than the others.', 'however, for estonian and finnish, the method fails completely.', 'only in less than 1 / 1000 cases does a nearest neighbor search in the induced embeddings return a correct translation of a query word.', '5 the sizes of wikipedias naturally vary across languages : e. g., fasttext trains on approximately 16m sentences and 363m word tokens for spanish, while it trains on 1m sentences and 12m words for finnish.', 'however, the difference in performance cannot be explained by the difference in training data sizes.', 'to verify that near - zero performance in finnish is not a result of insufficient training data, we have conducted another experiment using the large finnish wac corpus ( ljubesic et al., 2016 ) containing 1. 7b words in total ( this is similar in size to the english polyglot wikipedia ).', 'however, even with this large finnish corpus, the model does not induce anything useful : p @ 1 equals 0. 0.', 'we note that while languages with mixed marking may be harder to align, it seems unsupervised  #TAUTHOR_TAG is possible between similar, mixed marking languages.', 'so while unsupervised learning fails for english - finnish and english - estonian, performance is reasonable and stable for the more similar estonian - finnish pair ( table 2 ).', 'in general, unsupervised  #TAUTHOR_TAG, seems challenged when pairing en - glish with languages that are not isolating and do not have dependent marking.', '6 the promise of zero - supervision models is that we can learn cross - lingual embeddings even for low - resource languages.', 'on the other hand, a similar distribution of embeddings requires languages to be similar.', 'this raises the question whether we need fully unsupervised methods at all.', 'in fact, our supervised method that relies on very naive supervision in the form of identically spelled words leads to']",6
"['##inative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised  #TAUTHOR_TAG is challenged']","['##inative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised  #TAUTHOR_TAG is challenged']","['##inative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised  #TAUTHOR_TAG is challenged']","['##inative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised  #TAUTHOR_TAG is challenged by this kind of morphological complexity.', 'to evaluate this, we experiment with estonian and finnish, and we include greek, hungarian, polish, and turkish to see how their approach fares on combinations of these two morphological traits.', 'we show results in the left column of table 2.', 'the results are quite dramatic.', 'the approach achieves impressive performance for spanish, one of the languages  #TAUTHOR_TAG paper.', 'for the languages we add here, performance is less impressive.', 'for the languages with dependent marking ( hungarian, polish, and turkish ), p @ 1 scores are still reasonable, with turkish being slightly lower ( 0. 327 ) than the others.', 'however, for estonian and finnish, the method fails completely.', 'only in less than 1 / 1000 cases does a nearest neighbor search in the induced embeddings return a correct translation of a query word.', '5 the sizes of wikipedias naturally vary across languages : e. g., fasttext trains on approximately 16m sentences and 363m word tokens for spanish, while it trains on 1m sentences and 12m words for finnish.', 'however, the difference in performance cannot be explained by the difference in training data sizes.', 'to verify that near - zero performance in finnish is not a result of insufficient training data, we have conducted another experiment using the large finnish wac corpus ( ljubesic et al., 2016 ) containing 1. 7b words in total ( this is similar in size to the english polyglot wikipedia ).', 'however, even with this large finnish corpus, the model does not induce anything useful : p @ 1 equals 0. 0.', 'we note that while languages with mixed marking may be harder to align, it seems unsupervised  #TAUTHOR_TAG is possible between similar, mixed marking languages.', 'so while unsupervised learning fails for english - finnish and english - estonian, performance is reasonable and stable for the more similar estonian - finnish pair ( table 2 ).', 'in general, unsupervised  #TAUTHOR_TAG, seems challenged when pairing en - glish with languages that are not isolating and do not have dependent marking.', '6 the promise of zero - supervision models is that we can learn cross - lingual embeddings even for low - resource languages.', 'on the other hand, a similar distribution of embeddings requires languages to be similar.', 'this raises the question whether we need fully unsupervised methods at all.', 'in fact, our supervised method that relies on very naive supervision in the form of identically spelled words leads to']",7
['use'],['use'],['use the same hyperparameters'],"['use the same hyperparameters for inducing embeddings for all languages.', 'this is of course always practically possible, but we are interested in seeing whether  #TAUTHOR_TAG approach works on pre - trained embeddings induced with possibly very different hyper - parameters.', 'we focus on two hyper - parameters : context windowsize ( win ) and the parameter controlling the number of n - gram features in the fasttext model ( chn ), while at the same time varying the underlying algorithm : skip - gram vs. cbow.', 'the results for englishspanish are listed in table 3.', 'the small variations in the hyper - parameters with the same underlying algorithm ( i. e., using skipgram or cbow for both en and es ) yield only slight drops in the final scores.', 'still, the best scores are obtained with the same configuration on both sides.', 'our main finding here is that unsupervised  #TAUTHOR_TAG fails ( even ) for en - es when the two monolingual embedding spaces are induced by two different algorithms ( see the results of the entire spanish cbow column ).', '9 in sum, this means that the unsupervised approach is unlikely to work on pre - trained word embeddings unless they are induced on same - 9 we also checked if this result might be due to a lowerquality monolingual es space.', ""however, monolingual word similarity scores on available datasets in spanish show performance comparable to that of spanish skip - gram vectors : e. g., spearman's ρ correlation is ≈ 0. 7 on the es evaluation set from semeval - 2017 task 2 ( camacho -  #AUTHOR_TAG."", 'or comparable - domain, reasonably - sized training data using the same underlying algorithm']",7
"['a better understanding of the limitations of unsupervised  #TAUTHOR_TAG, we correlate the graph']","['a better understanding of the limitations of unsupervised  #TAUTHOR_TAG, we correlate the graph']","['a better understanding of the limitations of unsupervised  #TAUTHOR_TAG, we correlate the graph similarity metric described in § 2 ( right column of table 2 ) with performance']","[', in order to get a better understanding of the limitations of unsupervised  #TAUTHOR_TAG, we correlate the graph similarity metric described in § 2 ( right column of table 2 ) with performance across languages ( left column ).', 'since we already established that the monolingual word embeddings are far from isomorphic - in contrast with the intuitions motivating previous work  #AUTHOR_TAG b ;  #TAUTHOR_TAG is likely to work.', 'differences in morphology, domain, or embedding parameters seem to be predictive of poor performance, but a metric that is independent of linguistic categorizations and the characteristics of the monolingual corpora would be more widely applicable.', 'we plot the values in table 2 in figure 4.', 'recall that our graph similarity metric returns a value in the half - open interval [ 0, ∞ ).', 'the correlation between  #TAUTHOR_TAG performance and graph similarity is strong ( ρ ∼ 0. 89 )']",7
"['investigated when unsupervised  #TAUTHOR_TAG is possible and found that differences in morphology, domains or word embedding algorithms may challenge this approach.', 'further, we']","['investigated when unsupervised  #TAUTHOR_TAG is possible and found that differences in morphology, domains or word embedding algorithms may challenge this approach.', 'further, we']","['investigated when unsupervised  #TAUTHOR_TAG is possible and found that differences in morphology, domains or word embedding algorithms may challenge this approach.', 'further, we found eigenvector similarity of sampled nearest neighbor subgraphs to be predictive of unsupervised  #TAUTHOR_TAG performance.', 'we hope that this work will guide further developments in this new and exciting field']","['investigated when unsupervised  #TAUTHOR_TAG is possible and found that differences in morphology, domains or word embedding algorithms may challenge this approach.', 'further, we found eigenvector similarity of sampled nearest neighbor subgraphs to be predictive of unsupervised  #TAUTHOR_TAG performance.', 'we hope that this work will guide further developments in this new and exciting field']",2
,,,,5
,,,,5
"['discriminative model, as in  #TAUTHOR_TAG, requires a slightly different search']","['unnormalized discriminative model, as in  #TAUTHOR_TAG, requires a slightly different search']","['', 'beam - search parsing using an unnormalized discriminative model, as in  #TAUTHOR_TAG, requires a slightly different search strategy than the original generative model']","['', 'beam - search parsing using an unnormalized discriminative model, as in  #TAUTHOR_TAG, requires a slightly different search strategy than the original generative model described in  #AUTHOR_TAG ; 2004 ).', 'this alternate search strategy is closer to the approach taken in  #AUTHOR_TAG ; 2003 ), in that it enumerates a set of possible ways of attaching the next word before evaluating with the model.', 'this ensures comparability for models that do not have the sort of behavior described above for the generative models, rendering look - ahead statistics difficult to estimate.', 'this approach is effective, although somewhat less so than when a look - ahead statistic is used.', 'a generative parsing model can be used on its own, and it was shown in  #TAUTHOR_TAG that a discriminative parsing model can be used on its own.', '']",5
,,,,0
"['discriminative model, as in  #TAUTHOR_TAG, requires a slightly different search']","['unnormalized discriminative model, as in  #TAUTHOR_TAG, requires a slightly different search']","['', 'beam - search parsing using an unnormalized discriminative model, as in  #TAUTHOR_TAG, requires a slightly different search strategy than the original generative model']","['', 'beam - search parsing using an unnormalized discriminative model, as in  #TAUTHOR_TAG, requires a slightly different search strategy than the original generative model described in  #AUTHOR_TAG ; 2004 ).', 'this alternate search strategy is closer to the approach taken in  #AUTHOR_TAG ; 2003 ), in that it enumerates a set of possible ways of attaching the next word before evaluating with the model.', 'this ensures comparability for models that do not have the sort of behavior described above for the generative models, rendering look - ahead statistics difficult to estimate.', 'this approach is effective, although somewhat less so than when a look - ahead statistic is used.', 'a generative parsing model can be used on its own, and it was shown in  #TAUTHOR_TAG that a discriminative parsing model can be used on its own.', '']",0
"[',  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations because surface features such as log mel - spectrograms or waveform can poorly reveal the abundant information within speech.', 'contrastive predictive coding ( cpc ) [ 5 ] and wav2vec [ 7 ] use a multi - layer cnn to encode past context, representations are learned by predicting the future in latent space under a contrastive binary classification task.', 'autoregressive predictive coding ( apc )  #TAUTHOR_TAG uses autoregressive models to encode temporal information of past acoustic sequences ; the model predicts future frames like an rnn - based language model [ 11 ], optimized with reconstruction loss.', 'unidirectional models are commonly used in the previous approaches [ 2, 3, 4, 5,  #TAUTHOR_TAG 7 ].', 'however, this constraint on model architectures limits the potential of speech representation learning.', 'the recently proposed vq - wav2vec [ 8 ] approach attempts to apply the well - performing natural language processing ( nlp ) algorithm bert [ 12 ] on continuous speech.', 'input speech is discretized to a k - way quantized embedding space, so continuous speech could act like discrete units similar to word tokens in nlp tasks.', 'in vq - wav2vec [ 8 ], an exhaustive two - stage training pipeline with massive computing resources are required to adapt speech to nlp algorithm, as the quantization process is against the continuous nature of speech.', 'unlike [ 8 ] that adapts speech to bert [ 12 ] through quantization, the proposed approach can be seen as a modified version of bert [ 12 ] for direct application on continuous speech']",0
"[',  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations because surface features such as log mel - spectrograms or waveform can poorly reveal the abundant information within speech.', 'contrastive predictive coding ( cpc ) [ 5 ] and wav2vec [ 7 ] use a multi - layer cnn to encode past context, representations are learned by predicting the future in latent space under a contrastive binary classification task.', 'autoregressive predictive coding ( apc )  #TAUTHOR_TAG uses autoregressive models to encode temporal information of past acoustic sequences ; the model predicts future frames like an rnn - based language model [ 11 ], optimized with reconstruction loss.', 'unidirectional models are commonly used in the previous approaches [ 2, 3, 4, 5,  #TAUTHOR_TAG 7 ].', 'however, this constraint on model architectures limits the potential of speech representation learning.', 'the recently proposed vq - wav2vec [ 8 ] approach attempts to apply the well - performing natural language processing ( nlp ) algorithm bert [ 12 ] on continuous speech.', 'input speech is discretized to a k - way quantized embedding space, so continuous speech could act like discrete units similar to word tokens in nlp tasks.', 'in vq - wav2vec [ 8 ], an exhaustive two - stage training pipeline with massive computing resources are required to adapt speech to nlp algorithm, as the quantization process is against the continuous nature of speech.', 'unlike [ 8 ] that adapts speech to bert [ 12 ] through quantization, the proposed approach can be seen as a modified version of bert [ 12 ] for direct application on continuous speech']",0
"[',  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations']","['speech representation learning [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8, 9, 10 ] is effective in extracting high - level properties from speech.', 'slp downstream tasks can be improved through speech representations because surface features such as log mel - spectrograms or waveform can poorly reveal the abundant information within speech.', 'contrastive predictive coding ( cpc ) [ 5 ] and wav2vec [ 7 ] use a multi - layer cnn to encode past context, representations are learned by predicting the future in latent space under a contrastive binary classification task.', 'autoregressive predictive coding ( apc )  #TAUTHOR_TAG uses autoregressive models to encode temporal information of past acoustic sequences ; the model predicts future frames like an rnn - based language model [ 11 ], optimized with reconstruction loss.', 'unidirectional models are commonly used in the previous approaches [ 2, 3, 4, 5,  #TAUTHOR_TAG 7 ].', 'however, this constraint on model architectures limits the potential of speech representation learning.', 'the recently proposed vq - wav2vec [ 8 ] approach attempts to apply the well - performing natural language processing ( nlp ) algorithm bert [ 12 ] on continuous speech.', 'input speech is discretized to a k - way quantized embedding space, so continuous speech could act like discrete units similar to word tokens in nlp tasks.', 'in vq - wav2vec [ 8 ], an exhaustive two - stage training pipeline with massive computing resources are required to adapt speech to nlp algorithm, as the quantization process is against the continuous nature of speech.', 'unlike [ 8 ] that adapts speech to bert [ 12 ] through quantization, the proposed approach can be seen as a modified version of bert [ 12 ] for direct application on continuous speech']",0
"['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as they also experiment on phone classification and speaker verification.', 'as reported in  #TAUTHOR_TAG, the apc approach outperformed cpc representations [ 5, 7, 9 ] in both two tasks, which makes apc suitable as a strong baseline.', 'apc uses an unidirectional autoregressive model.', 'we compare the proposed approach with apc to show that our bidirectional approach has advantages in speech representation learning.', ""for fair comparison, we pre - train apc using their official implementations with the reported ideal parameters and settings, but expand the model's hidden size to h dim = 768 to match ours."", 'we also report results on 160 - dimensional log mel - features, which helps evaluate the accessibility of speech information from regular acoustic features']",0
"['5,  #TAUTHOR_TAG 7, 8 ],']","['the pre - trained models to representation extraction only [ 5,  #TAUTHOR_TAG 7, 8 ],']","['the pre - trained models to representation extraction only [ 5,  #TAUTHOR_TAG 7, 8 ],']","['previous left - to - right unidirectional approaches that only consider past sequences to predict information about future frames, the proposed method allows us to train a bidirectional speech representation model, alleviating the unidirectionality constraint of previous methods.', 'as a result, the mockingjay model obtains substantial improvements in several slp tasks.', 'moreover, as previous approaches restrict the power of the pre - trained models to representation extraction only [ 5,  #TAUTHOR_TAG 7, 8 ], the proposed method is robust and can be fine - tuned easily on downstream tasks.', 'we show that finetuning for 2 epochs easily acquires significant improvement.', '']",4
"['2, 3, 4, 5,  #TAUTHOR_TAG 7, 8 ], we evaluate different features']","['works [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8 ], we evaluate different features']","['2, 3, 4, 5,  #TAUTHOR_TAG 7, 8 ], we evaluate different features']","['previous works [ 2, 3, 4, 5,  #TAUTHOR_TAG 7, 8 ], we evaluate different features and representations on downstream tasks, including : phoneme classification, speaker recognition, and sentiment classification on spoken content.', 'for a fair comparison, each downstream task uses an identical model architecture and hyperparameters despite different input features.', 'we report results from 5 of our models : 1 ) base and 2 ) large where mockingjay representations are extracted from the last encoder layer, 3 ) the base - ft2 where we finetune base with random initialized downstream models for 2 epochs, and 4 ) the base - ft500 where we fine - tune for 500k steps, and finally 5 ) the large - ws where we incorporate hidden states from all encoder layers of the large model through a learnable weighted sum.', 'we did not fine - tune the large model, as it is meant for extracting representations.', 'empirically we found that even with supervised training, a random initialized mockingjay model followed by any downstream model is hard to be trained from scratch.', 'this shows that the proposed pre - training is essentially indispensable']",5
"['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as they also experiment on phone classification and speaker verification.', 'as reported in  #TAUTHOR_TAG, the apc approach outperformed cpc representations [ 5, 7, 9 ] in both two tasks, which makes apc suitable as a strong baseline.', 'apc uses an unidirectional autoregressive model.', 'we compare the proposed approach with apc to show that our bidirectional approach has advantages in speech representation learning.', ""for fair comparison, we pre - train apc using their official implementations with the reported ideal parameters and settings, but expand the model's hidden size to h dim = 768 to match ours."", 'we also report results on 160 - dimensional log mel - features, which helps evaluate the accessibility of speech information from regular acoustic features']",5
"['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as']","['proposed approaches are mainly compared with apc  #TAUTHOR_TAG representations, as they also experiment on phone classification and speaker verification.', 'as reported in  #TAUTHOR_TAG, the apc approach outperformed cpc representations [ 5, 7, 9 ] in both two tasks, which makes apc suitable as a strong baseline.', 'apc uses an unidirectional autoregressive model.', 'we compare the proposed approach with apc to show that our bidirectional approach has advantages in speech representation learning.', ""for fair comparison, we pre - train apc using their official implementations with the reported ideal parameters and settings, but expand the model's hidden size to h dim = 768 to match ours."", 'we also report results on 160 - dimensional log mel - features, which helps evaluate the accessibility of speech information from regular acoustic features']",5
"['dependency parsing  #TAUTHOR_TAG.', 'in these approaches']","['dependency parsing  #TAUTHOR_TAG.', 'in these approaches']","['dependency parsing  #TAUTHOR_TAG.', 'in these approaches extraction patterns']","['', 'more recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing  #TAUTHOR_TAG.', '']",0
"['dependency parsing  #TAUTHOR_TAG.', 'in these approaches']","['dependency parsing  #TAUTHOR_TAG.', 'in these approaches']","['dependency parsing  #TAUTHOR_TAG.', 'in these approaches extraction patterns']","['', 'more recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing  #TAUTHOR_TAG.', '']",0
['subtree model  #TAUTHOR_TAG. in this model any subtree of a'],['subtree model  #TAUTHOR_TAG. in this model any subtree of a'],['subtrees : the final model to be considered is the subtree model  #TAUTHOR_TAG. in this model any subtree of a'],"['', 'a pair of chains which share the same verb', 'but no direct descendants. example linked chains are shown in figure 2. this pattern representation encodes most of the information in', 'the sentence with the advantage of being able to link together event participants which neither of the svo or chain model can, for example the relation between "" smith "" and "" blog', '##gs "" in figure 1. subtrees : the final model to be considered is the subtree model  #TAUTHOR_TAG. in this model any subtree of a dependency tree', 'can be used as an extraction pattern, where a subtree is any set of nodes in the', 'tree which are connected to one another. single nodes are not considered to be subtrees. the subtree model is a richer representation than those', 'discussed so far and can represent any part of a dependency tree. each of the previous models form a proper subset of the subtrees. by choosing an appropriate subtree it is possible to link together any pair of nodes in a tree and consequently this model']",0
['subtree model  #TAUTHOR_TAG. in this model any subtree of a'],['subtree model  #TAUTHOR_TAG. in this model any subtree of a'],['subtrees : the final model to be considered is the subtree model  #TAUTHOR_TAG. in this model any subtree of a'],"['', 'a pair of chains which share the same verb', 'but no direct descendants. example linked chains are shown in figure 2. this pattern representation encodes most of the information in', 'the sentence with the advantage of being able to link together event participants which neither of the svo or chain model can, for example the relation between "" smith "" and "" blog', '##gs "" in figure 1. subtrees : the final model to be considered is the subtree model  #TAUTHOR_TAG. in this model any subtree of a dependency tree', 'can be used as an extraction pattern, where a subtree is any set of nodes in the', 'tree which are connected to one another. single nodes are not considered to be subtrees. the subtree model is a richer representation than those', 'discussed so far and can represent any part of a dependency tree. each of the previous models form a proper subset of the subtrees. by choosing an appropriate subtree it is possible to link together any pair of nodes in a tree and consequently this model']",0
"['pattern models.', ' #TAUTHOR_TAG compared']","['pattern models.', ' #TAUTHOR_TAG compared']","['have been few direct comparisons of the various pattern models.', ' #TAUTHOR_TAG compared three models ( svo, chains']","['have been few direct comparisons of the various pattern models.', ' #TAUTHOR_TAG compared three models ( svo, chains and subtrees ) on two ie scenarios using a entity extraction task.', '']",0
"['pattern models.', ' #TAUTHOR_TAG compared']","['pattern models.', ' #TAUTHOR_TAG compared']","['have been few direct comparisons of the various pattern models.', ' #TAUTHOR_TAG compared three models ( svo, chains']","['have been few direct comparisons of the various pattern models.', ' #TAUTHOR_TAG compared three models ( svo, chains and subtrees ) on two ie scenarios using a entity extraction task.', '']",0
"['preferred.', ' #TAUTHOR_TAG found that it was important to find']","['preferred.', ' #TAUTHOR_TAG found that it was important to find']","['preferred.', ' #TAUTHOR_TAG found that it was important to find the appropriate balance between these two factors.', 'they introduced the β parameter as a way of']","['for each model are ranked using a technique inspired by the tf - idf scoring commonly used in information retrieval ( manning and schutze, 1999 ).', 'the score for each pattern, p, is given by :', 'where tf p is the number of times pattern p appears in relevant documents, n is the total number of documents in the corpus and df p the number of documents in the collection containing the pattern p.', 'equation 1 combines two factors : the term frequency ( in relevant documents ) and inverse document frequency ( across the corpus ).', 'patterns which occur frequently in relevant documents without being too prevalent in the corpus are preferred.', ' #TAUTHOR_TAG found that it was important to find the appropriate balance between these two factors.', 'they introduced the β parameter as a way of controlling the relative contribution of the inverse document frequency.', 'β is tuned for each extraction task and pattern model combination.', 'although simple, this approach has the advantage that it can be applied to each of the four pattern models to provide a direct comparison']",0
"[',  #TAUTHOR_TAG only generated']","['complete the experiments with less restrictive parameters.', 'in addition,  #TAUTHOR_TAG only generated']","[',  #TAUTHOR_TAG only generated']","['', 'they comment that the size of their data set meant that it would have been difficult to complete the experiments with less restrictive parameters.', 'in addition,  #TAUTHOR_TAG only generated subtrees which appeared in at least three documents.', ' #AUTHOR_TAG and  #TAUTHOR_TAG both used the rightmost extension algorithm to generate subtrees.', 'to provide a direct comparison of the pattern models we also produced versions of the sets of patterns extracted for the svo, chain and linked chain models in which patterns which occurred fewer than four times were removed.', 'table 1 shows the number of patterns generated for each of the four models when the patterns are both filtered and unfiltered. ( although the set of unfiltered subtree patterns were not generated it is possible to determine the number of patterns which would be generated using a process described by  #AUTHOR_TAG table 1 : number of patterns generated by each model it can be seen that the various pattern models generate vastly different numbers of patterns and that the number of subtrees is significantly greater than the other three models.', 'previous analysis ( see section 3 ) suggested that the number of']",0
"[',  #TAUTHOR_TAG only generated']","['complete the experiments with less restrictive parameters.', 'in addition,  #TAUTHOR_TAG only generated']","[',  #TAUTHOR_TAG only generated']","['', 'they comment that the size of their data set meant that it would have been difficult to complete the experiments with less restrictive parameters.', 'in addition,  #TAUTHOR_TAG only generated subtrees which appeared in at least three documents.', ' #AUTHOR_TAG and  #TAUTHOR_TAG both used the rightmost extension algorithm to generate subtrees.', 'to provide a direct comparison of the pattern models we also produced versions of the sets of patterns extracted for the svo, chain and linked chain models in which patterns which occurred fewer than four times were removed.', 'table 1 shows the number of patterns generated for each of the four models when the patterns are both filtered and unfiltered. ( although the set of unfiltered subtree patterns were not generated it is possible to determine the number of patterns which would be generated using a process described by  #AUTHOR_TAG table 1 : number of patterns generated by each model it can be seen that the various pattern models generate vastly different numbers of patterns and that the number of subtrees is significantly greater than the other three models.', 'previous analysis ( see section 3 ) suggested that the number of']",0
['subtree model  #TAUTHOR_TAG. in this model any subtree of a'],['subtree model  #TAUTHOR_TAG. in this model any subtree of a'],['subtrees : the final model to be considered is the subtree model  #TAUTHOR_TAG. in this model any subtree of a'],"['', 'a pair of chains which share the same verb', 'but no direct descendants. example linked chains are shown in figure 2. this pattern representation encodes most of the information in', 'the sentence with the advantage of being able to link together event participants which neither of the svo or chain model can, for example the relation between "" smith "" and "" blog', '##gs "" in figure 1. subtrees : the final model to be considered is the subtree model  #TAUTHOR_TAG. in this model any subtree of a dependency tree', 'can be used as an extraction pattern, where a subtree is any set of nodes in the', 'tree which are connected to one another. single nodes are not considered to be subtrees. the subtree model is a richer representation than those', 'discussed so far and can represent any part of a dependency tree. each of the previous models form a proper subset of the subtrees. by choosing an appropriate subtree it is possible to link together any pair of nodes in a tree and consequently this model']",5
"['described by  #TAUTHOR_TAG.', 'let']","['described by  #TAUTHOR_TAG.', 'let']","['described by  #TAUTHOR_TAG.', 'let']","['compared each of the patterns models described in section 2 using an unsupervised ie experiment similar to one described by  #TAUTHOR_TAG.', 'let d be a corpus of documents and r a set of documents which are relevant to a particular extraction task.', 'in this context "" relevant "" means that the document contains the information we are interested in identifying.', 'd and r are such that d = r ∪r and r∩r = ∅. as assumption behind this approach is that useful patterns will be far more likely to occur in r than d overall']",5
"['by  #TAUTHOR_TAG.', 'to generate this additional text we used the re']","['by  #TAUTHOR_TAG.', 'to generate this additional text we used the reuters corpus  #AUTHOR_TAG which']","['by  #TAUTHOR_TAG.', 'to generate this additional text we used the reuters corpus  #AUTHOR_TAG which']","['value of β in equation 1 was set using a separate corpus from which the patterns were generated, a methodology suggested by  #TAUTHOR_TAG.', ""to generate this additional text we used the reuters corpus  #AUTHOR_TAG which consists of a year's worth of newswire output."", 'each document in the reuters corpus has been manually annotated with topic codes indicating its general subject area ( s ).', 'one of these topic codes ( c411 ) refers to management succession events and was used to identify documents which are relevant to the muc6 ie scenario.', 'a corpus consisting of 348 documents annotated with code c411 and 250 documents without that code, representing irrelevant documents, were taken from the reuters corpus to create a corpus with the same distribution of relevant and irrelevant documents as found in the muc - 6 corpus.', 'unlike the muc - 6 corpus, items belonging to the required semantic classes are not annotated in the reuters corpus.', 'they were identified automatically using a named entity identifier.', 'the patterns generated from the muc - 6 texts were ranked using formula 1 with a variety of values of β.', 'these sets of ranked patterns were then used to carry out a document filtering task on the reuters corpus - the aim of which is to differentiate documents based on whether or not they contain a relation of interest.', 'the various values for β were compared by computing the area under the curve.', 'it was found that the optimal value for β was 2 for all pattern models and this setting was used for the experiments']",5
[' #TAUTHOR_TAG showed that adequate'],[' #TAUTHOR_TAG showed that adequate'],[' #TAUTHOR_TAG showed that adequate knowledge about document relevance could be obtained automatically using an ir system'],"['', 'this sentence described as event involving three items : a person ( smith ), position ( ceo ) and company ( rooter ltd ).', 'we made use of a version of the muc - 6 corpus described by  #AUTHOR_TAG which consists of 598 documents.', 'for these experiments relevant documents were identified using annotations in the corpus.', 'however, this is not necessary since  #TAUTHOR_TAG showed that adequate knowledge about document relevance could be obtained automatically using an ir system']",4
['of  #TAUTHOR_TAG and  #AUTHOR_TAG on entity mention'],['of  #TAUTHOR_TAG and  #AUTHOR_TAG on entity mention'],['hypergraph model of  #TAUTHOR_TAG and  #AUTHOR_TAG on entity mention recognition for the ace2004 and ace'],"['', 'we present a modification to the standard lstm - based sequence labeling model that handles both problems and operates linearly in the number of tokens and the number of possible output labels at any token.', 'the proposed neural network approach additionally jointly models entity mention head 2 information, a subtask found to be useful for many information extraction applications.', 'our model significantly outperforms the previously mentioned hypergraph model of  #TAUTHOR_TAG and  #AUTHOR_TAG on entity mention recognition for the ace2004 and ace2005 corpora.', '']",4
['system  #TAUTHOR_TAG on'],['state - of - the - art system  #TAUTHOR_TAG on'],[' #TAUTHOR_TAG on'],"['show the performance of our approaches in table 1 compared to the previous state - of - the - art system  #TAUTHOR_TAG on both the ace2004 and ace2005 datasets.', 'we find that our lstm - flat baseline that ignores embedded entity mentions during training performs worse than  #TAUTHOR_TAG ; however, our other neural network - based approaches all outperform the previous feature - based approach.', 'among the neural network - based models, we find that our models that construct a hypergraph perform better than the lstm - flat models.', '']",4
"['we use pretrained word embeddings 5 trained on pubmed data  #AUTHOR_TAG whereas  #TAUTHOR_TAG did not have access to them.', 'we again find that our neural network model outperforms']","['we use pretrained word embeddings 5 trained on pubmed data  #AUTHOR_TAG whereas  #TAUTHOR_TAG did not have access to them.', 'we again find that our neural network model outperforms']","['we use pretrained word embeddings 5 trained on pubmed data  #AUTHOR_TAG whereas  #TAUTHOR_TAG did not have access to them.', 'we again find that our neural network model outperforms the previous state - of - the - art  #AUTHOR_TAG system.', 'however, we see that both softmax and sparsemax models perform comparably on this dataset']","['.', 'we suspect that it is because we use pretrained word embeddings 5 trained on pubmed data  #AUTHOR_TAG whereas  #TAUTHOR_TAG did not have access to them.', 'we again find that our neural network model outperforms the previous state - of - the - art  #AUTHOR_TAG system.', 'however, we see that both softmax and sparsemax models perform comparably on this dataset']",4
['a feature based mention hypergraph model  #TAUTHOR_TAG and'],['a feature based mention hypergraph model  #TAUTHOR_TAG and'],"['a feature based mention hypergraph model  #TAUTHOR_TAG and a recent multigraph model  #AUTHOR_TAG on the ace dataset.', 'our']","['this paper, we present a novel recurrent network - based model for nested named entity recognition and nested entity mention detection.', 'we propose a hypergraph representation for this problem and learn the structure using an lstm network in a greedy manner.', 'we show that our model significantly outperforms a feature based mention hypergraph model  #TAUTHOR_TAG and a recent multigraph model  #AUTHOR_TAG on the ace dataset.', 'our model also outperforms the constituency parser - based approach of  #AUTHOR_TAG on the genia dataset.', 'in future work, it would be interesting to learn global dependencies between the output labels for such a hypergraph structure and training the model globally.', 'we can also experiment with different representations such as the one in  #AUTHOR_TAG and use the recent advances in neural network approaches  #AUTHOR_TAG to learn the constituency parse tree efficiently.', 'interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of nsf, darpa or the u. s. government']",4
"[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']","[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']","[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']",[' #TAUTHOR_TAG'],3
"['timestep to model the possibility of beginning of a new entity.', 'the need for this will become more clear in section 4.', 'note that the hypergraph representation of our model is similar to  #TAUTHOR_TAG']","['timestep to model the possibility of beginning of a new entity.', 'the need for this will become more clear in section 4.', 'note that the hypergraph representation of our model is similar to  #TAUTHOR_TAG']","['the token "" his "" which did not appear in any entity output sequence in figure 1 : in our task - specific hypergraph construction we make sure that there is an "" o "" node at every timestep to model the possibility of beginning of a new entity.', 'the need for this will become more clear in section 4.', 'note that the hypergraph representation of our model is similar to  #TAUTHOR_TAG.', 'also, the expressiveness of our model is exactly']","['', 'if we look closely at figure 2 then we realise that there is an extra "" o "" node in the hypergraph corresponding to the token "" his "" which did not appear in any entity output sequence in figure 1 : in our task - specific hypergraph construction we make sure that there is an "" o "" node at every timestep to model the possibility of beginning of a new entity.', 'the need for this will become more clear in section 4.', 'note that the hypergraph representation of our model is similar to  #TAUTHOR_TAG.', 'also, the expressiveness of our model is exactly the same as  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'the major difference in the two approaches is in learning']",3
"['timestep to model the possibility of beginning of a new entity.', 'the need for this will become more clear in section 4.', 'note that the hypergraph representation of our model is similar to  #TAUTHOR_TAG']","['timestep to model the possibility of beginning of a new entity.', 'the need for this will become more clear in section 4.', 'note that the hypergraph representation of our model is similar to  #TAUTHOR_TAG']","['the token "" his "" which did not appear in any entity output sequence in figure 1 : in our task - specific hypergraph construction we make sure that there is an "" o "" node at every timestep to model the possibility of beginning of a new entity.', 'the need for this will become more clear in section 4.', 'note that the hypergraph representation of our model is similar to  #TAUTHOR_TAG.', 'also, the expressiveness of our model is exactly']","['', 'if we look closely at figure 2 then we realise that there is an extra "" o "" node in the hypergraph corresponding to the token "" his "" which did not appear in any entity output sequence in figure 1 : in our task - specific hypergraph construction we make sure that there is an "" o "" node at every timestep to model the possibility of beginning of a new entity.', 'the need for this will become more clear in section 4.', 'note that the hypergraph representation of our model is similar to  #TAUTHOR_TAG.', 'also, the expressiveness of our model is exactly the same as  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'the major difference in the two approaches is in learning']",3
['use a strict evaluation metric similar to  #TAUTHOR_TAG : an'],['use a strict evaluation metric similar to  #TAUTHOR_TAG : an'],['use a strict evaluation metric similar to  #TAUTHOR_TAG : an entity mention is considered correct if both the mention span'],"['use a strict evaluation metric similar to  #TAUTHOR_TAG : an entity mention is considered correct if both the mention span and the mention type are exactly correct.', 'similarly, for the task of joint extraction of entity mentions and mention heads, the mention span, head span and the entity type should all exactly match the gold label']",3
"['dataset split as  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'thus, the first 90']","['dataset split as  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'thus, the first 90 % of the sentences were used in training and the remaining 10 % were used for evaluation.', 'we also']","['', 'we follow the same dataset split as  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'thus, the first 90']","['also evaluate our model on the genia dataset  #AUTHOR_TAG for nested named entity recognition.', 'we follow the same dataset split as  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'thus, the first 90 % of the sentences were used in training and the remaining 10 % were used for evaluation.', 'we also consider five entity types - dna, rna, protein, cell line and cell type']",3
"[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']","[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']","[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']",[' #TAUTHOR_TAG'],0
"[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']","[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']","[' #TAUTHOR_TAG.', 'directed hypergraphs were also introduced']",[' #TAUTHOR_TAG'],5
"['dataset split as  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'thus, the first 90']","['dataset split as  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'thus, the first 90 % of the sentences were used in training and the remaining 10 % were used for evaluation.', 'we also']","['', 'we follow the same dataset split as  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'thus, the first 90']","['also evaluate our model on the genia dataset  #AUTHOR_TAG for nested named entity recognition.', 'we follow the same dataset split as  #AUTHOR_TAG ;  #TAUTHOR_TAG ;  #AUTHOR_TAG.', 'thus, the first 90 % of the sentences were used in training and the remaining 10 % were used for evaluation.', 'we also consider five entity types - dna, rna, protein, cell line and cell type']",5
['structure  #TAUTHOR_TAG on'],['( mh - f ) on hypergraph structure  #TAUTHOR_TAG on'],['model with the feature - based model ( mh - f ) on hypergraph structure  #TAUTHOR_TAG on both entity mention detection as well as the joint mention and mention heads'],"['compare our model with the feature - based model ( mh - f ) on hypergraph structure  #TAUTHOR_TAG on both entity mention detection as well as the joint mention and mention heads extraction.', 'we also compare with  #AUTHOR_TAG on entity mention detection only as their model cannot detect head phrases of the entity mentions.', ' #AUTHOR_TAG compare their approach with crf - based approaches such as a linear - chain crf, semi - markov crf and a cascaded approach  #AUTHOR_TAG and show that their model outperforms them.', 'hence, we do not include those results in our paper.', 'we also implement several lstm - based baselines for comparison.', 'our first baseline is a standard sequence labeling lstm model ( lstm - flat ).', 'a sequence model is not capable of handling the nested mentions, so we remove the embedded entity mention and keep the mention longer in length.', 'our second baseline is a hypergraph model ( lstm - output layer ) except that the dependencies are only modeled at the output layer and hence there are no connections to the tophidden layer from the label embeddings from the previous timestep ; instead, these connections are limited to the output layer']",7
['system  #TAUTHOR_TAG on'],['state - of - the - art system  #TAUTHOR_TAG on'],[' #TAUTHOR_TAG on'],"['show the performance of our approaches in table 1 compared to the previous state - of - the - art system  #TAUTHOR_TAG on both the ace2004 and ace2005 datasets.', 'we find that our lstm - flat baseline that ignores embedded entity mentions during training performs worse than  #TAUTHOR_TAG ; however, our other neural network - based approaches all outperform the previous feature - based approach.', 'among the neural network - based models, we find that our models that construct a hypergraph perform better than the lstm - flat models.', '']",7
['parser and the mention hypergraph model by  #TAUTHOR_TAG'],['compare our model with  #AUTHOR_TAG based on a constituency crf - based parser and the mention hypergraph model by  #TAUTHOR_TAG'],['compare our model with  #AUTHOR_TAG based on a constituency crf - based parser and the mention hypergraph model by  #TAUTHOR_TAG'],"['compare our model with  #AUTHOR_TAG based on a constituency crf - based parser and the mention hypergraph model by  #TAUTHOR_TAG and a recent multigraph model by  #AUTHOR_TAG.', 'table 3 : performance on the genia dataset on nested named entity recognition']",7
"[')  #TAUTHOR_TAG.', 'ol']","[' #TAUTHOR_TAG.', 'olid is an annotated']","[')  #TAUTHOR_TAG.', 'ol']","['automatic identification of offensive content online is an important task which has gained more attention in recent years.', 'social media platforms such as facebook and twitter have been investing heavily in ways to cope with the widespread forms of such content.', 'the task is usually modelled as supervised classification problem in which systems are trained using a dataset containing posts which are annotated with respect to the presence of some form ( s ) of abusive or offensive content.', 'examples of offensive content investigated in previous studies include hate speech  #AUTHOR_TAG 2018 ), cyberbulling  #AUTHOR_TAG, and aggression  #AUTHOR_TAG.', 'given the multitude of terms and definitions used in the literature, recent studies have investigated common aspects of the abusive language detection sub - tasks  #AUTHOR_TAG.', 'however, none of these initial studies focused on both the type and the target of the offensive language.', 'therefore, in conjunction with this task, we present the offensive language identification dataset ( olid )  #TAUTHOR_TAG.', 'olid is an annotated dataset with a three - level annotation model.', 'we show that breaking down offensive content into sub - categories by taking the type and target of offenses into account results in a flexible annotation model that can relate to the phenomena captured by previously annotated datasets such as the one by.', 'hate speech, for example, is commonly understood as an insult targeted at a group whereas cyberbulling is typically targeted at an individual ).', 'in offenseval 1 we use olid  #TAUTHOR_TAG and propose one sub - task for each layer of annotation as presented in section 3.', 'the remainder of this paper is organized as follows : section 3 presents the shared task description and the sub - tasks included in offenseval and section 4 includes a brief description of olid based on  #TAUTHOR_TAG.', '']",3
"[')  #TAUTHOR_TAG.', 'ol']","[' #TAUTHOR_TAG.', 'olid is an annotated']","[')  #TAUTHOR_TAG.', 'ol']","['automatic identification of offensive content online is an important task which has gained more attention in recent years.', 'social media platforms such as facebook and twitter have been investing heavily in ways to cope with the widespread forms of such content.', 'the task is usually modelled as supervised classification problem in which systems are trained using a dataset containing posts which are annotated with respect to the presence of some form ( s ) of abusive or offensive content.', 'examples of offensive content investigated in previous studies include hate speech  #AUTHOR_TAG 2018 ), cyberbulling  #AUTHOR_TAG, and aggression  #AUTHOR_TAG.', 'given the multitude of terms and definitions used in the literature, recent studies have investigated common aspects of the abusive language detection sub - tasks  #AUTHOR_TAG.', 'however, none of these initial studies focused on both the type and the target of the offensive language.', 'therefore, in conjunction with this task, we present the offensive language identification dataset ( olid )  #TAUTHOR_TAG.', 'olid is an annotated dataset with a three - level annotation model.', 'we show that breaking down offensive content into sub - categories by taking the type and target of offenses into account results in a flexible annotation model that can relate to the phenomena captured by previously annotated datasets such as the one by.', 'hate speech, for example, is commonly understood as an insult targeted at a group whereas cyberbulling is typically targeted at an individual ).', 'in offenseval 1 we use olid  #TAUTHOR_TAG and propose one sub - task for each layer of annotation as presented in section 3.', 'the remainder of this paper is organized as follows : section 3 presents the shared task description and the sub - tasks included in offenseval and section 4 includes a brief description of olid based on  #TAUTHOR_TAG.', '']",3
"['share similar properties and the hierarchical annotation model pro - posed proposed in olid  #TAUTHOR_TAG and used in offenseval aims to capture this.', 'considering that, for example, an insult targeted at an individual is commonly known as cyberbul']","['share similar properties and the hierarchical annotation model pro - posed proposed in olid  #TAUTHOR_TAG and used in offenseval aims to capture this.', 'considering that, for example, an insult targeted at an individual is commonly known as cyberbul']","['share similar properties and the hierarchical annotation model pro - posed proposed in olid  #TAUTHOR_TAG and used in offenseval aims to capture this.', 'considering that, for example, an insult targeted at an individual is commonly known as cyberbul']","['abusive and offense language identification sub - tasks have been explored in the past few years including aggression identification, bullying detection, hate speech, toxic comments, and offensive language.', 'aggression identification : the trac shared task on aggression identification  #AUTHOR_TAG provided participants with a dataset containing 15, 000 annotated facebook posts and com - ments in english and hindi for training and validation.', 'for testing, two different sets, one from facebook and one from twitter were provided.', 'systems were trained to discriminate between three classes : non - aggressive, covertly aggressive, and overtly aggressive.', 'the best performing systems in this competition used deep learning approaches based on convolutional neural networks ( cnn ), recurrent neural networks, and lstms  #AUTHOR_TAG.', 'bullying detection : several studies have been published on bullying detection.', 'one of them is the one by  #AUTHOR_TAG which apply sentiment analysis to detect bullying in tweets.', ' #AUTHOR_TAG use topic models to to identify relevant topics in bullying.', 'another related study is the one by  #AUTHOR_TAG which use user - related features such as the frequency of profanity in previous messages to improve bullying detection.', 'hate speech identification : it is perhaps the most widespread abusive language detection subtask.', ""there have been several studies published on this sub - task such as  #AUTHOR_TAG and  #AUTHOR_TAG who build a binary classifier to distinguish between'clean'comments and comments containing hate speech and profanity."", 'more recently, presented the hate speech detection dataset containing over 24, 000 english tweets labeled as non offensive, hate speech, and profanity.', 'offensive language : the germeval 2  #AUTHOR_TAG shared task focused on offensive language identification in german tweets.', 'a dataset of over 8, 500 annotated tweets was provided for a course - grained binary classification task in which systems were trained to discriminate between offensive and non - offensive tweets and a second task where the organizers broke down the offensive class into three classes : profanity, insult, and abuse.', 'toxic comments : the toxic comment classification challenge was an open competition at kaggle which provided participants with comments from wikipedia labeled in six classes : toxic, severe toxic, obscene, threat, insult, identity hate.', 'while each of these sub - tasks tackle a particular type of abuse or offense, they share similar properties and the hierarchical annotation model pro - posed proposed in olid  #TAUTHOR_TAG and used in offenseval aims to capture this.', 'considering that, for example, an insult targeted at an individual is commonly known as cyberbul']",3
"['was annotated using a hierarchical three - level annotation model introduced in  #TAUTHOR_TAG.', 'we use the annotation of']","['training and testing material used for offenseval is the aforementioned offensive language identification dataset ( olid ) dataset, built for this task.', 'olid was annotated using a hierarchical three - level annotation model introduced in  #TAUTHOR_TAG.', 'we use the annotation of']","['was annotated using a hierarchical three - level annotation model introduced in  #TAUTHOR_TAG.', 'we use the annotation of']","['training and testing material used for offenseval is the aforementioned offensive language identification dataset ( olid ) dataset, built for this task.', 'olid was annotated using a hierarchical three - level annotation model introduced in  #TAUTHOR_TAG.', 'we use the annotation of each of the three layers in olid to each sub - task in offenseval as follows']",3
"['of the data collection process and annotation is presented in  #TAUTHOR_TAG.', 'olid is a large']","['of the data collection process and annotation is presented in  #TAUTHOR_TAG.', 'olid is a large']","['this section we summarize olid, the dataset used for this task.', 'a detailed description of the data collection process and annotation is presented in  #TAUTHOR_TAG.', 'olid is a large collection of english tweets annotated using a hierarchical three - layer annotation model.', 'it contains 14, 100 annotated tweets divided in a training partition containing 13, 240 tweets and a test partition containing 860 tweets.', 'additionally, a small trial set containing 320 tweets was made available before the start of the competition.', 'the distribution of the labels in olid is shown in table 1.', 'we annotated the dataset using the crowdsourcing platform figure eight four examples of annotated instances in the dataset are presented in table 2']","['this section we summarize olid, the dataset used for this task.', 'a detailed description of the data collection process and annotation is presented in  #TAUTHOR_TAG.', 'olid is a large collection of english tweets annotated using a hierarchical three - layer annotation model.', 'it contains 14, 100 annotated tweets divided in a training partition containing 13, 240 tweets and a test partition containing 860 tweets.', 'additionally, a small trial set containing 320 tweets was made available before the start of the competition.', 'the distribution of the labels in olid is shown in table 1.', 'we annotated the dataset using the crowdsourcing platform figure eight four examples of annotated instances in the dataset are presented in table 2']",3
"['we used olid  #TAUTHOR_TAG, a']","['we used olid  #TAUTHOR_TAG, a']","['we used olid  #TAUTHOR_TAG, a dataset containing english tweets annotated with a hierarchical three - layer annotation model']","['this paper, we presented the results of semeval - 2016 task 6 : identifying and categorizing offensive language in social media ( offenseval ).', 'in offenseval we used olid  #TAUTHOR_TAG, a dataset containing english tweets annotated with a hierarchical three - layer annotation model which considers 1 ) whether a message is offensive or not ( sub - task a ) ; 2 ) what is the type of the offensive 7 in the camera - ready version of this report we will be including a table with references to all system descriptions papers.', 'message ( sub - task b ) ; and 3 ) what is the target of the offensive ( sub - task c ).', 'olid is publicly available to the research community.', '8 in total, nearly 800 teams signed up to participate in offenseval and 115 of them submitted results across the three sub - tasks.', 'in section 5 we discussed the approaches used by the 115 teams in the shared task.', 'we observed that both deep learning and traditional ml classifiers and classifier ensembles have been widely use and that most high - performing systems used state - of - theart deep learning models, in particular bert  #AUTHOR_TAG.', 'our public dataset can continue to be used to explore future advances in detecting offensive content and provide a a benchmark for evaluating different models.', 'in the future, we plan to release additional content to address the class imbalance and small test size, particularly in subtasks b and c']",3
"[')  #TAUTHOR_TAG.', 'ol']","[' #TAUTHOR_TAG.', 'olid is an annotated']","[')  #TAUTHOR_TAG.', 'ol']","['automatic identification of offensive content online is an important task which has gained more attention in recent years.', 'social media platforms such as facebook and twitter have been investing heavily in ways to cope with the widespread forms of such content.', 'the task is usually modelled as supervised classification problem in which systems are trained using a dataset containing posts which are annotated with respect to the presence of some form ( s ) of abusive or offensive content.', 'examples of offensive content investigated in previous studies include hate speech  #AUTHOR_TAG 2018 ), cyberbulling  #AUTHOR_TAG, and aggression  #AUTHOR_TAG.', 'given the multitude of terms and definitions used in the literature, recent studies have investigated common aspects of the abusive language detection sub - tasks  #AUTHOR_TAG.', 'however, none of these initial studies focused on both the type and the target of the offensive language.', 'therefore, in conjunction with this task, we present the offensive language identification dataset ( olid )  #TAUTHOR_TAG.', 'olid is an annotated dataset with a three - level annotation model.', 'we show that breaking down offensive content into sub - categories by taking the type and target of offenses into account results in a flexible annotation model that can relate to the phenomena captured by previously annotated datasets such as the one by.', 'hate speech, for example, is commonly understood as an insult targeted at a group whereas cyberbulling is typically targeted at an individual ).', 'in offenseval 1 we use olid  #TAUTHOR_TAG and propose one sub - task for each layer of annotation as presented in section 3.', 'the remainder of this paper is organized as follows : section 3 presents the shared task description and the sub - tasks included in offenseval and section 4 includes a brief description of olid based on  #TAUTHOR_TAG.', '']",4
"[')  #TAUTHOR_TAG.', 'ol']","[' #TAUTHOR_TAG.', 'olid is an annotated']","[')  #TAUTHOR_TAG.', 'ol']","['automatic identification of offensive content online is an important task which has gained more attention in recent years.', 'social media platforms such as facebook and twitter have been investing heavily in ways to cope with the widespread forms of such content.', 'the task is usually modelled as supervised classification problem in which systems are trained using a dataset containing posts which are annotated with respect to the presence of some form ( s ) of abusive or offensive content.', 'examples of offensive content investigated in previous studies include hate speech  #AUTHOR_TAG 2018 ), cyberbulling  #AUTHOR_TAG, and aggression  #AUTHOR_TAG.', 'given the multitude of terms and definitions used in the literature, recent studies have investigated common aspects of the abusive language detection sub - tasks  #AUTHOR_TAG.', 'however, none of these initial studies focused on both the type and the target of the offensive language.', 'therefore, in conjunction with this task, we present the offensive language identification dataset ( olid )  #TAUTHOR_TAG.', 'olid is an annotated dataset with a three - level annotation model.', 'we show that breaking down offensive content into sub - categories by taking the type and target of offenses into account results in a flexible annotation model that can relate to the phenomena captured by previously annotated datasets such as the one by.', 'hate speech, for example, is commonly understood as an insult targeted at a group whereas cyberbulling is typically targeted at an individual ).', 'in offenseval 1 we use olid  #TAUTHOR_TAG and propose one sub - task for each layer of annotation as presented in section 3.', 'the remainder of this paper is organized as follows : section 3 presents the shared task description and the sub - tasks included in offenseval and section 4 includes a brief description of olid based on  #TAUTHOR_TAG.', '']",6
"[')  #TAUTHOR_TAG.', 'ol']","[' #TAUTHOR_TAG.', 'olid is an annotated']","[')  #TAUTHOR_TAG.', 'ol']","['automatic identification of offensive content online is an important task which has gained more attention in recent years.', 'social media platforms such as facebook and twitter have been investing heavily in ways to cope with the widespread forms of such content.', 'the task is usually modelled as supervised classification problem in which systems are trained using a dataset containing posts which are annotated with respect to the presence of some form ( s ) of abusive or offensive content.', 'examples of offensive content investigated in previous studies include hate speech  #AUTHOR_TAG 2018 ), cyberbulling  #AUTHOR_TAG, and aggression  #AUTHOR_TAG.', 'given the multitude of terms and definitions used in the literature, recent studies have investigated common aspects of the abusive language detection sub - tasks  #AUTHOR_TAG.', 'however, none of these initial studies focused on both the type and the target of the offensive language.', 'therefore, in conjunction with this task, we present the offensive language identification dataset ( olid )  #TAUTHOR_TAG.', 'olid is an annotated dataset with a three - level annotation model.', 'we show that breaking down offensive content into sub - categories by taking the type and target of offenses into account results in a flexible annotation model that can relate to the phenomena captured by previously annotated datasets such as the one by.', 'hate speech, for example, is commonly understood as an insult targeted at a group whereas cyberbulling is typically targeted at an individual ).', 'in offenseval 1 we use olid  #TAUTHOR_TAG and propose one sub - task for each layer of annotation as presented in section 3.', 'the remainder of this paper is organized as follows : section 3 presents the shared task description and the sub - tasks included in offenseval and section 4 includes a brief description of olid based on  #TAUTHOR_TAG.', '']",5
"['share similar properties and the hierarchical annotation model pro - posed proposed in olid  #TAUTHOR_TAG and used in offenseval aims to capture this.', 'considering that, for example, an insult targeted at an individual is commonly known as cyberbul']","['share similar properties and the hierarchical annotation model pro - posed proposed in olid  #TAUTHOR_TAG and used in offenseval aims to capture this.', 'considering that, for example, an insult targeted at an individual is commonly known as cyberbul']","['share similar properties and the hierarchical annotation model pro - posed proposed in olid  #TAUTHOR_TAG and used in offenseval aims to capture this.', 'considering that, for example, an insult targeted at an individual is commonly known as cyberbul']","['abusive and offense language identification sub - tasks have been explored in the past few years including aggression identification, bullying detection, hate speech, toxic comments, and offensive language.', 'aggression identification : the trac shared task on aggression identification  #AUTHOR_TAG provided participants with a dataset containing 15, 000 annotated facebook posts and com - ments in english and hindi for training and validation.', 'for testing, two different sets, one from facebook and one from twitter were provided.', 'systems were trained to discriminate between three classes : non - aggressive, covertly aggressive, and overtly aggressive.', 'the best performing systems in this competition used deep learning approaches based on convolutional neural networks ( cnn ), recurrent neural networks, and lstms  #AUTHOR_TAG.', 'bullying detection : several studies have been published on bullying detection.', 'one of them is the one by  #AUTHOR_TAG which apply sentiment analysis to detect bullying in tweets.', ' #AUTHOR_TAG use topic models to to identify relevant topics in bullying.', 'another related study is the one by  #AUTHOR_TAG which use user - related features such as the frequency of profanity in previous messages to improve bullying detection.', 'hate speech identification : it is perhaps the most widespread abusive language detection subtask.', ""there have been several studies published on this sub - task such as  #AUTHOR_TAG and  #AUTHOR_TAG who build a binary classifier to distinguish between'clean'comments and comments containing hate speech and profanity."", 'more recently, presented the hate speech detection dataset containing over 24, 000 english tweets labeled as non offensive, hate speech, and profanity.', 'offensive language : the germeval 2  #AUTHOR_TAG shared task focused on offensive language identification in german tweets.', 'a dataset of over 8, 500 annotated tweets was provided for a course - grained binary classification task in which systems were trained to discriminate between offensive and non - offensive tweets and a second task where the organizers broke down the offensive class into three classes : profanity, insult, and abuse.', 'toxic comments : the toxic comment classification challenge was an open competition at kaggle which provided participants with comments from wikipedia labeled in six classes : toxic, severe toxic, obscene, threat, insult, identity hate.', 'while each of these sub - tasks tackle a particular type of abuse or offense, they share similar properties and the hierarchical annotation model pro - posed proposed in olid  #TAUTHOR_TAG and used in offenseval aims to capture this.', 'considering that, for example, an insult targeted at an individual is commonly known as cyberbul']",5
"['was annotated using a hierarchical three - level annotation model introduced in  #TAUTHOR_TAG.', 'we use the annotation of']","['training and testing material used for offenseval is the aforementioned offensive language identification dataset ( olid ) dataset, built for this task.', 'olid was annotated using a hierarchical three - level annotation model introduced in  #TAUTHOR_TAG.', 'we use the annotation of']","['was annotated using a hierarchical three - level annotation model introduced in  #TAUTHOR_TAG.', 'we use the annotation of']","['training and testing material used for offenseval is the aforementioned offensive language identification dataset ( olid ) dataset, built for this task.', 'olid was annotated using a hierarchical three - level annotation model introduced in  #TAUTHOR_TAG.', 'we use the annotation of each of the three layers in olid to each sub - task in offenseval as follows']",5
"['of the data collection process and annotation is presented in  #TAUTHOR_TAG.', 'olid is a large']","['of the data collection process and annotation is presented in  #TAUTHOR_TAG.', 'olid is a large']","['this section we summarize olid, the dataset used for this task.', 'a detailed description of the data collection process and annotation is presented in  #TAUTHOR_TAG.', 'olid is a large collection of english tweets annotated using a hierarchical three - layer annotation model.', 'it contains 14, 100 annotated tweets divided in a training partition containing 13, 240 tweets and a test partition containing 860 tweets.', 'additionally, a small trial set containing 320 tweets was made available before the start of the competition.', 'the distribution of the labels in olid is shown in table 1.', 'we annotated the dataset using the crowdsourcing platform figure eight four examples of annotated instances in the dataset are presented in table 2']","['this section we summarize olid, the dataset used for this task.', 'a detailed description of the data collection process and annotation is presented in  #TAUTHOR_TAG.', 'olid is a large collection of english tweets annotated using a hierarchical three - layer annotation model.', 'it contains 14, 100 annotated tweets divided in a training partition containing 13, 240 tweets and a test partition containing 860 tweets.', 'additionally, a small trial set containing 320 tweets was made available before the start of the competition.', 'the distribution of the labels in olid is shown in table 1.', 'we annotated the dataset using the crowdsourcing platform figure eight four examples of annotated instances in the dataset are presented in table 2']",5
"['we used olid  #TAUTHOR_TAG, a']","['we used olid  #TAUTHOR_TAG, a']","['we used olid  #TAUTHOR_TAG, a dataset containing english tweets annotated with a hierarchical three - layer annotation model']","['this paper, we presented the results of semeval - 2016 task 6 : identifying and categorizing offensive language in social media ( offenseval ).', 'in offenseval we used olid  #TAUTHOR_TAG, a dataset containing english tweets annotated with a hierarchical three - layer annotation model which considers 1 ) whether a message is offensive or not ( sub - task a ) ; 2 ) what is the type of the offensive 7 in the camera - ready version of this report we will be including a table with references to all system descriptions papers.', 'message ( sub - task b ) ; and 3 ) what is the target of the offensive ( sub - task c ).', 'olid is publicly available to the research community.', '8 in total, nearly 800 teams signed up to participate in offenseval and 115 of them submitted results across the three sub - tasks.', 'in section 5 we discussed the approaches used by the 115 teams in the shared task.', 'we observed that both deep learning and traditional ml classifiers and classifier ensembles have been widely use and that most high - performing systems used state - of - theart deep learning models, in particular bert  #AUTHOR_TAG.', 'our public dataset can continue to be used to explore future advances in detecting offensive content and provide a a benchmark for evaluating different models.', 'in the future, we plan to release additional content to address the class imbalance and small test size, particularly in subtasks b and c']",5
"['of  #TAUTHOR_TAG, which contains 1,']","['of  #TAUTHOR_TAG, which contains 1, 348 sentences taken from different parts of the british national corpus.', 'however, they only focused on vpcs in this dataset, where']","['to compare the performance of our system with others, we also used the dataset of  #TAUTHOR_TAG, which contains 1,']","['evaluate of our methods, we made use of two corpora.', 'statistical data on the corpora can be seen in table 1.', 'first, we used wiki50, in which several types of multiword expressions ( including vpcs ) and named entities were marked.', 'this corpus consists of 50 wikipedia pages, and contains 466 occurrences of vpcs.', 'in order to compare the performance of our system with others, we also used the dataset of  #TAUTHOR_TAG, which contains 1, 348 sentences taken from different parts of the british national corpus.', 'however, they only focused on vpcs in this dataset, where 65 % of the sentences contain a phrasal verb and 35 % contain a simplex verbpreposition combination.', 'as table 1 indicates, the tu & roth dataset only focused on 23 different vpcs, but 342 unique vpcs were annotated in the wiki50 corpus']",5
"['methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['machines ( svm )  #AUTHOR_TAG results are also reported to compare the performance of our methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['the weka package  #AUTHOR_TAG was trained with its default settings on the abovementioned feature set, which implements the c4. 5  #AUTHOR_TAG decision tree', 'algorithm. moreover, support vector machines ( svm )  #AUTHOR_TAG results are also reported to compare the performance of our methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not sufficiently large for splitting them into training and test sets', 'of appropriate size, we evaluated our models in a cross validation manner on the wiki50 corpus and', 'the tu & roth dataset. as  #TAUTHOR_TAG presented only the accuracy scores on the tu & roth dataset, we also employed an accuracy score as an evaluation metric on this dataset, where positive and negative examples were also marked', '. but, in the case of wiki50 corpus, where only the positive vpcs were manually annotated, the f β = 1 score was employed and interpreted on', 'the positive class as an evaluation metric. moreover, all potential vpcs were treated as negative that were', 'extracted by the candidate extraction method but were not marked as positive in the gold standard. thus,', '']",5
"['methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['machines ( svm )  #AUTHOR_TAG results are also reported to compare the performance of our methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['the weka package  #AUTHOR_TAG was trained with its default settings on the abovementioned feature set, which implements the c4. 5  #AUTHOR_TAG decision tree', 'algorithm. moreover, support vector machines ( svm )  #AUTHOR_TAG results are also reported to compare the performance of our methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not sufficiently large for splitting them into training and test sets', 'of appropriate size, we evaluated our models in a cross validation manner on the wiki50 corpus and', 'the tu & roth dataset. as  #TAUTHOR_TAG presented only the accuracy scores on the tu & roth dataset, we also employed an accuracy score as an evaluation metric on this dataset, where positive and negative examples were also marked', '. but, in the case of wiki50 corpus, where only the positive vpcs were manually annotated, the f β = 1 score was employed and interpreted on', 'the positive class as an evaluation metric. moreover, all potential vpcs were treated as negative that were', 'extracted by the candidate extraction method but were not marked as positive in the gold standard. thus,', '']",5
"['on the tu & roth dataset  #TAUTHOR_TAG.', '']","['on the tu & roth dataset  #TAUTHOR_TAG.', '']","['on the tu & roth dataset  #TAUTHOR_TAG.', '']","['order to compare the performance of our system with others, we evaluated it on the tu & roth dataset  #TAUTHOR_TAG.', '']",5
"['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where']","['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where']","['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where the authors examined a verbparticle combination only if the verbal components were formed with one of the previously given six verbs ( i. e.']","['this section, we concentrate on the first step of our approach, namely how vpc candidates can be selected from texts.', 'as we mentioned in section 1, our hypothesis is that the automatic detection of vpcs can be basically carried out by dependency parsers.', 'thus, we examined the performance of two parsers on vpc - specific syntactic labels.', 'as we had a full - coverage vpc annotated corpus where each individual occurrence of a vpc was manually marked, we were able to examine the characteristics of vpcs in a running text and evaluate the effectiveness of the parsers on this task.', 'therefore, here we examine dependency relations among the manually annotated gold standard vpcs, provided by the stanford parser  #AUTHOR_TAG and the bohnet parser  #AUTHOR_TAG for the wiki50 corpus.', 'in order to compare the efficiency of the parsers, both were applied using the same dependency represen therefore, we extended our candidate extraction method, where besides the verb - particle dependency relation, the preposition and adverbial modifier syntactic relations were also investigated among verbs and particles.', 'with this modification, 70. 24 % and 96. 42 % of vpcs in the wiki50 corpus could be identified.', 'in this phase, we found that the bohnet parser was more successful on the wiki50 corpus, i. e. it could cover more vpcs, hence we applied the bohnet parser in our further experiments.', 'some researchers filtered lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where the authors examined a verbparticle combination only if the verbal components were formed with one of the previously given six verbs ( i. e. make, take, have, give, do, get ).', 'since wiki50 was annotated for all vpc occurrences, we were able to check what percentage of vpcs could be covered if we applied this selection.', 'as table 3 shows, the six verbs used by  #TAUTHOR_TAG are responsible for only 50 vpcs on the wiki50 corpus, so it covers only 11. 16 % of all gold standard vpcs.', 'table 4 lists the most frequent vpcs and the verbal components on the wiki50 corpus.', '']",0
"['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where']","['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where']","['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where the authors examined a verbparticle combination only if the verbal components were formed with one of the previously given six verbs ( i. e.']","['this section, we concentrate on the first step of our approach, namely how vpc candidates can be selected from texts.', 'as we mentioned in section 1, our hypothesis is that the automatic detection of vpcs can be basically carried out by dependency parsers.', 'thus, we examined the performance of two parsers on vpc - specific syntactic labels.', 'as we had a full - coverage vpc annotated corpus where each individual occurrence of a vpc was manually marked, we were able to examine the characteristics of vpcs in a running text and evaluate the effectiveness of the parsers on this task.', 'therefore, here we examine dependency relations among the manually annotated gold standard vpcs, provided by the stanford parser  #AUTHOR_TAG and the bohnet parser  #AUTHOR_TAG for the wiki50 corpus.', 'in order to compare the efficiency of the parsers, both were applied using the same dependency represen therefore, we extended our candidate extraction method, where besides the verb - particle dependency relation, the preposition and adverbial modifier syntactic relations were also investigated among verbs and particles.', 'with this modification, 70. 24 % and 96. 42 % of vpcs in the wiki50 corpus could be identified.', 'in this phase, we found that the bohnet parser was more successful on the wiki50 corpus, i. e. it could cover more vpcs, hence we applied the bohnet parser in our further experiments.', 'some researchers filtered lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where the authors examined a verbparticle combination only if the verbal components were formed with one of the previously given six verbs ( i. e. make, take, have, give, do, get ).', 'since wiki50 was annotated for all vpc occurrences, we were able to check what percentage of vpcs could be covered if we applied this selection.', 'as table 3 shows, the six verbs used by  #TAUTHOR_TAG are responsible for only 50 vpcs on the wiki50 corpus, so it covers only 11. 16 % of all gold standard vpcs.', 'table 4 lists the most frequent vpcs and the verbal components on the wiki50 corpus.', '']",0
"['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where']","['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where']","['lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where the authors examined a verbparticle combination only if the verbal components were formed with one of the previously given six verbs ( i. e.']","['this section, we concentrate on the first step of our approach, namely how vpc candidates can be selected from texts.', 'as we mentioned in section 1, our hypothesis is that the automatic detection of vpcs can be basically carried out by dependency parsers.', 'thus, we examined the performance of two parsers on vpc - specific syntactic labels.', 'as we had a full - coverage vpc annotated corpus where each individual occurrence of a vpc was manually marked, we were able to examine the characteristics of vpcs in a running text and evaluate the effectiveness of the parsers on this task.', 'therefore, here we examine dependency relations among the manually annotated gold standard vpcs, provided by the stanford parser  #AUTHOR_TAG and the bohnet parser  #AUTHOR_TAG for the wiki50 corpus.', 'in order to compare the efficiency of the parsers, both were applied using the same dependency represen therefore, we extended our candidate extraction method, where besides the verb - particle dependency relation, the preposition and adverbial modifier syntactic relations were also investigated among verbs and particles.', 'with this modification, 70. 24 % and 96. 42 % of vpcs in the wiki50 corpus could be identified.', 'in this phase, we found that the bohnet parser was more successful on the wiki50 corpus, i. e. it could cover more vpcs, hence we applied the bohnet parser in our further experiments.', 'some researchers filtered lvc candidates by selecting only certain verbs that may be part of the construction.', 'one example is  #TAUTHOR_TAG, where the authors examined a verbparticle combination only if the verbal components were formed with one of the previously given six verbs ( i. e. make, take, have, give, do, get ).', 'since wiki50 was annotated for all vpc occurrences, we were able to check what percentage of vpcs could be covered if we applied this selection.', 'as table 3 shows, the six verbs used by  #TAUTHOR_TAG are responsible for only 50 vpcs on the wiki50 corpus, so it covers only 11. 16 % of all gold standard vpcs.', 'table 4 lists the most frequent vpcs and the verbal components on the wiki50 corpus.', '']",0
,,,,0
"['methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['machines ( svm )  #AUTHOR_TAG results are also reported to compare the performance of our methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['with that of', ' #TAUTHOR_TAG. as the investigated corpora were not']","['the weka package  #AUTHOR_TAG was trained with its default settings on the abovementioned feature set, which implements the c4. 5  #AUTHOR_TAG decision tree', 'algorithm. moreover, support vector machines ( svm )  #AUTHOR_TAG results are also reported to compare the performance of our methods with that of', ' #TAUTHOR_TAG. as the investigated corpora were not sufficiently large for splitting them into training and test sets', 'of appropriate size, we evaluated our models in a cross validation manner on the wiki50 corpus and', 'the tu & roth dataset. as  #TAUTHOR_TAG presented only the accuracy scores on the tu & roth dataset, we also employed an accuracy score as an evaluation metric on this dataset, where positive and negative examples were also marked', '. but, in the case of wiki50 corpus, where only the positive vpcs were manually annotated, the f β = 1 score was employed and interpreted on', 'the positive class as an evaluation metric. moreover, all potential vpcs were treated as negative that were', 'extracted by the candidate extraction method but were not marked as positive in the gold standard. thus,', '']",3
,,,,4
"['the method reported in  #TAUTHOR_TAG on the tu & roth dataset.', 'here, we also showed']","['the method reported in  #TAUTHOR_TAG on the tu & roth dataset.', 'here, we also showed']","['the method reported in  #TAUTHOR_TAG on the tu & roth dataset.', 'here, we also showed']","['this paper, we focused on the automatic detection of verb - particle combinations in raw texts.', 'our hypothesis was that parsers trained on texts annotated with extra information for vpcs can identify vpcs in texts.', 'we introduced our machine learning - based tool called vpctagger, which allowed us to automatically detect vpcs in context.', 'we solved the problem in a two - step approach.', 'in the first step, we extracted potential vpcs from a running text with a syntaxbased candidate extraction method and we applied a machine learning - based approach that made use of a rich feature set to classify extracted syntactic phrases in the second step.', 'in order to achieve a greater efficiency, we defined several new features like semantic and contextual, but according to our ablation analysis we found that each type of features contributed to the overall performance.', 'moreover, we also examined how syntactic parsers performed in the vpc detection task on the wiki50 corpus.', 'furthermore, we compared our methods with others when we evaluated our approach on the tu & roth dataset.', 'our method yielded better results than those got using the dependency parsers on the wiki50 corpus and the method reported in  #TAUTHOR_TAG on the tu & roth dataset.', 'here, we also showed how dependency parsers performed on identifying vpcs, and our results indicate that although the dependency label provided by the parsers is an essential feature in determining whether a specific vpc candidate is a genuine vpc or not, the results can be further improved by extending the system with additional features like lexical and semantic features.', '']",4
"['introduced by the translator, wan in  #TAUTHOR_TAG applied a co - training scheme']","['introduced by the translator, wan in  #TAUTHOR_TAG applied a co - training scheme.', 'in this setting classifiers are']","['introduced by the translator, wan in  #TAUTHOR_TAG applied a co - training scheme.', 'in this setting classifiers are trained in both languages and the two classifiers teach each']","['this paper we are interested in the problem of transferring knowledge gained from data gathered in one language to another language.', 'a simple and straightforward solution for this problem might be to use automatic machine translations.', 'however, while machine translation has been the subject of a great deal of development in recent years, many of the recent gains in performance manifest as syntactically as opposed to semantically correct sentences.', 'for example, "" pianyi "" is a word mainly used in positive comments in chinese but its translation from the online google translator is always "" cheap "", a word typically used in a negative context in english.', 'to reduce this kind of error introduced by the translator, wan in  #TAUTHOR_TAG applied a co - training scheme.', 'in this setting classifiers are trained in both languages and the two classifiers teach each other for the unlabeled examples.', 'the co - training approach manages to boost the performance as it allows the text similarity in the target language to compete with the "" fake "" similarity from the translated texts.', 'however, the translated texts are still used as training data and thus can potentially mislead the classifier.', 'as we are not really interested in predicting something on the language created by the translator, but rather on the real one, it may be better to further diminish the role of the translated texts in the learning process.', 'motivated by this observation, we suggest here to view this problem as a special case of domain adaptation, in the source domain, we mainly observe english features, while in the other domain mostly features from chinese.', 'the problem we address is how to associate the features under a unified setting.', 'there has been a lot of work in domain adaption for nlp  #AUTHOR_TAG  #AUTHOR_TAG and one suitable choice for our problem is the approach based on structural correspondence learning ( scl ) as in  #AUTHOR_TAG and  #AUTHOR_TAG b ).', 'the key idea of scl is to identify a low - dimensional representations that capture correspondence between features from both domains ( x s and x t in our case ) by modeling their correlations with some special pivot features.', 'the scl approach is a good fit for our problem as it performs knowledge transfer through identifying important features.', 'in the cross - lingual setting, we can restrict the translated texts by using them only through the pivot features.', 'we believe this form is more robust to errors in the language produced by the translator.', 'adapting language resources and knowledge to a new language was first studied for general text categorization and information retrieval as in  #AUTHOR_TAG, where the authors translate a keyword lexicon to perform cross - lingual text categorization.', 'in  #AUTHOR_TAG, different shortcomings']",0
"['as reported in  #TAUTHOR_TAG.', 'our solution to this problem is simple : instead of using']","['as reported in  #TAUTHOR_TAG.', 'our solution to this problem is simple : instead of using']","[', these two strategies give poor performance as reported in  #TAUTHOR_TAG.', 'our solution to this problem is simple : instead of using all the features']","['our task as a domain adaptation problem.', 'the source domain correspond to english reviews and the target domain for chinese ones.', 'the full feature vector is ( x s, x t ).', 'the difficulty we are facing is, due to noise in the translations, the conditional probabilities p ( y | x s ) and the one in the translated texts p ( y | x s ) may be quite different. consider the following two straightforward strategies of using automatic machine translations : one can translate the original english labeled data ( y, x s ) into ( y, x t ) in chinese and train a classifier, or one can train a classifier on ( y, x s ) and translate x t in chinese into x s in english so as to use the classifier. but as the conditional distribution can be quite different for the original language and the pseudo language produced by the machine translators, these two strategies give poor performance as reported in  #TAUTHOR_TAG.', 'our solution to this problem is simple : instead of using all the features as ( x s, x t ) and ( x s, x t ), we only preserves the pivot features in the translated texts x s and x t respectively and discard the other features produced by the translator.', 'so, now we will have ( x s, x tp ) and ( x sp, x t ) where x ( s | t ) p are pivot features in the source and the target languages.', 'in other words, when we use the scl on our problem, the translations are only used to decide if a certain pivot feature occurs or not in the training of the linear predictors.', 'all the other nonpivot features in the translators are blocked to reduce the noise.', 'in the original scl as we mentioned earlier, the final classifier is trained on the extended features ( x, w * x ).', 'however, as mentioned above we will only use the pivot features.', 'to represent this constraint, we can modify the vector to be ( w p * x, w * x ) where w p is a constant matrix that only selects the pivot features.', 'this modification will not affect the deduction procedure and results in  #AUTHOR_TAG.', 'experiments show that using only pivot features actually outperforms the full feature setting.', 'for the selection of the pivot features, we follow the automatic selection method proposed in  #AUTHOR_TAG a ).', 'we first select some candidates that occur at least some constant number of times in reviews of the two languages.', 'then, we rank these features according to their conditional entropy to the labels on the training']",3
"['set in  #TAUTHOR_TAG :', 'test set ( labeled']","['set in  #TAUTHOR_TAG :', 'test set ( labeled']","['in  #TAUTHOR_TAG :', 'test set ( labeled chinese reviews ) : the data set']","['comparsion, we use the same data set in  #TAUTHOR_TAG :', 'test set ( labeled chinese reviews ) : the data set contains a total of 886 labeled product reviews in chinese ( 451 positive reviews and 435 negative ones ).', 'these reviews are extracted from a popular chinese it product website it168 1.', 'the reviews are mainly about electronic devices like mp3 players, mobile phones, digital cameras and computers.', 'training set ( labeled english reviews ) : this is the data set used in the domain adaption experiment of  #AUTHOR_TAG b ).', 'it contains four major categories : books, dvds, electronics and kitchen appliances.', 'the data set consists of 8000 reviews with 4000 positive and 4000 negative, it is a public data set available on the web 2.', 'unlabeled set ( unlabeled chinese reviews ) : 1000 chinese reviews downloaded from the same website as the chinese training set.', 'they are of the same domain as the test set.', 'we translate each english review into chinese and vice versus through the public google translation service.', 'also following the setting in  #TAUTHOR_TAG, we only use the chinese unlabeled data and english training sets for our scl training procedures.', 'the test set is blind to the training stage.', 'the features we used are bigrams and unigrams in the two languages as in  #TAUTHOR_TAG.', 'in chinese, we first apply the stanford chinese word segmenter 3 to segment the reviews.', 'bigrams refers to a single chinese word and a bigram refers to two adjacent chinese words.', 'the features are also pre - processed and normalized as in  #AUTHOR_TAG b ).', 'table 3 : results on the negative']",5
"['set in  #TAUTHOR_TAG :', 'test set ( labeled']","['set in  #TAUTHOR_TAG :', 'test set ( labeled']","['in  #TAUTHOR_TAG :', 'test set ( labeled chinese reviews ) : the data set']","['comparsion, we use the same data set in  #TAUTHOR_TAG :', 'test set ( labeled chinese reviews ) : the data set contains a total of 886 labeled product reviews in chinese ( 451 positive reviews and 435 negative ones ).', 'these reviews are extracted from a popular chinese it product website it168 1.', 'the reviews are mainly about electronic devices like mp3 players, mobile phones, digital cameras and computers.', 'training set ( labeled english reviews ) : this is the data set used in the domain adaption experiment of  #AUTHOR_TAG b ).', 'it contains four major categories : books, dvds, electronics and kitchen appliances.', 'the data set consists of 8000 reviews with 4000 positive and 4000 negative, it is a public data set available on the web 2.', 'unlabeled set ( unlabeled chinese reviews ) : 1000 chinese reviews downloaded from the same website as the chinese training set.', 'they are of the same domain as the test set.', 'we translate each english review into chinese and vice versus through the public google translation service.', 'also following the setting in  #TAUTHOR_TAG, we only use the chinese unlabeled data and english training sets for our scl training procedures.', 'the test set is blind to the training stage.', 'the features we used are bigrams and unigrams in the two languages as in  #TAUTHOR_TAG.', 'in chinese, we first apply the stanford chinese word segmenter 3 to segment the reviews.', 'bigrams refers to a single chinese word and a bigram refers to two adjacent chinese words.', 'the features are also pre - processed and normalized as in  #AUTHOR_TAG b ).', 'table 3 : results on the negative']",5
"['set in  #TAUTHOR_TAG :', 'test set ( labeled']","['set in  #TAUTHOR_TAG :', 'test set ( labeled']","['in  #TAUTHOR_TAG :', 'test set ( labeled chinese reviews ) : the data set']","['comparsion, we use the same data set in  #TAUTHOR_TAG :', 'test set ( labeled chinese reviews ) : the data set contains a total of 886 labeled product reviews in chinese ( 451 positive reviews and 435 negative ones ).', 'these reviews are extracted from a popular chinese it product website it168 1.', 'the reviews are mainly about electronic devices like mp3 players, mobile phones, digital cameras and computers.', 'training set ( labeled english reviews ) : this is the data set used in the domain adaption experiment of  #AUTHOR_TAG b ).', 'it contains four major categories : books, dvds, electronics and kitchen appliances.', 'the data set consists of 8000 reviews with 4000 positive and 4000 negative, it is a public data set available on the web 2.', 'unlabeled set ( unlabeled chinese reviews ) : 1000 chinese reviews downloaded from the same website as the chinese training set.', 'they are of the same domain as the test set.', 'we translate each english review into chinese and vice versus through the public google translation service.', 'also following the setting in  #TAUTHOR_TAG, we only use the chinese unlabeled data and english training sets for our scl training procedures.', 'the test set is blind to the training stage.', 'the features we used are bigrams and unigrams in the two languages as in  #TAUTHOR_TAG.', 'in chinese, we first apply the stanford chinese word segmenter 3 to segment the reviews.', 'bigrams refers to a single chinese word and a bigram refers to two adjacent chinese words.', 'the features are also pre - processed and normalized as in  #AUTHOR_TAG b ).', 'table 3 : results on the negative']",5
"['compare our procedure with the co - training scheme reported in  #TAUTHOR_TAG :', 'the method with']","['compare our procedure with the co - training scheme reported in  #TAUTHOR_TAG :', 'the method with']","['compare our procedure with the co - training scheme reported in  #TAUTHOR_TAG :', 'the method with the best performance in  #TAUTHOR_TAG.', 'two standard svms are trained using the co - training scheme for the chinese views and the english views. and the results of the two svms are combined to']","['compare our procedure with the co - training scheme reported in  #TAUTHOR_TAG :', 'the method with the best performance in  #TAUTHOR_TAG.', 'two standard svms are trained using the co - training scheme for the chinese views and the english views. and the results of the two svms are combined to give the final output']",5
"['compare our procedure with the co - training scheme reported in  #TAUTHOR_TAG :', 'the method with']","['compare our procedure with the co - training scheme reported in  #TAUTHOR_TAG :', 'the method with']","['compare our procedure with the co - training scheme reported in  #TAUTHOR_TAG :', 'the method with the best performance in  #TAUTHOR_TAG.', 'two standard svms are trained using the co - training scheme for the chinese views and the english views. and the results of the two svms are combined to']","['compare our procedure with the co - training scheme reported in  #TAUTHOR_TAG :', 'the method with the best performance in  #TAUTHOR_TAG.', 'two standard svms are trained using the co - training scheme for the chinese views and the english views. and the results of the two svms are combined to give the final output']",7
['current statistical parser  #TAUTHOR_TAG'],['current statistical parser  #TAUTHOR_TAG'],['current statistical parser  #TAUTHOR_TAG'],"[', while the second determines the labels to be assigned to the selected elements. while some of these models are based on full parse trees  #AUTHOR_TAG, other methods have been proposed that eschew the need for a full parse ( connl, 2004 ; conll', ', 2005 ). because of the way the problem has been formulated - as a pipeline of parsing ( or chunking ) feeding into labelling - specific investigations of integrated approaches', ""that solve both the parsing and the semantic role labelling problems at the same time have not been studied. we present work to test the hypothesis that a current statistical parser  #TAUTHOR_TAG can output richer information robustly, that is without any significant degradation of the parser's accuracy on the original parsing task, by explicitly modelling semantic role labels as the interface"", 'between syntax and semantics. we achieve promising results both on the simple parsing task, where the accuracy of the parser is measured on the standard parseval measures, and also on the parsing task where the more complex labels of propbank are taken into', 'account. we will call the former task penn treebank parsing', '( ptb parsing ) and the latter task propbank parsing below. these results have several consequences. on the one hand', ', we show that it is possible to build a single integrated robust system successfully. this is a meaningful achievement, as a task combining semantic role labelling and parsing is more complex than simple syntactic parsing. while the shallow semantics of a constituent and its structural position are often correlated, they sometimes diverge. for example, some nominal temporal modifiers occupy an object position without being objects, like tuesday in figure 1 below. on the other hand, our results indicate that the proposed models are', 'robust. to model our task accurately, additional parameters must be estimated. however, given the current limited availability of annotated treebank', '##s, this more complex task will have to be solved with the same overall', ""amount of data, aggravating the difficulty of estimating the model's parameters due to sparse data. the limited availability of data is increased further by the high variability of the argumental labels a0 - a5 whose semantics is specific to a given"", 'verb or a given verb sense. solving this more complex problem successfully, then,', 'indicates that the models used are robust. finally, we achieve robustness without simplifying the parsing architecture. specifically, robustness is achieved', 'without resorting to the stipulation of strong independence assumptions to compensate for the limited availability and high variability of data. consequently, such an achievement demonstrates not only that the robustness of the parsing model, but', 'also its scalability and portability']",0
"['simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['statistical parsers, the simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['achieve the complex task of assigning semantic role labels while parsing, we use a family of statistical parsers, the simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG, which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.', 'this architecture has shown state - of - the - art performance.', 'ssn parsers comprise two components, one which estimates the parameters of a stochastic model for syntactic trees, and one which searches for the most probable syntactic tree given the parameter estimates.', 'as with many other statistical parsers  #AUTHOR_TAG, ssn parsers use a history - based model of parsing.', 'events in such a model are derivation moves.', 'the set of well - formed sequences of derivation moves in this parser is defined by a predictive lr pushdown automaton  #AUTHOR_TAG, which implements a form of left - corner parsing strategy.', 'the derivation moves include : projecting a constituent with a specified label, attaching one constituent to another, and shifting a tag - word pair onto the pushdown stack.', 'unlike standard history - based models, ssn parsers do not state any explicit independence assumptions between derivation steps.', 'they use a neural network architecture, called simple synchrony network  #AUTHOR_TAG, to induce a finite history representation of an unbounded sequence of moves.', '']",0
"['original ssn model in  #TAUTHOR_TAG, only the']","['according to the original ssn model in  #TAUTHOR_TAG, only the']","['according to the original ssn model in  #TAUTHOR_TAG, only the']",[' #TAUTHOR_TAG'],0
['current statistical parser  #TAUTHOR_TAG'],['current statistical parser  #TAUTHOR_TAG'],['current statistical parser  #TAUTHOR_TAG'],"[', while the second determines the labels to be assigned to the selected elements. while some of these models are based on full parse trees  #AUTHOR_TAG, other methods have been proposed that eschew the need for a full parse ( connl, 2004 ; conll', ', 2005 ). because of the way the problem has been formulated - as a pipeline of parsing ( or chunking ) feeding into labelling - specific investigations of integrated approaches', ""that solve both the parsing and the semantic role labelling problems at the same time have not been studied. we present work to test the hypothesis that a current statistical parser  #TAUTHOR_TAG can output richer information robustly, that is without any significant degradation of the parser's accuracy on the original parsing task, by explicitly modelling semantic role labels as the interface"", 'between syntax and semantics. we achieve promising results both on the simple parsing task, where the accuracy of the parser is measured on the standard parseval measures, and also on the parsing task where the more complex labels of propbank are taken into', 'account. we will call the former task penn treebank parsing', '( ptb parsing ) and the latter task propbank parsing below. these results have several consequences. on the one hand', ', we show that it is possible to build a single integrated robust system successfully. this is a meaningful achievement, as a task combining semantic role labelling and parsing is more complex than simple syntactic parsing. while the shallow semantics of a constituent and its structural position are often correlated, they sometimes diverge. for example, some nominal temporal modifiers occupy an object position without being objects, like tuesday in figure 1 below. on the other hand, our results indicate that the proposed models are', 'robust. to model our task accurately, additional parameters must be estimated. however, given the current limited availability of annotated treebank', '##s, this more complex task will have to be solved with the same overall', ""amount of data, aggravating the difficulty of estimating the model's parameters due to sparse data. the limited availability of data is increased further by the high variability of the argumental labels a0 - a5 whose semantics is specific to a given"", 'verb or a given verb sense. solving this more complex problem successfully, then,', 'indicates that the models used are robust. finally, we achieve robustness without simplifying the parsing architecture. specifically, robustness is achieved', 'without resorting to the stipulation of strong independence assumptions to compensate for the limited availability and high variability of data. consequently, such an achievement demonstrates not only that the robustness of the parsing model, but', 'also its scalability and portability']",5
"['simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['statistical parsers, the simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['achieve the complex task of assigning semantic role labels while parsing, we use a family of statistical parsers, the simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG, which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.', 'this architecture has shown state - of - the - art performance.', 'ssn parsers comprise two components, one which estimates the parameters of a stochastic model for syntactic trees, and one which searches for the most probable syntactic tree given the parameter estimates.', 'as with many other statistical parsers  #AUTHOR_TAG, ssn parsers use a history - based model of parsing.', 'events in such a model are derivation moves.', 'the set of well - formed sequences of derivation moves in this parser is defined by a predictive lr pushdown automaton  #AUTHOR_TAG, which implements a form of left - corner parsing strategy.', 'the derivation moves include : projecting a constituent with a specified label, attaching one constituent to another, and shifting a tag - word pair onto the pushdown stack.', 'unlike standard history - based models, ssn parsers do not state any explicit independence assumptions between derivation steps.', 'they use a neural network architecture, called simple synchrony network  #AUTHOR_TAG, to induce a finite history representation of an unbounded sequence of moves.', '']",5
['current statistical parser  #TAUTHOR_TAG'],['current statistical parser  #TAUTHOR_TAG'],['current statistical parser  #TAUTHOR_TAG'],"[', while the second determines the labels to be assigned to the selected elements. while some of these models are based on full parse trees  #AUTHOR_TAG, other methods have been proposed that eschew the need for a full parse ( connl, 2004 ; conll', ', 2005 ). because of the way the problem has been formulated - as a pipeline of parsing ( or chunking ) feeding into labelling - specific investigations of integrated approaches', ""that solve both the parsing and the semantic role labelling problems at the same time have not been studied. we present work to test the hypothesis that a current statistical parser  #TAUTHOR_TAG can output richer information robustly, that is without any significant degradation of the parser's accuracy on the original parsing task, by explicitly modelling semantic role labels as the interface"", 'between syntax and semantics. we achieve promising results both on the simple parsing task, where the accuracy of the parser is measured on the standard parseval measures, and also on the parsing task where the more complex labels of propbank are taken into', 'account. we will call the former task penn treebank parsing', '( ptb parsing ) and the latter task propbank parsing below. these results have several consequences. on the one hand', ', we show that it is possible to build a single integrated robust system successfully. this is a meaningful achievement, as a task combining semantic role labelling and parsing is more complex than simple syntactic parsing. while the shallow semantics of a constituent and its structural position are often correlated, they sometimes diverge. for example, some nominal temporal modifiers occupy an object position without being objects, like tuesday in figure 1 below. on the other hand, our results indicate that the proposed models are', 'robust. to model our task accurately, additional parameters must be estimated. however, given the current limited availability of annotated treebank', '##s, this more complex task will have to be solved with the same overall', ""amount of data, aggravating the difficulty of estimating the model's parameters due to sparse data. the limited availability of data is increased further by the high variability of the argumental labels a0 - a5 whose semantics is specific to a given"", 'verb or a given verb sense. solving this more complex problem successfully, then,', 'indicates that the models used are robust. finally, we achieve robustness without simplifying the parsing architecture. specifically, robustness is achieved', 'without resorting to the stipulation of strong independence assumptions to compensate for the limited availability and high variability of data. consequently, such an achievement demonstrates not only that the robustness of the parsing model, but', 'also its scalability and portability']",6
"['simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['statistical parsers, the simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['achieve the complex task of assigning semantic role labels while parsing, we use a family of statistical parsers, the simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG, which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.', 'this architecture has shown state - of - the - art performance.', 'ssn parsers comprise two components, one which estimates the parameters of a stochastic model for syntactic trees, and one which searches for the most probable syntactic tree given the parameter estimates.', 'as with many other statistical parsers  #AUTHOR_TAG, ssn parsers use a history - based model of parsing.', 'events in such a model are derivation moves.', 'the set of well - formed sequences of derivation moves in this parser is defined by a predictive lr pushdown automaton  #AUTHOR_TAG, which implements a form of left - corner parsing strategy.', 'the derivation moves include : projecting a constituent with a specified label, attaching one constituent to another, and shifting a tag - word pair onto the pushdown stack.', 'unlike standard history - based models, ssn parsers do not state any explicit independence assumptions between derivation steps.', 'they use a neural network architecture, called simple synchrony network  #AUTHOR_TAG, to induce a finite history representation of an unbounded sequence of moves.', '']",1
"['simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['statistical parsers, the simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG,']","['achieve the complex task of assigning semantic role labels while parsing, we use a family of statistical parsers, the simple synchrony network ( ssn ) parsers  #TAUTHOR_TAG, which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.', 'this architecture has shown state - of - the - art performance.', 'ssn parsers comprise two components, one which estimates the parameters of a stochastic model for syntactic trees, and one which searches for the most probable syntactic tree given the parameter estimates.', 'as with many other statistical parsers  #AUTHOR_TAG, ssn parsers use a history - based model of parsing.', 'events in such a model are derivation moves.', 'the set of well - formed sequences of derivation moves in this parser is defined by a predictive lr pushdown automaton  #AUTHOR_TAG, which implements a form of left - corner parsing strategy.', 'the derivation moves include : projecting a constituent with a specified label, attaching one constituent to another, and shifting a tag - word pair onto the pushdown stack.', 'unlike standard history - based models, ssn parsers do not state any explicit independence assumptions between derivation steps.', 'they use a neural network architecture, called simple synchrony network  #AUTHOR_TAG, to induce a finite history representation of an unbounded sequence of moves.', '']",1
"['parser  #TAUTHOR_TAG,', 'that was']","['of the original ssn parser  #TAUTHOR_TAG,', 'that was']","['parser  #TAUTHOR_TAG,', 'that was trained on the ptb data sets contrary to our ssn model trained on the propbank data', 'sets']","['', 'on two different tasks and the original ssn parser.', 'lary of our model. we reach a total of 4970 tagword pairs. 3 this vocabulary comprises the original 512 pairs of the', 'original ssn model, and our added pairs which must occur at least 10 times in the training data. our vocabulary as well as the new 240 pos tags and', 'the new 580 non - terminal labels are included in the set f of features input to the history representations as described in section 2. we perform two different', 'evaluations on our model trained on propbank data. recall that we distinguish between two parsing tasks : the propbank parsing task and the ptb parsing task. to evaluate the first parsing task, we compute the standard parseval measures of labelled recall and precision of constituents, taking into account not only the 33 original labels but also the 580 newly introduced propbank labels. this evaluation gives us an indication of how accurately and exhaustively we can recover this richer set of nonterminal labels. the results, computed on the testing data set from the propbank, are shown on the first', 'line of table 1. to', 'evaluate the ptb task, we compute the labelled recall', 'and precision of constituents, ignoring the set of propbank semantic role labels that our model assigns to constituents. this evaluation indicates how well we perform on the standard', 'ptb parsing task alone, and its results on the testing data set from the ptb are shown on the second line of table 1. the third line of table 1 gives the performance on', 'the simpler ptb parsing task of the original ssn parser  #TAUTHOR_TAG,', 'that was trained on the ptb data sets contrary to our ssn model trained on the propbank data', 'sets']",3
['##rs  #AUTHOR_TAG and pun of the day  #TAUTHOR_TAG humour classification datasets using only 10 % of known labels'],['on the 16000 one - liners  #AUTHOR_TAG and pun of the day  #TAUTHOR_TAG humour classification datasets using only 10 % of known labels'],['7 accuracy on the 16000 one - liners  #AUTHOR_TAG and pun of the day  #TAUTHOR_TAG humour classification datasets using only 10 % of known labels'],"['propose a novel tensor embedding method that can effectively extract lexical features for humor recognition.', 'specifically, we use wordword co - occurrence to encode the contextual content of documents, and then decompose the tensor to get corresponding vector representations.', 'we show that this simple method can capture features of lexical humor effectively for continuous humor recognition.', 'in particular, we achieve a distance of 0. 887 on a global humor ranking task, comparable to the top performing systems from semeval 2017 task 6b  #AUTHOR_TAG but without the need for any external training corpus.', 'in addition, we further show that this approach is also beneficial for small sample humor recognition tasks through a semi - supervised label propagation procedure, which achieves about 0. 7 accuracy on the 16000 one - liners  #AUTHOR_TAG and pun of the day  #TAUTHOR_TAG humour classification datasets using only 10 % of known labels']",1
"['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor']","['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor']","['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor recognition as a pairwise relative ranking task  #AUTHOR_TAG.', 'in']","['humor automatically is an important step for natural human - computer interaction  #AUTHOR_TAG.', 'while early works tend to frame humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor recognition as a pairwise relative ranking task  #AUTHOR_TAG.', 'in addition to pairwise ranking, semeval 2017 task 6 also includes a global ranking subtask.', '']",1
"['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor']","['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor']","['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor recognition as a pairwise relative ranking task  #AUTHOR_TAG.', 'in']","['humor automatically is an important step for natural human - computer interaction  #AUTHOR_TAG.', 'while early works tend to frame humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor recognition as a pairwise relative ranking task  #AUTHOR_TAG.', 'in addition to pairwise ranking, semeval 2017 task 6 also includes a global ranking subtask.', '']",0
"['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor']","['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor']","['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor recognition as a pairwise relative ranking task  #AUTHOR_TAG.', 'in']","['humor automatically is an important step for natural human - computer interaction  #AUTHOR_TAG.', 'while early works tend to frame humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor recognition as a pairwise relative ranking task  #AUTHOR_TAG.', 'in addition to pairwise ranking, semeval 2017 task 6 also includes a global ranking subtask.', '']",0
"['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor']","['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor']","['humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor recognition as a pairwise relative ranking task  #AUTHOR_TAG.', 'in']","['humor automatically is an important step for natural human - computer interaction  #AUTHOR_TAG.', 'while early works tend to frame humor recognition as a binary classification task  #TAUTHOR_TAG, the last few years have seen the emergence of humor recognition as a pairwise relative ranking task  #AUTHOR_TAG.', 'in addition to pairwise ranking, semeval 2017 task 6 also includes a global ranking subtask.', '']",0
"['- phoneme lstm encoder - decoder  #AUTHOR_TAG.', 'stylistic features include alliteration, rhyming, negative sentiment, and adult slang  #AUTHOR_TAG as well as emotional scenarios  #AUTHOR_TAG.', 'semantic features range from attempts to measure incongruity  #TAUTHOR_TAG to']","['use a combination of phonological, stylistic, semantic, and content - based features.', 'phonological features include acoustic features extracted from sitcom audio tracks  #AUTHOR_TAG and "" phonetic embeddings "" generated using a character - to - phoneme lstm encoder - decoder  #AUTHOR_TAG.', 'stylistic features include alliteration, rhyming, negative sentiment, and adult slang  #AUTHOR_TAG as well as emotional scenarios  #AUTHOR_TAG.', 'semantic features range from attempts to measure incongruity  #TAUTHOR_TAG to']","['use a combination of phonological, stylistic, semantic, and content - based features.', 'phonological features include acoustic features extracted from sitcom audio tracks  #AUTHOR_TAG and "" phonetic embeddings "" generated using a character - to - phoneme lstm encoder - decoder  #AUTHOR_TAG.', 'stylistic features include alliteration, rhyming, negative sentiment, and adult slang  #AUTHOR_TAG as well as emotional scenarios  #AUTHOR_TAG.', 'semantic features range from attempts to measure incongruity  #TAUTHOR_TAG to the use of word embeddings']","['and learning humor features are critical for automatic humor recognition.', 'previous works tend to use a combination of phonological, stylistic, semantic, and content - based features.', 'phonological features include acoustic features extracted from sitcom audio tracks  #AUTHOR_TAG and "" phonetic embeddings "" generated using a character - to - phoneme lstm encoder - decoder  #AUTHOR_TAG.', 'stylistic features include alliteration, rhyming, negative sentiment, and adult slang  #AUTHOR_TAG as well as emotional scenarios  #AUTHOR_TAG.', 'semantic features range from attempts to measure incongruity  #TAUTHOR_TAG to the use of word embeddings as inputs to neural models  #AUTHOR_TAG.', 'content - based approaches include word frequency  #AUTHOR_TAG, n - gram probability  #AUTHOR_TAG, and lexical centrality  #AUTHOR_TAG.', 'centrality is based on the observation that humorous responses to common stimuli tend to cluster around a small number of core jokes  #AUTHOR_TAG, with more central documents benefiting from "" wisdom of the crowd "".', 'while most humor features involve making population - level inferences based on document - level features, centrality is instead population - level feature directly.', ' #AUTHOR_TAG calculate their centrality feature using lexrank, a graph - based text summarization method  #AUTHOR_TAG.', 'compared with more traditional lexical similarity measures like tfidf, this method is better suited to short humor texts due to their short lengths leading to sparse vector representations  #AUTHOR_TAG']",0
"['so  #TAUTHOR_TAG that : w', 'where']","['so  #TAUTHOR_TAG that : w', 'where']","['so  #TAUTHOR_TAG that : w', 'where v r ∈ r v, d r ∈ r d, r is the predefined rank parameter, and ⊗ is the outer product, namely, v r ⊗ v r ⊗ d r being a three - dimensional tensor, and', 'with the tensor decomposition, we can find low - rank embeddings of sentences that capture the similarity']","['patterns of words can be used to measure lexical similarity for humor recognition.', 'state - of - the - art learning - based approaches like doc2vec  #AUTHOR_TAG or sent2vec  #AUTHOR_TAG usually require a large amount of data.', 'this is difficult to obtain for humor recognition.', 'we propose to use a novel tensor decomposition method to obtain lexical features of short humor texts.', 'to capture lexical similarity for humor recognition, we propose to represent the tensor through a novel word - word co - occurrence method, which has only been explored in the context of fake news detection  #AUTHOR_TAG.', 'considering a corpus d = { s 1, s 2,..., s d } with d sentences, we first build a vocabulary for it, namely, w 1, w 2,..., w v, where v is the number of words.', 'for each sentence s in d, we count the wordword co - occurrence in a small window h, and build a frequency matrix w s ∈ z v ×v, where z denotes the set of integers.', 'in particular, w s ( i, j ) indicates the frequency that word w i and w j cooccur in s within the window h. in this way, we can capture the lexical patterns of s in w s.', 'we then stack all w s as a three - dimensional tensor w ∈ z v ×v ×d.', 'the objective of tensor decomposition is to find an approximationw of w so  #TAUTHOR_TAG that : w', 'where v r ∈ r v, d r ∈ r d, r is the predefined rank parameter, and ⊗ is the outer product, namely, v r ⊗ v r ⊗ d r being a three - dimensional tensor, and', 'with the tensor decomposition, we can find low - rank embeddings of sentences that capture the similarity of contextual patterns  #AUTHOR_TAG.', 'in particular, c = [ d 1, d 2,..., d r ] ∈ r d×r, where the s - row of c is the embedding vector of sentence s. the euclidean distance of embeddings is used to measure the similarity of two sentences']",0
"[' #TAUTHOR_TAG.', 'different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques']","[' #TAUTHOR_TAG.', 'different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques']","['dependency parsers have developed a lot in the last decade  #TAUTHOR_TAG.', 'different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques']","['phrase - structure and dependency parsers have developed a lot in the last decade  #TAUTHOR_TAG.', 'different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques used ( and a growing gap between researcher communities ).', '']",0
"['an underlying pcfg  #TAUTHOR_TAG.', 'these approaches consists of two stages.', 'at the first stage']","['an underlying pcfg  #TAUTHOR_TAG.', 'these approaches consists of two stages.', 'at the first stage']","['an underlying pcfg  #TAUTHOR_TAG.', 'these approaches consists of two stages.', 'at the first stage they apply a pcfg']","['most successful supervised phrase - structure parsers are feature - rich discriminative parsers which heavily depend on an underlying pcfg  #TAUTHOR_TAG.', 'these approaches consists of two stages.', 'at the first stage they apply a pcfg to extract possible parses.', 'the full set of possible parses cannot be iterated through in practice, and is usually pruned as a consequence.', 'the n - best list parsers keep just the 50 - 100 best parses according to the pcfg.', 'other methods remove nodes and hyperedges whose posterior probability is under a predefined threshold from the forest ( chart ).', 'the task of the second stage is to select the best parse from the set of possible parses ( i. e. rerank this set ).', 'these methods employ a large feature set ( usually a few millions features )  #AUTHOR_TAG.', 'the n - best list approaches can straightforwardly employ local and non - local features as well because they decide at the sentence - level  #AUTHOR_TAG.', 'involving non - local features is more complicated in the forest - based approaches.', 'the conditional random field methods usually use only local features  #AUTHOR_TAG.', ' #AUTHOR_TAG introduced a beam - search and average perceptron - based procedure for incorporating them, however his empirical results show only minor improvement from incorporating non - local features.', 'in this study, we experiment with n - best list reranking and a packed - forest based model as well along with local features exclusively.', 'our goal is to investigate the extension of the standard feature set of these models by features extracted from the automatic dependency parse of the sentence in question']",0
"['standard tree.', ""our oracle extraction method is an extension of  #TAUTHOR_TAG's dynamic""]","['standard tree.', ""our oracle extraction method is an extension of  #TAUTHOR_TAG's dynamic programing procedure which takes into consideration pos tag and grammatical function matches as well and selects hyperedges with higher posterior probability""]","['in the set of possible parses most similar to the gold standard tree.', ""our oracle extraction method is an extension of  #TAUTHOR_TAG's dynamic programing procedure which takes into consideration pos tag and grammatical function matches as well and selects hyperedges with higher posterior probability""]","['', 'the feature values of a full possible parse is the sum of the local feature vectors ( for the hyperedges )  #AUTHOR_TAG.', 'learning is guided by the so - called oracle parse which is the full parse in the set of possible parses most similar to the gold standard tree.', ""our oracle extraction method is an extension of  #TAUTHOR_TAG's dynamic programing procedure which takes into consideration pos tag and grammatical function matches as well and selects hyperedges with higher posterior probability for tie - breaking."", 'for a detailed description of the training and supporting algorithms please refer to  #AUTHOR_TAG and  #TAUTHOR_TAG']",0
"[' #TAUTHOR_TAG.', 'different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques']","[' #TAUTHOR_TAG.', 'different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques']","['dependency parsers have developed a lot in the last decade  #TAUTHOR_TAG.', 'different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques']","['phrase - structure and dependency parsers have developed a lot in the last decade  #TAUTHOR_TAG.', 'different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques used ( and a growing gap between researcher communities ).', '']",1
"['standard tree.', ""our oracle extraction method is an extension of  #TAUTHOR_TAG's dynamic""]","['standard tree.', ""our oracle extraction method is an extension of  #TAUTHOR_TAG's dynamic programing procedure which takes into consideration pos tag and grammatical function matches as well and selects hyperedges with higher posterior probability""]","['in the set of possible parses most similar to the gold standard tree.', ""our oracle extraction method is an extension of  #TAUTHOR_TAG's dynamic programing procedure which takes into consideration pos tag and grammatical function matches as well and selects hyperedges with higher posterior probability""]","['', 'the feature values of a full possible parse is the sum of the local feature vectors ( for the hyperedges )  #AUTHOR_TAG.', 'learning is guided by the so - called oracle parse which is the full parse in the set of possible parses most similar to the gold standard tree.', ""our oracle extraction method is an extension of  #TAUTHOR_TAG's dynamic programing procedure which takes into consideration pos tag and grammatical function matches as well and selects hyperedges with higher posterior probability for tie - breaking."", 'for a detailed description of the training and supporting algorithms please refer to  #AUTHOR_TAG and  #TAUTHOR_TAG']",6
"['are similar to  #TAUTHOR_TAG,']","['are similar to  #TAUTHOR_TAG,']","['to fact that most of the', 'rr features are lexicalized while dep features are unlexicalized. regarding the two discriminative approaches, our findings are similar to  #TAUTHOR_TAG, i']","['', '. we also cite here previously published results on the same dataset by  #AUTHOR_TAG', '( a generative parser ) and  #AUTHOR_TAG ( a conditional random field - based discriminative parser', '). the rows rr, dep and rr + dep show the results achieved by the maxent 100 - best list parser while the avgper row show the results of the', 'forest - based average perceptron approach using the rr + dep feature set. we report numbers only at this feature configuration due to the lack of space', 'and because the difference between this and n - best list approaches is similarly moderate at other configurations as well. the results', 'of table 3 show that our simple features constructed from the automatic dependency parse of the sentence are as useful', 'as the stateof - the - art rich feature set for german. moreover these two features sets have a', 'certain level of diversity as their union could achieve significantly better results than any of them alone. this is probably due to fact that most of the', 'rr features are lexicalized while dep features are unlexicalized. regarding the two discriminative approaches, our findings are similar to  #TAUTHOR_TAG, i. e. the packed forest - based and n', '- best list procedures achieved similar results by using only local features. we found that the improvements by applying the dependency features are similar at the two evaluation metrics', '( with and without grammatical functions )']",3
[': textvqa  #TAUTHOR_TAG ( +'],[': textvqa  #TAUTHOR_TAG ( +'],['on three challenging datasets for the textvqa task : textvqa  #TAUTHOR_TAG ( +'],"['', 'model reasons about the answer beyond a single classification step and predicts it through our pointeraugmented multi - step decoder. 3 ) we adopt a rich feature representation for text tokens in images and show that it is better than features based only on word embedding in previous work. 4 )', 'our model significantly outperforms previous work on three challenging datasets for the textvqa task : textvqa  #TAUTHOR_TAG ( + 25 % relative ), st - vqa [ 8 ] ( + 65 % relative ), and ocr - vqa [ 37 ] ( + 32 % relative )']",4
[': textvqa  #TAUTHOR_TAG ( +'],[': textvqa  #TAUTHOR_TAG ( +'],['on three challenging datasets for the textvqa task : textvqa  #TAUTHOR_TAG ( +'],"['', 'model reasons about the answer beyond a single classification step and predicts it through our pointeraugmented multi - step decoder. 3 ) we adopt a rich feature representation for text tokens in images and show that it is better than features based only on word embedding in previous work. 4 )', 'our model significantly outperforms previous work on three challenging datasets for the textvqa task : textvqa  #TAUTHOR_TAG ( + 25 % relative ), st - vqa [ 8 ] ( + 65 % relative ), and ocr - vqa [ 37 ] ( + 32 % relative )']",4
"['[ 3, 43,  #TAUTHOR_TAG,']","['[ 3, 43,  #TAUTHOR_TAG,']","[""[ 3, 43,  #TAUTHOR_TAG, we extract appearance feature x fr m using the detector's output from""]","['', 'embedding of question words.', 'given a question as a sequence of k words, we embed these words into the corresponding sequence of d - dimensional feature vectors { x ques k } ( where k = 1, · · ·, k ) using a pretrained bert model [ 13 ].', '1 during training, the bert parameters are fine - tuned using the question answering loss.', 'embedding of detected objects.', 'given an image, we obtain a set of m visual objects through a pretrained detector ( faster r - cnn [ 41 ] in our case ).', ""following prior work [ 3, 43,  #TAUTHOR_TAG, we extract appearance feature x fr m using the detector's output from the m - th object ( where m = 1, · · ·, m )."", 'to capture its location in the image, we introduce a 4 - dimensional location fea -', 'where w im and h im are image width and height respectively.', '']",4
"[' #TAUTHOR_TAG, where our model is']","[' #TAUTHOR_TAG, where our model is']","['lorra  #TAUTHOR_TAG, where our model is']","['##ra ( line 1 ) by as much as 9. 5 % ( absolute ) when using the same ocr system as lorra and even fewer pretrained components. we', 'also analyze the performance of our model with respect to the maximum decoding steps, shown in figure 3, where decoding for multiple steps greatly improves the performance compared with a single step. figure 4 shows', 'qualitative examples ( more examples in appendix ) of our m4c model on the textvqa dataset in comparison to lorra  #TAUTHOR_TAG, where our model is capable of selecting multiple ocr tokens and combining them with its fixed vocabulary', 'in predicted answers. qualitative insights. when inspecting the errors, we find that a major source of errors is ocr failure ( e. g. in the last example in figure 4, we find that the digits on the watch are not detected )', '. this suggests that the accuracy of our model could be improved with better', '']",4
"[' #TAUTHOR_TAG, where our model is']","[' #TAUTHOR_TAG, where our model is']","['lorra  #TAUTHOR_TAG, where our model is']","['##ra ( line 1 ) by as much as 9. 5 % ( absolute ) when using the same ocr system as lorra and even fewer pretrained components. we', 'also analyze the performance of our model with respect to the maximum decoding steps, shown in figure 3, where decoding for multiple steps greatly improves the performance compared with a single step. figure 4 shows', 'qualitative examples ( more examples in appendix ) of our m4c model on the textvqa dataset in comparison to lorra  #TAUTHOR_TAG, where our model is capable of selecting multiple ocr tokens and combining them with its fixed vocabulary', 'in predicted answers. qualitative insights. when inspecting the errors, we find that a major source of errors is ocr failure ( e. g. in the last example in figure 4, we find that the digits on the watch are not detected )', '. this suggests that the accuracy of our model could be improved with better', '']",4
"['work lorra  #TAUTHOR_TAG, suggesting that it is particularly']","['work lorra  #TAUTHOR_TAG, suggesting that it is particularly']","['the previous work lorra  #TAUTHOR_TAG, suggesting that it is particularly']","[""the iterative answer decoding process, at each step our m4c model can decode an answer word either from the model's fixed vocabulary, or from the ocr tokens extracted from the image."", 'we find in our experiments that it is necessary to have both the fixed vocabulary space and the ocr tokens.', 'table 5 shows our ablation study where we remove the fixed answer vocabulary or the dynamic pointer network for ocr copying from our m4c.', 'both these two ablated versions have a large accuracy drop compared to our full model.', 'however, we note that even without fixed answer vocabulary, our restricted model ( m4c w / o fixed vocabulary in table 5 ) still outperforms the previous work lorra  #TAUTHOR_TAG, suggesting that it is particularly important to learn to copy multiple ocr tokens to form an answer ( a key feature in our model but not in lorra )']",4
[': textvqa  #TAUTHOR_TAG ( +'],[': textvqa  #TAUTHOR_TAG ( +'],['on three challenging datasets for the textvqa task : textvqa  #TAUTHOR_TAG ( +'],"['', 'model reasons about the answer beyond a single classification step and predicts it through our pointeraugmented multi - step decoder. 3 ) we adopt a rich feature representation for text tokens in images and show that it is better than features based only on word embedding in previous work. 4 )', 'our model significantly outperforms previous work on three challenging datasets for the textvqa task : textvqa  #TAUTHOR_TAG ( + 25 % relative ), st - vqa [ 8 ] ( + 65 % relative ), and ocr - vqa [ 37 ] ( + 32 % relative )']",1
"['task, recent works  #TAUTHOR_TAG 37 ] have proposed to copy ocr tokens by adding their indices to classifier']","['textvqa task, recent works  #TAUTHOR_TAG 37 ] have proposed to copy ocr tokens by adding their indices to classifier outputs.', 'however, apart from']","['35 ] based on pointer networks [ 50 ] and its variants.', 'for the textvqa task, recent works  #TAUTHOR_TAG 37 ] have proposed to copy ocr tokens by adding their indices to classifier']","['approaches on vision - and - language tasks often combined the image and text through attention over one modality conditioned on the other modality, such as image attention based on text ( e. g. [ 51, 34 ] ).', 'some approaches have explored multimodal fusion mechanisms such as bilinear models ( e. g. [ 14, 25 ] ), self - attention ( e. g. [ 15 ] ), and graph networks ( e. g. [ 30 ] ).', 'inspired by the success of transformer [ 48 ] and bert [ 13 ] architectures in natural language tasks, several recent works [ 33, 1, 47, 31, 29, 45, 53, 11 ] have also applied transformer - based fusion between image and text with self - supervision on large - scale datasets.', 'however, most existing works treat each modality with a specific set of parameters, which makes them hard to scale to more input modalities.', 'on the other hand, in our work we project all entities from each modality into a joint embedding space and treat them homogeneously with a transformer architecture over the list of all things.', 'our results suggest that joint embedding and self - attention are efficient when modeling multiple ( more than two ) input modalities.', 'dynamic copying with pointers.', 'many answers in the textvqa task come from text tokens in the image such as book titles or street signs.', 'as it is intractable to have every possible text token in the answer vocabulary, copying text from the image would often be an easier option for answer prediction.', 'prior work has explored dynamically copying the inputs in different tasks such as text summarization [ 42 ], knowledge retrieval [ 52 ], and image captioning [ 35 ] based on pointer networks [ 50 ] and its variants.', 'for the textvqa task, recent works  #TAUTHOR_TAG 37 ] have proposed to copy ocr tokens by adding their indices to classifier outputs.', 'however, apart from their limitation of copying only a single token ( or block ), one drawback of these approaches is that they require a pre - defined number of ocr tokens ( since the classifier has a fixed output dimension ) and their output is dependent on the ordering of the tokens.', 'in this work, we overcome this drawback using a permutation - invariant pointer network together with our multimodal transformer']",6
"['[ 3, 43,  #TAUTHOR_TAG,']","['[ 3, 43,  #TAUTHOR_TAG,']","[""[ 3, 43,  #TAUTHOR_TAG, we extract appearance feature x fr m using the detector's output from""]","['', 'embedding of question words.', 'given a question as a sequence of k words, we embed these words into the corresponding sequence of d - dimensional feature vectors { x ques k } ( where k = 1, · · ·, k ) using a pretrained bert model [ 13 ].', '1 during training, the bert parameters are fine - tuned using the question answering loss.', 'embedding of detected objects.', 'given an image, we obtain a set of m visual objects through a pretrained detector ( faster r - cnn [ 41 ] in our case ).', ""following prior work [ 3, 43,  #TAUTHOR_TAG, we extract appearance feature x fr m using the detector's output from the m - th object ( where m = 1, · · ·, m )."", 'to capture its location in the image, we introduce a 4 - dimensional location fea -', 'where w im and h im are image width and height respectively.', '']",5
"['dataset  #TAUTHOR_TAG,']","['evaluate our model on three challenging datasets for the textvqa task, including the textvqa dataset  #TAUTHOR_TAG,']","['evaluate our model on three challenging datasets for the textvqa task, including the textvqa dataset  #TAUTHOR_TAG, the st - vqa dataset [ 8 ], and the ocr - vqa dataset [ 37 ].', 'our model outperforms previous work by a significant margin on']","['evaluate our model on three challenging datasets for the textvqa task, including the textvqa dataset  #TAUTHOR_TAG, the st - vqa dataset [ 8 ], and the ocr - vqa dataset [ 37 ].', 'our model outperforms previous work by a significant margin on all the three datasets']",5
"[' #TAUTHOR_TAG, where our model is']","[' #TAUTHOR_TAG, where our model is']","['lorra  #TAUTHOR_TAG, where our model is']","['##ra ( line 1 ) by as much as 9. 5 % ( absolute ) when using the same ocr system as lorra and even fewer pretrained components. we', 'also analyze the performance of our model with respect to the maximum decoding steps, shown in figure 3, where decoding for multiple steps greatly improves the performance compared with a single step. figure 4 shows', 'qualitative examples ( more examples in appendix ) of our m4c model on the textvqa dataset in comparison to lorra  #TAUTHOR_TAG, where our model is capable of selecting multiple ocr tokens and combining them with its fixed vocabulary', 'in predicted answers. qualitative insights. when inspecting the errors, we find that a major source of errors is ocr failure ( e. g. in the last example in figure 4, we find that the digits on the watch are not detected )', '. this suggests that the accuracy of our model could be improved with better', '']",5
"[' #TAUTHOR_TAG, where our model is']","[' #TAUTHOR_TAG, where our model is']","['lorra  #TAUTHOR_TAG, where our model is']","['##ra ( line 1 ) by as much as 9. 5 % ( absolute ) when using the same ocr system as lorra and even fewer pretrained components. we', 'also analyze the performance of our model with respect to the maximum decoding steps, shown in figure 3, where decoding for multiple steps greatly improves the performance compared with a single step. figure 4 shows', 'qualitative examples ( more examples in appendix ) of our m4c model on the textvqa dataset in comparison to lorra  #TAUTHOR_TAG, where our model is capable of selecting multiple ocr tokens and combining them with its fixed vocabulary', 'in predicted answers. qualitative insights. when inspecting the errors, we find that a major source of errors is ocr failure ( e. g. in the last example in figure 4, we find that the digits on the watch are not detected )', '. this suggests that the accuracy of our model could be improved with better', '']",5
"[' #TAUTHOR_TAG, where our model is']","[' #TAUTHOR_TAG, where our model is']","['lorra  #TAUTHOR_TAG, where our model is']","['##ra ( line 1 ) by as much as 9. 5 % ( absolute ) when using the same ocr system as lorra and even fewer pretrained components. we', 'also analyze the performance of our model with respect to the maximum decoding steps, shown in figure 3, where decoding for multiple steps greatly improves the performance compared with a single step. figure 4 shows', 'qualitative examples ( more examples in appendix ) of our m4c model on the textvqa dataset in comparison to lorra  #TAUTHOR_TAG, where our model is capable of selecting multiple ocr tokens and combining them with its fixed vocabulary', 'in predicted answers. qualitative insights. when inspecting the errors, we find that a major source of errors is ocr failure ( e. g. in the last example in figure 4, we find that the digits on the watch are not detected )', '. this suggests that the accuracy of our model could be improved with better', '']",5
"['2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier']","['attempted to generate more naturally sounding speech by conditioning a tts model via speaker and prosody embedding [ 2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier']","['2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier work  #TAUTHOR_TAG']","['tacotron [ 1 ] paved the way for end - to - end text - to - speech ( tts ) using neural networks, researchers have attempted to generate more naturally sounding speech by conditioning a tts model via speaker and prosody embedding [ 2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier work  #TAUTHOR_TAG henceforth. ) because there is no available label for prosody, learning to control prosody in tts is a difficult problem to tackle.', 'recent approaches learn to extract prosody embedding from reference speech in an unsupervised manner and use prosody embedding to control the speech style  #TAUTHOR_TAG 5 ].', 'these models have demonstrated ability to generate speech with expressive styles with tacotron [ 1 ] using prosody embedding.', 'they can also transfer the prosody of one speaker to another using a different speaker id while leaving the prosody embedding unchanged.', 'however, we observed two limitations with the above models.', 'first, controlling the prosody at a specific moment of generated speech is not clear.', 'earlier works focused on prosody embedding with a fixed length ( a length of 1 in their experiments ) regardless of the length of the reference speech or that of the text input.', 'a loss of temporal information when squeezing reference speech into a fixed length embedding is highly likely.', 'therefore, fine - grained control of prosody at a specific moment of speech is difficult for embedding with a fixed length.', 'for example, we can set the global style as "" lively "" or "" sad, "" but we cannot control the prosody of a specific moment with fixed - length embedding.', ""because humans are sensitive to subtle changes of nuance, it is important to ensure finegrained control of prosody to represent one's intentions precisely."", 'secondly, inter - speaker prosody transfer is not robust if the difference between the pitch range of the source speaker and the target speaker is significant.', 'for example, when the source speaker ( female ) has higher pitch than the target speaker ( male ), the prosodytransferred speech tends to show a higher pitch than the usual pitch of the target speaker.', 'in this work, we focus on solving these two problems.', 'we will introduce two types of variable - length prosody embedding which have the same length as the reference speech or input text to enable sequential control of prosody.', 'in addition, we will show that normalizing prosody embedding helps to maintain the robustness of prosody transfers against speaker perturbations.', 'with our methods, speaker - normalized variable - length prosody embedding was able']",0
"['2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier']","['attempted to generate more naturally sounding speech by conditioning a tts model via speaker and prosody embedding [ 2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier']","['2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier work  #TAUTHOR_TAG']","['tacotron [ 1 ] paved the way for end - to - end text - to - speech ( tts ) using neural networks, researchers have attempted to generate more naturally sounding speech by conditioning a tts model via speaker and prosody embedding [ 2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier work  #TAUTHOR_TAG henceforth. ) because there is no available label for prosody, learning to control prosody in tts is a difficult problem to tackle.', 'recent approaches learn to extract prosody embedding from reference speech in an unsupervised manner and use prosody embedding to control the speech style  #TAUTHOR_TAG 5 ].', 'these models have demonstrated ability to generate speech with expressive styles with tacotron [ 1 ] using prosody embedding.', 'they can also transfer the prosody of one speaker to another using a different speaker id while leaving the prosody embedding unchanged.', 'however, we observed two limitations with the above models.', 'first, controlling the prosody at a specific moment of generated speech is not clear.', 'earlier works focused on prosody embedding with a fixed length ( a length of 1 in their experiments ) regardless of the length of the reference speech or that of the text input.', 'a loss of temporal information when squeezing reference speech into a fixed length embedding is highly likely.', 'therefore, fine - grained control of prosody at a specific moment of speech is difficult for embedding with a fixed length.', 'for example, we can set the global style as "" lively "" or "" sad, "" but we cannot control the prosody of a specific moment with fixed - length embedding.', ""because humans are sensitive to subtle changes of nuance, it is important to ensure finegrained control of prosody to represent one's intentions precisely."", 'secondly, inter - speaker prosody transfer is not robust if the difference between the pitch range of the source speaker and the target speaker is significant.', 'for example, when the source speaker ( female ) has higher pitch than the target speaker ( male ), the prosodytransferred speech tends to show a higher pitch than the usual pitch of the target speaker.', 'in this work, we focus on solving these two problems.', 'we will introduce two types of variable - length prosody embedding which have the same length as the reference speech or input text to enable sequential control of prosody.', 'in addition, we will show that normalizing prosody embedding helps to maintain the robustness of prosody transfers against speaker perturbations.', 'with our methods, speaker - normalized variable - length prosody embedding was able']",0
"['of the reference speech  #TAUTHOR_TAG.', '']","['compress the prosody of the reference speech  #TAUTHOR_TAG.', '']","['compress the prosody of the reference speech  #TAUTHOR_TAG.', '']","['##ody modeling had been done in a supervised manner by using annotated labels, such as those in tobi [ 7 ].', 'problems were reported about hand annotations, and the cost was high [ 8 ].', 'skerry - ryan et al. used convolutional neural networks and a gated recurrent unit ( gru ) [ 9 ] to compress the prosody of the reference speech  #TAUTHOR_TAG.', 'the output, denoted by p, is fixed - length prosody embedding.', 'they enabled prosody transfers using the prosody embedding, but they could not gain control of prosody at a specific point of time.', 'another problem was also reported [ 5 ] ; fixed - length prosody embedding worked poorly if the length of the reference speech was shorter than the speech to generate.', 'in addition, variablelength prosody embedding was also implemented using the output of the gru at every time step  #TAUTHOR_TAG.', 'however, this method did not draw attention because it could not obtain satisfactory results given that it was not robust with regard to text and speaker perturbations.', 'we noted the usefulness of variable - length prosody and elaborated on this concept for fine - grained prosody control.', 'wang et al. came up with the global style token ( gst ) tacotron to encode different speaking styles [ 5 ].', 'although they used the same reference encoder architecture used in earlier work  #TAUTHOR_TAG, they did not use p itself for prosody embedding.', 'using a content - based attention, they computed the attention weights for style tokens from p. the attention weights represent the contribution of each style token, and the weighted sum of the style tokens is now used for style embedding.', 'during the training step, each randomly initialized style token learns the speaking style in an unsupervised manner.', 'in the inference mode, it was possible to control prosody by either predicting the style embedding from the reference speech or specifying the attention weights of the style tokens.', 'this enables explicit control of the speaking style, but it nonetheless worked only in a global sense.', 'if we are interested in controlling the prosody of a phoneme, it would be ideal to obtain the same prosody for different phonemes when the phonemes are conditioned on the same prosody embedding.', 'however, gst tacotron generates various types of prosody for input phonemes that are conditioned on the same style embedding, which is not desirable for prosody control.', 'wang et al. also proposed text - side style control using multiple style embeddings for different segments of input text.', 'this method could roughly change the style of the text segments, but it is limited when used to control']",0
"['to prosody embedding using the reference encoder  #TAUTHOR_TAG.', 'a mel - spectro']","['to prosody embedding using the reference encoder  #TAUTHOR_TAG.', 'a mel - spectrogram of the reference speech proceeds through 2d - convolutional layers.', 'the']","['decoder state, respectively.', 'reference speech is encoded to prosody embedding using the reference encoder  #TAUTHOR_TAG.', 'a mel - spectrogram of the reference speech proceeds through 2d - convolutional layers.', 'the output of']","['used a simplified version [ 10 ] of tacotron for the base encoderdecoder architecture, but we used the original tacotron [ 1 ] style of the post - processing net and the griffin - lim algorithm [ 11 ] for spectrogram - to - waveform conversion.', 'for the encoder input x, we used the phoneme sequence of normalized text to ease the learning.', 'the one - hot speaker identity is converted into speaker embedding vector s by the embedding lookup layer.', 'equation 1 describes the base encoder - decoder, where e, p, and d denote the text encoder state, variable - length prosody embedding, and decoder state, respectively.', 'reference speech is encoded to prosody embedding using the reference encoder  #TAUTHOR_TAG.', 'a mel - spectrogram of the reference speech proceeds through 2d - convolutional layers.', 'the output of the last convolutional layer is fed to a uni - directional gru.', 'the last output of gru rn is the fixed - length prosody embedding p. if we use every output of gru r1 : n for prosody embedding, it forms the variablelength prosody embedding p1 : n']",0
"['2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier']","['attempted to generate more naturally sounding speech by conditioning a tts model via speaker and prosody embedding [ 2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier']","['2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier work  #TAUTHOR_TAG']","['tacotron [ 1 ] paved the way for end - to - end text - to - speech ( tts ) using neural networks, researchers have attempted to generate more naturally sounding speech by conditioning a tts model via speaker and prosody embedding [ 2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier work  #TAUTHOR_TAG henceforth. ) because there is no available label for prosody, learning to control prosody in tts is a difficult problem to tackle.', 'recent approaches learn to extract prosody embedding from reference speech in an unsupervised manner and use prosody embedding to control the speech style  #TAUTHOR_TAG 5 ].', 'these models have demonstrated ability to generate speech with expressive styles with tacotron [ 1 ] using prosody embedding.', 'they can also transfer the prosody of one speaker to another using a different speaker id while leaving the prosody embedding unchanged.', 'however, we observed two limitations with the above models.', 'first, controlling the prosody at a specific moment of generated speech is not clear.', 'earlier works focused on prosody embedding with a fixed length ( a length of 1 in their experiments ) regardless of the length of the reference speech or that of the text input.', 'a loss of temporal information when squeezing reference speech into a fixed length embedding is highly likely.', 'therefore, fine - grained control of prosody at a specific moment of speech is difficult for embedding with a fixed length.', 'for example, we can set the global style as "" lively "" or "" sad, "" but we cannot control the prosody of a specific moment with fixed - length embedding.', ""because humans are sensitive to subtle changes of nuance, it is important to ensure finegrained control of prosody to represent one's intentions precisely."", 'secondly, inter - speaker prosody transfer is not robust if the difference between the pitch range of the source speaker and the target speaker is significant.', 'for example, when the source speaker ( female ) has higher pitch than the target speaker ( male ), the prosodytransferred speech tends to show a higher pitch than the usual pitch of the target speaker.', 'in this work, we focus on solving these two problems.', 'we will introduce two types of variable - length prosody embedding which have the same length as the reference speech or input text to enable sequential control of prosody.', 'in addition, we will show that normalizing prosody embedding helps to maintain the robustness of prosody transfers against speaker perturbations.', 'with our methods, speaker - normalized variable - length prosody embedding was able']",3
['hyperparameter settings used in earlier work  #TAUTHOR_TAG'],['hyperparameter settings used in earlier work  #TAUTHOR_TAG'],"['the reference encoder.', 'unless otherwise stated, we used the same hyperparameter settings used in earlier work  #TAUTHOR_TAG']","['empirically found that the following modifications improved the generation quality.', 'we used coordconv [ 12 ] for the first convolutional layer.', 'according to its construction, coordconv can utilize positional information while losing the translation invariance.', 'we speculate that the positional information was helpful to encode prosody sequentially.', 'we used relu as the activation function to force the values of the prosody embedding to lie in [ 0, 1 ].', 'the proposed models are trained identically to the tacotron model.', 'the model is trained according to the l1 loss between the target spectrogram and the generated spectrogram, and no other supervision is given for the reference encoder.', 'unless otherwise stated, we used the same hyperparameter settings used in earlier work  #TAUTHOR_TAG']",3
['works  #TAUTHOR_TAG 5 ] used large'],['works  #TAUTHOR_TAG 5 ] used large'],['works  #TAUTHOR_TAG 5 ] used large amounts of data'],"['works  #TAUTHOR_TAG 5 ] used large amounts of data to train the prosodic tts model ( 296 hours of data for the multi - speaker model ).', 'to ensure a large amount of data, we used multiple datasets, in this case vctk, cmu arctic, and internal datasets.', 'the final dataset consisted of 104 hours ( 58 hours of english and 46 hours of korean ) with 136 speakers ( 128 english speakers and 8 korean speakers ).', 'because variable - length prosody embedding has a large enough capacity to copy the reference audio, we had to use a very small dimension for the bottleneck size.', 'this led us to the use of prosody sizes of 2 and 4 for the speech - side and text - side prosody embedding, respectively']",3
"[') with the first 13 mfccs, as proposed in earlier work  #TAUTHOR_TAG.', 'table 1 shows that']","['mean cepstral distortion ( mcd ) with the first 13 mfccs, as proposed in earlier work  #TAUTHOR_TAG.', 'table 1 shows that']","[') with the first 13 mfccs, as proposed in earlier work  #TAUTHOR_TAG.', 'table 1 shows that']","['compared our methods to gst tacotron both quantitatively and qualitatively.', 'for the quantitative comparison, we used the mean cepstral distortion ( mcd ) with the first 13 mfccs, as proposed in earlier work  #TAUTHOR_TAG.', 'table 1 shows that the proposed methods outperform gst tacotron in terms of mcd13, where a lower mcd is better.', '']",3
"['2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier']","['attempted to generate more naturally sounding speech by conditioning a tts model via speaker and prosody embedding [ 2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier']","['2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier work  #TAUTHOR_TAG']","['tacotron [ 1 ] paved the way for end - to - end text - to - speech ( tts ) using neural networks, researchers have attempted to generate more naturally sounding speech by conditioning a tts model via speaker and prosody embedding [ 2, 3,  #TAUTHOR_TAG 5, 6 ].', '( we use the term prosody as defined in earlier work  #TAUTHOR_TAG henceforth. ) because there is no available label for prosody, learning to control prosody in tts is a difficult problem to tackle.', 'recent approaches learn to extract prosody embedding from reference speech in an unsupervised manner and use prosody embedding to control the speech style  #TAUTHOR_TAG 5 ].', 'these models have demonstrated ability to generate speech with expressive styles with tacotron [ 1 ] using prosody embedding.', 'they can also transfer the prosody of one speaker to another using a different speaker id while leaving the prosody embedding unchanged.', 'however, we observed two limitations with the above models.', 'first, controlling the prosody at a specific moment of generated speech is not clear.', 'earlier works focused on prosody embedding with a fixed length ( a length of 1 in their experiments ) regardless of the length of the reference speech or that of the text input.', 'a loss of temporal information when squeezing reference speech into a fixed length embedding is highly likely.', 'therefore, fine - grained control of prosody at a specific moment of speech is difficult for embedding with a fixed length.', 'for example, we can set the global style as "" lively "" or "" sad, "" but we cannot control the prosody of a specific moment with fixed - length embedding.', ""because humans are sensitive to subtle changes of nuance, it is important to ensure finegrained control of prosody to represent one's intentions precisely."", 'secondly, inter - speaker prosody transfer is not robust if the difference between the pitch range of the source speaker and the target speaker is significant.', 'for example, when the source speaker ( female ) has higher pitch than the target speaker ( male ), the prosodytransferred speech tends to show a higher pitch than the usual pitch of the target speaker.', 'in this work, we focus on solving these two problems.', 'we will introduce two types of variable - length prosody embedding which have the same length as the reference speech or input text to enable sequential control of prosody.', 'in addition, we will show that normalizing prosody embedding helps to maintain the robustness of prosody transfers against speaker perturbations.', 'with our methods, speaker - normalized variable - length prosody embedding was able']",5
['hyperparameter settings used in earlier work  #TAUTHOR_TAG'],['hyperparameter settings used in earlier work  #TAUTHOR_TAG'],"['the reference encoder.', 'unless otherwise stated, we used the same hyperparameter settings used in earlier work  #TAUTHOR_TAG']","['empirically found that the following modifications improved the generation quality.', 'we used coordconv [ 12 ] for the first convolutional layer.', 'according to its construction, coordconv can utilize positional information while losing the translation invariance.', 'we speculate that the positional information was helpful to encode prosody sequentially.', 'we used relu as the activation function to force the values of the prosody embedding to lie in [ 0, 1 ].', 'the proposed models are trained identically to the tacotron model.', 'the model is trained according to the l1 loss between the target spectrogram and the generated spectrogram, and no other supervision is given for the reference encoder.', 'unless otherwise stated, we used the same hyperparameter settings used in earlier work  #TAUTHOR_TAG']",5
['works  #TAUTHOR_TAG 5 ] used large'],['works  #TAUTHOR_TAG 5 ] used large'],['works  #TAUTHOR_TAG 5 ] used large amounts of data'],"['works  #TAUTHOR_TAG 5 ] used large amounts of data to train the prosodic tts model ( 296 hours of data for the multi - speaker model ).', 'to ensure a large amount of data, we used multiple datasets, in this case vctk, cmu arctic, and internal datasets.', 'the final dataset consisted of 104 hours ( 58 hours of english and 46 hours of korean ) with 136 speakers ( 128 english speakers and 8 korean speakers ).', 'because variable - length prosody embedding has a large enough capacity to copy the reference audio, we had to use a very small dimension for the bottleneck size.', 'this led us to the use of prosody sizes of 2 and 4 for the speech - side and text - side prosody embedding, respectively']",5
"[') with the first 13 mfccs, as proposed in earlier work  #TAUTHOR_TAG.', 'table 1 shows that']","['mean cepstral distortion ( mcd ) with the first 13 mfccs, as proposed in earlier work  #TAUTHOR_TAG.', 'table 1 shows that']","[') with the first 13 mfccs, as proposed in earlier work  #TAUTHOR_TAG.', 'table 1 shows that']","['compared our methods to gst tacotron both quantitatively and qualitatively.', 'for the quantitative comparison, we used the mean cepstral distortion ( mcd ) with the first 13 mfccs, as proposed in earlier work  #TAUTHOR_TAG.', 'table 1 shows that the proposed methods outperform gst tacotron in terms of mcd13, where a lower mcd is better.', '']",5
"['of the reference speech  #TAUTHOR_TAG.', '']","['compress the prosody of the reference speech  #TAUTHOR_TAG.', '']","['compress the prosody of the reference speech  #TAUTHOR_TAG.', '']","['##ody modeling had been done in a supervised manner by using annotated labels, such as those in tobi [ 7 ].', 'problems were reported about hand annotations, and the cost was high [ 8 ].', 'skerry - ryan et al. used convolutional neural networks and a gated recurrent unit ( gru ) [ 9 ] to compress the prosody of the reference speech  #TAUTHOR_TAG.', 'the output, denoted by p, is fixed - length prosody embedding.', 'they enabled prosody transfers using the prosody embedding, but they could not gain control of prosody at a specific point of time.', 'another problem was also reported [ 5 ] ; fixed - length prosody embedding worked poorly if the length of the reference speech was shorter than the speech to generate.', 'in addition, variablelength prosody embedding was also implemented using the output of the gru at every time step  #TAUTHOR_TAG.', 'however, this method did not draw attention because it could not obtain satisfactory results given that it was not robust with regard to text and speaker perturbations.', 'we noted the usefulness of variable - length prosody and elaborated on this concept for fine - grained prosody control.', 'wang et al. came up with the global style token ( gst ) tacotron to encode different speaking styles [ 5 ].', 'although they used the same reference encoder architecture used in earlier work  #TAUTHOR_TAG, they did not use p itself for prosody embedding.', 'using a content - based attention, they computed the attention weights for style tokens from p. the attention weights represent the contribution of each style token, and the weighted sum of the style tokens is now used for style embedding.', 'during the training step, each randomly initialized style token learns the speaking style in an unsupervised manner.', 'in the inference mode, it was possible to control prosody by either predicting the style embedding from the reference speech or specifying the attention weights of the style tokens.', 'this enables explicit control of the speaking style, but it nonetheless worked only in a global sense.', 'if we are interested in controlling the prosody of a phoneme, it would be ideal to obtain the same prosody for different phonemes when the phonemes are conditioned on the same prosody embedding.', 'however, gst tacotron generates various types of prosody for input phonemes that are conditioned on the same style embedding, which is not desirable for prosody control.', 'wang et al. also proposed text - side style control using multiple style embeddings for different segments of input text.', 'this method could roughly change the style of the text segments, but it is limited when used to control']",4
"['of the reference speech  #TAUTHOR_TAG.', '']","['compress the prosody of the reference speech  #TAUTHOR_TAG.', '']","['compress the prosody of the reference speech  #TAUTHOR_TAG.', '']","['##ody modeling had been done in a supervised manner by using annotated labels, such as those in tobi [ 7 ].', 'problems were reported about hand annotations, and the cost was high [ 8 ].', 'skerry - ryan et al. used convolutional neural networks and a gated recurrent unit ( gru ) [ 9 ] to compress the prosody of the reference speech  #TAUTHOR_TAG.', 'the output, denoted by p, is fixed - length prosody embedding.', 'they enabled prosody transfers using the prosody embedding, but they could not gain control of prosody at a specific point of time.', 'another problem was also reported [ 5 ] ; fixed - length prosody embedding worked poorly if the length of the reference speech was shorter than the speech to generate.', 'in addition, variablelength prosody embedding was also implemented using the output of the gru at every time step  #TAUTHOR_TAG.', 'however, this method did not draw attention because it could not obtain satisfactory results given that it was not robust with regard to text and speaker perturbations.', 'we noted the usefulness of variable - length prosody and elaborated on this concept for fine - grained prosody control.', 'wang et al. came up with the global style token ( gst ) tacotron to encode different speaking styles [ 5 ].', 'although they used the same reference encoder architecture used in earlier work  #TAUTHOR_TAG, they did not use p itself for prosody embedding.', 'using a content - based attention, they computed the attention weights for style tokens from p. the attention weights represent the contribution of each style token, and the weighted sum of the style tokens is now used for style embedding.', 'during the training step, each randomly initialized style token learns the speaking style in an unsupervised manner.', 'in the inference mode, it was possible to control prosody by either predicting the style embedding from the reference speech or specifying the attention weights of the style tokens.', 'this enables explicit control of the speaking style, but it nonetheless worked only in a global sense.', 'if we are interested in controlling the prosody of a phoneme, it would be ideal to obtain the same prosody for different phonemes when the phonemes are conditioned on the same prosody embedding.', 'however, gst tacotron generates various types of prosody for input phonemes that are conditioned on the same style embedding, which is not desirable for prosody control.', 'wang et al. also proposed text - side style control using multiple style embeddings for different segments of input text.', 'this method could roughly change the style of the text segments, but it is limited when used to control']",4
"['of the reference speech  #TAUTHOR_TAG.', '']","['compress the prosody of the reference speech  #TAUTHOR_TAG.', '']","['compress the prosody of the reference speech  #TAUTHOR_TAG.', '']","['##ody modeling had been done in a supervised manner by using annotated labels, such as those in tobi [ 7 ].', 'problems were reported about hand annotations, and the cost was high [ 8 ].', 'skerry - ryan et al. used convolutional neural networks and a gated recurrent unit ( gru ) [ 9 ] to compress the prosody of the reference speech  #TAUTHOR_TAG.', 'the output, denoted by p, is fixed - length prosody embedding.', 'they enabled prosody transfers using the prosody embedding, but they could not gain control of prosody at a specific point of time.', 'another problem was also reported [ 5 ] ; fixed - length prosody embedding worked poorly if the length of the reference speech was shorter than the speech to generate.', 'in addition, variablelength prosody embedding was also implemented using the output of the gru at every time step  #TAUTHOR_TAG.', 'however, this method did not draw attention because it could not obtain satisfactory results given that it was not robust with regard to text and speaker perturbations.', 'we noted the usefulness of variable - length prosody and elaborated on this concept for fine - grained prosody control.', 'wang et al. came up with the global style token ( gst ) tacotron to encode different speaking styles [ 5 ].', 'although they used the same reference encoder architecture used in earlier work  #TAUTHOR_TAG, they did not use p itself for prosody embedding.', 'using a content - based attention, they computed the attention weights for style tokens from p. the attention weights represent the contribution of each style token, and the weighted sum of the style tokens is now used for style embedding.', 'during the training step, each randomly initialized style token learns the speaking style in an unsupervised manner.', 'in the inference mode, it was possible to control prosody by either predicting the style embedding from the reference speech or specifying the attention weights of the style tokens.', 'this enables explicit control of the speaking style, but it nonetheless worked only in a global sense.', 'if we are interested in controlling the prosody of a phoneme, it would be ideal to obtain the same prosody for different phonemes when the phonemes are conditioned on the same prosody embedding.', 'however, gst tacotron generates various types of prosody for input phonemes that are conditioned on the same style embedding, which is not desirable for prosody control.', 'wang et al. also proposed text - side style control using multiple style embeddings for different segments of input text.', 'this method could roughly change the style of the text segments, but it is limited when used to control']",6
"['of the nature of concrete vs. abstract words from a corpus - based perspective  #TAUTHOR_TAG.', 'in these studies, the authors have shown']","['of the nature of concrete vs. abstract words from a corpus - based perspective  #TAUTHOR_TAG.', 'in these studies, the authors have shown']","['##te im  #AUTHOR_TAG.', 'recently, multiple studies have focussed on providing a fine - grained analysis of the nature of concrete vs. abstract words from a corpus - based perspective  #TAUTHOR_TAG.', 'in these studies, the authors have shown']","['need of providing a clear description of the usage of concrete and abstract words in communication is becoming salient both in cognitive science and in computational linguistics.', 'in the cognitive science community, much has been said about concrete concepts, but there is still an open debate about the nature of abstract concepts ( barsalou and wiemer -  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'computational linguists have recognised the importance of investigating the concreteness of contexts in empirical models, for example for the automatic identification of non - literal language usage  #AUTHOR_TAG koper and schulte im  #AUTHOR_TAG.', 'recently, multiple studies have focussed on providing a fine - grained analysis of the nature of concrete vs. abstract words from a corpus - based perspective  #TAUTHOR_TAG.', 'in these studies, the authors have shown a general but consistent pattern : concrete words have a preference to co - occur with other concrete words, while abstract words co - occur more frequently with abstract words.', 'specifically,  #TAUTHOR_TAG performed their analyses across parts - of - speech by comparing the behaviour of nouns, verbs and adjectives in large - scale corpora.', 'these results are not fully in line with various theories of cognition which suggest that both concrete and abstract words should co - occur more often with concrete words because concrete information links the real - world usage of both concrete and abstract words to their mental representation  #AUTHOR_TAG']",0
"['of the nature of concrete vs. abstract words from a corpus - based perspective  #TAUTHOR_TAG.', 'in these studies, the authors have shown']","['of the nature of concrete vs. abstract words from a corpus - based perspective  #TAUTHOR_TAG.', 'in these studies, the authors have shown']","['##te im  #AUTHOR_TAG.', 'recently, multiple studies have focussed on providing a fine - grained analysis of the nature of concrete vs. abstract words from a corpus - based perspective  #TAUTHOR_TAG.', 'in these studies, the authors have shown']","['need of providing a clear description of the usage of concrete and abstract words in communication is becoming salient both in cognitive science and in computational linguistics.', 'in the cognitive science community, much has been said about concrete concepts, but there is still an open debate about the nature of abstract concepts ( barsalou and wiemer -  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'computational linguists have recognised the importance of investigating the concreteness of contexts in empirical models, for example for the automatic identification of non - literal language usage  #AUTHOR_TAG koper and schulte im  #AUTHOR_TAG.', 'recently, multiple studies have focussed on providing a fine - grained analysis of the nature of concrete vs. abstract words from a corpus - based perspective  #TAUTHOR_TAG.', 'in these studies, the authors have shown a general but consistent pattern : concrete words have a preference to co - occur with other concrete words, while abstract words co - occur more frequently with abstract words.', 'specifically,  #TAUTHOR_TAG performed their analyses across parts - of - speech by comparing the behaviour of nouns, verbs and adjectives in large - scale corpora.', 'these results are not fully in line with various theories of cognition which suggest that both concrete and abstract words should co - occur more often with concrete words because concrete information links the real - world usage of both concrete and abstract words to their mental representation  #AUTHOR_TAG']",0
"['studies by  #TAUTHOR_TAG and  #AUTHOR_TAG, mid - range concreteness scores indicate words that are difficult to categorise unambiguously regarding their concreteness.', '']","['studies by  #TAUTHOR_TAG and  #AUTHOR_TAG, mid - range concreteness scores indicate words that are difficult to categorise unambiguously regarding their concreteness.', '']","['most frequent pos from the 10 - billion word corpus encow16ax ( see below for details ).', 'moreover, as discussed in previous studies by  #TAUTHOR_TAG and  #AUTHOR_TAG, mid - range concreteness scores indicate words that are difficult to categorise unambiguously regarding their concreteness.', '']","['the following analyses, we used nouns and verbs extracted from the  #AUTHOR_TAG collection of concreteness ratings.', 'in this resource, the concreteness of 40, 000 english words was evaluated by human participants on a scale from 1 ( abstract ) to 5 ( concrete ).', 'given that participants did not have any overt information about part - of - speech ( henceforth, pos ) while performing the norming study, brysbaert et al. added this information post - hoc from the subtlex - us, a 51 - million word subtitle corpus  #AUTHOR_TAG.', 'in order to align the pos information to the current study, we disambiguated the pos of the normed words by extracting their most frequent pos from the 10 - billion word corpus encow16ax ( see below for details ).', 'moreover, as discussed in previous studies by  #TAUTHOR_TAG and  #AUTHOR_TAG, mid - range concreteness scores indicate words that are difficult to categorise unambiguously regarding their concreteness.', 'for this reason and in order to obtain a clear picture of the behaviour of concrete vs. abstract words, we selected only words with very high ( concrete ) or very low ( abstract ) concreteness scores.', '']",0
"['main results from  #TAUTHOR_TAG : in general, concrete']","['main results from  #TAUTHOR_TAG : in general, concrete']","['the main results from  #TAUTHOR_TAG : in general, concrete nouns should co - occur more frequently with concrete verbs']","['', 'first of all, we expect to replicate the main results from  #TAUTHOR_TAG : in general, concrete nouns should co - occur more frequently with concrete verbs and abstract nouns with abstract verbs.', 'moreover, we expect to identify the main patterns that characterise semantic effects of an interaction of concreteness in verb - noun subcategorisation, such as collocations and meaning shifts.', 'the motivation for this study is twofold : ( 1 ) from a cognitive science perspective we seek additional and more fine - grained evidence to better understand the clash between the existing corpus - based studies and the theories of cognition which predict predominantly concrete information in the context of both concrete and abstract words.', '( 2 ) from a computational perspective we expect some variability in the interaction of concreteness in verb - noun subcategorisation, given that abstract contexts are ubiquitous and salient empirical indicators for non - literal language identification, cf. carry a bag vs. carry a risk']",7
"['by  #TAUTHOR_TAG.', 'table 1 investigates more deeply the interaction between']","['by  #TAUTHOR_TAG.', 'table 1 investigates more deeply the interaction between']","['. 001 ).', 'this result is perfectly in line with the more general analysis by  #TAUTHOR_TAG.', 'table 1 investigates more deeply the interaction between the concreteness of verbs and nouns']","['a pre - test we analysed the overall distributions of verbs and nouns according to their concreteness scores.', 'figure 1 shows the overall distributions of verbs ( left, m = 3. 4, sd = 1. 1 ) and nouns ( right, m = 3. 9, sd = 1. 6 ) included in our analyses.', 'overall, nouns have significantly more extreme values than verbs : the majority of concrete nouns have concreteness scores clustering around 5. 00 while concrete verbs cluster around 4. 0.', 'similarly, abstract nouns have significantly lower scores ( i. e., they are more abstract ) than abstract verbs.', 'the numerical difference in the presence of extreme scores is also highlighted by the much higher standard deviation characterising nouns compared to verbs.', 'we interpret the lower amount of "" real "" extremes ( 1 and 5 ) for verbs as an indicator of the difficulty that participants had to clearly norm verbs compared to nouns.', 'for example, while comparing the nouns belief 1. 2 and ball 5. 0 humans would have a clear agreement on highly abstract and highly concrete scores ; on the contrary, the distinction between moralise 1. 4 and sit 4. 8 might be less clear.', 'in our main study, we analysed the concreteness of the nouns that are in a specific and direct syntactic relation with verbs.', 'the overall distributions in figure 2 are extremely consistent across syntactic relations : when looking at the means, the concreteness of nouns subcategorised by concrete verbs is significantly higher than the concreteness of nouns subcategorised by abstract verbs ( all p - values < 0. 001 ).', 'this result is perfectly in line with the more general analysis by  #TAUTHOR_TAG.', 'table 1 investigates more deeply the interaction between the concreteness of verbs and nouns for different syntactic functions.', 'it reports the average concreteness scores of the nouns subcategorised by concrete and abstract verbs ( ± standard deviation ), the difference between the concrete and abstract scores ( with significance tests ) and the overall average concreteness score by function.', 'the statistical analyses have been performed using a standard linear regression model.', 'the comparison between the scores in the first two columns ( abstract verbs and concrete verbs ) confirms that subject and direct object nouns that are subcategorised by concrete verbs are significantly more concrete than those subcategorised by abstract verbs.', 'the "" difference c - a "" column shows that these differences are all highly significant.', 'in addition, the nouns subcategorised by concrete verbs are extremely high on the concreteness scale ( mean 1 in this paper the number in subscript indicates the concreteness score from the  #AUTHOR_TAG']",3
"['##ategorisation.', 'the general pattern already described in  #TAUTHOR_TAG is confirmed by our quantitative']","['of the concreteness nature in verbnoun subcategorisation.', 'the general pattern already described in  #TAUTHOR_TAG is confirmed by our quantitative analysis : overall, concrete']","['##noun subcategorisation.', 'the general pattern already described in  #TAUTHOR_TAG is confirmed by our quantitative analysis : overall, concrete verbs']",[' #TAUTHOR_TAG'],3
"['.  #TAUTHOR_TAG apply a', 'cnn -']","['.  #TAUTHOR_TAG apply a', 'cnn -']","['.  #TAUTHOR_TAG apply a', 'cnn -']","['', 'a multi - label classification problem to accommodate the cda scenario. qu et al.  #TAUTHOR_TAG apply a', 'cnn - based text classifier proposed by kim [ 8 ] using a', 'fixed window to represent the context. although capable of classifying utterances', ""with cdas, qu et al.  #TAUTHOR_TAG's model only concerns a strictly - local context range and thus cannot include distant information. in this paper, we present a novel neural model that is adapted from convolutional"", '']",0
"['.  #TAUTHOR_TAG apply a', 'cnn -']","['.  #TAUTHOR_TAG apply a', 'cnn -']","['.  #TAUTHOR_TAG apply a', 'cnn -']","['', 'a multi - label classification problem to accommodate the cda scenario. qu et al.  #TAUTHOR_TAG apply a', 'cnn - based text classifier proposed by kim [ 8 ] using a', 'fixed window to represent the context. although capable of classifying utterances', ""with cdas, qu et al.  #TAUTHOR_TAG's model only concerns a strictly - local context range and thus cannot include distant information. in this paper, we present a novel neural model that is adapted from convolutional"", '']",0
"['.  #TAUTHOR_TAG apply a', 'cnn -']","['.  #TAUTHOR_TAG apply a', 'cnn -']","['.  #TAUTHOR_TAG apply a', 'cnn -']","['', 'a multi - label classification problem to accommodate the cda scenario. qu et al.  #TAUTHOR_TAG apply a', 'cnn - based text classifier proposed by kim [ 8 ] using a', 'fixed window to represent the context. although capable of classifying utterances', ""with cdas, qu et al.  #TAUTHOR_TAG's model only concerns a strictly - local context range and thus cannot include distant information. in this paper, we present a novel neural model that is adapted from convolutional"", '']",1
"['use the msdialog - intent dataset  #TAUTHOR_TAG to conduct experiments.', 'in the dataset, each of the 10,']","['use the msdialog - intent dataset  #TAUTHOR_TAG to conduct experiments.', 'in the dataset, each of the 10, 020 utterances is annotated with a subset of 12 das.', 'the abundance of information in a single']","['use the msdialog - intent dataset  #TAUTHOR_TAG to conduct experiments.', 'in the dataset, each of the 10, 020 utterances is annotated with a subset of 12 das.', 'the abundance of information in a single utterance (']","['use the msdialog - intent dataset  #TAUTHOR_TAG to conduct experiments.', 'in the dataset, each of the 10, 020 utterances is annotated with a subset of 12 das.', 'the abundance of information in a single utterance ( avg. 72 tokens / utterance ) breeds cda ( avg. 1. 83 das / utterance ).', 'we observe a strong correlation between the number of das and utterance length, which necessitates a cda model for forum conversations.', 'the dataset includes plenty of metadata for each utterance, e. g., answer vote and user affiliation.', 'for generalizability, our model only incorporates textual content of the dialogues.', 'besides, unlike qu et al.  #TAUTHOR_TAG, we keep all the da annotations in the dataset to preserve the meaningful da structures within and across utterances.', '']",5
"[' #TAUTHOR_TAG on multi - label classification, we adopt label - based']","[' #TAUTHOR_TAG on multi - label classification, we adopt label - based']","['previous work  #TAUTHOR_TAG on multi - label classification, we adopt label - based accuracy (']","['previous work  #TAUTHOR_TAG on multi - label classification, we adopt label - based accuracy ( i. e., hamming score ) and micro - f 1 score as our main evaluation metrics.', 'micro - precision and micro - recall are also reported to assist the analysis.', 'among all, accuracy is the only metrics that is on a per utterance basis.', ""therefore, student's paired t - test is performed only on accuracy."", 'other metrics ( p, r, f 1 ) provide an overall performance evaluation for all utterances']",5
"['use the msdialog - intent dataset  #TAUTHOR_TAG to conduct experiments.', 'in the dataset, each of the 10,']","['use the msdialog - intent dataset  #TAUTHOR_TAG to conduct experiments.', 'in the dataset, each of the 10, 020 utterances is annotated with a subset of 12 das.', 'the abundance of information in a single']","['use the msdialog - intent dataset  #TAUTHOR_TAG to conduct experiments.', 'in the dataset, each of the 10, 020 utterances is annotated with a subset of 12 das.', 'the abundance of information in a single utterance (']","['use the msdialog - intent dataset  #TAUTHOR_TAG to conduct experiments.', 'in the dataset, each of the 10, 020 utterances is annotated with a subset of 12 das.', 'the abundance of information in a single utterance ( avg. 72 tokens / utterance ) breeds cda ( avg. 1. 83 das / utterance ).', 'we observe a strong correlation between the number of das and utterance length, which necessitates a cda model for forum conversations.', 'the dataset includes plenty of metadata for each utterance, e. g., answer vote and user affiliation.', 'for generalizability, our model only incorporates textual content of the dialogues.', 'besides, unlike qu et al.  #TAUTHOR_TAG, we keep all the da annotations in the dataset to preserve the meaningful da structures within and across utterances.', '']",4
['recognition  #TAUTHOR_TAG'],['cda recognition  #TAUTHOR_TAG'],"['cda recognition  #TAUTHOR_TAG.', '• cnn - kim [ 8 ] :']","['this section, three versions of our proposed model with incremental improvements are evaluated against a cnn baseline [ 8 ] and the state - of - the - art approach for cda recognition  #TAUTHOR_TAG.', '• cnn - kim [ 8 ] : one of the first attempts to apply cnn to text classification.', 'the cnn model consists of three convolutional layers with the same filter size.', '• cnn - cr [ 14 ] : the state - of - the - art approach for cda recognition on the msdialog - intent dataset [ 14 ].', 'the cnn model incorporates context information with a window size of 3.', '• crnn ( v 1 ) : our base model that adapts crnn for cda recognition using bce loss and sigmoid activation function.', '• crnn ( v 2 ) : crnn ( v 1 ) with highway connections added between the convolutional layer and the fully connected layer.', '• crnn ( v 3 ) : crnn ( v 1 ) with highway connections and dynamic k - max pooling implemented']",7
[' #AUTHOR_TAG and unsupervised  #AUTHOR_TAG or supervised  #TAUTHOR_TAG b ;  #AUTHOR_TAG machine - learning - based sentiment'],[' #AUTHOR_TAG and unsupervised  #AUTHOR_TAG or supervised  #TAUTHOR_TAG b ;  #AUTHOR_TAG machine - learning - based sentiment'],"[' #AUTHOR_TAG and unsupervised  #AUTHOR_TAG or supervised  #TAUTHOR_TAG b ;  #AUTHOR_TAG machine - learning - based sentiment analysis.', 'as a result, constructing sentiment lexicons is one important research task in']","['lexicons contain the sentiment polarity and / or the strength of words or phrases  #AUTHOR_TAG a ;  #AUTHOR_TAG a ).', 'they have been used for both rule - based  #AUTHOR_TAG and unsupervised  #AUTHOR_TAG or supervised  #TAUTHOR_TAG b ;  #AUTHOR_TAG machine - learning - based sentiment analysis.', 'as a result, constructing sentiment lexicons is one important research task in sentiment analysis.', 'many approaches have been proposed to construct sentiment lexicons.', 'traditional methods manually label the sentiment attributes of words  #AUTHOR_TAG.', 'one benefit of such lexicons is high quality.', 'on the other hand, the methods are timeconsuming, requiring language and domain expertise.', 'recently, statistical methods have been exploited to learn sentiment lexicons automatically  #TAUTHOR_TAG.', 'such methods leverage knowledge resources ( bravo -  #AUTHOR_TAG or labeled sentiment data  #AUTHOR_TAG a ), giving significantly better coverage compared to manual lexicons.', 'among the automatic methods,  #TAUTHOR_TAG proposed to use tweets with emoticons or hashtags as training data.', 'the main advantage is that such training data are abundant, and manual annotation can be avoided.', 'despite that emoticons or hashtags can be noisy in indicating the sentiment of a tweet, existing research  #AUTHOR_TAG b ) has shown that effectiveness of such data when used to supervise sentiment classifiers.', ' #AUTHOR_TAG collect sentiment lexicons by calculating pointwise mutual information ( pmi ) between words and emoticons.', 'the resulting lexicons give the best results in a semeval13 benchmark  #AUTHOR_TAG.', 'in this paper, we show that a better lexicon can be learned by directly optimizing the prediction accuracy, taking the lexicon as input and emoticon as the output.', 'the correlation between our method and the method of  #TAUTHOR_TAG is analogous to the "" predicting "" vs "" counting "" correlation between distributional and distributed word representations  #AUTHOR_TAG.', 'we follow  #AUTHOR_TAG in using two simple attributes to represent each sentiment word, and take inspiration from  #AUTHOR_TAG in using a very simple neural network for sentiment prediction.', 'the method can leverage the same data as  #TAUTHOR_TAG and therefore benefits from both scale and annotation independence.', 'experiments show that the neural model gives the best results on standard benchmarks across multiple languages.', 'our code and lexicons are publicly available at https : / / github. com / duytinvo / acl2016']",4
"[' #TAUTHOR_TAG.', 'first,']","[' #TAUTHOR_TAG.', 'first,']","[' #TAUTHOR_TAG.', 'first,']",[' #TAUTHOR_TAG'],4
"[' #TAUTHOR_TAG.', 'first,']","[' #TAUTHOR_TAG.', 'first,']","[' #TAUTHOR_TAG.', 'first,']",[' #TAUTHOR_TAG'],4
[' #AUTHOR_TAG and unsupervised  #AUTHOR_TAG or supervised  #TAUTHOR_TAG b ;  #AUTHOR_TAG machine - learning - based sentiment'],[' #AUTHOR_TAG and unsupervised  #AUTHOR_TAG or supervised  #TAUTHOR_TAG b ;  #AUTHOR_TAG machine - learning - based sentiment'],"[' #AUTHOR_TAG and unsupervised  #AUTHOR_TAG or supervised  #TAUTHOR_TAG b ;  #AUTHOR_TAG machine - learning - based sentiment analysis.', 'as a result, constructing sentiment lexicons is one important research task in']","['lexicons contain the sentiment polarity and / or the strength of words or phrases  #AUTHOR_TAG a ;  #AUTHOR_TAG a ).', 'they have been used for both rule - based  #AUTHOR_TAG and unsupervised  #AUTHOR_TAG or supervised  #TAUTHOR_TAG b ;  #AUTHOR_TAG machine - learning - based sentiment analysis.', 'as a result, constructing sentiment lexicons is one important research task in sentiment analysis.', 'many approaches have been proposed to construct sentiment lexicons.', 'traditional methods manually label the sentiment attributes of words  #AUTHOR_TAG.', 'one benefit of such lexicons is high quality.', 'on the other hand, the methods are timeconsuming, requiring language and domain expertise.', 'recently, statistical methods have been exploited to learn sentiment lexicons automatically  #TAUTHOR_TAG.', 'such methods leverage knowledge resources ( bravo -  #AUTHOR_TAG or labeled sentiment data  #AUTHOR_TAG a ), giving significantly better coverage compared to manual lexicons.', 'among the automatic methods,  #TAUTHOR_TAG proposed to use tweets with emoticons or hashtags as training data.', 'the main advantage is that such training data are abundant, and manual annotation can be avoided.', 'despite that emoticons or hashtags can be noisy in indicating the sentiment of a tweet, existing research  #AUTHOR_TAG b ) has shown that effectiveness of such data when used to supervise sentiment classifiers.', ' #AUTHOR_TAG collect sentiment lexicons by calculating pointwise mutual information ( pmi ) between words and emoticons.', 'the resulting lexicons give the best results in a semeval13 benchmark  #AUTHOR_TAG.', 'in this paper, we show that a better lexicon can be learned by directly optimizing the prediction accuracy, taking the lexicon as input and emoticon as the output.', 'the correlation between our method and the method of  #TAUTHOR_TAG is analogous to the "" predicting "" vs "" counting "" correlation between distributional and distributed word representations  #AUTHOR_TAG.', 'we follow  #AUTHOR_TAG in using two simple attributes to represent each sentiment word, and take inspiration from  #AUTHOR_TAG in using a very simple neural network for sentiment prediction.', 'the method can leverage the same data as  #TAUTHOR_TAG and therefore benefits from both scale and annotation independence.', 'experiments show that the neural model gives the best results on standard benchmarks across multiple languages.', 'our code and lexicons are publicly available at https : / / github. com / duytinvo / acl2016']",5
['source as  #TAUTHOR_TAG to'],['source as  #TAUTHOR_TAG to'],"['more flexible compared to the first two methods.', 'we consider it as our baseline.', 'we use the same data source as  #TAUTHOR_TAG to']","['', 'we consider it as our baseline.', 'we use the same data source as  #TAUTHOR_TAG to train lexicons.', 'however, rather than relying on pmi, we take a machine - learning method in optimizing the prediction accuracy of emoticons using the lexicons.', 'to leverage large data, we use a very simple neural network to train the lexicons']",5
"['4  #TAUTHOR_TAG, hit 5  #AUTHOR_TAG a ) and']","['nrc 4  #TAUTHOR_TAG, hit 5  #AUTHOR_TAG a ) and']","['nrc 4  #TAUTHOR_TAG, hit 5  #AUTHOR_TAG a ) and']","['twitter benchmark of semeval13  #AUTHOR_TAG is used as the english test set.', 'in order to evaluate both unsupervised and supervised methods, we follow  #AUTHOR_TAG b ) and, removing neutral tweets.', 'the statistics is shown in table 2.', 'we compare our lexicon with the lexicons of nrc 4  #TAUTHOR_TAG, hit 5  #AUTHOR_TAG a ) and weka 6 ( bravo -  #AUTHOR_TAG.', 'as shown in table 3, using the unsupervised sentiment classification method ( unsup ) in section 5, our lexicon gives significantly better result in comparison with countbased lexicons of nrc.', 'under both settings, our lexicon yields the best results compared to other methods']",5
"[' #TAUTHOR_TAG.', 'first,']","[' #TAUTHOR_TAG.', 'first,']","[' #TAUTHOR_TAG.', 'first,']",[' #TAUTHOR_TAG'],5
"['- this is widely known as the grounding problem.', 'our work is similar in spirit to e. g.  #AUTHOR_TAG but advances it in several aspects  #TAUTHOR_TAG.', 'in this demo paper, we present a dialogue agent that']","['- this is widely known as the grounding problem.', 'our work is similar in spirit to e. g.  #AUTHOR_TAG but advances it in several aspects  #TAUTHOR_TAG.', 'in this demo paper, we present a dialogue agent that']","['adapt mappings between words, phrases, and sentences in natural language ( nl ) and perceptual aspects of the external environment - this is widely known as the grounding problem.', 'our work is similar in spirit to e. g.  #AUTHOR_TAG but advances it in several aspects  #TAUTHOR_TAG.', 'in this demo paper, we present a dialogue agent that learns visually grounded word meanings interactively from a human tutor,']","['intelligent systems / robots are brought out of the laboratory and into the physical world, they must become capable of natural everyday conversation with their human users about their physical surroundings.', 'among other competencies, this involves the ability to learn and adapt mappings between words, phrases, and sentences in natural language ( nl ) and perceptual aspects of the external environment - this is widely known as the grounding problem.', 'our work is similar in spirit to e. g.  #AUTHOR_TAG but advances it in several aspects  #TAUTHOR_TAG.', 'in this demo paper, we present a dialogue agent that learns visually grounded word meanings interactively from a human tutor, which we call : voila ( visually optimised interactive learning agent ).', 'our goal is to enable this agent to learn to identify and describe objects / attributes ( colour 1 http : / / www. furhatrobotics. com / and shape in this case ) in its immediate visual environment through interaction with human users, incrementally, over time.', 'unlike a lot of past work  #AUTHOR_TAG, here we assume that the agent is in the position of a child, who does not have any prior knowledge of perceptual categories.', 'hence, the agent must learn from scratch : ( 1 ) the perceptual / visual categories themselves ; and ( 2 ) how nl expressions map to these ; and in addition, ( 3 ) as a standard conversational agent, the agent much also learn to conduct natural, spontaneous conversations with real humans.', 'in this demonstration, voila plays the role of an interactive, concept learning agent that takes initiative in the dialogues and actively learns novel visual knowledge from the feedback from the human tutor.', 'what sets voila apart from other work in this area is :', ""• voila's dialogue strategy is optimised via reinforcement learning to achieve an optimal trade - off between the accuracy of the concepts it learns / has learnt from users, and the effort that the dialogues incur on the users : this is a form of active learning where the agent only asks about something if it doesn't already know the answer with some appropriate confidence ( see  #TAUTHOR_TAG for more detail )."", '• voila is trained on a corpus of real humanhuman conversations  #AUTHOR_TAG, and is thus able to process natural human dialogue, which contains phenomena such as self - corrections, repetitions and restarts, pauses, fillers, and continuations voila is deployed onto furhat, a humanlike robot head with a custom back - projected face, built - in stereo microphones, and a']",5
"['of  #TAUTHOR_TAG.', 'the']","['of  #TAUTHOR_TAG.', 'the']","['of  #TAUTHOR_TAG.', 'the framework consists of two core modules :', 'vision module']","['developed a multimodal framework in support of building an interactive learning system, which loosely follows that of  #TAUTHOR_TAG.', 'the framework consists of two core modules :', ""vision module the vision module produces visual attribute predictions, using two base feature categories : the hsv colour space for colour attributes, and a'bag of visual words'( i. e. phow descriptors ) for the object shapes / class."", 'it consists of a set of binary classifiers - logistic regression svm classifiers with stochastic gradient descent ( sgd )  #AUTHOR_TAG - to incrementally learn attribute predictions.', ""the visual classifiers ground visual attribute words such as'red ','circle'etc."", 'that appear as parameters of the dialogue acts used in the system.', 'dialogue module this module relies on a classical architecture for dialogue systems, composed of dialogue management ( dm ) and natural language understanding ( nlu ), as well as generation ( nlg ) components.', 'these components interact via dialogue act representations  #AUTHOR_TAG, e. g. inform ( color = red ), ask ( shape ).', 'the natural language understanding component processes user utterances by extracting a sequence of key patterns, slots and values, and then transforming them into dialogue - act representations, following a list of hand - crafted rules.', 'the nlg component makes use of a template - based approach that chooses a suitable learner utterance for a specific dialogue act, according to the statistical distribution of utterance templates from dialogue examples.', 'finally, the dm component is implemented with an optimised learning policy using reinforcement learning ( see section 3 ).', 'this optimised policy is trained to : ( 1 ) conduct interaction with human partners, and ( 2 ) achieve an optimum balance between classification performance and the cost of the dialogue to the tutor in the interactive learning process']",5
"[' #TAUTHOR_TAG, here we use a positive confidence threshold, which']","[' #TAUTHOR_TAG, here we use a positive confidence threshold, which']","['own predictions.', 'following previous work  #TAUTHOR_TAG, here we use a positive confidence threshold, which']","['first mdp performs a kind of active learning : the learner / agent only acquires the feedback from humans about a visual attribute if it is not confident enough already about its own predictions.', 'following previous work  #TAUTHOR_TAG, here we use a positive confidence threshold, which determines when the agent believes its own predictions.', 'for instance, the learner can ask either polar or wh - questions about an attribute if its confidence score is higher than a certain threshold ; otherwise, there should be no interaction about that attribute. but as  #TAUTHOR_TAG point out the confidence score from a classifier is not reliable enough at the early stages of learning, so in order to find an optimum dialogue policy, a threshold should be able to dynamically adjust according to the previous learning performance of the agent.', 'we therefore assign a separate but dependent component mdp for adjusting the threshold dynamically in order to optimise the trade - off between accuracy and cost.', ""note now that the adjusted confidence threshold will affect the agent's dialogue behaviour, modeled in the other mdp presented in the next section ( natural interaction with humans )""]",5
"['- this is widely known as the grounding problem.', 'our work is similar in spirit to e. g.  #AUTHOR_TAG but advances it in several aspects  #TAUTHOR_TAG.', 'in this demo paper, we present a dialogue agent that']","['- this is widely known as the grounding problem.', 'our work is similar in spirit to e. g.  #AUTHOR_TAG but advances it in several aspects  #TAUTHOR_TAG.', 'in this demo paper, we present a dialogue agent that']","['adapt mappings between words, phrases, and sentences in natural language ( nl ) and perceptual aspects of the external environment - this is widely known as the grounding problem.', 'our work is similar in spirit to e. g.  #AUTHOR_TAG but advances it in several aspects  #TAUTHOR_TAG.', 'in this demo paper, we present a dialogue agent that learns visually grounded word meanings interactively from a human tutor,']","['intelligent systems / robots are brought out of the laboratory and into the physical world, they must become capable of natural everyday conversation with their human users about their physical surroundings.', 'among other competencies, this involves the ability to learn and adapt mappings between words, phrases, and sentences in natural language ( nl ) and perceptual aspects of the external environment - this is widely known as the grounding problem.', 'our work is similar in spirit to e. g.  #AUTHOR_TAG but advances it in several aspects  #TAUTHOR_TAG.', 'in this demo paper, we present a dialogue agent that learns visually grounded word meanings interactively from a human tutor, which we call : voila ( visually optimised interactive learning agent ).', 'our goal is to enable this agent to learn to identify and describe objects / attributes ( colour 1 http : / / www. furhatrobotics. com / and shape in this case ) in its immediate visual environment through interaction with human users, incrementally, over time.', 'unlike a lot of past work  #AUTHOR_TAG, here we assume that the agent is in the position of a child, who does not have any prior knowledge of perceptual categories.', 'hence, the agent must learn from scratch : ( 1 ) the perceptual / visual categories themselves ; and ( 2 ) how nl expressions map to these ; and in addition, ( 3 ) as a standard conversational agent, the agent much also learn to conduct natural, spontaneous conversations with real humans.', 'in this demonstration, voila plays the role of an interactive, concept learning agent that takes initiative in the dialogues and actively learns novel visual knowledge from the feedback from the human tutor.', 'what sets voila apart from other work in this area is :', ""• voila's dialogue strategy is optimised via reinforcement learning to achieve an optimal trade - off between the accuracy of the concepts it learns / has learnt from users, and the effort that the dialogues incur on the users : this is a form of active learning where the agent only asks about something if it doesn't already know the answer with some appropriate confidence ( see  #TAUTHOR_TAG for more detail )."", '• voila is trained on a corpus of real humanhuman conversations  #AUTHOR_TAG, and is thus able to process natural human dialogue, which contains phenomena such as self - corrections, repetitions and restarts, pauses, fillers, and continuations voila is deployed onto furhat, a humanlike robot head with a custom back - projected face, built - in stereo microphones, and a']",0
"['of  #TAUTHOR_TAG.', 'the']","['of  #TAUTHOR_TAG.', 'the']","['of  #TAUTHOR_TAG.', 'the framework consists of two core modules :', 'vision module']","['developed a multimodal framework in support of building an interactive learning system, which loosely follows that of  #TAUTHOR_TAG.', 'the framework consists of two core modules :', ""vision module the vision module produces visual attribute predictions, using two base feature categories : the hsv colour space for colour attributes, and a'bag of visual words'( i. e. phow descriptors ) for the object shapes / class."", 'it consists of a set of binary classifiers - logistic regression svm classifiers with stochastic gradient descent ( sgd )  #AUTHOR_TAG - to incrementally learn attribute predictions.', ""the visual classifiers ground visual attribute words such as'red ','circle'etc."", 'that appear as parameters of the dialogue acts used in the system.', 'dialogue module this module relies on a classical architecture for dialogue systems, composed of dialogue management ( dm ) and natural language understanding ( nlu ), as well as generation ( nlg ) components.', 'these components interact via dialogue act representations  #AUTHOR_TAG, e. g. inform ( color = red ), ask ( shape ).', 'the natural language understanding component processes user utterances by extracting a sequence of key patterns, slots and values, and then transforming them into dialogue - act representations, following a list of hand - crafted rules.', 'the nlg component makes use of a template - based approach that chooses a suitable learner utterance for a specific dialogue act, according to the statistical distribution of utterance templates from dialogue examples.', 'finally, the dm component is implemented with an optimised learning policy using reinforcement learning ( see section 3 ).', 'this optimised policy is trained to : ( 1 ) conduct interaction with human partners, and ( 2 ) achieve an optimum balance between classification performance and the cost of the dialogue to the tutor in the interactive learning process']",3
"[' #TAUTHOR_TAG, here we use a positive confidence threshold, which']","[' #TAUTHOR_TAG, here we use a positive confidence threshold, which']","['own predictions.', 'following previous work  #TAUTHOR_TAG, here we use a positive confidence threshold, which']","['first mdp performs a kind of active learning : the learner / agent only acquires the feedback from humans about a visual attribute if it is not confident enough already about its own predictions.', 'following previous work  #TAUTHOR_TAG, here we use a positive confidence threshold, which determines when the agent believes its own predictions.', 'for instance, the learner can ask either polar or wh - questions about an attribute if its confidence score is higher than a certain threshold ; otherwise, there should be no interaction about that attribute. but as  #TAUTHOR_TAG point out the confidence score from a classifier is not reliable enough at the early stages of learning, so in order to find an optimum dialogue policy, a threshold should be able to dynamically adjust according to the previous learning performance of the agent.', 'we therefore assign a separate but dependent component mdp for adjusting the threshold dynamically in order to optimise the trade - off between accuracy and cost.', ""note now that the adjusted confidence threshold will affect the agent's dialogue behaviour, modeled in the other mdp presented in the next section ( natural interaction with humans )""]",1
"['the text is often noisy.', 'abuse can also have different facets.', ' #TAUTHOR_TAG released']","['the text is often noisy.', 'abuse can also have different facets.', ' #TAUTHOR_TAG released']","['the text is often noisy.', 'abuse can also have different facets.', ' #TAUTHOR_TAG released']","['social interaction involves an exchange of viewpoints and thoughts. but these views and thoughts can be caustic.', ""often we see that users resort to verbal abuse to win an argument or overshadow someone's opinion."", 'on twitter, people from every sphere have experienced online abuse.', 'be it a famous celebrity with millions of followers or someone representing a marginalized community such as lgbtq, women and more.', 'we want to channelize natural language processing ( nlp ) for social good and aid in the process of flagging abusive tweets and users.', 'detecting abuse on twitter can be challenging, particularly because the text is often noisy.', 'abuse can also have different facets.', ' #TAUTHOR_TAG released one of the initial data sets from twitter with the goal of identifying what constitutes racism and sexism.', '[ 9 ] in their work pointed out that hate speech is different from offensive language and released a data set of 25k tweets with the goal of distinguishing hate speech from offensive language.', 'stop saying dumb blondes with pretty faces as you need a pretty face to pull them off!!! # mkr in islam women must be locked in their houses and muslims claim this is treating them well table 1 : tweets from  #TAUTHOR_TAG find that racist and homophobic tweets are more likely to be classified as hate speech but sexist tweets are generally classified as offensive.', '[ 4 ] introduced a large, hand - coded corpus of online harassment data for studying the nature of harassing comments and the culture of trolling.', 'keeping these motivations in mind, we make the following salient contributions :', '• we build a deep context - aware attention - based model for abusive behavior detection on twitter.', 'to the best of our knowledge ours is the first work that exploits context aware attention for this task.', '• our model is robust and achieves consistent performance gains in all the three abusive data sets • we show how context aware attention helps in focusing on certain abusive keywords when used in specific context and improve the performance of abusive behavior detection']",0
"['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['approaches to abusive text detection can be broadly divided into two categories : 1 ) feature intensive machine learning algorithms such as logistic regression ( lr ), multilayer perceptron ( mlp ) and etc.', '2 ) deep learning models which learn feature representations on their own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model for detection of abuse in their corpus.', '[ 9 ] use a similar handcrafted feature engineered model to identify offensive language and distinguish it from hate speech.', '[ 2 ] in their work, experiment with multiple deep learning architectures for the task of hate speech detection on twitter using the same data set by  #TAUTHOR_TAG.', 'their best - reported f1 - score is achieved using long short term memory networks ( lstm ) + gradient boosting.', 'on the data set released by  #TAUTHOR_TAG, [ 5 ] experiment with a two - step approach of detecting abusive language first and then classifying them into specific types i. e. racist, sexist or none.', 'they achieve best results using a hybrid convolution neural network ( cnn ) with the intuition that character level input would counter the purposely or mistakenly misspelled words and made - up vocabularies.', '[ 6 ] in their work ran experiments on the gazetta dataset and the detox system ( [ 12 ] ) and show that a recurrent neural network ( rnn ) coupled with deep, classification - specific attention outperforms the previous state of the art in abusive comment moderation.', 'in their more recent work [ 7 ] explored how user embeddings, user - type embeddings, and user type biases can improve their previous rnn based model on the gazetta dataset.', 'attentive neural networks have been shown to perform well on a variety of nlp tasks ( [ 13 ], [ 11 ] ).', '[ 13 ] use hierarchical contextual attention for text classification ( i. e attention both at word and sentence level ) on six large scale text classification tasks and demonstrate that the proposed architecture outperform previous methods by a substantial margin.', 'we primarily focus on word level attention because most of the tweets are single sentence tweets']",0
"['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['approaches to abusive text detection can be broadly divided into two categories : 1 ) feature intensive machine learning algorithms such as logistic regression ( lr ), multilayer perceptron ( mlp ) and etc.', '2 ) deep learning models which learn feature representations on their own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model for detection of abuse in their corpus.', '[ 9 ] use a similar handcrafted feature engineered model to identify offensive language and distinguish it from hate speech.', '[ 2 ] in their work, experiment with multiple deep learning architectures for the task of hate speech detection on twitter using the same data set by  #TAUTHOR_TAG.', 'their best - reported f1 - score is achieved using long short term memory networks ( lstm ) + gradient boosting.', 'on the data set released by  #TAUTHOR_TAG, [ 5 ] experiment with a two - step approach of detecting abusive language first and then classifying them into specific types i. e. racist, sexist or none.', 'they achieve best results using a hybrid convolution neural network ( cnn ) with the intuition that character level input would counter the purposely or mistakenly misspelled words and made - up vocabularies.', '[ 6 ] in their work ran experiments on the gazetta dataset and the detox system ( [ 12 ] ) and show that a recurrent neural network ( rnn ) coupled with deep, classification - specific attention outperforms the previous state of the art in abusive comment moderation.', 'in their more recent work [ 7 ] explored how user embeddings, user - type embeddings, and user type biases can improve their previous rnn based model on the gazetta dataset.', 'attentive neural networks have been shown to perform well on a variety of nlp tasks ( [ 13 ], [ 11 ] ).', '[ 13 ] use hierarchical contextual attention for text classification ( i. e attention both at word and sentence level ) on six large scale text classification tasks and demonstrate that the proposed architecture outperform previous methods by a substantial margin.', 'we primarily focus on word level attention because most of the tweets are single sentence tweets']",0
"['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model']","['approaches to abusive text detection can be broadly divided into two categories : 1 ) feature intensive machine learning algorithms such as logistic regression ( lr ), multilayer perceptron ( mlp ) and etc.', '2 ) deep learning models which learn feature representations on their own.  #TAUTHOR_TAG released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1, and provided a feature engineered model for detection of abuse in their corpus.', '[ 9 ] use a similar handcrafted feature engineered model to identify offensive language and distinguish it from hate speech.', '[ 2 ] in their work, experiment with multiple deep learning architectures for the task of hate speech detection on twitter using the same data set by  #TAUTHOR_TAG.', 'their best - reported f1 - score is achieved using long short term memory networks ( lstm ) + gradient boosting.', 'on the data set released by  #TAUTHOR_TAG, [ 5 ] experiment with a two - step approach of detecting abusive language first and then classifying them into specific types i. e. racist, sexist or none.', 'they achieve best results using a hybrid convolution neural network ( cnn ) with the intuition that character level input would counter the purposely or mistakenly misspelled words and made - up vocabularies.', '[ 6 ] in their work ran experiments on the gazetta dataset and the detox system ( [ 12 ] ) and show that a recurrent neural network ( rnn ) coupled with deep, classification - specific attention outperforms the previous state of the art in abusive comment moderation.', 'in their more recent work [ 7 ] explored how user embeddings, user - type embeddings, and user type biases can improve their previous rnn based model on the gazetta dataset.', 'attentive neural networks have been shown to perform well on a variety of nlp tasks ( [ 13 ], [ 11 ] ).', '[ 13 ] use hierarchical contextual attention for text classification ( i. e attention both at word and sentence level ) on six large scale text classification tasks and demonstrate that the proposed architecture outperform previous methods by a substantial margin.', 'we primarily focus on word level attention because most of the tweets are single sentence tweets']",0
"['the text is often noisy.', 'abuse can also have different facets.', ' #TAUTHOR_TAG released']","['the text is often noisy.', 'abuse can also have different facets.', ' #TAUTHOR_TAG released']","['the text is often noisy.', 'abuse can also have different facets.', ' #TAUTHOR_TAG released']","['social interaction involves an exchange of viewpoints and thoughts. but these views and thoughts can be caustic.', ""often we see that users resort to verbal abuse to win an argument or overshadow someone's opinion."", 'on twitter, people from every sphere have experienced online abuse.', 'be it a famous celebrity with millions of followers or someone representing a marginalized community such as lgbtq, women and more.', 'we want to channelize natural language processing ( nlp ) for social good and aid in the process of flagging abusive tweets and users.', 'detecting abuse on twitter can be challenging, particularly because the text is often noisy.', 'abuse can also have different facets.', ' #TAUTHOR_TAG released one of the initial data sets from twitter with the goal of identifying what constitutes racism and sexism.', '[ 9 ] in their work pointed out that hate speech is different from offensive language and released a data set of 25k tweets with the goal of distinguishing hate speech from offensive language.', 'stop saying dumb blondes with pretty faces as you need a pretty face to pull them off!!! # mkr in islam women must be locked in their houses and muslims claim this is treating them well table 1 : tweets from  #TAUTHOR_TAG find that racist and homophobic tweets are more likely to be classified as hate speech but sexist tweets are generally classified as offensive.', '[ 4 ] introduced a large, hand - coded corpus of online harassment data for studying the nature of harassing comments and the culture of trolling.', 'keeping these motivations in mind, we make the following salient contributions :', '• we build a deep context - aware attention - based model for abusive behavior detection on twitter.', 'to the best of our knowledge ours is the first work that exploits context aware attention for this task.', '• our model is robust and achieves consistent performance gains in all the three abusive data sets • we show how context aware attention helps in focusing on certain abusive keywords when used in specific context and improve the performance of abusive behavior detection']",5
"['calculate the importance of the word as the similarity data set tweets count  #TAUTHOR_TAG 15, 84']","['calculate the importance of the word as the similarity data set tweets count  #TAUTHOR_TAG 15, 844 [ 9 ] 25, 112 [ 4 ] 20, 362 table']","['as we train our network.', 'once u i is obtained we calculate the importance of the word as the similarity data set tweets count  #TAUTHOR_TAG 15, 84']","['', 'u c is our word level context vector that is randomly initialized and learned as we train our network.', 'once u i is obtained we calculate the importance of the word as the similarity data set tweets count  #TAUTHOR_TAG 15, 844 [ 9 ] 25, 112 [ 4 ] 20, 362 table 2 : data sets and their total tweets count of u i with u c and get a normalized importance weight α i through a softmax function.', 'the context vector u c can be seen as a tool which filters which word is more important over all the words like that used in the lstm.', 'figure 2 shows the high - level architecture of this model.', 'w h and b h are the attention layers weights and biases.', 'more formally']",5
"['have used the 3 benchmark data sets for abusive content detection on twitter.', 'at the time of the experiment, the  #TAUTHOR_TAG data set had a total of 15, 84']","['have used the 3 benchmark data sets for abusive content detection on twitter.', 'at the time of the experiment, the  #TAUTHOR_TAG data set had a total of 15, 844 tweets out of which']","['have used the 3 benchmark data sets for abusive content detection on twitter.', 'at the time of the experiment, the  #TAUTHOR_TAG data set had a total of 15, 844 tweets out of which']","['have used the 3 benchmark data sets for abusive content detection on twitter.', 'at the time of the experiment, the  #TAUTHOR_TAG data set had a total of 15, 844 tweets out of which 1, 924 were labelled as belonging to racism, 3, 058 as sexism and 10, 862 as none.', 'the [ 9 ] data set had a total of 25, 112 tweets out of which 1498 were labelled as hate speech, 19, 326 as offensive language and 4, 288 as neither.', 'for the [ 4 ] data set, there were 20, 362 tweets out of which 5, 235 were positive harassment examples and 15, 127 were negative.', 'we call  #TAUTHOR_TAG, [ 9 ] data set as d2 and [ 4 ] as d3 for tweet tokenization, we use ekphrasis which is a text processing tool built specially from social platforms such as twitter.', '[ 3 ] use a big collection of twitter messages ( 330m ) to generate word embeddings, with a vocabulary size of 660k words, using glove ( [ 8 ] ).', 'we use these pre - trained word embeddings for initializing the first layer ( embedding layer ) of our neural networks']",5
"['have used the 3 benchmark data sets for abusive content detection on twitter.', 'at the time of the experiment, the  #TAUTHOR_TAG data set had a total of 15, 84']","['have used the 3 benchmark data sets for abusive content detection on twitter.', 'at the time of the experiment, the  #TAUTHOR_TAG data set had a total of 15, 844 tweets out of which']","['have used the 3 benchmark data sets for abusive content detection on twitter.', 'at the time of the experiment, the  #TAUTHOR_TAG data set had a total of 15, 844 tweets out of which']","['have used the 3 benchmark data sets for abusive content detection on twitter.', 'at the time of the experiment, the  #TAUTHOR_TAG data set had a total of 15, 844 tweets out of which 1, 924 were labelled as belonging to racism, 3, 058 as sexism and 10, 862 as none.', 'the [ 9 ] data set had a total of 25, 112 tweets out of which 1498 were labelled as hate speech, 19, 326 as offensive language and 4, 288 as neither.', 'for the [ 4 ] data set, there were 20, 362 tweets out of which 5, 235 were positive harassment examples and 15, 127 were negative.', 'we call  #TAUTHOR_TAG, [ 9 ] data set as d2 and [ 4 ] as d3 for tweet tokenization, we use ekphrasis which is a text processing tool built specially from social platforms such as twitter.', '[ 3 ] use a big collection of twitter messages ( 330m ) to generate word embeddings, with a vocabulary size of 660k words, using glove ( [ 8 ] ).', 'we use these pre - trained word embeddings for initializing the first layer ( embedding layer ) of our neural networks']",5
[' #TAUTHOR_TAG and'],[' #TAUTHOR_TAG and d3 and 5 fold cross - validations'],[' #TAUTHOR_TAG and'],"['network is trained at a learning rate of 0. 001 for 10 epochs, with a dropout of 0. 2 to prevent over - fitting.', 'the results are averaged over 10 - fold cross - validations for  #TAUTHOR_TAG and d3 and 5 fold cross - validations for d2 because [ 9 ] reported results using 5 fold cv.', 'because of class imbalance in all our data sets, we report weighted f1 scores.', 'table 3 shows our results in detail.', 'we compare our model with the best models reported in each paper.', 'because [ 4 ] is a data set paper, we cannot fill the corresponding row.', '* denotes the numbers from baseline papers.', 'all the results were reproducible except for the one marked red.', 'for  #AUTHOR_TAG data set, ( badjatiyaet al., 2017 ) claim that using gradient boosting with lstm embeddings obtained from random word embeddings boosted their performance by 12 f1 from 81. 0 to 93. 0.', 'when we tried to reproduce the result, we did not find any significant improvement over 81.', 'results show that our model is robust when it comes to the performance on all of the three data sets.', 'table 3 : data sets and the results of different models.', 'we reproduced the results for each model on three of the data sets']",5
"['annotation is either noisy or the difference between classes are very blurred and subtle.', 'the first tweet is a tweet from  #TAUTHOR_TAG,']","['annotation is either noisy or the difference between classes are very blurred and subtle.', 'the first tweet is a tweet from  #TAUTHOR_TAG,']","['annotation is either noisy or the difference between classes are very blurred and subtle.', 'the first tweet is a tweet from  #TAUTHOR_TAG, the second tweet is a tweet from from']","['also share some examples from the three data sets in figure 2 which our bilstm attention model could not classify correctly.', 'on closer investigation we find that most cases where our model fails are instances where annotation is either noisy or the difference between classes are very blurred and subtle.', 'the first tweet is a tweet from  #TAUTHOR_TAG, the second tweet is a tweet from from [ 9 ] data set and the third from the [ 4']",5
"['to each word by the contextual attention.', 'the first tweet is a sexist tweet from  #TAUTHOR_TAG where as the second tweet is an example of racist tweet from the same datset.', 'the third tweet is from [ 9 ] data set labelled as offensive language']","['to each word by the contextual attention.', 'the first tweet is a sexist tweet from  #TAUTHOR_TAG where as the second tweet is an example of racist tweet from the same datset.', 'the third tweet is from [ 9 ] data set labelled as offensive language']","['to each word by the contextual attention.', 'the first tweet is a sexist tweet from  #TAUTHOR_TAG where as the second tweet is an example of racist tweet from the same datset.', 'the third tweet is from [ 9 ] data set labelled as offensive language']","['color intensity corresponds to the weight given to each word by the contextual attention.', 'the first tweet is a sexist tweet from  #TAUTHOR_TAG where as the second tweet is an example of racist tweet from the same datset.', 'the third tweet is from [ 9 ] data set labelled as offensive language']",5
"['based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdivers']","['based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training']","['adversarial evaluation based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training data by providing effective examples that punish the model']","['is shown that many published models for the stanford question answering dataset  #AUTHOR_TAG lack robustness, suffering an over 50 % decrease in f1 score during adversarial evaluation based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training data by providing effective examples that punish the model for making certain superficial assumptions.', ""further, in order to improve robustness to  #TAUTHOR_TAG's semantic perturbations ( e. g., antonyms ), we jointly improve the model's semantic - relationship learning capabilities in addition to our addsentdiversebased adversarial training data augmentation."", 'with these additions, we show that we can make a state - of - the - art model significantly more robust, achieving a 36. 5 % increase in f1 score under many different types of adversarial evaluation while maintaining performance on the regular squad task']",1
"['based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdivers']","['based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training']","['adversarial evaluation based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training data by providing effective examples that punish the model']","['is shown that many published models for the stanford question answering dataset  #AUTHOR_TAG lack robustness, suffering an over 50 % decrease in f1 score during adversarial evaluation based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training data by providing effective examples that punish the model for making certain superficial assumptions.', ""further, in order to improve robustness to  #TAUTHOR_TAG's semantic perturbations ( e. g., antonyms ), we jointly improve the model's semantic - relationship learning capabilities in addition to our addsentdiversebased adversarial training data augmentation."", 'with these additions, we show that we can make a state - of - the - art model significantly more robust, achieving a 36. 5 % increase in f1 score under many different types of adversarial evaluation while maintaining performance on the regular squad task']",1
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",1
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",1
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",1
"['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model']","['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['##arial evaluation in computer vision, adversarial examples are frequently used to punish model oversensitivity, where semantic - preserving perturbations ( usually in the form of small noise vectors ) are added to an image to fool the classifier into giving it a different label  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model failure in the other direction : overstability, or the inability to detect semantic - altering noise.', 'it does so by generating distractor sentences that only resemble the questions syntactically and appending them to the context paragraphs ( detailed description included in sec. 3 ).', ""when tested on these adversarial examples,  #TAUTHOR_TAG showed that even the most'robust'amongst published models ( the mnemonic reader  #AUTHOR_TAG ) only achieved 46. 6 % f1 ( compared to 79. 6 % f1 on the regular task )."", ""since then, the fusionnet model  #AUTHOR_TAG used history - of - word representations and multi - level attention mechanism to obtain an improved 51. 4 % f1 score under adversarial evaluation, but that is still a 30 % decrease from the model's performance on the regular task."", 'we show, however, that one can make a pre - existing model significantly more robust by simply retraining it with better, higher variance adversarial training data, and improve it further with minor semantic feature additions to its inputs.', 'adversarial training it has been shown in the field of image classification that training with adversarial examples produces more robust and error - resistant models  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm.', 'despite performing well when evaluated on  #TAUTHOR_TAG in two superficial ways : using a different set of fake answers and prepending instead of appending the distractor sentence to the context ).', 'we show that using  #TAUTHOR_TAG to generate adversarial training data introduces new superficial trends for a model to exploit ; and instead we propose the addsentdiverse algorithm that generates highly varied data for adversarial training, resulting in more robust models']",1
"['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","[""' addsentdiverse'algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples for robust training purposes."", ""for each { context, question, answer } triple,  #TAUTHOR_TAG does the following : ( 1 ) several antonym and named - entity based semantic altering perturbations ( swapping ) are applied to the question ; ( 2 ) a fake answer is generated that matches the'type'of the original answer ( e. g., prague → chicago, etc. ) ; ( 3 ) the fake answer and the altered question are combined into a distractor statement based on a set of manually defined rules ; ( 4 ) errors in grammar are fixed by crowd - workers ; ( 5 ) the finalized distractor is appended to the end of the context."", 'the specificity of the algorithm creates new superficial cues that a model can learn and use during training and never get punished for : ( 1 ) a model can learn that it is unlikely for the last sentence to contain the real answer ; ( 2 ) a model can learn that the fixed set of fake answers should not be picked.', 'these nullify the effectiveness of the distractors as the model will learn to simply ignore them.', 'we thus introduce the addsentdiverse algorithm, which adds two modifications to  #TAUTHOR_TAG that allows for generating higher - variance adversarial examples.', 'namely, we randomize the distractor placement ( sec. 3. 1 ) and we diversity the set of fake answers used ( sec. 3. 2 ).', 'lastly, to address the antonymstyle semantic perturbations used in  #TAUTHOR_TAG we show that we need to improve model capabilities by adding indicator features for semantic relationships ( but only when ) in tandem with the addition of diverse adversarial data ( sec. 3. 3 )']",1
['antonymy ( which were inserted by  #TAUTHOR_TAG adversaries ; see'],"['antonymy ( which were inserted by  #TAUTHOR_TAG adversaries ; see sec. 3 ).', '']",['antonymy ( which were inserted by  #TAUTHOR_TAG adversaries ; see'],"['previous sections, we prevented the model from identifying distractors based on superficial clues such as location and fake answer identity by eliminating these correlations within the training data.', 'but even if we force the model to learn some deeper methods for identifying / discarding the distractors, it only has limited ability in recognizing semantic differences because its current inputs do not capture crucial aspects of lexical semantics such as antonymy ( which were inserted by  #TAUTHOR_TAG adversaries ; see sec. 3 ).', 'most current models use pretrained word embeddings ( e. g., glove  #AUTHOR_TAG and elmo  #AUTHOR_TAG ) as input, which are usually calculated based on the distributional hypothesis  #AUTHOR_TAG, and do not capture lexical semantic relations such as antonymy  #AUTHOR_TAG.', ""these shortcomings are reflected by our results in sec. 4. 6, where we see that we can't resolve all  #TAUTHOR_TAG - style adversaries by diversifying the training data alone."", 'for the model to be robust to semanticsbased ( e. g., antonym - style ) attacks, it needs extra knowledge of lexical semantic relations.', 'hence, we augment the input of each word in the question / context with two indicator features indicating the existence of its synonym and antonym ( using wordnet  #AUTHOR_TAG ) in the context / question, allowing the model to use lexical semantics directly instead of learned statistical correlations of the word embeddings']",1
"['based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdivers']","['based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training']","['adversarial evaluation based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training data by providing effective examples that punish the model']","['is shown that many published models for the stanford question answering dataset  #AUTHOR_TAG lack robustness, suffering an over 50 % decrease in f1 score during adversarial evaluation based on the  #TAUTHOR_TAG algorithm.', 'it has also been shown that retraining models on data generated by  #TAUTHOR_TAG has limited effect on their robustness.', 'we propose a novel alternative adversary - generation algorithm, addsentdiverse, that significantly increases the variance within the adversarial training data by providing effective examples that punish the model for making certain superficial assumptions.', ""further, in order to improve robustness to  #TAUTHOR_TAG's semantic perturbations ( e. g., antonyms ), we jointly improve the model's semantic - relationship learning capabilities in addition to our addsentdiversebased adversarial training data augmentation."", 'with these additions, we show that we can make a state - of - the - art model significantly more robust, achieving a 36. 5 % increase in f1 score under many different types of adversarial evaluation while maintaining performance on the regular squad task']",6
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",6
"['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model']","['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['##arial evaluation in computer vision, adversarial examples are frequently used to punish model oversensitivity, where semantic - preserving perturbations ( usually in the form of small noise vectors ) are added to an image to fool the classifier into giving it a different label  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model failure in the other direction : overstability, or the inability to detect semantic - altering noise.', 'it does so by generating distractor sentences that only resemble the questions syntactically and appending them to the context paragraphs ( detailed description included in sec. 3 ).', ""when tested on these adversarial examples,  #TAUTHOR_TAG showed that even the most'robust'amongst published models ( the mnemonic reader  #AUTHOR_TAG ) only achieved 46. 6 % f1 ( compared to 79. 6 % f1 on the regular task )."", ""since then, the fusionnet model  #AUTHOR_TAG used history - of - word representations and multi - level attention mechanism to obtain an improved 51. 4 % f1 score under adversarial evaluation, but that is still a 30 % decrease from the model's performance on the regular task."", 'we show, however, that one can make a pre - existing model significantly more robust by simply retraining it with better, higher variance adversarial training data, and improve it further with minor semantic feature additions to its inputs.', 'adversarial training it has been shown in the field of image classification that training with adversarial examples produces more robust and error - resistant models  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm.', 'despite performing well when evaluated on  #TAUTHOR_TAG in two superficial ways : using a different set of fake answers and prepending instead of appending the distractor sentence to the context ).', 'we show that using  #TAUTHOR_TAG to generate adversarial training data introduces new superficial trends for a model to exploit ; and instead we propose the addsentdiverse algorithm that generates highly varied data for adversarial training, resulting in more robust models']",6
"['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","[""' addsentdiverse'algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples for robust training purposes."", ""for each { context, question, answer } triple,  #TAUTHOR_TAG does the following : ( 1 ) several antonym and named - entity based semantic altering perturbations ( swapping ) are applied to the question ; ( 2 ) a fake answer is generated that matches the'type'of the original answer ( e. g., prague → chicago, etc. ) ; ( 3 ) the fake answer and the altered question are combined into a distractor statement based on a set of manually defined rules ; ( 4 ) errors in grammar are fixed by crowd - workers ; ( 5 ) the finalized distractor is appended to the end of the context."", 'the specificity of the algorithm creates new superficial cues that a model can learn and use during training and never get punished for : ( 1 ) a model can learn that it is unlikely for the last sentence to contain the real answer ; ( 2 ) a model can learn that the fixed set of fake answers should not be picked.', 'these nullify the effectiveness of the distractors as the model will learn to simply ignore them.', 'we thus introduce the addsentdiverse algorithm, which adds two modifications to  #TAUTHOR_TAG that allows for generating higher - variance adversarial examples.', 'namely, we randomize the distractor placement ( sec. 3. 1 ) and we diversity the set of fake answers used ( sec. 3. 2 ).', 'lastly, to address the antonymstyle semantic perturbations used in  #TAUTHOR_TAG we show that we need to improve model capabilities by adding indicator features for semantic relationships ( but only when ) in tandem with the addition of diverse adversarial data ( sec. 3. 3 )']",6
"['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","[""' addsentdiverse'algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples for robust training purposes."", ""for each { context, question, answer } triple,  #TAUTHOR_TAG does the following : ( 1 ) several antonym and named - entity based semantic altering perturbations ( swapping ) are applied to the question ; ( 2 ) a fake answer is generated that matches the'type'of the original answer ( e. g., prague → chicago, etc. ) ; ( 3 ) the fake answer and the altered question are combined into a distractor statement based on a set of manually defined rules ; ( 4 ) errors in grammar are fixed by crowd - workers ; ( 5 ) the finalized distractor is appended to the end of the context."", 'the specificity of the algorithm creates new superficial cues that a model can learn and use during training and never get punished for : ( 1 ) a model can learn that it is unlikely for the last sentence to contain the real answer ; ( 2 ) a model can learn that the fixed set of fake answers should not be picked.', 'these nullify the effectiveness of the distractors as the model will learn to simply ignore them.', 'we thus introduce the addsentdiverse algorithm, which adds two modifications to  #TAUTHOR_TAG that allows for generating higher - variance adversarial examples.', 'namely, we randomize the distractor placement ( sec. 3. 1 ) and we diversity the set of fake answers used ( sec. 3. 2 ).', 'lastly, to address the antonymstyle semantic perturbations used in  #TAUTHOR_TAG we show that we need to improve model capabilities by adding indicator features for semantic relationships ( but only when ) in tandem with the addition of diverse adversarial data ( sec. 3. 3 )']",6
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",0
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",0
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",0
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",0
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",0
"['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model']","['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['##arial evaluation in computer vision, adversarial examples are frequently used to punish model oversensitivity, where semantic - preserving perturbations ( usually in the form of small noise vectors ) are added to an image to fool the classifier into giving it a different label  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model failure in the other direction : overstability, or the inability to detect semantic - altering noise.', 'it does so by generating distractor sentences that only resemble the questions syntactically and appending them to the context paragraphs ( detailed description included in sec. 3 ).', ""when tested on these adversarial examples,  #TAUTHOR_TAG showed that even the most'robust'amongst published models ( the mnemonic reader  #AUTHOR_TAG ) only achieved 46. 6 % f1 ( compared to 79. 6 % f1 on the regular task )."", ""since then, the fusionnet model  #AUTHOR_TAG used history - of - word representations and multi - level attention mechanism to obtain an improved 51. 4 % f1 score under adversarial evaluation, but that is still a 30 % decrease from the model's performance on the regular task."", 'we show, however, that one can make a pre - existing model significantly more robust by simply retraining it with better, higher variance adversarial training data, and improve it further with minor semantic feature additions to its inputs.', 'adversarial training it has been shown in the field of image classification that training with adversarial examples produces more robust and error - resistant models  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm.', 'despite performing well when evaluated on  #TAUTHOR_TAG in two superficial ways : using a different set of fake answers and prepending instead of appending the distractor sentence to the context ).', 'we show that using  #TAUTHOR_TAG to generate adversarial training data introduces new superficial trends for a model to exploit ; and instead we propose the addsentdiverse algorithm that generates highly varied data for adversarial training, resulting in more robust models']",0
"['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model']","['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['##arial evaluation in computer vision, adversarial examples are frequently used to punish model oversensitivity, where semantic - preserving perturbations ( usually in the form of small noise vectors ) are added to an image to fool the classifier into giving it a different label  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model failure in the other direction : overstability, or the inability to detect semantic - altering noise.', 'it does so by generating distractor sentences that only resemble the questions syntactically and appending them to the context paragraphs ( detailed description included in sec. 3 ).', ""when tested on these adversarial examples,  #TAUTHOR_TAG showed that even the most'robust'amongst published models ( the mnemonic reader  #AUTHOR_TAG ) only achieved 46. 6 % f1 ( compared to 79. 6 % f1 on the regular task )."", ""since then, the fusionnet model  #AUTHOR_TAG used history - of - word representations and multi - level attention mechanism to obtain an improved 51. 4 % f1 score under adversarial evaluation, but that is still a 30 % decrease from the model's performance on the regular task."", 'we show, however, that one can make a pre - existing model significantly more robust by simply retraining it with better, higher variance adversarial training data, and improve it further with minor semantic feature additions to its inputs.', 'adversarial training it has been shown in the field of image classification that training with adversarial examples produces more robust and error - resistant models  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm.', 'despite performing well when evaluated on  #TAUTHOR_TAG in two superficial ways : using a different set of fake answers and prepending instead of appending the distractor sentence to the context ).', 'we show that using  #TAUTHOR_TAG to generate adversarial training data introduces new superficial trends for a model to exploit ; and instead we propose the addsentdiverse algorithm that generates highly varied data for adversarial training, resulting in more robust models']",0
"['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","['algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples']","[""' addsentdiverse'algorithm is a modified version of  #TAUTHOR_TAG, aimed at producing good adversarial examples for robust training purposes."", ""for each { context, question, answer } triple,  #TAUTHOR_TAG does the following : ( 1 ) several antonym and named - entity based semantic altering perturbations ( swapping ) are applied to the question ; ( 2 ) a fake answer is generated that matches the'type'of the original answer ( e. g., prague → chicago, etc. ) ; ( 3 ) the fake answer and the altered question are combined into a distractor statement based on a set of manually defined rules ; ( 4 ) errors in grammar are fixed by crowd - workers ; ( 5 ) the finalized distractor is appended to the end of the context."", 'the specificity of the algorithm creates new superficial cues that a model can learn and use during training and never get punished for : ( 1 ) a model can learn that it is unlikely for the last sentence to contain the real answer ; ( 2 ) a model can learn that the fixed set of fake answers should not be picked.', 'these nullify the effectiveness of the distractors as the model will learn to simply ignore them.', 'we thus introduce the addsentdiverse algorithm, which adds two modifications to  #TAUTHOR_TAG that allows for generating higher - variance adversarial examples.', 'namely, we randomize the distractor placement ( sec. 3. 1 ) and we diversity the set of fake answers used ( sec. 3. 2 ).', 'lastly, to address the antonymstyle semantic perturbations used in  #TAUTHOR_TAG we show that we need to improve model capabilities by adding indicator features for semantic relationships ( but only when ) in tandem with the addition of diverse adversarial data ( sec. 3. 3 )']",0
"['insert the distractor.', 'during training done by  #TAUTHOR_TAG, the distractor']","['insert the distractor.', 'during training done by  #TAUTHOR_TAG, the distractor']","['insert the distractor.', 'during training done by  #TAUTHOR_TAG, the distractor']","['', 'as shown in fig. 1, their distribution is highly dependent on the strategy used to insert the distractor.', 'during training done by  #TAUTHOR_TAG, the distractor is always added as the last sentence, creating a very skewed distribution for y.', 'this resulted in the model learning to ignore the last sentence, as it was never punished for doing so.', 'this, in turn, caused the retrained model to fail on addsentmod, where the distractor is inserted to the front instead of the back of the context paragraph ( this is shown by our experiments as well ).', 'however, fig. 1 shows that when the distractor is inserted randomly, the distributions of x and y are almost identical to that of x and y, indicating that no new correlation between the location of a sentence and its likelihood to contain the correct answer is introduced by the distractors, hence forcing the model to learn to discern them from']",0
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",4
[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],[' #TAUTHOR_TAG are syntactic'],"[', the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to q & a. this correlation between syntactic similarity and correctness is of course not true in general', "": the adversaries generated by  #TAUTHOR_TAG are syntactically similar to the question but do not answer them. the models'failures on  #TAUTHOR_TAG demonstrates their"", 'ignorance of this aspect of the task.  #TAUTHOR_TAG showed that the method is not very effective, as slight modifications', '( e. g., different positioning of the distractor sentence in the paragraph and different fake answer set ) to the adversary generation algorithm at', ""test time have drastic impact on the retrained model's performance. in this paper, we show that their method of adversarial training failed because the specificity of the"", ' #TAUTHOR_TAG algorithm along with the lack of naturally - occurring counterexamples allow models to', ""learn superficial clues regarding what is a'distractor'and subsequently ignore it ; thus significantly limiting their"", 'robustness. instead, we first introduce a novel algorithm, addsentdiverse, for generating adversarial examples with signifi - cantly higher variance ( by varying the locations where the distractors are placed and expanding the set of fake answers ), so that the model is punished during training time for making these superficial assumptions', '']",4
"['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model']","['a,  #TAUTHOR_TAG algorithm, which generates adversaries that pun']","['##arial evaluation in computer vision, adversarial examples are frequently used to punish model oversensitivity, where semantic - preserving perturbations ( usually in the form of small noise vectors ) are added to an image to fool the classifier into giving it a different label  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm, which generates adversaries that punish model failure in the other direction : overstability, or the inability to detect semantic - altering noise.', 'it does so by generating distractor sentences that only resemble the questions syntactically and appending them to the context paragraphs ( detailed description included in sec. 3 ).', ""when tested on these adversarial examples,  #TAUTHOR_TAG showed that even the most'robust'amongst published models ( the mnemonic reader  #AUTHOR_TAG ) only achieved 46. 6 % f1 ( compared to 79. 6 % f1 on the regular task )."", ""since then, the fusionnet model  #AUTHOR_TAG used history - of - word representations and multi - level attention mechanism to obtain an improved 51. 4 % f1 score under adversarial evaluation, but that is still a 30 % decrease from the model's performance on the regular task."", 'we show, however, that one can make a pre - existing model significantly more robust by simply retraining it with better, higher variance adversarial training data, and improve it further with minor semantic feature additions to its inputs.', 'adversarial training it has been shown in the field of image classification that training with adversarial examples produces more robust and error - resistant models  #AUTHOR_TAG.', 'in the field of q & a,  #TAUTHOR_TAG algorithm.', 'despite performing well when evaluated on  #TAUTHOR_TAG in two superficial ways : using a different set of fake answers and prepending instead of appending the distractor sentence to the context ).', 'we show that using  #TAUTHOR_TAG to generate adversarial training data introduces new superficial trends for a model to exploit ; and instead we propose the addsentdiverse algorithm that generates highly varied data for adversarial training, resulting in more robust models']",4
"[""instead of using  #TAUTHOR_TAG's pre - defined set."", '']","[""instead of using  #TAUTHOR_TAG's pre - defined set."", '']","[""prevent the model from superficially deciding what is a distractor based on certain specific words, we dynamically generate the fake answers instead of using  #TAUTHOR_TAG's pre - defined set."", '']","[""prevent the model from superficially deciding what is a distractor based on certain specific words, we dynamically generate the fake answers instead of using  #TAUTHOR_TAG's pre - defined set."", 'let s be the set that contains all the answers in the squad training data, tagged by their type ( e. g., person, location, etc. ).', 'for each answer a, we generate the fake answer dynamically by randomly selecting another answer a = a from s that has the same type as a, as opposed to  #TAUTHOR_TAG, which uses a pre - defined fake answer for each type ( e. g., "" chicago "" for any location ).', 'this creates a much larger set of fake answers, thus decreasing the correlation between any text and its likelihood of being a part of a distractor, forcing the model to become more robust']",4
"[""instead of using  #TAUTHOR_TAG's pre - defined set."", '']","[""instead of using  #TAUTHOR_TAG's pre - defined set."", '']","[""prevent the model from superficially deciding what is a distractor based on certain specific words, we dynamically generate the fake answers instead of using  #TAUTHOR_TAG's pre - defined set."", '']","[""prevent the model from superficially deciding what is a distractor based on certain specific words, we dynamically generate the fake answers instead of using  #TAUTHOR_TAG's pre - defined set."", 'let s be the set that contains all the answers in the squad training data, tagged by their type ( e. g., person, location, etc. ).', 'for each answer a, we generate the fake answer dynamically by randomly selecting another answer a = a from s that has the same type as a, as opposed to  #TAUTHOR_TAG, which uses a pre - defined fake answer for each type ( e. g., "" chicago "" for any location ).', 'this creates a much larger set of fake answers, thus decreasing the correlation between any text and its likelihood of being a part of a distractor, forcing the model to become more robust']",4
['antonymy ( which were inserted by  #TAUTHOR_TAG adversaries ; see'],"['antonymy ( which were inserted by  #TAUTHOR_TAG adversaries ; see sec. 3 ).', '']",['antonymy ( which were inserted by  #TAUTHOR_TAG adversaries ; see'],"['previous sections, we prevented the model from identifying distractors based on superficial clues such as location and fake answer identity by eliminating these correlations within the training data.', 'but even if we force the model to learn some deeper methods for identifying / discarding the distractors, it only has limited ability in recognizing semantic differences because its current inputs do not capture crucial aspects of lexical semantics such as antonymy ( which were inserted by  #TAUTHOR_TAG adversaries ; see sec. 3 ).', 'most current models use pretrained word embeddings ( e. g., glove  #AUTHOR_TAG and elmo  #AUTHOR_TAG ) as input, which are usually calculated based on the distributional hypothesis  #AUTHOR_TAG, and do not capture lexical semantic relations such as antonymy  #AUTHOR_TAG.', ""these shortcomings are reflected by our results in sec. 4. 6, where we see that we can't resolve all  #TAUTHOR_TAG - style adversaries by diversifying the training data alone."", 'for the model to be robust to semanticsbased ( e. g., antonym - style ) attacks, it needs extra knowledge of lexical semantic relations.', 'hence, we augment the input of each word in the question / context with two indicator features indicating the existence of its synonym and antonym ( using wordnet  #AUTHOR_TAG ) in the context / question, allowing the model to use lexical semantics directly instead of learned statistical correlations of the word embeddings']",4
['tested on  #TAUTHOR_TAG and adds'],"['tested on  #TAUTHOR_TAG and addsentprepend, whose only difference is']","['insrandom, where the distractor is randomly placed.', 'the retrained models are tested on  #TAUTHOR_TAG and adds']","[""also conducted experiments studying the effect of different distractor placement strategies on the trained models'robustness."", 'the bsae model was trained on 4 variations of addsentdiverseaugmented training set, with the only difference between them being the location of the distractor within the context : insfirst, where the distractor is prepended, inslast, where the distractor is appended, insmid, where the distractor is inserted in the middle and insrandom, where the distractor is randomly placed.', 'the retrained models are tested on  #TAUTHOR_TAG and addsentprepend, whose only difference is where the distractor is located.', 'the result is shown in performs well on test sets created by a similar distractor placement strategy, indicating that they are exploiting superficial trends instead of learning to process the semantics.', 'it is also shown that insrandom gives optimal performance on both evaluation datasets.', 'further investigations regarding distractor placement can be found in the appendix']",4
"['are evaluated on the original squad dev set and 4 adversarial datasets :  #TAUTHOR_TAG,']","['are evaluated on the original squad dev set and 4 adversarial datasets :  #TAUTHOR_TAG,']","['are evaluated on the original squad dev set and 4 adversarial datasets :  #TAUTHOR_TAG,']","['are evaluated on the original squad dev set and 4 adversarial datasets :  #TAUTHOR_TAG, where a different set of fake answers is used and the distractor is prepended to the context.', ""experiments measure the soft f1 score and all of the adversarial evaluations are modeldependent, following the style of  #TAUTHOR_TAG, where multiple adversaries are generated for each exam - ple in the evaluation set and the model's worst performance among the variants is recorded""]",5
"['are evaluated on the original squad dev set and 4 adversarial datasets :  #TAUTHOR_TAG,']","['are evaluated on the original squad dev set and 4 adversarial datasets :  #TAUTHOR_TAG,']","['are evaluated on the original squad dev set and 4 adversarial datasets :  #TAUTHOR_TAG,']","['are evaluated on the original squad dev set and 4 adversarial datasets :  #TAUTHOR_TAG, where a different set of fake answers is used and the distractor is prepended to the context.', ""experiments measure the soft f1 score and all of the adversarial evaluations are modeldependent, following the style of  #TAUTHOR_TAG, where multiple adversaries are generated for each exam - ple in the evaluation set and the model's worst performance among the variants is recorded""]",5
"['augmented with  #TAUTHOR_TAG, and squ']","['augmented with  #TAUTHOR_TAG, and squad']","['augmented with  #TAUTHOR_TAG, and squ']","[""our main experiment, we compare the bsae model's performance on different test sets when trained with three different training sets : the original squad data ( original - squad ), squad data augmented with  #TAUTHOR_TAG, and squad data augmented with our addsentdiverse generated adversaries."", 'for the latter two, we run the respective adversarial generation algorithms on the training set, and add randomly selected adversarial examples such that they make up 20 % of the total training data.', 'the results are shown in table 1.', 'first, as shown, the  #TAUTHOR_TAG - trained model is not able to perform well on test sets where the distractors are not inserted at the end, e. g., the addsentrandom adversarial test set.', '5 on the other hand, it can be seen that retraining with addsentdiverse boosts performance of the model significantly across all adversarial datasets, indicating a general increase in robustness']",5
"['augmented with  #TAUTHOR_TAG, and squ']","['augmented with  #TAUTHOR_TAG, and squad']","['augmented with  #TAUTHOR_TAG, and squ']","[""our main experiment, we compare the bsae model's performance on different test sets when trained with three different training sets : the original squad data ( original - squad ), squad data augmented with  #TAUTHOR_TAG, and squad data augmented with our addsentdiverse generated adversaries."", 'for the latter two, we run the respective adversarial generation algorithms on the training set, and add randomly selected adversarial examples such that they make up 20 % of the total training data.', 'the results are shown in table 1.', 'first, as shown, the  #TAUTHOR_TAG - trained model is not able to perform well on test sets where the distractors are not inserted at the end, e. g., the addsentrandom adversarial test set.', '5 on the other hand, it can be seen that retraining with addsentdiverse boosts performance of the model significantly across all adversarial datasets, indicating a general increase in robustness']",5
['tested on  #TAUTHOR_TAG and adds'],"['tested on  #TAUTHOR_TAG and addsentprepend, whose only difference is']","['insrandom, where the distractor is randomly placed.', 'the retrained models are tested on  #TAUTHOR_TAG and adds']","[""also conducted experiments studying the effect of different distractor placement strategies on the trained models'robustness."", 'the bsae model was trained on 4 variations of addsentdiverseaugmented training set, with the only difference between them being the location of the distractor within the context : insfirst, where the distractor is prepended, inslast, where the distractor is appended, insmid, where the distractor is inserted in the middle and insrandom, where the distractor is randomly placed.', 'the retrained models are tested on  #TAUTHOR_TAG and addsentprepend, whose only difference is where the distractor is located.', 'the result is shown in performs well on test sets created by a similar distractor placement strategy, indicating that they are exploiting superficial trends instead of learning to process the semantics.', 'it is also shown that insrandom gives optimal performance on both evaluation datasets.', 'further investigations regarding distractor placement can be found in the appendix']",5
['bsae + sa model on the  #TAUTHOR_TAG dataset and found that out of the'],['adversarially - trained bsae + sa model on the  #TAUTHOR_TAG dataset and found that out of the'],['our final adversarially - trained bsae + sa model on the  #TAUTHOR_TAG dataset and found that out of'],"[', we examined the errors of our final adversarially - trained bsae + sa model on the  #TAUTHOR_TAG dataset and found that out of the 21. 09 % remaining errors ( table 4 ), 33. 3 % ( 46 cases ) of these erroneous predictions occurred within the inserted distractor, and 63. 7 % ( 88 cases ) occurred on questions that the model got wrong in the original squad dev set ( without the inserted distractors ).', ""the former errors are mainly occurring within distractors created with named - entity replacements ( which we haven't addressed directly in the current paper ) or malformed distractors ( that in fact do answer the question )""]",5
"['was not skewed towards either  #TAUTHOR_TAG or addsentprepend, but was worse on both when compared to insrandom.', 'this method of calculating the distribution of p sa allows us to predict the model']","['was not skewed towards either  #TAUTHOR_TAG or addsentprepend, but was worse on both when compared to insrandom.', ""this method of calculating the distribution of p sa allows us to predict the model's""]","[""in our experiment studying the effect of distractor placement strategies ( see table 2 ), insmid's performance was not skewed towards either  #TAUTHOR_TAG or addsentprepend, but was worse on both when compared to insrandom."", ""this method of calculating the distribution of p sa allows us to predict the model's performance""]","['', 'we pick these n as they are typical lengths of contexts within the squad dataset ( the complete distribution of paragraph lengths in the squad training set is shown in fig. 4 ).', 'we see that under random insertion, the distribution is very close to uniform.', 'note that if we were to aggregate n and plot p sa for n ≤ 3, 5 and 7, as shown in fig. 3, the distributions of p sa created by inserting in the middle and inserting randomly are very similar, but the distribution of inserting in the middle is skewed against the beginnings and ends of the paragraphs.', ""this explains why in our experiment studying the effect of distractor placement strategies ( see table 2 ), insmid's performance was not skewed towards either  #TAUTHOR_TAG or addsentprepend, but was worse on both when compared to insrandom."", ""this method of calculating the distribution of p sa allows us to predict the model's performance when trained on datasets where the distractors are inserted at specific locations."", ""to test this hypothesis, we created two datasets : insfront - 3 and insfront - 6 where the distractors were inserted as the 3rd and 6th sentence from the beginning and measure the model's performance when trained on""]",5
"['simple', 'ones  #TAUTHOR_TAG. and hand']","['into simple', 'ones  #TAUTHOR_TAG. and hand']","['', 'ones  #TAUTHOR_TAG. and hand']","[', words ( e. g., use instead of exploit ) ; simpler syntactic', 'constructions ( e. g., no relative clauses or apposition ) ; and fewer modifiers ( e. g., he slept vs. he also slept ). in practice, simplification is thus often modeled using four main operations : splitting a complex sentence into several simpler sentences ; dropping and reordering phrases or constituents ; substituting words / phrases with simpler ones', '. as has been argued in previous work, sentence simplification has many potential applications. it is useful as a preprocessing step for a variety of nlp systems such as parsers and machine translation systems', ' #AUTHOR_TAG, summarisation  #AUTHOR_TAG, sentence fusion  #AUTHOR_TAG and semantic role labelling  #AUTHOR_TAG.', 'it also has wide ranging potential societal application as a reading aid for people with aphasis  #AUTHOR_TAG, for low literacy readers  #AUTHOR_TAG and for non native speakers  #AUTHOR_TAG. there has been much work recently', 'on developing computational frameworks for sentence simplification. synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence', ' #AUTHOR_TAG. machine translation systems have been adapted to translate complex sentences into simple', 'ones  #TAUTHOR_TAG. and handcrafted rules have been proposed to model the syntactic transformations involved in simplifications  #AUTHOR_TAG. in this paper', '']",0
[' #TAUTHOR_TAG and'],"['corpus developed by  #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between']","[' #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between']","['##ally well - informed syntactic transformation ( using e. g., detailed morphological and syntactic information ), they are limited in scope to purely syntactic rules and do not account for lexical simplifications and their interaction with', 'the sentential context. using the parallel dataset formed by simple english wikipedia ( swkp ) 1 and traditional english wikipedia ( ewkp ) 2, more recent work has focused on developing machine learning approaches to sentence simplification.  #AUTHOR_TAG constructed a parallel corpus ( pwkp ) of 108, 016', '/ 114, 924 complex / simple sentences by aligning sentences from ewkp and swkp and used the resulting bitext to train a simplification model inspired by syntax - based machine translation  #AUTHOR_TAG', '. their simplification model encodes the probabilities for four rewriting operations on the parse tree of an input sentences namely, substitution, reordering, splitting and deletion. it is combined with a language model to improve grammaticality and the decoder translates sentences into sim - pler ones by', 'greedily selecting the output sentence with highest probability. using both the pwkp corpus developed by  #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between parse trees of complex and of simple sentences.  #AUTHOR_TAG, they then generate all possible rewrites for a source tree and use integer linear', '']",0
[' #TAUTHOR_TAG and'],"['corpus developed by  #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between']","[' #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between']","['##ally well - informed syntactic transformation ( using e. g., detailed morphological and syntactic information ), they are limited in scope to purely syntactic rules and do not account for lexical simplifications and their interaction with', 'the sentential context. using the parallel dataset formed by simple english wikipedia ( swkp ) 1 and traditional english wikipedia ( ewkp ) 2, more recent work has focused on developing machine learning approaches to sentence simplification.  #AUTHOR_TAG constructed a parallel corpus ( pwkp ) of 108, 016', '/ 114, 924 complex / simple sentences by aligning sentences from ewkp and swkp and used the resulting bitext to train a simplification model inspired by syntax - based machine translation  #AUTHOR_TAG', '. their simplification model encodes the probabilities for four rewriting operations on the parse tree of an input sentences namely, substitution, reordering, splitting and deletion. it is combined with a language model to improve grammaticality and the decoder translates sentences into sim - pler ones by', 'greedily selecting the output sentence with highest probability. using both the pwkp corpus developed by  #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between parse trees of complex and of simple sentences.  #AUTHOR_TAG, they then generate all possible rewrites for a source tree and use integer linear', '']",0
[' #TAUTHOR_TAG and'],"['corpus developed by  #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between']","[' #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between']","['##ally well - informed syntactic transformation ( using e. g., detailed morphological and syntactic information ), they are limited in scope to purely syntactic rules and do not account for lexical simplifications and their interaction with', 'the sentential context. using the parallel dataset formed by simple english wikipedia ( swkp ) 1 and traditional english wikipedia ( ewkp ) 2, more recent work has focused on developing machine learning approaches to sentence simplification.  #AUTHOR_TAG constructed a parallel corpus ( pwkp ) of 108, 016', '/ 114, 924 complex / simple sentences by aligning sentences from ewkp and swkp and used the resulting bitext to train a simplification model inspired by syntax - based machine translation  #AUTHOR_TAG', '. their simplification model encodes the probabilities for four rewriting operations on the parse tree of an input sentences namely, substitution, reordering, splitting and deletion. it is combined with a language model to improve grammaticality and the decoder translates sentences into sim - pler ones by', 'greedily selecting the output sentence with highest probability. using both the pwkp corpus developed by  #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between parse trees of complex and of simple sentences.  #AUTHOR_TAG, they then generate all possible rewrites for a source tree and use integer linear', '']",0
"['on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and sw']","['on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and swkp respectively']","['drs - based simplification model is trained on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and sw']","['drs - based simplification model is trained on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and swkp respectively and automatically aligned them using tf * idf as a similarity measure.', 'pwkp contains 108016 / 114924 complex / simple sentence pairs.', 'we tokenize pwkp using stanford corenlp toolkit 8.', '']",0
"['simple', 'ones  #TAUTHOR_TAG. and hand']","['into simple', 'ones  #TAUTHOR_TAG. and hand']","['', 'ones  #TAUTHOR_TAG. and hand']","[', words ( e. g., use instead of exploit ) ; simpler syntactic', 'constructions ( e. g., no relative clauses or apposition ) ; and fewer modifiers ( e. g., he slept vs. he also slept ). in practice, simplification is thus often modeled using four main operations : splitting a complex sentence into several simpler sentences ; dropping and reordering phrases or constituents ; substituting words / phrases with simpler ones', '. as has been argued in previous work, sentence simplification has many potential applications. it is useful as a preprocessing step for a variety of nlp systems such as parsers and machine translation systems', ' #AUTHOR_TAG, summarisation  #AUTHOR_TAG, sentence fusion  #AUTHOR_TAG and semantic role labelling  #AUTHOR_TAG.', 'it also has wide ranging potential societal application as a reading aid for people with aphasis  #AUTHOR_TAG, for low literacy readers  #AUTHOR_TAG and for non native speakers  #AUTHOR_TAG. there has been much work recently', 'on developing computational frameworks for sentence simplification. synchronous grammars have been used in combination with linear integer programming to generate and rank all possible rewrites of an input sentence', ' #AUTHOR_TAG. machine translation systems have been adapted to translate complex sentences into simple', 'ones  #TAUTHOR_TAG. and handcrafted rules have been proposed to model the syntactic transformations involved in simplifications  #AUTHOR_TAG. in this paper', '']",6
[' #TAUTHOR_TAG and'],"['corpus developed by  #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between']","[' #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between']","['##ally well - informed syntactic transformation ( using e. g., detailed morphological and syntactic information ), they are limited in scope to purely syntactic rules and do not account for lexical simplifications and their interaction with', 'the sentential context. using the parallel dataset formed by simple english wikipedia ( swkp ) 1 and traditional english wikipedia ( ewkp ) 2, more recent work has focused on developing machine learning approaches to sentence simplification.  #AUTHOR_TAG constructed a parallel corpus ( pwkp ) of 108, 016', '/ 114, 924 complex / simple sentences by aligning sentences from ewkp and swkp and used the resulting bitext to train a simplification model inspired by syntax - based machine translation  #AUTHOR_TAG', '. their simplification model encodes the probabilities for four rewriting operations on the parse tree of an input sentences namely, substitution, reordering, splitting and deletion. it is combined with a language model to improve grammaticality and the decoder translates sentences into sim - pler ones by', 'greedily selecting the output sentence with highest probability. using both the pwkp corpus developed by  #TAUTHOR_TAG and the edit history of  #AUTHOR_TAG learn a quasi', 'synchronous grammar  #AUTHOR_TAG describing a loose alignment between parse trees of complex and of simple sentences.  #AUTHOR_TAG, they then generate all possible rewrites for a source tree and use integer linear', '']",5
"['use the em algorithm  #AUTHOR_TAG to estimate our split and deletion model parameters.', 'for an efficient implementation of em algorithm, we follow the work of  #AUTHOR_TAG and  #TAUTHOR_TAG ; and build training graphs ( figure 2 ) from the pair of complex and simple']","['use the em algorithm  #AUTHOR_TAG to estimate our split and deletion model parameters.', 'for an efficient implementation of em algorithm, we follow the work of  #AUTHOR_TAG and  #TAUTHOR_TAG ; and build training graphs ( figure 2 ) from the pair of complex and simple']","['use the em algorithm  #AUTHOR_TAG to estimate our split and deletion model parameters.', 'for an efficient implementation of em algorithm, we follow the work of  #AUTHOR_TAG and  #TAUTHOR_TAG ; and build training graphs ( figure 2 ) from the pair of complex and simple sentence pairs in the training data.', '']","['use the em algorithm  #AUTHOR_TAG to estimate our split and deletion model parameters.', 'for an efficient implementation of em algorithm, we follow the work of  #AUTHOR_TAG and  #TAUTHOR_TAG ; and build training graphs ( figure 2 ) from the pair of complex and simple sentence pairs in the training data.', 'each training graph represents a complexsimple sentence pair and consists of two types of nodes : major nodes ( m - nodes ) and operation nodes ( o - nodes ).', '']",5
['systems using the test set provided by  #TAUTHOR_TAG and relying both on automatic metrics and on human judgments'],['systems using the test set provided by  #TAUTHOR_TAG and relying both on automatic metrics and on human judgments'],['the test set provided by  #TAUTHOR_TAG and relying both on automatic metrics and on human judgments'],"['trained our simplification and translation models on the pwkp corpus.', 'to evaluate performance, we compare our approach with three other state of the art systems using the test set provided by  #TAUTHOR_TAG and relying both on automatic metrics and on human judgments']",5
"['on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and sw']","['on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and swkp respectively']","['drs - based simplification model is trained on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and sw']","['drs - based simplification model is trained on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and swkp respectively and automatically aligned them using tf * idf as a similarity measure.', 'pwkp contains 108016 / 114924 complex / simple sentence pairs.', 'we tokenize pwkp using stanford corenlp toolkit 8.', '']",5
"['on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and sw']","['on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and swkp respectively']","['drs - based simplification model is trained on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and sw']","['drs - based simplification model is trained on pwkp, a bi - text of complex and simple sentences provided by  #TAUTHOR_TAG.', 'to construct this bi - text,  #TAUTHOR_TAG extracted complex and simple sentences from ewkp and swkp respectively and automatically aligned them using tf * idf as a similarity measure.', 'pwkp contains 108016 / 114924 complex / simple sentence pairs.', 'we tokenize pwkp using stanford corenlp toolkit 8.', '']",5
['1 in  #TAUTHOR_TAG'],['1 in  #TAUTHOR_TAG'],"['( see figure 1 in  #TAUTHOR_TAG.', 'during the dialogue,']","['', 'the users can enter their appointment constraints via a graphical user interface and receive the results either by e - mail or via their electronic calendar.', 'agent systems are thus hooked up to e - mail, to a calendar manager and to the dialogue server.', 'the server interface is command - driven.', 'a client may connect to the server and open up a dialogue ( see figure 1 in  #TAUTHOR_TAG.', '']",5
['1 in  #TAUTHOR_TAG'],['1 in  #TAUTHOR_TAG'],"['( see figure 1 in  #TAUTHOR_TAG.', 'during the dialogue,']","['', 'the users can enter their appointment constraints via a graphical user interface and receive the results either by e - mail or via their electronic calendar.', 'agent systems are thus hooked up to e - mail, to a calendar manager and to the dialogue server.', 'the server interface is command - driven.', 'a client may connect to the server and open up a dialogue ( see figure 1 in  #TAUTHOR_TAG.', '']",0
['1 in  #TAUTHOR_TAG'],['1 in  #TAUTHOR_TAG'],"['( see figure 1 in  #TAUTHOR_TAG.', 'during the dialogue,']","['', 'the users can enter their appointment constraints via a graphical user interface and receive the results either by e - mail or via their electronic calendar.', 'agent systems are thus hooked up to e - mail, to a calendar manager and to the dialogue server.', 'the server interface is command - driven.', 'a client may connect to the server and open up a dialogue ( see figure 1 in  #TAUTHOR_TAG.', '']",6
"['of  #TAUTHOR_TAG, but the features and techniques we use are very']","['of  #TAUTHOR_TAG, but the features and techniques we use are very']","[""be used to match a caller's voice against models of known callers ). restricting our attention to voicemail transcripts means that our focus and goals are similar to those of  #TAUTHOR_TAG, but the features and techniques we use are very""]","[""may be available : the voicemail system or the pbx might provide information about the originating station of a call, and speaker identification can be used to match a caller's voice against models of known callers ). restricting our attention to voicemail transcripts means that our focus and goals are similar to those of  #TAUTHOR_TAG, but the features and techniques we use are very different. while the present task may seem broadly similar to named entity extraction"", 'from broadcast news  #AUTHOR_TAG, it is quite distinct from the latter : first, we are only interested in a small subset of the named entities ; and second, the structure of the voicemail transcripts', 'in our corpus is very different from broadcast news and certain aspects of this structure can be exploited for extracting caller names.  #TAUTHOR_TAG discuss three approaches : hand - crafted rules ; grammatical inference of subsequential transducers ; and log - linear classifiers with bigram and trigram features used as taggers  #AUTHOR_TAG. while the', 'latter are reported to yield the best overall performance, the hand - crafted rules resulted in higher recall. our phone number extract', '']",3
"['of  #TAUTHOR_TAG, but the features and techniques we use are very']","['of  #TAUTHOR_TAG, but the features and techniques we use are very']","[""be used to match a caller's voice against models of known callers ). restricting our attention to voicemail transcripts means that our focus and goals are similar to those of  #TAUTHOR_TAG, but the features and techniques we use are very""]","[""may be available : the voicemail system or the pbx might provide information about the originating station of a call, and speaker identification can be used to match a caller's voice against models of known callers ). restricting our attention to voicemail transcripts means that our focus and goals are similar to those of  #TAUTHOR_TAG, but the features and techniques we use are very different. while the present task may seem broadly similar to named entity extraction"", 'from broadcast news  #AUTHOR_TAG, it is quite distinct from the latter : first, we are only interested in a small subset of the named entities ; and second, the structure of the voicemail transcripts', 'in our corpus is very different from broadcast news and certain aspects of this structure can be exploited for extracting caller names.  #TAUTHOR_TAG discuss three approaches : hand - crafted rules ; grammatical inference of subsequential transducers ; and log - linear classifiers with bigram and trigram features used as taggers  #AUTHOR_TAG. while the', 'latter are reported to yield the best overall performance, the hand - crafted rules resulted in higher recall. our phone number extract', '']",3
"['by  #TAUTHOR_TAG, we hasten to point out that this']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['during training, and so we prefer the stricter criterion for evaluation on', 'previously annotated transcripts. while the results for the approach proposed here appear clearly worse than those reported by  #TAUTHOR_TAG, we hasten to point out that this is', '']",3
"['by  #TAUTHOR_TAG, we hasten to point out that this']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['during training, and so we prefer the stricter criterion for evaluation on', 'previously annotated transcripts. while the results for the approach proposed here appear clearly worse than those reported by  #TAUTHOR_TAG, we hasten to point out that this is', '']",3
"['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ;']","['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ;']","['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ; row col log - linear refers to the']","[""of the message, and a small number of lexical cues in the surrounding context of a candidate number ('call ','number '"", ', etc. ). this approach ( which we call classify below', ') increases the precision of the combined two steps to acceptable levels', 'without hurting recall too much. a comparison of performance results is presented in table 4. rows hzp rules and hzp log', '- linear refer to the rule - based baseline and the best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ; row col log - linear refers to the same named entity tagger we used in the previous section and is included for comparison with the hzp', 'models ; row ja digits refers to the simple baseline where we extract strings of spoken digits of plausible lengths. our main results appear in the remaining rows. the performance of our hand - crafted extraction grammar ( in row ja extract ) was about', 'what we had seen on the development data before, with recall being as high as one could reasonably expect. as mentioned above, using a simple pruning step in the second phase ( see ja extract + pr', '']",3
"['of  #TAUTHOR_TAG, but the features and techniques we use are very']","['of  #TAUTHOR_TAG, but the features and techniques we use are very']","[""be used to match a caller's voice against models of known callers ). restricting our attention to voicemail transcripts means that our focus and goals are similar to those of  #TAUTHOR_TAG, but the features and techniques we use are very""]","[""may be available : the voicemail system or the pbx might provide information about the originating station of a call, and speaker identification can be used to match a caller's voice against models of known callers ). restricting our attention to voicemail transcripts means that our focus and goals are similar to those of  #TAUTHOR_TAG, but the features and techniques we use are very different. while the present task may seem broadly similar to named entity extraction"", 'from broadcast news  #AUTHOR_TAG, it is quite distinct from the latter : first, we are only interested in a small subset of the named entities ; and second, the structure of the voicemail transcripts', 'in our corpus is very different from broadcast news and certain aspects of this structure can be exploited for extracting caller names.  #TAUTHOR_TAG discuss three approaches : hand - crafted rules ; grammatical inference of subsequential transducers ; and log - linear classifiers with bigram and trigram features used as taggers  #AUTHOR_TAG. while the', 'latter are reported to yield the best overall performance, the hand - crafted rules resulted in higher recall. our phone number extract', '']",0
"['by  #TAUTHOR_TAG, we hasten to point out that this']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['during training, and so we prefer the stricter criterion for evaluation on', 'previously annotated transcripts. while the results for the approach proposed here appear clearly worse than those reported by  #TAUTHOR_TAG, we hasten to point out that this is', '']",0
"['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ;']","['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ;']","['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ; row col log - linear refers to the']","[""of the message, and a small number of lexical cues in the surrounding context of a candidate number ('call ','number '"", ', etc. ). this approach ( which we call classify below', ') increases the precision of the combined two steps to acceptable levels', 'without hurting recall too much. a comparison of performance results is presented in table 4. rows hzp rules and hzp log', '- linear refer to the rule - based baseline and the best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ; row col log - linear refers to the same named entity tagger we used in the previous section and is included for comparison with the hzp', 'models ; row ja digits refers to the simple baseline where we extract strings of spoken digits of plausible lengths. our main results appear in the remaining rows. the performance of our hand - crafted extraction grammar ( in row ja extract ) was about', 'what we had seen on the development data before, with recall being as high as one could reasonably expect. as mentioned above, using a simple pruning step in the second phase ( see ja extract + pr', '']",0
"['of  #TAUTHOR_TAG.', '• the combined']","['of  #TAUTHOR_TAG.', '• the combined']","['of  #TAUTHOR_TAG.', '• the combined performance']","['novel contributions of this paper can be summarized as follows :', '• we demonstrated empirically that positional cues can be an important source of information for locating caller names and phrases.', '• we showed that good performance on the task of extracting caller information can be achieved using a very small inventory of lexical and positional features.', '• we argued that for extracting telephone numbers it is extremely useful to take the length of their numeric representation into account.', 'our grammar - based extractor translates spoken numbers into such a numeric representation.', '• our two - phase approach allows us to efficiently develop a simple extraction grammar for which the only requirement is high recall.', 'this places less of a burden on the grammar developers than having to write an accurate set of rules like the baseline of  #TAUTHOR_TAG.', '• the combined performance of our simple extraction grammar and the second - phase classifier exceeded the performance of all other methods, including the current state of the art  #TAUTHOR_TAG.', 'our results point towards approaches that use a small inventory of features that have been tailored to specific tasks.', '']",0
"['by  #TAUTHOR_TAG, we hasten to point out that this']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['during training, and so we prefer the stricter criterion for evaluation on', 'previously annotated transcripts. while the results for the approach proposed here appear clearly worse than those reported by  #TAUTHOR_TAG, we hasten to point out that this is', '']",5
"['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ;']","['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ;']","['best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ; row col log - linear refers to the']","[""of the message, and a small number of lexical cues in the surrounding context of a candidate number ('call ','number '"", ', etc. ). this approach ( which we call classify below', ') increases the precision of the combined two steps to acceptable levels', 'without hurting recall too much. a comparison of performance results is presented in table 4. rows hzp rules and hzp log', '- linear refer to the rule - based baseline and the best log - linear model of  #TAUTHOR_TAG and the figures are simply', 'taken from that paper ; row col log - linear refers to the same named entity tagger we used in the previous section and is included for comparison with the hzp', 'models ; row ja digits refers to the simple baseline where we extract strings of spoken digits of plausible lengths. our main results appear in the remaining rows. the performance of our hand - crafted extraction grammar ( in row ja extract ) was about', 'what we had seen on the development data before, with recall being as high as one could reasonably expect. as mentioned above, using a simple pruning step in the second phase ( see ja extract + pr', '']",5
"['of  #TAUTHOR_TAG.', '• the combined']","['of  #TAUTHOR_TAG.', '• the combined']","['of  #TAUTHOR_TAG.', '• the combined performance']","['novel contributions of this paper can be summarized as follows :', '• we demonstrated empirically that positional cues can be an important source of information for locating caller names and phrases.', '• we showed that good performance on the task of extracting caller information can be achieved using a very small inventory of lexical and positional features.', '• we argued that for extracting telephone numbers it is extremely useful to take the length of their numeric representation into account.', 'our grammar - based extractor translates spoken numbers into such a numeric representation.', '• our two - phase approach allows us to efficiently develop a simple extraction grammar for which the only requirement is high recall.', 'this places less of a burden on the grammar developers than having to write an accurate set of rules like the baseline of  #TAUTHOR_TAG.', '• the combined performance of our simple extraction grammar and the second - phase classifier exceeded the performance of all other methods, including the current state of the art  #TAUTHOR_TAG.', 'our results point towards approaches that use a small inventory of features that have been tailored to specific tasks.', '']",5
"['by  #TAUTHOR_TAG, we hasten to point out that this']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['during training, and so we prefer the stricter criterion for evaluation on', 'previously annotated transcripts. while the results for the approach proposed here appear clearly worse than those reported by  #TAUTHOR_TAG, we hasten to point out that this is', '']",7
"['by  #TAUTHOR_TAG, we hasten to point out that this']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['during training, and so we prefer the stricter criterion for evaluation on', 'previously annotated transcripts. while the results for the approach proposed here appear clearly worse than those reported by  #TAUTHOR_TAG, we hasten to point out that this is', '']",7
"['by  #TAUTHOR_TAG, we hasten to point out that this']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['during training, and so we prefer the stricter criterion for evaluation on', 'previously annotated transcripts. while the results for the approach proposed here appear clearly worse than those reported by  #TAUTHOR_TAG, we hasten to point out that this is', '']",4
"['by  #TAUTHOR_TAG, we hasten to point out that this']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['by  #TAUTHOR_TAG, we hasten to point out that this is', 'most likely not']","['during training, and so we prefer the stricter criterion for evaluation on', 'previously annotated transcripts. while the results for the approach proposed here appear clearly worse than those reported by  #TAUTHOR_TAG, we hasten to point out that this is', '']",4
"['of  #TAUTHOR_TAG.', '• the combined']","['of  #TAUTHOR_TAG.', '• the combined']","['of  #TAUTHOR_TAG.', '• the combined performance']","['novel contributions of this paper can be summarized as follows :', '• we demonstrated empirically that positional cues can be an important source of information for locating caller names and phrases.', '• we showed that good performance on the task of extracting caller information can be achieved using a very small inventory of lexical and positional features.', '• we argued that for extracting telephone numbers it is extremely useful to take the length of their numeric representation into account.', 'our grammar - based extractor translates spoken numbers into such a numeric representation.', '• our two - phase approach allows us to efficiently develop a simple extraction grammar for which the only requirement is high recall.', 'this places less of a burden on the grammar developers than having to write an accurate set of rules like the baseline of  #TAUTHOR_TAG.', '• the combined performance of our simple extraction grammar and the second - phase classifier exceeded the performance of all other methods, including the current state of the art  #TAUTHOR_TAG.', 'our results point towards approaches that use a small inventory of features that have been tailored to specific tasks.', '']",4
"['biases  #TAUTHOR_TAG, due to the source']","['biases  #TAUTHOR_TAG, due to the source']","['14 ].', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from']","['', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from which they are trained.', 'in effect, biases from the source data, such as in the differences in representation for men and women, that have been found in many different large - scale studies [ 5 ], [ 10 ], [ 12 ], carry through to the semantic relations in the word embeddings, which become baked into the learning systems that are built on top of them.', 'in this paper, we make three contributions towards addressing these concerns.', 'first we propose a new version of the word embedding association tests ( weats ) studied in  #TAUTHOR_TAG, designed to demonstrate and quantify bias in word embeddings, which puts them on a firm foundation by using the linguistic inquiry and word count ( liwc ) lexica [ 17 ] to systematically detect and measure embedding biases.', 'with this improved experimental setting, we find that european - american names are viewed more positively than african - american names, male names are more associated with work while female names are more associated with family, and that the academic disciplines of science and maths are more associated with male terms than the arts, which are more associated with female terms.', 'using this new methodology, we then find that there is a gender bias in the']",0
"['biases  #TAUTHOR_TAG, due to the source']","['biases  #TAUTHOR_TAG, due to the source']","['14 ].', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from']","['', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from which they are trained.', 'in effect, biases from the source data, such as in the differences in representation for men and women, that have been found in many different large - scale studies [ 5 ], [ 10 ], [ 12 ], carry through to the semantic relations in the word embeddings, which become baked into the learning systems that are built on top of them.', 'in this paper, we make three contributions towards addressing these concerns.', 'first we propose a new version of the word embedding association tests ( weats ) studied in  #TAUTHOR_TAG, designed to demonstrate and quantify bias in word embeddings, which puts them on a firm foundation by using the linguistic inquiry and word count ( liwc ) lexica [ 17 ] to systematically detect and measure embedding biases.', 'with this improved experimental setting, we find that european - american names are viewed more positively than african - american names, male names are more associated with work while female names are more associated with family, and that the academic disciplines of science and maths are more associated with male terms than the arts, which are more associated with female terms.', 'using this new methodology, we then find that there is a gender bias in the']",0
['embedding association tests studied in  #TAUTHOR_TAG by using the liwc lexic'],['embedding association tests studied in  #TAUTHOR_TAG by using the liwc lexica to systematically detect'],"['this paper, we conduct three experiments on semantic word embeddings.', 'we first propose a new version of the word embedding association tests studied in  #TAUTHOR_TAG by using the liwc lexica to systematically detect']","['this paper, we conduct three experiments on semantic word embeddings.', 'we first propose a new version of the word embedding association tests studied in  #TAUTHOR_TAG by using the liwc lexica to systematically detect and measure the biases within the embedding, keeping the tests comparable with the same set of target words.', 'we further extend this work using additional sets of target words, and compare sentiment across male and female names.', 'furthermore, we investigate gender bias in words that represent different occupations, comparing these associations with uk national employment statistics.', 'in the last experiment, we use orthogonal projections [ 2 ] to debias our word embeddings, and measure the reduction in the biases demonstrated in the previous two experiments']",0
['for u. s. employment statistics using an independent set of occupations found in  #TAUTHOR_TAG'],['for u. s. employment statistics using an independent set of occupations found in  #TAUTHOR_TAG'],"['. 57, p - value < 10 −6 ) between the word embedding association between gender and occupation and the number of people of each gender in the united kingdom working in those roles.', 'this supports a similar finding for u. s. employment statistics using an independent set of occupations found in  #TAUTHOR_TAG']","['the list of occupations from the previous section, we compared their association with each of the genders with the ratio of the actual number of men and women working in those roles, as recorded in the official statistics [ 15 ], where 1 indicates only men work in this role, and 0 only women.', 'we found that there is a strong, significant correlation ( ρ = 0. 57, p - value < 10 −6 ) between the word embedding association between gender and occupation and the number of people of each gender in the united kingdom working in those roles.', 'this supports a similar finding for u. s. employment statistics using an independent set of occupations found in  #TAUTHOR_TAG']",0
"['association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['can be used to remove biases once detected.', 'in this paper, we have introduced the liwc - weat, a set of objective tests extending the association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['we want ai to take a central position in society, we need to be able to detect and remove any source of possible discrimination, to ensure fairness and transparency, and ultimately trust in these learning systems.', 'principled methods to measure biases will certainly need to play a central role in this, as will an understanding of the origins of biases, and new developments in methods that can be used to remove biases once detected.', 'in this paper, we have introduced the liwc - weat, a set of objective tests extending the association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias in both the associations of gender and race, as first described in  #TAUTHOR_TAG, while additionally finding that male names have a slightly higher positive association than female names.', 'biases found in the embedding were also shown to reflect biases in the real world and the media, where we found a correlation between the number of men and women in an occupation and its association with each set of male and female names.', 'finally, using a projection algorithm [ 2 ], we were able to reduce the gender bias shown in the embeddings, resulting in a decrease in the difference between associations for all tests based upon gender.', 'further work in this direction will include removing bias in n - gram embeddings, embeddings that include multiple languages and new procedures for both generating better projections to remove a given bias, using debiased embeddings as an input to an upstream system and testing performance, and learning word embeddings which can be generated without chosen directions by construction']",0
"['association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['can be used to remove biases once detected.', 'in this paper, we have introduced the liwc - weat, a set of objective tests extending the association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['we want ai to take a central position in society, we need to be able to detect and remove any source of possible discrimination, to ensure fairness and transparency, and ultimately trust in these learning systems.', 'principled methods to measure biases will certainly need to play a central role in this, as will an understanding of the origins of biases, and new developments in methods that can be used to remove biases once detected.', 'in this paper, we have introduced the liwc - weat, a set of objective tests extending the association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias in both the associations of gender and race, as first described in  #TAUTHOR_TAG, while additionally finding that male names have a slightly higher positive association than female names.', 'biases found in the embedding were also shown to reflect biases in the real world and the media, where we found a correlation between the number of men and women in an occupation and its association with each set of male and female names.', 'finally, using a projection algorithm [ 2 ], we were able to reduce the gender bias shown in the embeddings, resulting in a decrease in the difference between associations for all tests based upon gender.', 'further work in this direction will include removing bias in n - gram embeddings, embeddings that include multiple languages and new procedures for both generating better projections to remove a given bias, using debiased embeddings as an input to an upstream system and testing performance, and learning word embeddings which can be generated without chosen directions by construction']",0
"['biases  #TAUTHOR_TAG, due to the source']","['biases  #TAUTHOR_TAG, due to the source']","['14 ].', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from']","['', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from which they are trained.', 'in effect, biases from the source data, such as in the differences in representation for men and women, that have been found in many different large - scale studies [ 5 ], [ 10 ], [ 12 ], carry through to the semantic relations in the word embeddings, which become baked into the learning systems that are built on top of them.', 'in this paper, we make three contributions towards addressing these concerns.', 'first we propose a new version of the word embedding association tests ( weats ) studied in  #TAUTHOR_TAG, designed to demonstrate and quantify bias in word embeddings, which puts them on a firm foundation by using the linguistic inquiry and word count ( liwc ) lexica [ 17 ] to systematically detect and measure embedding biases.', 'with this improved experimental setting, we find that european - american names are viewed more positively than african - american names, male names are more associated with work while female names are more associated with family, and that the academic disciplines of science and maths are more associated with male terms than the arts, which are more associated with female terms.', 'using this new methodology, we then find that there is a gender bias in the']",1
"['biases  #TAUTHOR_TAG, due to the source']","['biases  #TAUTHOR_TAG, due to the source']","['14 ].', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from']","['', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from which they are trained.', 'in effect, biases from the source data, such as in the differences in representation for men and women, that have been found in many different large - scale studies [ 5 ], [ 10 ], [ 12 ], carry through to the semantic relations in the word embeddings, which become baked into the learning systems that are built on top of them.', 'in this paper, we make three contributions towards addressing these concerns.', 'first we propose a new version of the word embedding association tests ( weats ) studied in  #TAUTHOR_TAG, designed to demonstrate and quantify bias in word embeddings, which puts them on a firm foundation by using the linguistic inquiry and word count ( liwc ) lexica [ 17 ] to systematically detect and measure embedding biases.', 'with this improved experimental setting, we find that european - american names are viewed more positively than african - american names, male names are more associated with work while female names are more associated with family, and that the academic disciplines of science and maths are more associated with male terms than the arts, which are more associated with female terms.', 'using this new methodology, we then find that there is a gender bias in the']",1
"['association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['can be used to remove biases once detected.', 'in this paper, we have introduced the liwc - weat, a set of objective tests extending the association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['we want ai to take a central position in society, we need to be able to detect and remove any source of possible discrimination, to ensure fairness and transparency, and ultimately trust in these learning systems.', 'principled methods to measure biases will certainly need to play a central role in this, as will an understanding of the origins of biases, and new developments in methods that can be used to remove biases once detected.', 'in this paper, we have introduced the liwc - weat, a set of objective tests extending the association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias in both the associations of gender and race, as first described in  #TAUTHOR_TAG, while additionally finding that male names have a slightly higher positive association than female names.', 'biases found in the embedding were also shown to reflect biases in the real world and the media, where we found a correlation between the number of men and women in an occupation and its association with each set of male and female names.', 'finally, using a projection algorithm [ 2 ], we were able to reduce the gender bias shown in the embeddings, resulting in a decrease in the difference between associations for all tests based upon gender.', 'further work in this direction will include removing bias in n - gram embeddings, embeddings that include multiple languages and new procedures for both generating better projections to remove a given bias, using debiased embeddings as an input to an upstream system and testing performance, and learning word embeddings which can be generated without chosen directions by construction']",1
"['biases  #TAUTHOR_TAG, due to the source']","['biases  #TAUTHOR_TAG, due to the source']","['14 ].', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from']","['', 'these word embeddings have been shown to contain the same biases  #TAUTHOR_TAG, due to the source data from which they are trained.', 'in effect, biases from the source data, such as in the differences in representation for men and women, that have been found in many different large - scale studies [ 5 ], [ 10 ], [ 12 ], carry through to the semantic relations in the word embeddings, which become baked into the learning systems that are built on top of them.', 'in this paper, we make three contributions towards addressing these concerns.', 'first we propose a new version of the word embedding association tests ( weats ) studied in  #TAUTHOR_TAG, designed to demonstrate and quantify bias in word embeddings, which puts them on a firm foundation by using the linguistic inquiry and word count ( liwc ) lexica [ 17 ] to systematically detect and measure embedding biases.', 'with this improved experimental setting, we find that european - american names are viewed more positively than african - american names, male names are more associated with work while female names are more associated with family, and that the academic disciplines of science and maths are more associated with male terms than the arts, which are more associated with female terms.', 'using this new methodology, we then find that there is a gender bias in the']",4
"['association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['can be used to remove biases once detected.', 'in this paper, we have introduced the liwc - weat, a set of objective tests extending the association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias']","['we want ai to take a central position in society, we need to be able to detect and remove any source of possible discrimination, to ensure fairness and transparency, and ultimately trust in these learning systems.', 'principled methods to measure biases will certainly need to play a central role in this, as will an understanding of the origins of biases, and new developments in methods that can be used to remove biases once detected.', 'in this paper, we have introduced the liwc - weat, a set of objective tests extending the association tests in  #TAUTHOR_TAG by using the liwc lexica to measure bias within word embeddings.', 'we found bias in both the associations of gender and race, as first described in  #TAUTHOR_TAG, while additionally finding that male names have a slightly higher positive association than female names.', 'biases found in the embedding were also shown to reflect biases in the real world and the media, where we found a correlation between the number of men and women in an occupation and its association with each set of male and female names.', 'finally, using a projection algorithm [ 2 ], we were able to reduce the gender bias shown in the embeddings, resulting in a decrease in the difference between associations for all tests based upon gender.', 'further work in this direction will include removing bias in n - gram embeddings, embeddings that include multiple languages and new procedures for both generating better projections to remove a given bias, using debiased embeddings as an input to an upstream system and testing performance, and learning word embeddings which can be generated without chosen directions by construction']",4
"['target european - american and african - american names used in  #TAUTHOR_TAG, we tested each of them']","['target european - american and african - american names used in  #TAUTHOR_TAG, we tested each of them']","['target european - american and african - american names used in  #TAUTHOR_TAG, we tested each of them']","['the list of target european - american and african - american names used in  #TAUTHOR_TAG, we tested each of them for their associated with the positive and negative emotion concepts found in [ 17 ] by using the methodology described by eq. 3 in sec. ii - b, replacing the short list of words used to originally represent pleasant and unpleasant attribute sets.', 'our test found that while both european - american names and african - american names are more associated with positive emotions than negative emotions, the test showed that european - american names are more associated with positive emotions than their african - american counterparts, as shown in fig. 1a.', 'this finding supports the association test in  #TAUTHOR_TAG, where they also found that european - american names were more pleasant than african - american names']",5
"['of  #TAUTHOR_TAG, with']","['of  #TAUTHOR_TAG, with maths']","['liwc [ 17 ].', 'the results of our test again support the findings of  #TAUTHOR_TAG, with']","[""further test was conducted to find the association between words related to different subject disciplines ( e. g. arts, maths, science ) with each of the genders using the'he'and'she'categories from liwc [ 17 ]."", 'the results of our test again support the findings of  #TAUTHOR_TAG, with maths and science terms being more closely associated with males, while arts terms are more closely associated with females, as shown in fig. 1b.', ""3 ) association of gender with career and family : taking the list of target gendered names used in  #TAUTHOR_TAG, we tested each of them for their associated with the career and family concepts using the categories of'work'and'family'found in liwc [ 17 ]."", 'as shown in fig. 1c, we found that the set of male names was more associated with the concept of work, while the female names were more associated with family, mirroring the results found in  #TAUTHOR_TAG.', 'extending this test, we generated a much larger set of male and female target names from an online list of baby names 1.', 'repeating the same test on this larger set of names, we found that male and female names were much less separated than suggested by previous results, with only minor differences between the two, as shown in fig. 1d']",5
"['target european - american and african - american names used in  #TAUTHOR_TAG, we tested each of them']","['target european - american and african - american names used in  #TAUTHOR_TAG, we tested each of them']","['target european - american and african - american names used in  #TAUTHOR_TAG, we tested each of them']","['the list of target european - american and african - american names used in  #TAUTHOR_TAG, we tested each of them for their associated with the positive and negative emotion concepts found in [ 17 ] by using the methodology described by eq. 3 in sec. ii - b, replacing the short list of words used to originally represent pleasant and unpleasant attribute sets.', 'our test found that while both european - american names and african - american names are more associated with positive emotions than negative emotions, the test showed that european - american names are more associated with positive emotions than their african - american counterparts, as shown in fig. 1a.', 'this finding supports the association test in  #TAUTHOR_TAG, where they also found that european - american names were more pleasant than african - american names']",3
"['of  #TAUTHOR_TAG, with']","['of  #TAUTHOR_TAG, with maths']","['liwc [ 17 ].', 'the results of our test again support the findings of  #TAUTHOR_TAG, with']","[""further test was conducted to find the association between words related to different subject disciplines ( e. g. arts, maths, science ) with each of the genders using the'he'and'she'categories from liwc [ 17 ]."", 'the results of our test again support the findings of  #TAUTHOR_TAG, with maths and science terms being more closely associated with males, while arts terms are more closely associated with females, as shown in fig. 1b.', ""3 ) association of gender with career and family : taking the list of target gendered names used in  #TAUTHOR_TAG, we tested each of them for their associated with the career and family concepts using the categories of'work'and'family'found in liwc [ 17 ]."", 'as shown in fig. 1c, we found that the set of male names was more associated with the concept of work, while the female names were more associated with family, mirroring the results found in  #TAUTHOR_TAG.', 'extending this test, we generated a much larger set of male and female target names from an online list of baby names 1.', 'repeating the same test on this larger set of names, we found that male and female names were much less separated than suggested by previous results, with only minor differences between the two, as shown in fig. 1d']",3
['for u. s. employment statistics using an independent set of occupations found in  #TAUTHOR_TAG'],['for u. s. employment statistics using an independent set of occupations found in  #TAUTHOR_TAG'],"['. 57, p - value < 10 −6 ) between the word embedding association between gender and occupation and the number of people of each gender in the united kingdom working in those roles.', 'this supports a similar finding for u. s. employment statistics using an independent set of occupations found in  #TAUTHOR_TAG']","['the list of occupations from the previous section, we compared their association with each of the genders with the ratio of the actual number of men and women working in those roles, as recorded in the official statistics [ 15 ], where 1 indicates only men work in this role, and 0 only women.', 'we found that there is a strong, significant correlation ( ρ = 0. 57, p - value < 10 −6 ) between the word embedding association between gender and occupation and the number of people of each gender in the united kingdom working in those roles.', 'this supports a similar finding for u. s. employment statistics using an independent set of occupations found in  #TAUTHOR_TAG']",3
"['3a.', 'male and females names tested in  #TAUTHOR_TAG showed a clear distinction in']","['3a.', 'male and females names tested in  #TAUTHOR_TAG showed a clear distinction in']","['. 3a.', 'male and females names tested in  #TAUTHOR_TAG showed a clear distinction in']","['', 'in experiment 1, we previously found that the disciplines of science and maths were more associated with male terms in the embedding, while the arts were closer to female terms.', 'the association of each of these subject disciplines with gender after orthogonal projection was found to be more balanced, with closer to equal association for both male and female terms, shown in fig. 3a.', 'male and females names tested in  #TAUTHOR_TAG showed a clear distinction in their association with work and family respectively, with our replication of the test in sec. iii - b3 finding the same results.', 'performing the same tests again after applying the gender projection to both name lists, we wished to quantify the change in associations.', 'we calculated the change in the distance between the centroids of each set of names before and after applying the orthogonal gender projection, finding that the association with work for males and family for females reduced, closing the gap between male and female names by 37. 5 % for the target names found in the original weat and 66 % for the extended list of names respectively.', 'in our experiment']",3
"['of  #TAUTHOR_TAG, with']","['of  #TAUTHOR_TAG, with maths']","['liwc [ 17 ].', 'the results of our test again support the findings of  #TAUTHOR_TAG, with']","[""further test was conducted to find the association between words related to different subject disciplines ( e. g. arts, maths, science ) with each of the genders using the'he'and'she'categories from liwc [ 17 ]."", 'the results of our test again support the findings of  #TAUTHOR_TAG, with maths and science terms being more closely associated with males, while arts terms are more closely associated with females, as shown in fig. 1b.', ""3 ) association of gender with career and family : taking the list of target gendered names used in  #TAUTHOR_TAG, we tested each of them for their associated with the career and family concepts using the categories of'work'and'family'found in liwc [ 17 ]."", 'as shown in fig. 1c, we found that the set of male names was more associated with the concept of work, while the female names were more associated with family, mirroring the results found in  #TAUTHOR_TAG.', 'extending this test, we generated a much larger set of male and female target names from an online list of baby names 1.', 'repeating the same test on this larger set of names, we found that male and female names were much less separated than suggested by previous results, with only minor differences between the two, as shown in fig. 1d']",7
['a ;  #TAUTHOR_TAG'],['a ;  #TAUTHOR_TAG'],"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'we identify two types of approaches for kbcentric qa systems : parsing -']",[' #TAUTHOR_TAG'],0
['a ;  #TAUTHOR_TAG'],['a ;  #TAUTHOR_TAG'],"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'we identify two types of approaches for kbcentric qa systems : parsing -']",[' #TAUTHOR_TAG'],0
['a ;  #TAUTHOR_TAG'],['a ;  #TAUTHOR_TAG'],"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'we identify two types of approaches for kbcentric qa systems : parsing -']",[' #TAUTHOR_TAG'],0
['a ;  #TAUTHOR_TAG'],['a ;  #TAUTHOR_TAG'],"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'we identify two types of approaches for kbcentric qa systems : parsing -']",[' #TAUTHOR_TAG'],0
"['', ' #TAUTHOR_TAG introduce a linguistically leaner ir -']","['', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based']","['', 'these queries are then ranked using a scoring function.', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based approach which identifies']","['', 'these queries are then ranked using a scoring function.', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based approach which identifies the kb triple most similar to the input nl question.', 'in  #TAUTHOR_TAG approach, kb triples and nl questions are represented as sums of embeddings of kb symbols and words respectively.', 'the similarity between a triple and a question is then simply the dot product of their embeddings.', 'interestingly,  #TAUTHOR_TAG system performs relatively well ( map score 0. 34 ) on the wikianswers dataset even without using the paraphrase corpus.', 'this suggests that the embedding method successfully captures the similarity between nl questions and kb queries.', 'our work continues this direction by further separating relations with entities']",0
"['', ' #TAUTHOR_TAG introduce a linguistically leaner ir -']","['', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based']","['', 'these queries are then ranked using a scoring function.', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based approach which identifies']","['', 'these queries are then ranked using a scoring function.', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based approach which identifies the kb triple most similar to the input nl question.', 'in  #TAUTHOR_TAG approach, kb triples and nl questions are represented as sums of embeddings of kb symbols and words respectively.', 'the similarity between a triple and a question is then simply the dot product of their embeddings.', 'interestingly,  #TAUTHOR_TAG system performs relatively well ( map score 0. 34 ) on the wikianswers dataset even without using the paraphrase corpus.', 'this suggests that the embedding method successfully captures the similarity between nl questions and kb queries.', 'our work continues this direction by further separating relations with entities']",0
"['', ' #TAUTHOR_TAG introduce a linguistically leaner ir -']","['', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based']","['', 'these queries are then ranked using a scoring function.', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based approach which identifies']","['', 'these queries are then ranked using a scoring function.', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based approach which identifies the kb triple most similar to the input nl question.', 'in  #TAUTHOR_TAG approach, kb triples and nl questions are represented as sums of embeddings of kb symbols and words respectively.', 'the similarity between a triple and a question is then simply the dot product of their embeddings.', 'interestingly,  #TAUTHOR_TAG system performs relatively well ( map score 0. 34 ) on the wikianswers dataset even without using the paraphrase corpus.', 'this suggests that the embedding method successfully captures the similarity between nl questions and kb queries.', 'our work continues this direction by further separating relations with entities']",0
"['share similar embeddings as measured for instance by cosine similarity.', 'the embeddings learned in  #TAUTHOR_TAG also encode context information.', 'they link the embedding of words with']","['share similar embeddings as measured for instance by cosine similarity.', 'the embeddings learned in  #TAUTHOR_TAG also encode context information.', 'they link the embedding of words with']","[' #AUTHOR_TAG such that words with similar context will naturally share similar embeddings as measured for instance by cosine similarity.', 'the embeddings learned in  #TAUTHOR_TAG also encode context information.', 'they link the embedding of words with the whole triple - answer in their scoring function.', 'by this means, the word embedding carries the information of the whole triple.', 'our model further distinguishes entities and relations.', 'noting that entities and relations may have some independence ( knowing that']","['embeddings are generally learned  #AUTHOR_TAG such that words with similar context will naturally share similar embeddings as measured for instance by cosine similarity.', 'the embeddings learned in  #TAUTHOR_TAG also encode context information.', 'they link the embedding of words with the whole triple - answer in their scoring function.', 'by this means, the word embedding carries the information of the whole triple.', 'our model further distinguishes entities and relations.', ""noting that entities and relations may have some independence ( knowing that'a man eats'doesn't help to tell'which man'), the distinction is done via orthogonality."", 'we show in the toy example that orthogonality helps to capture this independent structure of the data']",0
"['in  #TAUTHOR_TAG, given a']","['in  #TAUTHOR_TAG, given a']","['in  #TAUTHOR_TAG, given a question']","['in  #TAUTHOR_TAG, given a question to be answered, training is performed by imposing a margin - constraint between the correct answer and negative ones.', 'more precisely, note a a negative answer to the question q ( the correct answer to q being a ).', 'then for each question answer pair, the system tries to maximize the following function by performing a gradient ascent step : min (, s ( q, a ) − s ( q, a ) ) with the margin set to 0. 1.', 'in addition, the norms of columns in m and k are constrained to be inferior to 1.', 'the training is done in a stochastic way by randomly selecting a question answer pair at each step.', 'for each gradient step, the step size is calculated using adagrad  #AUTHOR_TAG.', 'the negative example is created by randomly replacing each element of ( e 1, r, e 2 ) by another one with probability 2 / 3']",0
"['', '(  #TAUTHOR_TAG ). gold standard answer triples are marked in bold. expressive power 2, so we decide to add it as a regularizer. more concrete']","['differs from', '(  #TAUTHOR_TAG ). gold standard answer triples are marked in bold. expressive power 2, so we decide to add it as a regularizer. more concrete']","['', '(  #TAUTHOR_TAG ). gold standard answer triples are marked in bold. expressive power 2, so we decide to add it as a regularizer. more concrete']","[', if relations and entities are orthogonal ( ∀r, e ( r ⊥ e ) ), then if two entities e,', 'e and two relations r, r are distinct ( i. e., | | e − e | | 2 ≥ and | | r − r', '| | 2 ≥ ), it follows that | | e + r − e − r | | 2 = | | e − e', '| | 2 + | | | r − r | | 2 ≥ 2 by pythagorean', 'theorem. that is, two sentences whose semantic representations involve two distinct entities and / or relations will have different values. in real problems, however, posi', ""##ng a hard orthogonality constraint largely reduces the model's what is the religious celebration of christians? ( christian. e be - all"", '- about. r original - sin. e ) ( easter. e be -', 'most - important - holiday. r christian. e ) what do cassava come from? ( cass', '##ava. e be - source - of. r security. e ) ( cassava. e be - grow - in. r africa. e ) table 1 : some examples for which our system differs from', '(  #TAUTHOR_TAG ). gold standard answer triples are marked in bold. expressive power 2, so we decide to add it as a regularizer. more concretely, let the correct triple be ( e 1, r, e 2 ) and the', 'negative one be ( e 1, r, e 2 ). consider that we are in a case', 'not satisfying the margin constraint, then we will try to maximize the following regularized function s ( q, a ) − s ( q, a ) − λ | e. r | with a gradient step. the regularizer | e. r | = | e 1. r | + | e 2. r | + | e 1. r | + | e 2. r | is minimized when all the entities and relations live in orthogonal space. the regularization parameter λ is chosen via an automatically constructed development set for which we', 'randomly selected 1 / 2000 of all the triples in the kb and generate associated questions. we discard these triples', 'from training and choose the λ value based on the score on the development set. the λ value is by this means set to 0. 01 with λ in { 0. 5, 0. 1, 0. 05, 0. 01, 0. 005, 0. 001 }. once the λ value is chosen', ', we retrain the whole system']",0
['a ;  #TAUTHOR_TAG'],['a ;  #TAUTHOR_TAG'],"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'we identify two types of approaches for kbcentric qa systems : parsing -']",[' #TAUTHOR_TAG'],5
['a ;  #TAUTHOR_TAG'],['a ;  #TAUTHOR_TAG'],"[' #AUTHOR_TAG a ;  #TAUTHOR_TAG.', 'we identify two types of approaches for kbcentric qa systems : parsing -']",[' #TAUTHOR_TAG'],5
"['and the embedding of the triple.', 'the model is introduced in  #TAUTHOR_TAG and we use the same scoring function.', 'note that the model actually sums up each word embedding to form the embedding of the sentence']","['and the embedding of the triple.', 'the model is introduced in  #TAUTHOR_TAG and we use the same scoring function.', 'note that the model actually sums up each word embedding to form the embedding of the sentence']","['k ψ ( a ).', 'we can score the matching of these embeddings :', 'which is the dot product between the embedding of the sentence and the embedding of the triple.', 'the model is introduced in  #TAUTHOR_TAG and we use the same scoring function.', 'note that the model actually sums up each word embedding to form the embedding of the sentence']","['model learns the embedding of each word and kb element by trying to score the correct answers highest.', 'mathematically, let q be the query, and a be the answer - triple to align.', 'denote the total number of words as n w and the number of kb elements as n kb.', 'then denote by φ ( q )', '∈ { 0, 1 } nw algorithm 1 training with orthogonality regularizer 1.', 'sample a positive training pair ( q i, a i ) from d. 2.', 'create a corrupted triple a i 3.', 'if s ( q i, a i ) − s ( q i, a i ) < 0. 1 : make a stochastic gradient ascent on s ( q i, a i ) − s ( q i, a i ) − λ | e. r | 4. normalize the embedding vector the 1 - hot representation indicating the presence or absence of words in the query.', 'similarly we denote the sparse representation on the kb side as ψ ( a ).', 'let m ∈ r d×nw be the embedding matrix for words and k ∈ r d×n kb be the embedding matrix for the elements in the kb.', 'd is the low dimension chosen by the user.', 'the embedding of the sentence is then calculated as m φ ( q ) and similarly the embedding of the answer - triple as k ψ ( a ).', 'we can score the matching of these embeddings :', 'which is the dot product between the embedding of the sentence and the embedding of the triple.', 'the model is introduced in  #TAUTHOR_TAG and we use the same scoring function.', 'note that the model actually sums up each word embedding to form the embedding of the sentence']",5
"['with another one.', 'we embed all the words and kb symbols in a space of 20 dimensions.', 'we compare the model  #TAUTHOR_TAG with the model where we enforce e and r (']","['with another one.', 'we embed all the words and kb symbols in a space of 20 dimensions.', 'we compare the model  #TAUTHOR_TAG with the model where we enforce e and r ( and also "" e "" and "" r "" ) to be orthogonal.', 'this means that words or kb symbols in fact live in an embedding space of']","['with another one.', 'we embed all the words and kb symbols in a space of 20 dimensions.', 'we compare the model  #TAUTHOR_TAG with the model where we enforce e and r (']","['', 'we separate these 2500 pairs into training ( 2450 ) and test ( 50 ).', 'notice that similarly to wikianswers, this toy dataset involves kb entities and relations whose type is known a priori.', 'the training corpus is built using one simple generation rule : ( e i, r j ) → "" e i r j "".', 'negative examples are created by replacing with probability 1 / 2 both entity and relation with another one.', 'we embed all the words and kb symbols in a space of 20 dimensions.', 'we compare the model  #TAUTHOR_TAG with the model where we enforce e and r ( and also "" e "" and "" r "" ) to be orthogonal.', 'this means that words or kb symbols in fact live in an embedding space of dimension 10.', 'at test time, for a given sentence "" e i r j "", a set of ( e, r ) pairs is ranked and we compute the proportion of cases where the first ranked pair is correct.', 'table 2 shows the results for both systems on two configurations : a configuration ( accuracy ( 1 ) ) where the number of pairs to be ranked is 1250 and another ( accuracy ( 2 ) ) with 2500 pairs.', '3 in both cases, imposing the orthogonality constraint improves performance by a large margin']",5
"['setting used in  #TAUTHOR_TAG.', 'table 3 compares different systems in this setting.', ""the embedding scores are taken from  #TAUTHOR_TAG's method."", 'in addition, table 1 shows some examples where']","['setting used in  #TAUTHOR_TAG.', 'table 3 compares different systems in this setting.', ""the embedding scores are taken from  #TAUTHOR_TAG's method."", 'in addition, table 1 shows some examples where']","['used in  #TAUTHOR_TAG.', 'table 3 compares different systems in this setting.', ""the embedding scores are taken from  #TAUTHOR_TAG's method."", 'in addition, table 1 shows some examples where the two systems differ and']","[""##ianswers contains a set of possible triples for each question and we re - rank these triples to report our system's performance."", 'this is the "" reranking "" setting used in  #TAUTHOR_TAG.', 'table 3 compares different systems in this setting.', ""the embedding scores are taken from  #TAUTHOR_TAG's method."", 'in addition, table 1 shows some examples where the two systems differ and where the orthogonality regularized embeddings seem to better support the identification of similar relations.', 'for instance, "" is the argument on "" is mapped to support. r rather than be - type - of. r and "" is the religious celebration of "" to be - mostimportant - holiday. r rather then be - all - about. r']",5
"['setting used in  #TAUTHOR_TAG.', 'table 3 compares different systems in this setting.', ""the embedding scores are taken from  #TAUTHOR_TAG's method."", 'in addition, table 1 shows some examples where']","['setting used in  #TAUTHOR_TAG.', 'table 3 compares different systems in this setting.', ""the embedding scores are taken from  #TAUTHOR_TAG's method."", 'in addition, table 1 shows some examples where']","['used in  #TAUTHOR_TAG.', 'table 3 compares different systems in this setting.', ""the embedding scores are taken from  #TAUTHOR_TAG's method."", 'in addition, table 1 shows some examples where the two systems differ and']","[""##ianswers contains a set of possible triples for each question and we re - rank these triples to report our system's performance."", 'this is the "" reranking "" setting used in  #TAUTHOR_TAG.', 'table 3 compares different systems in this setting.', ""the embedding scores are taken from  #TAUTHOR_TAG's method."", 'in addition, table 1 shows some examples where the two systems differ and where the orthogonality regularized embeddings seem to better support the identification of similar relations.', 'for instance, "" is the argument on "" is mapped to support. r rather than be - type - of. r and "" is the religious celebration of "" to be - mostimportant - holiday. r rather then be - all - about. r']",5
"['', ' #TAUTHOR_TAG introduce a linguistically leaner ir -']","['', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based']","['', 'these queries are then ranked using a scoring function.', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based approach which identifies']","['', 'these queries are then ranked using a scoring function.', ' #TAUTHOR_TAG introduce a linguistically leaner ir - based approach which identifies the kb triple most similar to the input nl question.', 'in  #TAUTHOR_TAG approach, kb triples and nl questions are represented as sums of embeddings of kb symbols and words respectively.', 'the similarity between a triple and a question is then simply the dot product of their embeddings.', 'interestingly,  #TAUTHOR_TAG system performs relatively well ( map score 0. 34 ) on the wikianswers dataset even without using the paraphrase corpus.', 'this suggests that the embedding method successfully captures the similarity between nl questions and kb queries.', 'our work continues this direction by further separating relations with entities']",6
"['', '(  #TAUTHOR_TAG ). gold standard answer triples are marked in bold. expressive power 2, so we decide to add it as a regularizer. more concrete']","['differs from', '(  #TAUTHOR_TAG ). gold standard answer triples are marked in bold. expressive power 2, so we decide to add it as a regularizer. more concrete']","['', '(  #TAUTHOR_TAG ). gold standard answer triples are marked in bold. expressive power 2, so we decide to add it as a regularizer. more concrete']","[', if relations and entities are orthogonal ( ∀r, e ( r ⊥ e ) ), then if two entities e,', 'e and two relations r, r are distinct ( i. e., | | e − e | | 2 ≥ and | | r − r', '| | 2 ≥ ), it follows that | | e + r − e − r | | 2 = | | e − e', '| | 2 + | | | r − r | | 2 ≥ 2 by pythagorean', 'theorem. that is, two sentences whose semantic representations involve two distinct entities and / or relations will have different values. in real problems, however, posi', ""##ng a hard orthogonality constraint largely reduces the model's what is the religious celebration of christians? ( christian. e be - all"", '- about. r original - sin. e ) ( easter. e be -', 'most - important - holiday. r christian. e ) what do cassava come from? ( cass', '##ava. e be - source - of. r security. e ) ( cassava. e be - grow - in. r africa. e ) table 1 : some examples for which our system differs from', '(  #TAUTHOR_TAG ). gold standard answer triples are marked in bold. expressive power 2, so we decide to add it as a regularizer. more concretely, let the correct triple be ( e 1, r, e 2 ) and the', 'negative one be ( e 1, r, e 2 ). consider that we are in a case', 'not satisfying the margin constraint, then we will try to maximize the following regularized function s ( q, a ) − s ( q, a ) − λ | e. r | with a gradient step. the regularizer | e. r | = | e 1. r | + | e 2. r | + | e 1. r | + | e 2. r | is minimized when all the entities and relations live in orthogonal space. the regularization parameter λ is chosen via an automatically constructed development set for which we', 'randomly selected 1 / 2000 of all the triples in the kb and generate associated questions. we discard these triples', 'from training and choose the λ value based on the score on the development set. the λ value is by this means set to 0. 01 with λ in { 0. 5, 0. 1, 0. 05, 0. 01, 0. 005, 0. 001 }. once the λ value is chosen', ', we retrain the whole system']",4
['semantic concepts in human vocabulary  #TAUTHOR_TAG'],['semantic concepts in human vocabulary  #TAUTHOR_TAG'],"['semantic concepts in human vocabulary  #TAUTHOR_TAG.', 'as such, there has been']","['representations of multimodal embeddings  #AUTHOR_TAG are receiving increasing attention recently in the machine learning literature, and techniques developed have found a wide spectrum of applications in the real world.', 'these types of vector representations are particularly desirable for the way in which they better model the grounding of perceptual or semantic concepts in human vocabulary  #TAUTHOR_TAG.', 'as such, there has been development towards so - called multimodal distributional semantic models  #TAUTHOR_TAG, which leverage textual co - occurance and visual features to form multimodal representations of words or concepts.', 'the work introduced in  #TAUTHOR_TAG sought to address many of the drawbacks of these models.', 'in particular, by incorporating visual information into the training objective, they address the biological inaccuracy of the existing models, in that word representations grounded in visual information have been shown to more closely approximate the way humans learn language.', 'furthermore, incorporating visual information alongside the text corpus allows the training set to consist of both visual and non - visual words.', 'as a result, the induced multimodal representations and multimodal mapping no longer rely on the assumption of full visual coverage of the vocabulary, so the results are able to generalize beyond the initial training set and to be applied to various representation - related tasks, such as image annotation or retrieval.', 'in this work, we introduce a further refinement on the multimodal skip - gram architecture, building upon the approaches of  #AUTHOR_TAG a ; b ),, and  #TAUTHOR_TAG.', 'rather than adding a visual term to the linguistic training objective, we directly situate terms in a visual context by replacing relevant words with multimodal pseudowords, derived by composing the textual representations with convolutional features projected into the multimodal space.', 'in this way, we further address the grounding problem of  #AUTHOR_TAG by incorpo - rating the word - level visual modality directly into the sentence context.', 'this model represents an advancement of the existing literature surrounding multimodal skip - gram, as well as multimodal distributional semantic models in general, by greatly simplifying the method of situating the words in the visual context and reducing the number of hyperparameters to tune by directly incorporating multimodal words into the existing objective function and hiearchical softmax formulations of the skip - gram models.', 'finally, we would also like the learned embeddings to be applicable to the problem of zero - shot learning  #AUTHOR_TAG.', 'by incorporating perceptual information into the skip - gram learning objective, we can leverage vocabulary terms for which no manually - annotated images were originally available.', 'in this way, these learned representations can be used to both grow the annotation set and retrieve new annotations for a given image set']",0
['semantic concepts in human vocabulary  #TAUTHOR_TAG'],['semantic concepts in human vocabulary  #TAUTHOR_TAG'],"['semantic concepts in human vocabulary  #TAUTHOR_TAG.', 'as such, there has been']","['representations of multimodal embeddings  #AUTHOR_TAG are receiving increasing attention recently in the machine learning literature, and techniques developed have found a wide spectrum of applications in the real world.', 'these types of vector representations are particularly desirable for the way in which they better model the grounding of perceptual or semantic concepts in human vocabulary  #TAUTHOR_TAG.', 'as such, there has been development towards so - called multimodal distributional semantic models  #TAUTHOR_TAG, which leverage textual co - occurance and visual features to form multimodal representations of words or concepts.', 'the work introduced in  #TAUTHOR_TAG sought to address many of the drawbacks of these models.', 'in particular, by incorporating visual information into the training objective, they address the biological inaccuracy of the existing models, in that word representations grounded in visual information have been shown to more closely approximate the way humans learn language.', 'furthermore, incorporating visual information alongside the text corpus allows the training set to consist of both visual and non - visual words.', 'as a result, the induced multimodal representations and multimodal mapping no longer rely on the assumption of full visual coverage of the vocabulary, so the results are able to generalize beyond the initial training set and to be applied to various representation - related tasks, such as image annotation or retrieval.', 'in this work, we introduce a further refinement on the multimodal skip - gram architecture, building upon the approaches of  #AUTHOR_TAG a ; b ),, and  #TAUTHOR_TAG.', 'rather than adding a visual term to the linguistic training objective, we directly situate terms in a visual context by replacing relevant words with multimodal pseudowords, derived by composing the textual representations with convolutional features projected into the multimodal space.', 'in this way, we further address the grounding problem of  #AUTHOR_TAG by incorpo - rating the word - level visual modality directly into the sentence context.', 'this model represents an advancement of the existing literature surrounding multimodal skip - gram, as well as multimodal distributional semantic models in general, by greatly simplifying the method of situating the words in the visual context and reducing the number of hyperparameters to tune by directly incorporating multimodal words into the existing objective function and hiearchical softmax formulations of the skip - gram models.', 'finally, we would also like the learned embeddings to be applicable to the problem of zero - shot learning  #AUTHOR_TAG.', 'by incorporating perceptual information into the skip - gram learning objective, we can leverage vocabulary terms for which no manually - annotated images were originally available.', 'in this way, these learned representations can be used to both grow the annotation set and retrieve new annotations for a given image set']",0
['semantic concepts in human vocabulary  #TAUTHOR_TAG'],['semantic concepts in human vocabulary  #TAUTHOR_TAG'],"['semantic concepts in human vocabulary  #TAUTHOR_TAG.', 'as such, there has been']","['representations of multimodal embeddings  #AUTHOR_TAG are receiving increasing attention recently in the machine learning literature, and techniques developed have found a wide spectrum of applications in the real world.', 'these types of vector representations are particularly desirable for the way in which they better model the grounding of perceptual or semantic concepts in human vocabulary  #TAUTHOR_TAG.', 'as such, there has been development towards so - called multimodal distributional semantic models  #TAUTHOR_TAG, which leverage textual co - occurance and visual features to form multimodal representations of words or concepts.', 'the work introduced in  #TAUTHOR_TAG sought to address many of the drawbacks of these models.', 'in particular, by incorporating visual information into the training objective, they address the biological inaccuracy of the existing models, in that word representations grounded in visual information have been shown to more closely approximate the way humans learn language.', 'furthermore, incorporating visual information alongside the text corpus allows the training set to consist of both visual and non - visual words.', 'as a result, the induced multimodal representations and multimodal mapping no longer rely on the assumption of full visual coverage of the vocabulary, so the results are able to generalize beyond the initial training set and to be applied to various representation - related tasks, such as image annotation or retrieval.', 'in this work, we introduce a further refinement on the multimodal skip - gram architecture, building upon the approaches of  #AUTHOR_TAG a ; b ),, and  #TAUTHOR_TAG.', 'rather than adding a visual term to the linguistic training objective, we directly situate terms in a visual context by replacing relevant words with multimodal pseudowords, derived by composing the textual representations with convolutional features projected into the multimodal space.', 'in this way, we further address the grounding problem of  #AUTHOR_TAG by incorpo - rating the word - level visual modality directly into the sentence context.', 'this model represents an advancement of the existing literature surrounding multimodal skip - gram, as well as multimodal distributional semantic models in general, by greatly simplifying the method of situating the words in the visual context and reducing the number of hyperparameters to tune by directly incorporating multimodal words into the existing objective function and hiearchical softmax formulations of the skip - gram models.', 'finally, we would also like the learned embeddings to be applicable to the problem of zero - shot learning  #AUTHOR_TAG.', 'by incorporating perceptual information into the skip - gram learning objective, we can leverage vocabulary terms for which no manually - annotated images were originally available.', 'in this way, these learned representations can be used to both grow the annotation set and retrieve new annotations for a given image set']",0
"['on multimodal representational models.', 'as explained in  #TAUTHOR_TAG, the majority of this']","['on multimodal representational models.', 'as explained in  #TAUTHOR_TAG, the majority of this']","['on multimodal representational models.', 'as explained in  #TAUTHOR_TAG, the majority of this literature focuses on constructing textual and visual representations independently and then combining']","['the last few years, there has been a wealth of literature on multimodal representational models.', 'as explained in  #TAUTHOR_TAG, the majority of this literature focuses on constructing textual and visual representations independently and then combining them under some metrics.', ' #AUTHOR_TAG utilize a direct approach to "" mixing "" the vector representations by concatenating the text and image vectors and applying singular value decomposition.', 'the image vectors used here, though, are constructed using the bag - of - visual - words method.', ' #AUTHOR_TAG, the authors utilize a more sophisticated approach to the concatenation method by extracting visual features using state - of - the - art convolutional neural networks and the skip - gram architecture for the text.', ' #AUTHOR_TAG also utilizes the skip - gram architecture and convolutional features ; however the two modalities are then combined using a natural similarity metric.', 'other recent work has presented several methods for directly incorporating visual context in neural language models.', ' #AUTHOR_TAG, word context is enhanced by global visual context ; i. e., a single image is used as the context for the whole sentence ( conversely, the sentence acts as a caption for the image ).', 'the multimodal skip - gram architecture proposed by  #TAUTHOR_TAG takes a more fine - grained approach by incorporating word - level visual context and concurrently training words to predict other text words in the window as well as their visual representation.', 'our model makes this approach even more explicit, by training the word vectors to predict an additive composition of the textual and visual context and thus constructing an implicit mapping between the textual and visual modalities.', 'finally, the work introduced in  #AUTHOR_TAG employs a similar "" pseudoword "" architecture to that proposed here.', 'however, the visual features used are in the form of perceptual information derived from either user - generated attributes or other textual annotations of imagery.', 'while this is shown to be useful for distinguishing classes of words ( e. g., between abstract and concrete ), it precludes any incorporation of visual, non - linguistic context and thus the derivation of any mapping between images and words or applications to representation - related tasks']",0
"['on multimodal representational models.', 'as explained in  #TAUTHOR_TAG, the majority of this']","['on multimodal representational models.', 'as explained in  #TAUTHOR_TAG, the majority of this']","['on multimodal representational models.', 'as explained in  #TAUTHOR_TAG, the majority of this literature focuses on constructing textual and visual representations independently and then combining']","['the last few years, there has been a wealth of literature on multimodal representational models.', 'as explained in  #TAUTHOR_TAG, the majority of this literature focuses on constructing textual and visual representations independently and then combining them under some metrics.', ' #AUTHOR_TAG utilize a direct approach to "" mixing "" the vector representations by concatenating the text and image vectors and applying singular value decomposition.', 'the image vectors used here, though, are constructed using the bag - of - visual - words method.', ' #AUTHOR_TAG, the authors utilize a more sophisticated approach to the concatenation method by extracting visual features using state - of - the - art convolutional neural networks and the skip - gram architecture for the text.', ' #AUTHOR_TAG also utilizes the skip - gram architecture and convolutional features ; however the two modalities are then combined using a natural similarity metric.', 'other recent work has presented several methods for directly incorporating visual context in neural language models.', ' #AUTHOR_TAG, word context is enhanced by global visual context ; i. e., a single image is used as the context for the whole sentence ( conversely, the sentence acts as a caption for the image ).', 'the multimodal skip - gram architecture proposed by  #TAUTHOR_TAG takes a more fine - grained approach by incorporating word - level visual context and concurrently training words to predict other text words in the window as well as their visual representation.', 'our model makes this approach even more explicit, by training the word vectors to predict an additive composition of the textual and visual context and thus constructing an implicit mapping between the textual and visual modalities.', 'finally, the work introduced in  #AUTHOR_TAG employs a similar "" pseudoword "" architecture to that proposed here.', 'however, the visual features used are in the form of perceptual information derived from either user - generated attributes or other textual annotations of imagery.', 'while this is shown to be useful for distinguishing classes of words ( e. g., between abstract and concrete ), it precludes any incorporation of visual, non - linguistic context and thus the derivation of any mapping between images and words or applications to representation - related tasks']",0
['semantic concepts in human vocabulary  #TAUTHOR_TAG'],['semantic concepts in human vocabulary  #TAUTHOR_TAG'],"['semantic concepts in human vocabulary  #TAUTHOR_TAG.', 'as such, there has been']","['representations of multimodal embeddings  #AUTHOR_TAG are receiving increasing attention recently in the machine learning literature, and techniques developed have found a wide spectrum of applications in the real world.', 'these types of vector representations are particularly desirable for the way in which they better model the grounding of perceptual or semantic concepts in human vocabulary  #TAUTHOR_TAG.', 'as such, there has been development towards so - called multimodal distributional semantic models  #TAUTHOR_TAG, which leverage textual co - occurance and visual features to form multimodal representations of words or concepts.', 'the work introduced in  #TAUTHOR_TAG sought to address many of the drawbacks of these models.', 'in particular, by incorporating visual information into the training objective, they address the biological inaccuracy of the existing models, in that word representations grounded in visual information have been shown to more closely approximate the way humans learn language.', 'furthermore, incorporating visual information alongside the text corpus allows the training set to consist of both visual and non - visual words.', 'as a result, the induced multimodal representations and multimodal mapping no longer rely on the assumption of full visual coverage of the vocabulary, so the results are able to generalize beyond the initial training set and to be applied to various representation - related tasks, such as image annotation or retrieval.', 'in this work, we introduce a further refinement on the multimodal skip - gram architecture, building upon the approaches of  #AUTHOR_TAG a ; b ),, and  #TAUTHOR_TAG.', 'rather than adding a visual term to the linguistic training objective, we directly situate terms in a visual context by replacing relevant words with multimodal pseudowords, derived by composing the textual representations with convolutional features projected into the multimodal space.', 'in this way, we further address the grounding problem of  #AUTHOR_TAG by incorpo - rating the word - level visual modality directly into the sentence context.', 'this model represents an advancement of the existing literature surrounding multimodal skip - gram, as well as multimodal distributional semantic models in general, by greatly simplifying the method of situating the words in the visual context and reducing the number of hyperparameters to tune by directly incorporating multimodal words into the existing objective function and hiearchical softmax formulations of the skip - gram models.', 'finally, we would also like the learned embeddings to be applicable to the problem of zero - shot learning  #AUTHOR_TAG.', 'by incorporating perceptual information into the skip - gram learning objective, we can leverage vocabulary terms for which no manually - annotated images were originally available.', 'in this way, these learned representations can be used to both grow the annotation set and retrieve new annotations for a given image set']",6
"['used by  #TAUTHOR_TAG.', 'in']","['used by  #TAUTHOR_TAG.', 'in']","['used by  #TAUTHOR_TAG.', 'in']","['our text corpus, keeping with the existing literature, we use a preprocessed dump of wikipedia 3 containing approximately 800m tokens.', 'for the visual data, we use the image data from ilsvrc 2012  #AUTHOR_TAG and the corresponding wordnet hierarchy  #AUTHOR_TAG to represent a word visually if the word or any of its hyponyms has an entry in imagenet and occurs more than 500 times in the text corpus.', 'this yields approximately 5, 100 "" visual "" words.', 'to construct the vectors for the visual representations, we follow a similar experimental set - up as that used by  #TAUTHOR_TAG.', 'in each of the cases described above - centroid and hypersphere -, we randomly sample 100 images from the corresponding synsets of imagenet for each visual word and use a pre - trained convolutional neural network as described in  #AUTHOR_TAG via the caffe toolkit  #AUTHOR_TAG to extract a 4096 - dimensional vector representation of each image.', 'we then treat the 100 vectors corresponding to each of the 5, 100 visual words as clusters in the 4096 - dimensional visual space']",3
"['used by  #TAUTHOR_TAG.', 'in']","['used by  #TAUTHOR_TAG.', 'in']","['used by  #TAUTHOR_TAG.', 'in']","['our text corpus, keeping with the existing literature, we use a preprocessed dump of wikipedia 3 containing approximately 800m tokens.', 'for the visual data, we use the image data from ilsvrc 2012  #AUTHOR_TAG and the corresponding wordnet hierarchy  #AUTHOR_TAG to represent a word visually if the word or any of its hyponyms has an entry in imagenet and occurs more than 500 times in the text corpus.', 'this yields approximately 5, 100 "" visual "" words.', 'to construct the vectors for the visual representations, we follow a similar experimental set - up as that used by  #TAUTHOR_TAG.', 'in each of the cases described above - centroid and hypersphere -, we randomly sample 100 images from the corresponding synsets of imagenet for each visual word and use a pre - trained convolutional neural network as described in  #AUTHOR_TAG via the caffe toolkit  #AUTHOR_TAG to extract a 4096 - dimensional vector representation of each image.', 'we then treat the 100 vectors corresponding to each of the 5, 100 visual words as clusters in the 4096 - dimensional visual space']",5
"['other multimodal word embeddings.', 'using the results published by  #TAUTHOR_TAG and a target word embedding of 300, we compare our results']","['other multimodal word embeddings.', 'using the results published by  #TAUTHOR_TAG and a target word embedding of 300, we compare our results']","['other multimodal word embeddings.', 'using the results published by  #TAUTHOR_TAG and a target word embedding of 300, we compare our results']","['similarity benchmarks to compare our technique to the existing literature, we evaluate our embeddings on four common benchmarks which capture several diverse aspects of word meaning : men, simlex - 999, semsim  #AUTHOR_TAG, vissim  #AUTHOR_TAG.', 'men was designed to capture general word "" relatedness.', '"" simlex - 999 and semsim measure notions of semantic similarity, and vissim ranks the same words as semsim but in terms of visual similarity.', 'in each case, the designers of the benchmarks provided pairs of words to human judges, who in turned provide ratings based on the metric of the benchmark.', ""to judge our model, we calculate the cosine similarity of our embeddings for the word pairs and then calculate spearman's ρ between our list of ratings and those of the human judges."", 'we evaluate three versions of our model on these benchmarks : pseudowords using the centroid method ( psuedowords - c ), pseudowords using the hypersphere method ( pseudowords - h ), and the centroid method with a randomly initialized mapping ( pseudowords - ran ), as explained below.', 'existing multimodal models we compare our results on these benchmarks against previously published results for other multimodal word embeddings.', 'using the results published by  #TAUTHOR_TAG and a target word embedding of 300, we compare our results to their mmskip - gram - a and mmskip - gram - b, which maximize the similarity of the textual and visual representations table 1 : spearman correlation between the generated multimodal similarities and the benchmark human judgments.', 'in all cases, results are reported on the full set of word similarity pairs.', 'under a max - margin framework. ; the former constrains the dimensionality of the visual features to be the same as the word embeddings, while the latter learns an explicit mapping between the textual and visual spaces.', 'we also include baseline results for pure - text skip - gram embeddings ( skip - gram ) )']",5
"['multimodal model of  #TAUTHOR_TAG performs better.', 'however, in the']","['multimodal model of  #TAUTHOR_TAG performs better.', 'however, in the']","['of capturing general relatedness and pure visual similarity, the multimodal model of  #TAUTHOR_TAG performs better.', 'however, in the case']","['the other hand, when the mapping is quickly pretrained on existing distributed word representations, the results are greatly improved.', 'in the cases of capturing general relatedness and pure visual similarity, the multimodal model of  #TAUTHOR_TAG performs better.', 'however, in the case of capturing semantic word similarity, our model performs signficantly better than mmskip - gram - b ( although it should be noted that these results are roughly on par with the benchmark authors  #AUTHOR_TAG and a point below the non - mapping mmskip - gram - a ).', 'although further work is needed to examine this result, the performance of the model in this case can be visualized through an example.', 'table 2 provides some insights on the changes made to the word embeddings as a result of the inclusion of visual information in the learning process.', 'in the two visual instances, our model captures many of the same nuances as mmskip - gram - b over the skip - gram model : donuts are more similar to other types of food than to places where you find donuts and owls are more similar to other birds of prey than just woodland creatures.', 'however, our model seems to capture more of the semantic idea of donuts as "" junk food "" rather than just the visual similarity of roundness ( the link established between donut and cupcake is particularly interesting ).', 'as for owl, some of the visual similarity is lost, by ranking sparrow first, with regards to the class of birds of prey, but there seems to be a recognition of the semantic relationship between the top similar words ( "" sparrow hawk "" is a synonym for "" kestrel "" in wordnet, for example ) as well as visual similarity via brown feathers and beaks.', 'as for the representations learned without explicit visual information, our model still seems to demonstrate the propagation of this information but in a different manner than mmskip - gram - table 2 : top 3 neighbors of the target words, ordered by similarity.', 'the training data contained visual information only for donut and owl b. the words ranked as similar to mural lose the artistic concepts of painting and portrait ranked highly by the other models ; instead our model ranks "" fresco "" and "" bas - relief "" alongside sculpture, capturing instead a more complex representation of "" artwork executed directly on a wall. "" for tobacco, our model dismisses the recreational uses of tobacco captured via "" cigar "" and "" cigarette, "" while also ignoring the naive "" crop "" sense']",4
"['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['', 'the lsa corpus. the present study shows, however, that the presence of the test materials in the ls', '##a corpus has an important effect, but also that the generic semantic knowledge derived from large corpora clearly improves the segmentation accuracy. this conclusion is drawn from two experiments in which the presence or absence of the test materials in the lsa', 'corpus is manipulated. the first experiment is based on the original materials from choi et al., which consisted of a small corpus ( 1, 000, 000', 'words ). the second experiment is based on a much larger corpus ( 25', ', 000, 000 words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']",0
"['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['', 'the lsa corpus. the present study shows, however, that the presence of the test materials in the ls', '##a corpus has an important effect, but also that the generic semantic knowledge derived from large corpora clearly improves the segmentation accuracy. this conclusion is drawn from two experiments in which the presence or absence of the test materials in the lsa', 'corpus is manipulated. the first experiment is based on the original materials from choi et al., which consisted of a small corpus ( 1, 000, 000', 'words ). the second experiment is based on a much larger corpus ( 25', ', 000, 000 words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']",0
['by  #TAUTHOR_TAG is'],['by  #TAUTHOR_TAG is'],['by  #TAUTHOR_TAG is made up of the three steps usually'],"['segmentation algorithm proposed by  #TAUTHOR_TAG is made up of the three steps usually found in any segmentation procedure based on lexical cohesion.', 'firstly, the document to be segmented is divided into minimal textual units, usually sentences.', 'then, a similarity index between every pair of adjacent units is calculated.', 'each raw similarity value is cast on an ordinal scale by taking the proportion of neighboring values that are smaller than it.', 'lastly, the document is segmented recursively according to the boundaries between the units that maximize the sum of the average similarities inside the segments thus comprised ( divisive clustering ).', '']",0
['by  #TAUTHOR_TAG is'],['by  #TAUTHOR_TAG is'],['by  #TAUTHOR_TAG is made up of the three steps usually'],"['segmentation algorithm proposed by  #TAUTHOR_TAG is made up of the three steps usually found in any segmentation procedure based on lexical cohesion.', 'firstly, the document to be segmented is divided into minimal textual units, usually sentences.', 'then, a similarity index between every pair of adjacent units is calculated.', 'each raw similarity value is cast on an ordinal scale by taking the proportion of neighboring values that are smaller than it.', 'lastly, the document is segmented recursively according to the boundaries between the units that maximize the sum of the average similarities inside the segments thus comprised ( divisive clustering ).', '']",0
['by  #TAUTHOR_TAG is'],['by  #TAUTHOR_TAG is'],['by  #TAUTHOR_TAG is made up of the three steps usually'],"['segmentation algorithm proposed by  #TAUTHOR_TAG is made up of the three steps usually found in any segmentation procedure based on lexical cohesion.', 'firstly, the document to be segmented is divided into minimal textual units, usually sentences.', 'then, a similarity index between every pair of adjacent units is calculated.', 'each raw similarity value is cast on an ordinal scale by taking the proportion of neighboring values that are smaller than it.', 'lastly, the document is segmented recursively according to the boundaries between the units that maximize the sum of the average similarities inside the segments thus comprised ( divisive clustering ).', '']",0
"['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']","['', 'the lsa corpus. the present study shows, however, that the presence of the test materials in the ls', '##a corpus has an important effect, but also that the generic semantic knowledge derived from large corpora clearly improves the segmentation accuracy. this conclusion is drawn from two experiments in which the presence or absence of the test materials in the lsa', 'corpus is manipulated. the first experiment is based on the original materials from choi et al., which consisted of a small corpus ( 1, 000, 000', 'words ). the second experiment is based on a much larger corpus ( 25', ', 000, 000 words ). before reporting these experiments,  #TAUTHOR_TAG and the use of lsa within this framework are described']",4
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['experiment was based on the procedure and test materials designed by  #TAUTHOR_TAG, which was also used by several authors as a benchmark for comparing segmentation systems ( brants et al. 2002 ; ferret 2002 ; kehagias et al. 2003 ; utiyama and isahara 2001 ).', 'the task consists in finding the boundaries between concatenated texts.', 'each test sample is a concatenation of ten text segments.', 'each segment consisted in the first n sentences of a randomly selected text from two sub - sections of the brown corpus.', 'for the present experiment, i used the most general test materials built by  #TAUTHOR_TAG, in which the size of the segments within each sample varies randomly from 3 to 11 sentences.', 'it is composed of 400 samples.', 'the analysis related to the comparison between the accuracy of the algorithm when the test materials were included in the lsa corpus ( within ) and when it was not ( without ).', 'one within semantic space, which corresponds to the one used by choi et al., was built using the entire brown corpus as the lsa corpus.', 'four hundred different without spaces were built, one for each test sample, by each time removing from the brown corpus only the sentences that make this sample.', 'to extract the lsa space and to apply the segmentation algorithm, a series of parameters had to be set.', 'first of all, paragraphs were used as documents for building the lexical tables because choi et al. observed that such middle - sized units were more effective than shorter units ( i. e., sentences ).', ""the words on choi's stoplist were removed, as were those that appeared only once in the whole corpus."", 'words were not stemmed, as in  #AUTHOR_TAG.', 'to build the lsa space, the singular value decomposition was realized using the program svdpackc ( berry 1992 ; berry et al. 1993 ), and the first 300 singular vectors were retained.', 'concerning the segmentation algorithm, i used the version in which the number of boundaries to be found is imposed, and thus fixed at nine.', 'an 11 × 11 rank mask was used for the ordinal transformation, as recommended by  #TAUTHOR_TAG']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['experiment was based on the procedure and test materials designed by  #TAUTHOR_TAG, which was also used by several authors as a benchmark for comparing segmentation systems ( brants et al. 2002 ; ferret 2002 ; kehagias et al. 2003 ; utiyama and isahara 2001 ).', 'the task consists in finding the boundaries between concatenated texts.', 'each test sample is a concatenation of ten text segments.', 'each segment consisted in the first n sentences of a randomly selected text from two sub - sections of the brown corpus.', 'for the present experiment, i used the most general test materials built by  #TAUTHOR_TAG, in which the size of the segments within each sample varies randomly from 3 to 11 sentences.', 'it is composed of 400 samples.', 'the analysis related to the comparison between the accuracy of the algorithm when the test materials were included in the lsa corpus ( within ) and when it was not ( without ).', 'one within semantic space, which corresponds to the one used by choi et al., was built using the entire brown corpus as the lsa corpus.', 'four hundred different without spaces were built, one for each test sample, by each time removing from the brown corpus only the sentences that make this sample.', 'to extract the lsa space and to apply the segmentation algorithm, a series of parameters had to be set.', 'first of all, paragraphs were used as documents for building the lexical tables because choi et al. observed that such middle - sized units were more effective than shorter units ( i. e., sentences ).', ""the words on choi's stoplist were removed, as were those that appeared only once in the whole corpus."", 'words were not stemmed, as in  #AUTHOR_TAG.', 'to build the lsa space, the singular value decomposition was realized using the program svdpackc ( berry 1992 ; berry et al. 1993 ), and the first 300 singular vectors were retained.', 'concerning the segmentation algorithm, i used the version in which the number of boundaries to be found is imposed, and thus fixed at nine.', 'an 11 × 11 rank mask was used for the ordinal transformation, as recommended by  #TAUTHOR_TAG']",5
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['experiment was based on the procedure and test materials designed by  #TAUTHOR_TAG, which was also used by several authors as a benchmark for comparing segmentation systems ( brants et al. 2002 ; ferret 2002 ; kehagias et al. 2003 ; utiyama and isahara 2001 ).', 'the task consists in finding the boundaries between concatenated texts.', 'each test sample is a concatenation of ten text segments.', 'each segment consisted in the first n sentences of a randomly selected text from two sub - sections of the brown corpus.', 'for the present experiment, i used the most general test materials built by  #TAUTHOR_TAG, in which the size of the segments within each sample varies randomly from 3 to 11 sentences.', 'it is composed of 400 samples.', 'the analysis related to the comparison between the accuracy of the algorithm when the test materials were included in the lsa corpus ( within ) and when it was not ( without ).', 'one within semantic space, which corresponds to the one used by choi et al., was built using the entire brown corpus as the lsa corpus.', 'four hundred different without spaces were built, one for each test sample, by each time removing from the brown corpus only the sentences that make this sample.', 'to extract the lsa space and to apply the segmentation algorithm, a series of parameters had to be set.', 'first of all, paragraphs were used as documents for building the lexical tables because choi et al. observed that such middle - sized units were more effective than shorter units ( i. e., sentences ).', ""the words on choi's stoplist were removed, as were those that appeared only once in the whole corpus."", 'words were not stemmed, as in  #AUTHOR_TAG.', 'to build the lsa space, the singular value decomposition was realized using the program svdpackc ( berry 1992 ; berry et al. 1993 ), and the first 300 singular vectors were retained.', 'concerning the segmentation algorithm, i used the version in which the number of boundaries to be found is imposed, and thus fixed at nine.', 'an 11 × 11 rank mask was used for the ordinal transformation, as recommended by  #TAUTHOR_TAG']",5
"['given in  #TAUTHOR_TAG.', 'it is composed of 400 samples of ten segments, of which the length varies randomly from']","['given in  #TAUTHOR_TAG.', 'it is composed of 400 samples of ten segments, of which the length varies randomly from']","['test materials were extracted from the 1997 - 1998 corpus following the guidelines given in  #TAUTHOR_TAG.', 'it is composed of 400 samples of ten segments, of which the length varies randomly from']","['test materials were extracted from the 1997 - 1998 corpus following the guidelines given in  #TAUTHOR_TAG.', 'it is composed of 400 samples of ten segments, of which the length varies randomly from 3 to 11 sentences.', 'three types of lsa space were composed.', 'the within space is based on the whole 1997 - 1998 corpus.', 'four hundred different without spaces were built as described in experiment 1.', 'finally, a former space was built from the 1995 - 1996 corpus.', 'the parameters employed to build the semantic spaces are identical to those used in experiment 1 with one exception : in order to reduce the size of the lexical tables the whole articles and not the paragraphs were used as documents']",5
"['the method presented in  #TAUTHOR_TAG, arguments']","['the method presented in  #TAUTHOR_TAG, arguments']","['the method presented in  #TAUTHOR_TAG, arguments are matched using a span matching criterion of intersection']","['in qa - srl involves aligning predicted and ground truth argument spans and evaluating role label equivalence.', 'since detecting question paraphrases is still an open challenge, we propose both unlabeled and labeled evaluation metrics.', 'unlabeled argument detection ( ua ) inspired by the method presented in  #TAUTHOR_TAG, arguments are matched using a span matching criterion of intersection over union ≥ 0. 5.', 'to credit each argument only once, we employ maximal bipartite matching 4 between the two sets of arguments, drawing an edge for each pair that passes the above mentioned criterion.', 'the resulting maximal matching determines the true - positive set, while remaining non - aligned arguments become false - positives or false - negatives']",6
"[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","[' #TAUTHOR_TAG,']","['extend our metric for evaluating manual or automatic redundant annotations, like the dense dataset or  #TAUTHOR_TAG, which predicts argument spans independently of each other.', 'to that end, we ignore predicted arguments that match ground - truth but are not selected by the bipartite matching due to redundancy.', 'after con - necting unmatched predicted arguments that overlap, we count one false positive for every connected component to avoid penalizing precision too harshly when predictions are redundant.', '']",3
['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],[' #TAUTHOR_TAG'],0
['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],[' #TAUTHOR_TAG'],0
['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],[' #TAUTHOR_TAG'],0
['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],[' #TAUTHOR_TAG'],0
['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],[' #TAUTHOR_TAG'],0
['present the'],['present the'],['present the results shown in'],"['present the results shown in table 3 for the parsing performance of the unlexicalized model of the stanford parser  #AUTHOR_TAG.', '']",0
['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],[' #TAUTHOR_TAG'],6
['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],['corpus.  #TAUTHOR_TAG compares'],[' #TAUTHOR_TAG'],4
"[' #TAUTHOR_TAG, only sentences with fewer than']","[' #TAUTHOR_TAG, only sentences with fewer than']","[' #TAUTHOR_TAG, only sentences with fewer than 35 words were used, which results in']","[' #TAUTHOR_TAG, only sentences with fewer than 35 words were used, which results in 20, 002 sentences for negra and 21, 365 sentences for tuba - d / z. because punctuation is not attached within the sentence in the corpus annotation, punctuation was removed.', 'to be able to train pcfg parsing models, it is necessary to convert the syntax graphs encoding trees with discontinuities in negra into traditional syntax trees.', '']",4
['present the'],['present the'],['present the results shown in'],"['present the results shown in table 3 for the parsing performance of the unlexicalized model of the stanford parser  #AUTHOR_TAG.', '']",4
['provided by  #TAUTHOR_TAG is inadequate'],['provided by  #TAUTHOR_TAG is inadequate'],['provided by  #TAUTHOR_TAG is inadequate'],"['', 'these instances are frequently due to elision of the verb in headlines and coordinated clauses.', 'table 5 : labeled dependency evaluation tion, we confirm that the parseval scores do not correlate with the scores in the other two evaluations, which given their closeness to the semantic functor argument structure make meaningful targets for evaluating parsers.', 'shifting the focus to the grammatical function evaluation, we showed that a grammatical function evaluation based on phrasal arguments as provided by  #TAUTHOR_TAG is inadequate for comparing parsers trained on the negra and tuba - d / z corpora.', 'by introducing non - branching phrase nodes above single - word arguments in negra, it is possible to provide a balanced comparison for the grammatical function label evaluation between negra and tuba - d / z on both phrasal and single - word arguments.', 'the models trained on both corpora perform very similarly in the grammatical function evaluation, in contrast to the claims in  #TAUTHOR_TAG.', '']",4
['provided by  #TAUTHOR_TAG is inadequate'],['provided by  #TAUTHOR_TAG is inadequate'],['provided by  #TAUTHOR_TAG is inadequate'],"['', 'these instances are frequently due to elision of the verb in headlines and coordinated clauses.', 'table 5 : labeled dependency evaluation tion, we confirm that the parseval scores do not correlate with the scores in the other two evaluations, which given their closeness to the semantic functor argument structure make meaningful targets for evaluating parsers.', 'shifting the focus to the grammatical function evaluation, we showed that a grammatical function evaluation based on phrasal arguments as provided by  #TAUTHOR_TAG is inadequate for comparing parsers trained on the negra and tuba - d / z corpora.', 'by introducing non - branching phrase nodes above single - word arguments in negra, it is possible to provide a balanced comparison for the grammatical function label evaluation between negra and tuba - d / z on both phrasal and single - word arguments.', 'the models trained on both corpora perform very similarly in the grammatical function evaluation, in contrast to the claims in  #TAUTHOR_TAG.', '']",4
"['argument structure.', 'in contrast to  #TAUTHOR_TAG a grammatical']","['not carry over to measures which are relevant to the semantic functor - argument structure.', 'in contrast to  #TAUTHOR_TAG a grammatical']","['of verbs show that this difference does not carry over to measures which are relevant to the semantic functor - argument structure.', 'in contrast to  #TAUTHOR_TAG a grammatical function evaluation on subjects, accusative objects, and dative objects establishes that negra']","['the general question of how to compare parsing results for different annotation schemes, we revisited the comparison of pcfg parsing results for the negra and tuba - d / z corpora.', 'we show that these different annotation schemes lead to very significant differences in parseval scores for unlexicalized pcfg parsing models, but grammatical function label and labeled dependency evaluations for arguments of verbs show that this difference does not carry over to measures which are relevant to the semantic functor - argument structure.', 'in contrast to  #TAUTHOR_TAG a grammatical function evaluation on subjects, accusative objects, and dative objects establishes that negra and tuba - d / z perform similarly when all types of words and phrases appearing as arguments are taken into consideration.', 'a labeled dependency evaluation based on grammatical relations, which links this work to current work on formalism - independent parser evaluation ( e. g.,  #AUTHOR_TAG, shows that the parsing performance for negra and tuba - d / z is comparable']",4
"[' #TAUTHOR_TAG, only sentences with fewer than']","[' #TAUTHOR_TAG, only sentences with fewer than']","[' #TAUTHOR_TAG, only sentences with fewer than 35 words were used, which results in']","[' #TAUTHOR_TAG, only sentences with fewer than 35 words were used, which results in 20, 002 sentences for negra and 21, 365 sentences for tuba - d / z. because punctuation is not attached within the sentence in the corpus annotation, punctuation was removed.', 'to be able to train pcfg parsing models, it is necessary to convert the syntax graphs encoding trees with discontinuities in negra into traditional syntax trees.', '']",5
"[' #TAUTHOR_TAG, only sentences with fewer than']","[' #TAUTHOR_TAG, only sentences with fewer than']","[' #TAUTHOR_TAG, only sentences with fewer than 35 words were used, which results in']","[' #TAUTHOR_TAG, only sentences with fewer than 35 words were used, which results in 20, 002 sentences for negra and 21, 365 sentences for tuba - d / z. because punctuation is not attached within the sentence in the corpus annotation, punctuation was removed.', 'to be able to train pcfg parsing models, it is necessary to convert the syntax graphs encoding trees with discontinuities in negra into traditional syntax trees.', '']",5
['present the'],['present the'],['present the results shown in'],"['present the results shown in table 3 for the parsing performance of the unlexicalized model of the stanford parser  #AUTHOR_TAG.', '']",5
['present the'],['present the'],['present the results shown in'],"['present the results shown in table 3 for the parsing performance of the unlexicalized model of the stanford parser  #AUTHOR_TAG.', '']",5
"['setup of  #TAUTHOR_TAG.', ' #AUTHOR_TAG explores a range of parsing models and the corpus preparation he uses differs from']","['setup of  #TAUTHOR_TAG.', ' #AUTHOR_TAG explores a range of parsing models and the corpus preparation he uses differs from']","['be comparable to the setup of  #TAUTHOR_TAG.', ' #AUTHOR_TAG explores a range of parsing models and the corpus preparation he uses differs from']","['##ing the issue of the ratio of terminals to non - terminals raised in the last section, one can question whether counting all brackets in the sentence equally, as done by the parseval metric, provides a good measure of how accurately the basic functor - argument structure of the sentence has been captured in a parse.', 'thus, it is useful to per - 7 our experimental setup is designed to support a comparison between negra and tuba - d / z for the three evaluation metrics and is intended to be comparable to the setup of  #TAUTHOR_TAG.', ' #AUTHOR_TAG explores a range of parsing models and the corpus preparation he uses differs from the one discussed in this paper so that a discussion of his results is beyond the scope of the corpus comparison in this paper.', '8 scores were calculated using evalb.', 'form an evaluation based on the grammatical function labels that are important for determining the functor - argument structure of the sentence : subjects, accusative objects, and dative objects.', '9 the first step in an evaluation of functor - argument structure is to identify whether an argument bears the correct grammatical function label']",3
[' #TAUTHOR_TAG'],['reference of the words we use and the relationships between them ( e. g.  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['has been considerable recent interest in the use of statistical methods for grouping words in large on - line corpora into categories which capture some of our intuitions about the reference of the words we use and the relationships between them ( e. g.  #TAUTHOR_TAG.', 'although they have received most attention from within computational linguistics, such approaches are also of interest from the point of view of psychology.', 'the huge task of developing concepts of word meanings is one that human beings readily achieve ; we are all generally aware of the similarities and differences between the meanings of words, despite the fact that in many cases these meanings are not amenable to rigourous definition.', '']",0
"['to that of  #TAUTHOR_TAG,']","['to that of  #TAUTHOR_TAG,']","['to that of  #TAUTHOR_TAG,']","['number of analyses were carried out on text corpora to examine the sorts of semantic groupings that can be achieved using simple statistical methods.', ""using an approach similar to that of  #TAUTHOR_TAG, each'target word'1 wi in the corpus was represented as a vector in which each component j is the probability that any one word position in a'context window'will be occupied by a'context word'wj, given that the window is centred on word wi."", 'the length of the window used can be varied.', 'the basic outline of the moving window used is shown in figure 1.', 'as figure 1 indicates, the portion of the moving window in which the context words are contained may exclude a small number of word positions immediately adjacent to the target word.', 'this is to weaken the effects of syntax, although the analyses described here do not make use of this facility.', 'following the creation of these vectors, heirarchi - figure 1 : design of the moving window word or immediately following the target word.', 'whilst it seems reasonable to suppose that children acquiring word meanings would be able to make use of more than this limited amount of context information, the analyses were carried out to investigate performance of the system under such crude conditions.', 'it was found on examination of the dendrograms resulting from the cluster analyses that even using this extremely impoverished source of information about the target words did permit a limited number of semantically coherent groupings of words to be created.', 'the members of some of these groups were selected following inspection of the relevant dendrograms and are listed in ( 1992 ), the distance metric used was the spearman rank correlation coefficient.', 'the approach described here differs from that of  #TAUTHOR_TAG in that context words both preceding and following the target word are considered ( although information about the ordering of the context was not used ), and in that euclidean distance, rather than average mutual information, is used for clustering.', 'each of the methods described here represents each target word in the same manner, regardless of the syntactic or semantic designation which might conventionally be assigned to it.', 'thus any differences or similarities between words must be detected purely from the statistics of the usage of the words, which are in turn determined by the characteristics of the contexts in which they occur']",3
"['to that of  #TAUTHOR_TAG,']","['to that of  #TAUTHOR_TAG,']","['to that of  #TAUTHOR_TAG,']","['number of analyses were carried out on text corpora to examine the sorts of semantic groupings that can be achieved using simple statistical methods.', ""using an approach similar to that of  #TAUTHOR_TAG, each'target word'1 wi in the corpus was represented as a vector in which each component j is the probability that any one word position in a'context window'will be occupied by a'context word'wj, given that the window is centred on word wi."", 'the length of the window used can be varied.', 'the basic outline of the moving window used is shown in figure 1.', 'as figure 1 indicates, the portion of the moving window in which the context words are contained may exclude a small number of word positions immediately adjacent to the target word.', 'this is to weaken the effects of syntax, although the analyses described here do not make use of this facility.', 'following the creation of these vectors, heirarchi - figure 1 : design of the moving window word or immediately following the target word.', 'whilst it seems reasonable to suppose that children acquiring word meanings would be able to make use of more than this limited amount of context information, the analyses were carried out to investigate performance of the system under such crude conditions.', 'it was found on examination of the dendrograms resulting from the cluster analyses that even using this extremely impoverished source of information about the target words did permit a limited number of semantically coherent groupings of words to be created.', 'the members of some of these groups were selected following inspection of the relevant dendrograms and are listed in ( 1992 ), the distance metric used was the spearman rank correlation coefficient.', 'the approach described here differs from that of  #TAUTHOR_TAG in that context words both preceding and following the target word are considered ( although information about the ordering of the context was not used ), and in that euclidean distance, rather than average mutual information, is used for clustering.', 'each of the methods described here represents each target word in the same manner, regardless of the syntactic or semantic designation which might conventionally be assigned to it.', 'thus any differences or similarities between words must be detected purely from the statistics of the usage of the words, which are in turn determined by the characteristics of the contexts in which they occur']",5
['in  #TAUTHOR_TAG and ( daume'],['in  #TAUTHOR_TAG and ( daume'],"['. in contrast, globally optimized clustering decisions were reported in  #TAUTHOR_TAG and ( daumeiii and  #AUTHOR_TAG a ), where all clustering possibilities are considered by searching on a bell tree representation or by using the learning as search optimization ( laso ) framework ( daumeiii and  #AUTHOR_TAG b ) respectively, but', 'the first search is partial']","['clustering decisions are locally optimized. in contrast, globally optimized clustering decisions were reported in  #TAUTHOR_TAG and ( daumeiii and  #AUTHOR_TAG a ), where all clustering possibilities are considered by searching on a bell tree representation or by using the learning as search optimization ( laso ) framework ( daumeiii and  #AUTHOR_TAG b ) respectively, but', 'the first search is partial and driven by heuristics and the second one only looks back in text. we argue that a more adequate clusterization', 'phase for coreference resolution can be obtained by using a graph representation. in this paper we describe a novel representation of the coreference', 'space as an undirected edge - weighted graph in', 'which the nodes represent all the mentions from a', 'text, whereas the edges between nodes constitute the confidence values derived', '']",4
"['.', 'we created the training examples in the same way as  #TAUTHOR_TAG, by pairing all mentions of the same type, obtaining their feature vectors and taking the outcome ( coreferent / noncoreferent ) from the key files']","[') is a normalizing factor.', 'we created the training examples in the same way as  #TAUTHOR_TAG, by pairing all mentions of the same type, obtaining their feature vectors and taking the outcome ( coreferent / noncoreferent ) from the key files']","[') is a normalizing factor.', 'we created the training examples in the same way as  #TAUTHOR_TAG, by pairing all mentions of the same type, obtaining their feature vectors and taking the outcome ( coreferent / noncoreferent ) from the key files']","['coreference confidence values that become the weights in the starting graphs are provided by a maximum entropy model, trained on the training datasets of the corpora used in our experiments.', 'for maximum entropy classification we used a maxent 4 tool.', 'based on the data seen, a maximum entropy model  #AUTHOR_TAG offers an expression ( 1 ) for the probability that there exists coreference c between a mention m i and a mention m j.', 'where g k ( m i, m j, c ) is a feature and λ k is its weight ; z ( m i, m j ) is a normalizing factor.', 'we created the training examples in the same way as  #TAUTHOR_TAG, by pairing all mentions of the same type, obtaining their feature vectors and taking the outcome ( coreferent / noncoreferent ) from the key files']",5
"['', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG']","['is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between']","['them is particularly poor, but it is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between']","['', 'apparent that the muc score does not vary significantly between systems. this only shows', 'that none of them is particularly poor, but it is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between three clusterization algorithms on ace phase 2. the learning algorithms are maxent for coreference and svm for stopping the cut in bestcut. in turn, we obtain the mentions from the key files', ', detect them with our mention detection algorithm or do not use any information about them. annotation keys and the system output, while the ecm - f metric aligns the detected entities with the key entities so that the number', 'of common mentions is maximized. the ecm - f scorer overcomes two shortcomings of the muc scorer : not considering single mentions and treating every error as equally important  #AUTHOR_TAG, which makes', 'the ecm - f a more adequate measure of coreference. our second', 'experiment evaluates the impact that the different categories of our added features have on the performance of the bestcut system. the experiment was performed with a maxent classifier on the muc6 corpus, which was priorly converted into ace format, and employed mention information from the key', 'annotations. table 5 : impact of feature categories on best - cut on muc6. baseline system', 'has the  #TAUTHOR_TAG features. the system was tested on key mentions']",5
"['', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG']","['is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between']","['them is particularly poor, but it is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between']","['', 'apparent that the muc score does not vary significantly between systems. this only shows', 'that none of them is particularly poor, but it is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between three clusterization algorithms on ace phase 2. the learning algorithms are maxent for coreference and svm for stopping the cut in bestcut. in turn, we obtain the mentions from the key files', ', detect them with our mention detection algorithm or do not use any information about them. annotation keys and the system output, while the ecm - f metric aligns the detected entities with the key entities so that the number', 'of common mentions is maximized. the ecm - f scorer overcomes two shortcomings of the muc scorer : not considering single mentions and treating every error as equally important  #AUTHOR_TAG, which makes', 'the ecm - f a more adequate measure of coreference. our second', 'experiment evaluates the impact that the different categories of our added features have on the performance of the bestcut system. the experiment was performed with a maxent classifier on the muc6 corpus, which was priorly converted into ace format, and employed mention information from the key', 'annotations. table 5 : impact of feature categories on best - cut on muc6. baseline system', 'has the  #TAUTHOR_TAG features. the system was tested on key mentions']",5
"['', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG']","['is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between']","['them is particularly poor, but it is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between']","['', 'apparent that the muc score does not vary significantly between systems. this only shows', 'that none of them is particularly poor, but it is not a relevant way of comparing methods - the muc metric has been found', 'too indulgent by researchers  #TAUTHOR_TAG,  #AUTHOR_TAG table 4 : comparison of results between three clusterization algorithms on ace phase 2. the learning algorithms are maxent for coreference and svm for stopping the cut in bestcut. in turn, we obtain the mentions from the key files', ', detect them with our mention detection algorithm or do not use any information about them. annotation keys and the system output, while the ecm - f metric aligns the detected entities with the key entities so that the number', 'of common mentions is maximized. the ecm - f scorer overcomes two shortcomings of the muc scorer : not considering single mentions and treating every error as equally important  #AUTHOR_TAG, which makes', 'the ecm - f a more adequate measure of coreference. our second', 'experiment evaluates the impact that the different categories of our added features have on the performance of the bestcut system. the experiment was performed with a maxent classifier on the muc6 corpus, which was priorly converted into ace format, and employed mention information from the key', 'annotations. table 5 : impact of feature categories on best - cut on muc6. baseline system', 'has the  #TAUTHOR_TAG features. the system was tested on key mentions']",5
"['sub - word information from a word  #TAUTHOR_TAG.', 'the models achieved higher']","['sub - word information from a word  #TAUTHOR_TAG.', 'the models achieved higher']","['extracting sub - word information from a word  #TAUTHOR_TAG.', 'the models achieved higher performance']","['entity recognition ( ner ) is designed to extract entities such as location and product from texts.', 'the results are used in sophisticated tasks including summarizations and recommendations.', 'in the past several years, sequential neural models such as long - short term memory ( lstm ) have been applied to ner.', 'they have outperformed the conventional models  #AUTHOR_TAG.', 'recently, convolutional neural network ( cnn ) was introduced into many models for extracting sub - word information from a word  #TAUTHOR_TAG.', 'the models achieved higher performance because cnn can capture capitalization, suffixes, and prefixes  #AUTHOR_TAG.', 'these models predict a tag for each word assuming that words can be separated clearly by explicit word separators ( e. g. blank spaces ).', 'we refer to such model as a "" wordbased model "", even if inputs include characters.', 'when japanese ner employs a recent neural model, two obstacles arise.', 'first, extracting sub - word information by cnn is unsuitable for japanese language.', 'the reasons are that japanese words tend to be shorter than english and japanese characters have no capitalization.', '']",0
"[', blstm - cnns - crf  #TAUTHOR_TAG achieved state -']","['are words and characters.', 'above all, blstm - cnns - crf  #TAUTHOR_TAG achieved state - of - theart']","[', blstm - cnns - crf  #TAUTHOR_TAG achieved state -']","['models : conventional ner systems employ machine learning algorithms that use inputs which are hand - crafted features such as pos tags.', 'support vector machine  #AUTHOR_TAG, maximum entropy models  #AUTHOR_TAG, hidden markov models  #AUTHOR_TAG and crf  #AUTHOR_TAG were applied.', 'word - based neural models : a neural model was applied to sequence labeling tasks also in ner  #AUTHOR_TAG.', 'modified models using bi - directional lstm ( blstm ) or stacked lstm were proposed  #AUTHOR_TAG.', 'recently, new approaches introducing cnn or lstm for extracting subword information from character inputs have been found to outperform other models  #AUTHOR_TAG.', ' #AUTHOR_TAG proposed the model using an attention mechanism whose inputs are words and characters.', 'above all, blstm - cnns - crf  #TAUTHOR_TAG achieved state - of - theart performance on the standard english corpus : conll2003  #AUTHOR_TAG.', 'character - based neural models :  #AUTHOR_TAG proposed a character - based neural model.', 'this model, which inputs only characters, exhibits good performance on the condition that no external knowledge is used.', 'this model predicts a tag for each character and forces that predicted tags in a word are the same.', 'therefore, it is unsuitable for languages in which boundary conflicts occur.', 'japanese ner : for japanese ner, many models using conventional algorithms have been proposed  #AUTHOR_TAG.', 'most such models are character - based models to deal with boundary conflicts.', ' #AUTHOR_TAG applied a neural model to japanese ner.', 'this study uses non - sequential neural networks with inputs that are hand - crafted features.', 'this model uses no recent advanced approaches for ner, such as word embedding or cnn to extract sub - word information.', 'therefore, the effectiveness of recent neural models for japanese ner has not been evaluated']",0
['- crf  #TAUTHOR_TAG because it achieves'],"['this study, we specifically examine blstmcnns - crf  #TAUTHOR_TAG because it achieves state - of - the - art']",['- crf  #TAUTHOR_TAG because it achieves'],"['this study, we specifically examine blstmcnns - crf  #TAUTHOR_TAG because it achieves state - of - the - art performance in the conll 2003 corpus.', 'figure 1 presents the architecture of this model.', 'this word - based model combines cnn, blstm, and crf layers.', 'we describe each layer of this model as the following.', '']",0
['- crf  #TAUTHOR_TAG because it achieves'],"['this study, we specifically examine blstmcnns - crf  #TAUTHOR_TAG because it achieves state - of - the - art']",['- crf  #TAUTHOR_TAG because it achieves'],"['this study, we specifically examine blstmcnns - crf  #TAUTHOR_TAG because it achieves state - of - the - art performance in the conll 2003 corpus.', 'figure 1 presents the architecture of this model.', 'this word - based model combines cnn, blstm, and crf layers.', 'we describe each layer of this model as the following.', '']",1
"['embeddings with the effectiveness shown in english  #TAUTHOR_TAG.', 'we']","['embeddings with the effectiveness shown in english  #TAUTHOR_TAG.', 'we']","['pre - training of word embeddings with the effectiveness shown in english  #TAUTHOR_TAG.', 'we assume that it is difficult for the cnn layer to extract the japanese sub - word information.', 'moreover, we assume that sufficient information can be extracted from a simple character input.', 'consequently, the model uses no cnn layer']","['', 'additionally, we introduce word information with character information as inputs of this model.', 'character information is a character embedding and word information is the embedding of the word containing the character.', 'that is, the same word embedding will be used as inputs of characters constructing a word.', 'this enables us to utilize pre - training of word embeddings with the effectiveness shown in english  #TAUTHOR_TAG.', 'we assume that it is difficult for the cnn layer to extract the japanese sub - word information.', 'moreover, we assume that sufficient information can be extracted from a simple character input.', 'consequently, the model uses no cnn layer']",7
"['pt in english  #TAUTHOR_TAG.', '']","['pt in english  #TAUTHOR_TAG.', 'therefore,']","['. 75 pt in english  #TAUTHOR_TAG.', '']","['', 'when comparing blstm - crf and blstm - cnns - crf, the cnn layer is worse by 0. 18 pt.', 'here, the cnn layer and the crf layer improve by 2. 36 pt and 1. 75 pt in english  #TAUTHOR_TAG.', '']",7
"['reported for an earlier study  #TAUTHOR_TAG.', '']","['reported for an earlier study  #TAUTHOR_TAG.', '']","['reported for an earlier study  #TAUTHOR_TAG.', '']","['evaluate our models using the mainichi newspaper corpus.', 'we specifically examine the four categories of the highest frequency : product, location, organization, time. statistics related to this corpus.', 'we prepared pretrained word embeddings using skip - gram model  #AUTHOR_TAG.', 'seven years ( 1995 - 1996 and 1998 - 2002 ) of mainichi newspaper articles which include almost 500 million words are used for pre - training.', 'we conduct parameter tuning using the development dataset.', 'we choose the unit number of lstm as 300, the size of word embedding as 500, that of character embedding as 50, the maximum epoch as 20, and the batch size as 60.', 'we use adam  #AUTHOR_TAG, with the learning rate of 0. 001 for optimization.', 'we use mecab  #AUTHOR_TAG for word segmentation.', 'other conditions are the same as those reported for an earlier study  #TAUTHOR_TAG.', 'table 2 : f1 score of each models.', 'average is a weighted average.', '† expresses the best result in the word - based models for each entity category.', 'bold means the best result in all models for each entity category.', '"" output "" means the unit of prediction ; "" input "" shows information used as inputs']",5
"['5,  #TAUTHOR_TAG']","['trained on thousands of hours of data [ 5,  #TAUTHOR_TAG']","['trained on thousands of hours of data [ 5,  #TAUTHOR_TAG.', 'in']","['', 'instead of building an automatic speech recognition ( asr ) system from different components such as the acoustic model ( am ), language model ( lm ), and pronunciation model ( pm ), e2e models rely on a single neural network to directly learn speech - to - text mapping.', 'representative systems include a word - based connectionist temporal classification ( ctc ) model [ 1 ], recurrent neural network transducer ( rnn - t ) [ 2, 3 ], and attention - based models such as "" listen, attend, and spell "" ( las ) [ 4 ].', 'recent advances have shown that e2e models can outperform the state - of - the - art conventional system when trained on thousands of hours of data [ 5,  #TAUTHOR_TAG.', 'in previous work [ 7 ], it has been shown that contextual information ( i. e., phrases relevant to recognition in the current context such as contact names, geographic place names, songs, etc. ) can improve asr accuracy.', 'such phrases are often foreign words, or are rarely seen in training.', 'recognizing these phrases is challenging.', '']",0
"['5,  #TAUTHOR_TAG']","['trained on thousands of hours of data [ 5,  #TAUTHOR_TAG']","['trained on thousands of hours of data [ 5,  #TAUTHOR_TAG.', 'in']","['', 'instead of building an automatic speech recognition ( asr ) system from different components such as the acoustic model ( am ), language model ( lm ), and pronunciation model ( pm ), e2e models rely on a single neural network to directly learn speech - to - text mapping.', 'representative systems include a word - based connectionist temporal classification ( ctc ) model [ 1 ], recurrent neural network transducer ( rnn - t ) [ 2, 3 ], and attention - based models such as "" listen, attend, and spell "" ( las ) [ 4 ].', 'recent advances have shown that e2e models can outperform the state - of - the - art conventional system when trained on thousands of hours of data [ 5,  #TAUTHOR_TAG.', 'in previous work [ 7 ], it has been shown that contextual information ( i. e., phrases relevant to recognition in the current context such as contact names, geographic place names, songs, etc. ) can improve asr accuracy.', 'such phrases are often foreign words, or are rarely seen in training.', 'recognizing these phrases is challenging.', '']",0
"[' #TAUTHOR_TAG.', 'bias']","['decoding [ 10 ] and contextual biasing  #TAUTHOR_TAG.', 'biasing phrases']","['decoding [ 10 ] and contextual biasing  #TAUTHOR_TAG.', 'biasing phrases are first represented as n - gram wfst in']","['fusion has been used in e2e models for decoding [ 10 ] and contextual biasing  #TAUTHOR_TAG.', 'biasing phrases are first represented as n - gram wfst in the word level ( g ), and then left composed with a "" speller "" fst ( s ) to produce a contextual lm : c = min ( det ( s • g ) ).', '']",0
"[' #TAUTHOR_TAG.', 'bias']","['decoding [ 10 ] and contextual biasing  #TAUTHOR_TAG.', 'biasing phrases']","['decoding [ 10 ] and contextual biasing  #TAUTHOR_TAG.', 'biasing phrases are first represented as n - gram wfst in']","['fusion has been used in e2e models for decoding [ 10 ] and contextual biasing  #TAUTHOR_TAG.', 'biasing phrases are first represented as n - gram wfst in the word level ( g ), and then left composed with a "" speller "" fst ( s ) to produce a contextual lm : c = min ( det ( s • g ) ).', '']",0
"['1  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words [ 1  #TAUTHOR_TAG,']","['1  #TAUTHOR_TAG,']","['wordpiece - phoneme model differs from a wordpiece - only model in that it may decompose a few words to phonemes in training.', 'the output of the model is a single softmax whose symbol set is the union of wordpiece and phoneme symbols.', 'we use a pronunciation lexicon to obtain phoneme sequences of words.', 'since phonemes show strength in recognizing rare words [ 1  #TAUTHOR_TAG, we want to present these words as phonemes more often.', 'in a target sentence, we decide to randomly present the i th word as phonemes with a probability', ', 1. 0 ) where p0 and t are constants and c ( i ) is an integer representing the number of time the word appears in our entire training corpus.', 'therefore, the words that appear t times or less will be presented as phonemes with probability p0.', 'for words that appear more than t times, the more frequent they are, the less likely they are presented as phonemes 2.', 'note that the decision of whether to use wordpieces or phonemes is made randomly at each gradient iteration, and thus a given sentence could have different target sequences at different epochs.', 'we use context - independent phonemes as in [ 1  #TAUTHOR_TAG']",0
"['1  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words [ 1  #TAUTHOR_TAG,']","['1  #TAUTHOR_TAG,']","['wordpiece - phoneme model differs from a wordpiece - only model in that it may decompose a few words to phonemes in training.', 'the output of the model is a single softmax whose symbol set is the union of wordpiece and phoneme symbols.', 'we use a pronunciation lexicon to obtain phoneme sequences of words.', 'since phonemes show strength in recognizing rare words [ 1  #TAUTHOR_TAG, we want to present these words as phonemes more often.', 'in a target sentence, we decide to randomly present the i th word as phonemes with a probability', ', 1. 0 ) where p0 and t are constants and c ( i ) is an integer representing the number of time the word appears in our entire training corpus.', 'therefore, the words that appear t times or less will be presented as phonemes with probability p0.', 'for words that appear more than t times, the more frequent they are, the less likely they are presented as phonemes 2.', 'note that the decision of whether to use wordpieces or phonemes is made randomly at each gradient iteration, and thus a given sentence could have different target sequences at different epochs.', 'we use context - independent phonemes as in [ 1  #TAUTHOR_TAG']",3
"['1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['[ 1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops']","['generate words as outputs, we search through a decoding graph similar to [ 1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops around state 0 ( we show only a few for simplicity ), but also has a pronunciation section ( states 1 through 14 ).', 'the pronunciation section is a prefix tree with phonemes as inputs, and outputs are wordpieces of the corresponding word produced by the wpm in section 3. 1.', 'specifically, for each word in the biasing list, we look up pronunciations from the lexicon and split the word into its constituent wordpieces.', '']",3
"['to  #TAUTHOR_TAG, an input utterance is divided to']","['to  #TAUTHOR_TAG, an input utterance is divided to 25 - ms frames, windowed and shifted']","['to  #TAUTHOR_TAG, an input utterance is divided to']","['to  #TAUTHOR_TAG, an input utterance is divided to 25 - ms frames, windowed and shifted at a rate of 10 ms.', 'a 80 - dimensional logmel feature is extracted at each frame, and the current frame and two frames to the left are concatenated to produce a 240 - dimensional log - mel feature.', '']",3
"['to  #TAUTHOR_TAG, an input utterance is divided to']","['to  #TAUTHOR_TAG, an input utterance is divided to 25 - ms frames, windowed and shifted']","['to  #TAUTHOR_TAG, an input utterance is divided to']","['to  #TAUTHOR_TAG, an input utterance is divided to 25 - ms frames, windowed and shifted at a rate of 10 ms.', 'a 80 - dimensional logmel feature is extracted at each frame, and the current frame and two frames to the left are concatenated to produce a 240 - dimensional log - mel feature.', '']",3
['1  #TAUTHOR_TAG. since'],"['1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces']","['the superior per - formance of the wordpiece - phoneme model to the robustness of phonemes to', 'oov words, as observed in [ 1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces']","['wordpiece model. we attribute the superior per - formance of the wordpiece - phoneme model to the robustness of phonemes to', 'oov words, as observed in [ 1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces and phonemes as modeling units, we can further perform wordpiece biasing in addition to phoneme', '- based biasing by building a wordpiece fst in parallel to the phoneme fst. this further reduces the', '']",3
"['1  #TAUTHOR_TAG,']","['phonemes show strength in recognizing rare words [ 1  #TAUTHOR_TAG,']","['1  #TAUTHOR_TAG,']","['wordpiece - phoneme model differs from a wordpiece - only model in that it may decompose a few words to phonemes in training.', 'the output of the model is a single softmax whose symbol set is the union of wordpiece and phoneme symbols.', 'we use a pronunciation lexicon to obtain phoneme sequences of words.', 'since phonemes show strength in recognizing rare words [ 1  #TAUTHOR_TAG, we want to present these words as phonemes more often.', 'in a target sentence, we decide to randomly present the i th word as phonemes with a probability', ', 1. 0 ) where p0 and t are constants and c ( i ) is an integer representing the number of time the word appears in our entire training corpus.', 'therefore, the words that appear t times or less will be presented as phonemes with probability p0.', 'for words that appear more than t times, the more frequent they are, the less likely they are presented as phonemes 2.', 'note that the decision of whether to use wordpieces or phonemes is made randomly at each gradient iteration, and thus a given sentence could have different target sequences at different epochs.', 'we use context - independent phonemes as in [ 1  #TAUTHOR_TAG']",5
"['1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['[ 1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops']","['generate words as outputs, we search through a decoding graph similar to [ 1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops around state 0 ( we show only a few for simplicity ), but also has a pronunciation section ( states 1 through 14 ).', 'the pronunciation section is a prefix tree with phonemes as inputs, and outputs are wordpieces of the corresponding word produced by the wpm in section 3. 1.', 'specifically, for each word in the biasing list, we look up pronunciations from the lexicon and split the word into its constituent wordpieces.', '']",5
"['to  #TAUTHOR_TAG, an input utterance is divided to']","['to  #TAUTHOR_TAG, an input utterance is divided to 25 - ms frames, windowed and shifted']","['to  #TAUTHOR_TAG, an input utterance is divided to']","['to  #TAUTHOR_TAG, an input utterance is divided to 25 - ms frames, windowed and shifted at a rate of 10 ms.', 'a 80 - dimensional logmel feature is extracted at each frame, and the current frame and two frames to the left are concatenated to produce a 240 - dimensional log - mel feature.', '']",5
"['to  #TAUTHOR_TAG, an input utterance is divided to']","['to  #TAUTHOR_TAG, an input utterance is divided to 25 - ms frames, windowed and shifted']","['to  #TAUTHOR_TAG, an input utterance is divided to']","['to  #TAUTHOR_TAG, an input utterance is divided to 25 - ms frames, windowed and shifted at a rate of 10 ms.', 'a 80 - dimensional logmel feature is extracted at each frame, and the current frame and two frames to the left are concatenated to produce a 240 - dimensional log - mel feature.', '']",5
['1  #TAUTHOR_TAG. since'],"['1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces']","['the superior per - formance of the wordpiece - phoneme model to the robustness of phonemes to', 'oov words, as observed in [ 1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces']","['wordpiece model. we attribute the superior per - formance of the wordpiece - phoneme model to the robustness of phonemes to', 'oov words, as observed in [ 1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces and phonemes as modeling units, we can further perform wordpiece biasing in addition to phoneme', '- based biasing by building a wordpiece fst in parallel to the phoneme fst. this further reduces the', '']",5
"['1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['[ 1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops']","['generate words as outputs, we search through a decoding graph similar to [ 1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops around state 0 ( we show only a few for simplicity ), but also has a pronunciation section ( states 1 through 14 ).', 'the pronunciation section is a prefix tree with phonemes as inputs, and outputs are wordpieces of the corresponding word produced by the wpm in section 3. 1.', 'specifically, for each word in the biasing list, we look up pronunciations from the lexicon and split the word into its constituent wordpieces.', '']",4
['1  #TAUTHOR_TAG. since'],"['1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces']","['the superior per - formance of the wordpiece - phoneme model to the robustness of phonemes to', 'oov words, as observed in [ 1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces']","['wordpiece model. we attribute the superior per - formance of the wordpiece - phoneme model to the robustness of phonemes to', 'oov words, as observed in [ 1  #TAUTHOR_TAG. since the wordpiece -', 'phoneme model contains both wordpieces and phonemes as modeling units, we can further perform wordpiece biasing in addition to phoneme', '- based biasing by building a wordpiece fst in parallel to the phoneme fst. this further reduces the', '']",4
"['1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['[ 1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in']","['1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops']","['generate words as outputs, we search through a decoding graph similar to [ 1  #TAUTHOR_TAG but accept both phonemes and wordpieces.', 'an example is shown in figure 2.', 'the decoding fst has wordpiece loops around state 0 ( we show only a few for simplicity ), but also has a pronunciation section ( states 1 through 14 ).', 'the pronunciation section is a prefix tree with phonemes as inputs, and outputs are wordpieces of the corresponding word produced by the wpm in section 3. 1.', 'specifically, for each word in the biasing list, we look up pronunciations from the lexicon and split the word into its constituent wordpieces.', '']",6
"['than graphemes  #TAUTHOR_TAG in e2e modeling, it would be interesting to explore longer phonemic units such as phoneme pieces for biasing']","['than graphemes  #TAUTHOR_TAG in e2e modeling, it would be interesting to explore longer phonemic units such as phoneme pieces for biasing']","['than graphemes  #TAUTHOR_TAG in e2e modeling, it would be interesting to explore longer phonemic units such as phoneme pieces for biasing']","['this work we proposed a wordpiece - phoneme rnn - t model and phoneme - level contextual biasing to recognize foreign words.', 'biasing at the phoneme level enables us to avoid the oov problem in the wordpiece model.', 'evaluating on a test set containing navigation queries to french place names, we show the proposed approach performs significantly better than a state - of - the - art grapheme and wordpiece model, by 16 % and 8 %, respectively in terms of relative wer reductions.', 'wordpiece biasing is complimentary to phoneme biasing and adds a further 2 % reduction.', 'lastly, since wordpieces perform better than graphemes  #TAUTHOR_TAG in e2e modeling, it would be interesting to explore longer phonemic units such as phoneme pieces for biasing']",2
"['strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['machine translation ( nmt )  #AUTHOR_TAG is rapidly proving itself to be a strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['machine translation ( nmt )  #AUTHOR_TAG is rapidly proving itself to be a strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve learning of lowresource languages is to use resources from related languages  #AUTHOR_TAG.', 'however, adapting these resources is not trivial.', 'nmt offers some simple ways of doing this.', 'for example,  #TAUTHOR_TAG train a parent model on a ( possibly unrelated ) high - resource language pair, then use this model to initialize a child model which is further trained on a low - resource language pair.', 'in particular, they showed that a french - english model could be used to improve translation on a wide range of low - resource language pairs such as hausa -, turkish -, and uzbek - english.', 'in this paper, we explore the opposite scenario, where the parent language pair is also lowresource, but related to the child language pair.', 'we show that, at least in the case of three turkic languages ( turkish, uzbek, and uyghur ), the original method of  #TAUTHOR_TAG does not always work, but it is still possible to use the parent model to considerably improve the child model.', 'the basic idea is to exploit the relationship between the parent and child language lexicons.', ""zoph et al.'s original method makes no assumption about the relatedness of the parent and child languages, so it effectively makes a random assignment of the parent - language word embeddings to child - language words. but if we assume that the parent and child lexicons are related, it should be beneficial to transfer source word embeddings from parent - language words to their child - language equivalents."", 'thus, the problem amounts to finding a representation of the data that ensures a sufficient overlap between the vocabularies of the languages.', 'to do this, we map the source languages to a common alphabet and use byte pair encoding ( bpe )  #AUTHOR_TAG on the union of the vocabularies to increase the number of common subwords.', 'in our experiments, we show that transfer learning helps word - based translation, but not always significantly. but when used on top of a much stronger bpe baseline, it yields larger and statistically significant improvements.', 'using uzbek as a parent language and turkish and uyghur as child languages, we obtain improvements over bpe of 0. 8 and 4. 3 bleu, respectively.', '']",1
"['strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['machine translation ( nmt )  #AUTHOR_TAG is rapidly proving itself to be a strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['machine translation ( nmt )  #AUTHOR_TAG is rapidly proving itself to be a strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve learning of lowresource languages is to use resources from related languages  #AUTHOR_TAG.', 'however, adapting these resources is not trivial.', 'nmt offers some simple ways of doing this.', 'for example,  #TAUTHOR_TAG train a parent model on a ( possibly unrelated ) high - resource language pair, then use this model to initialize a child model which is further trained on a low - resource language pair.', 'in particular, they showed that a french - english model could be used to improve translation on a wide range of low - resource language pairs such as hausa -, turkish -, and uzbek - english.', 'in this paper, we explore the opposite scenario, where the parent language pair is also lowresource, but related to the child language pair.', 'we show that, at least in the case of three turkic languages ( turkish, uzbek, and uyghur ), the original method of  #TAUTHOR_TAG does not always work, but it is still possible to use the parent model to considerably improve the child model.', 'the basic idea is to exploit the relationship between the parent and child language lexicons.', ""zoph et al.'s original method makes no assumption about the relatedness of the parent and child languages, so it effectively makes a random assignment of the parent - language word embeddings to child - language words. but if we assume that the parent and child lexicons are related, it should be beneficial to transfer source word embeddings from parent - language words to their child - language equivalents."", 'thus, the problem amounts to finding a representation of the data that ensures a sufficient overlap between the vocabularies of the languages.', 'to do this, we map the source languages to a common alphabet and use byte pair encoding ( bpe )  #AUTHOR_TAG on the union of the vocabularies to increase the number of common subwords.', 'in our experiments, we show that transfer learning helps word - based translation, but not always significantly. but when used on top of a much stronger bpe baseline, it yields larger and statistically significant improvements.', 'using uzbek as a parent language and turkish and uyghur as child languages, we obtain improvements over bpe of 0. 8 and 4. 3 bleu, respectively.', '']",1
"['strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['machine translation ( nmt )  #AUTHOR_TAG is rapidly proving itself to be a strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['machine translation ( nmt )  #AUTHOR_TAG is rapidly proving itself to be a strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve learning of lowresource languages is to use resources from related languages  #AUTHOR_TAG.', 'however, adapting these resources is not trivial.', 'nmt offers some simple ways of doing this.', 'for example,  #TAUTHOR_TAG train a parent model on a ( possibly unrelated ) high - resource language pair, then use this model to initialize a child model which is further trained on a low - resource language pair.', 'in particular, they showed that a french - english model could be used to improve translation on a wide range of low - resource language pairs such as hausa -, turkish -, and uzbek - english.', 'in this paper, we explore the opposite scenario, where the parent language pair is also lowresource, but related to the child language pair.', 'we show that, at least in the case of three turkic languages ( turkish, uzbek, and uyghur ), the original method of  #TAUTHOR_TAG does not always work, but it is still possible to use the parent model to considerably improve the child model.', 'the basic idea is to exploit the relationship between the parent and child language lexicons.', ""zoph et al.'s original method makes no assumption about the relatedness of the parent and child languages, so it effectively makes a random assignment of the parent - language word embeddings to child - language words. but if we assume that the parent and child lexicons are related, it should be beneficial to transfer source word embeddings from parent - language words to their child - language equivalents."", 'thus, the problem amounts to finding a representation of the data that ensures a sufficient overlap between the vocabularies of the languages.', 'to do this, we map the source languages to a common alphabet and use byte pair encoding ( bpe )  #AUTHOR_TAG on the union of the vocabularies to increase the number of common subwords.', 'in our experiments, we show that transfer learning helps word - based translation, but not always significantly. but when used on top of a much stronger bpe baseline, it yields larger and statistically significant improvements.', 'using uzbek as a parent language and turkish and uyghur as child languages, we obtain improvements over bpe of 0. 8 and 4. 3 bleu, respectively.', '']",5
"[' #TAUTHOR_TAG.', 'in their work,']","[' #TAUTHOR_TAG.', 'in their work,']","[' #TAUTHOR_TAG.', 'in their work,']","['follow the transfer learning approach proposed by  #TAUTHOR_TAG.', 'in their work, a parent model is first trained on a high - resource language pair.', ""then the child model's parameter values are copied from the parent's and are fine - tuned on its low - resource data."", '']",5
['extend the transfer method of  #TAUTHOR_TAG to share the parent and'],['extend the transfer method of  #TAUTHOR_TAG to share the parent and'],['extend the transfer method of  #TAUTHOR_TAG to share the parent and'],"[""basic idea of our method is to extend the transfer method of  #TAUTHOR_TAG to share the parent and child's source vocabularies, so that when source word embeddings are transferred, a word that appears in both vocabularies keeps its embedding."", 'in order for this to work, it must be the case that the parent and child languages have considerable vocabulary overlap, and that when a word occurs in both languages, it often has a similar meaning in both languages.', 'thus, we need to process the data to make these two assumptions hold as much as possible']",5
"['based systems using transfer without vocabulary - sharing,', 'corresponding with the method of  #TAUTHOR_TAG ( § 2']","['based systems using transfer without vocabulary - sharing,', 'corresponding with the method of  #TAUTHOR_TAG ( § 2']","['based systems using transfer without vocabulary - sharing,', 'corresponding with the method of  #TAUTHOR_TAG ( § 2. 2 ) : one where the target word embeddings are fine', '- tuned, and one where they are frozen']","['', '##ased systems, respectively, to maximize the tokenized', 'bleu on the development set. after translation at test time, we rejoined bpe segments, recased, and det', '##okenized. finally, we evaluated using case - sensitive', 'bleu. as a baseline, we trained a child model using bpe but without transfer ( that is, with weights randomly initialized', '). we also compared against a word - based baseline ( without transfer ) and two word - based systems using transfer without vocabulary - sharing,', 'corresponding with the method of  #TAUTHOR_TAG ( § 2. 2 ) : one where the target word embeddings are fine', '- tuned, and one where they are frozen']",5
"['this paper, we have shown that the transfer learning method of  #TAUTHOR_TAG, while appealing,']","['this paper, we have shown that the transfer learning method of  #TAUTHOR_TAG, while appealing,']","['this paper, we have shown that the transfer learning method of  #TAUTHOR_TAG, while appealing,']","['this paper, we have shown that the transfer learning method of  #TAUTHOR_TAG, while appealing, might not always work in a low - resource context.', 'however, by combining it with bpe, we can improve nmt performance on a low - resource language pair by exploiting its lexical similarity with another related, low - resource language.', 'our results show consistent improvement in two turkic languages.', 'our approach, which relies on segmenting words into subwords, seems well suited to agglutinative languages ; further investigation would be needed to confirm whether our method works on other types of languages']",5
"['strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['machine translation ( nmt )  #AUTHOR_TAG is rapidly proving itself to be a strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve']","['machine translation ( nmt )  #AUTHOR_TAG is rapidly proving itself to be a strong competitor to other statistical machine translation methods.', 'however, it still lags behind other statistical methods on very lowresource language pairs  #TAUTHOR_TAG.', 'a common strategy to improve learning of lowresource languages is to use resources from related languages  #AUTHOR_TAG.', 'however, adapting these resources is not trivial.', 'nmt offers some simple ways of doing this.', 'for example,  #TAUTHOR_TAG train a parent model on a ( possibly unrelated ) high - resource language pair, then use this model to initialize a child model which is further trained on a low - resource language pair.', 'in particular, they showed that a french - english model could be used to improve translation on a wide range of low - resource language pairs such as hausa -, turkish -, and uzbek - english.', 'in this paper, we explore the opposite scenario, where the parent language pair is also lowresource, but related to the child language pair.', 'we show that, at least in the case of three turkic languages ( turkish, uzbek, and uyghur ), the original method of  #TAUTHOR_TAG does not always work, but it is still possible to use the parent model to considerably improve the child model.', 'the basic idea is to exploit the relationship between the parent and child language lexicons.', ""zoph et al.'s original method makes no assumption about the relatedness of the parent and child languages, so it effectively makes a random assignment of the parent - language word embeddings to child - language words. but if we assume that the parent and child lexicons are related, it should be beneficial to transfer source word embeddings from parent - language words to their child - language equivalents."", 'thus, the problem amounts to finding a representation of the data that ensures a sufficient overlap between the vocabularies of the languages.', 'to do this, we map the source languages to a common alphabet and use byte pair encoding ( bpe )  #AUTHOR_TAG on the union of the vocabularies to increase the number of common subwords.', 'in our experiments, we show that transfer learning helps word - based translation, but not always significantly. but when used on top of a much stronger bpe baseline, it yields larger and statistically significant improvements.', 'using uzbek as a parent language and turkish and uyghur as child languages, we obtain improvements over bpe of 0. 8 and 4. 3 bleu, respectively.', '']",0
['extend the transfer method of  #TAUTHOR_TAG to share the parent and'],['extend the transfer method of  #TAUTHOR_TAG to share the parent and'],['extend the transfer method of  #TAUTHOR_TAG to share the parent and'],"[""basic idea of our method is to extend the transfer method of  #TAUTHOR_TAG to share the parent and child's source vocabularies, so that when source word embeddings are transferred, a word that appears in both vocabularies keeps its embedding."", 'in order for this to work, it must be the case that the parent and child languages have considerable vocabulary overlap, and that when a word occurs in both languages, it often has a similar meaning in both languages.', 'thus, we need to process the data to make these two assumptions hold as much as possible']",6
"['this paper, we have shown that the transfer learning method of  #TAUTHOR_TAG, while appealing,']","['this paper, we have shown that the transfer learning method of  #TAUTHOR_TAG, while appealing,']","['this paper, we have shown that the transfer learning method of  #TAUTHOR_TAG, while appealing,']","['this paper, we have shown that the transfer learning method of  #TAUTHOR_TAG, while appealing, might not always work in a low - resource context.', 'however, by combining it with bpe, we can improve nmt performance on a low - resource language pair by exploiting its lexical similarity with another related, low - resource language.', 'our results show consistent improvement in two turkic languages.', 'our approach, which relies on segmenting words into subwords, seems well suited to agglutinative languages ; further investigation would be needed to confirm whether our method works on other types of languages']",6
"['category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['the category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['is an open and collaborative multilingual encyclopedia contributed by several collaborators currently having 5. 6 million english articles [ 21 ].', 'constantly, the articles are updated and new articles are added by its collaborators.', 'about 74 % of wikipedia articles fall under the category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages which contain concepts and facts about the article, category pages provides a list of content pages into several classes based on specific criteria and disambiguation pages help to locate different content pages with same title.', 'wikipedia is an abundant resource for generation of different types of multilingual, cross lingual, cross script and language independent corpus, etc., its markup has been used extensively to automatically generate ner annotated corpus for training machine learning models  #TAUTHOR_TAG [ 5 ] [ 6 ] [ 11 ] [ 12 ] [ 13 ] [ 14 ] 19 ].', 'the latest involvement using wikipedia is the portable cross lingual ner for low resource languages using translation of an annotated ner corpus from english [ 12, 19 ].', 'another approach to cross lingual and language independent corpora is to learn a model on language independent features of a source language and test the model on other languages using same features [ 13 ].', ' #AUTHOR_TAG [ 5 ] constructed a massive english ner corpus by the classification of wikipedia articles to its category types by mapping them to conll - 2003 ner tagset.', '']",0
"['category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['the category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['is an open and collaborative multilingual encyclopedia contributed by several collaborators currently having 5. 6 million english articles [ 21 ].', 'constantly, the articles are updated and new articles are added by its collaborators.', 'about 74 % of wikipedia articles fall under the category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages which contain concepts and facts about the article, category pages provides a list of content pages into several classes based on specific criteria and disambiguation pages help to locate different content pages with same title.', 'wikipedia is an abundant resource for generation of different types of multilingual, cross lingual, cross script and language independent corpus, etc., its markup has been used extensively to automatically generate ner annotated corpus for training machine learning models  #TAUTHOR_TAG [ 5 ] [ 6 ] [ 11 ] [ 12 ] [ 13 ] [ 14 ] 19 ].', 'the latest involvement using wikipedia is the portable cross lingual ner for low resource languages using translation of an annotated ner corpus from english [ 12, 19 ].', 'another approach to cross lingual and language independent corpora is to learn a model on language independent features of a source language and test the model on other languages using same features [ 13 ].', ' #AUTHOR_TAG [ 5 ] constructed a massive english ner corpus by the classification of wikipedia articles to its category types by mapping them to conll - 2003 ner tagset.', '']",0
"['category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['the category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages']","['is an open and collaborative multilingual encyclopedia contributed by several collaborators currently having 5. 6 million english articles [ 21 ].', 'constantly, the articles are updated and new articles are added by its collaborators.', 'about 74 % of wikipedia articles fall under the category of named entity classes  #TAUTHOR_TAG, therefore, we consider wikipedia links among articles to construct the hi - en - wp ner annotated corpus.', 'wikipedia includes content pages which contain concepts and facts about the article, category pages provides a list of content pages into several classes based on specific criteria and disambiguation pages help to locate different content pages with same title.', 'wikipedia is an abundant resource for generation of different types of multilingual, cross lingual, cross script and language independent corpus, etc., its markup has been used extensively to automatically generate ner annotated corpus for training machine learning models  #TAUTHOR_TAG [ 5 ] [ 6 ] [ 11 ] [ 12 ] [ 13 ] [ 14 ] 19 ].', 'the latest involvement using wikipedia is the portable cross lingual ner for low resource languages using translation of an annotated ner corpus from english [ 12, 19 ].', 'another approach to cross lingual and language independent corpora is to learn a model on language independent features of a source language and test the model on other languages using same features [ 13 ].', ' #AUTHOR_TAG [ 5 ] constructed a massive english ner corpus by the classification of wikipedia articles to its category types by mapping them to conll - 2003 ner tagset.', '']",5
"['as a named entity.', 'this approach is similar to  #AUTHOR_TAG  #TAUTHOR_TAG to']","['as a named entity.', 'this approach is similar to  #AUTHOR_TAG  #TAUTHOR_TAG to']","['as a named entity.', 'this approach is similar to  #AUTHOR_TAG  #TAUTHOR_TAG to']","['being a huge source of information, its articles comprise of : topic and its comprehensive summary in paragraphs and images ; reference to reliable resources ; and hyperlinks, also called wikilinks to other articles.', 'our method takes the advantage of wikilinks between the articles from which linktext is extracted.', 'since wikilinks are links to articles, it may be considered as a named entity.', 'this approach is similar to  #AUTHOR_TAG  #TAUTHOR_TAG to generate the ner data from wikilinks.', 'a total number of 7285 tokens and multi - tokens expressions were extracted from the links by parsing the 13 identified wikipedia webpages.', 'we consider these expressions as probable nes after the removal of duplicates from the set of tokens obtained.', 'in order to distinguish among the tokens an intuitive approach is to calculate the distribution of different type of tokens.', 'to make this achievable, we grouped them according to pos tags.', 'we consider the supposition that nes are often nnp, moreover, the common nouns, verbs and rest of the pos tags generated help to filter out the non nes.', 'wordtypes.', 'we adopt a subset of wordtypes proposed by  #AUTHOR_TAG [ 16 ], which maps uppercase letters to a, lowercase to a, and, digits to 0.', 'the brief statics of the generated hi - en - wp corpus is presented in table 1']",3
"['is expectedly low, in agreement with the results of  #AUTHOR_TAG  #TAUTHOR_TAG.', 'the variation reflected in']","['is expectedly low, in agreement with the results of  #AUTHOR_TAG  #TAUTHOR_TAG.', 'the variation reflected in']","['as location.', 'the misc f - score is expectedly low, in agreement with the results of  #AUTHOR_TAG  #TAUTHOR_TAG.', 'the variation reflected in']","['', 'when trained with misc as a separate class, high values for per suggests that they comparatively easy to identify.', 'it may be due to sufficiently large amount of training data as compared to rest of the tags.', 'whereas, low precision value for loc tag suggests that other entities are wrongly classified as location.', 'the misc f - score is expectedly low, in agreement with the results of  #AUTHOR_TAG  #TAUTHOR_TAG.', 'the variation reflected in f - score among all may be the effect of diversity in linguistic attributes.', 'an increase in accuracy from 89 % to 92 % is observed when the model is trained without misc tag which reflects that the confusion is created in data by the inclusion of training examples that belong to misc tag.', 'the fig. 1 illustrates the effect of varying size of the hi - en - wp training data.', 'the improving trend of accuracy score on increasing training data sufficiently produces scope to scale the size of corpus in future']",3
"[' #TAUTHOR_TAG.', 'the statistics of the final training']","[' #TAUTHOR_TAG.', 'the statistics of the final training']","[' #TAUTHOR_TAG.', 'the statistics of the final training data is given in table 1.', 'we use chinese - english translation lexicon version 3. 0 ( ldc']","['this set of experiments, we use the same data as  #TAUTHOR_TAG.', 'the statistics of the final training data is given in table 1.', 'we use chinese - english translation lexicon version 3. 0 ( ldc2002l27 ) as our ground truth bilingual lexicon for evaluation.', 'the baseline models are monogiza system  #AUTHOR_TAG, translation matrix ( tm )  #AUTHOR_TAG, isometric alignment ( ia )  #AUTHOR_TAG b ) and adversarial training approach  #TAUTHOR_TAG.', 'table 2 summarizes the performance of baseline models and our approach.', 'the results of baseline models are cited from  #TAUTHOR_TAG.', 'as we can see from the table, our model could achieve superior performance compared with other baseline models']",5
"[' #TAUTHOR_TAG.', 'the statistics of the final training']","[' #TAUTHOR_TAG.', 'the statistics of the final training']","[' #TAUTHOR_TAG.', 'the statistics of the final training data is given in table 1.', 'we use chinese - english translation lexicon version 3. 0 ( ldc']","['this set of experiments, we use the same data as  #TAUTHOR_TAG.', 'the statistics of the final training data is given in table 1.', 'we use chinese - english translation lexicon version 3. 0 ( ldc2002l27 ) as our ground truth bilingual lexicon for evaluation.', 'the baseline models are monogiza system  #AUTHOR_TAG, translation matrix ( tm )  #AUTHOR_TAG, isometric alignment ( ia )  #AUTHOR_TAG b ) and adversarial training approach  #TAUTHOR_TAG.', 'table 2 summarizes the performance of baseline models and our approach.', 'the results of baseline models are cited from  #TAUTHOR_TAG.', 'as we can see from the table, our model could achieve superior performance compared with other baseline models']",5
"[' #TAUTHOR_TAG.', 'the statistics of the final training']","[' #TAUTHOR_TAG.', 'the statistics of the final training']","[' #TAUTHOR_TAG.', 'the statistics of the final training data is given in table 1.', 'we use chinese - english translation lexicon version 3. 0 ( ldc']","['this set of experiments, we use the same data as  #TAUTHOR_TAG.', 'the statistics of the final training data is given in table 1.', 'we use chinese - english translation lexicon version 3. 0 ( ldc2002l27 ) as our ground truth bilingual lexicon for evaluation.', 'the baseline models are monogiza system  #AUTHOR_TAG, translation matrix ( tm )  #AUTHOR_TAG, isometric alignment ( ia )  #AUTHOR_TAG b ) and adversarial training approach  #TAUTHOR_TAG.', 'table 2 summarizes the performance of baseline models and our approach.', 'the results of baseline models are cited from  #TAUTHOR_TAG.', 'as we can see from the table, our model could achieve superior performance compared with other baseline models']",5
"['english language pairs.', 'again, we use the same dataset with  #TAUTHOR_TAG. and the statistics are shown in the experimental results']","['on spanish - english and italian - english language pairs.', 'again, we use the same dataset with  #TAUTHOR_TAG. and the statistics are shown in the experimental results']","['english language pairs.', 'again, we use the same dataset with  #TAUTHOR_TAG. and the statistics are shown in the experimental results are shown in table 4.', '']","['also conduct experiments on spanish - english and italian - english language pairs.', 'again, we use the same dataset with  #TAUTHOR_TAG. and the statistics are shown in the experimental results are shown in table 4.', 'because spanish, italian and english are closely related languages, the accuracy would be higher than the chinese - english dataset.', 'our model is able to outperform baseline model in this setting']",5
"[' #TAUTHOR_TAG.', 'the statistics of the final training']","[' #TAUTHOR_TAG.', 'the statistics of the final training']","[' #TAUTHOR_TAG.', 'the statistics of the final training data is given in table 1.', 'we use chinese - english translation lexicon version 3. 0 ( ldc']","['this set of experiments, we use the same data as  #TAUTHOR_TAG.', 'the statistics of the final training data is given in table 1.', 'we use chinese - english translation lexicon version 3. 0 ( ldc2002l27 ) as our ground truth bilingual lexicon for evaluation.', 'the baseline models are monogiza system  #AUTHOR_TAG, translation matrix ( tm )  #AUTHOR_TAG, isometric alignment ( ia )  #AUTHOR_TAG b ) and adversarial training approach  #TAUTHOR_TAG.', 'table 2 summarizes the performance of baseline models and our approach.', 'the results of baseline models are cited from  #TAUTHOR_TAG.', 'as we can see from the table, our model could achieve superior performance compared with other baseline models']",4
"['method with  #AUTHOR_TAG, whose method improves  #TAUTHOR_TAG by more sophiscated refinement procedure and validation criterion.', 'we replace']","['method with  #AUTHOR_TAG, whose method improves  #TAUTHOR_TAG by more sophiscated refinement procedure and validation criterion.', 'we replace']","['method with  #AUTHOR_TAG, whose method improves  #TAUTHOR_TAG by more sophiscated refinement procedure and validation criterion.', 'we replace']","['this section, we integrate our method with  #AUTHOR_TAG, whose method improves  #TAUTHOR_TAG by more sophiscated refinement procedure and validation criterion.', 'we replace their first step, namely the adversarial training step, with our model.', 'basically, we first map the source and target embeddings into the latent space using our algorithm, and then fine - tune the identity mapping in the latent space with the closed - form procrustes solution.', 'we use their similarity measure, namely cross - domain similarity local scaling ( csls ), to produce reliable matching pairs and validation criterion for unsupervised model selection.', 'we conduct experiments on english - spanish, english - russian and english - chinese datasets, which are the same as  #AUTHOR_TAG.', 'the results are shown in table 5.', 'as seen, our model could consistently achieve better performance compared with adversarial training.', 'after refinement, our model could further achieve competitive and even superior results compared with state - of - the - art unsupervised methods.', 'this further demonstrates the capacity of our model']",4
"['method with  #AUTHOR_TAG, whose method improves  #TAUTHOR_TAG by more sophiscated refinement procedure and validation criterion.', 'we replace']","['method with  #AUTHOR_TAG, whose method improves  #TAUTHOR_TAG by more sophiscated refinement procedure and validation criterion.', 'we replace']","['method with  #AUTHOR_TAG, whose method improves  #TAUTHOR_TAG by more sophiscated refinement procedure and validation criterion.', 'we replace']","['this section, we integrate our method with  #AUTHOR_TAG, whose method improves  #TAUTHOR_TAG by more sophiscated refinement procedure and validation criterion.', 'we replace their first step, namely the adversarial training step, with our model.', 'basically, we first map the source and target embeddings into the latent space using our algorithm, and then fine - tune the identity mapping in the latent space with the closed - form procrustes solution.', 'we use their similarity measure, namely cross - domain similarity local scaling ( csls ), to produce reliable matching pairs and validation criterion for unsupervised model selection.', 'we conduct experiments on english - spanish, english - russian and english - chinese datasets, which are the same as  #AUTHOR_TAG.', 'the results are shown in table 5.', 'as seen, our model could consistently achieve better performance compared with adversarial training.', 'after refinement, our model could further achieve competitive and even superior results compared with state - of - the - art unsupervised methods.', 'this further demonstrates the capacity of our model']",6
"['level  #TAUTHOR_TAG.', 'in these publications, the authors use information -']","['level  #TAUTHOR_TAG.', 'in these publications, the authors use information - retrieval ( ir ) techniques']","['similar algorithms that select translation correspondences explicitly at the document level  #TAUTHOR_TAG.', 'in these publications, the authors use information -']","['paper presents a simple sentence - level translation pair extraction algorithm from comparable monolingual news data.', 'it differs from similar algorithms that select translation correspondences explicitly at the document level  #TAUTHOR_TAG.', 'in these publications, the authors use information - retrieval ( ir ) techniques to match document pairs that are likely translations of each other.', '']",4
"[': the word - overlap filter in  #TAUTHOR_TAG has been implemented : for a sentence pair ( s, t ) to be considered parallel the ratio of the lengths of the two sentences has to be smaller than two']","['sentence - level filter : the word - overlap filter in  #TAUTHOR_TAG has been implemented : for a sentence pair ( s, t ) to be considered parallel the ratio of the lengths of the two sentences has to be smaller than two. additionally,']","[': the word - overlap filter in  #TAUTHOR_TAG has been implemented : for a sentence pair ( s, t ) to be considered parallel the ratio of the lengths of the two sentences has to be smaller than two']","['', 'terms σ ( s j, t ). once the current partial sum is lower than the best score ( s, t best ) computed so far, the computation can be safely discarded as τ', '( t i, s ), σ ( s j, t ) ≤ • frequency - sorting : here, we aim at making the early pruning step more efficient. source and target words are sorted according to the source and target vocabulary frequency : less frequent words occur at', 'the beginning of a sentence. these words are likely to contribute terms with high partial scores. as a result, the early - stopping step fires earlier and becomes more', 'effective. • sentence - level filter : the word - overlap filter in  #TAUTHOR_TAG has been implemented : for a sentence pair ( s, t ) to be considered parallel the ratio of the lengths of the two sentences has to be smaller than two. additionally, at least half of the words in each sentence have to have a translation', 'in the other sentence based on the word - based lexicon. here, the implementation of the coverage restriction is tightly integrated into the above', 'implementation : the decision whether a target word is covered can be cached. likewise, source word', 'coverage can be decided by a simple array look - up']",5
"['length - based filtering and the coverage filtering without caching the coverage decisions  #TAUTHOR_TAG.', 'caching the target word probabilities results in the biggest reduction.', 'the results are representative :']","['length - based filtering and the coverage filtering without caching the coverage decisions  #TAUTHOR_TAG.', 'caching the target word probabilities results in the biggest reduction.', 'the results are representative :']","['is 61 736 sentences.', 'all the techniques presented result in some improvement.', 'the baseline uses only the length - based filtering and the coverage filtering without caching the coverage decisions  #TAUTHOR_TAG.', 'caching the target word probabilities results in the biggest reduction.', 'the results are representative']","['parallel sentence extraction algorithm presented in this paper is tested in detail on the largescale spanish - english gigaword data  #AUTHOR_TAG.', 'the spanish data comes from 3 news feeds : agence france - presse ( afp ), associated press worldstream ( apw ), and xinhua news sentences.', 'here, the size of the target candidate set θ is 61 736 sentences.', 'all the techniques presented result in some improvement.', 'the baseline uses only the length - based filtering and the coverage filtering without caching the coverage decisions  #TAUTHOR_TAG.', 'caching the target word probabilities results in the biggest reduction.', 'the results are representative : finding the highest scoring target sentence t for a given source sentence s takes about 1 second on average.', 'since 20 million source sentences are processed, and the workload is distributed over roughly 120 processors, overall processing time sums to less than 3 days.', 'here, the total number of translation pairs considered is close to 1 trillion.', 'the effect of including additional sentence pairs along with selection statistics is presented in table 3.', 'translation results are presented for a standard phrase - based smt system.', 'here, both languages use a test set with a single reference.', '']",5
"[' #TAUTHOR_TAG.', 'in']","[' #TAUTHOR_TAG.', 'in particular,']","['the document level  #TAUTHOR_TAG.', 'in']","['this paper, we have presented a novel sentencelevel pair extraction algorithm for comparable data.', 'we use a simple symmetrized scoring function based on the model - 1 translation probability.', 'with the help of an efficient implementation, it avoids any translation candidate selection at the document level  #TAUTHOR_TAG.', '']",5
"[' #TAUTHOR_TAG.', 'in']","[' #TAUTHOR_TAG.', 'in particular,']","['the document level  #TAUTHOR_TAG.', 'in']","['this paper, we have presented a novel sentencelevel pair extraction algorithm for comparable data.', 'we use a simple symmetrized scoring function based on the model - 1 translation probability.', 'with the help of an efficient implementation, it avoids any translation candidate selection at the document level  #TAUTHOR_TAG.', '']",5
['perplexity on the writingprompts  #TAUTHOR_TAG story generation dataset'],['reasoning and state - of - the - art perplexity on the writingprompts  #TAUTHOR_TAG story generation dataset'],['- of - the - art perplexity on the writingprompts  #TAUTHOR_TAG story generation dataset'],"['generated with neural language models have shown promise in grammatical and stylistic consistency.', 'however, the generated stories are still lacking in common sense reasoning, e. g., they often contain sentences deprived of world knowledge.', 'we propose a simple multi - task learning scheme to achieve quantitatively better common sense reasoning in language models by leveraging auxiliary training signals from datasets designed to provide common sense grounding.', 'when combined with our two - stage fine - tuning pipeline, our method achieves improved common sense reasoning and state - of - the - art perplexity on the writingprompts  #TAUTHOR_TAG story generation dataset']",5
"['on', 'the writingprompts  #TAUTHOR_TAG our primary task is to']","['perplexity on', 'the writingprompts  #TAUTHOR_TAG our primary task is to']","['perplexity on', 'the writingprompts  #TAUTHOR_TAG our primary task is to']","['', 'the writingprompts  #TAUTHOR_TAG our primary task is to perform language modeling  #AUTHOR_TAG on the writingprompts dataset. a language model learns to assign the probability of a text sequence x = x 1,..., x t using the conditional probability factorization : we', 'train our model using a standard cross - entropy loss between next - step true tokens and predicted probabilities given current tokens. writingprompts  #TAUTHOR_TAG is a dataset of prompts and short stories crawled from reddi', '##t. the aim of the dataset is to produce a story given a free - text prompt. we reduce this conditional text generation task into a generic language modeling task by simply concatenating the prompt before the story and treating a prompt - story pair as one input to the transformer decoder model. this human', '- readable format ( example in figure 1 ) is chosen because gpt2 may have been trained on similarly formatted text from the web.', 'when sampling, we can either seed the model with a prompt or allow it to generate its own prompt']",5
"['in  #TAUTHOR_TAG.', 'we estimate the']","['in  #TAUTHOR_TAG.', 'we estimate the']","['in  #TAUTHOR_TAG.', ""we estimate the corresponding word - level perplexity by taking the product of each subword's probabilities to""]","['perform three types of evaluation on the model to assess its readability, reliance on the prompt ( prompt ranking ) and csr.', 'readability is measured in terms of model perplexity on the test set of writingprompts.', 'because gpt2 uses subword tokenization  #AUTHOR_TAG, it is not directly comparable to the wordlevel perplexity obtained in  #TAUTHOR_TAG.', ""we estimate the corresponding word - level perplexity by taking the product of each subword's probabilities to obtain probabilities for each word."", 'both sub - word perplexity and word - level perplexities are reported in our experiments.', 'prompt ranking  #TAUTHOR_TAG assesses how well a model matches a story to its given prompt.', 'this is measured by computing the likelihood of stories conditioned under ten different prompts, nine of which are randomly sampled and one is the true prompt.', 'following  #TAUTHOR_TAG, we count a random story sample as correct when it ranks the true prompt with the lowest perplexity.', 'we compute the accuracy from 1000 random samples.', 'csr is evaluated on two multiple choice datasets - swag and story cloze  #AUTHOR_TAG.', '']",5
"['were going to get out of there. there were', 'bodies everywhere. table 4 : sample generated by gpt2 → bc →', 'wp + swag + synth primed', 'with the same prompt as  #TAUTHOR_TAG']","['t know', 'how they were going to get out of there. there were', 'bodies everywhere. table 4 : sample generated by gpt2 → bc →', 'wp + swag + synth primed', 'with the same prompt as  #TAUTHOR_TAG']","['were going to get out of there. there were', 'bodies everywhere. table 4 : sample generated by gpt2 → bc →', 'wp + swag + synth primed', 'with the same prompt as  #TAUTHOR_TAG']","['', 'still haven\'t gotten past this door, "" the ex said, resting a hand on the ufo that stood in the doorway. "" i\'m fine', '. "" "" good! i\'ve never seen anything like it, have i steve? "" steve stood up. "" yes i have. "" he picked up his controller. "" ok, shoot! "" the aliens yelled. "" this is no time to hesitate. "" steve put the controller to his ear. "" who are you? what are you doing here? "" the aliens pulled the gun towards him. "" we - we\'re here to kidnap you. "" steve put his hands on the ufo, and pulled the trigger. the gun went off. the aliens, scared, immediately realized where they were and ran towards the other two aliens. they kept running. steve continued on his way towards his childhood toy house. when he was just a teen, he had built his own helicopter. he always felt they had lost. the abandoned building on the edge', 'of the highway he and', ""the ex had entered had been the perfect landing spot. he didn't know where they were. he"", ""didn't know"", 'how they were going to get out of there. there were', 'bodies everywhere. table 4 : sample generated by gpt2 → bc →', 'wp + swag + synth primed', 'with the same prompt as  #TAUTHOR_TAG']",5
"['on', 'the writingprompts  #TAUTHOR_TAG our primary task is to']","['perplexity on', 'the writingprompts  #TAUTHOR_TAG our primary task is to']","['perplexity on', 'the writingprompts  #TAUTHOR_TAG our primary task is to']","['', 'the writingprompts  #TAUTHOR_TAG our primary task is to perform language modeling  #AUTHOR_TAG on the writingprompts dataset. a language model learns to assign the probability of a text sequence x = x 1,..., x t using the conditional probability factorization : we', 'train our model using a standard cross - entropy loss between next - step true tokens and predicted probabilities given current tokens. writingprompts  #TAUTHOR_TAG is a dataset of prompts and short stories crawled from reddi', '##t. the aim of the dataset is to produce a story given a free - text prompt. we reduce this conditional text generation task into a generic language modeling task by simply concatenating the prompt before the story and treating a prompt - story pair as one input to the transformer decoder model. this human', '- readable format ( example in figure 1 ) is chosen because gpt2 may have been trained on similarly formatted text from the web.', 'when sampling, we can either seed the model with a prompt or allow it to generate its own prompt']",0
"['in  #TAUTHOR_TAG.', 'we estimate the']","['in  #TAUTHOR_TAG.', 'we estimate the']","['in  #TAUTHOR_TAG.', ""we estimate the corresponding word - level perplexity by taking the product of each subword's probabilities to""]","['perform three types of evaluation on the model to assess its readability, reliance on the prompt ( prompt ranking ) and csr.', 'readability is measured in terms of model perplexity on the test set of writingprompts.', 'because gpt2 uses subword tokenization  #AUTHOR_TAG, it is not directly comparable to the wordlevel perplexity obtained in  #TAUTHOR_TAG.', ""we estimate the corresponding word - level perplexity by taking the product of each subword's probabilities to obtain probabilities for each word."", 'both sub - word perplexity and word - level perplexities are reported in our experiments.', 'prompt ranking  #TAUTHOR_TAG assesses how well a model matches a story to its given prompt.', 'this is measured by computing the likelihood of stories conditioned under ten different prompts, nine of which are randomly sampled and one is the true prompt.', 'following  #TAUTHOR_TAG, we count a random story sample as correct when it ranks the true prompt with the lowest perplexity.', 'we compute the accuracy from 1000 random samples.', 'csr is evaluated on two multiple choice datasets - swag and story cloze  #AUTHOR_TAG.', '']",0
"['in  #TAUTHOR_TAG.', 'we estimate the']","['in  #TAUTHOR_TAG.', 'we estimate the']","['in  #TAUTHOR_TAG.', ""we estimate the corresponding word - level perplexity by taking the product of each subword's probabilities to""]","['perform three types of evaluation on the model to assess its readability, reliance on the prompt ( prompt ranking ) and csr.', 'readability is measured in terms of model perplexity on the test set of writingprompts.', 'because gpt2 uses subword tokenization  #AUTHOR_TAG, it is not directly comparable to the wordlevel perplexity obtained in  #TAUTHOR_TAG.', ""we estimate the corresponding word - level perplexity by taking the product of each subword's probabilities to obtain probabilities for each word."", 'both sub - word perplexity and word - level perplexities are reported in our experiments.', 'prompt ranking  #TAUTHOR_TAG assesses how well a model matches a story to its given prompt.', 'this is measured by computing the likelihood of stories conditioned under ten different prompts, nine of which are randomly sampled and one is the true prompt.', 'following  #TAUTHOR_TAG, we count a random story sample as correct when it ranks the true prompt with the lowest perplexity.', 'we compute the accuracy from 1000 random samples.', 'csr is evaluated on two multiple choice datasets - swag and story cloze  #AUTHOR_TAG.', '']",0
"['in neural story generation  #AUTHOR_TAG has shown success in using hierarchical methods  #TAUTHOR_TAG to generate stories.', 'in these schemes, a neural architecture is engineered to first generate an outline or a prompt, then to expand the prompt into a full - length story.', 'our']","['in neural story generation  #AUTHOR_TAG has shown success in using hierarchical methods  #TAUTHOR_TAG to generate stories.', 'in these schemes, a neural architecture is engineered to first generate an outline or a prompt, then to expand the prompt into a full - length story.', 'our']","['generation : recent work in neural story generation  #AUTHOR_TAG has shown success in using hierarchical methods  #TAUTHOR_TAG to generate stories.', 'in these schemes, a neural architecture is engineered to first generate an outline or a prompt, then to expand the prompt into a full - length story.', 'our']","['generation : recent work in neural story generation  #AUTHOR_TAG has shown success in using hierarchical methods  #TAUTHOR_TAG to generate stories.', 'in these schemes, a neural architecture is engineered to first generate an outline or a prompt, then to expand the prompt into a full - length story.', 'our work performs hierarchical generation, but our main focus is on achieving better common sense in the generated text rather than engineering task - specific architectures.', 'common sense reasoning : common sense reasoning ( csr ) has been studied through many benchmarks such as swag  #AUTHOR_TAG, story cloze  #AUTHOR_TAG, the winograd schema challenge  #AUTHOR_TAG, and commonsenseqa  #AUTHOR_TAG.', 'recent methods  #AUTHOR_TAG on these benchmarks focus on large - scale pre - training of language models.', 'they show that transfer learning is an effective means to improve csr and our fine - tuning pipeline builds upon these techniques.', 'our results on swag and story cloze are far from state - of - the - art  #AUTHOR_TAG.', 'however, our aim is not to directly tackle swag or story cloze, but instead to use it as a constraint on our model and a proxy to estimate the likelihood of generating sensible text.', 'multi - task learning : multi - task learning ( mtl ) introduces inductive bias in a model, helps reduce overfitting and increases robustness  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'our work builds upon mtl principles as we introduce auxiliary tasks to specifically tackle csr ( søgaard and  #AUTHOR_TAG.', 'contrary to conventional auxiliary multi - task learning  #AUTHOR_TAG, which adds an additional classifier to the final representations of the model for learning auxiliary tasks, we use perplexity ranking, which does not introduce additional parameters.', 'we argue that perplexity ranking, by definition, guarantees that the model will generate sensible text with a higher probability']",0
"['model  #TAUTHOR_TAG,']","['model  #TAUTHOR_TAG,']","['models with the attention - based fusion model  #TAUTHOR_TAG,']","['', 'we also generate stories by sampling from our model using nucleus sampling with p = 0. 9  #AUTHOR_TAG.', 'we present example story completions in table 2 and full sampled stories in our appendix and table 4.', 'pre - training : we compare our models with the attention - based fusion model  #TAUTHOR_TAG, which has been designed for and trained on writingprompts.', 'we observe that a pre - trained gpt2 performing zero - shot inference on writingprompts ( gpt2 in table 3 ) is a strong baseline.', 'by fine - tuning gpt2 on writingprompts ( gpt2 → wp ), we outperform the fusion model in perplexity.', 'all our models outperform the fusion model in prompt ranking, which suggests that task - specific models are unnecessary given pretraining.', 'intermediate fine - tuning : the first stage in our pipeline performs intermediate fine - tuning of gpt2 on bookcorpus ( gpt2 → bc in table 3 ).', 'to confirm that intermediate fine - tuning helps downstream performance, we evaluate the zero - shot performance of the model on writingprompts.', '']",7
"['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['models defining joint distributions over parse trees and sentences are good theoretical models for interpreting natural language data, and appealing tools for tasks such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they often impose strong independence assumptions which restrict the use of arbitrary features for effective disambiguation.', 'moreover, generative parsers are typically trained by maximizing the joint probability of the parse tree and the sentence - an objective that only indirectly relates to the goal of parsing.', 'at test time, these models require a relatively expensive recognition algo - 1 our code is available at https : / / github. com / cheng6076 / virnng. git.', 'rithm  #AUTHOR_TAG to recover the parse tree, but the parsing performance consistently lags behind their discriminative competitors  #AUTHOR_TAG, which are directly trained to maximize the conditional probability of the parse tree given the sentence, where linear - time decoding algorithms exist ( e. g., for transition - based parsers ).', 'in this work, we propose a parsing and language modeling framework that marries a generative model with a discriminative recognition algorithm in order to have the best of both worlds.', 'the idea of combining these two types of models is not new.', '']",0
"['importance sampling  #TAUTHOR_TAG.', 'consider a']","['importance sampling  #TAUTHOR_TAG.', 'consider a']","['importance sampling  #TAUTHOR_TAG.', 'consider a simple directed graphical model with discrete latent variables a (']","['proposed a framework that integrates a generative parser with a discriminative recognition model and showed how it can be instantiated with rnngs.', 'we demonstrated that a unified framework, which relates to expectation maximization and variational inference, enables effective parsing and language modeling algorithms.', 'evaluation on the english penn treebank, revealed that our framework obtains competitive performance on constituency parsing and state - of - the - art results on single - model language modeling.', 'in the future, we would like to perform grammar induction based on equation ( 8 ), with gradient descent and posterior regularization techniques  #AUTHOR_TAG a comparison to importance sampling  #TAUTHOR_TAG.', 'consider a simple directed graphical model with discrete latent variables a ( e. g., a is the transition action sequence ) and observed variables x ( e. g., x is the sentence ).', 'the model evidence, or the marginal likelihood p ( x ) = a p ( x, a ) is often intractable to compute.', 'importance sampling transforms the above quantity into an expectation over a distribution q ( a ), which is known and easy to sample from :', 'where q ( a ) is the proposal distribution and w ( x, a ) = p ( x, a ) q ( a ) the importance weight.', '']",0
"['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['models defining joint distributions over parse trees and sentences are good theoretical models for interpreting natural language data, and appealing tools for tasks such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they often impose strong independence assumptions which restrict the use of arbitrary features for effective disambiguation.', 'moreover, generative parsers are typically trained by maximizing the joint probability of the parse tree and the sentence - an objective that only indirectly relates to the goal of parsing.', 'at test time, these models require a relatively expensive recognition algo - 1 our code is available at https : / / github. com / cheng6076 / virnng. git.', 'rithm  #AUTHOR_TAG to recover the parse tree, but the parsing performance consistently lags behind their discriminative competitors  #AUTHOR_TAG, which are directly trained to maximize the conditional probability of the parse tree given the sentence, where linear - time decoding algorithms exist ( e. g., for transition - based parsers ).', 'in this work, we propose a parsing and language modeling framework that marries a generative model with a discriminative recognition algorithm in order to have the best of both worlds.', 'the idea of combining these two types of models is not new.', '']",1
"['importance sampling  #TAUTHOR_TAG.', 'consider a']","['importance sampling  #TAUTHOR_TAG.', 'consider a']","['importance sampling  #TAUTHOR_TAG.', 'consider a simple directed graphical model with discrete latent variables a (']","['proposed a framework that integrates a generative parser with a discriminative recognition model and showed how it can be instantiated with rnngs.', 'we demonstrated that a unified framework, which relates to expectation maximization and variational inference, enables effective parsing and language modeling algorithms.', 'evaluation on the english penn treebank, revealed that our framework obtains competitive performance on constituency parsing and state - of - the - art results on single - model language modeling.', 'in the future, we would like to perform grammar induction based on equation ( 8 ), with gradient descent and posterior regularization techniques  #AUTHOR_TAG a comparison to importance sampling  #TAUTHOR_TAG.', 'consider a simple directed graphical model with discrete latent variables a ( e. g., a is the transition action sequence ) and observed variables x ( e. g., x is the sentence ).', 'the model evidence, or the marginal likelihood p ( x ) = a p ( x, a ) is often intractable to compute.', 'importance sampling transforms the above quantity into an expectation over a distribution q ( a ), which is known and easy to sample from :', 'where q ( a ) is the proposal distribution and w ( x, a ) = p ( x, a ) q ( a ) the importance weight.', '']",1
"['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they']","['models defining joint distributions over parse trees and sentences are good theoretical models for interpreting natural language data, and appealing tools for tasks such as parsing, grammar induction and language modeling  #TAUTHOR_TAG.', 'however, they often impose strong independence assumptions which restrict the use of arbitrary features for effective disambiguation.', 'moreover, generative parsers are typically trained by maximizing the joint probability of the parse tree and the sentence - an objective that only indirectly relates to the goal of parsing.', 'at test time, these models require a relatively expensive recognition algo - 1 our code is available at https : / / github. com / cheng6076 / virnng. git.', 'rithm  #AUTHOR_TAG to recover the parse tree, but the parsing performance consistently lags behind their discriminative competitors  #AUTHOR_TAG, which are directly trained to maximize the conditional probability of the parse tree given the sentence, where linear - time decoding algorithms exist ( e. g., for transition - based parsers ).', 'in this work, we propose a parsing and language modeling framework that marries a generative model with a discriminative recognition algorithm in order to have the best of both worlds.', 'the idea of combining these two types of models is not new.', '']",5
"['##s ;  #TAUTHOR_TAG, a']","['describe recurrent neural network grammars ( rnngs ;  #TAUTHOR_TAG, a top - down transition - based algorithm for parsing']","['##s ;  #TAUTHOR_TAG, a top - down transition - based algorithm for parsing']","['this section we briefly describe recurrent neural network grammars ( rnngs ;  #TAUTHOR_TAG, a top - down transition - based algorithm for parsing and generation.', 'there are two versions of rnng, one discriminative, the other generative.', 'we follow the original paper in presenting the discriminative variant first.', '']",5
['with a stack - lstm  #TAUTHOR_TAG'],['with a stack - lstm  #TAUTHOR_TAG'],['the stack embedding d t which encodes the stack of the decoder and is obtained with a stack - lstm  #TAUTHOR_TAG'],"['decoder is a generative rnng that models the joint probability p ( x, y ) of a latent parse tree y and an observed sentence x. since the parse tree is defined by a sequence of transition actions a, we write p ( x, y ) as p ( x, a ).', '3 the joint distribution p ( x, a ) is factorized into a sequence of transition probabilities and terminal probabilities ( when actions are gen ), which are parametrized by a transitional state embedding u :', 'where i is an indicator function and u t represents the state embedding at time step t. specifically, the conditional probability of the next action is :', 'where a t represents the action embedding at time step t, a the action space and b a the bias.', 'similarly, the next word probability ( when gen is invoked ) is computed as :', 'where w denotes all words in the vocabulary.', 'to satisfy the independence assumptions imposed by the generative model, u t uses only a restricted set of features defined over the output buffer and the stack - we consider p ( a ) as a context insensitive prior distribution.', 'specifically, we use the following features : 1 ) the stack embedding d t which encodes the stack of the decoder and is obtained with a stack - lstm  #TAUTHOR_TAG ; 2 ) the output buffer embedding o t ; we use a standard lstm to compose the output buffer and o t is represented as the most recent state of the lstm ; and 3 ) the parent non - terminal embedding n t which is accessible in the generative model because the rnng employs a depth - first generation order.', 'finally, u t is computed as :', 'where ws are weight parameters and b d the bias']",5
"['objective is :', 'where l x and l a can be balanced with the task focus ( e. g, language modeling or parsing ).', '5 here, gen and shift refer to the same action with different definitions for encoding and decoding.', '6 see § 4 and appendix a for comparison between this objective and the importance sampler of']","['objective is :', 'where l x and l a can be balanced with the task focus ( e. g, language modeling or parsing ).', '5 here, gen and shift refer to the same action with different definitions for encoding and decoding.', '6 see § 4 and appendix a for comparison between this objective and the importance sampler of']","['the distribution q ( a | x ) and p ( a ), and the final objective is :', 'where l x and l a can be balanced with the task focus ( e. g, language modeling or parsing ).', '5 here, gen and shift refer to the same action with different definitions for encoding and decoding.', '6 see § 4 and appendix a for comparison between this objective and the importance sampler of']","['an auto - encoder whose encoder infers the latent parse tree and the decoder generates the observed sentence from the parse tree.', '5 the maximum likelihood estimate of the decoder parameters is determined by the log marginal likelihood of the sentence :', ""we follow expectation - maximization and variational inference techniques to construct an evidence lower bound of the above quantity ( by jensen's inequality ), denoted as follows :"", 'where p ( x, a ) = p ( x | a ) p ( a ) comes from the decoder or the generative model, and q ( a | x ) comes from the encoder or the recognition model.', 'the objective function 6 in equation ( 8 ), denoted by l x, is unsupervised and suited to a grammar induction task.', 'this objective can be optimized with the methods shown in.', 'next, consider the case when the parse tree is observed.', 'we can directly maximize the log likelihood of the parse tree for the encoder output log q ( a | x ) and the decoder output log p ( a ) :', 'this supervised objective leverages extra information of labeled parse trees to regularize the distribution q ( a | x ) and p ( a ), and the final objective is :', 'where l x and l a can be balanced with the task focus ( e. g, language modeling or parsing ).', '5 here, gen and shift refer to the same action with different definitions for encoding and decoding.', '6 see § 4 and appendix a for comparison between this objective and the importance sampler of']",5
"['to use the variational approximation q ( a | x ) as the proposal distribution as in the importance sampler of  #TAUTHOR_TAG.', 'we discuss details in appendix a']","['to use the variational approximation q ( a | x ) as the proposal distribution as in the importance sampler of  #TAUTHOR_TAG.', 'we discuss details in appendix a']","['a pessimistic approximation of p ( x ).', '7 another way of computing p ( x ) ( without lower bounding ) would be to use the variational approximation q ( a | x ) as the proposal distribution as in the importance sampler of  #TAUTHOR_TAG.', 'we discuss details in appendix a']","['consider two inference tasks, namely parsing and language modeling.', 'parsing in parsing, we are interested in the parse tree that maximizes the posterior p ( a | x ) ( or the joint p ( a, x ) ).', 'however, the decoder alone does not have a bottom - up recognition mechanism for computing the posterior.', 'thanks to the encoder, we can compute an approximated posterior q ( a | x ) in linear time and select the parse tree that maximizes this approximation.', 'an alternative is to generate candidate trees by sampling from q ( a | x ), re - rank them with respect to the joint p ( x, a ) ( which is proportional to the true posterior ), and select the sample that maximizes the true posterior.', 'language modeling in language modeling, our goal is to compute the marginal probability p ( x ) = a p ( x, a ), which is typically intractable.', 'to approximate this quantity, we can use equation ( 8 ) to compute a lower bound of the log likelihood log p ( x ) and then exponentiate it to get a pessimistic approximation of p ( x ).', '7 another way of computing p ( x ) ( without lower bounding ) would be to use the variational approximation q ( a | x ) as the proposal distribution as in the importance sampler of  #TAUTHOR_TAG.', 'we discuss details in appendix a']",5
"['with the importance - sampling based inference of  #TAUTHOR_TAG.', 'there, a generative rnng and a discriminative rnng are trained separately ; during language modeling, the']","['with the importance - sampling based inference of  #TAUTHOR_TAG.', 'there, a generative rnng and a discriminative rnng are trained separately ; during language modeling, the']","['a discriminative parser.', 'further connections can be drawn with the importance - sampling based inference of  #TAUTHOR_TAG.', 'there, a generative rnng and a discriminative rnng are trained separately ; during language modeling, the output of the discriminative model serves as the proposal distribution of an importance sampler p ( x ) = e q ( a | x )', 'p ( x, a ) q ( a | x ).', 'compared to their']","['framework is related to a class of variational autoencoders, which use neural networks for posterior approximation in variational inference.', 'this technique has been previously used for topic modeling and sentence compression discriminative parsers  #AUTHOR_TAG 90. 4  #AUTHOR_TAG 90.', '4  #AUTHOR_TAG 91. 7  #AUTHOR_TAG 89. 9  #AUTHOR_TAG 92. 8', 'generative parsers  #AUTHOR_TAG 90.', '1  #AUTHOR_TAG 92.', '4  #AUTHOR_TAG 93. 3', 'this work argmax a q ( a | x ) 89. 3 argmax a p ( a, x ) 90. 1 table 2 : parsing results ( f1 ) on the ptb test set..', 'another interpretation of the proposed framework is from the perspective of guided policy search in reinforcement learning  #AUTHOR_TAG, where a generative parser is trained to imitate the trace of a discriminative parser.', 'further connections can be drawn with the importance - sampling based inference of  #TAUTHOR_TAG.', 'there, a generative rnng and a discriminative rnng are trained separately ; during language modeling, the output of the discriminative model serves as the proposal distribution of an importance sampler p ( x ) = e q ( a | x )', 'p ( x, a ) q ( a | x ).', 'compared to their work, we unify the generative and discriminative rnngs in a single framework, and adopt a joint training objective']",5
"['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['performed experiments on the english penn treebank dataset ; we used sections 2 - 21 for training, 24 for validation, and 23 for testing.', ' #AUTHOR_TAG, we represent each word in three ways : as a learned vector, a pretrained vector, and a pos tag vector.', 'the encoder word embedding is the concatenation of all three vectors while the decoder uses only the first two since we do not consider pos tags in generation.', 'table 1 presents details on the hyper - parameters we used.', 'to find the map parse tree argmax a p ( a, x ) ( where p ( a, x ) is used rank the output of q ( a | x ) ) and to compute the language modeling perplexity ( where a ∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2 and 3, respectively.', 'as can be seen, the single framework we propose obtains competitive parsing performance.', 'comparing the two inference kn - 5 255. 2 lstm 113.', '4  #AUTHOR_TAG 102. 4 this work : a ∼ q ( a | x ) 99. 8 table 3 : language modeling results ( perplexity ).', '']",5
"['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['performed experiments on the english penn treebank dataset ; we used sections 2 - 21 for training, 24 for validation, and 23 for testing.', ' #AUTHOR_TAG, we represent each word in three ways : as a learned vector, a pretrained vector, and a pos tag vector.', 'the encoder word embedding is the concatenation of all three vectors while the decoder uses only the first two since we do not consider pos tags in generation.', 'table 1 presents details on the hyper - parameters we used.', 'to find the map parse tree argmax a p ( a, x ) ( where p ( a, x ) is used rank the output of q ( a | x ) ) and to compute the language modeling perplexity ( where a ∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2 and 3, respectively.', 'as can be seen, the single framework we propose obtains competitive parsing performance.', 'comparing the two inference kn - 5 255. 2 lstm 113.', '4  #AUTHOR_TAG 102. 4 this work : a ∼ q ( a | x ) 99. 8 table 3 : language modeling results ( perplexity ).', '']",5
"['importance sampling  #TAUTHOR_TAG.', 'consider a']","['importance sampling  #TAUTHOR_TAG.', 'consider a']","['importance sampling  #TAUTHOR_TAG.', 'consider a simple directed graphical model with discrete latent variables a (']","['proposed a framework that integrates a generative parser with a discriminative recognition model and showed how it can be instantiated with rnngs.', 'we demonstrated that a unified framework, which relates to expectation maximization and variational inference, enables effective parsing and language modeling algorithms.', 'evaluation on the english penn treebank, revealed that our framework obtains competitive performance on constituency parsing and state - of - the - art results on single - model language modeling.', 'in the future, we would like to perform grammar induction based on equation ( 8 ), with gradient descent and posterior regularization techniques  #AUTHOR_TAG a comparison to importance sampling  #TAUTHOR_TAG.', 'consider a simple directed graphical model with discrete latent variables a ( e. g., a is the transition action sequence ) and observed variables x ( e. g., x is the sentence ).', 'the model evidence, or the marginal likelihood p ( x ) = a p ( x, a ) is often intractable to compute.', 'importance sampling transforms the above quantity into an expectation over a distribution q ( a ), which is known and easy to sample from :', 'where q ( a ) is the proposal distribution and w ( x, a ) = p ( x, a ) q ( a ) the importance weight.', '']",5
"['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['performed experiments on the english penn treebank dataset ; we used sections 2 - 21 for training, 24 for validation, and 23 for testing.', ' #AUTHOR_TAG, we represent each word in three ways : as a learned vector, a pretrained vector, and a pos tag vector.', 'the encoder word embedding is the concatenation of all three vectors while the decoder uses only the first two since we do not consider pos tags in generation.', 'table 1 presents details on the hyper - parameters we used.', 'to find the map parse tree argmax a p ( a, x ) ( where p ( a, x ) is used rank the output of q ( a | x ) ) and to compute the language modeling perplexity ( where a ∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2 and 3, respectively.', 'as can be seen, the single framework we propose obtains competitive parsing performance.', 'comparing the two inference kn - 5 255. 2 lstm 113.', '4  #AUTHOR_TAG 102. 4 this work : a ∼ q ( a | x ) 99. 8 table 3 : language modeling results ( perplexity ).', '']",4
"['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['performed experiments on the english penn treebank dataset ; we used sections 2 - 21 for training, 24 for validation, and 23 for testing.', ' #AUTHOR_TAG, we represent each word in three ways : as a learned vector, a pretrained vector, and a pos tag vector.', 'the encoder word embedding is the concatenation of all three vectors while the decoder uses only the first two since we do not consider pos tags in generation.', 'table 1 presents details on the hyper - parameters we used.', 'to find the map parse tree argmax a p ( a, x ) ( where p ( a, x ) is used rank the output of q ( a | x ) ) and to compute the language modeling perplexity ( where a ∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2 and 3, respectively.', 'as can be seen, the single framework we propose obtains competitive parsing performance.', 'comparing the two inference kn - 5 255. 2 lstm 113.', '4  #AUTHOR_TAG 102. 4 this work : a ∼ q ( a | x ) 99. 8 table 3 : language modeling results ( perplexity ).', '']",4
"['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['performed experiments on the english penn treebank dataset ; we used sections 2 - 21 for training, 24 for validation, and 23 for testing.', ' #AUTHOR_TAG, we represent each word in three ways : as a learned vector, a pretrained vector, and a pos tag vector.', 'the encoder word embedding is the concatenation of all three vectors while the decoder uses only the first two since we do not consider pos tags in generation.', 'table 1 presents details on the hyper - parameters we used.', 'to find the map parse tree argmax a p ( a, x ) ( where p ( a, x ) is used rank the output of q ( a | x ) ) and to compute the language modeling perplexity ( where a ∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2 and 3, respectively.', 'as can be seen, the single framework we propose obtains competitive parsing performance.', 'comparing the two inference kn - 5 255. 2 lstm 113.', '4  #AUTHOR_TAG 102. 4 this work : a ∼ q ( a | x ) 99. 8 table 3 : language modeling results ( perplexity ).', '']",4
"['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['performed experiments on the english penn treebank dataset ; we used sections 2 - 21 for training, 24 for validation, and 23 for testing.', ' #AUTHOR_TAG, we represent each word in three ways : as a learned vector, a pretrained vector, and a pos tag vector.', 'the encoder word embedding is the concatenation of all three vectors while the decoder uses only the first two since we do not consider pos tags in generation.', 'table 1 presents details on the hyper - parameters we used.', 'to find the map parse tree argmax a p ( a, x ) ( where p ( a, x ) is used rank the output of q ( a | x ) ) and to compute the language modeling perplexity ( where a ∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2 and 3, respectively.', 'as can be seen, the single framework we propose obtains competitive parsing performance.', 'comparing the two inference kn - 5 255. 2 lstm 113.', '4  #AUTHOR_TAG 102. 4 this work : a ∼ q ( a | x ) 99. 8 table 3 : language modeling results ( perplexity ).', '']",4
"['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['performed experiments on the english penn treebank dataset ; we used sections 2 - 21 for training, 24 for validation, and 23 for testing.', ' #AUTHOR_TAG, we represent each word in three ways : as a learned vector, a pretrained vector, and a pos tag vector.', 'the encoder word embedding is the concatenation of all three vectors while the decoder uses only the first two since we do not consider pos tags in generation.', 'table 1 presents details on the hyper - parameters we used.', 'to find the map parse tree argmax a p ( a, x ) ( where p ( a, x ) is used rank the output of q ( a | x ) ) and to compute the language modeling perplexity ( where a ∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2 and 3, respectively.', 'as can be seen, the single framework we propose obtains competitive parsing performance.', 'comparing the two inference kn - 5 255. 2 lstm 113.', '4  #AUTHOR_TAG 102. 4 this work : a ∼ q ( a | x ) 99. 8 table 3 : language modeling results ( perplexity ).', '']",4
"['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2']","['performed experiments on the english penn treebank dataset ; we used sections 2 - 21 for training, 24 for validation, and 23 for testing.', ' #AUTHOR_TAG, we represent each word in three ways : as a learned vector, a pretrained vector, and a pos tag vector.', 'the encoder word embedding is the concatenation of all three vectors while the decoder uses only the first two since we do not consider pos tags in generation.', 'table 1 presents details on the hyper - parameters we used.', 'to find the map parse tree argmax a p ( a, x ) ( where p ( a, x ) is used rank the output of q ( a | x ) ) and to compute the language modeling perplexity ( where a ∼ q ( a | x ) ), we collect 100 samples from q ( a | x ), same as  #TAUTHOR_TAG.', 'experimental results for constituency parsing and language modeling are shown in tables 2 and 3, respectively.', 'as can be seen, the single framework we propose obtains competitive parsing performance.', 'comparing the two inference kn - 5 255. 2 lstm 113.', '4  #AUTHOR_TAG 102. 4 this work : a ∼ q ( a | x ) 99. 8 table 3 : language modeling results ( perplexity ).', '']",3
['following the work of  #TAUTHOR_TAG'],['following the work of  #TAUTHOR_TAG'],"['from natural language questions following the work of  #TAUTHOR_TAG.', 'second, paraphrases of logical forms and questions']","['in natural language processing tasks have gained momentum in recent years due to the increasingly popular neural network methods.', 'in this paper, we explore deep learning techniques for answering multi - step reasoning questions that operate on semi - structured tables.', 'challenges here arise from the level of logical compositionality expressed by questions, as well as the domain openness.', 'our approach is weakly supervised, trained on question - answer - table triples without requiring intermediate strong supervision.', 'it performs two phases : first, machine understandable logical forms ( programs ) are generated from natural language questions following the work of  #TAUTHOR_TAG.', 'second, paraphrases of logical forms and questions are embedded in a jointly learned vector space using word and character convolutional neural networks.', 'a neural scoring function is further used to rank and retrieve the most probable logical form ( interpretation ) of a question.', 'our best single model achieves 34. 8 % accuracy on the wikitablequestions dataset, while the best ensemble of our models pushes the state - of - the - art score on this task to 38. 7 %, thus slightly surpassing both the engineered feature scoring baseline, as well as the neural programmer model of  #TAUTHOR_TAG']",5
"['g.  #TAUTHOR_TAG.', 'unsur']","['specific topic ( e. g.  #TAUTHOR_TAG.', 'unsurprisingly,']","['g.  #TAUTHOR_TAG.', 'unsur']",[' #TAUTHOR_TAG'],5
"['g.  #TAUTHOR_TAG.', 'unsur']","['specific topic ( e. g.  #TAUTHOR_TAG.', 'unsurprisingly,']","['g.  #TAUTHOR_TAG.', 'unsur']",[' #TAUTHOR_TAG'],5
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",5
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",5
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",5
['a set of candidate logical forms { z i } i∈iq is generated using the method of  #TAUTHOR_TAG'],[': i ) a set of candidate logical forms { z i } i∈iq is generated using the method of  #TAUTHOR_TAG'],['a set of candidate logical forms { z i } i∈iq is generated using the method of  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
['a set of candidate logical forms { z i } i∈iq is generated using the method of  #TAUTHOR_TAG'],[': i ) a set of candidate logical forms { z i } i∈iq is generated using the method of  #TAUTHOR_TAG'],['a set of candidate logical forms { z i } i∈iq is generated using the method of  #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],5
['be found in  #TAUTHOR_TAG'],['be found in  #TAUTHOR_TAG'],"['', 'details about lambda dcs language can be found in  #TAUTHOR_TAG return t t is']",[' #TAUTHOR_TAG'],5
['neural programmer  #TAUTHOR_TAG baselines'],"['neural programmer  #TAUTHOR_TAG baselines.', 'the best']","['neural programmer  #TAUTHOR_TAG baselines.', 'the best performing single model is a linear combination between bi - linear and fc models, namely cnn - fc - bilinear - sep, that gives an accuracy of 34. 8']","['', 'all hyperparameters are tunned on the development data split of the wiki - tablequestions table.', 'we evaluate the model every 500 steps on the validation set, and choose the best performing model after reaching 50, 000 training steps using the early stopping procedure.', 'each model variant is trained eight times and the best one of each variant is eventually run against the test set.', 'table 1 shows the performance of our models compared to neural programmer  #TAUTHOR_TAG baselines.', 'the best performing single model is a linear combination between bi - linear and fc models, namely cnn - fc - bilinear - sep, that gives an accuracy of 34. 8 %.', 'one explanation for this is that the two methods are able to recover different types of errors.', 'our best final model is an ensemble of 15 single models, reaching a state - of - the - art accuracy for this task of 38. 7 %.', 'the score of the ensemble is calculated by averaging over the normalized scores of its constituents.', 'the significant increase in performance of the ensemble over the single model shows that the different models learn unique features']",5
['following the work of  #TAUTHOR_TAG'],['following the work of  #TAUTHOR_TAG'],"['from natural language questions following the work of  #TAUTHOR_TAG.', 'second, paraphrases of logical forms and questions']","['in natural language processing tasks have gained momentum in recent years due to the increasingly popular neural network methods.', 'in this paper, we explore deep learning techniques for answering multi - step reasoning questions that operate on semi - structured tables.', 'challenges here arise from the level of logical compositionality expressed by questions, as well as the domain openness.', 'our approach is weakly supervised, trained on question - answer - table triples without requiring intermediate strong supervision.', 'it performs two phases : first, machine understandable logical forms ( programs ) are generated from natural language questions following the work of  #TAUTHOR_TAG.', 'second, paraphrases of logical forms and questions are embedded in a jointly learned vector space using word and character convolutional neural networks.', 'a neural scoring function is further used to rank and retrieve the most probable logical form ( interpretation ) of a question.', 'our best single model achieves 34. 8 % accuracy on the wikitablequestions dataset, while the best ensemble of our models pushes the state - of - the - art score on this task to 38. 7 %, thus slightly surpassing both the engineered feature scoring baseline, as well as the neural programmer model of  #TAUTHOR_TAG']",4
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",4
"['g.  #TAUTHOR_TAG.', 'unsur']","['specific topic ( e. g.  #TAUTHOR_TAG.', 'unsurprisingly,']","['g.  #TAUTHOR_TAG.', 'unsur']",[' #TAUTHOR_TAG'],0
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",0
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",0
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",0
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",0
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",0
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",0
"[',  #TAUTHOR_TAG targets more complicated']","[',  #TAUTHOR_TAG targets more complicated questions']","['', 'of compositionality,  #TAUTHOR_TAG targets more complicated']","['is suited for factoid questions with a modest amount', 'of compositionality,  #TAUTHOR_TAG targets more complicated questions. both of these paraphrase - driven', 'qa systems differ from our work as their scoring relies on hand - crafted features. [  #TAUTHOR_TAG also focus on compositional questions, but instead of generating and', 'ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the', 'question. a list of discrete operations are manually defined and each operation is parametrized by a real - valued vector that is learned during training', '. a separate recurrent neural network ( rnn ) is used for modeling the history of selected operations and the question representation. the probability distributions over operations and columns are induced using the question embedding,', 'the history and an attention vector. while their model performs well on semi - structured tables, understanding', 'how it generated the logical form is not trivial. recently,  #TAUTHOR_TAG propose neural en', '##quirer, a fully neural, end - to - end differentiable network that executes queries across multiple tables. they use a synthetic dataset to demonstrate the abilities of the model to deal', '']",0
['be found in  #TAUTHOR_TAG'],['be found in  #TAUTHOR_TAG'],"['', 'details about lambda dcs language can be found in  #TAUTHOR_TAG return t t is']",[' #TAUTHOR_TAG'],0
"[', but a manual annotation by  #TAUTHOR_TAG reveals that pl2015 can']",['but a manual annotation by  #TAUTHOR_TAG reveals that pl2015 can'],"[', but a manual annotation by  #TAUTHOR_TAG reveals that pl2015 can answer only']","['use the train - validation - test split of wikitablequestions dataset containing 9, 659, 1, 200 and 4, 344 questions, respectively.', 'we obtain about 3. 8 million training ( q, t, l ) triples from pl2015, where l is a binary indicator of correctness ( whether the logical form gives the correct answer when executed ).', 'during training we ignore questions for which a single matching pair ( q, t ) is not present.', 'the percentage of questions for which a candidate logical form exists that evaluates to the correct answer is called oracle score.', 'pl2015 report an oracle score of 76. 7 %, but a manual annotation by  #TAUTHOR_TAG reveals that pl2015 can answer only 53. 5 % of the questions correctly.', 'the difference can be explained by incorrect logical forms that give the correct answer by chance']",0
[' #TAUTHOR_TAG is a large'],[' #TAUTHOR_TAG is a largescale'],[' #TAUTHOR_TAG is a largescale dataset of red'],"[' #TAUTHOR_TAG is a largescale dataset of reddit posts from users with one or multiple mental health conditions.', 'the users were identified by constructing patterns for discovering self - reported diagnoses of nine different mental disorders.', 'for example, if a user writes "" i was officially diagnosed with depression last year "", she / he / other would be considered to suffer from depression.', 'nine or more control users, which are meant to represent general population, are selected for each diagnosed user by their similarity, i. e., by their number of posts and the subreddits ( sub - forums on reddit ) they post in.', ""diagnosed users'language is normalized by removing posts with specific mental health signals and discussions, in order to analyze the language of general discussions and to be more comparable to the control groups."", 'the nine disorders and the number of users per disorder, as well as average number of posts per user, are shown in table 1.', 'for each disorder,  #TAUTHOR_TAG analyze the differences in language use between diagnosed users and their respective control groups.', ' #TAUTHOR_TAG also provide benchmark results for the binary classification task of predicting whether the user belongs to the diagnosed or the control group.', 'we reproduce  #TAUTHOR_TAG baseline models for each disorder and compare to our deep learning - based model, explained in section 2. 3']",0
[' #TAUTHOR_TAG is a large'],[' #TAUTHOR_TAG is a largescale'],[' #TAUTHOR_TAG is a largescale dataset of red'],"[' #TAUTHOR_TAG is a largescale dataset of reddit posts from users with one or multiple mental health conditions.', 'the users were identified by constructing patterns for discovering self - reported diagnoses of nine different mental disorders.', 'for example, if a user writes "" i was officially diagnosed with depression last year "", she / he / other would be considered to suffer from depression.', 'nine or more control users, which are meant to represent general population, are selected for each diagnosed user by their similarity, i. e., by their number of posts and the subreddits ( sub - forums on reddit ) they post in.', ""diagnosed users'language is normalized by removing posts with specific mental health signals and discussions, in order to analyze the language of general discussions and to be more comparable to the control groups."", 'the nine disorders and the number of users per disorder, as well as average number of posts per user, are shown in table 1.', 'for each disorder,  #TAUTHOR_TAG analyze the differences in language use between diagnosed users and their respective control groups.', ' #TAUTHOR_TAG also provide benchmark results for the binary classification task of predicting whether the user belongs to the diagnosed or the control group.', 'we reproduce  #TAUTHOR_TAG baseline models for each disorder and compare to our deep learning - based model, explained in section 2. 3']",0
['select nine or more control users for'],['select nine or more control users for'],['select nine or more control users for'],"['select nine or more control users for each diagnosed user and run their experiments with these mappings.', 'with this exact mapping not being available, for each of the nine conditions, we had to select the control group ourselves.', 'for each diagnosed user, we draw exactly nine control users from the pool of 335, 952 control users present in  #TAUTHOR_TAG and proceed to train and test our binary classifiers on the newly created sub - datasets.', 'in order to create a statistically - fair comparison, we run the selection process multiple times, as well as reimplement the benchmark models used in  #TAUTHOR_TAG.', 'multiple sub - datasets with different control groups not only provide us with unbiased results, but also show how results of a binary classification can differ depending on the control group']",0
['prevalent disorder in the  #TAUTHOR_TAG dataset with a number of studies in'],['prevalent disorder in the  #TAUTHOR_TAG dataset with a number of studies in'],['prevalent disorder in the  #TAUTHOR_TAG dataset with a number of studies in'],"['han, through attention mechanism, provides a clear way to identify posts, and words or phrases in those posts, relevant for classification.', 'we examine attention weights on a word level and compare the most attended words to prior research on depression.', 'depression is selected as the most prevalent disorder in the  #TAUTHOR_TAG dataset with a number of studies in the field  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'for each post, we extracted two words with the highest attention weight as being the most relevant for the classification.', 'if the two words are appearing next to each other in a post we consider them as bigram.', '']",0
['prevalent disorder in the  #TAUTHOR_TAG dataset with a number of studies in'],['prevalent disorder in the  #TAUTHOR_TAG dataset with a number of studies in'],['prevalent disorder in the  #TAUTHOR_TAG dataset with a number of studies in'],"['han, through attention mechanism, provides a clear way to identify posts, and words or phrases in those posts, relevant for classification.', 'we examine attention weights on a word level and compare the most attended words to prior research on depression.', 'depression is selected as the most prevalent disorder in the  #TAUTHOR_TAG dataset with a number of studies in the field  #AUTHOR_TAG b ;  #AUTHOR_TAG.', 'for each post, we extracted two words with the highest attention weight as being the most relevant for the classification.', 'if the two words are appearing next to each other in a post we consider them as bigram.', '']",0
"['##ic andsnajder, 2018 ;  #TAUTHOR_TAG ; sek']","[' #AUTHOR_TAG gjurkovic andsnajder, 2018 ;  #TAUTHOR_TAG ; sekulic et al., 2018 ;  #AUTHOR_TAG.', 'previous approaches']","['as a richer source of high - volume data  #AUTHOR_TAG gjurkovic andsnajder, 2018 ;  #TAUTHOR_TAG ; sek']","['recent years, social media has been a valuable source for psychological research.', 'while most studies use twitter data  #AUTHOR_TAG a ( coppersmith et al.,, 2014  #AUTHOR_TAG b ), a recent stream turns to reddit as a richer source of high - volume data  #AUTHOR_TAG gjurkovic andsnajder, 2018 ;  #TAUTHOR_TAG ; sekulic et al., 2018 ;  #AUTHOR_TAG.', ""previous approaches to author's mental health prediction usually relied on linguistic and stylistic features, e. g., linguistic inquiry and word count ( liwc )  #AUTHOR_TAG - a widely used feature extractor for various studies regarding mental health  #AUTHOR_TAG sekulic et al., 2018 ;  #AUTHOR_TAG."", ' #AUTHOR_TAG built a feature attention network for depression detection on reddit, showing high interpretability, but low improvement in accuracy.', ' #AUTHOR_TAG concatenate all the tweets of a twitter user in a single document and experiment with various deep neu - ral models for depression detection.', ""some of the previous studies use deep learning methods on a post level to infer general information about a user  #AUTHOR_TAG, or detect different mental health concepts in posts themselves ( rojas -  #AUTHOR_TAG, while we focus on utilizing all of the users'text."", '']",0
['select nine or more control users for'],['select nine or more control users for'],['select nine or more control users for'],"['select nine or more control users for each diagnosed user and run their experiments with these mappings.', 'with this exact mapping not being available, for each of the nine conditions, we had to select the control group ourselves.', 'for each diagnosed user, we draw exactly nine control users from the pool of 335, 952 control users present in  #TAUTHOR_TAG and proceed to train and test our binary classifiers on the newly created sub - datasets.', 'in order to create a statistically - fair comparison, we run the selection process multiple times, as well as reimplement the benchmark models used in  #TAUTHOR_TAG.', 'multiple sub - datasets with different control groups not only provide us with unbiased results, but also show how results of a binary classification can differ depending on the control group']",6
['select nine or more control users for'],['select nine or more control users for'],['select nine or more control users for'],"['select nine or more control users for each diagnosed user and run their experiments with these mappings.', 'with this exact mapping not being available, for each of the nine conditions, we had to select the control group ourselves.', 'for each diagnosed user, we draw exactly nine control users from the pool of 335, 952 control users present in  #TAUTHOR_TAG and proceed to train and test our binary classifiers on the newly created sub - datasets.', 'in order to create a statistically - fair comparison, we run the selection process multiple times, as well as reimplement the benchmark models used in  #TAUTHOR_TAG.', 'multiple sub - datasets with different control groups not only provide us with unbiased results, but also show how results of a binary classification can differ depending on the control group']",6
['select nine or more control users for'],['select nine or more control users for'],['select nine or more control users for'],"['select nine or more control users for each diagnosed user and run their experiments with these mappings.', 'with this exact mapping not being available, for each of the nine conditions, we had to select the control group ourselves.', 'for each diagnosed user, we draw exactly nine control users from the pool of 335, 952 control users present in  #TAUTHOR_TAG and proceed to train and test our binary classifiers on the newly created sub - datasets.', 'in order to create a statistically - fair comparison, we run the selection process multiple times, as well as reimplement the benchmark models used in  #TAUTHOR_TAG.', 'multiple sub - datasets with different control groups not only provide us with unbiased results, but also show how results of a binary classification can differ depending on the control group']",4
"['to  #TAUTHOR_TAG, supervised fasttext yields worse']","['to  #TAUTHOR_TAG, supervised fasttext yields worse']","['to  #TAUTHOR_TAG, supervised fasttext yields worse results']","['', 'we observe higher f 1 score for the han in disorders with sufficient data, suggesting once again that deep neural models are data - hungry  #AUTHOR_TAG.', 'logistic regression and linear svm achieve higher scores where there is a smaller number of diagnosed users.', 'in contrast to  #TAUTHOR_TAG, supervised fasttext yields worse results than tuned linear models.', 'we further investigate the impact of the size of the dataset on the final results of classification.', 'we limit the number of posts per user available to the model to examine the amount needed for reasonable performance.', 'the results for 50, 100, 150, 200, and 250 posts per user available are presented in figure 1.', 'experiments were run three times for each disorder and each number of available posts, every time with a different control group selected.', 'we observe a positive correlation between the data provided to the model and the performance, although we find an upper bound to this tendency.', 'as the average number of posts per user is roughly 160 ( table 1 ), it is reasonable to expect of a model to perform well with similar amounts of data available.', 'however, further analysis is required to see if the model reaches the plateau because a large amount of data is not needed for the task, or due to it not being expressive enough']",4
"[',  #TAUTHOR_TAG how automatically']","['salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically']","['salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically']","['', 'while identification is mostly syntactic, classification requires semantic knowledge to be taken into account.', 'semantic information is usually captured through lexicalized features on the predicate and the head - word of the argument to be classified.', 'since lexical features tend to be sparse, srl systems are prone to overfit the training data and generalize poorly to new corpora.', 'indeed, the srl evaluation exercises at conll - 2004 ( carreras and marquez, 2005 observed that all systems showed a significant performance degradation ( ∼10 f 1 points ) when applied to test data from a different genre of that of the training set.', ' #AUTHOR_TAG showed that this performance degradation is essentially caused by the argument classification subtask, and suggested the lexical data sparseness as one of the main reasons.', 'the same authors studied the contribution of the different feature types in srl and concluded that the lexical features were the most salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically generated selectional preferences ( sp ) for verbs were able to perform better than pure lexical features in a role classification experiment, disconnected from a full - fledged srl system.', 'sps introduce semantic generalizations on the type of arguments preferred by the predicates and, thus, they are expected to improve results on infrequent and unknown words.', 'the positive effect was especially relevant for out - of - domain data.', 'in this paper we advance  #TAUTHOR_TAG in two directions : ( 1 ) we learn separate sps for prepositions and verbs, showing improvement over using sps for verbs alone.', '( 2 ) we integrate the information of several sp models in a state - of - the - art srl system ( swirl 1 ) and show significant improvements in sr classification.', 'the key for the improvement lies in a metaclassifier, trained to select among the predictions provided by several role classification models']",0
"['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered both first order and second order similarity. in first order similarity, the similarity of two words was computed using the cosine (', 'or jaccard measure ) of the co - occurrence vectors of the two words. co - occurrence', 'vectors where constructed using freely available software ( pado and  #AUTHOR_TAG run over the british national corpus.', 'we used the optimal parameters ( pado and  #AUTHOR_TAG. we will refer to these similarities as sim cos and sim jac, respectively. in contrast, second order similarity uses vectors of similar words', ', i. e., the similarity of two words was computed using the', ""cosine ( or jaccard measure ) between the thesaurus entries of those words in lin's thesaurus  #AUTHOR_TAG. we refer"", 'to these as sim 2 cos and sim 2 jac. given a target sentence with a verb and its arguments, the task of sr classification is to assign the correct role to each of the', '']",0
"['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered both first order and second order similarity. in first order similarity, the similarity of two words was computed using the cosine (', 'or jaccard measure ) of the co - occurrence vectors of the two words. co - occurrence', 'vectors where constructed using freely available software ( pado and  #AUTHOR_TAG run over the british national corpus.', 'we used the optimal parameters ( pado and  #AUTHOR_TAG. we will refer to these similarities as sim cos and sim jac, respectively. in contrast, second order similarity uses vectors of similar words', ', i. e., the similarity of two words was computed using the', ""cosine ( or jaccard measure ) between the thesaurus entries of those words in lin's thesaurus  #AUTHOR_TAG. we refer"", 'to these as sim 2 cos and sim 2 jac. given a target sentence with a verb and its arguments, the task of sr classification is to assign the correct role to each of the', '']",0
"[',  #TAUTHOR_TAG how automatically']","['salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically']","['salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically']","['', 'while identification is mostly syntactic, classification requires semantic knowledge to be taken into account.', 'semantic information is usually captured through lexicalized features on the predicate and the head - word of the argument to be classified.', 'since lexical features tend to be sparse, srl systems are prone to overfit the training data and generalize poorly to new corpora.', 'indeed, the srl evaluation exercises at conll - 2004 ( carreras and marquez, 2005 observed that all systems showed a significant performance degradation ( ∼10 f 1 points ) when applied to test data from a different genre of that of the training set.', ' #AUTHOR_TAG showed that this performance degradation is essentially caused by the argument classification subtask, and suggested the lexical data sparseness as one of the main reasons.', 'the same authors studied the contribution of the different feature types in srl and concluded that the lexical features were the most salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically generated selectional preferences ( sp ) for verbs were able to perform better than pure lexical features in a role classification experiment, disconnected from a full - fledged srl system.', 'sps introduce semantic generalizations on the type of arguments preferred by the predicates and, thus, they are expected to improve results on infrequent and unknown words.', 'the positive effect was especially relevant for out - of - domain data.', 'in this paper we advance  #TAUTHOR_TAG in two directions : ( 1 ) we learn separate sps for prepositions and verbs, showing improvement over using sps for verbs alone.', '( 2 ) we integrate the information of several sp models in a state - of - the - art srl system ( swirl 1 ) and show significant improvements in sr classification.', 'the key for the improvement lies in a metaclassifier, trained to select among the predictions provided by several role classification models']",1
"['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered both first order and second order similarity. in first order similarity, the similarity of two words was computed using the cosine (', 'or jaccard measure ) of the co - occurrence vectors of the two words. co - occurrence', 'vectors where constructed using freely available software ( pado and  #AUTHOR_TAG run over the british national corpus.', 'we used the optimal parameters ( pado and  #AUTHOR_TAG. we will refer to these similarities as sim cos and sim jac, respectively. in contrast, second order similarity uses vectors of similar words', ', i. e., the similarity of two words was computed using the', ""cosine ( or jaccard measure ) between the thesaurus entries of those words in lin's thesaurus  #AUTHOR_TAG. we refer"", 'to these as sim 2 cos and sim 2 jac. given a target sentence with a verb and its arguments, the task of sr classification is to assign the correct role to each of the', '']",1
"[',  #TAUTHOR_TAG how automatically']","['salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically']","['salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically']","['', 'while identification is mostly syntactic, classification requires semantic knowledge to be taken into account.', 'semantic information is usually captured through lexicalized features on the predicate and the head - word of the argument to be classified.', 'since lexical features tend to be sparse, srl systems are prone to overfit the training data and generalize poorly to new corpora.', 'indeed, the srl evaluation exercises at conll - 2004 ( carreras and marquez, 2005 observed that all systems showed a significant performance degradation ( ∼10 f 1 points ) when applied to test data from a different genre of that of the training set.', ' #AUTHOR_TAG showed that this performance degradation is essentially caused by the argument classification subtask, and suggested the lexical data sparseness as one of the main reasons.', 'the same authors studied the contribution of the different feature types in srl and concluded that the lexical features were the most salient features in argument classification  #AUTHOR_TAG.', 'in recent work,  #TAUTHOR_TAG how automatically generated selectional preferences ( sp ) for verbs were able to perform better than pure lexical features in a role classification experiment, disconnected from a full - fledged srl system.', 'sps introduce semantic generalizations on the type of arguments preferred by the predicates and, thus, they are expected to improve results on infrequent and unknown words.', 'the positive effect was especially relevant for out - of - domain data.', 'in this paper we advance  #TAUTHOR_TAG in two directions : ( 1 ) we learn separate sps for prepositions and verbs, showing improvement over using sps for verbs alone.', '( 2 ) we integrate the information of several sp models in a state - of - the - art srl system ( swirl 1 ) and show significant improvements in sr classification.', 'the key for the improvement lies in a metaclassifier, trained to select among the predictions provided by several role classification models']",6
"['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered both first order and second order similarity. in first order similarity, the similarity of two words was computed using the cosine (', 'or jaccard measure ) of the co - occurrence vectors of the two words. co - occurrence', 'vectors where constructed using freely available software ( pado and  #AUTHOR_TAG run over the british national corpus.', 'we used the optimal parameters ( pado and  #AUTHOR_TAG. we will refer to these similarities as sim cos and sim jac, respectively. in contrast, second order similarity uses vectors of similar words', ', i. e., the similarity of two words was computed using the', ""cosine ( or jaccard measure ) between the thesaurus entries of those words in lin's thesaurus  #AUTHOR_TAG. we refer"", 'to these as sim 2 cos and sim 2 jac. given a target sentence with a verb and its arguments, the task of sr classification is to assign the correct role to each of the', '']",6
"['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered both first order and second order similarity. in first order similarity, the similarity of two words was computed using the cosine (', 'or jaccard measure ) of the co - occurrence vectors of the two words. co - occurrence', 'vectors where constructed using freely available software ( pado and  #AUTHOR_TAG run over the british national corpus.', 'we used the optimal parameters ( pado and  #AUTHOR_TAG. we will refer to these similarities as sim cos and sim jac, respectively. in contrast, second order similarity uses vectors of similar words', ', i. e., the similarity of two words was computed using the', ""cosine ( or jaccard measure ) between the thesaurus entries of those words in lin's thesaurus  #AUTHOR_TAG. we refer"", 'to these as sim 2 cos and sim 2 jac. given a target sentence with a verb and its arguments, the task of sr classification is to assign the correct role to each of the', '']",6
"['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered']","['as res. the other model is an in - house method  #TAUTHOR_TAG, which only takes into account the depth', 'of the most common ancestor, and returns sps that are as specific as possible. distributional similarity : following  #TAUTHOR_TAG we considered both first order and second order similarity. in first order similarity, the similarity of two words was computed using the cosine (', 'or jaccard measure ) of the co - occurrence vectors of the two words. co - occurrence', 'vectors where constructed using freely available software ( pado and  #AUTHOR_TAG run over the british national corpus.', 'we used the optimal parameters ( pado and  #AUTHOR_TAG. we will refer to these similarities as sim cos and sim jac, respectively. in contrast, second order similarity uses vectors of similar words', ', i. e., the similarity of two words was computed using the', ""cosine ( or jaccard measure ) between the thesaurus entries of those words in lin's thesaurus  #AUTHOR_TAG. we refer"", 'to these as sim 2 cos and sim 2 jac. given a target sentence with a verb and its arguments, the task of sr classification is to assign the correct role to each of the', '']",4
"['purposes and other properties  #TAUTHOR_TAG 11, 7, 1 ].', 'in contrast, editor roles have']","['purposes and other properties  #TAUTHOR_TAG 11, 7, 1 ].', 'in contrast, editor roles have']","['purposes and other properties  #TAUTHOR_TAG 11, 7, 1 ].', 'in contrast, editor roles have generally been studied in nlp using online collaborative writing applications']","['that experienced and successful writers revise differently than inexperienced writers [ 4 ], various intelligent writing tools have been developed that provide localized feedback on text characteristics [ 5, 3, 6, 9 ].', 'these tools typically suggest edits to guide revision, rather than model the editing process after observing revisions.', 'with the long term goal of developing an intelligent revision assistant, this paper presents an approach to modeling student editor roles.', 'prior natural language processing ( nlp ) approaches to student revision analysis have focused on identifying revisions during argumentative writing and classifying their purposes and other properties  #TAUTHOR_TAG 11, 7, 1 ].', 'in contrast, editor roles have generally been studied in nlp using online collaborative writing applications such as wikipedia [ 10 ].', 'inspired by the use of wikipedia revision histories [ 10 ], in this paper we similarly use topic modeling applied to revision histories to identify editor roles in the domain of student argumentative writing.', 'to model student revision histories, between - draft essay revisions are extracted at a sentence - level and represented in terms of the following three aspects : operation ( add, delete, or modify a sentence ), purpose ( e. g., correct grammar versus improve fluency ), and position ( revise at the beginning, middle or the end of an essay ).', 'to identify editor roles, a latent dirichlet allocation ( lda ) [ 2 ] graphical model is then applied to these revision histories.', 'finally, we show that the identified roles capture the variability in our data as well as correlate with writing improvement']",0
['corpus study in  #TAUTHOR_TAG showed that content changes'],['corpus study in  #TAUTHOR_TAG showed that content changes'],['corpus study in  #TAUTHOR_TAG showed that content changes'],"['corpus study in  #TAUTHOR_TAG showed that content changes are correlated with argumentative writing improvement, reaffirming the statement of [ 4 ].', 'using a similar method, we investigate if our editor roles are related to writing improvement.', 'we calculate partial pearson correlations between editor roles and score2 while controlling for score1 to regress out the effect of the correlation between score1 and score2 ( corr. = 0. 692, p < 0. 001 ).', 'table 4 shows that the roles consisting of only surface edits or a mixture of edits are not correlated to writing improvement.', 'however, persuasive editor, which consists of content revisions, shows a positive significant correlation to writing improvement.', 'our results suggest that the persuasive editor is the role of an experienced writer']",0
"['and college students  #TAUTHOR_TAG.', 'we']","['written by both high - school and college students  #TAUTHOR_TAG.', 'we']","['and college students  #TAUTHOR_TAG.', 'we divide our data']","['work takes advantage of several corpora of multiple drafts of argumentative essays written by both high - school and college students  #TAUTHOR_TAG.', 'we divide our data into a modeling corpus ( 185 paired drafts, 3245 revisions ) and an evaluation corpus ( 107 paired draft, 2045 revisions ), based on whether expert grades are available before ( score1 ) and after ( score2 ) essay revision.', 'although the grading rubrics for the college and high - school essays in the evaluation corpus are different, both are based upon common criteria of argumentative writing, e. g., clear thesis, convincing evidence, clear wording without grammatical errors, etc.', '']",5
"['and college students  #TAUTHOR_TAG.', 'we']","['written by both high - school and college students  #TAUTHOR_TAG.', 'we']","['and college students  #TAUTHOR_TAG.', 'we divide our data']","['work takes advantage of several corpora of multiple drafts of argumentative essays written by both high - school and college students  #TAUTHOR_TAG.', 'we divide our data into a modeling corpus ( 185 paired drafts, 3245 revisions ) and an evaluation corpus ( 107 paired draft, 2045 revisions ), based on whether expert grades are available before ( score1 ) and after ( score2 ) essay revision.', 'although the grading rubrics for the college and high - school essays in the evaluation corpus are different, both are based upon common criteria of argumentative writing, e. g., clear thesis, convincing evidence, clear wording without grammatical errors, etc.', '']",6
['corpus study in  #TAUTHOR_TAG showed that content changes'],['corpus study in  #TAUTHOR_TAG showed that content changes'],['corpus study in  #TAUTHOR_TAG showed that content changes'],"['corpus study in  #TAUTHOR_TAG showed that content changes are correlated with argumentative writing improvement, reaffirming the statement of [ 4 ].', 'using a similar method, we investigate if our editor roles are related to writing improvement.', 'we calculate partial pearson correlations between editor roles and score2 while controlling for score1 to regress out the effect of the correlation between score1 and score2 ( corr. = 0. 692, p < 0. 001 ).', 'table 4 shows that the roles consisting of only surface edits or a mixture of edits are not correlated to writing improvement.', 'however, persuasive editor, which consists of content revisions, shows a positive significant correlation to writing improvement.', 'our results suggest that the persuasive editor is the role of an experienced writer']",3
"['graph  #TAUTHOR_TAG.', 'in these methods the input']","['graph  #TAUTHOR_TAG.', 'in these methods the input']","['reason over a knowledge graph  #TAUTHOR_TAG.', 'in these methods the input question is first']","['number of approaches for question answering have been proposed recently that use reinforcement learning to reason over a knowledge graph  #TAUTHOR_TAG.', '']",0
['our work on the recent reinforcement learning approaches introduced in  #TAUTHOR_TAG and  #AUTHOR_TAG'],['our work on the recent reinforcement learning approaches introduced in  #TAUTHOR_TAG and  #AUTHOR_TAG'],"['base our work on the recent reinforcement learning approaches introduced in  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'we denote the knowledge graph as']","['base our work on the recent reinforcement learning approaches introduced in  #TAUTHOR_TAG and  #AUTHOR_TAG.', '']",0
['of  #TAUTHOR_TAG a binary'],['of  #TAUTHOR_TAG a binary'],"['', 'in the framework of  #TAUTHOR_TAG a binary reward is used which rewards the learner']","['', 'this is illustrated in figure 3.', 'in the framework of  #TAUTHOR_TAG a binary reward is used which rewards the learner for the answer being wrong or correct.', ""following a similar protocol, we could award a score of 1 to return'no answer'when there is no answer available in the kg."", 'however, we cannot achieve reasonable training with such reward structure.', ""this is because there is no specific pattern for'no answer'that could be directly learned."", '']",0
"[',  #TAUTHOR_TAG proposed a ws']","['resource deprived languages.', 'to circumvent this problem,  #TAUTHOR_TAG proposed a wsd method that can be']","['of the resource deprived languages.', 'to circumvent this problem,  #TAUTHOR_TAG proposed a wsd method that can be applied to a language even when no sense tagged corpus for that language is available.', '']","['sense disambiguation ( wsd ) is one of the most widely investigated problems of natural language processing ( nlp ).', 'previous works have shown that supervised approaches to word sense disambiguation which rely on sense annotated corpora  #AUTHOR_TAG outperform unsupervised  #AUTHOR_TAG and knowledge based approaches  #AUTHOR_TAG.', 'however, creation of sense marked corpora has always remained a costly proposition, especially for some of the resource deprived languages.', 'to circumvent this problem,  #TAUTHOR_TAG proposed a wsd method that can be applied to a language even when no sense tagged corpus for that language is available.', 'this is achieved by projecting wordnet and corpus parameters from another language to the language in question.', 'the approach is centered on a novel synset based multilingual dictionary  #AUTHOR_TAG where the synsets of different languages are aligned and thereafter the words within the synsets are manually cross - linked.', ""for example, the word w l 1 belonging to synset s of language l 1 will be manually cross - linked to the word w l 2 of the corresponding synset in language l 2 to indicate that w l 2 is the best substitute for w l 1 according to an experienced bilingual speaker's intuition."", 'we extend their work by addressing the following question on the economics of annotation, lexicon building and performance :', '• is there an optimal point of balance between the annotation effort and the lexicon building ( i. e. manual cross - linking']",1
['of  #TAUTHOR_TAG on parameter projection for multilingual ws'],['of  #TAUTHOR_TAG on parameter projection for multilingual'],"['we discuss the work of  #TAUTHOR_TAG on parameter projection for multilingual wsd.', '']","['', 'in section 3 we describe the synset based multilingual dictionary which enables parameter projection.', 'in section 4 we discuss the work of  #TAUTHOR_TAG on parameter projection for multilingual wsd.', 'section 5 is on the economics of multilingual wsd.', 'in section 6 we propose a probabilistic model for representing the cross - linkage of words within synsets.', 'in section 7 we present a strategy for injecting hard - to - disambiguate cases from the target language using selective sampling.', 'in section 8 we introduce a measure for cost - benefit analysis for calculating the value for money in terms of accuracy, annotation effort and lexicon building effort.', 'in section 9 we describe the experimental setup.', '']",0
['by  #TAUTHOR_TAG has shown that'],['by  #TAUTHOR_TAG has shown that'],"['resource scarce languages.', 'recent work by  #TAUTHOR_TAG has shown that it is']","[""based approaches to wsd such as lesk's algorithm  #AUTHOR_TAG, walker's algorithm  #AUTHOR_TAG, conceptual density  #AUTHOR_TAG and pagerank  #AUTHOR_TAG are less demanding in terms of resources but fail to deliver good results."", 'supervised approaches like svm  #AUTHOR_TAG and k - nn  #AUTHOR_TAG, on the other hand, give better accuracies, but the requirement of large annotated corpora renders them unsuitable for resource scarce languages.', 'recent work by  #TAUTHOR_TAG has shown that it is possible to project the parameters learnt from the annotation work of one language to another language provided aligned wordnets for two languages are available.', 'however, their work does not address the question of further improving the accuracy of wsd by using a small amount of training data from the target language.', 'some similar work has been done in the area of domain adaptation where  #AUTHOR_TAG showed that adding just 30 % of the target data to the source data achieved the same performance as that obtained by taking the entire source and target data.', 'similarly, agirre and de  #AUTHOR_TAG reported a 22 % error reduction when source and target data were combined for training a classifier, compared to the case when only the target data was used for training the classifier.', 'however, such combining of training statistics has not been tried in cases where the source data is in one language and the target data is in another language.', 'to the best of our knowledge, no previous work has attempted to perform resource conscious allwords multilingual word sense disambiguation by finding a trade - off between the cost ( in terms of annotation effort and lexicon creation effort ) and the quality in terms of f - score']",0
"['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for the accuracy achieved thereof.', 'specifically, they do not explore the inclusion of small amount of annotated data from the target language to boost the accuracy ( as mentioned earlier, supervised systems which use annotated data from the target language are known to perform better ).', 'further, it is conceivable that with respect to accuracy - cost trade - off, there obtains a case for balancing one cost against the other, viz., the cost of cross - linking and the cost of annotation.', 'in some cases bilingual lexicographers ( needed for manual cross - linking ) may be more expensive compared to monolingual annotators.', 'there it makes sense to place fewer bets on manual crosslinking and more on collecting annotated corpora.', 'on the other hand if manual cross - linking is cheap then a very small amount of annotated corpora can be used in conjunction with full manual crosslinking to boost the accuracy.', 'based on the above discussion, if k a is the cost of sense annotating one word, k c is the cost of manually cross - linking a word and a is the accuracy desired then the problem of multilingual wsd can be cast as an optimization problem :', 'accuracy ≥ a where, w c and w a are the number of words to be manually cross linked and annotated respectively.', 'ours is thus a 3 - factor economic model ( crosslinking, annotation and accuracy ) as opposed to the 2 - factor model ( cross - linking, accuracy ) proposed by  #TAUTHOR_TAG']",0
"['our probabilistic cross linking model.', 'the model proposed by  #TAUTHOR_TAG is a deterministic model where the']","['our probabilistic cross linking model.', 'the model proposed by  #TAUTHOR_TAG is a deterministic model where the']","['', 'in the following paragraphs, we explain our probabilistic cross linking model.', 'the model proposed by  #TAUTHOR_TAG is a deterministic model where the expected count']","['mentioned earlier, in some cases where bilingual lexicographers are expensive we might be interested in reducing the effort of manual crosslinking.', 'for such situations, we propose that only a small number of words, comprising of the most frequently appearing ones should be manually cross linked and the rest of the words should be cross - linked using a probabilistic model.', 'the rationale here is simple : invest money in words which are bound to occur frequently in the test data and achieve maximum impact on the accuracy.', 'in the following paragraphs, we explain our probabilistic cross linking model.', 'the model proposed by  #TAUTHOR_TAG is a deterministic model where the expected count for ( sense s, marathi word w ), i. e., the number of times the word w appears in sense s is approximated by the count for the corresponding cross linked hindi word.', 'such a model assumes that each marathi word links to appropriate hindi word ( s ) as identified manually by a lexicographer.', 'instead, we propose a probabilistic model where a marathi word can link to every word in the corresponding hindi synset with some probability.', 'the expected count for ( s, w ) can then be estimated as :', 'where, p ( h i | w, s ) is the probability that the word h i from the corresponding hindi synset is the correct cross - linked word for the given marathi word.', 'for example, one of the senses of the marathi word maan is { neck } i. e. "" the body part which connects the head to the rest of the body "".', 'the corresponding hindi synset has 10 words { gardan, gala, greeva, halak, kandhar and so on }. thus, using equation ( 2 ), the expected count, e [ c ( { neck }, maan ) ], is calculated as']",0
"['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for the accuracy achieved thereof.', 'specifically, they do not explore the inclusion of small amount of annotated data from the target language to boost the accuracy ( as mentioned earlier, supervised systems which use annotated data from the target language are known to perform better ).', 'further, it is conceivable that with respect to accuracy - cost trade - off, there obtains a case for balancing one cost against the other, viz., the cost of cross - linking and the cost of annotation.', 'in some cases bilingual lexicographers ( needed for manual cross - linking ) may be more expensive compared to monolingual annotators.', 'there it makes sense to place fewer bets on manual crosslinking and more on collecting annotated corpora.', 'on the other hand if manual cross - linking is cheap then a very small amount of annotated corpora can be used in conjunction with full manual crosslinking to boost the accuracy.', 'based on the above discussion, if k a is the cost of sense annotating one word, k c is the cost of manually cross - linking a word and a is the accuracy desired then the problem of multilingual wsd can be cast as an optimization problem :', 'accuracy ≥ a where, w c and w a are the number of words to be manually cross linked and annotated respectively.', 'ours is thus a 3 - factor economic model ( crosslinking, annotation and accuracy ) as opposed to the 2 - factor model ( cross - linking, accuracy ) proposed by  #TAUTHOR_TAG']",4
"['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['the commodity itself.', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for']","['', 'the work of  #TAUTHOR_TAG as described above does not attempt to reach an optimal costbenefit point in this economic system.', 'they place their bets on manual cross - linking only and settle for the accuracy achieved thereof.', 'specifically, they do not explore the inclusion of small amount of annotated data from the target language to boost the accuracy ( as mentioned earlier, supervised systems which use annotated data from the target language are known to perform better ).', 'further, it is conceivable that with respect to accuracy - cost trade - off, there obtains a case for balancing one cost against the other, viz., the cost of cross - linking and the cost of annotation.', 'in some cases bilingual lexicographers ( needed for manual cross - linking ) may be more expensive compared to monolingual annotators.', 'there it makes sense to place fewer bets on manual crosslinking and more on collecting annotated corpora.', 'on the other hand if manual cross - linking is cheap then a very small amount of annotated corpora can be used in conjunction with full manual crosslinking to boost the accuracy.', 'based on the above discussion, if k a is the cost of sense annotating one word, k c is the cost of manually cross - linking a word and a is the accuracy desired then the problem of multilingual wsd can be cast as an optimization problem :', 'accuracy ≥ a where, w c and w a are the number of words to be manually cross linked and annotated respectively.', 'ours is thus a 3 - factor economic model ( crosslinking, annotation and accuracy ) as opposed to the 2 - factor model ( cross - linking, accuracy ) proposed by  #TAUTHOR_TAG']",6
"['.', 'we used the same dataset as described in  #TAUTHOR_TAG for']","['a resource conscious marathi ( t l ) wsd engine.', 'we used the same dataset as described in  #TAUTHOR_TAG for']","['', 'we used the same dataset as described in  #TAUTHOR_TAG for']","['used hindi as the source language ( s l ) and trained a wsd engine using hindi sense tagged corpus.', 'the parameters thus learnt were then projected using the multidict ( refer section 3 and 4 ) to build a resource conscious marathi ( t l ) wsd engine.', 'we used the same dataset as described in  #TAUTHOR_TAG for all our experiments.', 'the data was collected from two domains, viz., tourism and health.', 'the data for tourism domain was collected by manually translating english documents downloaded from indian tourism websites into hindi and marathi.', 'similarly, english documents for health domain were obtained from two doctors and were manually translated into hindi and marathi.', 'the hindi and marathi documents thus created were manually sense annotated by two lexicographers adept in hindi and marathi using the respective wordnets as sense repositories.', 'table 2 summarizes some statistics about the corpora.', 'as for cross - linking, hindi is used as the pivot language and words in marathi synset are linked to the words in the corresponding hindi synset.', 'the total number of cross - links that were manually setup were 3600 for tourism and 1800 for health.', 'the cost of cross - linking as well as sense annotating one word was taken to be 10 rupees.', 'these costs were estimated based on quotations from lexicographers.', 'however, these costs need to be taken as representative values only and may vary greatly depending on the availability of skilled bilingual lexicographers and skilled monolingual annotators.', 'table 2 : number of polysemous words and average degree of polysemy']",3
"['.', 'we used the same dataset as described in  #TAUTHOR_TAG for']","['a resource conscious marathi ( t l ) wsd engine.', 'we used the same dataset as described in  #TAUTHOR_TAG for']","['', 'we used the same dataset as described in  #TAUTHOR_TAG for']","['used hindi as the source language ( s l ) and trained a wsd engine using hindi sense tagged corpus.', 'the parameters thus learnt were then projected using the multidict ( refer section 3 and 4 ) to build a resource conscious marathi ( t l ) wsd engine.', 'we used the same dataset as described in  #TAUTHOR_TAG for all our experiments.', 'the data was collected from two domains, viz., tourism and health.', 'the data for tourism domain was collected by manually translating english documents downloaded from indian tourism websites into hindi and marathi.', 'similarly, english documents for health domain were obtained from two doctors and were manually translated into hindi and marathi.', 'the hindi and marathi documents thus created were manually sense annotated by two lexicographers adept in hindi and marathi using the respective wordnets as sense repositories.', 'table 2 summarizes some statistics about the corpora.', 'as for cross - linking, hindi is used as the pivot language and words in marathi synset are linked to the words in the corresponding hindi synset.', 'the total number of cross - links that were manually setup were 3600 for tourism and 1800 for health.', 'the cost of cross - linking as well as sense annotating one word was taken to be 10 rupees.', 'these costs were estimated based on quotations from lexicographers.', 'however, these costs need to be taken as representative values only and may vary greatly depending on the availability of skilled bilingual lexicographers and skilled monolingual annotators.', 'table 2 : number of polysemous words and average degree of polysemy']",5
"['focused on only the segmentation part of the voice identification task  #TAUTHOR_TAG.', 'here, we instead assume an initial segmentation and then try to create clusters corresponding to segments of the the waste']","['focused on only the segmentation part of the voice identification task  #TAUTHOR_TAG.', 'here, we instead assume an initial segmentation and then try to create clusters corresponding to segments of the the waste']","['obvious when a voice has reappeared.', 'our previous work focused on only the segmentation part of the voice identification task  #TAUTHOR_TAG.', 'here, we instead assume an initial segmentation and then try to create clusters corresponding to segments of the the waste land which are spoken by the same voice.', 'of particular interest is the influence of the initial segmentation on the success of this downstream task']","['', 'above the antique mantel was displayed as though a window gave upon the sylvan scene the change of philomel [ 97 ] [ 98 ] [ 99 ] although the stylistic contrasts between these and other voices are clear to many readers, eliot does not explicitly mark the transitions, nor is it obvious when a voice has reappeared.', 'our previous work focused on only the segmentation part of the voice identification task  #TAUTHOR_TAG.', 'here, we instead assume an initial segmentation and then try to create clusters corresponding to segments of the the waste land which are spoken by the same voice.', 'of particular interest is the influence of the initial segmentation on the success of this downstream task']",0
"[' #TAUTHOR_TAG.', 'our segmentation model for the waste']","[' #TAUTHOR_TAG.', 'our segmentation model for the waste']","['here is built on our earlier work  #TAUTHOR_TAG.', 'our segmentation model for the waste land was based on a stylistic change curve whose values are the distance between stylistic feature vectors derived from 50 token spans on either side of each point ( spaces between tokens ) in the text ; the local maxima of this curve represent likely voice switches.', 'performance on the waste land was far from perfect, but evaluation using standard text segmentation metrics  #AUTHOR_TAG indicated that it was well above various baselines']","['is a small body of work applying quantitative methods to poetry :  #AUTHOR_TAG looked at lexical and semantic diversity in shakespearean sonnets and correlated this with aesthetic success, whereas  #AUTHOR_TAG developed statistics of formulaic style and applied them to the chanson de roland to determine whether it represents an oral or written style.', ' #AUTHOR_TAG quantify various aspects of poety, including style and sentiment, and use these features to distinguish professional and amateur writers of contemporary poetry.', 'with respect to novels, the work of mc  #AUTHOR_TAG is very relevant ; they used principal components analysis of lexical frequency to discriminate different voices and narrative styles in sections of ulysses by james joyce.', 'clustering techniques have been applied to literature in general ; for instance,  #AUTHOR_TAG clustered novels according to style, and recent work in distinguishing two authors of sections of the bible  #AUTHOR_TAG relies crucially on an initial clustering which is bootstrapped into a supervised classifier which is applied to segments.', 'beyond literature, the tasks of stylistic inconsistency detection  #AUTHOR_TAG and intrinsic ( unsupervised ) plagiarism detection  #AUTHOR_TAG are very closely related to our interests here, though in such tasks usually only two authors are posited ; more general kinds of authorship identification  #AUTHOR_TAG may include many more authors, though some form of supervision ( i. e. training data ) is usually assumed.', 'our work here is built on our earlier work  #TAUTHOR_TAG.', 'our segmentation model for the waste land was based on a stylistic change curve whose values are the distance between stylistic feature vectors derived from 50 token spans on either side of each point ( spaces between tokens ) in the text ; the local maxima of this curve represent likely voice switches.', 'performance on the waste land was far from perfect, but evaluation using standard text segmentation metrics  #AUTHOR_TAG indicated that it was well above various baselines']",0
"['approach to voice identification in the waste land consists first of identifying the boundaries of voice spans  #TAUTHOR_TAG.', 'given a segmentation of the text, we consider']","['approach to voice identification in the waste land consists first of identifying the boundaries of voice spans  #TAUTHOR_TAG.', 'given a segmentation of the text, we consider']","['approach to voice identification in the waste land consists first of identifying the boundaries of voice spans  #TAUTHOR_TAG.', 'given a segmentation of the text, we consider each span as a data point in a clustering problem.', 'the elements of the vector correspond to the best feature set from the segmentation task, with the rationale that features which were useful']","['approach to voice identification in the waste land consists first of identifying the boundaries of voice spans  #TAUTHOR_TAG.', 'given a segmentation of the text, we consider each span as a data point in a clustering problem.', 'the elements of the vector correspond to the best feature set from the segmentation task, with the rationale that features which were useful for detecting changes in style should also be useful for identifying stylistic similarities.', 'our features therefore include : a collection of readability metrics ( including word length ), frequency of punctuation, line breaks, and various parts - ofspeech, lexical density, average frequency in a large external corpus  #AUTHOR_TAG, lexiconbased sentiment metrics using sentiwordnet  #AUTHOR_TAG, formality score  #AUTHOR_TAG, and, perhaps most notably, the centroid of 20 - dimensional distributional vectors built using latent semantic analysis  #AUTHOR_TAG, reflecting the use of words in a large web corpus  #AUTHOR_TAG ; in previous work  #AUTHOR_TAG, we established that such vectors contain useful stylistic information about the english lexicon ( including rare words that appear only occasionally in such a corpus ), and indeed lsa vectors were the single most promising feature type for segmentation.', 'for a more detailed discussion of the feature set, see  #TAUTHOR_TAG.', '']",0
"['approach to voice identification in the waste land consists first of identifying the boundaries of voice spans  #TAUTHOR_TAG.', 'given a segmentation of the text, we consider']","['approach to voice identification in the waste land consists first of identifying the boundaries of voice spans  #TAUTHOR_TAG.', 'given a segmentation of the text, we consider']","['approach to voice identification in the waste land consists first of identifying the boundaries of voice spans  #TAUTHOR_TAG.', 'given a segmentation of the text, we consider each span as a data point in a clustering problem.', 'the elements of the vector correspond to the best feature set from the segmentation task, with the rationale that features which were useful']","['approach to voice identification in the waste land consists first of identifying the boundaries of voice spans  #TAUTHOR_TAG.', 'given a segmentation of the text, we consider each span as a data point in a clustering problem.', 'the elements of the vector correspond to the best feature set from the segmentation task, with the rationale that features which were useful for detecting changes in style should also be useful for identifying stylistic similarities.', 'our features therefore include : a collection of readability metrics ( including word length ), frequency of punctuation, line breaks, and various parts - ofspeech, lexical density, average frequency in a large external corpus  #AUTHOR_TAG, lexiconbased sentiment metrics using sentiwordnet  #AUTHOR_TAG, formality score  #AUTHOR_TAG, and, perhaps most notably, the centroid of 20 - dimensional distributional vectors built using latent semantic analysis  #AUTHOR_TAG, reflecting the use of words in a large web corpus  #AUTHOR_TAG ; in previous work  #AUTHOR_TAG, we established that such vectors contain useful stylistic information about the english lexicon ( including rare words that appear only occasionally in such a corpus ), and indeed lsa vectors were the single most promising feature type for segmentation.', 'for a more detailed discussion of the feature set, see  #TAUTHOR_TAG.', '']",0
"['focused on only the segmentation part of the voice identification task  #TAUTHOR_TAG.', 'here, we instead assume an initial segmentation and then try to create clusters corresponding to segments of the the waste']","['focused on only the segmentation part of the voice identification task  #TAUTHOR_TAG.', 'here, we instead assume an initial segmentation and then try to create clusters corresponding to segments of the the waste']","['obvious when a voice has reappeared.', 'our previous work focused on only the segmentation part of the voice identification task  #TAUTHOR_TAG.', 'here, we instead assume an initial segmentation and then try to create clusters corresponding to segments of the the waste land which are spoken by the same voice.', 'of particular interest is the influence of the initial segmentation on the success of this downstream task']","['', 'above the antique mantel was displayed as though a window gave upon the sylvan scene the change of philomel [ 97 ] [ 98 ] [ 99 ] although the stylistic contrasts between these and other voices are clear to many readers, eliot does not explicitly mark the transitions, nor is it obvious when a voice has reappeared.', 'our previous work focused on only the segmentation part of the voice identification task  #TAUTHOR_TAG.', 'here, we instead assume an initial segmentation and then try to create clusters corresponding to segments of the the waste land which are spoken by the same voice.', 'of particular interest is the influence of the initial segmentation on the success of this downstream task']",1
"['automatic segmentation model, we use the settings from  #TAUTHOR_TAG. we also compare three possible clusterings for', '']","['automatic segmentation model, we use the settings from  #TAUTHOR_TAG. we also compare three possible clusterings for', 'each segmentation']","['automatic segmentation model, we use the settings from  #TAUTHOR_TAG. we also compare three possible clusterings for', '']","['. the average size of the 69 segments in the gold standard', 'is 50 tokens ; the range, however, is fairly wide : the longest is 373 tokens, while the shortest consists of a single token.', 'our annotation has 13 voices altogether. we consider three segmentations : the segmentation of our gold standard ( gold ), the segmentation predicted by our segmentation model ( automatic ), and a segmentation which consists of equallength spans ( even ), with', 'the same number of spans as in the gold standard. the even segmentation should', 'be viewed as the baseline for segmentation, and the gold segmentation an "" oracle "" representing an upper bound on segmentation performance. for the automatic segmentation model, we use the settings from  #TAUTHOR_TAG. we also compare three possible clusterings for', 'each segmentation : no clustering at all ( initial ), that is, we assume that each segment is a new voice ; k - means clustering ( k - means ), as outlined above ; and random clustering ( random ),', 'in which we randomly assign each voice to a cluster. for these latter two methods, which both have a random component, we averaged our metrics over 50 runs. random and initial are here, of course, to provide baselines for judging the effectiveness of k - means clustering', 'model. finally, when using the gold standard segmentation and k - means clustering, we included another oracle option ( seeded ) : instead of the standard k - means method of randomly choosing them', 'from the available datapoints, each centroid is initialized to the longest instance of a different voice, essentially', 'seeding each cluster. table 1 contains the results for our first evaluation of voice clustering, the automatically - generated poems. in all the conditions, using the gold segmentation far outstrips the other two options. the automatic segmentation is consistently better than the evenly - spaced baseline, but the performance is actually worse than expected ; the segmentation metrics we used in our earlier work the results', 'for the waste land are in table 2. many of the basic patterns are the same, including the consistent ranking of the methods ; overall, however, the clustering is far less effective.', 'this is particularly true for the gold - standard condition, which only increases modest', '##ly between the initial and clustered state ; the marked increase in recall is balanced by a major loss of precision. in fact, unlike with the artificial text, the most promising aspect of the clustering seems to be the fairly sizable boost to the quality of clusters in automatic segmenting', 'performance. the effect of seeding is also very consistent, nearly as effective as in the automatic case']",5
['deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work'],['deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work'],"[')  #AUTHOR_TAG. recently, a number of taskspecific attention variants have been proposed to deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work performed', 'while at apple. to deal with repetition and over - copying in']","['often caused by the gap between the input and output vocabularies )  #AUTHOR_TAG. recently, a number of taskspecific attention variants have been proposed to deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work performed', 'while at apple. to deal with repetition and over - copying in summarization,  #AUTHOR_TAG introduced a method of attending over keyphrases to improve argument generation, and  #AUTHOR_TAG introduced a method that attends to an agenda of items to improve recipe generation. perhaps not surprisingly, general - purpose attention mechanisms', 'targeting individual problems from the list above have also begun to be developed. copynet  #AUTHOR_TAG and pointer - generator networks  #AUTHOR_TAG, for example, aim to reduce input', '- output vocabulary mismatch and, thereby, improve specificity, while the coveragebased techniques of  #TAUTHOR_TAG tackle repetition and under - generation. these techniques, however, often require significant hyperparameter tuning and are purposely limited to fixing a specific problem in', 'the generated text. we present here a general - purpose addition to the standard seq2seq framework that aims to simultaneously', 'tackle all of the above issues. in particular, we propose scratchpad, a novel write mechanism that allows the decoder to keep notes on its past actions ( i. e., generation, attention, copying )', 'by directly modifying encoder states. the scratchpad mechanism essentially lets the decoder more easily keep track of what the model has focused on', '']",0
['deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work'],['deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work'],"[')  #AUTHOR_TAG. recently, a number of taskspecific attention variants have been proposed to deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work performed', 'while at apple. to deal with repetition and over - copying in']","['often caused by the gap between the input and output vocabularies )  #AUTHOR_TAG. recently, a number of taskspecific attention variants have been proposed to deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work performed', 'while at apple. to deal with repetition and over - copying in summarization,  #AUTHOR_TAG introduced a method of attending over keyphrases to improve argument generation, and  #AUTHOR_TAG introduced a method that attends to an agenda of items to improve recipe generation. perhaps not surprisingly, general - purpose attention mechanisms', 'targeting individual problems from the list above have also begun to be developed. copynet  #AUTHOR_TAG and pointer - generator networks  #AUTHOR_TAG, for example, aim to reduce input', '- output vocabulary mismatch and, thereby, improve specificity, while the coveragebased techniques of  #TAUTHOR_TAG tackle repetition and under - generation. these techniques, however, often require significant hyperparameter tuning and are purposely limited to fixing a specific problem in', 'the generated text. we present here a general - purpose addition to the standard seq2seq framework that aims to simultaneously', 'tackle all of the above issues. in particular, we propose scratchpad, a novel write mechanism that allows the decoder to keep notes on its past actions ( i. e., generation, attention, copying )', 'by directly modifying encoder states. the scratchpad mechanism essentially lets the decoder more easily keep track of what the model has focused on', '']",0
['deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work'],['deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work'],"[')  #AUTHOR_TAG. recently, a number of taskspecific attention variants have been proposed to deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work performed', 'while at apple. to deal with repetition and over - copying in']","['often caused by the gap between the input and output vocabularies )  #AUTHOR_TAG. recently, a number of taskspecific attention variants have been proposed to deal with these issues :  #AUTHOR_TAG introduced a coverage mechanism  #TAUTHOR_TAG * work performed', 'while at apple. to deal with repetition and over - copying in summarization,  #AUTHOR_TAG introduced a method of attending over keyphrases to improve argument generation, and  #AUTHOR_TAG introduced a method that attends to an agenda of items to improve recipe generation. perhaps not surprisingly, general - purpose attention mechanisms', 'targeting individual problems from the list above have also begun to be developed. copynet  #AUTHOR_TAG and pointer - generator networks  #AUTHOR_TAG, for example, aim to reduce input', '- output vocabulary mismatch and, thereby, improve specificity, while the coveragebased techniques of  #TAUTHOR_TAG tackle repetition and under - generation. these techniques, however, often require significant hyperparameter tuning and are purposely limited to fixing a specific problem in', 'the generated text. we present here a general - purpose addition to the standard seq2seq framework that aims to simultaneously', 'tackle all of the above issues. in particular, we propose scratchpad, a novel write mechanism that allows the decoder to keep notes on its past actions ( i. e., generation, attention, copying )', 'by directly modifying encoder states. the scratchpad mechanism essentially lets the decoder more easily keep track of what the model has focused on', '']",0
['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],"['', 'of text  #AUTHOR_TAG, with most of the work being a variant of the seq2seq approach.  #AUTHOR_TAG, a seq2seq model with copynet and a coverage mechanism  #TAUTHOR_TAG is used to achieve state - of', '- the - art results. we have demonstrated that our scratchpad outperforms this approach in both quantitative and qualitative evaluations. attention closest to our work, in', 'the general paradigm of seq2seq learning, is the coverage mechanism introduced in  #TAUTHOR_TAG', 'and later adapted for summarization in  #AUTHOR_TAG. both works try to minimize erroneous repetitions generated by a copy mechanism by introducing a new vector to keep track of what has been', 'used from the encoder thus far.  #AUTHOR_TAG, for example, use an extra gru to keep track of this information, whereas  #AUTHOR_TAG keep track of the sum of attention weights and add a penalty to the loss function', 'based on it to discourage repetition. our approach is much simpler than either solution since it does not require any extra vectors or an additional loss term ; rather, the encoder vector itself is being used as scratch memory. our', 'experiments also show that for the question generation task, the scratchpad performs better than coverage based approaches. our idea was influenced by the dialogue generation work', 'of  #AUTHOR_TAG in which the entire sequence of interactions is', 're - encoded every time a response is generated by the decoder']",0
"['incorporates coverage  #TAUTHOR_TAG.', 'table 1 shows ble']","['incorporates coverage  #TAUTHOR_TAG.', 'table 1 shows bleu scores of our approach on 3 iwslt translation tasks along with reported results from']","['incorporates coverage  #TAUTHOR_TAG.', 'table 1 shows bleu scores of our approach on 3 iwslt translation tasks along with reported results from previous work.', 'our']","['evaluate on the iwlst 14 english to german and spanish to english translation datasets  #AUTHOR_TAG as well as the iwslt 15  #AUTHOR_TAG english to vietnamese translation dataset.', 'for iwslt14  #AUTHOR_TAG, we compare to the models evaluated by  #AUTHOR_TAG, which includes a transformer  #AUTHOR_TAG and rnn - based models  #AUTHOR_TAG.', 'for iwslt15, we primarily compare to gnmt  #AUTHOR_TAG, which incorporates coverage  #TAUTHOR_TAG.', 'table 1 shows bleu scores of our approach on 3 iwslt translation tasks along with reported results from previous work.', 'our approach achieves state - of - the - art or comparable results on all datasets.', 'experimental details for iwslt14, our encoder is a 3 - layer bi - lstm  #AUTHOR_TAG, where outputs are combined by concatenation, and the decoder is a 3 - layer lstm as well.', 'for iwslt15 the encoder and decoder are 2 - layers.', ""we follow, using the'general'score function, input feeding, and combining the attentional context and hidden state."", 'since we use input feeding, steps ( 1 ) and ( 2 ) in section 3 are switched.', ""all our models have a hidden size of 512 ( for the lstm and any mlp's )."", '']",3
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],"['', 'accordingly, we compare our scratchpad mechanism against three baselines : ( 1 ) seq2seq, ( 2 ) copynet and ( 3 ) coverage, a method introduced by  #TAUTHOR_TAG that aims to solve attention - related problems.', 'seq2seq is the standard approach introduced in.', 'the copynet  #AUTHOR_TAG baseline additionally gives the seq2seq model the ability to copy vocabulary from the source to the target.', '']",3
['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],"['', 'of text  #AUTHOR_TAG, with most of the work being a variant of the seq2seq approach.  #AUTHOR_TAG, a seq2seq model with copynet and a coverage mechanism  #TAUTHOR_TAG is used to achieve state - of', '- the - art results. we have demonstrated that our scratchpad outperforms this approach in both quantitative and qualitative evaluations. attention closest to our work, in', 'the general paradigm of seq2seq learning, is the coverage mechanism introduced in  #TAUTHOR_TAG', 'and later adapted for summarization in  #AUTHOR_TAG. both works try to minimize erroneous repetitions generated by a copy mechanism by introducing a new vector to keep track of what has been', 'used from the encoder thus far.  #AUTHOR_TAG, for example, use an extra gru to keep track of this information, whereas  #AUTHOR_TAG keep track of the sum of attention weights and add a penalty to the loss function', 'based on it to discourage repetition. our approach is much simpler than either solution since it does not require any extra vectors or an additional loss term ; rather, the encoder vector itself is being used as scratch memory. our', 'experiments also show that for the question generation task, the scratchpad performs better than coverage based approaches. our idea was influenced by the dialogue generation work', 'of  #AUTHOR_TAG in which the entire sequence of interactions is', 're - encoded every time a response is generated by the decoder']",3
['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],"['', 'of text  #AUTHOR_TAG, with most of the work being a variant of the seq2seq approach.  #AUTHOR_TAG, a seq2seq model with copynet and a coverage mechanism  #TAUTHOR_TAG is used to achieve state - of', '- the - art results. we have demonstrated that our scratchpad outperforms this approach in both quantitative and qualitative evaluations. attention closest to our work, in', 'the general paradigm of seq2seq learning, is the coverage mechanism introduced in  #TAUTHOR_TAG', 'and later adapted for summarization in  #AUTHOR_TAG. both works try to minimize erroneous repetitions generated by a copy mechanism by introducing a new vector to keep track of what has been', 'used from the encoder thus far.  #AUTHOR_TAG, for example, use an extra gru to keep track of this information, whereas  #AUTHOR_TAG keep track of the sum of attention weights and add a penalty to the loss function', 'based on it to discourage repetition. our approach is much simpler than either solution since it does not require any extra vectors or an additional loss term ; rather, the encoder vector itself is being used as scratch memory. our', 'experiments also show that for the question generation task, the scratchpad performs better than coverage based approaches. our idea was influenced by the dialogue generation work', 'of  #AUTHOR_TAG in which the entire sequence of interactions is', 're - encoded every time a response is generated by the decoder']",3
['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],['by  #TAUTHOR_TAG'],"['', 'accordingly, we compare our scratchpad mechanism against three baselines : ( 1 ) seq2seq, ( 2 ) copynet and ( 3 ) coverage, a method introduced by  #TAUTHOR_TAG that aims to solve attention - related problems.', 'seq2seq is the standard approach introduced in.', 'the copynet  #AUTHOR_TAG baseline additionally gives the seq2seq model the ability to copy vocabulary from the source to the target.', '']",5
['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],"['', 'of text  #AUTHOR_TAG, with most of the work being a variant of the seq2seq approach.  #AUTHOR_TAG, a seq2seq model with copynet and a coverage mechanism  #TAUTHOR_TAG is used to achieve state - of', '- the - art results. we have demonstrated that our scratchpad outperforms this approach in both quantitative and qualitative evaluations. attention closest to our work, in', 'the general paradigm of seq2seq learning, is the coverage mechanism introduced in  #TAUTHOR_TAG', 'and later adapted for summarization in  #AUTHOR_TAG. both works try to minimize erroneous repetitions generated by a copy mechanism by introducing a new vector to keep track of what has been', 'used from the encoder thus far.  #AUTHOR_TAG, for example, use an extra gru to keep track of this information, whereas  #AUTHOR_TAG keep track of the sum of attention weights and add a penalty to the loss function', 'based on it to discourage repetition. our approach is much simpler than either solution since it does not require any extra vectors or an additional loss term ; rather, the encoder vector itself is being used as scratch memory. our', 'experiments also show that for the question generation task, the scratchpad performs better than coverage based approaches. our idea was influenced by the dialogue generation work', 'of  #AUTHOR_TAG in which the entire sequence of interactions is', 're - encoded every time a response is generated by the decoder']",5
['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],['coverage mechanism  #TAUTHOR_TAG is used to'],"['', 'of text  #AUTHOR_TAG, with most of the work being a variant of the seq2seq approach.  #AUTHOR_TAG, a seq2seq model with copynet and a coverage mechanism  #TAUTHOR_TAG is used to achieve state - of', '- the - art results. we have demonstrated that our scratchpad outperforms this approach in both quantitative and qualitative evaluations. attention closest to our work, in', 'the general paradigm of seq2seq learning, is the coverage mechanism introduced in  #TAUTHOR_TAG', 'and later adapted for summarization in  #AUTHOR_TAG. both works try to minimize erroneous repetitions generated by a copy mechanism by introducing a new vector to keep track of what has been', 'used from the encoder thus far.  #AUTHOR_TAG, for example, use an extra gru to keep track of this information, whereas  #AUTHOR_TAG keep track of the sum of attention weights and add a penalty to the loss function', 'based on it to discourage repetition. our approach is much simpler than either solution since it does not require any extra vectors or an additional loss term ; rather, the encoder vector itself is being used as scratch memory. our', 'experiments also show that for the question generation task, the scratchpad performs better than coverage based approaches. our idea was influenced by the dialogue generation work', 'of  #AUTHOR_TAG in which the entire sequence of interactions is', 're - encoded every time a response is generated by the decoder']",5
"[' #TAUTHOR_TAG either imposed an extra', 'term to']","[' #TAUTHOR_TAG either imposed an extra', 'term to']","['based on coverage based approaches  #TAUTHOR_TAG either imposed an extra', 'term to the loss']","['', 'focused distributions ( very low entropy, e. g. ≤ 0. 5 ) increasing significantly, over 4× that for the non - scratchpad model. previous work based on coverage based approaches  #TAUTHOR_TAG either imposed an extra', 'term to the loss function or used an extra vector to keep track of which parts of the input sequences had been attended to, thereby focusing the attention weights in subsequent steps on tokens that received little attention before. in other words, focusing the attention on the relevant parts of the input. our proposed approach naturally learns to focus the attention on the important tokens, without a need for modifying the loss function or introducing coverage vectors']",4
"['', ' #TAUTHOR_TAG proposed a model that learns']","['has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns']","['program scripts  #AUTHOR_TAG.', 'prior work has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns']","['', 'prior work has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns to perform the task from a parallel corpus of regular expressions and the text descriptions.', 'to account for the given representational disparity between formal regular expressions and natural language, their model utilizes a domain specific 1 code and data are submitted as supplementary material.', '']",0
"['', ' #TAUTHOR_TAG proposed a model that learns']","['has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns']","['program scripts  #AUTHOR_TAG.', 'prior work has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns']","['', 'prior work has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns to perform the task from a parallel corpus of regular expressions and the text descriptions.', 'to account for the given representational disparity between formal regular expressions and natural language, their model utilizes a domain specific 1 code and data are submitted as supplementary material.', '']",5
"[' #TAUTHOR_TAG.', '']","[' #TAUTHOR_TAG.', '']","['level operations.', 'we identify these via frequency analysis of smaller datasets from previous work  #TAUTHOR_TAG.', '']","['', 'in the generate step, we generate regular expression representations from a small manually - crafted grammar ( table 1 ).', 'our grammar includes 15 nonterminal derivations and 6 terminals and of both basic and high - level operations.', 'we identify these via frequency analysis of smaller datasets from previous work  #TAUTHOR_TAG.', 'every grammar rule has associated verbalizations for both regular expressions and language descriptions.', 'we use this grammar to stochastically generate regular expressions and their corresponding synthetic language descriptions.', 'this generation process is shown in figure 2.', 'while the automatically generated descriptions are semantically correct, they do not exhibit richness and variability of human - generated descriptions.', '']",5
"[' #TAUTHOR_TAG ( kb13 ), although it contains far fewer data points ( 824 ).', 'we use']","[' #TAUTHOR_TAG ( kb13 ), although it contains far fewer data points ( 824 ).', 'we use']","[' #TAUTHOR_TAG ( kb13 ), although it contains far fewer data points ( 824 ).', 'we use']","['we split the 10, 000 regexp and description pairs in nl - rx into 65 % train, 10 % dev, and 25 % test sets.', 'in addition, we also evaluate our model on the dataset used by  #TAUTHOR_TAG ( kb13 ), although it contains far fewer data points ( 824 ).', 'we use the 75 / 25 train / test split used in their work in order directly compare our performance to theirs.', 'training we perform a hyper - parameter gridsearch ( on the dev set ), to determine our model hyper - parameters : learning - rate = 1. 0, encoderdepth = 2, decoder - depth = 2, batch size = 32, dropout = 0. 25.', 'we use a torch  #AUTHOR_TAG implementation of attention sequence to sequence networks from  #AUTHOR_TAG.', 'we train our models on the train set for 20 epochs, and choose the model with the best average loss on the dev set.', 'called dfa - equal.', 'we employ functional equality because there are many ways to write equivalent regular expressions.', 'for example, ( a | b ) is functionally equivalent to ( b | a ), despite their string representations differing.', ""we report dfa - equal accuracy as our model's evaluation metric, using  #TAUTHOR_TAG's implementation to directly compare our results""]",5
"[' #TAUTHOR_TAG ( kb13 ), although it contains far fewer data points ( 824 ).', 'we use']","[' #TAUTHOR_TAG ( kb13 ), although it contains far fewer data points ( 824 ).', 'we use']","[' #TAUTHOR_TAG ( kb13 ), although it contains far fewer data points ( 824 ).', 'we use']","['we split the 10, 000 regexp and description pairs in nl - rx into 65 % train, 10 % dev, and 25 % test sets.', 'in addition, we also evaluate our model on the dataset used by  #TAUTHOR_TAG ( kb13 ), although it contains far fewer data points ( 824 ).', 'we use the 75 / 25 train / test split used in their work in order directly compare our performance to theirs.', 'training we perform a hyper - parameter gridsearch ( on the dev set ), to determine our model hyper - parameters : learning - rate = 1. 0, encoderdepth = 2, decoder - depth = 2, batch size = 32, dropout = 0. 25.', 'we use a torch  #AUTHOR_TAG implementation of attention sequence to sequence networks from  #AUTHOR_TAG.', 'we train our models on the train set for 20 epochs, and choose the model with the best average loss on the dev set.', 'called dfa - equal.', 'we employ functional equality because there are many ways to write equivalent regular expressions.', 'for example, ( a | b ) is functionally equivalent to ( b | a ), despite their string representations differing.', ""we report dfa - equal accuracy as our model's evaluation metric, using  #TAUTHOR_TAG's implementation to directly compare our results""]",5
"['model from  #TAUTHOR_TAG, explained above']","['prediction.', 'semantic - unify : our second baseline, semanticunify, is the previous state - of - the - art model from  #TAUTHOR_TAG, explained above.', '']","[': our second baseline, semanticunify, is the previous state - of - the - art model from  #TAUTHOR_TAG, explained above.', '']","['', 'semantic - unify : our second baseline, semanticunify, is the previous state - of - the - art model from  #TAUTHOR_TAG, explained above.', '']",5
"['', ' #TAUTHOR_TAG proposed a model that learns']","['has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns']","['program scripts  #AUTHOR_TAG.', 'prior work has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns']","['', 'prior work has demonstrated the feasibility of this task.', ' #TAUTHOR_TAG proposed a model that learns to perform the task from a parallel corpus of regular expressions and the text descriptions.', 'to account for the given representational disparity between formal regular expressions and natural language, their model utilizes a domain specific 1 code and data are submitted as supplementary material.', '']",3
"[',  #TAUTHOR_TAG showed that a']","['to natural language questions,  #TAUTHOR_TAG showed that a']","['.', 'by converting such kb queries to natural language questions,  #TAUTHOR_TAG showed that']","['base population ( kbp, e. g. :  #AUTHOR_TAG attempts to identify facts within raw text and convert them into triples consisting of a subject, object and the relation between them.', 'one common form of this task is slot filling  #AUTHOR_TAG, in which a knowledge base ( kb ) query, such as place of birth ( obama,? ) is applied to a set of documents and a set of slot fillers is returned.', 'by converting such kb queries to natural language questions,  #TAUTHOR_TAG showed that a question answering ( qa ) system could be effectively applied to this task.', 'however,  #TAUTHOR_TAG approach relied on a modified qa model architecture and a dedicated slot - filling training corpus.', 'here, we investigate the utility of standard qa data and models for this task.', ""our results show that this approach is effective in the zero - shot and low - resource cases, and is more robust on a set of test instances designed to challenge the models'ability to identify relations between subject and object."", 'figure 1 gives an overview of using qa on the slot - filling task.', 'starting at the top right, a kb query is translated into a natural language question, which can then be fed into a qa model that has been trained on an appropriate resource.', 'when applied to a set of texts, this model needs to predict the correct answer within each text, including the possibility that a text contains no answer.', 'within this framework, we consider different models and training and test datasets, but we keep the translation of kb queries into natural language questions fixed, based on the crowd - sourced templates used by  #TAUTHOR_TAG']",0
"[' #TAUTHOR_TAG, which uses an additional bias term to allow']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', 'to signal']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow']","['answer, based on the spans provided by the annotators. in other words, we are left with the original question', 'and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as positive examples', '. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training time.', 'we also construct a series of datasets that combine increasing quantities of the uwre entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10', '3, 10 4, 10 5 and 10 6 uwre instances are added to our squad training set, while leaving the squ', '##ad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', '']",0
"[' #TAUTHOR_TAG, which uses an additional bias term to allow']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', 'to signal']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow']","['answer, based on the spans provided by the annotators. in other words, we are left with the original question', 'and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as positive examples', '. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training time.', 'we also construct a series of datasets that combine increasing quantities of the uwre entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10', '3, 10 4, 10 5 and 10 6 uwre instances are added to our squad training set, while leaving the squ', '##ad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', '']",0
"[' #TAUTHOR_TAG, which uses an additional bias term to allow']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', 'to signal']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow']","['answer, based on the spans provided by the annotators. in other words, we are left with the original question', 'and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as positive examples', '. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training time.', 'we also construct a series of datasets that combine increasing quantities of the uwre entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10', '3, 10 4, 10 5 and 10 6 uwre instances are added to our squad training set, while leaving the squ', '##ad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', '']",0
"[',  #TAUTHOR_TAG showed that a']","['to natural language questions,  #TAUTHOR_TAG showed that a']","['.', 'by converting such kb queries to natural language questions,  #TAUTHOR_TAG showed that']","['base population ( kbp, e. g. :  #AUTHOR_TAG attempts to identify facts within raw text and convert them into triples consisting of a subject, object and the relation between them.', 'one common form of this task is slot filling  #AUTHOR_TAG, in which a knowledge base ( kb ) query, such as place of birth ( obama,? ) is applied to a set of documents and a set of slot fillers is returned.', 'by converting such kb queries to natural language questions,  #TAUTHOR_TAG showed that a question answering ( qa ) system could be effectively applied to this task.', 'however,  #TAUTHOR_TAG approach relied on a modified qa model architecture and a dedicated slot - filling training corpus.', 'here, we investigate the utility of standard qa data and models for this task.', ""our results show that this approach is effective in the zero - shot and low - resource cases, and is more robust on a set of test instances designed to challenge the models'ability to identify relations between subject and object."", 'figure 1 gives an overview of using qa on the slot - filling task.', 'starting at the top right, a kb query is translated into a natural language question, which can then be fed into a qa model that has been trained on an appropriate resource.', 'when applied to a set of texts, this model needs to predict the correct answer within each text, including the possibility that a text contains no answer.', 'within this framework, we consider different models and training and test datasets, but we keep the translation of kb queries into natural language questions fixed, based on the crowd - sourced templates used by  #TAUTHOR_TAG']",5
"[' #TAUTHOR_TAG, which uses an additional bias term to allow']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', 'to signal']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow']","['answer, based on the spans provided by the annotators. in other words, we are left with the original question', 'and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as positive examples', '. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training time.', 'we also construct a series of datasets that combine increasing quantities of the uwre entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10', '3, 10 4, 10 5 and 10 6 uwre instances are added to our squad training set, while leaving the squ', '##ad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', '']",5
"[' #TAUTHOR_TAG, which uses an additional bias term to allow']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', 'to signal']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow']","['answer, based on the spans provided by the annotators. in other words, we are left with the original question', 'and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as positive examples', '. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training time.', 'we also construct a series of datasets that combine increasing quantities of the uwre entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10', '3, 10 4, 10 5 and 10 6 uwre instances are added to our squad training set, while leaving the squ', '##ad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', '']",5
"[' #TAUTHOR_TAG, which uses an additional bias term to allow']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', 'to signal']","['modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow']","['answer, based on the spans provided by the annotators. in other words, we are left with the original question', 'and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as positive examples', '. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training time.', 'we also construct a series of datasets that combine increasing quantities of the uwre entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10', '3, 10 4, 10 5 and 10 6 uwre instances are added to our squad training set, while leaving the squ', '##ad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG, which uses an additional bias term to allow the model', '']",3
['slot filling  #TAUTHOR_TAG modify'],['slot filling  #TAUTHOR_TAG modify'],['slot filling  #TAUTHOR_TAG modify'],"['results on our challenge test set suggest that the model does not learn to examine the relation between the answer span and the relation subject unless the training data requires it.', 'in the case of squad, the fact that the answer has to be found within a multi - sentence paragraph provides enough potential distractors to overcome this issue.', ""other models may show different patterns of strength and weakness, but to be able to investigate and exploit further qa systems quickly would require a means of producing'no answer'predictions without the need to modify the model implementation."", '4 using an unmodified qa model for slot filling  #TAUTHOR_TAG modify the bidaf architecture to produce an additional output representing the probability that no answer is present in the text.', 'in this experiment, we investigate whether it is possible to adapt a qa model to the slot filling task without having to understand and modify its internal structure and implementation.', 'our approach model acc bidaf 0. 82 fastqa 0. 99 merely requires prefixing all texts with a dummy token that stands in for the answer when no real answer is present.', 'data we train our models on a modified version of squad, which has been augmented with negative examples by removing answer spans, as described in section 2, and then had the token noanswerfound inserted into every text and as the answer for the negative examples, as described above.', 'models we train both bidaf  #AUTHOR_TAG and fastqa  #AUTHOR_TAG models on the modified squad training data, using their standard architectures and hyperparameters.', 'evaluation we evaluate f1 on the same zeroshot evaluation considered in section 2 and also accuracy on the challenge test set from section 3.', 'results table 3 reveals that the unmodified bidaf model is almost as effective as the  #TAUTHOR_TAG model in terms of zero - shot f1 on the original uwre test set.', ""in contrast, fastqa's performance is substantially worse."", ""however, table 4 reveals that fastqa is extremely accurate on the challenge test set, while bidaf's performance is comparable to the modified model trained on squad."", 'the unmodified bidaf and fastqa architectures have complementary strengths on the two evaluations.', ""fastqa's strong performance on the challenge instances may be related to its use of binary features indicating whether a word was present in the question""]",4
"['from a linguistic resource  #TAUTHOR_TAG.', 'we review qvec,']","['from a linguistic resource  #TAUTHOR_TAG.', 'we review qvec,']","['from a linguistic resource  #TAUTHOR_TAG.', 'we review qvec,']","['introduce qvec - cca - an intrinsic evaluation measure of the quality of word embeddings.', 'our method is a modification of qvec - an evaluation based on alignment of embeddings to a matrix of features extracted from a linguistic resource  #TAUTHOR_TAG.', 'we review qvec, and then describe qvec - cca']",6
"['evaluate the semantic content of word vectors,  #TAUTHOR_TAG exploit supersense annotations in a wordnetannotated corpus - sem']","['evaluate the semantic content of word vectors,  #TAUTHOR_TAG exploit supersense annotations in a wordnetannotated corpus - semcor  #AUTHOR_TAG table']","['evaluate the semantic content of word vectors,  #TAUTHOR_TAG exploit supersense annotations in a wordnetannotated corpus - semcor  #AUTHOR_TAG table']","['evaluate the semantic content of word vectors,  #TAUTHOR_TAG exploit supersense annotations in a wordnetannotated corpus - semcor  #AUTHOR_TAG table 2 : linguistic dimension word vector matrix with syntactic vectors, constructed using ptb.', '• we first train 21 word vector models : variants of cbow and skip - gram models  #AUTHOR_TAG ; their modifications cwindow, structured skip - gram, and cbow with attention  #AUTHOR_TAG b ;  #AUTHOR_TAG a ) ; glove vectors  #AUTHOR_TAG ; latent semantic analysis ( lsa ) based vectors  #AUTHOR_TAG ; and retrofitted glove and lsa vectors.', '• we then evaluate these word vector models using existing intrinsic evaluation methods : qvec and the proposed qvec - cca, and also word similarity tasks using the wordsim353 dataset  #AUTHOR_TAG ws - 353 ), men dataset  #AUTHOR_TAG, and simlex - 999 dataset  #AUTHOR_TAG simlex ).', '3 • in addition, the same vectors are evaluated using extrinsic text classification tasks.', 'our semantic benchmarks are four binary categorization tasks from the 20 newsgroups ( 20ng ) ; sentiment analysis task  #AUTHOR_TAG senti ) ; and the metaphor detection  #AUTHOR_TAG metaphor ).', ""• finally, we compute the pearson's correlation coefficient r to quantify the linear relationship between the intrinsic and extrinsic scorings."", 'the higher the correlation, the better suited the intrinsic evaluation to be used as a proxy to the extrinsic task.', 'we extend the setup of  #TAUTHOR_TAG with two syntactic benchmarks, and evaluate qvec - cca with the syntactic matrix.', 'the first task is pos tagging ; we use the lstm - crf model  #AUTHOR_TAG, and the second is dependency parsing ( parse ), using the stack - lstm model of']",6
"['evaluate the semantic content of word vectors,  #TAUTHOR_TAG exploit supersense annotations in a wordnetannotated corpus - sem']","['evaluate the semantic content of word vectors,  #TAUTHOR_TAG exploit supersense annotations in a wordnetannotated corpus - semcor  #AUTHOR_TAG table']","['evaluate the semantic content of word vectors,  #TAUTHOR_TAG exploit supersense annotations in a wordnetannotated corpus - semcor  #AUTHOR_TAG table']","['evaluate the semantic content of word vectors,  #TAUTHOR_TAG exploit supersense annotations in a wordnetannotated corpus - semcor  #AUTHOR_TAG table 2 : linguistic dimension word vector matrix with syntactic vectors, constructed using ptb.', '• we first train 21 word vector models : variants of cbow and skip - gram models  #AUTHOR_TAG ; their modifications cwindow, structured skip - gram, and cbow with attention  #AUTHOR_TAG b ;  #AUTHOR_TAG a ) ; glove vectors  #AUTHOR_TAG ; latent semantic analysis ( lsa ) based vectors  #AUTHOR_TAG ; and retrofitted glove and lsa vectors.', '• we then evaluate these word vector models using existing intrinsic evaluation methods : qvec and the proposed qvec - cca, and also word similarity tasks using the wordsim353 dataset  #AUTHOR_TAG ws - 353 ), men dataset  #AUTHOR_TAG, and simlex - 999 dataset  #AUTHOR_TAG simlex ).', '3 • in addition, the same vectors are evaluated using extrinsic text classification tasks.', 'our semantic benchmarks are four binary categorization tasks from the 20 newsgroups ( 20ng ) ; sentiment analysis task  #AUTHOR_TAG senti ) ; and the metaphor detection  #AUTHOR_TAG metaphor ).', ""• finally, we compute the pearson's correlation coefficient r to quantify the linear relationship between the intrinsic and extrinsic scorings."", 'the higher the correlation, the better suited the intrinsic evaluation to be used as a proxy to the extrinsic task.', 'we extend the setup of  #TAUTHOR_TAG with two syntactic benchmarks, and evaluate qvec - cca with the syntactic matrix.', 'the first task is pos tagging ; we use the lstm - crf model  #AUTHOR_TAG, and the second is dependency parsing ( parse ), using the stack - lstm model of']",0
"['- by - word conditioned on a dialogue context [  #TAUTHOR_TAG b.', 'the second are discriminative models,']","['responses word - by - word conditioned on a dialogue context [  #TAUTHOR_TAG b.', 'the second are discriminative models,']","['- by - word conditioned on a dialogue context [  #TAUTHOR_TAG b.', 'the second are discriminative models,']","['have recently started investigating sequence - to - sequence ( seq2seq ) models for dialogue applications.', 'these models typically use neural networks to both represent dialogue histories and to generate or select appropriate responses.', 'such models are able to leverage large amounts of data in order to learn meaningful natural language representations and generation strategies, while requiring a minimum amount of domain knowledge and hand - crafting.', ""although the seq2seq framework is different from the well - established goal - oriented setting [  #AUTHOR_TAG these models have already been applied to several real - world applications, with microsoft's system xiaoice [  #AUTHOR_TAG ] and google's smart reply system [  #AUTHOR_TAG ] as two prominent examples."", 'researchers have mainly explored two types of seq2seq models.', 'the first are generative models, which are usually trained with cross - entropy to generate responses word - by - word conditioned on a dialogue context [  #TAUTHOR_TAG b.', 'the second are discriminative models, which are trained to select an appropriate response from a set of candidate responses [  #AUTHOR_TAG.', 'in a related strand of work, researchers have also investigated applying neural networks to the different components of a standard dialogue system, including natural language understanding, natural language generation, dialogue state tracking and evaluation [  #AUTHOR_TAG mrksic et al., 2015.', 'in this paper, we focus on generative models trained with cross - entropy.', '']",0
"['example, given a dialogue context, the model must generate an appropriate response.', 'we also present results on twitter in the appendix.', 'this task has been studied extensively in the recent literature [  #TAUTHOR_TAG.', 'corpus : the ubunt']","['example, given a dialogue context, the model must generate an appropriate response.', 'we also present results on twitter in the appendix.', 'this task has been studied extensively in the recent literature [  #TAUTHOR_TAG.', 'corpus : the ubuntu dialogue corpus consists of about']","[' #AUTHOR_TAG ].', 'for each example, given a dialogue context, the model must generate an appropriate response.', 'we also present results on twitter in the appendix.', 'this task has been studied extensively in the recent literature [  #TAUTHOR_TAG.', 'corpus : the ubuntu dialogue corpus consists of about half a million dialogues']","['apply our generative models to dialogue response generation on the ubuntu dialogue corpus [  #AUTHOR_TAG ].', 'for each example, given a dialogue context, the model must generate an appropriate response.', 'we also present results on twitter in the appendix.', 'this task has been studied extensively in the recent literature [  #TAUTHOR_TAG.', 'corpus : the ubuntu dialogue corpus consists of about half a million dialogues extracted from the # ubuntu internet relayed chat ( irc ) channel.', 'users entering this chat channel usually have a specific technical problem.', 'typically, users first describe their problem, and other users try to help them resolve it.', 'the technical problems range from software - related and hardware - related issues ( e. g. installing packages, fixing broken drivers ) to informational needs ( e. g. finding software )']",0
"['', ' #TAUTHOR_TAG propose ranking']","['', ' #TAUTHOR_TAG propose ranking']","[' #AUTHOR_TAG ].', ' #TAUTHOR_TAG propose ranking']","['', ' #TAUTHOR_TAG propose ranking candidate responses according to a mutual information criterion, in order to incorporate dialogue context efficiently and retrieve on - topic responses.', '']",0
"['- by - word conditioned on a dialogue context [  #TAUTHOR_TAG b.', 'the second are discriminative models,']","['responses word - by - word conditioned on a dialogue context [  #TAUTHOR_TAG b.', 'the second are discriminative models,']","['- by - word conditioned on a dialogue context [  #TAUTHOR_TAG b.', 'the second are discriminative models,']","['have recently started investigating sequence - to - sequence ( seq2seq ) models for dialogue applications.', 'these models typically use neural networks to both represent dialogue histories and to generate or select appropriate responses.', 'such models are able to leverage large amounts of data in order to learn meaningful natural language representations and generation strategies, while requiring a minimum amount of domain knowledge and hand - crafting.', ""although the seq2seq framework is different from the well - established goal - oriented setting [  #AUTHOR_TAG these models have already been applied to several real - world applications, with microsoft's system xiaoice [  #AUTHOR_TAG ] and google's smart reply system [  #AUTHOR_TAG ] as two prominent examples."", 'researchers have mainly explored two types of seq2seq models.', 'the first are generative models, which are usually trained with cross - entropy to generate responses word - by - word conditioned on a dialogue context [  #TAUTHOR_TAG b.', 'the second are discriminative models, which are trained to select an appropriate response from a set of candidate responses [  #AUTHOR_TAG.', 'in a related strand of work, researchers have also investigated applying neural networks to the different components of a standard dialogue system, including natural language understanding, natural language generation, dialogue state tracking and evaluation [  #AUTHOR_TAG mrksic et al., 2015.', 'in this paper, we focus on generative models trained with cross - entropy.', '']",1
"['of hotels  #TAUTHOR_TAG.', 'we show an experimental study evaluating the single features']","['of hotels  #TAUTHOR_TAG.', 'we show an experimental study evaluating the single features']","['to fake reviews.', 'we focus our study in a variant of the stylistic feature character n - grams named character n - grams in tokens.', 'we also study an emotion - based feature and a linguistic processes feature based on liwc variables.', 'we evaluated the proposed features with a support vector machines ( svm ) classifier using a corpus of 1600 reviews of hotels  #TAUTHOR_TAG.', 'we show an experimental study evaluating the single features']","['is commonly present on the web through of fake opinions, untrue reviews, malicious comments or unwanted texts posted in electronic commerce sites and blogs.', 'the purpose of those kinds of spam is promote products and services, or simply damage their reputation.', 'a deceptive opinion spam can be defined as a fictitious opinion written with the intention to sound authentic in order to mislead the reader.', 'an opinion spam usually is a short text written by an unknown author using a not very well defined style.', 'these characteristics make the problem of automatic detection of opinion spam a very challenging problem.', 'first attempts for solving this problem considered unsupervised approaches trying to identify duplicate content  #AUTHOR_TAG, and searching for unusual review patterns  #AUTHOR_TAG or groups of opinion spammers  #AUTHOR_TAG.', 'later, supervised methods were presented.', 'such is the case of  #AUTHOR_TAG a ;  #AUTHOR_TAG b ) in which the authors extended the n - gram feature by incorporating syntactic production rules derived from probabilistic context free grammar parse trees.', 'in  #AUTHOR_TAG a learning from positive and unlabeled examples ( pu - learning ) approach was successfully applied to detect deceptive opinion spam, using only few examples of deceptive opinions and a set of unlabeled data.', 'then, in ( hernandez  #AUTHOR_TAG a ) the authors proposed a pu - learning variant for the same task, concluding the appropriateness of their approach for detecting opinion spam.', 'in this paper we study the feasibility of the application of different features for representing safely information about clues related to fake reviews.', 'we focus our study in a variant of the stylistic feature character n - grams named character n - grams in tokens.', 'we also study an emotion - based feature and a linguistic processes feature based on liwc variables.', 'we evaluated the proposed features with a support vector machines ( svm ) classifier using a corpus of 1600 reviews of hotels  #TAUTHOR_TAG.', 'we show an experimental study evaluating the single features and combining them with the intention to obtain better features.', 'after that previous study, we selected the one with we obtained the best results and made direct and indirect comparisons with some other methods.', 'the obtained results show that the proposed features can capture information from the contents of the reviews and the writing style allowing to obtain classification results as good as with traditional character n - grams but with a lower dimensionality of representation.', 'the rest of the paper is organized as follows.', 'section 2 describes briefly the proposed features.', 'section 3 shows the experimental study performed.', 'the description of the corpus and the different experiments carried out can also be found in this section.', '']",5
"['presented in  #TAUTHOR_TAG.', 'we first describe the corpus and then we show the different experiments']","['presented in  #TAUTHOR_TAG.', 'we first describe the corpus and then we show the different experiments made.', 'finally we compare our results with those published previously']","['presented in  #TAUTHOR_TAG.', 'we first describe the corpus and then we show the different experiments made.', 'finally we compare our results with those published previously']","['order to evaluate our proposal, we have performed some experimental study on the first publicly available opinion spam dataset gathered and presented in  #TAUTHOR_TAG.', 'we first describe the corpus and then we show the different experiments made.', 'finally we compare our results with those published previously']",5
"[', personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used']","[', personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc']","[', verb, pronoun, personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc2007, unigrams and bigrams', 'as set of features with a svm classifier. in  #AUTHOR_TAG, profile alignment compatibility features combined with unigrams, bigrams and syntactic production rules were proposed for representing the opinion spam corpus. then, a multivariate performance measures version of svm classifier ( named svm perf ) was', 'trained. in ( hernandez  #AUTHOR_TAG b )']","[', verb, pronoun, personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc2007, unigrams and bigrams', 'as set of features with a svm classifier. in  #AUTHOR_TAG, profile alignment compatibility features combined with unigrams, bigrams and syntactic production rules were proposed for representing the opinion spam corpus. then, a multivariate performance measures version of svm classifier ( named svm perf ) was', 'trained. in ( hernandez  #AUTHOR_TAG b ) the authors studied two different representations : character n -', 'grams and word n - grams. in particular,', 'the best results were obtained with a naive bayes classifier using character 4 and 5 grams as features. as we stated before, two kinds of', 'comparisons are shown : an indirect ( we could not obtain the complete set of results reported by the authors ) and a direct ( the authors kindly', 'made available the results and a statistical comparison can be performed ). in table 4 we can', 'observe the indirect comparison of our results with those of  #AUTHOR_TAG and  #AUTHOR_TAG obtained with a 10 fold cross validation experiment, and then', '']",5
"[', personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used']","[', personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc']","[', verb, pronoun, personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc2007, unigrams and bigrams', 'as set of features with a svm classifier. in  #AUTHOR_TAG, profile alignment compatibility features combined with unigrams, bigrams and syntactic production rules were proposed for representing the opinion spam corpus. then, a multivariate performance measures version of svm classifier ( named svm perf ) was', 'trained. in ( hernandez  #AUTHOR_TAG b )']","[', verb, pronoun, personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc2007, unigrams and bigrams', 'as set of features with a svm classifier. in  #AUTHOR_TAG, profile alignment compatibility features combined with unigrams, bigrams and syntactic production rules were proposed for representing the opinion spam corpus. then, a multivariate performance measures version of svm classifier ( named svm perf ) was', 'trained. in ( hernandez  #AUTHOR_TAG b ) the authors studied two different representations : character n -', 'grams and word n - grams. in particular,', 'the best results were obtained with a naive bayes classifier using character 4 and 5 grams as features. as we stated before, two kinds of', 'comparisons are shown : an indirect ( we could not obtain the complete set of results reported by the authors ) and a direct ( the authors kindly', 'made available the results and a statistical comparison can be performed ). in table 4 we can', 'observe the indirect comparison of our results with those of  #AUTHOR_TAG and  #AUTHOR_TAG obtained with a 10 fold cross validation experiment, and then', '']",5
['by  #TAUTHOR_TAG with 800 reviews each one ( 400'],['by  #TAUTHOR_TAG with 800 reviews each one ( 400'],['by  #TAUTHOR_TAG with 800 reviews each one ( 400'],"['this work we have proposed some interesting features for deceptive opinions detection.', 'we have studied how different features contribute to model deception clues.', 'character n - grams in tokens seems to capture correctly the content and the writing style of the reviews helping this, in some way, to differentiate truthful from deceptive opinions.', 'many works have demonstrated that emotions - based features can discriminate deceptive text, but in our experimental study this feature seems not to provide too much useful information for detecting deception in reviews.', 'we also have used some variables extracted from liwc as pronouns, articles and verbs.', 'that information combined with character 4 - grams in tokens was selected for modeling the representation of the reviews.', 'for the experimental study we have used the positive and negative polarities reviews corresponding to the corpora proposed by  #TAUTHOR_TAG with 800 reviews each one ( 400 true and 400 false opinions ).', 'we have used both corpora in a separate way but we have performed experiments joining both polarities reviews in a combined corpus of 1600 reviews.', 'from the results obtained with the different features we have concluded that character 4 - grams in tokens with liwc variables performs the best using a svm classifier.', 'we made also a comparison with the approach of ( hernandez  #AUTHOR_TAG b ) and the results were similar ( no statistically significant difference was found ), but our low dimensionality representation makes our approach more efficient.', 'for future work we plans to investigate another emotion / sentiment features in order to study the contributions in tasks of deception detection of opinion spam.', 'also we are interesting to test our model with other corpora related to opinion spam as the one recently proposed in']",5
['opinion spam corpus presented in  #TAUTHOR_TAG is'],['opinion spam corpus presented in  #TAUTHOR_TAG is'],"['opinion spam corpus presented in  #TAUTHOR_TAG is composed of 1600 positive and negative opinions for hotels with the corresponding gold - standard.', 'from the 800 positive reviews  #TAUTHOR_TAG, the 400 truthful where']","['opinion spam corpus presented in  #TAUTHOR_TAG is composed of 1600 positive and negative opinions for hotels with the corresponding gold - standard.', 'from the 800 positive reviews  #TAUTHOR_TAG, the 400 truthful where mined from tripadvisor 5 - star reviews about the 20 most popular hotels in chicago area.', 'all reviews were written in english, have at least 150 characters and correspond to users who had posted opinions previously on tripadvisor ( non first - time authors ).', 'the 400 deceptive opinions correspond to the same 20 hotels and were gathered using amazon mechanical turk crowdsourcing service.', 'from the 800 negative reviews  #AUTHOR_TAG, the 400 truthful where mined from tripadvisor, expedia, hotels. com, orbitz, priceline and yelp.', 'the reviews are 1 or 2 - star category and are about the same 20 hotels in chicago.', 'the 400 deceptive reviews correspond to the same 20 hotels and were obtained using amazon mechanical turk']",0
['opinion spam corpus presented in  #TAUTHOR_TAG is'],['opinion spam corpus presented in  #TAUTHOR_TAG is'],"['opinion spam corpus presented in  #TAUTHOR_TAG is composed of 1600 positive and negative opinions for hotels with the corresponding gold - standard.', 'from the 800 positive reviews  #TAUTHOR_TAG, the 400 truthful where']","['opinion spam corpus presented in  #TAUTHOR_TAG is composed of 1600 positive and negative opinions for hotels with the corresponding gold - standard.', 'from the 800 positive reviews  #TAUTHOR_TAG, the 400 truthful where mined from tripadvisor 5 - star reviews about the 20 most popular hotels in chicago area.', 'all reviews were written in english, have at least 150 characters and correspond to users who had posted opinions previously on tripadvisor ( non first - time authors ).', 'the 400 deceptive opinions correspond to the same 20 hotels and were gathered using amazon mechanical turk crowdsourcing service.', 'from the 800 negative reviews  #AUTHOR_TAG, the 400 truthful where mined from tripadvisor, expedia, hotels. com, orbitz, priceline and yelp.', 'the reviews are 1 or 2 - star category and are about the same 20 hotels in chicago.', 'the 400 deceptive reviews correspond to the same 20 hotels and were obtained using amazon mechanical turk']",0
"[', personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used']","[', personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc']","[', verb, pronoun, personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc2007, unigrams and bigrams', 'as set of features with a svm classifier. in  #AUTHOR_TAG, profile alignment compatibility features combined with unigrams, bigrams and syntactic production rules were proposed for representing the opinion spam corpus. then, a multivariate performance measures version of svm classifier ( named svm perf ) was', 'trained. in ( hernandez  #AUTHOR_TAG b )']","[', verb, pronoun, personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc2007, unigrams and bigrams', 'as set of features with a svm classifier. in  #AUTHOR_TAG, profile alignment compatibility features combined with unigrams, bigrams and syntactic production rules were proposed for representing the opinion spam corpus. then, a multivariate performance measures version of svm classifier ( named svm perf ) was', 'trained. in ( hernandez  #AUTHOR_TAG b ) the authors studied two different representations : character n -', 'grams and word n - grams. in particular,', 'the best results were obtained with a naive bayes classifier using character 4 and 5 grams as features. as we stated before, two kinds of', 'comparisons are shown : an indirect ( we could not obtain the complete set of results reported by the authors ) and a direct ( the authors kindly', 'made available the results and a statistical comparison can be performed ). in table 4 we can', 'observe the indirect comparison of our results with those of  #AUTHOR_TAG and  #AUTHOR_TAG obtained with a 10 fold cross validation experiment, and then', '']",0
"[', personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used']","[', personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc']","[', verb, pronoun, personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc2007, unigrams and bigrams', 'as set of features with a svm classifier. in  #AUTHOR_TAG, profile alignment compatibility features combined with unigrams, bigrams and syntactic production rules were proposed for representing the opinion spam corpus. then, a multivariate performance measures version of svm classifier ( named svm perf ) was', 'trained. in ( hernandez  #AUTHOR_TAG b )']","[', verb, pronoun, personal pronoun, positive cues, perceptual words and future tense. in  #AUTHOR_TAG a semi - supervised model called', 'mixing population and individual property pu learning, is presented. the model', 'is then incorporated to a svm classifier. in  #TAUTHOR_TAG used the 80 dimensions of liwc2007, unigrams and bigrams', 'as set of features with a svm classifier. in  #AUTHOR_TAG, profile alignment compatibility features combined with unigrams, bigrams and syntactic production rules were proposed for representing the opinion spam corpus. then, a multivariate performance measures version of svm classifier ( named svm perf ) was', 'trained. in ( hernandez  #AUTHOR_TAG b ) the authors studied two different representations : character n -', 'grams and word n - grams. in particular,', 'the best results were obtained with a naive bayes classifier using character 4 and 5 grams as features. as we stated before, two kinds of', 'comparisons are shown : an indirect ( we could not obtain the complete set of results reported by the authors ) and a direct ( the authors kindly', 'made available the results and a statistical comparison can be performed ). in table 4 we can', 'observe the indirect comparison of our results with those of  #AUTHOR_TAG and  #AUTHOR_TAG obtained with a 10 fold cross validation experiment, and then', '']",3
['- validation  #TAUTHOR_TAG 89. 8'],"['89 %', '5 fold cross - validation  #TAUTHOR_TAG 89. 8 %  #AUTHOR_TAG 91. 3 % our approach 89. 8 %']","['', '5 fold cross - validation  #TAUTHOR_TAG 89. 8 %  #AUTHOR_TAG 91. 3 % our approach 89. 8 %']","['fold cross - validation  #AUTHOR_TAG 70. 50 %  #AUTHOR_TAG 86. 69 % our approach 89 %', '5 fold cross - validation  #TAUTHOR_TAG 89. 8 %  #AUTHOR_TAG 91. 3 % our approach 89. 8 % table 4 : indirect comparison of the performance.', 'deceptive opinions detection for positive reviews of opinion spam corpus ( 800 opinions ).', 'in table 5 we can observe the direct comparison of the performance for the positive and negative polarities reviews of the opinion spam corpus considering the proposal of ( hernandez  #AUTHOR_TAG b ).', 'first column shows the representation proposed, the second one shows the amount of attributes ( attr. ) of the representation, the third column shows the f - measure value ( f ) obtained after a 10 fold cross - validation process, and the last column shows the p - value obtained in the statistical significance test used to study the differences of performance between ( hernandez  #AUTHOR_TAG b ) it is interesting to note that the f - measure values obtained with both approaches are quite similar for positive and negative reviews, as we can observe in table 5.', '']",3
"['dream dataset ( see  #TAUTHOR_TAG fine tunes albert, a large pretrained transformer - based model, and additionally combines']","['dream dataset ( see  #TAUTHOR_TAG fine tunes albert, a large pretrained transformer - based model, and additionally combines']","['of mrc, the current state - of - the - art model on the dream dataset ( see  #TAUTHOR_TAG fine tunes albert, a large pretrained transformer - based model, and additionally combines']","['- choice machine reading comprehension ( mrc ) is an important and challenging natural language understanding ( nlu ) task, in which a machine must choose the answer to a question from a set of choices, with the question placed in context of text passages or dialog.', 'in the last a couple of years the nlu field has been revolutionized with the advent of models based on the transformer architecture, which are pretrained on massive amounts of unsupervised data and then fine - tuned for various supervised learning nlu tasks.', 'transformer models have come to dominate a wide variety of leader - boards in the nlu field ; in the area of mrc, the current state - of - the - art model on the dream dataset ( see  #TAUTHOR_TAG fine tunes albert, a large pretrained transformer - based model, and additionally combines it with an extra layer of multi - head attention between context and question - answer [  #AUTHOR_TAG ].', 'the purpose of this note is to document a new state - of - the - art result in the dream task, which is accomplished by, additionally, performing multi - task learning on two mrc multi - choice reading comprehension tasks ( race and dream )']",0
"['5.', 'dream  #TAUTHOR_TAG is a much smaller reading comprehension dataset with more than 6']","['question provides 4 answer options to choose from.', 'the human ceiling performance is 94. 5.', 'dream  #TAUTHOR_TAG is a much smaller reading comprehension dataset with more than 6, 000 dialogues and over 10, 000 questions.', 'the average dialogue length is 86 words.', '']","['5.', 'dream  #TAUTHOR_TAG is a much smaller reading comprehension dataset with more than 6']","['[  #AUTHOR_TAG ] is a large - scale reading comprehension dataset with more than 28, 000 passages and nearly 100, 000 questions.', 'the average passage length is 322 words.', 'each question provides 4 answer options to choose from.', 'the human ceiling performance is 94. 5.', 'dream  #TAUTHOR_TAG is a much smaller reading comprehension dataset with more than 6, 000 dialogues and over 10, 000 questions.', 'the average dialogue length is 86 words.', 'each question provides 3 answer options to choose from.', 'the human ceiling performance is 98. 6']",0
"['gbdt  #TAUTHOR_TAG,']","['works on the dream task include feature - based gbdt  #TAUTHOR_TAG,']","['works on the dream task include feature - based gbdt  #TAUTHOR_TAG,']","['works on the dream task include feature - based gbdt  #TAUTHOR_TAG, and ftlm [  #AUTHOR_TAG ] which is based on the transformer [  #AUTHOR_TAG ] architecture.', 'the top system accuracy on the dream leaderboard has been advanced gradually to above 90 percent, since the break - through of the text encoder in the form of large pretrained transformerbased models ( bert [  #AUTHOR_TAG ], xlnet [  #AUTHOR_TAG a ], roberta [  #AUTHOR_TAG ], albert [  #AUTHOR_TAG ] ).', 'transfer learning is a widely used practice in machine learning ( ml ) that focuses on utilizing knowledge gained while solving one problem and applying it to a different but related problem.', 'using pretrained language models ( lms ) such as elmo [  #AUTHOR_TAG ] and bert [  #AUTHOR_TAG ] in down - stream tasks is an example of sequential transfer learning.', 'on the other hand, multi - task learning, which involves learning several similar tasks simultaneously, is able to share the knowledge learned among the tasks.', 'on the dream leaderboard 1, the recent top systems include roberta large + mmm in [  #AUTHOR_TAG ] and albert xxlarge + duma in [  #AUTHOR_TAG ].', 'both systems employ model architectures composed of a transformer - based encoder and some matching / attention mechanism between the context and the question - answer pair.', 'roberta large + mmm in [  #AUTHOR_TAG ] additionally employed two stages of transfer learning : coarse - tuning with natural language inference ( nli ) tasks and multi - task learning with multi - choice reading comprehension tasks.', 'we used albert xxlarge + duma as our model architecture and did multi - task learning on top of that, as through experiments we felt it efficiently boosts the performance on top of the powerful albert xxlarge model']",0
"['to choose the best answer from multiple choices.', 'in this note we will focus on the multi - choice mrc tasks, more specifically, the dream task  #TAUTHOR_TAG ]']","['to choose the best answer from multiple choices.', 'in this note we will focus on the multi - choice mrc tasks, more specifically, the dream task  #TAUTHOR_TAG ]']","['to choose the best answer from multiple choices.', 'in this note we will focus on the multi - choice mrc tasks, more specifically, the dream task  #TAUTHOR_TAG ]']","['a computer system understand text within context and answer questions is challenging but has attracted a lot of interest of the artificial intelligence community and general audience for a long time.', 'in the recent years, many machine reading comprehension ( mrc ) datasets have been published, with different genres and formats of the context and questions.', 'the context could be in the form of text passages, or in the form of dialogues.', 'the questions could be open - formed ( e. g. hotpotqa [  #AUTHOR_TAG ] ), asking the system to either extract the answers as spans from the context or external knowledge, or abstract and summarize the answers ; the questions could also be in the form of asking the system to choose the best answer from multiple choices.', 'in this note we will focus on the multi - choice mrc tasks, more specifically, the dream task  #TAUTHOR_TAG ]']",5
"['##s the use of many different features.', ' #TAUTHOR_TAG proposed a bayesian network model that combines linguistically motivated features']","['automatic detection warrants the use of many different features.', ' #TAUTHOR_TAG proposed a bayesian network model that combines linguistically motivated features']","['automatic detection warrants the use of many different features.', ' #TAUTHOR_TAG proposed a bayesian network model that combines linguistically motivated features']","['multiword expressions ( mwes ) exhibit a range of idiosyncrasies, their automatic detection warrants the use of many different features.', ' #TAUTHOR_TAG proposed a bayesian network model that combines linguistically motivated features and also models their interactions.', 'in this paper, we extend their model with new features and apply it to croatian, a morphologically complex and a relatively free word order language, achieving a satisfactory performance of 0. 823 f1 - score.', 'furthermore, by comparing against ( semi ) naive bayes models, we demonstrate that manually modeling feature interactions is indeed important.', 'we make our annotated dataset of croatian mwes freely available']",0
"['', 'recently,  #TAUTHOR_TAG proposed an approach']","['recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['##word expressions ( mwes ) have attracted a great deal of attention in the natural language processing community.', 'while mwes span a wide range of types, common to all is the idiosyncrasy at the lexical, syntactic, semantic, pragmatic, or statistical level  #AUTHOR_TAG.', 'a variety of models has been proposed for the automatic identification of mwe in corpora, including statistical  #AUTHOR_TAG and linguistic - based approaches  #AUTHOR_TAG ; see  #AUTHOR_TAG for a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach for the detection of mwe candidates that combines a number of statistical and linguistic features.', 'the most interesting aspect of their work is that they explicitly model the linguistically motivated interactions between the features using a bayesian network ( bn ).', 'the advantages of bns lie in their interpretability and the possibility to encode linguistic knowledge in the form of the network structure.', 'furthermore, unlike most previous work, tsvetkov and wintner address mwe of various types and flexible syntactic constructions.', 'they show that the manually - designed bn outperforms a number of strong baselines, including an svm model, on english, french, and hebrew datasets.', 'another advantage of their model is that it is in principle language - independent, aside from a few language - specific features.', 'in this paper, we address the task of mwe detection ( type - level mwe classification ) for croatian, a south slavic language with a rich morphology and a relatively free word order.', 'the starting point of our work is the model of  #TAUTHOR_TAG, which we extend with a number of features, including language - specific ones that account for the relatively free word order.', 'our main research question is whether modeling the interactions between features is important, and whether these can be learned automatically.', ' #TAUTHOR_TAG showed that a manually - designed bn substantially outperforms the one whose structure is learned automatically, hypothesizing that the cause for this might be the increased model complexity.', 'we conduct a similar experiment using a structurelearning algorithm, but also model the interactions using a simpler, semi - naive bayes classifier, for which the number of parameters is restricted.', 'finally, we compare these models against a structurefree counterpart, a naive bayes classifier.', 'for the experiments, we compile a new manually annotated dataset of croatian mwes.', 'unlike  #TAUTHOR_TAG, who only consider bigrams, we consider mwes of up to five words in length.', 'we make the dataset freely available, along with all feature sets needed to replicate the experiments']",0
"['', 'recently,  #TAUTHOR_TAG proposed an approach']","['recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['##word expressions ( mwes ) have attracted a great deal of attention in the natural language processing community.', 'while mwes span a wide range of types, common to all is the idiosyncrasy at the lexical, syntactic, semantic, pragmatic, or statistical level  #AUTHOR_TAG.', 'a variety of models has been proposed for the automatic identification of mwe in corpora, including statistical  #AUTHOR_TAG and linguistic - based approaches  #AUTHOR_TAG ; see  #AUTHOR_TAG for a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach for the detection of mwe candidates that combines a number of statistical and linguistic features.', 'the most interesting aspect of their work is that they explicitly model the linguistically motivated interactions between the features using a bayesian network ( bn ).', 'the advantages of bns lie in their interpretability and the possibility to encode linguistic knowledge in the form of the network structure.', 'furthermore, unlike most previous work, tsvetkov and wintner address mwe of various types and flexible syntactic constructions.', 'they show that the manually - designed bn outperforms a number of strong baselines, including an svm model, on english, french, and hebrew datasets.', 'another advantage of their model is that it is in principle language - independent, aside from a few language - specific features.', 'in this paper, we address the task of mwe detection ( type - level mwe classification ) for croatian, a south slavic language with a rich morphology and a relatively free word order.', 'the starting point of our work is the model of  #TAUTHOR_TAG, which we extend with a number of features, including language - specific ones that account for the relatively free word order.', 'our main research question is whether modeling the interactions between features is important, and whether these can be learned automatically.', ' #TAUTHOR_TAG showed that a manually - designed bn substantially outperforms the one whose structure is learned automatically, hypothesizing that the cause for this might be the increased model complexity.', 'we conduct a similar experiment using a structurelearning algorithm, but also model the interactions using a simpler, semi - naive bayes classifier, for which the number of parameters is restricted.', 'finally, we compare these models against a structurefree counterpart, a naive bayes classifier.', 'for the experiments, we compile a new manually annotated dataset of croatian mwes.', 'unlike  #TAUTHOR_TAG, who only consider bigrams, we consider mwes of up to five words in length.', 'we make the dataset freely available, along with all feature sets needed to replicate the experiments']",0
"['features.', 'the model of  #TAUTHOR_TAG uses nine statistically and linguistically motivated features, computed for']","['features.', 'the model of  #TAUTHOR_TAG uses nine statistically and linguistically motivated features, computed for']","['features.', 'the model of  #TAUTHOR_TAG uses nine statistically and linguistically motivated features, computed for each mwe candidate and designed to discriminate between mwes and ordinary word sequences.', 'we adopted eight of these features : 1 ( 1']","['features.', 'the model of  #TAUTHOR_TAG uses nine statistically and linguistically motivated features, computed for each mwe candidate and designed to discriminate between mwes and ordinary word sequences.', ""we adopted eight of these features : 1 ( 1 ) capitalization ( indicating which mwe constituents are capitalized ), ( 2 ) hyphenation ( which constituents are hyphenated ), ( 3 ) fossil word ( whether constituents also occur outside of the mwe ), ( 4 ) frozen form ( whether the mwe is morphologically frozen ), ( 5 ) partial morphological inflection ( whether mwe admits only limited inflection ), ( 6 ) syntactic pattern ( the mwe's part - of - speech pattern ), ( 7 ) semantic context, and ( 8 ) association measure."", 'the values of statistical features were computed from hrwac, a 1. 2b - token croatian web corpus compiled by ljubesic and  #AUTHOR_TAG.', 'all numeric features were discretized into five reference levels based on their average values in the corpus.', 'interesting mwe examples from the corpus that showcase the above - mentioned statistical properties are curriculum vitae, which is made of fossil words, hodati po jajima ( to walk on eggshells ), which is a frozen form, and zlatno doba ( golden age ), which almost exclusively appears in the nominative and locative singular ( partial inflection ).', 'modified features.', 'in the original model, the semantic context feature computes the lexical variety of the words following a mwe candidate vary, the idea being that mwes have a more restricted context.', 'in our sample - based analysis of croatian mwes, we concluded that in many cases this restriction is not limited to the right context.', 'thus, we introduced two additional features : one for the left context and another considering a 5 - word window around the mwe.', 'likewise, we used the dice coefficient association measure, rather than pmi as used in the original model, as the former turned out to be more discriminative.', 'new features.', 'we introduced six new features, four of which were inspired by our analysis of croatian mwes.', 'the simile feature is motivated by the observation that many croatian similes are mwes, e. g., plakati kao ljuta godina, ( to cry like a bitter year - to cry heavily ).', 'we consider a mwe to be a simile if it contains a preposition kao ( like ) or poput ( as ).', '']",0
"['##s the use of many different features.', ' #TAUTHOR_TAG proposed a bayesian network model that combines linguistically motivated features']","['automatic detection warrants the use of many different features.', ' #TAUTHOR_TAG proposed a bayesian network model that combines linguistically motivated features']","['automatic detection warrants the use of many different features.', ' #TAUTHOR_TAG proposed a bayesian network model that combines linguistically motivated features']","['multiword expressions ( mwes ) exhibit a range of idiosyncrasies, their automatic detection warrants the use of many different features.', ' #TAUTHOR_TAG proposed a bayesian network model that combines linguistically motivated features and also models their interactions.', 'in this paper, we extend their model with new features and apply it to croatian, a morphologically complex and a relatively free word order language, achieving a satisfactory performance of 0. 823 f1 - score.', 'furthermore, by comparing against ( semi ) naive bayes models, we demonstrate that manually modeling feature interactions is indeed important.', 'we make our annotated dataset of croatian mwes freely available']",6
"['', 'recently,  #TAUTHOR_TAG proposed an approach']","['recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['##word expressions ( mwes ) have attracted a great deal of attention in the natural language processing community.', 'while mwes span a wide range of types, common to all is the idiosyncrasy at the lexical, syntactic, semantic, pragmatic, or statistical level  #AUTHOR_TAG.', 'a variety of models has been proposed for the automatic identification of mwe in corpora, including statistical  #AUTHOR_TAG and linguistic - based approaches  #AUTHOR_TAG ; see  #AUTHOR_TAG for a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach for the detection of mwe candidates that combines a number of statistical and linguistic features.', 'the most interesting aspect of their work is that they explicitly model the linguistically motivated interactions between the features using a bayesian network ( bn ).', 'the advantages of bns lie in their interpretability and the possibility to encode linguistic knowledge in the form of the network structure.', 'furthermore, unlike most previous work, tsvetkov and wintner address mwe of various types and flexible syntactic constructions.', 'they show that the manually - designed bn outperforms a number of strong baselines, including an svm model, on english, french, and hebrew datasets.', 'another advantage of their model is that it is in principle language - independent, aside from a few language - specific features.', 'in this paper, we address the task of mwe detection ( type - level mwe classification ) for croatian, a south slavic language with a rich morphology and a relatively free word order.', 'the starting point of our work is the model of  #TAUTHOR_TAG, which we extend with a number of features, including language - specific ones that account for the relatively free word order.', 'our main research question is whether modeling the interactions between features is important, and whether these can be learned automatically.', ' #TAUTHOR_TAG showed that a manually - designed bn substantially outperforms the one whose structure is learned automatically, hypothesizing that the cause for this might be the increased model complexity.', 'we conduct a similar experiment using a structurelearning algorithm, but also model the interactions using a simpler, semi - naive bayes classifier, for which the number of parameters is restricted.', 'finally, we compare these models against a structurefree counterpart, a naive bayes classifier.', 'for the experiments, we compile a new manually annotated dataset of croatian mwes.', 'unlike  #TAUTHOR_TAG, who only consider bigrams, we consider mwes of up to five words in length.', 'we make the dataset freely available, along with all feature sets needed to replicate the experiments']",6
"['adopt the bn model of  #TAUTHOR_TAG, but extend']","['adopt the bn model of  #TAUTHOR_TAG, but extend']","['adopt the bn model of  #TAUTHOR_TAG, but extend']","['adopt the bn model of  #TAUTHOR_TAG, but extend it with language - specific as well as semantically motivated features.', 'most newly added features were inspired by the analysis of croatian mwes of  #AUTHOR_TAG, and a sample - based analysis of a mwe from a dictionary of croatian mwes ( kovacevic, 2012 ) and their occurrences in the hrwac corpus ( ljubesic and  #AUTHOR_TAG.', 'the mwe candidates were postagged using the tagger from  #AUTHOR_TAG']",6
['of  #TAUTHOR_TAG'],['of  #TAUTHOR_TAG'],"['##n.', 'we adopted the bayesian network model of  #TAUTHOR_TAG']","['described the experiments on using a combination of linguistically motivated features for mwe detection in croatian.', 'we adopted the bayesian network model of  #TAUTHOR_TAG and extended it with new features and manually - designed feature interactions, inspired by an analysis of croatian mwes.', 'to train and evaluate the model, we built a manually annotated dataset of croatian mwes.', 'on this dataset, our model substantially outperforms statistical baselines, reaching a satisfactory performance of 0. 823 f1 - score on our dataset.', 'the model also outperforms the ( semi ) naive bayes models, which limit the feature interactions, as well as a bayesian network model with automatically learned feature interactions.', 'thus, the main finding of our work is that the model benefits from the linguistically motivated, manually - designed feature interactions, which proves that mwe features interact in rather intricate ways']",6
"['', 'recently,  #TAUTHOR_TAG proposed an approach']","['recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['##word expressions ( mwes ) have attracted a great deal of attention in the natural language processing community.', 'while mwes span a wide range of types, common to all is the idiosyncrasy at the lexical, syntactic, semantic, pragmatic, or statistical level  #AUTHOR_TAG.', 'a variety of models has been proposed for the automatic identification of mwe in corpora, including statistical  #AUTHOR_TAG and linguistic - based approaches  #AUTHOR_TAG ; see  #AUTHOR_TAG for a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach for the detection of mwe candidates that combines a number of statistical and linguistic features.', 'the most interesting aspect of their work is that they explicitly model the linguistically motivated interactions between the features using a bayesian network ( bn ).', 'the advantages of bns lie in their interpretability and the possibility to encode linguistic knowledge in the form of the network structure.', 'furthermore, unlike most previous work, tsvetkov and wintner address mwe of various types and flexible syntactic constructions.', 'they show that the manually - designed bn outperforms a number of strong baselines, including an svm model, on english, french, and hebrew datasets.', 'another advantage of their model is that it is in principle language - independent, aside from a few language - specific features.', 'in this paper, we address the task of mwe detection ( type - level mwe classification ) for croatian, a south slavic language with a rich morphology and a relatively free word order.', 'the starting point of our work is the model of  #TAUTHOR_TAG, which we extend with a number of features, including language - specific ones that account for the relatively free word order.', 'our main research question is whether modeling the interactions between features is important, and whether these can be learned automatically.', ' #TAUTHOR_TAG showed that a manually - designed bn substantially outperforms the one whose structure is learned automatically, hypothesizing that the cause for this might be the increased model complexity.', 'we conduct a similar experiment using a structurelearning algorithm, but also model the interactions using a simpler, semi - naive bayes classifier, for which the number of parameters is restricted.', 'finally, we compare these models against a structurefree counterpart, a naive bayes classifier.', 'for the experiments, we compile a new manually annotated dataset of croatian mwes.', 'unlike  #TAUTHOR_TAG, who only consider bigrams, we consider mwes of up to five words in length.', 'we make the dataset freely available, along with all feature sets needed to replicate the experiments']",3
"['', 'recently,  #TAUTHOR_TAG proposed an approach']","['recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach']","['##word expressions ( mwes ) have attracted a great deal of attention in the natural language processing community.', 'while mwes span a wide range of types, common to all is the idiosyncrasy at the lexical, syntactic, semantic, pragmatic, or statistical level  #AUTHOR_TAG.', 'a variety of models has been proposed for the automatic identification of mwe in corpora, including statistical  #AUTHOR_TAG and linguistic - based approaches  #AUTHOR_TAG ; see  #AUTHOR_TAG for a recent overview.', ' #AUTHOR_TAG argued for a combination of the two approaches.', 'recently,  #TAUTHOR_TAG proposed an approach for the detection of mwe candidates that combines a number of statistical and linguistic features.', 'the most interesting aspect of their work is that they explicitly model the linguistically motivated interactions between the features using a bayesian network ( bn ).', 'the advantages of bns lie in their interpretability and the possibility to encode linguistic knowledge in the form of the network structure.', 'furthermore, unlike most previous work, tsvetkov and wintner address mwe of various types and flexible syntactic constructions.', 'they show that the manually - designed bn outperforms a number of strong baselines, including an svm model, on english, french, and hebrew datasets.', 'another advantage of their model is that it is in principle language - independent, aside from a few language - specific features.', 'in this paper, we address the task of mwe detection ( type - level mwe classification ) for croatian, a south slavic language with a rich morphology and a relatively free word order.', 'the starting point of our work is the model of  #TAUTHOR_TAG, which we extend with a number of features, including language - specific ones that account for the relatively free word order.', 'our main research question is whether modeling the interactions between features is important, and whether these can be learned automatically.', ' #TAUTHOR_TAG showed that a manually - designed bn substantially outperforms the one whose structure is learned automatically, hypothesizing that the cause for this might be the increased model complexity.', 'we conduct a similar experiment using a structurelearning algorithm, but also model the interactions using a simpler, semi - naive bayes classifier, for which the number of parameters is restricted.', 'finally, we compare these models against a structurefree counterpart, a naive bayes classifier.', 'for the experiments, we compile a new manually annotated dataset of croatian mwes.', 'unlike  #TAUTHOR_TAG, who only consider bigrams, we consider mwes of up to five words in length.', 'we make the dataset freely available, along with all feature sets needed to replicate the experiments']",4
"['features.', 'the model of  #TAUTHOR_TAG uses nine statistically and linguistically motivated features, computed for']","['features.', 'the model of  #TAUTHOR_TAG uses nine statistically and linguistically motivated features, computed for']","['features.', 'the model of  #TAUTHOR_TAG uses nine statistically and linguistically motivated features, computed for each mwe candidate and designed to discriminate between mwes and ordinary word sequences.', 'we adopted eight of these features : 1 ( 1']","['features.', 'the model of  #TAUTHOR_TAG uses nine statistically and linguistically motivated features, computed for each mwe candidate and designed to discriminate between mwes and ordinary word sequences.', ""we adopted eight of these features : 1 ( 1 ) capitalization ( indicating which mwe constituents are capitalized ), ( 2 ) hyphenation ( which constituents are hyphenated ), ( 3 ) fossil word ( whether constituents also occur outside of the mwe ), ( 4 ) frozen form ( whether the mwe is morphologically frozen ), ( 5 ) partial morphological inflection ( whether mwe admits only limited inflection ), ( 6 ) syntactic pattern ( the mwe's part - of - speech pattern ), ( 7 ) semantic context, and ( 8 ) association measure."", 'the values of statistical features were computed from hrwac, a 1. 2b - token croatian web corpus compiled by ljubesic and  #AUTHOR_TAG.', 'all numeric features were discretized into five reference levels based on their average values in the corpus.', 'interesting mwe examples from the corpus that showcase the above - mentioned statistical properties are curriculum vitae, which is made of fossil words, hodati po jajima ( to walk on eggshells ), which is a frozen form, and zlatno doba ( golden age ), which almost exclusively appears in the nominative and locative singular ( partial inflection ).', 'modified features.', 'in the original model, the semantic context feature computes the lexical variety of the words following a mwe candidate vary, the idea being that mwes have a more restricted context.', 'in our sample - based analysis of croatian mwes, we concluded that in many cases this restriction is not limited to the right context.', 'thus, we introduced two additional features : one for the left context and another considering a 5 - word window around the mwe.', 'likewise, we used the dice coefficient association measure, rather than pmi as used in the original model, as the former turned out to be more discriminative.', 'new features.', 'we introduced six new features, four of which were inspired by our analysis of croatian mwes.', 'the simile feature is motivated by the observation that many croatian similes are mwes, e. g., plakati kao ljuta godina, ( to cry like a bitter year - to cry heavily ).', 'we consider a mwe to be a simile if it contains a preposition kao ( like ) or poput ( as ).', '']",5
"['helpful "" votes  #TAUTHOR_TAG ; 2 ) peer']","['of "" helpful "" votes  #TAUTHOR_TAG ; 2 ) peer']","['helpful "" votes  #TAUTHOR_TAG ; 2 ) peer reviews']","['', 'nonetheless, several properties distinguish our corpus of peer reviews from other types of reviews : 1 ) the helpfulness of our peer reviews is directly rated using a discrete scale from one to five instead of being defined as a function of binary votes ( e. g. the percentage of "" helpful "" votes  #TAUTHOR_TAG ; 2 ) peer reviews frequently refer to the related students\'papers, thus review analysis needs to take into account paper topics ; 3 ) within the context of education, peer - review helpfulness often has a writing specific semantics, e. g. improving revision likelihood ; 4 ) in general, peer - review corpora collected from classrooms are of a much smaller size compared to online product reviews.', 'to tailor existing techniques to peer reviews, we will thus propose new specialized features to address these issues']",4
['prior findings of product reviews  #TAUTHOR_TAG where product scores'],['prior findings of product reviews  #TAUTHOR_TAG where product scores'],['prior findings of product reviews  #TAUTHOR_TAG where product scores'],"['of the generic features is presented in table 2, showing that all classes except syntactic ( syn ) and meta - data ( met ) features are sig - nificantly correlated with both helpfulness rating ( r ) and helpfulness ranking ( r s ).', 'structural features ( bolded ) achieve the highest pearson ( 0. 60 ) and spearman correlation coefficients ( 0. 59 ) ( although within the significant correlations, the difference among coefficients are insignificant ).', 'note that in isolation, met ( paper ratings ) are not significantly correlated with peer - review helpfulness, which is different from prior findings of product reviews  #TAUTHOR_TAG where product scores are significantly correlated with product - review helpfulness.', 'however, when combined with other features, met does appear to add value ( last row ).', 'when comparing the performance between predicting helpfulness ratings versus ranking, we observe r ≈ r s consistently for our peer reviews, while  #TAUTHOR_TAG reported r < r s for product reviews.', ""4 finally, we observed a similar feature redundancy effect as  #TAUTHOR_TAG did, in that simply combining all features does not improve the model's performance."", 'interestingly, our best feature combination ( last row ) is the same as theirs.', 'in sum our results verify our hypothesis that the effectiveness of generic features can be transferred to our peerreview domain for predicting review helpfulness']",4
['prior findings of product reviews  #TAUTHOR_TAG where product scores'],['prior findings of product reviews  #TAUTHOR_TAG where product scores'],['prior findings of product reviews  #TAUTHOR_TAG where product scores'],"['of the generic features is presented in table 2, showing that all classes except syntactic ( syn ) and meta - data ( met ) features are sig - nificantly correlated with both helpfulness rating ( r ) and helpfulness ranking ( r s ).', 'structural features ( bolded ) achieve the highest pearson ( 0. 60 ) and spearman correlation coefficients ( 0. 59 ) ( although within the significant correlations, the difference among coefficients are insignificant ).', 'note that in isolation, met ( paper ratings ) are not significantly correlated with peer - review helpfulness, which is different from prior findings of product reviews  #TAUTHOR_TAG where product scores are significantly correlated with product - review helpfulness.', 'however, when combined with other features, met does appear to add value ( last row ).', 'when comparing the performance between predicting helpfulness ratings versus ranking, we observe r ≈ r s consistently for our peer reviews, while  #TAUTHOR_TAG reported r < r s for product reviews.', ""4 finally, we observed a similar feature redundancy effect as  #TAUTHOR_TAG did, in that simply combining all features does not improve the model's performance."", 'interestingly, our best feature combination ( last row ) is the same as theirs.', 'in sum our results verify our hypothesis that the effectiveness of generic features can be transferred to our peerreview domain for predicting review helpfulness']",4
"['than ten thousand product reviews  #TAUTHOR_TAG, this is an important']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable']","['the difference between peer reviews and other types of reviews as discussed in section 2, our work demonstrates that many generic linguistic features are also effective in predicting peer - review helpfulness.', ""the model's performance can be alter - natively achieved and further improved by adding auxiliary features tailored to peer reviews."", 'these specialized features not only introduce domain expertise, but also capture linguistic information at an abstracted level, which can help avoid the risk of over - fitting.', 'given only 267 peer reviews in our case compared to more than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable to the results of  #TAUTHOR_TAG, we indirectly compared them by analyzing the utility of features in isolation and combined.', 'while str + ugr + met is found as the best combination of generic features for both types of reviews, the best individual feature type is different ( review unigrams work best for product reviews ; structural features work best for peer reviews ).', 'more importantly, meta - data, which are found to significantly affect the perceived helpfulness of product reviews  #TAUTHOR_TAG, have no predictive power for peer reviews.', 'perhaps because the paper grades and other helpfulness ratings are not visible to the reviewers, we have less of a social dimension for predicting the helpfulness of peer reviews.', 'we also found that svm regression does not favor ranking over predicting helpfulness as in  #TAUTHOR_TAG']",4
"['than ten thousand product reviews  #TAUTHOR_TAG, this is an important']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable']","['the difference between peer reviews and other types of reviews as discussed in section 2, our work demonstrates that many generic linguistic features are also effective in predicting peer - review helpfulness.', ""the model's performance can be alter - natively achieved and further improved by adding auxiliary features tailored to peer reviews."", 'these specialized features not only introduce domain expertise, but also capture linguistic information at an abstracted level, which can help avoid the risk of over - fitting.', 'given only 267 peer reviews in our case compared to more than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable to the results of  #TAUTHOR_TAG, we indirectly compared them by analyzing the utility of features in isolation and combined.', 'while str + ugr + met is found as the best combination of generic features for both types of reviews, the best individual feature type is different ( review unigrams work best for product reviews ; structural features work best for peer reviews ).', 'more importantly, meta - data, which are found to significantly affect the perceived helpfulness of product reviews  #TAUTHOR_TAG, have no predictive power for peer reviews.', 'perhaps because the paper grades and other helpfulness ratings are not visible to the reviewers, we have less of a social dimension for predicting the helpfulness of peer reviews.', 'we also found that svm regression does not favor ranking over predicting helpfulness as in  #TAUTHOR_TAG']",4
"['than ten thousand product reviews  #TAUTHOR_TAG, this is an important']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable']","['the difference between peer reviews and other types of reviews as discussed in section 2, our work demonstrates that many generic linguistic features are also effective in predicting peer - review helpfulness.', ""the model's performance can be alter - natively achieved and further improved by adding auxiliary features tailored to peer reviews."", 'these specialized features not only introduce domain expertise, but also capture linguistic information at an abstracted level, which can help avoid the risk of over - fitting.', 'given only 267 peer reviews in our case compared to more than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable to the results of  #TAUTHOR_TAG, we indirectly compared them by analyzing the utility of features in isolation and combined.', 'while str + ugr + met is found as the best combination of generic features for both types of reviews, the best individual feature type is different ( review unigrams work best for product reviews ; structural features work best for peer reviews ).', 'more importantly, meta - data, which are found to significantly affect the perceived helpfulness of product reviews  #TAUTHOR_TAG, have no predictive power for peer reviews.', 'perhaps because the paper grades and other helpfulness ratings are not visible to the reviewers, we have less of a social dimension for predicting the helpfulness of peer reviews.', 'we also found that svm regression does not favor ranking over predicting helpfulness as in  #TAUTHOR_TAG']",4
"['texts, aiming to replicate the feature sets used by  #TAUTHOR_TAG.', 'while structural, lexical and syntactic features']","['texts, aiming to replicate the feature sets used by  #TAUTHOR_TAG.', 'while structural, lexical and syntactic features']","['papers based on the results of syntactic analysis of the texts, aiming to replicate the feature sets used by  #TAUTHOR_TAG.', 'while structural, lexical and syntactic features are created in']","['', 'the support and explanation of the ideas could use some work. broading the explanations to include all groups could be useful.', 'my concerns come from some of the claims that are put forth.', 'page 2 says that the 13th amendment ended the war.', 'is this true? was there no more fighting or problems once this amendment was added?...', 'the arguments were sorted up into paragraphs, keeping the area of interest clear, but be careful about bringing up new things at the end and then simply leaving them there without elaboration ( ie black sterilization at the end of the paragraph ).', 'an unhelpful peer review of average - rating 1 :', 'your paper and its main points are easy to find and to follow.', 'as shown in table 1, we first mine generic linguistic features from reviews and papers based on the results of syntactic analysis of the texts, aiming to replicate the feature sets used by  #TAUTHOR_TAG.', 'while structural, lexical and syntactic features are created in the same way as suggested in their paper, we adapt the semantic and meta - data features to peer reviews by converting the mentions of product properties to mentions of the history topics and by using paper ratings assigned by peers instead of product scores.', '1', ""in addition, the following specialized features are motivated by an empirical study in cognitive science  #AUTHOR_TAG, which suggests that students'revision likelihood is significantly correlated with certain feedback features, and by our prior work for detecting these cognitive science constructs automatically :"", 'cognitive - science features ( cogs ) : for a given review, cognitive - science constructs that are significantly correlated with review implementation likelihood are manually coded for each idea unit  #AUTHOR_TAG within the review.', 'note, however, that peer - review helpfulness is rated for the whole review, which can include multiple idea units.', '']",5
"[' #TAUTHOR_TAG, we train']","[' #TAUTHOR_TAG, we train']","[' #TAUTHOR_TAG, we train']","[' #TAUTHOR_TAG, we train our helpfulness model using svm regression with a radial basis function kernel provided by svm light  #AUTHOR_TAG.', 'we first evaluate each feature type in isolation to investigate its predictive power of peerreview helpfulness ; we then examine them together in various combinations to find the most useful feature set for modeling peer - review helpfulness.', '']",5
"['than ten thousand product reviews  #TAUTHOR_TAG, this is an important']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable']","['the difference between peer reviews and other types of reviews as discussed in section 2, our work demonstrates that many generic linguistic features are also effective in predicting peer - review helpfulness.', ""the model's performance can be alter - natively achieved and further improved by adding auxiliary features tailored to peer reviews."", 'these specialized features not only introduce domain expertise, but also capture linguistic information at an abstracted level, which can help avoid the risk of over - fitting.', 'given only 267 peer reviews in our case compared to more than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable to the results of  #TAUTHOR_TAG, we indirectly compared them by analyzing the utility of features in isolation and combined.', 'while str + ugr + met is found as the best combination of generic features for both types of reviews, the best individual feature type is different ( review unigrams work best for product reviews ; structural features work best for peer reviews ).', 'more importantly, meta - data, which are found to significantly affect the perceived helpfulness of product reviews  #TAUTHOR_TAG, have no predictive power for peer reviews.', 'perhaps because the paper grades and other helpfulness ratings are not visible to the reviewers, we have less of a social dimension for predicting the helpfulness of peer reviews.', 'we also found that svm regression does not favor ranking over predicting helpfulness as in  #TAUTHOR_TAG']",5
['prior findings of product reviews  #TAUTHOR_TAG where product scores'],['prior findings of product reviews  #TAUTHOR_TAG where product scores'],['prior findings of product reviews  #TAUTHOR_TAG where product scores'],"['of the generic features is presented in table 2, showing that all classes except syntactic ( syn ) and meta - data ( met ) features are sig - nificantly correlated with both helpfulness rating ( r ) and helpfulness ranking ( r s ).', 'structural features ( bolded ) achieve the highest pearson ( 0. 60 ) and spearman correlation coefficients ( 0. 59 ) ( although within the significant correlations, the difference among coefficients are insignificant ).', 'note that in isolation, met ( paper ratings ) are not significantly correlated with peer - review helpfulness, which is different from prior findings of product reviews  #TAUTHOR_TAG where product scores are significantly correlated with product - review helpfulness.', 'however, when combined with other features, met does appear to add value ( last row ).', 'when comparing the performance between predicting helpfulness ratings versus ranking, we observe r ≈ r s consistently for our peer reviews, while  #TAUTHOR_TAG reported r < r s for product reviews.', ""4 finally, we observed a similar feature redundancy effect as  #TAUTHOR_TAG did, in that simply combining all features does not improve the model's performance."", 'interestingly, our best feature combination ( last row ) is the same as theirs.', 'in sum our results verify our hypothesis that the effectiveness of generic features can be transferred to our peerreview domain for predicting review helpfulness']",3
"['than ten thousand product reviews  #TAUTHOR_TAG, this is an important']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results']","['than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable']","['the difference between peer reviews and other types of reviews as discussed in section 2, our work demonstrates that many generic linguistic features are also effective in predicting peer - review helpfulness.', ""the model's performance can be alter - natively achieved and further improved by adding auxiliary features tailored to peer reviews."", 'these specialized features not only introduce domain expertise, but also capture linguistic information at an abstracted level, which can help avoid the risk of over - fitting.', 'given only 267 peer reviews in our case compared to more than ten thousand product reviews  #TAUTHOR_TAG, this is an important consideration.', 'though our absolute quantitative results are not directly comparable to the results of  #TAUTHOR_TAG, we indirectly compared them by analyzing the utility of features in isolation and combined.', 'while str + ugr + met is found as the best combination of generic features for both types of reviews, the best individual feature type is different ( review unigrams work best for product reviews ; structural features work best for peer reviews ).', 'more importantly, meta - data, which are found to significantly affect the perceived helpfulness of product reviews  #TAUTHOR_TAG, have no predictive power for peer reviews.', 'perhaps because the paper grades and other helpfulness ratings are not visible to the reviewers, we have less of a social dimension for predicting the helpfulness of peer reviews.', 'we also found that svm regression does not favor ranking over predicting helpfulness as in  #TAUTHOR_TAG']",1
"['lr states as simple context information of  #TAUTHOR_TAG,']","['lr states as simple context information of  #TAUTHOR_TAG, [ kentaro']","['lr states as simple context information of  #TAUTHOR_TAG,']","['the first approach [ wright and wrigley 1991 ] of combining a probabilistic method into the glr technique was published, some probabilistic glr parsers also have been implemented in which probabilities are assigned to actions of lr parsing tables by using lookaheads or lr states as simple context information of  #TAUTHOR_TAG, [ kentaro et al. 1998 ], and [  #AUTHOR_TAG ] which does not use the stack information of the glr parser effectively, because of highly complex internal glr stack.', 'as a result, they have used relatively limited contextual information for disambiguation.', '[  #AUTHOR_TAG ] have proposed a conditional action model that uses the partially constructed parse represented by the graph - structured stack as the additional context.', 'however, this method inappropriately defined sub - tree structure.', 'our proposed model uses surface phrasal types representing the structural characteristics of the sub - trees for its additional contextual information']",0
"['lr states as simple context information of  #TAUTHOR_TAG,']","['lr states as simple context information of  #TAUTHOR_TAG, [ kentaro']","['lr states as simple context information of  #TAUTHOR_TAG,']","['the first approach [ wright and wrigley 1991 ] of combining a probabilistic method into the glr technique was published, some probabilistic glr parsers also have been implemented in which probabilities are assigned to actions of lr parsing tables by using lookaheads or lr states as simple context information of  #TAUTHOR_TAG, [ kentaro et al. 1998 ], and [  #AUTHOR_TAG ] which does not use the stack information of the glr parser effectively, because of highly complex internal glr stack.', 'as a result, they have used relatively limited contextual information for disambiguation.', '[  #AUTHOR_TAG ] have proposed a conditional action model that uses the partially constructed parse represented by the graph - structured stack as the additional context.', 'however, this method inappropriately defined sub - tree structure.', 'our proposed model uses surface phrasal types representing the structural characteristics of the sub - trees for its additional contextual information']",1
"['3,  #TAUTHOR_TAG 5 ] ) take various approaches to']","['3,  #TAUTHOR_TAG 5 ] ) take various approaches to the']","['3,  #TAUTHOR_TAG 5 ] ) take various approaches to the issue']","['', '##ect the input and output, in order to perform an evaluation? this issue is discussed in the sparck jones', 'paper [ 1 ]. in some cases, we can evaluate the language technology in isolation from', 'any front - end or back - end application, as shown in figure 1, where probes are inserted on either side of the language interface itself. this gives us the kind of evaluation used for word error rate in speech ( speech in, transcription out ) or for machine translation', ', as proposed in the brew / thompson paper ( source text in, target text out ) [ 2 ]. this kind of evaluation computes output as a simple function of', 'input to the language system. unfortunately, it is not always possible to', 'measure a meaningful output - for example, researchers have struggled long and hard with measurements for understanding - how can a system demonstrate that it has understood? if we had a general semantic representation, then we could insert', 'a probe on the output side of the semantic component, independent of any specific application. the last three papers ( [ 3,  #TAUTHOR_TAG 5 ] ) take various approaches to the issue of predicate - argument 1the penn treebank parse annotations provide an', 'interesting case where annotation supported evaluation. by creating a theory - neutral description of a correct', 'parse, the treebank annotation enabled researchers to take the next step in agreeing to use the parse annotations ( bracketings ) as a "" gold standard "" against which to compare system - derived bracketings [ 9 ]. this evaluation, in turn, has enabled interesting automated teaming approaches to parsing.']",0
"['3,  #TAUTHOR_TAG 5 ] ) take various approaches to']","['3,  #TAUTHOR_TAG 5 ] ) take various approaches to the']","['3,  #TAUTHOR_TAG 5 ] ) take various approaches to the issue']","['', '##ect the input and output, in order to perform an evaluation? this issue is discussed in the sparck jones', 'paper [ 1 ]. in some cases, we can evaluate the language technology in isolation from', 'any front - end or back - end application, as shown in figure 1, where probes are inserted on either side of the language interface itself. this gives us the kind of evaluation used for word error rate in speech ( speech in, transcription out ) or for machine translation', ', as proposed in the brew / thompson paper ( source text in, target text out ) [ 2 ]. this kind of evaluation computes output as a simple function of', 'input to the language system. unfortunately, it is not always possible to', 'measure a meaningful output - for example, researchers have struggled long and hard with measurements for understanding - how can a system demonstrate that it has understood? if we had a general semantic representation, then we could insert', 'a probe on the output side of the semantic component, independent of any specific application. the last three papers ( [ 3,  #TAUTHOR_TAG 5 ] ) take various approaches to the issue of predicate - argument 1the penn treebank parse annotations provide an', 'interesting case where annotation supported evaluation. by creating a theory - neutral description of a correct', 'parse, the treebank annotation enabled researchers to take the next step in agreeing to use the parse annotations ( bracketings ) as a "" gold standard "" against which to compare system - derived bracketings [ 9 ]. this evaluation, in turn, has enabled interesting automated teaming approaches to parsing.']",0
"['3,  #TAUTHOR_TAG 5 ]']","['ongoing work in new annotation and evaluation approaches for human language technology [ 3,  #TAUTHOR_TAG 5 ]']","['about the ongoing work in new annotation and evaluation approaches for human language technology [ 3,  #TAUTHOR_TAG 5 ]']","['session focused on experimental or planned approaches to human language technology evaluation and included an overview and five papers : two papers on experimental evaluation approaches [ l, 2 ], and three about the ongoing work in new annotation and evaluation approaches for human language technology [ 3,  #TAUTHOR_TAG 5 ].', 'this was followed by fifteen minutes of general discussion.', 'when considering evaluation, it is important to consider the basic issues involved in evaluation :', '•. why evaluate : what are the goals of evaluation?', '']",0
"['3,  #TAUTHOR_TAG 5 ] ) take various']","['last three papers ( [ 3,  #TAUTHOR_TAG 5 ] ) take various']","['3,  #TAUTHOR_TAG 5 ] ) take various approaches to']","['', 'this issue is discussed in the sparck jones paper [ 1 ].', 'in some cases, we can evaluate the language technology in isolation from any front - end or back - end application, as shown in figure 1, where probes are inserted on either side of the language interface itself.', 'this gives us the kind of evaluation used for word error rate in speech ( speech in, transcription out ) or for machine translation, as proposed in the brew / thompson paper ( source text in, target text out ) [ 2 ].', 'this kind of evaluation computes output as a simple function of input to the language system.', 'unfortunately, it is not always possible to measure a meaningful output - for example, researchers have struggled long and hard with measurements for understanding - how can a system demonstrate that it has understood? if we had a general semantic representation, then we could insert a probe on the output side of the semantic component, independent of any specific application.', 'the last three papers ( [ 3,  #TAUTHOR_TAG 5 ] ) take various approaches to the issue of predicate - argument 1the penn treebank parse annotations provide an interesting case where annotation supported evaluation.', 'by creating a theory - neutral description of a correct parse, the treebank annotation enabled researchers to take the next step in agreeing to use the parse annotations ( bracketings ) as a "" gold standard "" against which to compare system - derived bracketings [ 9 ].', 'this evaluation, in turn, has enabled interesting automated teaming approaches to parsing.', 'right now, we can only measure understanding by evaluating an interface coupled to an application - figure 2 shows the application back - end included inside the evaluation.', 'this allows us to evaluate understanding in terms of getting the right answer for a specific task, as is done in the air travel in formation ( atis ) system, which evaluates language input / database answer output pairs.', 'however, this means that to evaluate spoken language understanding, it is necessary to build an entire air travel information system.', 'finally, for certain kinds of applications, particularly interactive applications, it is appropriate to enlarge the scope of evaluation still further to include the users.', 'for interactive systems, this is particularly important because the user response determines what the system does next, so that it is not possible to use pre - recorded data.', '2 increasingly complex human - computer interfaces, as well as complex collaborative tools, demand that a system be evaluated in']",0
"['3,  #TAUTHOR_TAG 5 ] all reflect a concern to develop better evaluation methods for semantics, with a shared focus on predicate - argument evaluation']","['obtain maximum leverage.', 'the last three papers [ 3,  #TAUTHOR_TAG 5 ] all reflect a concern to develop better evaluation methods for semantics, with a shared focus on predicate - argument evaluation.', '']","['3,  #TAUTHOR_TAG 5 ] all reflect a concern to develop better evaluation methods for semantics, with a shared focus on predicate - argument evaluation.', 'the treebank annotation paper [ 3 ] discusses the new predicate - argument annotation work under treebank.', 'the paper by grishman discusses a range of new evaluation efforts for muc, which are aimed at providing finer']","['evaluation plays such an important role in driving research, we must weigh carefully what and how we evaluate.', 'evaluation should be theory neutral, to avoid bias against novel approaches ; it should also push the frontiers of what we know how to do ; and finally, it should support a broad range of research interests because evaluation is expensive.', 'it requires significant community investment in infrastructure, not to mention time devoted to running evaluations and participating in them.', 'for example, we estimate that the atis evaluation required several person - years to prepare annotated data, a staffof two to three people at nist over several months to run the evaluation, time spent agreeing on standards, and months of staff effort at participating sites.', 'altogether, the annual cost of an evaluation certainly exceeds five person - years, or conservatively at least $ 500, 000 per evaluation.', 'given this level of investment, it is critical to co - ordinate effort and obtain maximum leverage.', 'the last three papers [ 3,  #TAUTHOR_TAG 5 ] all reflect a concern to develop better evaluation methods for semantics, with a shared focus on predicate - argument evaluation.', 'the treebank annotation paper [ 3 ] discusses the new predicate - argument annotation work under treebank.', 'the paper by grishman discusses a range of new evaluation efforts for muc, which are aimed at providing finer grained component evaluations.', 'the last paper, by moore, describes a similar, but distinct, effort towards developing more semantic evaluation methods for the spoken language community']",0
"['outlined in  #TAUTHOR_TAG, although the tree']","['outlined in  #TAUTHOR_TAG, although the treebank annotations']","['outlined in  #TAUTHOR_TAG, although the treebank annotations may be a sub - set']",[' #TAUTHOR_TAG'],0
['- speech  #TAUTHOR_TAG'],['part - of - speech  #TAUTHOR_TAG'],['- speech  #TAUTHOR_TAG'],"['annotated corpora and treebanks are the primary tools that we have for developing and evaluating models and theories for natural language processing.', 'given their importance for testing our hypotheses, it is imperative that they are of the best quality possible.', 'however, manual annotation is tedious and error - prone, especially if many annotators are involved.', 'it is therefore desirable to have automatic means for detecting errors and inconsistencies in the annotation.', 'automatic methods for error detection in treebanks have been developed in the decca project 1 for several different annotation types, for example part - of - speech  #TAUTHOR_TAG, constituency syntax  #AUTHOR_TAG b ), and dependency syntax  #AUTHOR_TAG.', 'these algorithms work on the assumption that two data points that appear in identical contexts should be labeled in the same way.', 'while the data points in question, or nuclei, can be single tokens, spans of tokens, or edges between two tokens, context is usually modeled as n - grams over the surrounding tokens.', 'a nucleus that occurs 1 http : / / www. decca. osu. edu multiple times in identical contexts but is labeled differently shows variation and is considered a potential error.', 'natural language is ambiguous and variation found by an algorithm may be a genuine ambiguity rather than an annotation error.', 'although we can support an annotator in finding inconsistencies in a treebank, these inconsistencies still need to be judged by humans.', 'in this paper, we present a tool that allows a user to run automatic error detection on a corpus annotated with part - of - speech or dependency syntax.', '2 the tool provides the user with a graphical interface to browse the variation nuclei found by the algorithm and inspect their label distribution.', 'the user can always switch between high - level aggregate views and the actual sentences containing the potential error in order to decide if that particular annotation is incorrect or not.', 'the interface thus brings together the output of the error detection algorithm with a direct access to the corpus data.', 'this speeds up the process of tracking down inconsistencies and errors in the annotation considerably compared to working with the raw output of the original decca tools.', 'several options allow the user to fine - tune the behavior of the algorithm.', 'the tool is part of icarus ( gartner et al., 2013 ), a general search and exploration tool.', '']",0
"['algorithm, described in  #TAUTHOR_TAG for pos tags, works by starting from individual tokens ( the nuclei ) by recording their assigned part - of - speech over an']","['algorithm, described in  #TAUTHOR_TAG for pos tags, works by starting from individual tokens ( the nuclei ) by recording their assigned part - of - speech over an']","['algorithm, described in  #TAUTHOR_TAG for pos tags, works by starting from individual tokens ( the nuclei ) by recording their assigned part - of - speech over an entire treebank.', 'from there,']","['algorithm, described in  #TAUTHOR_TAG for pos tags, works by starting from individual tokens ( the nuclei ) by recording their assigned part - of - speech over an entire treebank.', 'from there, it iteratively increases the context for each instance by extending the string to both sides to include adjacent tokens.', 'it thus successively builds larger n - grams by adding tokens to the left or to the right. instances are grouped together if their context is identical, i. e. if their token ngrams match.', '']",0
"['addition to the output of the algorithm by  #TAUTHOR_TAG, the tool also']","['addition to the output of the algorithm by  #TAUTHOR_TAG, the tool also']","['addition to the output of the algorithm by  #TAUTHOR_TAG, the tool also']","['addition to the output of the algorithm by  #TAUTHOR_TAG, the tool also provides a second view, which displays tag distributions of word forms to the user ( see figure 2 ).', 'to the left, a list of unique label combinations is shown.', 'selecting one of them displays a list of word forms that occur with exactly these tags in the corpus.', 'this list is shown below the list of label combinations.', 'to the right, the frequencies of the different labels are shown in a bar chart.', 'the leftmost bar for each label always shows the total frequency summed over all word forms in the set.', 'selecting one or more in the list of word forms adds additional bars to the chart that show the frequencies for each selected word form.', 'as an example, figure 2 shows the tag combination [ vvinf ] [ vvizu ], which are used to tag infinitives with and without incorporated zu in german.', 'there are three word forms in the corpus that occur with these two part - of - speech tags : hinzukommen, aufzulosen, and anzunahern.', 'the chart on the right shows the frequencies for each word form and part - of - speech tag, revealing that hinzukommen is mostly tagged as vvinf but once as vvizu, whereas for the other two word forms it is the other way around.', 'this example is interesting if one is looking for annotation errors in the tiger treebank, because the two part - of - speech tags should have a complementary distribution ( a german verb either incorporates zu or it does not ).', 'double clicking on the word forms in the list in the lower left corner will again open up a tab that shows all sentences containing this word form, regardless of their part - of - speech tag.', 'the user may then inspect the sentences and decide whether the annotations are erroneous or not.', 'if the user wants to see a specific combination, which is more useful if the total number of sentences is large, she can also click on one of the bars in the chart to get all sentences matching that combination.', 'in the example, the one instance of hinzukommen being tagged as vvizu is incorrect, 4 and the instances of the two other verbs tagged as vvinf are as well']",6
"['not cover them.', 'these results are in line with findings by  #TAUTHOR_TAG for the penn treebank.', 'they show that even manually annotated corpora']","['not cover them.', 'these results are in line with findings by  #TAUTHOR_TAG for the penn treebank.', 'they show that even manually annotated corpora']","['the annotation guidelines do not cover them.', 'these results are in line with findings by  #TAUTHOR_TAG for the penn treebank.', 'they show that even manually annotated corpora contain errors and an automatic error mining tool can be a big help in finding them.', 'furthermore,']","['ran the error mining algorithm for part - ofspeech on the german tiger treebank ( the dependency version by  #AUTHOR_TAG ) and manually evaluated a small sample of n - grams in order to get an idea of how useful the output is.', 'we manually checked 115 out of the 207 variation 6 - grams found by the tool, which amounts to 119 different nuclei.', 'for 99. 16 % of these nuclei, we found erroneous annotations in the associated sentences.', '95. 6 % of these are errors where we are able to decide what the right tag should be, the remaining ones are more difficult to disambiguate because the annotation guidelines do not cover them.', 'these results are in line with findings by  #TAUTHOR_TAG for the penn treebank.', 'they show that even manually annotated corpora contain errors and an automatic error mining tool can be a big help in finding them.', 'furthermore, it can help annotators to improve their annotation guidelines by pointing out phenomena that are not covered by the guidelines, because these phenomena will be more likely to show variation']",3
"['by  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the user can view errors from two perspectives that aggregate error information']","['by  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the user can view errors from two perspectives that aggregate error information']","['by  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the user can view errors from two perspectives that aggregate error information']","['- quality annotations for linguistic corpora are important for testing hypotheses in nlp and linguistic research.', 'automatically marking potential annotation errors and inconsistencies are one way of supporting annotators in their work.', 'we presented a tool that provides a graphical interface for annotators to find and evaluate annotation errors in treebanks.', 'it implements the error detection algorithms by  #TAUTHOR_TAG and  #AUTHOR_TAG.', 'the user can view errors from two perspectives that aggregate error information found by the algorithm, and it is always easy to go directly to the actual sentences for manual inspection.', 'the tool is currently extended such that annotators can make changes to the data directly in the interface when they find an error']",5
"['##e speech in the form of racism and sexism is commonplace on the internet  #TAUTHOR_TAG.', 'for this']","['##e speech in the form of racism and sexism is commonplace on the internet  #TAUTHOR_TAG.', 'for this reason, there has been both an academic and an industry interest in detection of hate speech.', 'the volume of data to be reviewed']","['##e speech in the form of racism and sexism is commonplace on the internet  #TAUTHOR_TAG.', 'for this reason, there has been both an academic and an industry interest in detection of hate speech.', 'the volume of data to be reviewed']","['##e speech in the form of racism and sexism is commonplace on the internet  #TAUTHOR_TAG.', 'for this reason, there has been both an academic and an industry interest in detection of hate speech.', 'the volume of data to be reviewed for creating data sets encourages a use of crowd sourcing for the annotation efforts.', 'in this paper, we provide an examination of the influence of annotator knowledge of hate speech on classification models by comparing classification results obtained from training on expert and amateur annotations.', 'we provide an evaluation on our own data set and run our models on  #TAUTHOR_TAG.', 'we find that amateur annotators are more likely than expert annotators to label items as hate speech, and that systems trained on expert annotations outperform systems trained on amateur annotations']",0
"['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']","['related work in the field of abusive language detection has focused on detecting profanity using list - based methods to identify offensive words  #AUTHOR_TAG.', 'these methods traditionally suffer from a poor recall and do not address hate speech.', ' #AUTHOR_TAG incorporate edit distances to find variants of slurs, they are not able to find terms that do not occur in these lists.', ' #AUTHOR_TAG address this, by using comprehensive lists of slurs obtained from hatebase 4.', ' #TAUTHOR_TAG for containing hate speech.', 'our work closely resembles  #TAUTHOR_TAG classification experiments on a hate speech data set.', ' #TAUTHOR_TAG, using character n - grams and gender information.', ' #AUTHOR_TAG employ a wide array of features for abusive language detection, including but not limited to pos tags, the number of blacklisted words in a document, n - gram features including token and character n - grams and length features.', 'the primary challenge this paper presents, is the need for good annotation guidelines, if one wishes to detect specific subsets of abusive language']",0
"['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']","['related work in the field of abusive language detection has focused on detecting profanity using list - based methods to identify offensive words  #AUTHOR_TAG.', 'these methods traditionally suffer from a poor recall and do not address hate speech.', ' #AUTHOR_TAG incorporate edit distances to find variants of slurs, they are not able to find terms that do not occur in these lists.', ' #AUTHOR_TAG address this, by using comprehensive lists of slurs obtained from hatebase 4.', ' #TAUTHOR_TAG for containing hate speech.', 'our work closely resembles  #TAUTHOR_TAG classification experiments on a hate speech data set.', ' #TAUTHOR_TAG, using character n - grams and gender information.', ' #AUTHOR_TAG employ a wide array of features for abusive language detection, including but not limited to pos tags, the number of blacklisted words in a document, n - gram features including token and character n - grams and length features.', 'the primary challenge this paper presents, is the need for good annotation guidelines, if one wishes to detect specific subsets of abusive language']",0
"['expert annotators 1.', 'our data set extends the  #TAUTHOR_TAG data set by 4, 033 tweets.', 'we also illustrate, how amateur and expert annotations influence classification efforts.', 'finally, we show the effects of allowing majority voting on classification and agreement between the amateur and']","['expert annotators 1.', 'our data set extends the  #TAUTHOR_TAG data set by 4, 033 tweets.', 'we also illustrate, how amateur and expert annotations influence classification efforts.', 'finally, we show the effects of allowing majority voting on classification and agreement between the amateur and']","['expert annotators 1.', 'our data set extends the  #TAUTHOR_TAG data set by 4, 033 tweets.', 'we also illustrate, how amateur and expert annotations influence classification efforts.', 'finally, we show the effects of allowing majority voting on classification and agreement between the amateur and expert annotators']","['amounts of hate speech on exists on platforms that allow for user generated documents, which creates a need to detect and filter it  #AUTHOR_TAG, and to create data sets that contain hate speech and are annotated for the occurrence of hate speech.', 'the need for corpus creation must be weighted against the psychological tax of being exposed to large amounts of abusive language  #AUTHOR_TAG.', 'a number of studies on profanity and hate speech detection, have crowdsourced their annotations due to the resources required to annotate large data sets and the possibility of distributing the load onto the crowd  #AUTHOR_TAG.', ' #AUTHOR_TAG investigate annotator reliability for hate speech annotation, concluding that "" hate speech is a fuzzy construct that requires significantly better definitions and guidelines in order to be annotated reliably "".', 'hate speech is hard to detect for humans  #AUTHOR_TAG, which warrants a thorough understanding of the benefits and pitfalls of crowdsourced annotation.', 'this need is reinforced by previous studies, which utilize crowdsourcing of hate speech without knowledge on the quality of crowdsourced annotations for hate speech labeling.', 'in addition, it is important to understand how different manners of obtaining labeling can influence the classification models and how it is possible to obtain good annotations, while ensuring that annotators are not likely to experience adverse effects of annotating hate speech.', 'our contribution we provide annotations of 6, 909 tweets for hate speech by annotators from crowdflower and annotators that have a theoretical and applied knowledge of hate speech, henceforth amateur and expert annotators 1.', 'our data set extends the  #TAUTHOR_TAG data set by 4, 033 tweets.', 'we also illustrate, how amateur and expert annotations influence classification efforts.', 'finally, we show the effects of allowing majority voting on classification and agreement between the amateur and expert annotators']",6
"['scores  #TAUTHOR_TAG,']","['scores  #TAUTHOR_TAG,']","['classification scores  #TAUTHOR_TAG,']","['', 'we follow  #AUTHOR_TAG, in their use of the length of comments in tokens, and the average length of the words in a tweet.', 'author historical salient terms given the promising results obtained for sarcasm detection  #AUTHOR_TAG, we calculate the author historical salient terms ( ahst ).', 'we obtain up to 3200 tweets for each user in our data set, calculate the tf - idf scores, and identify the top 100 terms.', 'we then add a binary feature signifying the occurrence of each of these 100 terms.', 'interestingly, this feature performs worse than any other feature.', 'particularly when trained on expert annotations, suggesting that hate speech may be more situational or that users engaging in hate speech, do not only, or even primarily engage in hate speech.', 'gender following the indication that gender can positively influence classification scores  #TAUTHOR_TAG, we compute the gender of the users in our data set.', 'to counteract the low coverage in  #TAUTHOR_TAG, we use a lexicon trained on twitter  #AUTHOR_TAG to calculate the probability of gender.', 'using these probabilities we assign binary gender.', 'both the probability of a gender for a user and the binary gender are used as individual features.', 'we find that using gender information only contributes to the classification score for amateur annotators.', 'minority class misclassification we find that some features trained on expert and amateur annotations result in misclassification on the minority classes, including identifying no instances of the mi - nority classes ( see table 4 ).', 'these misclassifications of the minority classes are largely due to the small number of instances in those classes.', 'in spite of this, we do not believe that only boosting the size of the minority classes is a good approach, as we should seek to mimic reality in our data sets for hate speech detection.', 'results running our system on the  #TAUTHOR_TAG interestingly, the main cause of error is false positives.', 'this holds true using both amateur and expert annotations.', 'we mitigate personal bias in our annotations, as multiple people have participated in the annotation process.', ' #TAUTHOR_TAG may']",6
"['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['data set is obtained by sampling tweets from the 130k tweets extracted by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing for an overlap with the data set released by  #TAUTHOR_TAG.', 'we find that there is an overlap of 2, 876 tweets ( see table 1 ) between the two data sets.', 'racism sexism neither count 1 95 2780 given the distribution of the labels in  #TAUTHOR_TAG and our annotated data set ( see table 2 ), it is to be expected the largest overlap occurs with tweets annotated as negative for hate speech.', 'observing table 2, we see that the label distribution in our data set generally differs from the distribution in  #TAUTHOR_TAG.', 'in fact, we see that the amateur majority voted labels is the only distribution that tends towards a label distribution similar to  #TAUTHOR_TAG.', 'in addition to "" racism "", "" sexism "", and "" neither "", we add the label "" both "" for tweets that contain both racism and sexism.', 'we add this label, as the intersection of multiple oppressions can differ from the forms of oppression it consists of  #AUTHOR_TAG, and as such becomes a unique form of oppression.', 'thus, we introduce a labeling scheme that follows an intersectional approach  #AUTHOR_TAG.', 'we do not require annotators to follow links.', 'instead, we ask them to annotate tweets only containing links as "" neither ""']",3
"['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['data set is obtained by sampling tweets from the 130k tweets extracted by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing for an overlap with the data set released by  #TAUTHOR_TAG.', 'we find that there is an overlap of 2, 876 tweets ( see table 1 ) between the two data sets.', 'racism sexism neither count 1 95 2780 given the distribution of the labels in  #TAUTHOR_TAG and our annotated data set ( see table 2 ), it is to be expected the largest overlap occurs with tweets annotated as negative for hate speech.', 'observing table 2, we see that the label distribution in our data set generally differs from the distribution in  #TAUTHOR_TAG.', 'in fact, we see that the amateur majority voted labels is the only distribution that tends towards a label distribution similar to  #TAUTHOR_TAG.', 'in addition to "" racism "", "" sexism "", and "" neither "", we add the label "" both "" for tweets that contain both racism and sexism.', 'we add this label, as the intersection of multiple oppressions can differ from the forms of oppression it consists of  #AUTHOR_TAG, and as such becomes a unique form of oppression.', 'thus, we introduce a labeling scheme that follows an intersectional approach  #AUTHOR_TAG.', 'we do not require annotators to follow links.', 'instead, we ask them to annotate tweets only containing links as "" neither ""']",3
"['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['data set is obtained by sampling tweets from the 130k tweets extracted by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing for an overlap with the data set released by  #TAUTHOR_TAG.', 'we find that there is an overlap of 2, 876 tweets ( see table 1 ) between the two data sets.', 'racism sexism neither count 1 95 2780 given the distribution of the labels in  #TAUTHOR_TAG and our annotated data set ( see table 2 ), it is to be expected the largest overlap occurs with tweets annotated as negative for hate speech.', 'observing table 2, we see that the label distribution in our data set generally differs from the distribution in  #TAUTHOR_TAG.', 'in fact, we see that the amateur majority voted labels is the only distribution that tends towards a label distribution similar to  #TAUTHOR_TAG.', 'in addition to "" racism "", "" sexism "", and "" neither "", we add the label "" both "" for tweets that contain both racism and sexism.', 'we add this label, as the intersection of multiple oppressions can differ from the forms of oppression it consists of  #AUTHOR_TAG, and as such becomes a unique form of oppression.', 'thus, we introduce a labeling scheme that follows an intersectional approach  #AUTHOR_TAG.', 'we do not require annotators to follow links.', 'instead, we ask them to annotate tweets only containing links as "" neither ""']",3
"['recruit feminist and antiracism activists to annotate the data set.', 'we present the annotators with  #TAUTHOR_TAG.', 'if a tweet fails any of  #TAUTHOR_TAG, the annotators are instructed to label it as the relevant form of hate speech.', 'expert annot']","['recruit feminist and antiracism activists to annotate the data set.', 'we present the annotators with  #TAUTHOR_TAG.', 'if a tweet fails any of  #TAUTHOR_TAG, the annotators are instructed to label it as the relevant form of hate speech.', 'expert annotators are given the choice of skipping tweets, if']","['recruit feminist and antiracism activists to annotate the data set.', 'we present the annotators with  #TAUTHOR_TAG.', 'if a tweet fails any of  #TAUTHOR_TAG, the annotators are instructed to label it as the relevant form of hate speech.', 'expert annotators are given the choice of skipping tweets, if they are not confident in']","['recruit feminist and antiracism activists to annotate the data set.', 'we present the annotators with  #TAUTHOR_TAG.', 'if a tweet fails any of  #TAUTHOR_TAG, the annotators are instructed to label it as the relevant form of hate speech.', 'expert annotators are given the choice of skipping tweets, if they are not confident in which label to assign, and a "" noise "" label in case the annotators are presented with non - english tweets.', 'due to privacy concerns, all expert annotators are treated as a single entity.', 'amateur annotations amateur annotators are recruited on crowdflower without any selection, to mitigate selection biases.', 'they are presented with 6, 909 tweets that have been annotated by the expert annotators.', 'the amateur annotators are not provided with the option to skip tweets, as they are not presented tweets the experts had skipped or labeled as "" noise "".', 'annotator agreement considering annotator agreement, we find that the inter - annotator agreement among the amateur annotators is κ = 0. 57 ( σ = 0. 08 ).', 'majority vote full agreement expert 0. 34 0. 70 the low agreement in table 2 provides further evidence to the claim by  #AUTHOR_TAG that annotation of hate speech is a hard task.', 'table 2 suggests that if only cases of full agreement are considered, it is possible to obtain good annotations using crowdsourcing.', 'overlap considering the overlap with the  #TAUTHOR_TAG.', 'interestingly, we see that the vast majority of disagreements between our annotators and  #TAUTHOR_TAG the influence of the features listed in table 4 for each annotator group.', 'model selection we perform a grid search over all possible feature combinations to find the best performing features.', 'we find that the features with the highest performance are not necessarily the features with the best performance.', 'for instance, token unigrams obtains the highest f1 - score, precision, and the second highest recall on the amateur annotations, yet this feature fails to classify the minority classes.', 'features we use a range of features focusing on both the textual information given in the tweets as well as extra - linguistic information including pos tags obtained using  #AUTHOR_TAG and spacy 2.', 'in table 4 3, we see that the most significant features trained on majority voted amateur annotations emphasize extra - linguistic features while the most significant features trained on expert annotations emphasize the content of the tweets']",3
"['scores  #TAUTHOR_TAG,']","['scores  #TAUTHOR_TAG,']","['classification scores  #TAUTHOR_TAG,']","['', 'we follow  #AUTHOR_TAG, in their use of the length of comments in tokens, and the average length of the words in a tweet.', 'author historical salient terms given the promising results obtained for sarcasm detection  #AUTHOR_TAG, we calculate the author historical salient terms ( ahst ).', 'we obtain up to 3200 tweets for each user in our data set, calculate the tf - idf scores, and identify the top 100 terms.', 'we then add a binary feature signifying the occurrence of each of these 100 terms.', 'interestingly, this feature performs worse than any other feature.', 'particularly when trained on expert annotations, suggesting that hate speech may be more situational or that users engaging in hate speech, do not only, or even primarily engage in hate speech.', 'gender following the indication that gender can positively influence classification scores  #TAUTHOR_TAG, we compute the gender of the users in our data set.', 'to counteract the low coverage in  #TAUTHOR_TAG, we use a lexicon trained on twitter  #AUTHOR_TAG to calculate the probability of gender.', 'using these probabilities we assign binary gender.', 'both the probability of a gender for a user and the binary gender are used as individual features.', 'we find that using gender information only contributes to the classification score for amateur annotators.', 'minority class misclassification we find that some features trained on expert and amateur annotations result in misclassification on the minority classes, including identifying no instances of the mi - nority classes ( see table 4 ).', 'these misclassifications of the minority classes are largely due to the small number of instances in those classes.', 'in spite of this, we do not believe that only boosting the size of the minority classes is a good approach, as we should seek to mimic reality in our data sets for hate speech detection.', 'results running our system on the  #TAUTHOR_TAG interestingly, the main cause of error is false positives.', 'this holds true using both amateur and expert annotations.', 'we mitigate personal bias in our annotations, as multiple people have participated in the annotation process.', ' #TAUTHOR_TAG may']",3
"['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']","['', ' #TAUTHOR_TAG']","['related work in the field of abusive language detection has focused on detecting profanity using list - based methods to identify offensive words  #AUTHOR_TAG.', 'these methods traditionally suffer from a poor recall and do not address hate speech.', ' #AUTHOR_TAG incorporate edit distances to find variants of slurs, they are not able to find terms that do not occur in these lists.', ' #AUTHOR_TAG address this, by using comprehensive lists of slurs obtained from hatebase 4.', ' #TAUTHOR_TAG for containing hate speech.', 'our work closely resembles  #TAUTHOR_TAG classification experiments on a hate speech data set.', ' #TAUTHOR_TAG, using character n - grams and gender information.', ' #AUTHOR_TAG employ a wide array of features for abusive language detection, including but not limited to pos tags, the number of blacklisted words in a document, n - gram features including token and character n - grams and length features.', 'the primary challenge this paper presents, is the need for good annotation guidelines, if one wishes to detect specific subsets of abusive language']",3
"['efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['find that using expert annotations can produce models that perform comparably to previous classification efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set for the binary classification task but under - performs for the multi - class classification task.', 'we suggest that a weighted f1 - score be applied in evaluation of classification efforts on hate speech corpora, such that misclassification on minority classes is penalized.', 'our annotation and classification results expand on the claim of  #AUTHOR_TAG that hate speech is hard to annotate without intimate knowledge of hate speech.', 'furthermore, we find that considering only cases of full agreement among amateur annota - tors can produce relatively good annotations as compared to expert annotators.', 'this can allow for a significant decrease in the annotations burden of expert annotators by asking them to primarily consider the cases in which amateur annotators have disagreed.', 'future work we will seek to further investigate the socio - linguistic features such as gender and location.', 'furthermore, we will expand to more forms of hate speech.', 'finally, we will review the negative class in  #TAUTHOR_TAG']",3
"['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing']","['data set is obtained by sampling tweets from the 130k tweets extracted by  #TAUTHOR_TAG.', 'the order of the tweets is selected by our database connection, thus allowing for an overlap with the data set released by  #TAUTHOR_TAG.', 'we find that there is an overlap of 2, 876 tweets ( see table 1 ) between the two data sets.', 'racism sexism neither count 1 95 2780 given the distribution of the labels in  #TAUTHOR_TAG and our annotated data set ( see table 2 ), it is to be expected the largest overlap occurs with tweets annotated as negative for hate speech.', 'observing table 2, we see that the label distribution in our data set generally differs from the distribution in  #TAUTHOR_TAG.', 'in fact, we see that the amateur majority voted labels is the only distribution that tends towards a label distribution similar to  #TAUTHOR_TAG.', 'in addition to "" racism "", "" sexism "", and "" neither "", we add the label "" both "" for tweets that contain both racism and sexism.', 'we add this label, as the intersection of multiple oppressions can differ from the forms of oppression it consists of  #AUTHOR_TAG, and as such becomes a unique form of oppression.', 'thus, we introduce a labeling scheme that follows an intersectional approach  #AUTHOR_TAG.', 'we do not require annotators to follow links.', 'instead, we ask them to annotate tweets only containing links as "" neither ""']",4
"['recruit feminist and antiracism activists to annotate the data set.', 'we present the annotators with  #TAUTHOR_TAG.', 'if a tweet fails any of  #TAUTHOR_TAG, the annotators are instructed to label it as the relevant form of hate speech.', 'expert annot']","['recruit feminist and antiracism activists to annotate the data set.', 'we present the annotators with  #TAUTHOR_TAG.', 'if a tweet fails any of  #TAUTHOR_TAG, the annotators are instructed to label it as the relevant form of hate speech.', 'expert annotators are given the choice of skipping tweets, if']","['recruit feminist and antiracism activists to annotate the data set.', 'we present the annotators with  #TAUTHOR_TAG.', 'if a tweet fails any of  #TAUTHOR_TAG, the annotators are instructed to label it as the relevant form of hate speech.', 'expert annotators are given the choice of skipping tweets, if they are not confident in']","['recruit feminist and antiracism activists to annotate the data set.', 'we present the annotators with  #TAUTHOR_TAG.', 'if a tweet fails any of  #TAUTHOR_TAG, the annotators are instructed to label it as the relevant form of hate speech.', 'expert annotators are given the choice of skipping tweets, if they are not confident in which label to assign, and a "" noise "" label in case the annotators are presented with non - english tweets.', 'due to privacy concerns, all expert annotators are treated as a single entity.', 'amateur annotations amateur annotators are recruited on crowdflower without any selection, to mitigate selection biases.', 'they are presented with 6, 909 tweets that have been annotated by the expert annotators.', 'the amateur annotators are not provided with the option to skip tweets, as they are not presented tweets the experts had skipped or labeled as "" noise "".', 'annotator agreement considering annotator agreement, we find that the inter - annotator agreement among the amateur annotators is κ = 0. 57 ( σ = 0. 08 ).', 'majority vote full agreement expert 0. 34 0. 70 the low agreement in table 2 provides further evidence to the claim by  #AUTHOR_TAG that annotation of hate speech is a hard task.', 'table 2 suggests that if only cases of full agreement are considered, it is possible to obtain good annotations using crowdsourcing.', 'overlap considering the overlap with the  #TAUTHOR_TAG.', 'interestingly, we see that the vast majority of disagreements between our annotators and  #TAUTHOR_TAG the influence of the features listed in table 4 for each annotator group.', 'model selection we perform a grid search over all possible feature combinations to find the best performing features.', 'we find that the features with the highest performance are not necessarily the features with the best performance.', 'for instance, token unigrams obtains the highest f1 - score, precision, and the second highest recall on the amateur annotations, yet this feature fails to classify the minority classes.', 'features we use a range of features focusing on both the textual information given in the tweets as well as extra - linguistic information including pos tags obtained using  #AUTHOR_TAG and spacy 2.', 'in table 4 3, we see that the most significant features trained on majority voted amateur annotations emphasize extra - linguistic features while the most significant features trained on expert annotations emphasize the content of the tweets']",4
"['scores  #TAUTHOR_TAG,']","['scores  #TAUTHOR_TAG,']","['classification scores  #TAUTHOR_TAG,']","['', 'we follow  #AUTHOR_TAG, in their use of the length of comments in tokens, and the average length of the words in a tweet.', 'author historical salient terms given the promising results obtained for sarcasm detection  #AUTHOR_TAG, we calculate the author historical salient terms ( ahst ).', 'we obtain up to 3200 tweets for each user in our data set, calculate the tf - idf scores, and identify the top 100 terms.', 'we then add a binary feature signifying the occurrence of each of these 100 terms.', 'interestingly, this feature performs worse than any other feature.', 'particularly when trained on expert annotations, suggesting that hate speech may be more situational or that users engaging in hate speech, do not only, or even primarily engage in hate speech.', 'gender following the indication that gender can positively influence classification scores  #TAUTHOR_TAG, we compute the gender of the users in our data set.', 'to counteract the low coverage in  #TAUTHOR_TAG, we use a lexicon trained on twitter  #AUTHOR_TAG to calculate the probability of gender.', 'using these probabilities we assign binary gender.', 'both the probability of a gender for a user and the binary gender are used as individual features.', 'we find that using gender information only contributes to the classification score for amateur annotators.', 'minority class misclassification we find that some features trained on expert and amateur annotations result in misclassification on the minority classes, including identifying no instances of the mi - nority classes ( see table 4 ).', 'these misclassifications of the minority classes are largely due to the small number of instances in those classes.', 'in spite of this, we do not believe that only boosting the size of the minority classes is a good approach, as we should seek to mimic reality in our data sets for hate speech detection.', 'results running our system on the  #TAUTHOR_TAG interestingly, the main cause of error is false positives.', 'this holds true using both amateur and expert annotations.', 'we mitigate personal bias in our annotations, as multiple people have participated in the annotation process.', ' #TAUTHOR_TAG may']",4
"['efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['find that using expert annotations can produce models that perform comparably to previous classification efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set for the binary classification task but under - performs for the multi - class classification task.', 'we suggest that a weighted f1 - score be applied in evaluation of classification efforts on hate speech corpora, such that misclassification on minority classes is penalized.', 'our annotation and classification results expand on the claim of  #AUTHOR_TAG that hate speech is hard to annotate without intimate knowledge of hate speech.', 'furthermore, we find that considering only cases of full agreement among amateur annota - tors can produce relatively good annotations as compared to expert annotators.', 'this can allow for a significant decrease in the annotations burden of expert annotators by asking them to primarily consider the cases in which amateur annotators have disagreed.', 'future work we will seek to further investigate the socio - linguistic features such as gender and location.', 'furthermore, we will expand to more forms of hate speech.', 'finally, we will review the negative class in  #TAUTHOR_TAG']",4
"['efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set']","['find that using expert annotations can produce models that perform comparably to previous classification efforts.', 'our best model is on par with previous work on the  #TAUTHOR_TAG data set for the binary classification task but under - performs for the multi - class classification task.', 'we suggest that a weighted f1 - score be applied in evaluation of classification efforts on hate speech corpora, such that misclassification on minority classes is penalized.', 'our annotation and classification results expand on the claim of  #AUTHOR_TAG that hate speech is hard to annotate without intimate knowledge of hate speech.', 'furthermore, we find that considering only cases of full agreement among amateur annota - tors can produce relatively good annotations as compared to expert annotators.', 'this can allow for a significant decrease in the annotations burden of expert annotators by asking them to primarily consider the cases in which amateur annotators have disagreed.', 'future work we will seek to further investigate the socio - linguistic features such as gender and location.', 'furthermore, we will expand to more forms of hate speech.', 'finally, we will review the negative class in  #TAUTHOR_TAG']",1
,,,,5
['sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],['. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],['. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],"['of a collected nl utterance and an associated mr. using this framework, we collected a dataset of 50k instances in the', 'restaurant domain, which is 10 times bigger than datasets currently used for nlg training, e. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to evaluate the quality of the collected corpus, we analyse the data with regards to', 'lexical richness and syntactic variation and compare our results to other popular', 'datasets in similar domains, i. e. sfrest, sfhot and bagel. we use the lexical complexity analyser  #AUTHOR_TAG to measure various dimensions of lexical', 'richness and variation, such as mean segmental type - token ratio ( msttr ) and lexical sophistication ( ls ). the results of lexical analysis ( see table 1 ) show that our corpus is lexically more diverse and as such, considerably more complex. in order to evaluate syntactic variation and complexity of nl references in our corpus,', '']",5
,,,,1
['sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],['. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],['. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],"['of a collected nl utterance and an associated mr. using this framework, we collected a dataset of 50k instances in the', 'restaurant domain, which is 10 times bigger than datasets currently used for nlg training, e. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to evaluate the quality of the collected corpus, we analyse the data with regards to', 'lexical richness and syntactic variation and compare our results to other popular', 'datasets in similar domains, i. e. sfrest, sfhot and bagel. we use the lexical complexity analyser  #AUTHOR_TAG to measure various dimensions of lexical', 'richness and variation, such as mean segmental type - token ratio ( msttr ) and lexical sophistication ( ls ). the results of lexical analysis ( see table 1 ) show that our corpus is lexically more diverse and as such, considerably more complex. in order to evaluate syntactic variation and complexity of nl references in our corpus,', '']",1
,,,,4
,,,,4
['sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],['. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],['. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],"['of a collected nl utterance and an associated mr. using this framework, we collected a dataset of 50k instances in the', 'restaurant domain, which is 10 times bigger than datasets currently used for nlg training, e. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to evaluate the quality of the collected corpus, we analyse the data with regards to', 'lexical richness and syntactic variation and compare our results to other popular', 'datasets in similar domains, i. e. sfrest, sfhot and bagel. we use the lexical complexity analyser  #AUTHOR_TAG to measure various dimensions of lexical', 'richness and variation, such as mean segmental type - token ratio ( msttr ) and lexical sophistication ( ls ). the results of lexical analysis ( see table 1 ) show that our corpus is lexically more diverse and as such, considerably more complex. in order to evaluate syntactic variation and complexity of nl references in our corpus,', '']",4
['sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],['. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],['. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to'],"['of a collected nl utterance and an associated mr. using this framework, we collected a dataset of 50k instances in the', 'restaurant domain, which is 10 times bigger than datasets currently used for nlg training, e. g. sfrest and sfhot  #TAUTHOR_TAG or bagel  #AUTHOR_TAG. to evaluate the quality of the collected corpus, we analyse the data with regards to', 'lexical richness and syntactic variation and compare our results to other popular', 'datasets in similar domains, i. e. sfrest, sfhot and bagel. we use the lexical complexity analyser  #AUTHOR_TAG to measure various dimensions of lexical', 'richness and variation, such as mean segmental type - token ratio ( msttr ) and lexical sophistication ( ls ). the results of lexical analysis ( see table 1 ) show that our corpus is lexically more diverse and as such, considerably more complex. in order to evaluate syntactic variation and complexity of nl references in our corpus,', '']",4
"['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important']","['simplification is the task to find and substitute a complex word or phrase in a sentence with its simpler synonymous expression.', 'we define complex word as a word that has lexical and subjective difficulty in a sentence.', 'it can help in reading comprehension for children and language learners  #AUTHOR_TAG.', 'this task is a rather easier task which prepare a pair of complex and simple representations than a challenging task which changes the substitute pair in a given context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important to ensure the reliability and reproducibility of evaluation.', 'however, few resources are available for the automatic evaluation of lexical simplification.', ' #AUTHOR_TAG and  #AUTHOR_TAG created benchmark datasets for evaluating english lexical simplification.', 'in addition,  #AUTHOR_TAG extracted simplification candidates and constructed an evaluation dataset using english wikipedia and simple english wikipedia.', 'in contrast, such a parallel corpus does not exist in japanese.', ' #TAUTHOR_TAG constructed an evaluation dataset for japanese lexical simplification 1 in languages other than english.', 'however, there are four drawbacks in the dataset of  #TAUTHOR_TAG did not integrate simplification ranking considering the quality.', 'hence, we propose a new dataset addressing the problems in  #TAUTHOR_TAG.', 'the main contributions of our study are as follows :', '• it is the first controlled and balanced dataset for japanese lexical simplification.', 'we extract sentences from a balanced corpus and control sentences to have only one complex word.', 'experimental results show that our dataset is more suitable than previous datasets for evaluating systems with respect to correlation with human judgment.', '• the consistency of simplification ranking is greatly improved by allowing candidates to have ties and by considering the reliability of annotators.', 'our dataset is available at github 2']",4
['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsour'],"['', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', '']","['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the']","['for  #AUTHOR_TAG. during the simplification ranking task, annotators were asked to reorder the target word and', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the substitute extraction task', '']",4
"[' #TAUTHOR_TAG.', '']","[' #TAUTHOR_TAG.', '']","['the quality of the ranking integration, the spearman rank correlation coefficient was calculated.', 'the baseline integration ranking used an average score  #TAUTHOR_TAG.', '']","['evaluate the quality of the ranking integration, the spearman rank correlation coefficient was calculated.', 'the baseline integration ranking used an average score  #TAUTHOR_TAG.', 'our proposed method excludes outlier annotators by using a reliability score calculated using the method developed by  #AUTHOR_TAG.', 'pairwise agreement is calculated between each pair of sets ( p 1, p 2 ∈ p ) from all the possible pairings ( p ) ( equation 1 ).', 'the agreement among annotators from the substitute evaluation phase was 0. 669, and agreement among the students is 0. 673, which is similar to the level found in crowdsourcing.', '']",4
"[' #TAUTHOR_TAG.', '']","[' #TAUTHOR_TAG.', '']","['the quality of the ranking integration, the spearman rank correlation coefficient was calculated.', 'the baseline integration ranking used an average score  #TAUTHOR_TAG.', '']","['evaluate the quality of the ranking integration, the spearman rank correlation coefficient was calculated.', 'the baseline integration ranking used an average score  #TAUTHOR_TAG.', 'our proposed method excludes outlier annotators by using a reliability score calculated using the method developed by  #AUTHOR_TAG.', 'pairwise agreement is calculated between each pair of sets ( p 1, p 2 ∈ p ) from all the possible pairings ( p ) ( equation 1 ).', 'the agreement among annotators from the substitute evaluation phase was 0. 669, and agreement among the students is 0. 673, which is similar to the level found in crowdsourcing.', '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['ranked substitutes according to the metrics, and calculated the 1 - best accuracy for each target word.', 'finally, to compare two datasets, we used the pearson product - moment correlation coefficient between our dataset and the dataset of  #TAUTHOR_TAG against the annotated data.', 'table 4 shows the result of this experiment.', 'the pearson coefficient shows that our dataset correlates with human annotation better than the dataset of  #TAUTHOR_TAG, possibly because we controlled each sentence to include only one complex word.', 'because our dataset is balanced, the accuracy of web corpus - based metrics ( frequency and number of users ) closer than the dataset of  #TAUTHOR_TAG']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['ranked substitutes according to the metrics, and calculated the 1 - best accuracy for each target word.', 'finally, to compare two datasets, we used the pearson product - moment correlation coefficient between our dataset and the dataset of  #TAUTHOR_TAG against the annotated data.', 'table 4 shows the result of this experiment.', 'the pearson coefficient shows that our dataset correlates with human annotation better than the dataset of  #TAUTHOR_TAG, possibly because we controlled each sentence to include only one complex word.', 'because our dataset is balanced, the accuracy of web corpus - based metrics ( frequency and number of users ) closer than the dataset of  #TAUTHOR_TAG']",4
"['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important']","['simplification is the task to find and substitute a complex word or phrase in a sentence with its simpler synonymous expression.', 'we define complex word as a word that has lexical and subjective difficulty in a sentence.', 'it can help in reading comprehension for children and language learners  #AUTHOR_TAG.', 'this task is a rather easier task which prepare a pair of complex and simple representations than a challenging task which changes the substitute pair in a given context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important to ensure the reliability and reproducibility of evaluation.', 'however, few resources are available for the automatic evaluation of lexical simplification.', ' #AUTHOR_TAG and  #AUTHOR_TAG created benchmark datasets for evaluating english lexical simplification.', 'in addition,  #AUTHOR_TAG extracted simplification candidates and constructed an evaluation dataset using english wikipedia and simple english wikipedia.', 'in contrast, such a parallel corpus does not exist in japanese.', ' #TAUTHOR_TAG constructed an evaluation dataset for japanese lexical simplification 1 in languages other than english.', 'however, there are four drawbacks in the dataset of  #TAUTHOR_TAG did not integrate simplification ranking considering the quality.', 'hence, we propose a new dataset addressing the problems in  #TAUTHOR_TAG.', 'the main contributions of our study are as follows :', '• it is the first controlled and balanced dataset for japanese lexical simplification.', 'we extract sentences from a balanced corpus and control sentences to have only one complex word.', 'experimental results show that our dataset is more suitable than previous datasets for evaluating systems with respect to correlation with human judgment.', '• the consistency of simplification ranking is greatly improved by allowing candidates to have ties and by considering the reliability of annotators.', 'our dataset is available at github 2']",5
['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsour'],"['', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', '']","['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the']","['for  #AUTHOR_TAG. during the simplification ranking task, annotators were asked to reorder the target word and', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the substitute extraction task', '']",5
['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsour'],"['', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', '']","['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the']","['for  #AUTHOR_TAG. during the simplification ranking task, annotators were asked to reorder the target word and', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the substitute extraction task', '']",5
['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsour'],"['', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', '']","['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the']","['for  #AUTHOR_TAG. during the simplification ranking task, annotators were asked to reorder the target word and', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the substitute extraction task', '']",5
['follows the data creation procedure of  #TAUTHOR_TAG dataset with improvements'],['follows the data creation procedure of  #TAUTHOR_TAG dataset with improvements'],"['of japanese lexical simplification.', 'figure 2 illustrates how we constructed the dataset.', 'it follows the data creation procedure of  #TAUTHOR_TAG dataset with improvements']","['create a balanced dataset for the evaluation of japanese lexical simplification.', 'figure 2 illustrates how we constructed the dataset.', 'it follows the data creation procedure of  #TAUTHOR_TAG dataset with improvements to resolve the problems described in section 3.', 'we use a crowdsourcing application, lancers, 3 3 http : / / www. lancers. jp / figure 3 : example of annotation of extracting substitutes.', 'annotators are provided with substitutes that preserve the meaning of target word which is shown bold in the sentence.', 'in addition, annotators can write a substitute including particles.', 'to perform substitute extraction, substitute evaluation, and substitute ranking.', 'in each task, we requested the annotators to complete at least 95 % of their previous assignments correctly.', 'they were native japanese speakers']",5
"[' #TAUTHOR_TAG.', '']","[' #TAUTHOR_TAG.', '']","['the quality of the ranking integration, the spearman rank correlation coefficient was calculated.', 'the baseline integration ranking used an average score  #TAUTHOR_TAG.', '']","['evaluate the quality of the ranking integration, the spearman rank correlation coefficient was calculated.', 'the baseline integration ranking used an average score  #TAUTHOR_TAG.', 'our proposed method excludes outlier annotators by using a reliability score calculated using the method developed by  #AUTHOR_TAG.', 'pairwise agreement is calculated between each pair of sets ( p 1, p 2 ∈ p ) from all the possible pairings ( p ) ( equation 1 ).', 'the agreement among annotators from the substitute evaluation phase was 0. 669, and agreement among the students is 0. 673, which is similar to the level found in crowdsourcing.', '']",5
"[' #TAUTHOR_TAG.', 'annotated']","[' #TAUTHOR_TAG.', 'annotated']","[' #TAUTHOR_TAG.', 'annotated']","['this section, we evaluate our dataset using five simple lexical simplification methods.', 'we calcu - late 1 - best accuracy in our dataset and the dataset of  #TAUTHOR_TAG.', ""annotated data is collected by our and  #TAUTHOR_TAG's work in ranking substitutes task, and which size is 21, 700 ( ( 2010 + 2330 ) 5 ) rankings."", 'then, we calculate correlation between the accuracies of annotated data and either those of  #TAUTHOR_TAG or those of our dataset']",5
"[' #TAUTHOR_TAG.', 'annotated']","[' #TAUTHOR_TAG.', 'annotated']","[' #TAUTHOR_TAG.', 'annotated']","['this section, we evaluate our dataset using five simple lexical simplification methods.', 'we calcu - late 1 - best accuracy in our dataset and the dataset of  #TAUTHOR_TAG.', ""annotated data is collected by our and  #TAUTHOR_TAG's work in ranking substitutes task, and which size is 21, 700 ( ( 2010 + 2330 ) 5 ) rankings."", 'then, we calculate correlation between the accuracies of annotated data and either those of  #TAUTHOR_TAG or those of our dataset']",5
"[' #TAUTHOR_TAG.', 'annotated']","[' #TAUTHOR_TAG.', 'annotated']","[' #TAUTHOR_TAG.', 'annotated']","['this section, we evaluate our dataset using five simple lexical simplification methods.', 'we calcu - late 1 - best accuracy in our dataset and the dataset of  #TAUTHOR_TAG.', ""annotated data is collected by our and  #TAUTHOR_TAG's work in ranking substitutes task, and which size is 21, 700 ( ( 2010 + 2330 ) 5 ) rankings."", 'then, we calculate correlation between the accuracies of annotated data and either those of  #TAUTHOR_TAG or those of our dataset']",5
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['ranked substitutes according to the metrics, and calculated the 1 - best accuracy for each target word.', 'finally, to compare two datasets, we used the pearson product - moment correlation coefficient between our dataset and the dataset of  #TAUTHOR_TAG against the annotated data.', 'table 4 shows the result of this experiment.', 'the pearson coefficient shows that our dataset correlates with human annotation better than the dataset of  #TAUTHOR_TAG, possibly because we controlled each sentence to include only one complex word.', 'because our dataset is balanced, the accuracy of web corpus - based metrics ( frequency and number of users ) closer than the dataset of  #TAUTHOR_TAG']",5
"['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important']","['simplification is the task to find and substitute a complex word or phrase in a sentence with its simpler synonymous expression.', 'we define complex word as a word that has lexical and subjective difficulty in a sentence.', 'it can help in reading comprehension for children and language learners  #AUTHOR_TAG.', 'this task is a rather easier task which prepare a pair of complex and simple representations than a challenging task which changes the substitute pair in a given context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important to ensure the reliability and reproducibility of evaluation.', 'however, few resources are available for the automatic evaluation of lexical simplification.', ' #AUTHOR_TAG and  #AUTHOR_TAG created benchmark datasets for evaluating english lexical simplification.', 'in addition,  #AUTHOR_TAG extracted simplification candidates and constructed an evaluation dataset using english wikipedia and simple english wikipedia.', 'in contrast, such a parallel corpus does not exist in japanese.', ' #TAUTHOR_TAG constructed an evaluation dataset for japanese lexical simplification 1 in languages other than english.', 'however, there are four drawbacks in the dataset of  #TAUTHOR_TAG did not integrate simplification ranking considering the quality.', 'hence, we propose a new dataset addressing the problems in  #TAUTHOR_TAG.', 'the main contributions of our study are as follows :', '• it is the first controlled and balanced dataset for japanese lexical simplification.', 'we extract sentences from a balanced corpus and control sentences to have only one complex word.', 'experimental results show that our dataset is more suitable than previous datasets for evaluating systems with respect to correlation with human judgment.', '• the consistency of simplification ranking is greatly improved by allowing candidates to have ties and by considering the reliability of annotators.', 'our dataset is available at github 2']",0
"['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important']","['simplification is the task to find and substitute a complex word or phrase in a sentence with its simpler synonymous expression.', 'we define complex word as a word that has lexical and subjective difficulty in a sentence.', 'it can help in reading comprehension for children and language learners  #AUTHOR_TAG.', 'this task is a rather easier task which prepare a pair of complex and simple representations than a challenging task which changes the substitute pair in a given context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important to ensure the reliability and reproducibility of evaluation.', 'however, few resources are available for the automatic evaluation of lexical simplification.', ' #AUTHOR_TAG and  #AUTHOR_TAG created benchmark datasets for evaluating english lexical simplification.', 'in addition,  #AUTHOR_TAG extracted simplification candidates and constructed an evaluation dataset using english wikipedia and simple english wikipedia.', 'in contrast, such a parallel corpus does not exist in japanese.', ' #TAUTHOR_TAG constructed an evaluation dataset for japanese lexical simplification 1 in languages other than english.', 'however, there are four drawbacks in the dataset of  #TAUTHOR_TAG did not integrate simplification ranking considering the quality.', 'hence, we propose a new dataset addressing the problems in  #TAUTHOR_TAG.', 'the main contributions of our study are as follows :', '• it is the first controlled and balanced dataset for japanese lexical simplification.', 'we extract sentences from a balanced corpus and control sentences to have only one complex word.', 'experimental results show that our dataset is more suitable than previous datasets for evaluating systems with respect to correlation with human judgment.', '• the consistency of simplification ranking is greatly improved by allowing candidates to have ties and by considering the reliability of annotators.', 'our dataset is available at github 2']",0
['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsour'],"['', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', '']","['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the']","['for  #AUTHOR_TAG. during the simplification ranking task, annotators were asked to reorder the target word and', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the substitute extraction task', '']",0
['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsour'],"['', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', '']","['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the']","['for  #AUTHOR_TAG. during the simplification ranking task, annotators were asked to reorder the target word and', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the substitute extraction task', '']",0
['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsour'],"['', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', '']","['substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the']","['for  #AUTHOR_TAG. during the simplification ranking task, annotators were asked to reorder the target word and', 'its substitutes in a single order without allowing ties.  #TAUTHOR_TAG used crowdsourcing to', 'find five annotators different from those who performed the substitute extraction task', '']",0
"['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark']","['context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important']","['simplification is the task to find and substitute a complex word or phrase in a sentence with its simpler synonymous expression.', 'we define complex word as a word that has lexical and subjective difficulty in a sentence.', 'it can help in reading comprehension for children and language learners  #AUTHOR_TAG.', 'this task is a rather easier task which prepare a pair of complex and simple representations than a challenging task which changes the substitute pair in a given context  #TAUTHOR_TAG.', 'construction of a benchmark dataset is important to ensure the reliability and reproducibility of evaluation.', 'however, few resources are available for the automatic evaluation of lexical simplification.', ' #AUTHOR_TAG and  #AUTHOR_TAG created benchmark datasets for evaluating english lexical simplification.', 'in addition,  #AUTHOR_TAG extracted simplification candidates and constructed an evaluation dataset using english wikipedia and simple english wikipedia.', 'in contrast, such a parallel corpus does not exist in japanese.', ' #TAUTHOR_TAG constructed an evaluation dataset for japanese lexical simplification 1 in languages other than english.', 'however, there are four drawbacks in the dataset of  #TAUTHOR_TAG did not integrate simplification ranking considering the quality.', 'hence, we propose a new dataset addressing the problems in  #TAUTHOR_TAG.', 'the main contributions of our study are as follows :', '• it is the first controlled and balanced dataset for japanese lexical simplification.', 'we extract sentences from a balanced corpus and control sentences to have only one complex word.', 'experimental results show that our dataset is more suitable than previous datasets for evaluating systems with respect to correlation with human judgment.', '• the consistency of simplification ranking is greatly improved by allowing candidates to have ties and by considering the reliability of annotators.', 'our dataset is available at github 2']",6
['follows the data creation procedure of  #TAUTHOR_TAG dataset with improvements'],['follows the data creation procedure of  #TAUTHOR_TAG dataset with improvements'],"['of japanese lexical simplification.', 'figure 2 illustrates how we constructed the dataset.', 'it follows the data creation procedure of  #TAUTHOR_TAG dataset with improvements']","['create a balanced dataset for the evaluation of japanese lexical simplification.', 'figure 2 illustrates how we constructed the dataset.', 'it follows the data creation procedure of  #TAUTHOR_TAG dataset with improvements to resolve the problems described in section 3.', 'we use a crowdsourcing application, lancers, 3 3 http : / / www. lancers. jp / figure 3 : example of annotation of extracting substitutes.', 'annotators are provided with substitutes that preserve the meaning of target word which is shown bold in the sentence.', 'in addition, annotators can write a substitute including particles.', 'to perform substitute extraction, substitute evaluation, and substitute ranking.', 'in each task, we requested the annotators to complete at least 95 % of their previous assignments correctly.', 'they were native japanese speakers']",6
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"['ranked substitutes according to the metrics, and calculated the 1 - best accuracy for each target word.', 'finally, to compare two datasets, we used the pearson product - moment correlation coefficient between our dataset and the dataset of  #TAUTHOR_TAG against the annotated data.', 'table 4 shows the result of this experiment.', 'the pearson coefficient shows that our dataset correlates with human annotation better than the dataset of  #TAUTHOR_TAG, possibly because we controlled each sentence to include only one complex word.', 'because our dataset is balanced, the accuracy of web corpus - based metrics ( frequency and number of users ) closer than the dataset of  #TAUTHOR_TAG']",6
"[' #TAUTHOR_TAG.', 'our dataset has two advantages : ( 1']","[' #TAUTHOR_TAG.', 'our dataset has two advantages : ( 1 ) improved correlation with human']","['previous work  #TAUTHOR_TAG.', 'our dataset has two advantages : ( 1']","[""##ators'rankings were integrated into one ranking, using a maximum likelihood estimation  #AUTHOR_TAG to penalize deceptive annotators as was done by  #AUTHOR_TAG."", 'this method estimates the reliability of annotators in addition to determining the true order of rankings.', 'we applied the reliability score to exclude extraordinary annotators.', 'table 1 shows the characteristics of our dataset.', 'it is about the same size as previous work  #TAUTHOR_TAG.', 'our dataset has two advantages : ( 1 ) improved correlation with human judgment by making a controlled and balanced dataset, and ( 2 ) enhanced consistency by allowing ties in ranking and removing outlier annotators.', 'in the following subsections, we evaluate our dataset in detail']",3
"['more reliable modeling', 'of smaller datasets. more detailed discussion of relation between the markov logic network ( mln ) approach of  #TAUTHOR_TAG and our non - parametric method is presented in']","['more reliable modeling', 'of smaller datasets. more detailed discussion of relation between the markov logic network ( mln ) approach of  #TAUTHOR_TAG and our non - parametric method is presented in']","['more reliable modeling', 'of smaller datasets. more detailed discussion of relation between the markov logic network ( mln ) approach of  #TAUTHOR_TAG and our non - parametric method is presented in section 3', '. hierarchical pitman - yor processes (']","['hyperpriors and the potential for more reliable modeling', 'of smaller datasets. more detailed discussion of relation between the markov logic network ( mln ) approach of  #TAUTHOR_TAG and our non - parametric method is presented in section 3', '. hierarchical pitman - yor processes ( or their special case, hierarchical dirichlet processes )', 'have previously been used in nlp, for example, in the context of syntactic parsing  #AUTHOR_TAG. however, in all these cases the effective size of the state space (', 'i. e., the number of sub - symbols in the infinite pcfg  #AUTHOR_TAG, or the number of adapted productions in the adaptor', 'grammar  #AUTHOR_TAG ) was not very large. in our case, the state space size equals the total number of distinct semantic clusters', ', and, thus, is expected to be exceedingly large even for moderate datasets : for example, the mln model induces', '18, 543 distinct clusters from 18, 471 sentences of the genia corpus  #TAUTHOR_TAG. this suggests that standard inference methods for hierarchical py processes, such as gibbs sampling, metropolis - hastings ( mh )', 'sampling with uniform proposals, or the structured mean - field algorithm, are unlikely to result in efficient inference : for example in standard gibbs sampling all thousands of alternatives should be considered at each sampling move. instead, we use a split - merge mh sampling algorithm, which is a standard and efficient inference tool for', 'non - hierarchical py processes  #AUTHOR_TAG but has not previously been used in hierarchical setting. we extend the sampler to include composition - decomposition of syntactic fragments in order to cluster fragments of variables size, as', '']",7
"['more reliable modeling', 'of smaller datasets. more detailed discussion of relation between the markov logic network ( mln ) approach of  #TAUTHOR_TAG and our non - parametric method is presented in']","['more reliable modeling', 'of smaller datasets. more detailed discussion of relation between the markov logic network ( mln ) approach of  #TAUTHOR_TAG and our non - parametric method is presented in']","['more reliable modeling', 'of smaller datasets. more detailed discussion of relation between the markov logic network ( mln ) approach of  #TAUTHOR_TAG and our non - parametric method is presented in section 3', '. hierarchical pitman - yor processes (']","['hyperpriors and the potential for more reliable modeling', 'of smaller datasets. more detailed discussion of relation between the markov logic network ( mln ) approach of  #TAUTHOR_TAG and our non - parametric method is presented in section 3', '. hierarchical pitman - yor processes ( or their special case, hierarchical dirichlet processes )', 'have previously been used in nlp, for example, in the context of syntactic parsing  #AUTHOR_TAG. however, in all these cases the effective size of the state space (', 'i. e., the number of sub - symbols in the infinite pcfg  #AUTHOR_TAG, or the number of adapted productions in the adaptor', 'grammar  #AUTHOR_TAG ) was not very large. in our case, the state space size equals the total number of distinct semantic clusters', ', and, thus, is expected to be exceedingly large even for moderate datasets : for example, the mln model induces', '18, 543 distinct clusters from 18, 471 sentences of the genia corpus  #TAUTHOR_TAG. this suggests that standard inference methods for hierarchical py processes, such as gibbs sampling, metropolis - hastings ( mh )', 'sampling with uniform proposals, or the structured mean - field algorithm, are unlikely to result in efficient inference : for example in standard gibbs sampling all thousands of alternatives should be considered at each sampling move. instead, we use a split - merge mh sampling algorithm, which is a standard and efficient inference tool for', 'non - hierarchical py processes  #AUTHOR_TAG but has not previously been used in hierarchical setting. we extend the sampler to include composition - decomposition of syntactic fragments in order to cluster fragments of variables size, as', '']",5
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', 'a example question is shown in figure 3']",[' #TAUTHOR_TAG'],5
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', 'a example question is shown in figure 3']",[' #TAUTHOR_TAG'],5
"['both of these constraints. third, as in  #TAUTHOR_TAG,']","['both of these constraints. third, as in  #TAUTHOR_TAG,']","['both of these constraints. third, as in  #TAUTHOR_TAG,']","['', 'only if they are connected by an arc in the dependency tree. this is a slight simplification of the semantic role labeling problem but one often made. thus, the argument identification and', 'labeling stages consist of labeling each syntactic arc with a semantic role label. in comparison, the mln model does not explicitly assume contiguity', 'of lexical items and does not make this directionality assumption but their clustering algorithm uses initialization and clusterization moves such that', 'the resulting model also obeys both of these constraints. third, as in  #TAUTHOR_TAG, we do not model polysemy as we assume that each syntactic fragment corresponds to a single semantic class. this is not a model assumption and is only used at inference as it reduces mixing time of the markov chain. it is not likely', 'to be restrictive for the biomedical domain studied', 'in our experiments. as in some of the recent work on learning semantic representations  #TAUTHOR_TAG, we assume that dependency structures are provided for every sentence. this assumption allows us to construct models of semantics not markovian within a sequence of words ( see for an example a model described', 'in  #AUTHOR_TAG ), but rather markovian within a dependency tree. though we include generation of the syntactic structure in our model, we would not expect that this syntactic component would result in an', 'accurate syntactic model, even if trained in a supervised way, as the chosen independence assumptions are oversimplistic. in this way, we can use a simple generative story and build on top of the recent success in syntactic parsing']",3
"['both of these constraints. third, as in  #TAUTHOR_TAG,']","['both of these constraints. third, as in  #TAUTHOR_TAG,']","['both of these constraints. third, as in  #TAUTHOR_TAG,']","['', 'only if they are connected by an arc in the dependency tree. this is a slight simplification of the semantic role labeling problem but one often made. thus, the argument identification and', 'labeling stages consist of labeling each syntactic arc with a semantic role label. in comparison, the mln model does not explicitly assume contiguity', 'of lexical items and does not make this directionality assumption but their clustering algorithm uses initialization and clusterization moves such that', 'the resulting model also obeys both of these constraints. third, as in  #TAUTHOR_TAG, we do not model polysemy as we assume that each syntactic fragment corresponds to a single semantic class. this is not a model assumption and is only used at inference as it reduces mixing time of the markov chain. it is not likely', 'to be restrictive for the biomedical domain studied', 'in our experiments. as in some of the recent work on learning semantic representations  #TAUTHOR_TAG, we assume that dependency structures are provided for every sentence. this assumption allows us to construct models of semantics not markovian within a sequence of words ( see for an example a model described', 'in  #AUTHOR_TAG ), but rather markovian within a dependency tree. though we include generation of the syntactic structure in our model, we would not expect that this syntactic component would result in an', 'accurate syntactic model, even if trained in a supervised way, as the chosen independence assumptions are oversimplistic. in this way, we can use a simple generative story and build on top of the recent success in syntactic parsing']",3
['work of  #TAUTHOR_TAG models joint probability of'],['work of  #TAUTHOR_TAG models joint probability of'],['work of  #TAUTHOR_TAG models joint probability of'],"['work of  #TAUTHOR_TAG models joint probability of the dependency tree and its latent semantic representation using markov logic networks ( mlns )  #AUTHOR_TAG, selecting parameters ( weights of first - order clauses ) to maximize the probability of the observed dependency structures.', 'for each sentence, the mln induces a markov network, an undirected graphical model with nodes corresponding to ground atoms and cliques corresponding to ground clauses.', 'the mln is a powerful formalism and allows for modeling complex interaction between features of the input ( syntactic trees ) and latent output ( semantic representation ), however, unsupervised learning of semantics with general mlns can be prohibitively expensive.', 'the reason for this is that mlns are undirected models and when learned to maximize likelihood of syntactically annotated sentences, they would require marginalization over semantic representation but also over the entire space of syntactic structures and lexical units.', 'given the complexity of the semantic parsing task and the need to tackle large datasets, even approximate methods are likely to be infeasible.', 'in order to overcome this problem,  #TAUTHOR_TAG group parameters and impose local normalization constraints within each group.', 'given these normalization constraints, and additional structural constraints satisfied by the model, namely that the clauses should be engineered in such a way that they induce treestructured graphs for every sentence, the parameters can be estimated by a variant of the em algorithm.', 'the class of such restricted mlns is equivalent to the class of directed graphical models over the same set of random variables corresponding to fragments of syntactic and semantic structure.', 'given that the above constraints do not directly fit into the mln methodology, we believe that it is more natural to regard their model as a directed model with an underlying generative story specifying how the semantic structure is generated and how the syntactic parse is drawn for this semantic structure.', 'this view would facilitate understanding what kind of features can easily be integrated into the model, simplify application of non - parametric bayesian techniques and expedite the use of inference techniques designed specifically for directed models.', 'our approach makes one step in this direction by proposing a non - parametric version of such generative model']",1
['work of  #TAUTHOR_TAG models joint probability of'],['work of  #TAUTHOR_TAG models joint probability of'],['work of  #TAUTHOR_TAG models joint probability of'],"['work of  #TAUTHOR_TAG models joint probability of the dependency tree and its latent semantic representation using markov logic networks ( mlns )  #AUTHOR_TAG, selecting parameters ( weights of first - order clauses ) to maximize the probability of the observed dependency structures.', 'for each sentence, the mln induces a markov network, an undirected graphical model with nodes corresponding to ground atoms and cliques corresponding to ground clauses.', 'the mln is a powerful formalism and allows for modeling complex interaction between features of the input ( syntactic trees ) and latent output ( semantic representation ), however, unsupervised learning of semantics with general mlns can be prohibitively expensive.', 'the reason for this is that mlns are undirected models and when learned to maximize likelihood of syntactically annotated sentences, they would require marginalization over semantic representation but also over the entire space of syntactic structures and lexical units.', 'given the complexity of the semantic parsing task and the need to tackle large datasets, even approximate methods are likely to be infeasible.', 'in order to overcome this problem,  #TAUTHOR_TAG group parameters and impose local normalization constraints within each group.', 'given these normalization constraints, and additional structural constraints satisfied by the model, namely that the clauses should be engineered in such a way that they induce treestructured graphs for every sentence, the parameters can be estimated by a variant of the em algorithm.', 'the class of such restricted mlns is equivalent to the class of directed graphical models over the same set of random variables corresponding to fragments of syntactic and semantic structure.', 'given that the above constraints do not directly fit into the mln methodology, we believe that it is more natural to regard their model as a directed model with an underlying generative story specifying how the semantic structure is generated and how the syntactic parse is drawn for this semantic structure.', 'this view would facilitate understanding what kind of features can easily be integrated into the model, simplify application of non - parametric bayesian techniques and expedite the use of inference techniques designed specifically for directed models.', 'our approach makes one step in this direction by proposing a non - parametric version of such generative model']",1
"['upon the mcb model in  #TAUTHOR_TAG, which']","['upon the mcb model in  #TAUTHOR_TAG, which']","['upon the mcb model in  #TAUTHOR_TAG, which']",[' #TAUTHOR_TAG'],0
"['upon the mcb model in  #TAUTHOR_TAG, which']","['upon the mcb model in  #TAUTHOR_TAG, which']","['upon the mcb model in  #TAUTHOR_TAG, which']",[' #TAUTHOR_TAG'],0
"['1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of']","['product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of']","['##rd product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of the fusion module remains an on - going research topic.', 'in general,']","['attention module : images are passed through an embedding layer consisting of a pre - trained convnet model, such as resnet pretrained with the imagenet dataset [ 10 ].', 'this generates image features i f ∈ r c×h×w, where c, h and w are depth, height and width of the extracted feature maps.', 'fusion module i is then used to generate a set of image attention coefficients.', 'first, question features q w are tiled as the same spatial shape of i f.', 'afterwards, the fusion module models the joint relationship j attn ∈ r o×h×w between questions and images, mapping them to a common space of dimension o. in the simplest case, one can implement the fusion module using either concatenation or hadamard product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of the fusion module remains an on - going research topic.', 'in general, it should both effectively capture the latent relationship between multi - modal features meanwhile be easy to optimize.', '']",0
"['upon the mcb model in  #TAUTHOR_TAG, which']","['upon the mcb model in  #TAUTHOR_TAG, which']","['upon the mcb model in  #TAUTHOR_TAG, which']",[' #TAUTHOR_TAG'],4
['##d implementation of mcb  #TAUTHOR_TAG and mfb [ 25 ]'],['build the attention supervision on top of the opensourced implementation of mcb  #TAUTHOR_TAG and mfb [ 25 ]'],"['build the attention supervision on top of the opensourced implementation of mcb  #TAUTHOR_TAG and mfb [ 25 ].', 'similar to them, we extract the image feature from']","['build the attention supervision on top of the opensourced implementation of mcb  #TAUTHOR_TAG and mfb [ 25 ].', 'similar to them, we extract the image feature from res5c layer of resnet - 152, resulting in 14 × 14 spatial grid ( h = 14, w = 14, c = 2048 ).', 'we construct our ground - truth visual grounding labels to be g v = 2 glimpse maps per qa pair, where the first map is object - level grounding and the second map is region - level grounding, as discussed in section 4. let ( x i min, y i min, x i max, y i max ) be the coordinate of i th selected object bounding box in the grounding labels, then the mined object - level attention maps c 0 gt are :', 'where i [ · ] is the indicator function.', '']",4
"['upon the mcb model in  #TAUTHOR_TAG, which']","['upon the mcb model in  #TAUTHOR_TAG, which']","['upon the mcb model in  #TAUTHOR_TAG, which']",[' #TAUTHOR_TAG'],6
"['on the model presented in  #TAUTHOR_TAG.', 'main innovation is']","['on the model presented in  #TAUTHOR_TAG.', 'main innovation is']","['on the model presented in  #TAUTHOR_TAG.', 'main innovation is the attention supervision module']","['a main novelty of the vqa model, we add an image attention supervision module as an auxiliary classification task, where ground - truth visual grounding labels c gt ∈ r h×w ×g v are used to guide the model to focus on meaningful parts of the image to answer each question.', 'to do that, we simply treat the generated attention coefficients c v as a probability distribution, and then compare it with the ground - truth using kl - divergence.', 'interestingly, we introduce two attention maps, corresponding to relevant region - level and objectlevel groundings, as shown in figure 3.', 'sections 4 and 5 provide details about our proposed method to obtain the attention labels and to train the resulting model, respectively.', 'j a n s figure 2.', 'schematic diagram of the main parts of the vqa model.', 'it is mostly based on the model presented in  #TAUTHOR_TAG.', 'main innovation is the attention supervision module that incorporates visual grounding as an auxiliary task.', 'this module is trained through the use of a set of image attention labels that are automatically mined from the visual genome dataset']",6
['##d implementation of mcb  #TAUTHOR_TAG and mfb [ 25 ]'],['build the attention supervision on top of the opensourced implementation of mcb  #TAUTHOR_TAG and mfb [ 25 ]'],"['build the attention supervision on top of the opensourced implementation of mcb  #TAUTHOR_TAG and mfb [ 25 ].', 'similar to them, we extract the image feature from']","['build the attention supervision on top of the opensourced implementation of mcb  #TAUTHOR_TAG and mfb [ 25 ].', 'similar to them, we extract the image feature from res5c layer of resnet - 152, resulting in 14 × 14 spatial grid ( h = 14, w = 14, c = 2048 ).', 'we construct our ground - truth visual grounding labels to be g v = 2 glimpse maps per qa pair, where the first map is object - level grounding and the second map is region - level grounding, as discussed in section 4. let ( x i min, y i min, x i max, y i max ) be the coordinate of i th selected object bounding box in the grounding labels, then the mined object - level attention maps c 0 gt are :', 'where i [ · ] is the indicator function.', '']",6
"['1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of']","['product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of']","['##rd product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of the fusion module remains an on - going research topic.', 'in general,']","['attention module : images are passed through an embedding layer consisting of a pre - trained convnet model, such as resnet pretrained with the imagenet dataset [ 10 ].', 'this generates image features i f ∈ r c×h×w, where c, h and w are depth, height and width of the extracted feature maps.', 'fusion module i is then used to generate a set of image attention coefficients.', 'first, question features q w are tiled as the same spatial shape of i f.', 'afterwards, the fusion module models the joint relationship j attn ∈ r o×h×w between questions and images, mapping them to a common space of dimension o. in the simplest case, one can implement the fusion module using either concatenation or hadamard product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of the fusion module remains an on - going research topic.', 'in general, it should both effectively capture the latent relationship between multi - modal features meanwhile be easy to optimize.', '']",3
"['of 17 qa pairs per image.', 'we follow the processing scheme from  #TAUTHOR_TAG, where non - informative words in the questions']","['of 17 qa pairs per image.', 'we follow the processing scheme from  #TAUTHOR_TAG, where non - informative words in the questions']","['##7 images, with an average of 17 qa pairs per image.', 'we follow the processing scheme from  #TAUTHOR_TAG, where non - informative words in the questions']","['', 'the task is to predict a correct answer a given a corresponding image - question pair ( i, q ).', 'as a main advantage with respect to version 1. 0 [ 9 ], for every question vqa - 2. 0 includes complementary images that lead to different answers, reducing language bias by forcing the model to use the visual information.', 'visual genome : the visual genome ( vg ) dataset [ 12 ] contains 108077 images, with an average of 17 qa pairs per image.', 'we follow the processing scheme from  #TAUTHOR_TAG, where non - informative words in the questions and answers such as "" a "" and "" is "" are removed.', 'afterwards, ( i, q, a ) triplets with answers to be single keyword and overlapped with vqa - 2. 0 dataset are included in our training set.', 'this adds 97697 images and about 1 million questions to the training set.', '']",3
['342 - mcb  #TAUTHOR_TAG 0 authors also collect 137'],['human [ 5 ] 0. 623 - 80. 62 pj - x [ 17 ] 0. 396 0. 342 - mcb  #TAUTHOR_TAG 0 authors also collect 1374'],['[ 5 ] 0. 623 - 80. 62 pj - x [ 17 ] 0. 396 0. 342 - mcb  #TAUTHOR_TAG 0 authors also collect 137'],"['/ % vqa - hat vqa - x vqa - 2. 0 human [ 5 ] 0. 623 - 80. 62 pj - x [ 17 ] 0. 396 0. 342 - mcb  #TAUTHOR_TAG 0 authors also collect 1374 × 3 = 4122 hat maps for vqa - 1. 0 validation sets, where each of the 1374 ( i, q, a ) were labeled by three different annotators, so one can compare the level of agreement among labels.', 'we use vqa - hat to evaluate visual grounding performance, by comparing the rank - correlation between human attention and model attention, as in [ 5, 17 ].', 'vqa - x : vqa - x dataset [ 17 ] contains 2000 labeled attention maps in vqa - 2. 0 validation sets.', 'in contrast to vqa - hat, vqa - x attention maps are in the form of instance segmentations, where annotators were asked to segment objects and / or regions that most prominently justify the answer.', 'hence the attentions are more specific and localized.', 'we use vqa - x to evaluate visual grounding performance by comparing the rank - correlation, as in [ 5, 17 ]']",3
"['1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of']","['product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of']","['##rd product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of the fusion module remains an on - going research topic.', 'in general,']","['attention module : images are passed through an embedding layer consisting of a pre - trained convnet model, such as resnet pretrained with the imagenet dataset [ 10 ].', 'this generates image features i f ∈ r c×h×w, where c, h and w are depth, height and width of the extracted feature maps.', 'fusion module i is then used to generate a set of image attention coefficients.', 'first, question features q w are tiled as the same spatial shape of i f.', 'afterwards, the fusion module models the joint relationship j attn ∈ r o×h×w between questions and images, mapping them to a common space of dimension o. in the simplest case, one can implement the fusion module using either concatenation or hadamard product [ 1 ], but more effective pooling schemes can be applied  #TAUTHOR_TAG 11, 25, 26 ].', 'the design choice of the fusion module remains an on - going research topic.', 'in general, it should both effectively capture the latent relationship between multi - modal features meanwhile be easy to optimize.', '']",5
"['of 17 qa pairs per image.', 'we follow the processing scheme from  #TAUTHOR_TAG, where non - informative words in the questions']","['of 17 qa pairs per image.', 'we follow the processing scheme from  #TAUTHOR_TAG, where non - informative words in the questions']","['##7 images, with an average of 17 qa pairs per image.', 'we follow the processing scheme from  #TAUTHOR_TAG, where non - informative words in the questions']","['', 'the task is to predict a correct answer a given a corresponding image - question pair ( i, q ).', 'as a main advantage with respect to version 1. 0 [ 9 ], for every question vqa - 2. 0 includes complementary images that lead to different answers, reducing language bias by forcing the model to use the visual information.', 'visual genome : the visual genome ( vg ) dataset [ 12 ] contains 108077 images, with an average of 17 qa pairs per image.', 'we follow the processing scheme from  #TAUTHOR_TAG, where non - informative words in the questions and answers such as "" a "" and "" is "" are removed.', 'afterwards, ( i, q, a ) triplets with answers to be single keyword and overlapped with vqa - 2. 0 dataset are included in our training set.', 'this adds 97697 images and about 1 million questions to the training set.', '']",5
['a single model handles translations for multiple languages  #TAUTHOR_TAG'],['a single model handles translations for multiple languages  #TAUTHOR_TAG'],"['mnmt systems will be compact, because a single model handles translations for multiple languages  #TAUTHOR_TAG']","['mnmt systems will be compact, because a single model handles translations for multiple languages  #TAUTHOR_TAG. this can reduce the deployment footprint', ', which is crucial for con - there are multiple mnmt scenarios based on available resources and studies have been conducted for the following scenarios (', 'figure 1 1 ) : multiway translation. the goal is constructing a single nmt system for one - to - many  #AUTHOR_TAG, many', '- to - one  #AUTHOR_TAG or many - tomany  #AUTHOR_TAG a ) translation using parallel corpora for more than one language pair. low or zero - resource translation. for most', 'of the language pairs in the world, there are small or no parallel corpora,', 'and three main directions have been studied for this scenario. transfer learning : transferring translation knowledge from a high - resource language pair to improve the translation of a low - resource language pair', '. pivot translation : using a high - resource language ( usually english ) as a pivot', 'to translate between a language pair  #AUTHOR_TAG a ). zeroshot translation : translating between language pairs without parallel corpora  #TAUTHOR_TAG. multi - source translation.', '']",0
['a single model handles translations for multiple languages  #TAUTHOR_TAG'],['a single model handles translations for multiple languages  #TAUTHOR_TAG'],"['mnmt systems will be compact, because a single model handles translations for multiple languages  #TAUTHOR_TAG']","['mnmt systems will be compact, because a single model handles translations for multiple languages  #TAUTHOR_TAG. this can reduce the deployment footprint', ', which is crucial for con - there are multiple mnmt scenarios based on available resources and studies have been conducted for the following scenarios (', 'figure 1 1 ) : multiway translation. the goal is constructing a single nmt system for one - to - many  #AUTHOR_TAG, many', '- to - one  #AUTHOR_TAG or many - tomany  #AUTHOR_TAG a ) translation using parallel corpora for more than one language pair. low or zero - resource translation. for most', 'of the language pairs in the world, there are small or no parallel corpora,', 'and three main directions have been studied for this scenario. transfer learning : transferring translation knowledge from a high - resource language pair to improve the translation of a low - resource language pair', '. pivot translation : using a high - resource language ( usually english ) as a pivot', 'to translate between a language pair  #AUTHOR_TAG a ). zeroshot translation : translating between language pairs without parallel corpora  #TAUTHOR_TAG. multi - source translation.', '']",0
['a single model handles translations for multiple languages  #TAUTHOR_TAG'],['a single model handles translations for multiple languages  #TAUTHOR_TAG'],"['mnmt systems will be compact, because a single model handles translations for multiple languages  #TAUTHOR_TAG']","['mnmt systems will be compact, because a single model handles translations for multiple languages  #TAUTHOR_TAG. this can reduce the deployment footprint', ', which is crucial for con - there are multiple mnmt scenarios based on available resources and studies have been conducted for the following scenarios (', 'figure 1 1 ) : multiway translation. the goal is constructing a single nmt system for one - to - many  #AUTHOR_TAG, many', '- to - one  #AUTHOR_TAG or many - tomany  #AUTHOR_TAG a ) translation using parallel corpora for more than one language pair. low or zero - resource translation. for most', 'of the language pairs in the world, there are small or no parallel corpora,', 'and three main directions have been studied for this scenario. transfer learning : transferring translation knowledge from a high - resource language pair to improve the translation of a low - resource language pair', '. pivot translation : using a high - resource language ( usually english ) as a pivot', 'to translate between a language pair  #AUTHOR_TAG a ). zeroshot translation : translating between language pairs without parallel corpora  #TAUTHOR_TAG. multi - source translation.', '']",0
"['the language embedding size )  #TAUTHOR_TAG, but the language embeddings']","['the language embedding size )  #TAUTHOR_TAG, but the language embeddings']","['the language embedding size )  #TAUTHOR_TAG, but the language embeddings']","['between the extremities of parameter sharing exemplified by the above mentioned models, lies an array of choices.', 'the degree of parameter sharing depends on the divergence between the languages involved and can be controlled at various layers of the mnmt system.', 'sharing encoders among multiple languages is very effective and is widely used  #AUTHOR_TAG.', ' #AUTHOR_TAG explored target language, source language and pair specific attention parameters.', 'they showed that target language specific attention performs better than other attention sharing configurations.', 'for self - attention based nmt models, explored various parameter sharing strategies.', 'they showed that sharing the decoder self - attention and encoder - decoder inter - attention parameters is useful for linguistically dissimilar languages.', ' #AUTHOR_TAG further proposed a routing network to dynamically control parameter sharing learned from the data.', 'designing the right sharing strategy is important to maintaining a balance between model compactness and translation accuracy.', 'dynamic parameter or representation generation.', 'instead of defining the parameter sharing protocol a priori,  #AUTHOR_TAG learned the degree of parameter sharing from the data.', 'this is achieved by defining the language specific model parameters as a function of global parameters and language embeddings.', 'this approach also reduces the number of language specific parameters ( only language embeddings ), while still allowing each language to have its own unique parameters for different network layers.', 'in fact, the number of parameters is only a small multiple of the compact model ( the multiplication factor accounts for the language embedding size )  #TAUTHOR_TAG, but the language embeddings can directly impact the model parameters instead of the weak influence that language tags have.', 'universal encoder representation.', 'ideally, multiway systems should generate encoder representations that are language agnostic.', 'however, the attention mechanism sees a variable number of encoder representations depending on the sentence length ( this could vary for translations of the same sentence ).', 'to overcome this, an attention bridge network generates a fixed number of contextual representations that are input to the attention network  #AUTHOR_TAG vazquez et al., 2018 ).', ' #AUTHOR_TAG pointed out that the contextualized embeddings are word order dependent, hence not language agnostic.', 'multiple target languages.', 'this is a challenging scenario because parameter sharing has to be balanced with the capability to generate sentences in each target language.', ' #AUTHOR_TAG added the language tag to the beginning as well as end of sequence to avoid its attenuation in a leftto - right encoder.', 'explored multiple methods for supporting target languages : ( a ) target language tag at beginning of the decoder, ( b ) target language dependent positional embeddings, and ( c ) divide hidden units of each decoder layer into shared and language - dependent ones.', 'each of these methods provide gains over  #TAUTHOR_TAG, and combining all gave the best results']",0
"['the language embedding size )  #TAUTHOR_TAG, but the language embeddings']","['the language embedding size )  #TAUTHOR_TAG, but the language embeddings']","['the language embedding size )  #TAUTHOR_TAG, but the language embeddings']","['between the extremities of parameter sharing exemplified by the above mentioned models, lies an array of choices.', 'the degree of parameter sharing depends on the divergence between the languages involved and can be controlled at various layers of the mnmt system.', 'sharing encoders among multiple languages is very effective and is widely used  #AUTHOR_TAG.', ' #AUTHOR_TAG explored target language, source language and pair specific attention parameters.', 'they showed that target language specific attention performs better than other attention sharing configurations.', 'for self - attention based nmt models, explored various parameter sharing strategies.', 'they showed that sharing the decoder self - attention and encoder - decoder inter - attention parameters is useful for linguistically dissimilar languages.', ' #AUTHOR_TAG further proposed a routing network to dynamically control parameter sharing learned from the data.', 'designing the right sharing strategy is important to maintaining a balance between model compactness and translation accuracy.', 'dynamic parameter or representation generation.', 'instead of defining the parameter sharing protocol a priori,  #AUTHOR_TAG learned the degree of parameter sharing from the data.', 'this is achieved by defining the language specific model parameters as a function of global parameters and language embeddings.', 'this approach also reduces the number of language specific parameters ( only language embeddings ), while still allowing each language to have its own unique parameters for different network layers.', 'in fact, the number of parameters is only a small multiple of the compact model ( the multiplication factor accounts for the language embedding size )  #TAUTHOR_TAG, but the language embeddings can directly impact the model parameters instead of the weak influence that language tags have.', 'universal encoder representation.', 'ideally, multiway systems should generate encoder representations that are language agnostic.', 'however, the attention mechanism sees a variable number of encoder representations depending on the sentence length ( this could vary for translations of the same sentence ).', 'to overcome this, an attention bridge network generates a fixed number of contextual representations that are input to the attention network  #AUTHOR_TAG vazquez et al., 2018 ).', ' #AUTHOR_TAG pointed out that the contextualized embeddings are word order dependent, hence not language agnostic.', 'multiple target languages.', 'this is a challenging scenario because parameter sharing has to be balanced with the capability to generate sentences in each target language.', ' #AUTHOR_TAG added the language tag to the beginning as well as end of sequence to avoid its attenuation in a leftto - right encoder.', 'explored multiple methods for supporting target languages : ( a ) target language tag at beginning of the decoder, ( b ) target language dependent positional embeddings, and ( c ) divide hidden units of each decoder layer into shared and language - dependent ones.', 'each of these methods provide gains over  #TAUTHOR_TAG, and combining all gave the best results']",0
['language pairs  #TAUTHOR_TAG or'],['language pairs  #TAUTHOR_TAG or'],"['', 'all the available languages pairs are trained jointly to minimize the mean negative log - likelihood for each language pair.', 'as some language pairs would have more data than other languages, the model may be biased.', 'to avoid this, sentence pairs from different language pairs are sampled to maintain a healthy balance.', 'mini - batches can be comprised of a mix of samples from different language pairs  #TAUTHOR_TAG or the training schedule']","['', 'all the available languages pairs are trained jointly to minimize the mean negative log - likelihood for each language pair.', 'as some language pairs would have more data than other languages, the model may be biased.', 'to avoid this, sentence pairs from different language pairs are sampled to maintain a healthy balance.', 'mini - batches can be comprised of a mix of samples from different language pairs  #TAUTHOR_TAG or the training schedule can cycle through mini - batches consisting of a language pair only  #AUTHOR_TAG a ).', 'for architectures with language specific layers, the latter approach is convenient to implement.', 'knowledge distillation.', 'in this approach suggested by  #AUTHOR_TAG, bilingual models are first trained for all language pairs involved.', 'these bilingual models are used as teacher models to train a single student model for all language pairs.', 'the student model is trained using a linear interpolation of the standard likelihood loss as well as distillation loss that captures the distance between the output distributions of the student and teacher models.', 'the distillation loss is applied for a language pair only if the teacher model shows better translation accuracy than the student model on the validation set.', 'this approach shows better results than joint training of a black - box model, but training time increases significantly because bilingual models also have to be trained']",0
"['was first demonstrated by  #TAUTHOR_TAG.', 'however, this']","['generating pseudo - parallel corpora.', 'this scenario is known as zero - shot nmt.', 'zero - shot nmt also requires a pivot language but it is only used during training without the need to generate pseudoparallel corpora.', 'training.', 'zero - shot nmt was first demonstrated by  #TAUTHOR_TAG.', 'however, this zero - shot translation method is inferior to pivoting.', 'they showed']","['- shot nmt also requires a pivot language but it is only used during training without the need to generate pseudoparallel corpora.', 'training.', 'zero - shot nmt was first demonstrated by  #TAUTHOR_TAG.', 'however, this zero - shot translation method is inferior to pivoting']","['approaches proposed so far involve pivoting or synthetic corpus generation, which is a slow process due to its two - step nature.', 'it is more interesting, and challenging, to enable translation between a zero - resource pair without explicitly involving a pivot language during decoding or for generating pseudo - parallel corpora.', 'this scenario is known as zero - shot nmt.', 'zero - shot nmt also requires a pivot language but it is only used during training without the need to generate pseudoparallel corpora.', 'training.', 'zero - shot nmt was first demonstrated by  #TAUTHOR_TAG.', 'however, this zero - shot translation method is inferior to pivoting.', 'they showed that the context vectors ( from attention ) for unseen language pairs differ from the seen language pairs, possibly explaining the degradation in translation quality.', ' #AUTHOR_TAG tried to overcome this limitation by augmenting the training data with the pseudo - parallel unseen pairs generated by iterative application of the same zeroshot translation.', ' #AUTHOR_TAG included explicit language invariance losses in the optimization function to encourage parallel sentences to have the same representation.', 'reinforcement learning for zero - shot learning was explored by  #AUTHOR_TAG where the dual learning framework was combined with rewards from language models.', 'corpus size.', 'work on translation for indian languages showed that zero - shot works well only when the training corpora are extremely large  #AUTHOR_TAG.', 'as the corpora for most indian languages contain fewer than 100k sentences, the zero - shot approach is rather infeasible despite linguistic similarity.', ' #AUTHOR_TAG confirmed this in the case of european languages where small training corpora were used.', ' #AUTHOR_TAG also showed that zero - shot translation works well only when the training corpora are large, while  #AUTHOR_TAG show that massively multilingual models are beneficial for zeroshot translation.', 'language control.', 'zero - shot nmt tends to translate into the wrong language at times and  #AUTHOR_TAG proposed to filter the output of the softmax so as to force the model to translate into the desired language']",0
"['. as there are always vocabulary overlaps between different domains,', 'there are no', 'zero - shot translation  #TAUTHOR_TAG settings in']","['domain adaptation for nmt. while pivoting is a popular approach for mn', '##mt  #AUTHOR_TAG, it is unsuitable for domain adaptation. as there are always vocabulary overlaps between different domains,', 'there are no', 'zero - shot translation  #TAUTHOR_TAG settings in']","['. as there are always vocabulary overlaps between different domains,', 'there are no', 'zero - shot translation  #TAUTHOR_TAG settings in']","['', 'in - domain monolingual corpora  #AUTHOR_TAG a ), which is similar to the pseduo - parallel corpus generation in mnmt', ' #AUTHOR_TAG b ). there are also many differences between mnmt and domain adaptation for nmt. while pivoting is a popular approach for mn', '##mt  #AUTHOR_TAG, it is unsuitable for domain adaptation. as there are always vocabulary overlaps between different domains,', 'there are no', 'zero - shot translation  #TAUTHOR_TAG settings in domain adaptation. in addition, it not uncommon to write domain specific sentences in different styles and so multi - source approaches are not applicable', 'either. on the other hand, data selection approaches', 'in domain adaptation that select out - of - domain sentences which are similar to in - domain sentences ( 2017a', ') have not been applied to mnmt. in addition, instance weighting approaches  #AUTHOR_TAG b ) that interpolate in - domain and out - of - domain', 'models have not been studied for mnmt. however, with the development of cross - lingual sentence embeddings, data selection and instance weighting', 'approaches might be applicable for mnmt in the near future']",0
"['remains an open problem  #TAUTHOR_TAG.', 'multilingual and multi - domain nmt.', 'jointly tackling multilingual and multi - domain translation is an interesting']","['remains an open problem  #TAUTHOR_TAG.', 'multilingual and multi - domain nmt.', 'jointly tackling multilingual and multi - domain translation is an interesting']","['', 'the compact mnmt models can handle code - mixed input, but code - mixed output remains an open problem  #TAUTHOR_TAG.', 'multilingual and multi - domain nmt.', 'jointly tackling multilingual and multi - domain translation is an interesting direction with many practical use cases.', 'when extending an nmt system to a new language, the parallel corpus in the domain of interest may not be available']","['', 'multiway systems for multiple low - resource target languages need more attention.', 'the right balance between sharing representations vs. maintaining the distinctiveness of the target language for generation needs exploring.', 'explore pre - training models.', 'pre - training embeddings, encoders and decoders have been shown to be useful for nmt  #AUTHOR_TAG.', 'how pre - training can be incorporated into different mnmt architectures, is an important as well.', 'recent advances in cross - lingual word  #AUTHOR_TAG a ;  #AUTHOR_TAG and sentence embeddings  #AUTHOR_TAG b ;  #AUTHOR_TAG a ;  #AUTHOR_TAG could provide directions for this line of investigation.', 'related languages, language registers and dialects.', 'translation involving related languages, language registers and dialects can be further explored given the importance of this use case.', 'code - mixed language.', 'addressing intrasentence multilingualism i. e. code mixed input and output, creoles and pidgins is an interesting research direction.', 'the compact mnmt models can handle code - mixed input, but code - mixed output remains an open problem  #TAUTHOR_TAG.', 'multilingual and multi - domain nmt.', 'jointly tackling multilingual and multi - domain translation is an interesting direction with many practical use cases.', 'when extending an nmt system to a new language, the parallel corpus in the domain of interest may not be available.', 'transfer learning in this case has to span languages and domains']",2
"['forward by  #TAUTHOR_TAG.', 'the main']","['forward by  #TAUTHOR_TAG.', 'the main']","['it contains two other noun phrases.', 'two basenp data sets have been put forward by  #TAUTHOR_TAG.', 'the main data set consist of four sections']","['phrase recognition can be divided in two tasks : recognizing base noun phrases and recognizing arbitrary noun phrases.', 'base noun phrases ( basenps ) are noun phrases which do not contain another noun phrase.', 'for example, the sentence in [ early trading ] in [ hong kong ] [ monday ], [ gold ] was quoted at [ $ 366. 50 ] [ an ounce ].', 'contains six basenps ( marked as phrases between square brackets ).', 'the phrase $ 366. 50 an ounce is a noun phrase as well.', 'however, it is not a basenp since it contains two other noun phrases.', 'two basenp data sets have been put forward by  #TAUTHOR_TAG.', 'the main data set consist of four sections ( 15 - 18 ) of the wall street journal ( wsj ) part of the penn treebank  #AUTHOR_TAG as training material and one section ( 20 ) as test material 1.', 'the basenps in this data are slightly different from the ones that can be derived from the treebank, most notably in the attachment of genitive markers.', 'the recognition task involving arbitrary noun phrases attempts to find both basenps and noun phrases that contain other noun phrases.', 'a standard data set for this task was put forward at the conll - 99 workshop.', '']",0
"['forward by  #TAUTHOR_TAG.', 'the main']","['forward by  #TAUTHOR_TAG.', 'the main']","['it contains two other noun phrases.', 'two basenp data sets have been put forward by  #TAUTHOR_TAG.', 'the main data set consist of four sections']","['phrase recognition can be divided in two tasks : recognizing base noun phrases and recognizing arbitrary noun phrases.', 'base noun phrases ( basenps ) are noun phrases which do not contain another noun phrase.', 'for example, the sentence in [ early trading ] in [ hong kong ] [ monday ], [ gold ] was quoted at [ $ 366. 50 ] [ an ounce ].', 'contains six basenps ( marked as phrases between square brackets ).', 'the phrase $ 366. 50 an ounce is a noun phrase as well.', 'however, it is not a basenp since it contains two other noun phrases.', 'two basenp data sets have been put forward by  #TAUTHOR_TAG.', 'the main data set consist of four sections ( 15 - 18 ) of the wall street journal ( wsj ) part of the penn treebank  #AUTHOR_TAG as training material and one section ( 20 ) as test material 1.', 'the basenps in this data are slightly different from the ones that can be derived from the treebank, most notably in the attachment of genitive markers.', 'the recognition task involving arbitrary noun phrases attempts to find both basenps and noun phrases that contain other noun phrases.', 'a standard data set for this task was put forward at the conll - 99 workshop.', '']",0
"['forward by  #TAUTHOR_TAG.', 'the main']","['forward by  #TAUTHOR_TAG.', 'the main']","['it contains two other noun phrases.', 'two basenp data sets have been put forward by  #TAUTHOR_TAG.', 'the main data set consist of four sections']","['phrase recognition can be divided in two tasks : recognizing base noun phrases and recognizing arbitrary noun phrases.', 'base noun phrases ( basenps ) are noun phrases which do not contain another noun phrase.', 'for example, the sentence in [ early trading ] in [ hong kong ] [ monday ], [ gold ] was quoted at [ $ 366. 50 ] [ an ounce ].', 'contains six basenps ( marked as phrases between square brackets ).', 'the phrase $ 366. 50 an ounce is a noun phrase as well.', 'however, it is not a basenp since it contains two other noun phrases.', 'two basenp data sets have been put forward by  #TAUTHOR_TAG.', 'the main data set consist of four sections ( 15 - 18 ) of the wall street journal ( wsj ) part of the penn treebank  #AUTHOR_TAG as training material and one section ( 20 ) as test material 1.', 'the basenps in this data are slightly different from the ones that can be derived from the treebank, most notably in the attachment of genitive markers.', 'the recognition task involving arbitrary noun phrases attempts to find both basenps and noun phrases that contain other noun phrases.', 'a standard data set for this task was put forward at the conll - 99 workshop.', '']",0
"['construction method.', 'an alternative representation for basenps has been put forward by  #TAUTHOR_TAG.', 'they have defined base']","['regarding only the shortest phrases between open and close brackets as basenps  #AUTHOR_TAG.', 'we have used the bracket representation ( o + c ) in combination with the second basenp construction method.', 'an alternative representation for basenps has been put forward by  #TAUTHOR_TAG.', 'they have defined basenp recognition as a tagging task : words can be']","['+ c ) in combination with the second basenp construction method.', 'an alternative representation for basenps has been put forward by  #TAUTHOR_TAG.', 'they have defined basenp recognition as a tagging task : words can be']","['our example sentence in section 2. 1, noun phrases are represented by bracket structures.', 'both  #AUTHOR_TAG and  #AUTHOR_TAG have shown how classifiers can process bracket structures.', 'one classifier can be trained to recognize open brackets ( o ) while another will process close brackets ( c ).', 'their results can be converted to basenps by making pairs of open and close brackets with large probability scores  #AUTHOR_TAG or by regarding only the shortest phrases between open and close brackets as basenps  #AUTHOR_TAG.', 'we have used the bracket representation ( o + c ) in combination with the second basenp construction method.', 'an alternative representation for basenps has been put forward by  #TAUTHOR_TAG.', 'they have defined basenp recognition as a tagging task : words can be inside a basenp ( 1 ) or outside of basenps ( o ).', '']",0
"['construction method.', 'an alternative representation for basenps has been put forward by  #TAUTHOR_TAG.', 'they have defined base']","['regarding only the shortest phrases between open and close brackets as basenps  #AUTHOR_TAG.', 'we have used the bracket representation ( o + c ) in combination with the second basenp construction method.', 'an alternative representation for basenps has been put forward by  #TAUTHOR_TAG.', 'they have defined basenp recognition as a tagging task : words can be']","['+ c ) in combination with the second basenp construction method.', 'an alternative representation for basenps has been put forward by  #TAUTHOR_TAG.', 'they have defined basenp recognition as a tagging task : words can be']","['our example sentence in section 2. 1, noun phrases are represented by bracket structures.', 'both  #AUTHOR_TAG and  #AUTHOR_TAG have shown how classifiers can process bracket structures.', 'one classifier can be trained to recognize open brackets ( o ) while another will process close brackets ( c ).', 'their results can be converted to basenps by making pairs of open and close brackets with large probability scores  #AUTHOR_TAG or by regarding only the shortest phrases between open and close brackets as basenps  #AUTHOR_TAG.', 'we have used the bracket representation ( o + c ) in combination with the second basenp construction method.', 'an alternative representation for basenps has been put forward by  #TAUTHOR_TAG.', 'they have defined basenp recognition as a tagging task : words can be inside a basenp ( 1 ) or outside of basenps ( o ).', '']",0
"[' #TAUTHOR_TAG', '. snow reaches the best']","[' #TAUTHOR_TAG', '. snow reaches the best performance on this']","[' #TAUTHOR_TAG', '. snow reaches the best performance on this task ( fz = i = 92. 8 ). there has been less']","['', 'phrases. they compare two data representations and report that a representation with bracket structures outperforms the iob tagging representation introduced by  #TAUTHOR_TAG', '. snow reaches the best performance on this task ( fz = i = 92. 8 ). there has been less work on identifying general noun', 'phrases than on recognizing basenps.  #AUTHOR_TAG extended a definite clause grammar with rules induced by a learner that was based upon the maximum description length principle. he processed other parts of the penn treebank than we with an f ~ = i rate of about 60. our earlier effort to process the conll data set was performed in the same way as described in this paper but without using the combination method for basenps. we obtained an f ~', '= i rate of 82. 98 ( conll - 99, 1999 )']",0
"[' #TAUTHOR_TAG', '. snow reaches the best']","[' #TAUTHOR_TAG', '. snow reaches the best performance on this']","[' #TAUTHOR_TAG', '. snow reaches the best performance on this task ( fz = i = 92. 8 ). there has been less']","['', 'phrases. they compare two data representations and report that a representation with bracket structures outperforms the iob tagging representation introduced by  #TAUTHOR_TAG', '. snow reaches the best performance on this task ( fz = i = 92. 8 ). there has been less work on identifying general noun', 'phrases than on recognizing basenps.  #AUTHOR_TAG extended a definite clause grammar with rules induced by a learner that was based upon the maximum description length principle. he processed other parts of the penn treebank than we with an f ~ = i rate of about 60. our earlier effort to process the conll data set was performed in the same way as described in this paper but without using the combination method for basenps. we obtained an f ~', '= i rate of 82. 98 ( conll - 99, 1999 )']",4
[' #TAUTHOR_TAG model to allow incremental reading without loss of'],[' #TAUTHOR_TAG model to allow incremental reading without loss of'],"['restriction to unidirectional language models in the model, perform poorly.', 'we present extensions to the docqa  #TAUTHOR_TAG model to allow incremental reading without loss of']","['system which performs goal - directed continual learning must not only learn incrementally but process and absorb information incrementally.', 'such a system also has to understand when its goals have been achieved.', 'in this paper, we consider these issues in the context of question answering.', 'current state - of - the - art question answering models reason over an entire passage, not incrementally. as we will show, naive approaches to incremental reading, such as restriction to unidirectional language models in the model, perform poorly.', 'we present extensions to the docqa  #TAUTHOR_TAG model to allow incremental reading without loss of accuracy.', 'the model also jointly learns to provide the best answer given the text that is seen so far and predict whether this best - so - far answer is sufficient']",6
"['11,  #TAUTHOR_TAG 4, 8 ]']","['[ 11,  #TAUTHOR_TAG 4, 8 ]']","['11,  #TAUTHOR_TAG 4, 8 ]']","['can read and comprehend text incrementally.', 'for instance, given a piece of text, our mental state gets updated as we read [ 10 ].', 'we do not necessarily wait until the end of a long document to understand its first sentence.', 'this incremental reading mechanism allows us to avoid consuming more input if we have already reached our goal, and is analogous to the problem faced by a goal - directed continuous learning system, which must also incrementally absorb new information, determine how to use it, and determine if its goals have been achieved.', 'inspired by how humans read and learn from text incrementally, we introduce incremental models for text comprehension.', 'our primary goal is to address the problem of incremental reading in the context of language comprehension and question answering ( qa ).', 'we formulate the problem as designing a model for question - answering that consumes text incrementally.', 'by design and definition, recurrent neural networks ( rnns ), e. g. long short - term memory networks ( lstms ) [ 5 ], process data sequentially, and update their internal states as they read the new tokens.', 'however, on tasks like question answering, in all the existing well - performing models, rnns are employed in a bidirectional way, or a self - attention mechanism is employed [ 11,  #TAUTHOR_TAG 4, 8 ].', '']",6
"['. [ 11,  #TAUTHOR_TAG, they process the full']","['[ 11,  #TAUTHOR_TAG, they process the full']","['of the art results, e. g. [ 11,  #TAUTHOR_TAG, they process the full context before making any decisions.', 'we show that it is possible to modify these models to be incremental while achieving similar performance.', 'having an incremental model, allows us']","['this paper, we propose a model that reads and comprehends text incrementally.', 'as a testbed for our approach, we have chosen the question answering task.', 'we aim to build a model that can learn incrementally from text, where the learning goal is to answer a given question.', 'in standard question answering, we do not care how the context is presented to the model, and for the models that achieve state of the art results, e. g. [ 11,  #TAUTHOR_TAG, they process the full context before making any decisions.', 'we show that it is possible to modify these models to be incremental while achieving similar performance.', 'having an incremental model, allows us to employ an early stopping strategy where the model avoids reading the rest of the text as soon as it reaches a state where it thinks it has the answer']",6
"['11,  #TAUTHOR_TAG 4, 8 ]']","['[ 11,  #TAUTHOR_TAG 4, 8 ]']","['11,  #TAUTHOR_TAG 4, 8 ]']","['can read and comprehend text incrementally.', 'for instance, given a piece of text, our mental state gets updated as we read [ 10 ].', 'we do not necessarily wait until the end of a long document to understand its first sentence.', 'this incremental reading mechanism allows us to avoid consuming more input if we have already reached our goal, and is analogous to the problem faced by a goal - directed continuous learning system, which must also incrementally absorb new information, determine how to use it, and determine if its goals have been achieved.', 'inspired by how humans read and learn from text incrementally, we introduce incremental models for text comprehension.', 'our primary goal is to address the problem of incremental reading in the context of language comprehension and question answering ( qa ).', 'we formulate the problem as designing a model for question - answering that consumes text incrementally.', 'by design and definition, recurrent neural networks ( rnns ), e. g. long short - term memory networks ( lstms ) [ 5 ], process data sequentially, and update their internal states as they read the new tokens.', 'however, on tasks like question answering, in all the existing well - performing models, rnns are employed in a bidirectional way, or a self - attention mechanism is employed [ 11,  #TAUTHOR_TAG 4, 8 ].', '']",0
"['11,  #TAUTHOR_TAG 4, 8 ]']","['[ 11,  #TAUTHOR_TAG 4, 8 ]']","['11,  #TAUTHOR_TAG 4, 8 ]']","['can read and comprehend text incrementally.', 'for instance, given a piece of text, our mental state gets updated as we read [ 10 ].', 'we do not necessarily wait until the end of a long document to understand its first sentence.', 'this incremental reading mechanism allows us to avoid consuming more input if we have already reached our goal, and is analogous to the problem faced by a goal - directed continuous learning system, which must also incrementally absorb new information, determine how to use it, and determine if its goals have been achieved.', 'inspired by how humans read and learn from text incrementally, we introduce incremental models for text comprehension.', 'our primary goal is to address the problem of incremental reading in the context of language comprehension and question answering ( qa ).', 'we formulate the problem as designing a model for question - answering that consumes text incrementally.', 'by design and definition, recurrent neural networks ( rnns ), e. g. long short - term memory networks ( lstms ) [ 5 ], process data sequentially, and update their internal states as they read the new tokens.', 'however, on tasks like question answering, in all the existing well - performing models, rnns are employed in a bidirectional way, or a self - attention mechanism is employed [ 11,  #TAUTHOR_TAG 4, 8 ].', '']",1
"['as the baseline model  #TAUTHOR_TAG.', 'the']","['use docqa as the baseline model  #TAUTHOR_TAG.', 'the']","['as the baseline model  #TAUTHOR_TAG.', 'the architecture of doc']","['use docqa as the baseline model  #TAUTHOR_TAG.', 'the architecture of docqa is illustrated in figure 4a.', 'the output of this model is two vectors with the length of the given context.', 'one of the vectors indicates the probability of each token in the context to be the start token of the answer span.', 'the other vector indicates the probability of each token in the context to be the end of the answer span.', 'the gold labels indicate the ground truth begin and end of the answer spans.', 'docqa is inherently bidirectional thus making it hard to process the input incrementally.', 'it is possible to remove the bidirectionality by replacing the bidirectional layers with single - directional layers and replacing the global attention with an attention layer that only attends to the past, but this change significantly reduces performance.', 'sliced docqa in order to enable the docqa model to process the context sequence incrementally despite having bidirectional rnn and attention layers, we use the concept of slicing [ 13 ].', 'we divide the context sequence into slices and apply the model to each slice.', '']",5
"['. [ 11,  #TAUTHOR_TAG, they process the full']","['[ 11,  #TAUTHOR_TAG, they process the full']","['of the art results, e. g. [ 11,  #TAUTHOR_TAG, they process the full context before making any decisions.', 'we show that it is possible to modify these models to be incremental while achieving similar performance.', 'having an incremental model, allows us']","['this paper, we propose a model that reads and comprehends text incrementally.', 'as a testbed for our approach, we have chosen the question answering task.', 'we aim to build a model that can learn incrementally from text, where the learning goal is to answer a given question.', 'in standard question answering, we do not care how the context is presented to the model, and for the models that achieve state of the art results, e. g. [ 11,  #TAUTHOR_TAG, they process the full context before making any decisions.', 'we show that it is possible to modify these models to be incremental while achieving similar performance.', 'having an incremental model, allows us to employ an early stopping strategy where the model avoids reading the rest of the text as soon as it reaches a state where it thinks it has the answer']",4
"['1, 2, 3,  #TAUTHOR_TAG 12, 13 ]']","['image captioning networks [ 1, 2, 3,  #TAUTHOR_TAG 12, 13 ]']","['1, 2, 3,  #TAUTHOR_TAG 12, 13 ]']","['of cnns and rnns have been widely used for the image captioning networks [ 1, 2, 3,  #TAUTHOR_TAG 12, 13 ].', 'an end - to - end neural network consisting of a vision cnn followed by a language generating rnn was proposed [ 1 ].', '']",5
"['to verify their effect.', 'we used scn - lstm  #TAUTHOR_TAG as a decoder which is a tag integrated network.', 'image features and distinctive -']","['to verify their effect.', 'we used scn - lstm  #TAUTHOR_TAG as a decoder which is a tag integrated network.', 'image features and distinctive - attributes predicted by']","['to verify their effect.', 'we used scn - lstm  #TAUTHOR_TAG as a decoder which is a tag integrated network.', 'image features and distinctive -']","['', 'in section 3. 2, the method is discussed in detail and it contains a scheme to construct a vocabulary from the semantic information.', 'after extracting the semantic information from training sets, we learn distinctive - attribute prediction model with image - information pairs.', 'the model will be described in section 3. 3.', 'after getting distinctive - attribute from images, we apply these attributes to an caption generation network to verify their effect.', 'we used scn - lstm  #TAUTHOR_TAG as a decoder which is a tag integrated network.', 'image features and distinctive - attributes predicted by the proposed model are served as inputs of the model.', 'the scn - lstm unit with attribute integration and factorization [ 17 ] is represented as', 'where z = 1 ( t = 1 ) · c v. denotes the element - wise multiply operator.', 'for = i, f, o, c, x', 'where d p indicates distinctive - attribute predicted by the proposed model described in section 3. 3.', 'similar to  #TAUTHOR_TAG 13, 18 ], the objective function is composed of the conditional log - likelihood on the image feature and the attribute as', 'where i n, f ( · ), and x indicates the nth image, an image feature extraction function, and the caption, respectively.', 'n denotes the number of training images.', 'the length−t caption, x, is represented by a sequence of words ; x 0, x 1, x 2,..., x t.', 'modeling joint probability over the words with chain rule, log term is redefined']",5
"['of vocabulary size, gan  #TAUTHOR_TAG and fang']","['of vocabulary size, gan  #TAUTHOR_TAG and fang']","['in the perspective of vocabulary size, gan  #TAUTHOR_TAG and fang [ 12 ] selected 1000 words and wu', '[ 13 ] selected 256 words, respectively']","['', '. in the perspective of vocabulary size, gan  #TAUTHOR_TAG and fang [ 12 ] selected 1000 words and wu', '[ 13 ] selected 256 words, respectively. they all selected vocabulary among nouns, verbs, and adjectives. we determine the', 'words to be included in the vocabulary based on the idf scores. we do not distinguish between verbs, nouns, adjectives, and other parts of speech. the larger the idf value', '']",5
['generally follows  #TAUTHOR_TAG except'],['generally follows  #TAUTHOR_TAG except'],"['in pairs with images.', 'the training results with the different vectors will be reported in sec 4. 4.', 'scn - lstm training procedure generally follows  #TAUTHOR_TAG except']","['', 'the training results with the different vectors will be reported in sec 4. 4.', 'scn - lstm training procedure generally follows  #TAUTHOR_TAG except for the dimension of the input attribute vector.', 'we use the public implementation [ 30 ] of this method opened by gan who is the author of the published paper  #TAUTHOR_TAG.', 'for an image feature, we take out the output of the 2048 - way pool5 layer from resnet - 152 which is pre - trained on the imagenet dataset [ 31 ].', 'word embedding vectors are initialized with the word2vec vectors proposed by [ 32 ].', 'the number of hidden units and the number of factors are both set to 512.', 'we set batch size as 64 and use gradient clipping [ 33 ] and dropout [ 34 ].', 'early stopping was applied for validation sets with the maximum number of epochs 20.', 'adam optimizer [ 29 ] was used with learning rate 2 × 10 −4.', 'in testing, we use beam search for caption generation and select the top 5 best words at each lstm step as the candidates.', 'we average inferred probability for 5 identical scn - lstm model as  #TAUTHOR_TAG did']",5
['generally follows  #TAUTHOR_TAG except'],['generally follows  #TAUTHOR_TAG except'],"['in pairs with images.', 'the training results with the different vectors will be reported in sec 4. 4.', 'scn - lstm training procedure generally follows  #TAUTHOR_TAG except']","['', 'the training results with the different vectors will be reported in sec 4. 4.', 'scn - lstm training procedure generally follows  #TAUTHOR_TAG except for the dimension of the input attribute vector.', 'we use the public implementation [ 30 ] of this method opened by gan who is the author of the published paper  #TAUTHOR_TAG.', 'for an image feature, we take out the output of the 2048 - way pool5 layer from resnet - 152 which is pre - trained on the imagenet dataset [ 31 ].', 'word embedding vectors are initialized with the word2vec vectors proposed by [ 32 ].', 'the number of hidden units and the number of factors are both set to 512.', 'we set batch size as 64 and use gradient clipping [ 33 ] and dropout [ 34 ].', 'early stopping was applied for validation sets with the maximum number of epochs 20.', 'adam optimizer [ 29 ] was used with learning rate 2 × 10 −4.', 'in testing, we use beam search for caption generation and select the top 5 best words at each lstm step as the candidates.', 'we average inferred probability for 5 identical scn - lstm model as  #TAUTHOR_TAG did']",5
['method with scn  #TAUTHOR_TAG 30 ]'],['method with scn  #TAUTHOR_TAG 30 ]'],['method with scn  #TAUTHOR_TAG 30 ]'],"['the experiment, we compared our method with scn  #TAUTHOR_TAG 30 ] that uses extracted tags according to their semantic concept detection method.', 'to evaluate the proposed method with more pictures, we compare the predicted semantic attributes by using scn and the proposed scheme.', 'the results are listed in table 5.', 'the attribute in scn and the proposed method ( dae ) is called as tag and distinctive - attribute, respectively.', 'the tag represents probabilities, on the other hand, the attribute from dae is distinctiveness score itself.', 'we listed the top eight attributes in descending order.', 'in the case of dae, words after stemming are displayed as they are.', 'the captions obtained using image features and extracted semantic information are also compared in the table.', '']",5
"['to verify their effect.', 'we used scn - lstm  #TAUTHOR_TAG as a decoder which is a tag integrated network.', 'image features and distinctive -']","['to verify their effect.', 'we used scn - lstm  #TAUTHOR_TAG as a decoder which is a tag integrated network.', 'image features and distinctive - attributes predicted by']","['to verify their effect.', 'we used scn - lstm  #TAUTHOR_TAG as a decoder which is a tag integrated network.', 'image features and distinctive -']","['', 'in section 3. 2, the method is discussed in detail and it contains a scheme to construct a vocabulary from the semantic information.', 'after extracting the semantic information from training sets, we learn distinctive - attribute prediction model with image - information pairs.', 'the model will be described in section 3. 3.', 'after getting distinctive - attribute from images, we apply these attributes to an caption generation network to verify their effect.', 'we used scn - lstm  #TAUTHOR_TAG as a decoder which is a tag integrated network.', 'image features and distinctive - attributes predicted by the proposed model are served as inputs of the model.', 'the scn - lstm unit with attribute integration and factorization [ 17 ] is represented as', 'where z = 1 ( t = 1 ) · c v. denotes the element - wise multiply operator.', 'for = i, f, o, c, x', 'where d p indicates distinctive - attribute predicted by the proposed model described in section 3. 3.', 'similar to  #TAUTHOR_TAG 13, 18 ], the objective function is composed of the conditional log - likelihood on the image feature and the attribute as', 'where i n, f ( · ), and x indicates the nth image, an image feature extraction function, and the caption, respectively.', 'n denotes the number of training images.', 'the length−t caption, x, is represented by a sequence of words ; x 0, x 1, x 2,..., x t.', 'modeling joint probability over the words with chain rule, log term is redefined']",3
['generally follows  #TAUTHOR_TAG except'],['generally follows  #TAUTHOR_TAG except'],"['in pairs with images.', 'the training results with the different vectors will be reported in sec 4. 4.', 'scn - lstm training procedure generally follows  #TAUTHOR_TAG except']","['', 'the training results with the different vectors will be reported in sec 4. 4.', 'scn - lstm training procedure generally follows  #TAUTHOR_TAG except for the dimension of the input attribute vector.', 'we use the public implementation [ 30 ] of this method opened by gan who is the author of the published paper  #TAUTHOR_TAG.', 'for an image feature, we take out the output of the 2048 - way pool5 layer from resnet - 152 which is pre - trained on the imagenet dataset [ 31 ].', 'word embedding vectors are initialized with the word2vec vectors proposed by [ 32 ].', 'the number of hidden units and the number of factors are both set to 512.', 'we set batch size as 64 and use gradient clipping [ 33 ] and dropout [ 34 ].', 'early stopping was applied for validation sets with the maximum number of epochs 20.', 'adam optimizer [ 29 ] was used with learning rate 2 × 10 −4.', 'in testing, we use beam search for caption generation and select the top 5 best words at each lstm step as the candidates.', 'we average inferred probability for 5 identical scn - lstm model as  #TAUTHOR_TAG did']",3
"['of vocabulary size, gan  #TAUTHOR_TAG and fang']","['of vocabulary size, gan  #TAUTHOR_TAG and fang']","['in the perspective of vocabulary size, gan  #TAUTHOR_TAG and fang [ 12 ] selected 1000 words and wu', '[ 13 ] selected 256 words, respectively']","['', '. in the perspective of vocabulary size, gan  #TAUTHOR_TAG and fang [ 12 ] selected 1000 words and wu', '[ 13 ] selected 256 words, respectively. they all selected vocabulary among nouns, verbs, and adjectives. we determine the', 'words to be included in the vocabulary based on the idf scores. we do not distinguish between verbs, nouns, adjectives, and other parts of speech. the larger the idf value', '']",4
"['initialized with a xavier initialization [ 27 ].', 'we note that our network does not contain softmax as a final layer, different from other attribute predictors described in previous papers  #TAUTHOR_TAG 13 ].', 'hence, we use the output of an activation']","['initialized with a xavier initialization [ 27 ].', 'we note that our network does not contain softmax as a final layer, different from other attribute predictors described in previous papers  #TAUTHOR_TAG 13 ].', 'hence, we use the output of an activation']","['', 'each fc is initialized with a xavier initialization [ 27 ].', 'we note that our network does not contain softmax as a final layer, different from other attribute predictors described in previous papers  #TAUTHOR_TAG 13 ].', 'hence, we use the output of an activation function of']","['', 'we use relu [ 25 ] as nonlinear activation function for all fc.', 'we adopt batch normalization ( bn ) [ 26 ] right after each fc and before activation.', 'the training is regularized by dropout with ratio 0. 3 for the first three fcs.', 'each fc is initialized with a xavier initialization [ 27 ].', 'we note that our network does not contain softmax as a final layer, different from other attribute predictors described in previous papers  #TAUTHOR_TAG 13 ].', '']",4
"['of the proposed distinctive - attribute prediction model.', 'the output attribute of previous methods  #TAUTHOR_TAG 12, 13, 19 ] represent probabilities, on the other hand, that of']","['of the proposed distinctive - attribute prediction model.', 'the output attribute of previous methods  #TAUTHOR_TAG 12, 13, 19 ] represent probabilities, on the other hand, that of']","['compare the performance of the proposed distinctive - attribute prediction model.', 'the output attribute of previous methods  #TAUTHOR_TAG 12, 13, 19 ] represent probabilities, on the other hand, that of']","['use the macro - average f1 metric to compare the performance of the proposed distinctive - attribute prediction model.', 'the output attribute of previous methods  #TAUTHOR_TAG 12, 13, 19 ] represent probabilities, on the other hand, that of the proposed method are the distinctiveness score itself.', 'we evaluate the prediction considering it as a multi - label and multi - class classification problem..', 'in case the value 0. 0 occupies most of the elements, it disturbs accurately comparing the performance.', 'therefore, we exclude those elements intentionally in the comparison.', 'each word in attribute vocabulary is regarded as one class, respectively.', 'the macro - averaged f1 score is computed globally by counting the total number of true positives, false negatives, true negatives, and false positives.', 'the widely used metrics, bleu - 1, 2, 3, 4 [ 35 ], meteor [ 36 ], rougl - l [ 37 ], cider [ 38 ] are selected to evaluate overall captioning performance.', 'the code released by the coco evaluation server [ 21 ] is used for computation']",4
"['us to do inference efficiently since our inference time is merely the inference time', ""of two sequential crf's ; in contrast  #TAUTHOR_TAG reported an""]","['second crf uses features derived from the output of the first crf. this gives us the advantage of defining a rich set of features to', 'model non - local dependencies, and also eliminates the need to do approximate inference, since we do not explicitly capture the non - local dependencies', 'in a single model, like the more complex existing approaches. this also enables us to do inference efficiently since our inference time is merely the inference time', ""of two sequential crf's ; in contrast  #TAUTHOR_TAG reported an increase"", '']","['us to do inference efficiently since our inference time is merely the inference time', ""of two sequential crf's ; in contrast  #TAUTHOR_TAG reported an increase"", '']","['mc  #AUTHOR_TAG, and conditional random fields ( crfs )  #AUTHOR_TAG have been successfully employed in ner and other information extraction tasks. all these models encode the markov property i. e. labels directly depend only on the labels', 'assigned to a small window around them. these models exploit this property for tractable computation as this allows the forward - backward, viterbi and clique calibration algorithms', 'to become tractable. although this constraint is essential to make exact inference tractable, it makes us unable to exploit the non - local structure present in natural language. label consistency is an example of a non', '- local dependency important in ner. apart from label consistency between the same token sequences, we would', 'also like to exploit richer sources of dependencies between similar token sequences. for example, as shown in figure 1, we would want it to encourage einstein to be labeled "" person "" if there is strong evidence that albert einstein should be labeled ""', 'person "". sequence models unfortu - nately cannot model this due to their markovian assumption. recent approaches attempting to capture non', '##local dependencies model the non - local dependencies directly, and use approximate inference algorithms, since exact inference is in general, not tractable for graphs', 'with non - local structure.  #AUTHOR_TAG define a relational markov network ( rmn ) which explicitly models long - distance dependencies, and use it', 'to represent relations between entities. sutton and mc  #AUTHOR_TAG augment a sequential crf', 'with skip - edges i. e. edges between different occurrences of a token, in a document. both these approaches use loop', '##y belief propagation  #AUTHOR_TAG for approximate inference.  #AUTHOR_TAG hand - set penalties for inconsistency in entity labeling at different occurrences in the text, based on some statistics from training data. they then employ gibbs', 'sampling  #AUTHOR_TAG for dealing with their local feature weights and their non - local penalties to do', 'approximate inference. we present a simple two - stage approach where our second crf uses features derived from the output of the first crf. this gives us the advantage of defining a rich set of features to', 'model non - local dependencies, and also eliminates the need to do approximate inference, since we do not explicitly capture the non - local dependencies', 'in a single model, like the more complex existing approaches. this also enables us to do inference efficiently since our inference time is merely the inference time', ""of two sequential crf's ; in contrast  #TAUTHOR_TAG reported an increase"", 'in running time by a factor of 30 over the sequential crf, with their gibbs sampling approximate inference. in all, our approach', 'is simpler, yields higher f1 scores, and is also much more computationally efficient than existing approaches modeling nonlocal dependencies']",4
['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling'],['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling'],['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling goes up by'],"['our two - stage approach, we manage to get improvements on the f1 measure over existing approaches that model non - local dependencies.', 'at the same time, the simplicity of our two - stage approach keeps inference time down to just the inference time of two sequential crfs, when compared to approaches such as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling goes up by a factor of about 30, compared to the viterbi algorithm for the sequential crf.', 'below, we give some intuition about areas for improvement in existing work and explain how our approach incorporates the improvements.', '• most existing work to capture labelconsistency, has attempted to create all n 2 pairwise dependencies between the different occurrences of an entity,  #TAUTHOR_TAG, where n is the number of occurrences of the given entity.', 'this complicates the dependency graph making inference harder.', 'it also leads to the penalty for deviation in labeling to grow linearly with n, since each entity would be connected to θ ( n ) entities.', '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', 'additionally, our']","['', 'as we would expect the additional gains from features approximating nonlocal dependencies across the whole test corpus are relatively small.', 'we use the approximate randomization test  #AUTHOR_TAG for statistical significance of the difference between the basic sequential crf and our second round crf, which has additional features derived from the output of the first crf.', 'with a 1000 iterations, our improvements were statistically significant with a p - value of 0. 001.', 'since this value is less than the cutoff threshold of 0. 05, we reject the null hypothesis.', 'the simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential crf ; in contrast, approaches like gibbs sampling that model the dependencies directly can increase inference time by a factor of 30  #TAUTHOR_TAG.', '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', 'additionally, our']","['', 'as we would expect the additional gains from features approximating nonlocal dependencies across the whole test corpus are relatively small.', 'we use the approximate randomization test  #AUTHOR_TAG for statistical significance of the difference between the basic sequential crf and our second round crf, which has additional features derived from the output of the first crf.', 'with a 1000 iterations, our improvements were statistically significant with a p - value of 0. 001.', 'since this value is less than the cutoff threshold of 0. 05, we reject the null hypothesis.', 'the simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential crf ; in contrast, approaches like gibbs sampling that model the dependencies directly can increase inference time by a factor of 30  #TAUTHOR_TAG.', '']",4
[' #TAUTHOR_TAG'],[' #TAUTHOR_TAG'],"[' #TAUTHOR_TAG.', 'additionally, our']","['', 'as we would expect the additional gains from features approximating nonlocal dependencies across the whole test corpus are relatively small.', 'we use the approximate randomization test  #AUTHOR_TAG for statistical significance of the difference between the basic sequential crf and our second round crf, which has additional features derived from the output of the first crf.', 'with a 1000 iterations, our improvements were statistically significant with a p - value of 0. 001.', 'since this value is less than the cutoff threshold of 0. 05, we reject the null hypothesis.', 'the simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like  #AUTHOR_TAG and  #TAUTHOR_TAG.', 'additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential crf ; in contrast, approaches like gibbs sampling that model the dependencies directly can increase inference time by a factor of 30  #TAUTHOR_TAG.', '']",4
"[', and china, the country  #TAUTHOR_TAG. the first should']","[', and china, the country  #TAUTHOR_TAG. the first should']","['containing references to both the china daily, a newspaper, and china, the country  #TAUTHOR_TAG. the first should be labeled as an organization', ', and second as a location. the counts of subsequence labelings within a']","['', 'most of the density ) at both the document and corpus levels. a notable exception to this is the labeling of the same text as both organization and', 'location within the same document and across documents. this is a due to the large amount of sports news in the conll dataset due to which city and country names are often also team names. we will see that our approach is capable of exploiting this as well, i. e. we can learn a model which would not penalize an organization', '- location inconsistency as strongly as it penalizes other inconsistencies. in addition, we also want to model subsequence constraints :', 'having seen albert einstein earlier in a document as a person is a good indicator that a subsequent occurrence of einstein should also be labeled as a', 'person. here, we would expect that a subsequence would gain much more by knowing the label of a supersequence, than the other way', 'around. however, as can be seen from table 2, we find that the', 'consistency constraint does not hold nearly so strictly in this case. a very common case of this in the conll dataset is that', 'of documents containing references to both the china daily, a newspaper, and china, the country  #TAUTHOR_TAG. the first should be labeled as an organization', ', and second as a location. the counts of subsequence labelings within a document and across documents listed in table 2, show that there are many off - diagonal entries : the china daily case is among the most', 'common, occurring 328 times in the dataset. just as we can model off - diagonal pat - terns with exact token sequence matches, we can also model off - diagonal patterns for the token subsequence case', '. in addition, we could also derive some value by enforcing some label consistency at the level of an individual token. obviously, our model', 'would learn much lower weights for these constraints, when compared to label consistency at the level of token sequences']",0
['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling'],['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling'],['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling goes up by'],"['our two - stage approach, we manage to get improvements on the f1 measure over existing approaches that model non - local dependencies.', 'at the same time, the simplicity of our two - stage approach keeps inference time down to just the inference time of two sequential crfs, when compared to approaches such as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling goes up by a factor of about 30, compared to the viterbi algorithm for the sequential crf.', 'below, we give some intuition about areas for improvement in existing work and explain how our approach incorporates the improvements.', '• most existing work to capture labelconsistency, has attempted to create all n 2 pairwise dependencies between the different occurrences of an entity,  #TAUTHOR_TAG, where n is the number of occurrences of the given entity.', 'this complicates the dependency graph making inference harder.', 'it also leads to the penalty for deviation in labeling to grow linearly with n, since each entity would be connected to θ ( n ) entities.', '']",0
['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling'],['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling'],['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling goes up by'],"['our two - stage approach, we manage to get improvements on the f1 measure over existing approaches that model non - local dependencies.', 'at the same time, the simplicity of our two - stage approach keeps inference time down to just the inference time of two sequential crfs, when compared to approaches such as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling goes up by a factor of about 30, compared to the viterbi algorithm for the sequential crf.', 'below, we give some intuition about areas for improvement in existing work and explain how our approach incorporates the improvements.', '• most existing work to capture labelconsistency, has attempted to create all n 2 pairwise dependencies between the different occurrences of an entity,  #TAUTHOR_TAG, where n is the number of occurrences of the given entity.', 'this complicates the dependency graph making inference harder.', 'it also leads to the penalty for deviation in labeling to grow linearly with n, since each entity would be connected to θ ( n ) entities.', '']",0
['underlying crf sequence model ( which  #AUTHOR_TAG lack ) and  #TAUTHOR_TAG who hand - set penalties'],['underlying crf sequence model ( which  #AUTHOR_TAG lack ) and  #TAUTHOR_TAG who hand - set penalties'],"['chain crfs, which add additional non - local edges to the underlying crf sequence model ( which  #AUTHOR_TAG lack ) and  #TAUTHOR_TAG who hand - set penalties']","['work looking to directly model non - local dependencies and do approximate inference are that of  #AUTHOR_TAG, who use a relational markov network ( rmn )  #AUTHOR_TAG to explicitly model long - distance dependencies, sutton and mc  #AUTHOR_TAG, who introduce skip - chain crfs, which add additional non - local edges to the underlying crf sequence model ( which  #AUTHOR_TAG lack ) and  #TAUTHOR_TAG who hand - set penalties for inconsistency in labels based on the training data and then use gibbs sampling for doing approximate inference where the goal is to obtain the label sequence that maximizes the product of the crf objective function and their penalty.', 'unfortunately, in the rmn model, the dependencies must be defined in the model structure before doing any inference, and so the authors use heuristic part - of - speech patterns, and then add dependencies between these text spans using clique templates.', 'this generates an extremely large number of overlapping candidate entities, which renders necessary additional templates to enforce the constraint that text subsequences cannot both be different entities, something that is more naturally modeled by a crf.', 'another disadvantage of this approach is that it uses loopy belief propagation and a voted perceptron for approximate learning and inference, which are inherently unstable algorithms leading to convergence problems, as noted by the authors.', '']",0
['underlying crf sequence model ( which  #AUTHOR_TAG lack ) and  #TAUTHOR_TAG who hand - set penalties'],['underlying crf sequence model ( which  #AUTHOR_TAG lack ) and  #TAUTHOR_TAG who hand - set penalties'],"['chain crfs, which add additional non - local edges to the underlying crf sequence model ( which  #AUTHOR_TAG lack ) and  #TAUTHOR_TAG who hand - set penalties']","['work looking to directly model non - local dependencies and do approximate inference are that of  #AUTHOR_TAG, who use a relational markov network ( rmn )  #AUTHOR_TAG to explicitly model long - distance dependencies, sutton and mc  #AUTHOR_TAG, who introduce skip - chain crfs, which add additional non - local edges to the underlying crf sequence model ( which  #AUTHOR_TAG lack ) and  #TAUTHOR_TAG who hand - set penalties for inconsistency in labels based on the training data and then use gibbs sampling for doing approximate inference where the goal is to obtain the label sequence that maximizes the product of the crf objective function and their penalty.', 'unfortunately, in the rmn model, the dependencies must be defined in the model structure before doing any inference, and so the authors use heuristic part - of - speech patterns, and then add dependencies between these text spans using clique templates.', 'this generates an extremely large number of overlapping candidate entities, which renders necessary additional templates to enforce the constraint that text subsequences cannot both be different entities, something that is more naturally modeled by a crf.', 'another disadvantage of this approach is that it uses loopy belief propagation and a voted perceptron for approximate learning and inference, which are inherently unstable algorithms leading to convergence problems, as noted by the authors.', '']",0
"[', and china, the country  #TAUTHOR_TAG. the first should']","[', and china, the country  #TAUTHOR_TAG. the first should']","['containing references to both the china daily, a newspaper, and china, the country  #TAUTHOR_TAG. the first should be labeled as an organization', ', and second as a location. the counts of subsequence labelings within a']","['', 'most of the density ) at both the document and corpus levels. a notable exception to this is the labeling of the same text as both organization and', 'location within the same document and across documents. this is a due to the large amount of sports news in the conll dataset due to which city and country names are often also team names. we will see that our approach is capable of exploiting this as well, i. e. we can learn a model which would not penalize an organization', '- location inconsistency as strongly as it penalizes other inconsistencies. in addition, we also want to model subsequence constraints :', 'having seen albert einstein earlier in a document as a person is a good indicator that a subsequent occurrence of einstein should also be labeled as a', 'person. here, we would expect that a subsequence would gain much more by knowing the label of a supersequence, than the other way', 'around. however, as can be seen from table 2, we find that the', 'consistency constraint does not hold nearly so strictly in this case. a very common case of this in the conll dataset is that', 'of documents containing references to both the china daily, a newspaper, and china, the country  #TAUTHOR_TAG. the first should be labeled as an organization', ', and second as a location. the counts of subsequence labelings within a document and across documents listed in table 2, show that there are many off - diagonal entries : the china daily case is among the most', 'common, occurring 328 times in the dataset. just as we can model off - diagonal pat - terns with exact token sequence matches, we can also model off - diagonal patterns for the token subsequence case', '. in addition, we could also derive some value by enforcing some label consistency at the level of an individual token. obviously, our model', 'would learn much lower weights for these constraints, when compared to label consistency at the level of token sequences']",3
['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling'],['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling'],['as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling goes up by'],"['our two - stage approach, we manage to get improvements on the f1 measure over existing approaches that model non - local dependencies.', 'at the same time, the simplicity of our two - stage approach keeps inference time down to just the inference time of two sequential crfs, when compared to approaches such as those of  #TAUTHOR_TAG who report that their inference time with gibbs sampling goes up by a factor of about 30, compared to the viterbi algorithm for the sequential crf.', 'below, we give some intuition about areas for improvement in existing work and explain how our approach incorporates the improvements.', '• most existing work to capture labelconsistency, has attempted to create all n 2 pairwise dependencies between the different occurrences of an entity,  #TAUTHOR_TAG, where n is the number of occurrences of the given entity.', 'this complicates the dependency graph making inference harder.', 'it also leads to the penalty for deviation in labeling to grow linearly with n, since each entity would be connected to θ ( n ) entities.', '']",1
"['experiment of  #TAUTHOR_TAG for transitive verbs.', 'then we']","['experiment of  #TAUTHOR_TAG for transitive verbs.', 'then we']","['us to realize the concrete computations in lower dimensional spaces, thus reduce the space complexity of the implementation. we experiment in two different tasks with promising results : first, we repeat the disambiguation experiment of  #TAUTHOR_TAG for transitive verbs.', 'then we proceed to a novel task : we use the oxford junior dictionary  #AUTHOR_TAG, oxford concise school dictionary  #AUTHOR_TAG, and wordnet in order to derive a set of term / definition pairs, measure the similarity of each term with every definition,']","['', 'in which context vectors live, namely we stipulate that s = n. as a result of this decision, we become able to compare lexical', 'meanings of words with compositional meanings of phrases and sentences. we show how the theoretical computations of  #AUTHOR_TAG instantiate in this concrete setting, and how the frobenius algebras, originating from group theory  #AUTHOR_TAG and later extended to vector spaces', ' #AUTHOR_TAG, allow us to not only represent meanings of words with complex roles, such as verbs, adj', '##ectives, and prepositions, in an intuitive relational manner, but also to stay faithful to their original linguistic types. equally', 'as importantly, this model enables us to realize the concrete computations in lower dimensional spaces, thus reduce the space complexity of the implementation. we experiment in two different tasks with promising results : first, we repeat the disambiguation experiment of  #TAUTHOR_TAG for transitive verbs.', 'then we proceed to a novel task : we use the oxford junior dictionary  #AUTHOR_TAG, oxford concise school dictionary  #AUTHOR_TAG, and wordnet in order to derive a set of term / definition pairs, measure the similarity of each term with every definition, and use this measurement to classify the definitions to specific terms', '']",3
"['verb  #TAUTHOR_TAG provides us with a matrix in n', '2. in order to embed this in n 3, as required by the categorical']","['verb  #TAUTHOR_TAG provides us with a matrix in n', '2. in order to embed this in n 3, as required by the categorical']","['verb  #TAUTHOR_TAG provides us with a matrix in n', '2. in order to embed this in n 3, as required by the categorical framework, we apply a σ : n 2 → n 3 map to', 'it. now the frobenius operation']","['. we use a pictorial calculus that allows convenient graphical representations of the derivations. in this notation, each tensor is represented by a triangle,', 'and its rank can be determined by the outgoing wires. the tensor product is depicted', 'as juxtaposition of triangles. we also remind to the reader that the relational method for constructing a tensor for the', 'meaning of a verb  #TAUTHOR_TAG provides us with a matrix in n', '2. in order to embed this in n 3, as required by the categorical framework, we apply a σ : n 2 → n 3 map to', 'it. now the frobenius operation σ gives us some options for the form of the resulting tensor, which are presented below : cpsbj the first', '']",3
"['), following closely the parameters of the setting described in  #AUTHOR_TAG, later used by  #TAUTHOR_TAG.', 'specifically, we use the 2000 most frequent words as the basis for our vector space ; this single space will serve as a semantic space for both nouns and sentences.', 'the weights of the vectors are set to the ratio of the probability of the context']","['british national corpus ( bnc ), following closely the parameters of the setting described in  #AUTHOR_TAG, later used by  #TAUTHOR_TAG.', 'specifically, we use the 2000 most frequent words as the basis for our vector space ; this single space will serve as a semantic space for both nouns and sentences.', 'the weights of the vectors are set to the ratio of the probability of the context']","['), following closely the parameters of the setting described in  #AUTHOR_TAG, later used by  #TAUTHOR_TAG.', 'specifically, we use the 2000 most frequent words as the basis for our vector space ; this single space will serve as a semantic space for both nouns and sentences.', 'the weights of the vectors are set to the ratio of the probability of the context word given the target word to the probability of the context word overall.', 'as our similarity measure we use the cosine distance']","['train our vectors from a lemmatised version of the british national corpus ( bnc ), following closely the parameters of the setting described in  #AUTHOR_TAG, later used by  #TAUTHOR_TAG.', 'specifically, we use the 2000 most frequent words as the basis for our vector space ; this single space will serve as a semantic space for both nouns and sentences.', 'the weights of the vectors are set to the ratio of the probability of the context word given the target word to the probability of the context word overall.', 'as our similarity measure we use the cosine distance']",3
"['described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['for transitive sentences described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['first test our models against the disambiguation task for transitive sentences described in  #TAUTHOR_TAG.', 'the goal is to assess how well a model can discriminate between the different senses of an ambiguous verb, given the context ( subject and object ) of that verb.', 'the entries of this dataset consist of a target verb, a subject, an object, and a landmark verb used for the comparison.', 'one such entry for example is, "" write, pupil, name, spell "".', 'a good compositional model should be able to understand that the sentence "" pupil write name "" is closer to the sentence "" pupil spell name "" than, for example, to "" pupil publish name "".', 'on the other hand, given the context "" writer, book "" these results should be reversed.', 'the dataset contains 200 such entries with verbs from celex, hence 400 sentences.', ""the evaluation of this experiment is performed by calculating spearman's ρ correlation against the judgements of 25 human evaluators."", 'as our baselines we use an additive ( addtv ) and a multiplicative ( multp ) model, where the meaning of a sentence is computed by adding and point - wise multiplying, respectively, the context vectors of its words.', 'the results are shown in table 1.', 'the most successful s = n model for this task is the copyobject model, which is performing really close to the original relational model of  #TAUTHOR_TAG, with the difference to be statistically insignificant.', 'this is a promising result, since it suggests that the lower - dimensional new model performs similarly with the richer structure of the old model for transitive sentences, while at the same time allows generalisation to even more complex sentences 1.', 'more importantly, note that the categorical models are the only ones that respect the word order and grammatical structure of sentences ; a feature completely dismissed in the simple multiplicative model']",3
"['experiment of  #TAUTHOR_TAG for transitive verbs.', 'then we']","['experiment of  #TAUTHOR_TAG for transitive verbs.', 'then we']","['us to realize the concrete computations in lower dimensional spaces, thus reduce the space complexity of the implementation. we experiment in two different tasks with promising results : first, we repeat the disambiguation experiment of  #TAUTHOR_TAG for transitive verbs.', 'then we proceed to a novel task : we use the oxford junior dictionary  #AUTHOR_TAG, oxford concise school dictionary  #AUTHOR_TAG, and wordnet in order to derive a set of term / definition pairs, measure the similarity of each term with every definition,']","['', 'in which context vectors live, namely we stipulate that s = n. as a result of this decision, we become able to compare lexical', 'meanings of words with compositional meanings of phrases and sentences. we show how the theoretical computations of  #AUTHOR_TAG instantiate in this concrete setting, and how the frobenius algebras, originating from group theory  #AUTHOR_TAG and later extended to vector spaces', ' #AUTHOR_TAG, allow us to not only represent meanings of words with complex roles, such as verbs, adj', '##ectives, and prepositions, in an intuitive relational manner, but also to stay faithful to their original linguistic types. equally', 'as importantly, this model enables us to realize the concrete computations in lower dimensional spaces, thus reduce the space complexity of the implementation. we experiment in two different tasks with promising results : first, we repeat the disambiguation experiment of  #TAUTHOR_TAG for transitive verbs.', 'then we proceed to a novel task : we use the oxford junior dictionary  #AUTHOR_TAG, oxford concise school dictionary  #AUTHOR_TAG, and wordnet in order to derive a set of term / definition pairs, measure the similarity of each term with every definition, and use this measurement to classify the definitions to specific terms', '']",5
"['), following closely the parameters of the setting described in  #AUTHOR_TAG, later used by  #TAUTHOR_TAG.', 'specifically, we use the 2000 most frequent words as the basis for our vector space ; this single space will serve as a semantic space for both nouns and sentences.', 'the weights of the vectors are set to the ratio of the probability of the context']","['british national corpus ( bnc ), following closely the parameters of the setting described in  #AUTHOR_TAG, later used by  #TAUTHOR_TAG.', 'specifically, we use the 2000 most frequent words as the basis for our vector space ; this single space will serve as a semantic space for both nouns and sentences.', 'the weights of the vectors are set to the ratio of the probability of the context']","['), following closely the parameters of the setting described in  #AUTHOR_TAG, later used by  #TAUTHOR_TAG.', 'specifically, we use the 2000 most frequent words as the basis for our vector space ; this single space will serve as a semantic space for both nouns and sentences.', 'the weights of the vectors are set to the ratio of the probability of the context word given the target word to the probability of the context word overall.', 'as our similarity measure we use the cosine distance']","['train our vectors from a lemmatised version of the british national corpus ( bnc ), following closely the parameters of the setting described in  #AUTHOR_TAG, later used by  #TAUTHOR_TAG.', 'specifically, we use the 2000 most frequent words as the basis for our vector space ; this single space will serve as a semantic space for both nouns and sentences.', 'the weights of the vectors are set to the ratio of the probability of the context word given the target word to the probability of the context word overall.', 'as our similarity measure we use the cosine distance']",5
"['described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['for transitive sentences described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['first test our models against the disambiguation task for transitive sentences described in  #TAUTHOR_TAG.', 'the goal is to assess how well a model can discriminate between the different senses of an ambiguous verb, given the context ( subject and object ) of that verb.', 'the entries of this dataset consist of a target verb, a subject, an object, and a landmark verb used for the comparison.', 'one such entry for example is, "" write, pupil, name, spell "".', 'a good compositional model should be able to understand that the sentence "" pupil write name "" is closer to the sentence "" pupil spell name "" than, for example, to "" pupil publish name "".', 'on the other hand, given the context "" writer, book "" these results should be reversed.', 'the dataset contains 200 such entries with verbs from celex, hence 400 sentences.', ""the evaluation of this experiment is performed by calculating spearman's ρ correlation against the judgements of 25 human evaluators."", 'as our baselines we use an additive ( addtv ) and a multiplicative ( multp ) model, where the meaning of a sentence is computed by adding and point - wise multiplying, respectively, the context vectors of its words.', 'the results are shown in table 1.', 'the most successful s = n model for this task is the copyobject model, which is performing really close to the original relational model of  #TAUTHOR_TAG, with the difference to be statistically insignificant.', 'this is a promising result, since it suggests that the lower - dimensional new model performs similarly with the richer structure of the old model for transitive sentences, while at the same time allows generalisation to even more complex sentences 1.', 'more importantly, note that the categorical models are the only ones that respect the word order and grammatical structure of sentences ; a feature completely dismissed in the simple multiplicative model']",5
['work of  #TAUTHOR_TAG was the first large - scale practical implementation of this'],['work of  #TAUTHOR_TAG was the first large - scale practical implementation of this'],['work of  #TAUTHOR_TAG was the first large - scale practical implementation of this framework for intransitive'],"['work of  #TAUTHOR_TAG was the first large - scale practical implementation of this framework for intransitive and transitive sentences, and thus a first step towards providing some concrete answers to these questions.', '']",0
"['d n )  #TAUTHOR_TAG to θ ( d ),']","['n )  #TAUTHOR_TAG to θ ( d ),']","['d n )  #TAUTHOR_TAG to θ ( d ), making the problem much more tractable.', 'what remains to be solved is a theoretical issue, that in practice the meaning of relational words']","['work presented in this paper stems from the observation that the theory does not impose a special choice of sentence space, in particular it does not impose that tensors for s should have ranks greater than 1.', ""hence we stipulate that s = n and show how this instantiation works by performing the computations on the example transitive sentence'dogs chase cats '."", 'take − − → do g and −→ cat be the context vectors for the subject and the object, both living in n as prescribed by their types.', 'as any vector, these can be expressed as weighted sums of their basis vectors, that is,', '. by putting everything together, the meaning of the sentence is calculated as follows ; this result lives in n, since it is a weighted sum over − → n j :', 'an important consequence of our design decision is that it enables us to reduce the space complexity of the implementation from θ ( d n )  #TAUTHOR_TAG to θ ( d ), making the problem much more tractable.', ""what remains to be solved is a theoretical issue, that in practice the meaning of relational words such as'chase'as calculated by equation 5 is a matrix living in n 2 - however, the mathematical framework above prescribes that it should be a rank - 3 tensor in n 3."", 'the necessary expansions are achieved by using frobenius algebraic operations, for which the following sections first provide the mathematical definitions and then a linguistic justification']",4
"['verb  #TAUTHOR_TAG provides us with a matrix in n', '2. in order to embed this in n 3, as required by the categorical']","['verb  #TAUTHOR_TAG provides us with a matrix in n', '2. in order to embed this in n 3, as required by the categorical']","['verb  #TAUTHOR_TAG provides us with a matrix in n', '2. in order to embed this in n 3, as required by the categorical framework, we apply a σ : n 2 → n 3 map to', 'it. now the frobenius operation']","['. we use a pictorial calculus that allows convenient graphical representations of the derivations. in this notation, each tensor is represented by a triangle,', 'and its rank can be determined by the outgoing wires. the tensor product is depicted', 'as juxtaposition of triangles. we also remind to the reader that the relational method for constructing a tensor for the', 'meaning of a verb  #TAUTHOR_TAG provides us with a matrix in n', '2. in order to embed this in n 3, as required by the categorical framework, we apply a σ : n 2 → n 3 map to', 'it. now the frobenius operation σ gives us some options for the form of the resulting tensor, which are presented below : cpsbj the first', '']",4
"['described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['for transitive sentences described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['first test our models against the disambiguation task for transitive sentences described in  #TAUTHOR_TAG.', 'the goal is to assess how well a model can discriminate between the different senses of an ambiguous verb, given the context ( subject and object ) of that verb.', 'the entries of this dataset consist of a target verb, a subject, an object, and a landmark verb used for the comparison.', 'one such entry for example is, "" write, pupil, name, spell "".', 'a good compositional model should be able to understand that the sentence "" pupil write name "" is closer to the sentence "" pupil spell name "" than, for example, to "" pupil publish name "".', 'on the other hand, given the context "" writer, book "" these results should be reversed.', 'the dataset contains 200 such entries with verbs from celex, hence 400 sentences.', ""the evaluation of this experiment is performed by calculating spearman's ρ correlation against the judgements of 25 human evaluators."", 'as our baselines we use an additive ( addtv ) and a multiplicative ( multp ) model, where the meaning of a sentence is computed by adding and point - wise multiplying, respectively, the context vectors of its words.', 'the results are shown in table 1.', 'the most successful s = n model for this task is the copyobject model, which is performing really close to the original relational model of  #TAUTHOR_TAG, with the difference to be statistically insignificant.', 'this is a promising result, since it suggests that the lower - dimensional new model performs similarly with the richer structure of the old model for transitive sentences, while at the same time allows generalisation to even more complex sentences 1.', 'more importantly, note that the categorical models are the only ones that respect the word order and grammatical structure of sentences ; a feature completely dismissed in the simple multiplicative model']",4
"['of  #TAUTHOR_TAG with s = n 2, provided a ρ of']","['of  #TAUTHOR_TAG with s = n 2, provided a ρ of 0. 21.', 'when computed with our program with the exact same parameters ( without embedding them in the s = n model ), we obtained a ρ']","['or an', '1 the original relational model of  #TAUTHOR_TAG with s = n 2, provided a ρ of']","['ability of reliably comparing the meaning of single words with larger textual fragments, e. g. phrases or even sentences, can be an invaluable tool for many challenging nlp tasks, such as definition classification, paraphrasing, sentiment analysis, or even the simple everyday search on the internet.', 'in this task we examine the extent to which our models can correctly match a number of terms ( single words ) with a number of definitions ( phrases ).', 'to our knowledge, this is the first time a compositional distributional model is tested for its ability to match words with phrases.', 'our dataset consists of 112 terms ( 72 nouns and 40 verbs ) and their main definitions, extracted from the oxford junior dictionary  #AUTHOR_TAG.', 'for each term, and in order to get a richer dataset, we added two more definitions that expressed the same or an', '1 the original relational model of  #TAUTHOR_TAG with s = n 2, provided a ρ of 0. 21.', 'when computed with our program with the exact same parameters ( without embedding them in the s = n model ), we obtained a ρ of 0. 195.', 'the differences between both of these and our best model are statistically insignificant.', ' #AUTHOR_TAG b ), a direct non - relational model was used to compute verb matrices ; this provided a ρ of 0. 28.', 'however, as explained by the authors themselves, this method is not general and for instance cannot be used for intransitive verbs.', 'alternative meaning, using the entries from the oxford concise school dictionary  #AUTHOR_TAG or by paraphrasing with the wordnet synonyms of the words in the definitions.', 'so in total we obtained three definitions per term.', 'in all cases a definition for a noun - term is a noun phrase, whereas the definitions for the verb - terms consist of verb phrases.', 'for the latter case, we construct our verb vectors by summing over all context vectors of objects with which the verb appears in the corpus in a verb phrase ; that is, we use ver b = i − − → ob j i.', 'a sample of the dataset is shown in table 2 ; the complete dataset will be made available online.', 'we approach the evaluation problem as a classification task, where the terms have the role of the classes.', 'specifically, we calculate the distance between each definition and every term in the dataset, and the definition is assigned to the term that gives the higher similarity.', 'we evaluate the results by calculating accuracy ( table 3 ).', 'our model is referred to as the copy - object model ( cpobj ), and is compared with the multiplicative and additive models.', 'the copy - object and']",4
"['d n )  #TAUTHOR_TAG to θ ( d ),']","['n )  #TAUTHOR_TAG to θ ( d ),']","['d n )  #TAUTHOR_TAG to θ ( d ), making the problem much more tractable.', 'what remains to be solved is a theoretical issue, that in practice the meaning of relational words']","['work presented in this paper stems from the observation that the theory does not impose a special choice of sentence space, in particular it does not impose that tensors for s should have ranks greater than 1.', ""hence we stipulate that s = n and show how this instantiation works by performing the computations on the example transitive sentence'dogs chase cats '."", 'take − − → do g and −→ cat be the context vectors for the subject and the object, both living in n as prescribed by their types.', 'as any vector, these can be expressed as weighted sums of their basis vectors, that is,', '. by putting everything together, the meaning of the sentence is calculated as follows ; this result lives in n, since it is a weighted sum over − → n j :', 'an important consequence of our design decision is that it enables us to reduce the space complexity of the implementation from θ ( d n )  #TAUTHOR_TAG to θ ( d ), making the problem much more tractable.', ""what remains to be solved is a theoretical issue, that in practice the meaning of relational words such as'chase'as calculated by equation 5 is a matrix living in n 2 - however, the mathematical framework above prescribes that it should be a rank - 3 tensor in n 3."", 'the necessary expansions are achieved by using frobenius algebraic operations, for which the following sections first provide the mathematical definitions and then a linguistic justification']",6
"['described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['for transitive sentences described in  #TAUTHOR_TAG.', 'the goal is to assess how']","['first test our models against the disambiguation task for transitive sentences described in  #TAUTHOR_TAG.', 'the goal is to assess how well a model can discriminate between the different senses of an ambiguous verb, given the context ( subject and object ) of that verb.', 'the entries of this dataset consist of a target verb, a subject, an object, and a landmark verb used for the comparison.', 'one such entry for example is, "" write, pupil, name, spell "".', 'a good compositional model should be able to understand that the sentence "" pupil write name "" is closer to the sentence "" pupil spell name "" than, for example, to "" pupil publish name "".', 'on the other hand, given the context "" writer, book "" these results should be reversed.', 'the dataset contains 200 such entries with verbs from celex, hence 400 sentences.', ""the evaluation of this experiment is performed by calculating spearman's ρ correlation against the judgements of 25 human evaluators."", 'as our baselines we use an additive ( addtv ) and a multiplicative ( multp ) model, where the meaning of a sentence is computed by adding and point - wise multiplying, respectively, the context vectors of its words.', 'the results are shown in table 1.', 'the most successful s = n model for this task is the copyobject model, which is performing really close to the original relational model of  #TAUTHOR_TAG, with the difference to be statistically insignificant.', 'this is a promising result, since it suggests that the lower - dimensional new model performs similarly with the richer structure of the old model for transitive sentences, while at the same time allows generalisation to even more complex sentences 1.', 'more importantly, note that the categorical models are the only ones that respect the word order and grammatical structure of sentences ; a feature completely dismissed in the simple multiplicative model']",6
"['of  #TAUTHOR_TAG with s = n 2, provided a ρ of']","['of  #TAUTHOR_TAG with s = n 2, provided a ρ of 0. 21.', 'when computed with our program with the exact same parameters ( without embedding them in the s = n model ), we obtained a ρ']","['or an', '1 the original relational model of  #TAUTHOR_TAG with s = n 2, provided a ρ of']","['ability of reliably comparing the meaning of single words with larger textual fragments, e. g. phrases or even sentences, can be an invaluable tool for many challenging nlp tasks, such as definition classification, paraphrasing, sentiment analysis, or even the simple everyday search on the internet.', 'in this task we examine the extent to which our models can correctly match a number of terms ( single words ) with a number of definitions ( phrases ).', 'to our knowledge, this is the first time a compositional distributional model is tested for its ability to match words with phrases.', 'our dataset consists of 112 terms ( 72 nouns and 40 verbs ) and their main definitions, extracted from the oxford junior dictionary  #AUTHOR_TAG.', 'for each term, and in order to get a richer dataset, we added two more definitions that expressed the same or an', '1 the original relational model of  #TAUTHOR_TAG with s = n 2, provided a ρ of 0. 21.', 'when computed with our program with the exact same parameters ( without embedding them in the s = n model ), we obtained a ρ of 0. 195.', 'the differences between both of these and our best model are statistically insignificant.', ' #AUTHOR_TAG b ), a direct non - relational model was used to compute verb matrices ; this provided a ρ of 0. 28.', 'however, as explained by the authors themselves, this method is not general and for instance cannot be used for intransitive verbs.', 'alternative meaning, using the entries from the oxford concise school dictionary  #AUTHOR_TAG or by paraphrasing with the wordnet synonyms of the words in the definitions.', 'so in total we obtained three definitions per term.', 'in all cases a definition for a noun - term is a noun phrase, whereas the definitions for the verb - terms consist of verb phrases.', 'for the latter case, we construct our verb vectors by summing over all context vectors of objects with which the verb appears in the corpus in a verb phrase ; that is, we use ver b = i − − → ob j i.', 'a sample of the dataset is shown in table 2 ; the complete dataset will be made available online.', 'we approach the evaluation problem as a classification task, where the terms have the role of the classes.', 'specifically, we calculate the distance between each definition and every term in the dataset, and the definition is assigned to the term that gives the higher similarity.', 'we evaluate the results by calculating accuracy ( table 3 ).', 'our model is referred to as the copy - object model ( cpobj ), and is compared with the multiplicative and additive models.', 'the copy - object and']",6
"[' #TAUTHOR_TAG.', ' #AUTHOR_TAG observed that intentional small scale perturbations ( i. e., adversarial examples ) to']","[' #TAUTHOR_TAG.', ' #AUTHOR_TAG observed that intentional small scale perturbations ( i. e., adversarial examples ) to']","['joint tasks  #TAUTHOR_TAG.', ' #AUTHOR_TAG observed that intentional small scale perturbations ( i. e., adversarial examples ) to the input of such models']","['neural network methods have recently been exploited in various natural language processing ( nlp ) tasks, such as parsing, pos tagging  #AUTHOR_TAG, relation extraction ( dos  #AUTHOR_TAG, translation  #AUTHOR_TAG, and joint tasks  #TAUTHOR_TAG.', ' #AUTHOR_TAG observed that intentional small scale perturbations ( i. e., adversarial examples ) to the input of such models may lead to incorrect decisions ( with high confidence ).', ' #AUTHOR_TAG proposed adversarial training ( at ) ( for image recognition ) as a regularization method which uses a mixture of clean and adversarial examples to enhance the robustness of the model.', 'although at has recently been applied in nlp tasks ( e. g., text classification  #AUTHOR_TAG ), this paper - to the best of our knowledge - is the first attempt investigating regularization effects of at in a joint setting for two related tasks.', '']",5
"[' #TAUTHOR_TAG, who']","[' #TAUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less']","[' #TAUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less']","['crf - layer and ( iii ) character level embeddings. compared to  #TAUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less than 1 % ) on the joint task. on', 'the other hand,  #AUTHOR_TAG use the same model for the ade biomedical dataset, where we report a 2. 5 % overall improvement. this indicates that nlp tools are', 'not always accurate for various contexts. for the conll04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #AUTHOR_TAG ; adel and schutze ( 2017 ) on the ec task. the baseline model outperforms the', '']",5
"[' #TAUTHOR_TAG, who']","[' #TAUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less']","[' #TAUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less']","['crf - layer and ( iii ) character level embeddings. compared to  #TAUTHOR_TAG, who rely on nlp', 'tools, the baseline performs within a reasonable margin ( less than 1 % ) on the joint task. on', 'the other hand,  #AUTHOR_TAG use the same model for the ade biomedical dataset, where we report a 2. 5 % overall improvement. this indicates that nlp tools are', 'not always accurate for various contexts. for the conll04 dataset, we use two evaluation settings. we use the', 'relaxed evaluation similar to  #AUTHOR_TAG ; adel and schutze ( 2017 ) on the ec task. the baseline model outperforms the', '']",4
['to social media data  #TAUTHOR_TAG'],['pos taggers to social media data  #TAUTHOR_TAG'],"['pos taggers to social media data  #TAUTHOR_TAG.', 'additionally, lexical normalisation and other preprocessing strategies have been shown to enhance the performance of nlp tools over social media data  #AUTHOR_TAG han et al']","['', 'however, there have been recent successes in adapting parsers and pos taggers to social media data  #TAUTHOR_TAG.', 'additionally, lexical normalisation and other preprocessing strategies have been shown to enhance the performance of nlp tools over social media data  #AUTHOR_TAG han et al., to appear ).', 'furthermore, social media posts tend to be short and the content highly varied, meaning it is difficult to adapt a tool to the domain, or harness textual context to disambiguate the content.', 'there is also the engineering challenge of real - time processing of the text stream, as much of nlp research is carried out offline with only secondary concern for throughput.', 'as such, we might conclude that social media data is a foe of nlp, in that it challenges traditional assumptions made in nlp research on the nature of the target text and the requirements for real - time responsiveness.', 'however, if we look beyond the immediate text content of social media, we quickly realise that there are various non - textual data sources that can be used to enhance the robustness and accuracy of nlp models, in']",0
"[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '']","['for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","['##s that average between about 100 and 600 tokens  #AUTHOR_TAG, short answer scoring datasets may have average', 'answer lengths of just several words  #AUTHOR_TAG to almost 60 words  #AUTHOR_TAG. 2. rubrics focus', 'on content only in sas vs. broader writing quality in aes. 3. purpose and genre. aes tasks cover persuasive', ', narrative, and source - dependent reading comprehension and english language arts ( ela ), while sas tasks tend to be from science, math, and ela reading comprehension', '. given these differences, the feature sets for aes and sas systems are often different, with aes incorporating', 'a larger set of features to capture writing quality  #AUTHOR_TAG. nevertheless, deep learning approaches to aes have thus far demonstrated strong performance with minimal inputs consisting of unigrams and word embeddings. for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '##p - aes data.  #AUTHOR_TAG train score - specific word embeddings with several lstm architectures.  #AUTHOR_TAG demonstrate that a hierarchical cnn architecture produces strong results on the asap - aes data.  #AUTHOR_TAG show state - of - the', '- art performance on the asap - aes dataset with a memory network architecture. in this work', ', we investigate whether deep neural', 'network approaches with similarly minimal feature sets can produce good performance on the sas task, including whether they can exceed a strong non - neural baseline. unigram embeddingbased neural network approaches to essay scoring capture content', 'signals from their input features, but the extent to which they capture other aspects of writing quality rubrics has not been established. these approaches as implemented', 'would seem to lend themselves even better to the purely content - focused rubrics in sas, where content signals should dominate', 'in achieving good humanmachine agreement. on the other hand, recurrent neural networks may derive some of their predictive power in aes from', 'more redundant signals in longer input sequences ( as sketched by  #TAUTHOR_TAG', '. as a result, the shorter responses in sas may hinder the ability of recurrent networks to', 'achieve state - of - the - art results. to explore the effectiveness of neural network architectures on sas, we use', 'the basic architecture and parameters of  #TAUTHOR_TAG on three publicly available short answer datasets : asap - sas  #AUTHOR_TAG, powergrading  #AUTHOR_TAG, and sra  #AUTHOR_TAG ( dzikovska et al', '.,, 2013. while these datasets differ with respect to the length and complexity of student responses, all prompts in the datasets focus on content accuracy. we explore how well the optimal parameters', 'for aes from  #TAUTHOR_TAG fare on these datasets, and whether different architectures and parameters perform better on the sas task']",0
"[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '']","['for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","['##s that average between about 100 and 600 tokens  #AUTHOR_TAG, short answer scoring datasets may have average', 'answer lengths of just several words  #AUTHOR_TAG to almost 60 words  #AUTHOR_TAG. 2. rubrics focus', 'on content only in sas vs. broader writing quality in aes. 3. purpose and genre. aes tasks cover persuasive', ', narrative, and source - dependent reading comprehension and english language arts ( ela ), while sas tasks tend to be from science, math, and ela reading comprehension', '. given these differences, the feature sets for aes and sas systems are often different, with aes incorporating', 'a larger set of features to capture writing quality  #AUTHOR_TAG. nevertheless, deep learning approaches to aes have thus far demonstrated strong performance with minimal inputs consisting of unigrams and word embeddings. for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '##p - aes data.  #AUTHOR_TAG train score - specific word embeddings with several lstm architectures.  #AUTHOR_TAG demonstrate that a hierarchical cnn architecture produces strong results on the asap - aes data.  #AUTHOR_TAG show state - of - the', '- art performance on the asap - aes dataset with a memory network architecture. in this work', ', we investigate whether deep neural', 'network approaches with similarly minimal feature sets can produce good performance on the sas task, including whether they can exceed a strong non - neural baseline. unigram embeddingbased neural network approaches to essay scoring capture content', 'signals from their input features, but the extent to which they capture other aspects of writing quality rubrics has not been established. these approaches as implemented', 'would seem to lend themselves even better to the purely content - focused rubrics in sas, where content signals should dominate', 'in achieving good humanmachine agreement. on the other hand, recurrent neural networks may derive some of their predictive power in aes from', 'more redundant signals in longer input sequences ( as sketched by  #TAUTHOR_TAG', '. as a result, the shorter responses in sas may hinder the ability of recurrent networks to', 'achieve state - of - the - art results. to explore the effectiveness of neural network architectures on sas, we use', 'the basic architecture and parameters of  #TAUTHOR_TAG on three publicly available short answer datasets : asap - sas  #AUTHOR_TAG, powergrading  #AUTHOR_TAG, and sra  #AUTHOR_TAG ( dzikovska et al', '.,, 2013. while these datasets differ with respect to the length and complexity of student responses, all prompts in the datasets focus on content accuracy. we explore how well the optimal parameters', 'for aes from  #TAUTHOR_TAG fare on these datasets, and whether different architectures and parameters perform better on the sas task']",0
"[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '']","['for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","['##s that average between about 100 and 600 tokens  #AUTHOR_TAG, short answer scoring datasets may have average', 'answer lengths of just several words  #AUTHOR_TAG to almost 60 words  #AUTHOR_TAG. 2. rubrics focus', 'on content only in sas vs. broader writing quality in aes. 3. purpose and genre. aes tasks cover persuasive', ', narrative, and source - dependent reading comprehension and english language arts ( ela ), while sas tasks tend to be from science, math, and ela reading comprehension', '. given these differences, the feature sets for aes and sas systems are often different, with aes incorporating', 'a larger set of features to capture writing quality  #AUTHOR_TAG. nevertheless, deep learning approaches to aes have thus far demonstrated strong performance with minimal inputs consisting of unigrams and word embeddings. for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '##p - aes data.  #AUTHOR_TAG train score - specific word embeddings with several lstm architectures.  #AUTHOR_TAG demonstrate that a hierarchical cnn architecture produces strong results on the asap - aes data.  #AUTHOR_TAG show state - of - the', '- art performance on the asap - aes dataset with a memory network architecture. in this work', ', we investigate whether deep neural', 'network approaches with similarly minimal feature sets can produce good performance on the sas task, including whether they can exceed a strong non - neural baseline. unigram embeddingbased neural network approaches to essay scoring capture content', 'signals from their input features, but the extent to which they capture other aspects of writing quality rubrics has not been established. these approaches as implemented', 'would seem to lend themselves even better to the purely content - focused rubrics in sas, where content signals should dominate', 'in achieving good humanmachine agreement. on the other hand, recurrent neural networks may derive some of their predictive power in aes from', 'more redundant signals in longer input sequences ( as sketched by  #TAUTHOR_TAG', '. as a result, the shorter responses in sas may hinder the ability of recurrent networks to', 'achieve state - of - the - art results. to explore the effectiveness of neural network architectures on sas, we use', 'the basic architecture and parameters of  #TAUTHOR_TAG on three publicly available short answer datasets : asap - sas  #AUTHOR_TAG, powergrading  #AUTHOR_TAG, and sra  #AUTHOR_TAG ( dzikovska et al', '.,, 2013. while these datasets differ with respect to the length and complexity of student responses, all prompts in the datasets focus on content accuracy. we explore how well the optimal parameters', 'for aes from  #TAUTHOR_TAG fare on these datasets, and whether different architectures and parameters perform better on the sas task']",0
['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG'],['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG'],"['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG.', '']","['focus in this section is comparing different architecture and parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG.', 'table 2 shows the results of our experiments on the development set for asap - sas and powergrading, and table 3 shows the corresponding results for sra.', '']",0
"['parameter set in  #TAUTHOR_TAG', ': tuned embeddings ( here, glove 100 dimensions ),']","['parameter set in  #TAUTHOR_TAG', ': tuned embeddings ( here, glove 100 dimensions ),']","['parameter set in  #TAUTHOR_TAG', ': tuned embeddings ( here, glove 100 dimensions ),']","[' #TAUTHOR_TAG', ': tuned embeddings ( here, glove 100 dimensions ), 300 - dimensional lstm, unidirectional, mean - over - time', '']",0
"['parameter set in  #TAUTHOR_TAG', ': tuned embeddings ( here, glove 100 dimensions ),']","['parameter set in  #TAUTHOR_TAG', ': tuned embeddings ( here, glove 100 dimensions ),']","['parameter set in  #TAUTHOR_TAG', ': tuned embeddings ( here, glove 100 dimensions ),']","[' #TAUTHOR_TAG', ': tuned embeddings ( here, glove 100 dimensions ), 300 - dimensional lstm, unidirectional, mean - over - time', '']",0
"[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '']","['for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","['##s that average between about 100 and 600 tokens  #AUTHOR_TAG, short answer scoring datasets may have average', 'answer lengths of just several words  #AUTHOR_TAG to almost 60 words  #AUTHOR_TAG. 2. rubrics focus', 'on content only in sas vs. broader writing quality in aes. 3. purpose and genre. aes tasks cover persuasive', ', narrative, and source - dependent reading comprehension and english language arts ( ela ), while sas tasks tend to be from science, math, and ela reading comprehension', '. given these differences, the feature sets for aes and sas systems are often different, with aes incorporating', 'a larger set of features to capture writing quality  #AUTHOR_TAG. nevertheless, deep learning approaches to aes have thus far demonstrated strong performance with minimal inputs consisting of unigrams and word embeddings. for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '##p - aes data.  #AUTHOR_TAG train score - specific word embeddings with several lstm architectures.  #AUTHOR_TAG demonstrate that a hierarchical cnn architecture produces strong results on the asap - aes data.  #AUTHOR_TAG show state - of - the', '- art performance on the asap - aes dataset with a memory network architecture. in this work', ', we investigate whether deep neural', 'network approaches with similarly minimal feature sets can produce good performance on the sas task, including whether they can exceed a strong non - neural baseline. unigram embeddingbased neural network approaches to essay scoring capture content', 'signals from their input features, but the extent to which they capture other aspects of writing quality rubrics has not been established. these approaches as implemented', 'would seem to lend themselves even better to the purely content - focused rubrics in sas, where content signals should dominate', 'in achieving good humanmachine agreement. on the other hand, recurrent neural networks may derive some of their predictive power in aes from', 'more redundant signals in longer input sequences ( as sketched by  #TAUTHOR_TAG', '. as a result, the shorter responses in sas may hinder the ability of recurrent networks to', 'achieve state - of - the - art results. to explore the effectiveness of neural network architectures on sas, we use', 'the basic architecture and parameters of  #TAUTHOR_TAG on three publicly available short answer datasets : asap - sas  #AUTHOR_TAG, powergrading  #AUTHOR_TAG, and sra  #AUTHOR_TAG ( dzikovska et al', '.,, 2013. while these datasets differ with respect to the length and complexity of student responses, all prompts in the datasets focus on content accuracy. we explore how well the optimal parameters', 'for aes from  #TAUTHOR_TAG fare on these datasets, and whether different architectures and parameters perform better on the sas task']",5
"[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","[',  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '']","['for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on']","['##s that average between about 100 and 600 tokens  #AUTHOR_TAG, short answer scoring datasets may have average', 'answer lengths of just several words  #AUTHOR_TAG to almost 60 words  #AUTHOR_TAG. 2. rubrics focus', 'on content only in sas vs. broader writing quality in aes. 3. purpose and genre. aes tasks cover persuasive', ', narrative, and source - dependent reading comprehension and english language arts ( ela ), while sas tasks tend to be from science, math, and ela reading comprehension', '. given these differences, the feature sets for aes and sas systems are often different, with aes incorporating', 'a larger set of features to capture writing quality  #AUTHOR_TAG. nevertheless, deep learning approaches to aes have thus far demonstrated strong performance with minimal inputs consisting of unigrams and word embeddings. for example,  #TAUTHOR_TAG explore simple ls', '##tm and cnn - based', 'architectures with regression and evaluate on the asa', '##p - aes data.  #AUTHOR_TAG train score - specific word embeddings with several lstm architectures.  #AUTHOR_TAG demonstrate that a hierarchical cnn architecture produces strong results on the asap - aes data.  #AUTHOR_TAG show state - of - the', '- art performance on the asap - aes dataset with a memory network architecture. in this work', ', we investigate whether deep neural', 'network approaches with similarly minimal feature sets can produce good performance on the sas task, including whether they can exceed a strong non - neural baseline. unigram embeddingbased neural network approaches to essay scoring capture content', 'signals from their input features, but the extent to which they capture other aspects of writing quality rubrics has not been established. these approaches as implemented', 'would seem to lend themselves even better to the purely content - focused rubrics in sas, where content signals should dominate', 'in achieving good humanmachine agreement. on the other hand, recurrent neural networks may derive some of their predictive power in aes from', 'more redundant signals in longer input sequences ( as sketched by  #TAUTHOR_TAG', '. as a result, the shorter responses in sas may hinder the ability of recurrent networks to', 'achieve state - of - the - art results. to explore the effectiveness of neural network architectures on sas, we use', 'the basic architecture and parameters of  #TAUTHOR_TAG on three publicly available short answer datasets : asap - sas  #AUTHOR_TAG, powergrading  #AUTHOR_TAG, and sra  #AUTHOR_TAG ( dzikovska et al', '.,, 2013. while these datasets differ with respect to the length and complexity of student responses, all prompts in the datasets focus on content accuracy. we explore how well the optimal parameters', 'for aes from  #TAUTHOR_TAG fare on these datasets, and whether different architectures and parameters perform better on the sas task']",5
"['sas setting.', 'we took the best parameter set from  #TAUTHOR_TAG as our reference since it performed best on the aes data.', 'we looked at the effect of varying several important parameters to discern the effectiveness of each for sas']","['sas setting.', 'we took the best parameter set from  #TAUTHOR_TAG as our reference since it performed best on the aes data.', 'we looked at the effect of varying several important parameters to discern the effectiveness of each for sas :', '•']","['carried out a series of experiments across datasets to discern the effect of specific parameters in the sas setting.', 'we took the best parameter set from  #TAUTHOR_TAG as our reference since it performed best on the aes data.', 'we looked at the effect of varying several important parameters to discern the effectiveness of each for sas']","['carried out a series of experiments across datasets to discern the effect of specific parameters in the sas setting.', 'we took the best parameter set from  #TAUTHOR_TAG as our reference since it performed best on the aes data.', 'we looked at the effect of varying several important parameters to discern the effectiveness of each for sas :', '• the role of the mean - over - time layer, which was crucial for good performance in  #AUTHOR_TAG • the utility of pretrained embeddings', '']",5
['explored by  #TAUTHOR_TAG ( figure 4 )'],"['explored by  #TAUTHOR_TAG ( figure 4 ).', '3 first, the word tokens of each response are']",['explored by  #TAUTHOR_TAG ( figure 4 )'],"['work with the basic neural network architecture explored by  #TAUTHOR_TAG ( figure 4 ).', '3 first, the word tokens of each response are converted to embeddings.', 'optionally, features are extracted from the embeddings by a convolutional network layer.', '']",5
['explored by  #TAUTHOR_TAG ( figure 4 )'],"['explored by  #TAUTHOR_TAG ( figure 4 ).', '3 first, the word tokens of each response are']",['explored by  #TAUTHOR_TAG ( figure 4 )'],"['work with the basic neural network architecture explored by  #TAUTHOR_TAG ( figure 4 ).', '3 first, the word tokens of each response are converted to embeddings.', 'optionally, features are extracted from the embeddings by a convolutional network layer.', '']",5
"['following  #TAUTHOR_TAG.', 'the text is tokenized with']","['following  #TAUTHOR_TAG.', 'the text is tokenized with']","['as input to the neural networks following  #TAUTHOR_TAG.', 'the text is tokenized with the standard nltk tokenizer and lowercased.', 'all numbers are mapped to a single < num > symbol.', '4 each response is padded with a dummy token to uniform length, but these dummy tokens are masked out']","['text is lightly preprocessed as input to the neural networks following  #TAUTHOR_TAG.', 'the text is tokenized with the standard nltk tokenizer and lowercased.', 'all numbers are mapped to a single < num > symbol.', '4 each response is padded with a dummy token to uniform length, but these dummy tokens are masked out during model training.', 'for the asap - sas and powergrading datasets, prior to training, we scale all scores of responses to [ 0, 1 ] and use these scaled scores as input to the networks.', '']",5
"['test set ( section 3. 6 ).', 'following  #TAUTHOR_TAG, for']","['test set ( section 3. 6 ).', 'following  #TAUTHOR_TAG, for']","['on the test set ( section 3. 6 ).', 'following  #TAUTHOR_TAG, for']","['decay is a maximum decay rate, which we set to 0. 999.', 'this decay rate updating procedure allows the weights to be updated quickly at first while stabilizing across time.', 'all models are trained for 50 epochs for parameter exploration on the development set ( section 3. 5 ) and 50 epochs for the final models on the test set ( section 3. 6 ).', 'following  #TAUTHOR_TAG, for our parameter exploration experiments on the development set, we report the best performance across epochs.', 'when we train final models on the combined training and development set and evaluate on the test set, we report the results from the last epoch.', 'during development, we observed that even after employing best practices for ensuring repro - ducibility of results 5, there was still some small variation between runs of the same parameter settings.', 'the reasons for this variability were not clear']",5
['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG'],['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG'],"['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG.', '']","['focus in this section is comparing different architecture and parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG.', 'table 2 shows the results of our experiments on the development set for asap - sas and powergrading, and table 3 shows the corresponding results for sra.', '']",5
['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG'],['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG'],"['parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG.', '']","['focus in this section is comparing different architecture and parameter choices for the neural networks with the best parameters from  #TAUTHOR_TAG.', 'table 2 shows the results of our experiments on the development set for asap - sas and powergrading, and table 3 shows the corresponding results for sra.', '']",4
"['on many prompts, but contrary to  #TAUTHOR_TAG, bidirectional ls']","['on many prompts, but contrary to  #TAUTHOR_TAG, bidirectional lstms and attention produced']","['- time produced competitive results on many prompts, but contrary to  #TAUTHOR_TAG, bidirectional lstms and attention produced']","['', 'only the powergrading dataset, with very short answers and a small vocabulary for each prompt, benefitted from a significantly smaller lstm dimensionality.', 'the relationship between task, rubrics, vocabulary size, and the representational capacity of neural models for sas need further exploration.', 'third, a mean - over - time aggregation mechanism on top of the lstm generally performed well, but notably this mechanism was not nearly as important as in the aes task.', 'mean - over - time produced competitive results on many prompts, but contrary to  #TAUTHOR_TAG, bidirectional lstms and attention produced some of the best results, which is consistent with results for neural models on other text classification tasks ( e. g.,  #AUTHOR_TAG ).', ""research is needed to explain these emerging differences in effective neural architectures for aes vs. sas, including model - specific factors such as the interaction of an lstm's integration of features over time and the redundancy of predictive signals in essays vs. short answers, along with data - specific factors such as the consistency of human scoring, the demands of different rubrics, and the homogeneity or diversity of prompts in each setting."", 'at the same time, different from the aes task, the family of neural architectures explored here needs further augmenting to achieve state - of - the - art results on the sas task.', 'moreover, more experiments are needed to document how well neural systems perform relative to highly optimized non - neural systems.', 'while further parameter optimizations and different architectures may yield better results, it may be the case that the sas task of content scoring with relatively short response sequences requires neural approaches to employ a larger set of features  #AUTHOR_TAG or a greater level of prompt - specific tuning, or pairing with methods from active learning  #AUTHOR_TAG']",4
"['on many prompts, but contrary to  #TAUTHOR_TAG, bidirectional ls']","['on many prompts, but contrary to  #TAUTHOR_TAG, bidirectional lstms and attention produced']","['- time produced competitive results on many prompts, but contrary to  #TAUTHOR_TAG, bidirectional lstms and attention produced']","['', 'only the powergrading dataset, with very short answers and a small vocabulary for each prompt, benefitted from a significantly smaller lstm dimensionality.', 'the relationship between task, rubrics, vocabulary size, and the representational capacity of neural models for sas need further exploration.', 'third, a mean - over - time aggregation mechanism on top of the lstm generally performed well, but notably this mechanism was not nearly as important as in the aes task.', 'mean - over - time produced competitive results on many prompts, but contrary to  #TAUTHOR_TAG, bidirectional lstms and attention produced some of the best results, which is consistent with results for neural models on other text classification tasks ( e. g.,  #AUTHOR_TAG ).', ""research is needed to explain these emerging differences in effective neural architectures for aes vs. sas, including model - specific factors such as the interaction of an lstm's integration of features over time and the redundancy of predictive signals in essays vs. short answers, along with data - specific factors such as the consistency of human scoring, the demands of different rubrics, and the homogeneity or diversity of prompts in each setting."", 'at the same time, different from the aes task, the family of neural architectures explored here needs further augmenting to achieve state - of - the - art results on the sas task.', 'moreover, more experiments are needed to document how well neural systems perform relative to highly optimized non - neural systems.', 'while further parameter optimizations and different architectures may yield better results, it may be the case that the sas task of content scoring with relatively short response sequences requires neural approaches to employ a larger set of features  #AUTHOR_TAG or a greater level of prompt - specific tuning, or pairing with methods from active learning  #AUTHOR_TAG']",2
"['of humour anchors  #TAUTHOR_TAG, for improving the']","['of humour anchors  #TAUTHOR_TAG, for improving the']","['of humour anchors  #TAUTHOR_TAG, for improving the performance of semantic features and show that, while an intriguing idea, humour anchors contain several pitfalls that can hurt performance']","['paper attempts to marry the interpretability of statistical machine learning approaches with the more robust models of joke structure and joke semantics capable of being learned by neural models.', 'specifically, we explore the use of semantic relatedness features based on word associations, rather than the more common word2vec similarity, on a binary humour identification task and identify several factors that make word associations a better fit for humour.', 'we also explore the effects of using joke structure, in the form of humour anchors  #TAUTHOR_TAG, for improving the performance of semantic features and show that, while an intriguing idea, humour anchors contain several pitfalls that can hurt performance']",5
"['document  #TAUTHOR_TAG, and bear little resemblance to the way']","['word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way']","['word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way']","['particular, has received increased attention from the', 'nlp community with semeval - 2017 devoting two tasks to it : ranking humorous tweets  #AUTHOR_TAG and interpreting english puns  #AUTHOR_TAG.', 'this recent attention has lead to advancements such as sequence - based neural humour models capable of implicitly learning a joke structure and semantic features  #AUTHOR_TAG a ;  #AUTHOR_TAG', '. while these approaches offer good performance, their reliance on complicated neural architectures over explicitly engineered features present a problem for interpretability which may make it difficult to diagnose problems if results go wrong. works which take a more interpretable statistical machine', 'learning approach have their own drawbacks. for example, the representation of joke semantics has been fairly basic', ', typically computing word embedding similarities between all word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way humans actually interpret humour. additionally, many works fail to take advantage of joke structure, treating texts as unordered bags - of - words  #AUTHOR_TAG', 'b ;  #AUTHOR_TAG. this paper aims to marry the interpretability of statistical machine learning approaches with the more nuanced models of joke structure and joke semantics of', 'neural approaches. specifically, we explore the effectiveness modelling joke semantics using semantic relatedness features based on word associations, rather than the more common semantic similarity features based on word embeddings. we', 'present evidence not only that relatedness in general is better suited than similarity for computational hum', '##our tasks this work is licenced under a creative commons attribution 4. 0 international licence. licence details : http : / / creativecommons. org / licenses / by / 4. 0 /', 'due to its broader nature, but also that word associations are particularly well suited due to their ability to map more nuanced relationships  #AUTHOR_TAG and asymmetric', 'nature. while such features have been explored in the past  #AUTHOR_TAG b ), this work presents a more in depth analysis, focusing on a more fundamental task ( binary', 'humour classification vs. relative humour ranking ) on with a dataset that better represents natural language ( oneliners and puns vs. twitter hashtag games', '), and is the first work to incorporate interpolated word association strengths. furthermore, we introduce a novel method for targetting our semantic features using joke structure to help reduce noise and', 'increase reliability. specifically, we experiment with integrating the extraction of humour anchors, the "" meaningful, complete, minimal set of word spans ""  #TAUTHOR_TAG that allow humour to occur, into the humour classification process itself, the first work to do so. we', 'are also making the code used to run these experiments publicly available 1']",5
"['document  #TAUTHOR_TAG, and bear little resemblance to the way']","['word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way']","['word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way']","['particular, has received increased attention from the', 'nlp community with semeval - 2017 devoting two tasks to it : ranking humorous tweets  #AUTHOR_TAG and interpreting english puns  #AUTHOR_TAG.', 'this recent attention has lead to advancements such as sequence - based neural humour models capable of implicitly learning a joke structure and semantic features  #AUTHOR_TAG a ;  #AUTHOR_TAG', '. while these approaches offer good performance, their reliance on complicated neural architectures over explicitly engineered features present a problem for interpretability which may make it difficult to diagnose problems if results go wrong. works which take a more interpretable statistical machine', 'learning approach have their own drawbacks. for example, the representation of joke semantics has been fairly basic', ', typically computing word embedding similarities between all word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way humans actually interpret humour. additionally, many works fail to take advantage of joke structure, treating texts as unordered bags - of - words  #AUTHOR_TAG', 'b ;  #AUTHOR_TAG. this paper aims to marry the interpretability of statistical machine learning approaches with the more nuanced models of joke structure and joke semantics of', 'neural approaches. specifically, we explore the effectiveness modelling joke semantics using semantic relatedness features based on word associations, rather than the more common semantic similarity features based on word embeddings. we', 'present evidence not only that relatedness in general is better suited than similarity for computational hum', '##our tasks this work is licenced under a creative commons attribution 4. 0 international licence. licence details : http : / / creativecommons. org / licenses / by / 4. 0 /', 'due to its broader nature, but also that word associations are particularly well suited due to their ability to map more nuanced relationships  #AUTHOR_TAG and asymmetric', 'nature. while such features have been explored in the past  #AUTHOR_TAG b ), this work presents a more in depth analysis, focusing on a more fundamental task ( binary', 'humour classification vs. relative humour ranking ) on with a dataset that better represents natural language ( oneliners and puns vs. twitter hashtag games', '), and is the first work to incorporate interpolated word association strengths. furthermore, we introduce a novel method for targetting our semantic features using joke structure to help reduce noise and', 'increase reliability. specifically, we experiment with integrating the extraction of humour anchors, the "" meaningful, complete, minimal set of word spans ""  #TAUTHOR_TAG that allow humour to occur, into the humour classification process itself, the first work to do so. we', 'are also making the code used to run these experiments publicly available 1']",5
"['), collected in  #TAUTHOR_TAG, and 16000 one - liner (']","['( potd ), collected in  #TAUTHOR_TAG, and 16000 one - liner ( ol ), collected in  #AUTHOR_TAG.', 'potd']","['), collected in  #TAUTHOR_TAG, and 16000 one - liner (']","['evaluate our classifiers across two separate datasets : pun of the day ( potd ), collected in  #TAUTHOR_TAG, and 16000 one - liner ( ol ), collected in  #AUTHOR_TAG.', 'potd consists of positive examples collected from the pun of the day website 2 and negative examples collected from a combination of news sources, question / answer forums, and lists of proverbs  #TAUTHOR_TAG.', 'ol consists of positive examples scraped from humour websites and negative examples taken from a combination of new headlines, sentences from the british national corpus, and proverbs']",5
['using the method described in  #TAUTHOR_TAG using'],['using the method described in  #TAUTHOR_TAG using'],"['default, word association and word2vec features are computed across all word pairs in a document.', 'however, we also experiment computing these features only across pairs of humour anchor ( ha ) words.', 'has are extracted using the method described in  #TAUTHOR_TAG using the same baseline humour model described in']","['default, word association and word2vec features are computed across all word pairs in a document.', 'however, we also experiment computing these features only across pairs of humour anchor ( ha ) words.', 'has are extracted using the method described in  #TAUTHOR_TAG using the same baseline humour model described in section 3. 2 for anchor candidate evaluation.', ""ha extraction's requirement of a fully trained anchor candidate evaluator raises the problem of what data that evaluator should be trained on."", 'given that, as described in section 3. 1, we experiment on two separate humour datasets, we train the anchor candidate evaluator on the opposite dataset from the overall humour classifier.', 'this is to avoid overfitting or biasing the anchor candidate evaluator by training on the test data']",5
"['only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['mentioned in section 2. 2, using has for humour recognition is an appealing notion and would allow semantic features to be targeted only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['mentioned in section 2. 2, using has for humour recognition is an appealing notion and would allow semantic features to be targeted only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only makes has more intriguing.', 'unfortunately, as can be seen in table 1, ha targetting actually hurts the performance of our humour model.', 'one obvious suspect for this drop in performance is the quality of the extracted has, a sample of which is shown in extracted anchors were either incomplete, as is the case with dark and santa, or nonsensical, like profectionist.', ""as described in section 2. 2,  #TAUTHOR_TAG's ha extraction algorithm requires a fully trained humour model, the accuracy of which undoubtedly affects the quality of the extracted has."", '']",5
"['document  #TAUTHOR_TAG, and bear little resemblance to the way']","['word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way']","['word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way']","['particular, has received increased attention from the', 'nlp community with semeval - 2017 devoting two tasks to it : ranking humorous tweets  #AUTHOR_TAG and interpreting english puns  #AUTHOR_TAG.', 'this recent attention has lead to advancements such as sequence - based neural humour models capable of implicitly learning a joke structure and semantic features  #AUTHOR_TAG a ;  #AUTHOR_TAG', '. while these approaches offer good performance, their reliance on complicated neural architectures over explicitly engineered features present a problem for interpretability which may make it difficult to diagnose problems if results go wrong. works which take a more interpretable statistical machine', 'learning approach have their own drawbacks. for example, the representation of joke semantics has been fairly basic', ', typically computing word embedding similarities between all word pairs in a document  #TAUTHOR_TAG, and bear little resemblance to the way humans actually interpret humour. additionally, many works fail to take advantage of joke structure, treating texts as unordered bags - of - words  #AUTHOR_TAG', 'b ;  #AUTHOR_TAG. this paper aims to marry the interpretability of statistical machine learning approaches with the more nuanced models of joke structure and joke semantics of', 'neural approaches. specifically, we explore the effectiveness modelling joke semantics using semantic relatedness features based on word associations, rather than the more common semantic similarity features based on word embeddings. we', 'present evidence not only that relatedness in general is better suited than similarity for computational hum', '##our tasks this work is licenced under a creative commons attribution 4. 0 international licence. licence details : http : / / creativecommons. org / licenses / by / 4. 0 /', 'due to its broader nature, but also that word associations are particularly well suited due to their ability to map more nuanced relationships  #AUTHOR_TAG and asymmetric', 'nature. while such features have been explored in the past  #AUTHOR_TAG b ), this work presents a more in depth analysis, focusing on a more fundamental task ( binary', 'humour classification vs. relative humour ranking ) on with a dataset that better represents natural language ( oneliners and puns vs. twitter hashtag games', '), and is the first work to incorporate interpolated word association strengths. furthermore, we introduce a novel method for targetting our semantic features using joke structure to help reduce noise and', 'increase reliability. specifically, we experiment with integrating the extraction of humour anchors, the "" meaningful, complete, minimal set of word spans ""  #TAUTHOR_TAG that allow humour to occur, into the humour classification process itself, the first work to do so. we', 'are also making the code used to run these experiments publicly available 1']",0
"['pairs of vectors representing words in a document  #TAUTHOR_TAG kukovacec et al., 2017 ).', 'however, measuring incongru']","['pairs of vectors representing words in a document  #TAUTHOR_TAG kukovacec et al., 2017 ).', 'however, measuring incongruity and overlap in terms of similarity is a rather odd choice. just']","['pairs of vectors representing words in a document  #TAUTHOR_TAG kukovacec et al., 2017 ).', 'however, measuring incongru']","['ssth, we expect that punchlines that do not sufficiently overlap with their setup are unfunny as they do not flow logically from the context.', 'similarly, punchlines that are not sufficiently incongruent with their setup are unfunny as there is no re - evaluation.', 'as overlap and incongruity are difficult to measure directly, one common approach is instead to use word embeddings, such as word2vec  #AUTHOR_TAG, to calculate the cosine similarities between pairs of vectors representing words in a document  #TAUTHOR_TAG kukovacec et al., 2017 ).', 'however, measuring incongruity and overlap in terms of similarity is a rather odd choice. just because two scripts overlap does not imply they are similar.', 'in the "" doctor "" example in section 2, the two scripts, namely [ the patient is seeking medical advice ] and [ the patient is having an affair with the doctor\'s wife ], overlap in terms of the people and locations involved but otherwise are quite different.', 'similarly, incongruent scripts such as [ dog bites man ] and [ man bites dog ] are very similar in all but the assignment of the roles.', 'compared with similarity, relatedness is a much broader concept.', '']",0
"['semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG']","['features designed to', ""capture joke semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG's""]","['semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG']","['independent. this means poor models of joke structure can affect the performance of features designed to', 'capture joke semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG\'s "" incongruity "" feature set, maximum and minimum word embedding similarities between pairs of words in a document, perform fairly well.  #AUTHOR_TAG b ) takes a similar approach with', 'their word association features. the problems comes from the fact that both works compute these values across all possible pairs of words in a document. this can introduce noise as not all word pairs are meaningful ( e. g. pairs of stopwords ) and internally - cohesive setups and punchlines can bias maximum similarity scores. while this can be somewhat alleviated by judicial filtering of stopwords, this does not guarantee meaningful word pairs either.  #AUTHOR_TAG, in addition to their humour classifier, also', 'introduces a method for identifying jokes\'humour anchors ( has ), the "" meaningful, complete, minimal set', 'of word spans "" that allow humour to occur. while', ""this is slightly different from identifying a joke's setup and punchline, focusing only on pairs of has would help reducing noise by increasing the precision of meaningful word pairs selection without sacrificing recall. however,  #TAUTHOR_TAG does not use their extracted has to improve their humour"", '']",0
"['semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG']","['features designed to', ""capture joke semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG's""]","['semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG']","['independent. this means poor models of joke structure can affect the performance of features designed to', 'capture joke semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG\'s "" incongruity "" feature set, maximum and minimum word embedding similarities between pairs of words in a document, perform fairly well.  #AUTHOR_TAG b ) takes a similar approach with', 'their word association features. the problems comes from the fact that both works compute these values across all possible pairs of words in a document. this can introduce noise as not all word pairs are meaningful ( e. g. pairs of stopwords ) and internally - cohesive setups and punchlines can bias maximum similarity scores. while this can be somewhat alleviated by judicial filtering of stopwords, this does not guarantee meaningful word pairs either.  #AUTHOR_TAG, in addition to their humour classifier, also', 'introduces a method for identifying jokes\'humour anchors ( has ), the "" meaningful, complete, minimal set', 'of word spans "" that allow humour to occur. while', ""this is slightly different from identifying a joke's setup and punchline, focusing only on pairs of has would help reducing noise by increasing the precision of meaningful word pairs selection without sacrificing recall. however,  #TAUTHOR_TAG does not use their extracted has to improve their humour"", '']",0
"['semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG']","['features designed to', ""capture joke semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG's""]","['semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG']","['independent. this means poor models of joke structure can affect the performance of features designed to', 'capture joke semantics. despite the issues mentioned in section 2. 1,  #TAUTHOR_TAG\'s "" incongruity "" feature set, maximum and minimum word embedding similarities between pairs of words in a document, perform fairly well.  #AUTHOR_TAG b ) takes a similar approach with', 'their word association features. the problems comes from the fact that both works compute these values across all possible pairs of words in a document. this can introduce noise as not all word pairs are meaningful ( e. g. pairs of stopwords ) and internally - cohesive setups and punchlines can bias maximum similarity scores. while this can be somewhat alleviated by judicial filtering of stopwords, this does not guarantee meaningful word pairs either.  #AUTHOR_TAG, in addition to their humour classifier, also', 'introduces a method for identifying jokes\'humour anchors ( has ), the "" meaningful, complete, minimal set', 'of word spans "" that allow humour to occur. while', ""this is slightly different from identifying a joke's setup and punchline, focusing only on pairs of has would help reducing noise by increasing the precision of meaningful word pairs selection without sacrificing recall. however,  #TAUTHOR_TAG does not use their extracted has to improve their humour"", '']",0
"['), collected in  #TAUTHOR_TAG, and 16000 one - liner (']","['( potd ), collected in  #TAUTHOR_TAG, and 16000 one - liner ( ol ), collected in  #AUTHOR_TAG.', 'potd']","['), collected in  #TAUTHOR_TAG, and 16000 one - liner (']","['evaluate our classifiers across two separate datasets : pun of the day ( potd ), collected in  #TAUTHOR_TAG, and 16000 one - liner ( ol ), collected in  #AUTHOR_TAG.', 'potd consists of positive examples collected from the pun of the day website 2 and negative examples collected from a combination of news sources, question / answer forums, and lists of proverbs  #TAUTHOR_TAG.', 'ol consists of positive examples scraped from humour websites and negative examples taken from a combination of new headlines, sentences from the british national corpus, and proverbs']",0
"['to  #TAUTHOR_TAG, we']","['to  #TAUTHOR_TAG, we']","['to  #TAUTHOR_TAG, we compute the minimum, maximum, and average word2vec similarity between ordered word pairs.', 'not only']","['to  #TAUTHOR_TAG, we compute the minimum, maximum, and average word2vec similarity between ordered word pairs.', 'not only is this a common humour recognition feature  #TAUTHOR_TAG kukovacec et al., 2017 ), but it also acts as a point of comparison for word association strength.', '']",0
"['only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['mentioned in section 2. 2, using has for humour recognition is an appealing notion and would allow semantic features to be targeted only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['mentioned in section 2. 2, using has for humour recognition is an appealing notion and would allow semantic features to be targeted only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only makes has more intriguing.', 'unfortunately, as can be seen in table 1, ha targetting actually hurts the performance of our humour model.', 'one obvious suspect for this drop in performance is the quality of the extracted has, a sample of which is shown in extracted anchors were either incomplete, as is the case with dark and santa, or nonsensical, like profectionist.', ""as described in section 2. 2,  #TAUTHOR_TAG's ha extraction algorithm requires a fully trained humour model, the accuracy of which undoubtedly affects the quality of the extracted has."", '']",0
"['only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['mentioned in section 2. 2, using has for humour recognition is an appealing notion and would allow semantic features to be targeted only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['mentioned in section 2. 2, using has for humour recognition is an appealing notion and would allow semantic features to be targeted only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only makes has more intriguing.', 'unfortunately, as can be seen in table 1, ha targetting actually hurts the performance of our humour model.', 'one obvious suspect for this drop in performance is the quality of the extracted has, a sample of which is shown in extracted anchors were either incomplete, as is the case with dark and santa, or nonsensical, like profectionist.', ""as described in section 2. 2,  #TAUTHOR_TAG's ha extraction algorithm requires a fully trained humour model, the accuracy of which undoubtedly affects the quality of the extracted has."", '']",0
"[""version of  #TAUTHOR_TAG's highest""]","[""version of  #TAUTHOR_TAG's highest""]","[""own version of  #TAUTHOR_TAG's highest performing classifier."", 'this model was chosen']","[""our baseline we implemented our own version of  #TAUTHOR_TAG's highest performing classifier."", 'this model was chosen due to its high performance and its use of statistical machine learning techniques which make it a fair point of comparison.', 'features include, for each document, minimum and maximum word2vec similarities between all word pairs, the total number of word sense combinations in each document according to wordnet, minimum and maximum wordnet path similarities between all word pairs, number of words with negative / positive polarity as well as weak / strong subjectivities according to the  #AUTHOR_TAG sentiment lexicon, number of and length of longest alliteration and rhyme chains according to the cmu pronouncing dictionary 3, labels of the five nearest neighbours in the training set according to word frequencies, and an averaged word2vec embedding across all words for a total of 318 feature dimensions.', 'we then train a random forest classifier using the scikit - learn 4 python library with 100 estimators but otherwise default settings.', ""all word2vec features, including those described below, use google's pre - trained 300 dimension word2vec embeddings 5""]",6
"['to  #TAUTHOR_TAG, we']","['to  #TAUTHOR_TAG, we']","['to  #TAUTHOR_TAG, we compute the minimum, maximum, and average word2vec similarity between ordered word pairs.', 'not only']","['to  #TAUTHOR_TAG, we compute the minimum, maximum, and average word2vec similarity between ordered word pairs.', 'not only is this a common humour recognition feature  #TAUTHOR_TAG kukovacec et al., 2017 ), but it also acts as a point of comparison for word association strength.', '']",3
"['only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['mentioned in section 2. 2, using has for humour recognition is an appealing notion and would allow semantic features to be targeted only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only']","['mentioned in section 2. 2, using has for humour recognition is an appealing notion and would allow semantic features to be targeted only to meaningful word pairs, potentially increasing their effectiveness.', 'the wonderfully simple extraction method described in  #TAUTHOR_TAG only makes has more intriguing.', 'unfortunately, as can be seen in table 1, ha targetting actually hurts the performance of our humour model.', 'one obvious suspect for this drop in performance is the quality of the extracted has, a sample of which is shown in extracted anchors were either incomplete, as is the case with dark and santa, or nonsensical, like profectionist.', ""as described in section 2. 2,  #TAUTHOR_TAG's ha extraction algorithm requires a fully trained humour model, the accuracy of which undoubtedly affects the quality of the extracted has."", '']",3
"[' #TAUTHOR_TAG baseline.', 'one interesting aspect to note is that our model uses only 28 feature dimensions compared to  #TAUTHOR_TAG']","[' #TAUTHOR_TAG baseline.', ""one interesting aspect to note is that our model uses only 28 feature dimensions compared to  #TAUTHOR_TAG's 318."", 'while this is not exactly a fair comparison in']","['results of our experiments are reported in table 1.', 'in general, our model performs slightly worse than the  #TAUTHOR_TAG baseline.', 'one interesting aspect to note is that our model uses only 28 feature dimensions compared to  #TAUTHOR_TAG']","['results of our experiments are reported in table 1.', 'in general, our model performs slightly worse than the  #TAUTHOR_TAG baseline.', ""one interesting aspect to note is that our model uses only 28 feature dimensions compared to  #TAUTHOR_TAG's 318."", 'while this is not exactly a fair comparison in the case of our ml - based word association strengths ( our ml strength predictor takes 415 feature dimensions as input ), graph - based associations perform similarly and do truly use only 28 dimensions.', ""overall performance is similar across both datasets with the only notable exception being graph - based usf performing better on ol than potd. this is likely due to ol being better suited than potd to usf's relatively smaller set of associations ( 72, 176 pairs and 10, 617 unique words versus eat's 325, 588 and 23, 218 )""]",4
"[' #TAUTHOR_TAG baseline.', 'one interesting aspect to note is that our model uses only 28 feature dimensions compared to  #TAUTHOR_TAG']","[' #TAUTHOR_TAG baseline.', ""one interesting aspect to note is that our model uses only 28 feature dimensions compared to  #TAUTHOR_TAG's 318."", 'while this is not exactly a fair comparison in']","['results of our experiments are reported in table 1.', 'in general, our model performs slightly worse than the  #TAUTHOR_TAG baseline.', 'one interesting aspect to note is that our model uses only 28 feature dimensions compared to  #TAUTHOR_TAG']","['results of our experiments are reported in table 1.', 'in general, our model performs slightly worse than the  #TAUTHOR_TAG baseline.', ""one interesting aspect to note is that our model uses only 28 feature dimensions compared to  #TAUTHOR_TAG's 318."", 'while this is not exactly a fair comparison in the case of our ml - based word association strengths ( our ml strength predictor takes 415 feature dimensions as input ), graph - based associations perform similarly and do truly use only 28 dimensions.', ""overall performance is similar across both datasets with the only notable exception being graph - based usf performing better on ol than potd. this is likely due to ol being better suited than potd to usf's relatively smaller set of associations ( 72, 176 pairs and 10, 617 unique words versus eat's 325, 588 and 23, 218 )""]",4
"[',  #TAUTHOR_TAG showed that a']","['to natural language questions,  #TAUTHOR_TAG showed that a']","['.', 'by converting such kb queries to natural language questions,  #TAUTHOR_TAG showed that']","['', 'by converting such kb queries to natural language questions,  #TAUTHOR_TAG showed that a question answering ( qa ) system could be effectively applied to this task.', 'however,  #TAUTHOR_TAG relied on a modified qa model architecture and a dedicated slot - filling training corpus.', 'here, we investigate the utility of standard qa data and models for this task.', ""our results show that this approach is effective in the zero - shot and low - resource cases, and is more robust on a set of test instances that challenge the models'ability to identify relations between subject and object."", 'figure 1 gives an overview of using qa on the slot - filling task.', 'starting at the top right, a kb query is translated into a natural language question, which can then be fed into a qa model that has been trained on an appropriate resource.', 'when applied to a set of texts, this model needs to predict the correct answer within each text, including the possibility that a text contains no answer.', 'within this framework, we consider different models and training and test datasets, but we keep the translation of kb queries into natural language questions fixed, based on the crowd - sourced templates used by  #TAUTHOR_TAG']",6
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",6
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",6
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",6
"[' #TAUTHOR_TAG test set.', 'in particular, we']","[' #TAUTHOR_TAG test set.', 'in particular, we']","['above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between']","['this second experiment, we want to test the ability of the models decribed above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between the entity and the answer, rather than just recognising an answer phrase of the right type.', 'data we construct a challenge test set of negative examples based on sentences which are about the wrong entity but which do contain potential answers that are valid for the question and relation type.', '']",6
"[' #TAUTHOR_TAG test set.', 'in particular, we']","[' #TAUTHOR_TAG test set.', 'in particular, we']","['above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between']","['this second experiment, we want to test the ability of the models decribed above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between the entity and the answer, rather than just recognising an answer phrase of the right type.', 'data we construct a challenge test set of negative examples based on sentences which are about the wrong entity but which do contain potential answers that are valid for the question and relation type.', '']",6
"[' #TAUTHOR_TAG test set.', 'in particular, we']","[' #TAUTHOR_TAG test set.', 'in particular, we']","['above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between']","['this second experiment, we want to test the ability of the models decribed above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between the entity and the answer, rather than just recognising an answer phrase of the right type.', 'data we construct a challenge test set of negative examples based on sentences which are about the wrong entity but which do contain potential answers that are valid for the question and relation type.', '']",6
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",5
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",5
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",5
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",5
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",5
['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split'],['increasing quantities of the  #TAUTHOR_TAG entity split training set into the squ'],"['contain the answer, based on the spans provided by the annotators. in other words, we are left with the original', 'question and a paragraph relevant to the topic of that question, but which typically no longer contains sentences answering it. alongside these negative examples, we also retain the original squad instances as', 'positive examples. this process is applied to both the train and dev sets, allowing us to evaluate a model that uses only question answering data at training', 'time. we also construct a series of datasets that combine increasing quantities of the  #TAUTHOR_TAG entity split training set into the squad training set, to evaluate the benefits of squad when dedicated relation extraction data is limited. random samples of 10 3, 10', '4, 10 5 and 10 6  #TAUTHOR_TAG instances are added to', 'our squad training set, while leaving the squad dev dataset untouched. models we employ the same modified bidaf  #AUTHOR_TAG model as  #TAUTHOR_TAG', ', which uses an additional bias term to allow the model to signal when no answer is predicted within the text. evaluation following the approach of  #TAUTHOR_TAG,', '']",5
"[' #TAUTHOR_TAG test set.', 'in particular, we']","[' #TAUTHOR_TAG test set.', 'in particular, we']","['above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between']","['this second experiment, we want to test the ability of the models decribed above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between the entity and the answer, rather than just recognising an answer phrase of the right type.', 'data we construct a challenge test set of negative examples based on sentences which are about the wrong entity but which do contain potential answers that are valid for the question and relation type.', '']",5
"[' #TAUTHOR_TAG test set.', 'in particular, we']","[' #TAUTHOR_TAG test set.', 'in particular, we']","['above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between']","['this second experiment, we want to test the ability of the models decribed above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between the entity and the answer, rather than just recognising an answer phrase of the right type.', 'data we construct a challenge test set of negative examples based on sentences which are about the wrong entity but which do contain potential answers that are valid for the question and relation type.', '']",5
"[' #TAUTHOR_TAG test set.', 'in particular, we']","[' #TAUTHOR_TAG test set.', 'in particular, we']","['above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between']","['this second experiment, we want to test the ability of the models decribed above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between the entity and the answer, rather than just recognising an answer phrase of the right type.', 'data we construct a challenge test set of negative examples based on sentences which are about the wrong entity but which do contain potential answers that are valid for the question and relation type.', '']",5
"[' #TAUTHOR_TAG test set.', 'in particular, we']","[' #TAUTHOR_TAG test set.', 'in particular, we']","['above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between']","['this second experiment, we want to test the ability of the models decribed above to generalise to data beyond the  #TAUTHOR_TAG test set.', 'in particular, we want to verify that the bidaf model is able to recognise the assertion of a relation between the entity and the answer, rather than just recognising an answer phrase of the right type.', 'data we construct a challenge test set of negative examples based on sentences which are about the wrong entity but which do contain potential answers that are valid for the question and relation type.', '']",5
['slot filling  #TAUTHOR_TAG modify'],['slot filling  #TAUTHOR_TAG modify'],['slot filling  #TAUTHOR_TAG modify'],"['results on our challenge test set suggest that the model does not learn to examine the relation between the answer span and the relation subject unless the training data requires it.', 'in the case of squad, the multi - sentence paragraph structure around the answer provides enough potential distractors to overcome this issue.', ""other models may show different patterns of strength and weakness, but to be able to investigate and exploit further qa systems quickly would require a means of producing'no answer'predictions without the need to modify the model implementation."", '4 using an unmodified qa model for slot filling  #TAUTHOR_TAG modify the bidaf architecture to produce an additional output representing the probability that no answer is present in the text.', 'in this experiment, we investigate whether it is possible to adapt a qa model to the slot filling task without having to understand and modify its internal structure and implementation.', 'our approach merely requires prefixing all texts with a dummy token that stands in for the answer when no real answer is present.', 'data we train our models on a modified version of squad, which has been augmented with negative examples by removing answer spans, as described in section 2, and then had the token noanswerfound inserted into every text and as the answer for the negative examples, as described above.', 'models we train both bidaf  #AUTHOR_TAG and fastqa  #AUTHOR_TAG models on the modified squad training data, using their standard architectures and hyperparameters.', 'evaluation we evaluate f1 on the same zeroshot evaluation considered in section 2 and also accuracy on the challenge test set from section 3.', 'results table 3 reveals that the unmodified bidaf model is almost as effective as the  #TAUTHOR_TAG test set.', ""in contrast, fastqa's performance is substantially worse."", ""however, table 4 reveals that fastqa is extremely accurate on the challenge test set, while bidaf's performance is comparable to the modified model trained on squad."", 'discussion the unmodified bidaf and fastqa architectures have complementary strengths on the two evaluations.', ""fastqa's strong performance on the challenge instances may be related to its use of binary features indicating whether a word was present in the question""]",5
"['.', 'we extend the morphochains system  #TAUTHOR_TAG to provide morphological analyses that can abstract over spe']","['other.', 'we extend the morphochains system  #TAUTHOR_TAG to provide morphological analyses that can abstract over spelling differences in functionally similar morphs.', '']","['', 'we extend the morphochains system  #TAUTHOR_TAG to provide morphological analyses that can abstract over spe']","['major motivation for unsupervised morphological analysis is to reduce the sparse data problem in under - resourced languages.', 'most previous work focuses on segmenting surface forms into their constituent morphs ( e. g., taking : tak + ing ), but surface form segmentation does not solve the sparse data problem as the analyses of take and taking are not connected to each other.', 'we extend the morphochains system  #TAUTHOR_TAG to provide morphological analyses that can abstract over spelling differences in functionally similar morphs.', 'these analyses are not required to use all the orthographic material of a word ( stopping : stop + ing ), nor are they limited to only that material ( acidified : acid + ify + ed ).', 'on average across six typologically varied languages our system has a similar or better f - score on emma ( a measure of underlying morpheme accuracy ) than three strong baselines ; moreover, the total number of distinct morphemes identified by our system is on average 12. 8 % lower than for morfessor  #AUTHOR_TAG, a stateof - the - art surface segmentation system']",6
['system  #TAUTHOR_TAG'],['system  #TAUTHOR_TAG'],"[' #AUTHOR_TAG.', 'we present a system that adapts the unsupervised morphochains segmentation system  #TAUTHOR_TAG']","['', 'we present a system that adapts the unsupervised morphochains segmentation system  #TAUTHOR_TAG to provide morphological analyses that aim to abstract over spelling differences in functionally similar morphemes.', 'like morphochains, our system uses an unsupervised log - linear model whose parameters are learned using contrastive estimation  #AUTHOR_TAG.', 'the original morphochains system learns to identify child - parent pairs of morphologically related words, where the child ( e. g., stopping ) is formed from the parent ( stop ) by adding an affix and possibly a spelling transformation ( both represented as features in the model ).', 'however, these spelling transformations are never used to output underlying morphemes, instead the system just returns a segmentation by post - processing the inferred child - parent pairs.', 'we extend the morphochains system in sev - eral ways : first, we use the spelling transformation features to output underlying morphemes for each word rather than a segmentation ; second, we broaden the types of morphological changes that can be identified to include compounds ; and third, we modify the set of features used in the log - linear model to improve the overall']",6
"['morphochains segmentation system  #TAUTHOR_TAG, 1 which defines a morphological chain as a sequence of']","['morphochains segmentation system  #TAUTHOR_TAG, 1 which defines a morphological chain as a sequence of']","['base our work on the morphochains segmentation system  #TAUTHOR_TAG, 1 which defines a morphological chain as a sequence of']","['base our work on the morphochains segmentation system  #TAUTHOR_TAG, 1 which defines a morphological chain as a sequence of child - parent pairs.', 'each pair consists of two morphologically related words where the child must be longer than the parent.', ""to analyse a word we want to find the best parent for that word ; we do so recursively until we conclude that the stop condition is met ( i. e. a word doesn't have a morphological parent )."", 'the word standardizes, for example, produces the following chain :', '']",5
"['parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a']","['pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a']","['parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by']","['predict child - parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a feature vector φ : w × z → r d, where w is a set of words and z is the set of ( parent, type ) pairs for words in w. the model defines the conditional probability of a particular ( parent, type ) pair z ∈ z given word w ∈ w as :', 'step word where c ( w ) ⊂ z denotes the set of parent candidates for w and θ is a weight vector.', 'our goal is to learn the feature weights in an unsupervised fashion.', 'following  #TAUTHOR_TAG, we do so using contrastive estimation ( ce )  #AUTHOR_TAG.', ""in ce every training example w ∈ w serves as both a positive example and a set of implied negative examples - strings that are similar to w but don't occur in the corpus."", 'the negative examples are the source of the probability mass allocated to the positive examples.', 'the word w and its negative examples constitute the neighbourhood n ( w ) of w.', 'given the list of words w and their neighbourhoods, the ce likelihood is defined as :', 'we use the same neighbourhood functions as  #TAUTHOR_TAG.', 'specifically, for each word w in the corpus w, we create neighbours in two ways : by swapping two adjacent characters of w ( walking→walkign ) and by swapping two pairs of adjacent characters, where one pair is at the beginning of the word, and the other at the end of the word ( walking→awlkign ).', 'we use lbfgs - b  #AUTHOR_TAG to optimize the regularized log - likelihood of the model']",5
"['parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a']","['pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a']","['parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by']","['predict child - parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a feature vector φ : w × z → r d, where w is a set of words and z is the set of ( parent, type ) pairs for words in w. the model defines the conditional probability of a particular ( parent, type ) pair z ∈ z given word w ∈ w as :', 'step word where c ( w ) ⊂ z denotes the set of parent candidates for w and θ is a weight vector.', 'our goal is to learn the feature weights in an unsupervised fashion.', 'following  #TAUTHOR_TAG, we do so using contrastive estimation ( ce )  #AUTHOR_TAG.', ""in ce every training example w ∈ w serves as both a positive example and a set of implied negative examples - strings that are similar to w but don't occur in the corpus."", 'the negative examples are the source of the probability mass allocated to the positive examples.', 'the word w and its negative examples constitute the neighbourhood n ( w ) of w.', 'given the list of words w and their neighbourhoods, the ce likelihood is defined as :', 'we use the same neighbourhood functions as  #TAUTHOR_TAG.', 'specifically, for each word w in the corpus w, we create neighbours in two ways : by swapping two adjacent characters of w ( walking→walkign ) and by swapping two pairs of adjacent characters, where one pair is at the beginning of the word, and the other at the end of the word ( walking→awlkign ).', 'we use lbfgs - b  #AUTHOR_TAG to optimize the regularized log - likelihood of the model']",5
"['parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a']","['pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a']","['parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by']","['predict child - parent pairs using a log - linear model, following  #TAUTHOR_TAG.', 'the model consists of a set of features represented by a feature vector φ : w × z → r d, where w is a set of words and z is the set of ( parent, type ) pairs for words in w. the model defines the conditional probability of a particular ( parent, type ) pair z ∈ z given word w ∈ w as :', 'step word where c ( w ) ⊂ z denotes the set of parent candidates for w and θ is a weight vector.', 'our goal is to learn the feature weights in an unsupervised fashion.', 'following  #TAUTHOR_TAG, we do so using contrastive estimation ( ce )  #AUTHOR_TAG.', ""in ce every training example w ∈ w serves as both a positive example and a set of implied negative examples - strings that are similar to w but don't occur in the corpus."", 'the negative examples are the source of the probability mass allocated to the positive examples.', 'the word w and its negative examples constitute the neighbourhood n ( w ) of w.', 'given the list of words w and their neighbourhoods, the ce likelihood is defined as :', 'we use the same neighbourhood functions as  #TAUTHOR_TAG.', 'specifically, for each word w in the corpus w, we create neighbours in two ways : by swapping two adjacent characters of w ( walking→walkign ) and by swapping two pairs of adjacent characters, where one pair is at the beginning of the word, and the other at the end of the word ( walking→awlkign ).', 'we use lbfgs - b  #AUTHOR_TAG to optimize the regularized log - likelihood of the model']",5
"[' #TAUTHOR_TAG.', 'stopcos = y is the maximum cosine similarity between the']","[' #TAUTHOR_TAG.', 'stopcos = y is the maximum cosine similarity between the']","[' #TAUTHOR_TAG.', 'stopcos = y is the maximum cosine similarity between the word and']","['therefore modify the affix features in two ways.', 'first, we identify a more precise set of likely affixes using letter successor entropy ( lse ) values  #AUTHOR_TAG, which are typically high at morph boundaries.', 'lse is computed at each point in the word as the entropy of the distribution over the next character given the word prefix so far.', 'when selecting likely affixes, we use an lse threshold value of 3. 0 as suggested by  #AUTHOR_TAG, and we require that the affix has appeared in at least 50 types with a corpus frequency of at least 100.', 'we then define two features ( preflist, suflist ), which are active if the proposed prefix or suffix for a parent - child pair is in the set of likely prefixes or suffixes.', 'table 4 shows the list of likely english affixes found by using lse ( 62 suffixes and 42 prefixes ).', 'for german and turkish, our other two development languages ( see § 3 ), the lists contain 498 suffixes / 183 prefixes and 181 suffixes / 35 prefixes, respectively.', '4 in addition, we use a much larger set of affix features, pref = x and suf = x, where x is instantiated with all possible word prefixes ( suffixes ) for which both w and xw ( wx ) are words in the training data.', 'transformations to help distinguish between probable and improbable transformations, we introduce transformation - specific features.', 'for deletion we use the deleted letter ( deleted ).', 'for repetition we use the repeated letter and its preceding 2 - and 1 - character contexts ( repeated, renv2 renv1 ).', 'for modification we use the combination of the involved letters ( modified ).', 'finally, for compounding we use the headword ( i. e. the parent of the compound ), the modifier and the connector, if such exists ( head, modifier, connector ).', 'since these compound features can be very sparse, we also add a single compound feature, which is active when both parts of the compound are present in the training data.', 'stop condition to identify words with no parents we use two types of binary features suggested by  #TAUTHOR_TAG.', 'stopcos = y is the maximum cosine similarity between the word and any of its parent candidates ( using bins of size 0. 1 ), and stoplen = x is instantiated for all possible word lengths x in the training data.', 'for illustration, if we are considering whether decided is a word with no parents ( table']",5
"['', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important']","['affix occurrence frequencies as used by', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important']","['', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important for english ( + 3']","['every language, and is a clear improvement over the original morphochains. 8 lang method to see', 'where the benefit is coming from, we performed ablation tests ( table 7 ). results show the importance of the lse - based affix features ( model - a ). using these features gives gains of + 1. 0 %, 3. 8 % and 0. 6', '% f - 1 absolute on english, german and turkish respectively over using the raw affix occurrence frequencies as used by', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important for english ( + 3. 5', '% ) and german ( + 1. 1 % ).', 'although we expected that the data selection scheme would have the biggest impact on turkish because of its small training data, it has very little effect on this language. as expected, the compounding transformation ( model - c', ') has a prominent impact on german ( + 2. 7 % ) and a modest effect on english and turkish. the three features preflist, suflist, compound ( model -', ""b ) have the least impact on the model's performance ( on average 0. 5 % f - 1 absolute ), however the effect is substantial considering that this gain is achieved their hyperparameters separately for each language. finally, it"", 'is not clear how they tuned the frequency - related hyperparameters for morfessor. we found that morfessor performed better than morphochains when either low frequency', 'words are pruned from its input, or its log - frequency option is used rather than raw frequency.', 'by merely 3 features as opposed to a new feature type with many instantiations. table 8 shows some example outputs for english, german and turkish', '. these analyses include some correctly identified spe', '##lling changes ( example 1 ) compounds ( example 4 ), and purely concatenative morphology ( example 6', '). in example 2, + ble is counted as incorrect because our model predicts + ble both for deplorable and reproducible while the reference analysis', 'uses able s and ible s, respectively. since emma uses one - to - one alignment, it', 'deems one of the alignments wrong. the opposite problem occurs in example 4 : our', 'model analyses aus in two ways, either as a prefix aus + or as a separate word aus ( part of a compound', '), whereas the reference analysis always treats it as a separate word aus. example 6 illustrates an oversegment', '##ation error, caused by encountering two similar forms of the verb giy, giymeyi', '##n and giymeyi']",5
"['', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important']","['affix occurrence frequencies as used by', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important']","['', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important for english ( + 3']","['every language, and is a clear improvement over the original morphochains. 8 lang method to see', 'where the benefit is coming from, we performed ablation tests ( table 7 ). results show the importance of the lse - based affix features ( model - a ). using these features gives gains of + 1. 0 %, 3. 8 % and 0. 6', '% f - 1 absolute on english, german and turkish respectively over using the raw affix occurrence frequencies as used by', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important for english ( + 3. 5', '% ) and german ( + 1. 1 % ).', 'although we expected that the data selection scheme would have the biggest impact on turkish because of its small training data, it has very little effect on this language. as expected, the compounding transformation ( model - c', ') has a prominent impact on german ( + 2. 7 % ) and a modest effect on english and turkish. the three features preflist, suflist, compound ( model -', ""b ) have the least impact on the model's performance ( on average 0. 5 % f - 1 absolute ), however the effect is substantial considering that this gain is achieved their hyperparameters separately for each language. finally, it"", 'is not clear how they tuned the frequency - related hyperparameters for morfessor. we found that morfessor performed better than morphochains when either low frequency', 'words are pruned from its input, or its log - frequency option is used rather than raw frequency.', 'by merely 3 features as opposed to a new feature type with many instantiations. table 8 shows some example outputs for english, german and turkish', '. these analyses include some correctly identified spe', '##lling changes ( example 1 ) compounds ( example 4 ), and purely concatenative morphology ( example 6', '). in example 2, + ble is counted as incorrect because our model predicts + ble both for deplorable and reproducible while the reference analysis', 'uses able s and ible s, respectively. since emma uses one - to - one alignment, it', 'deems one of the alignments wrong. the opposite problem occurs in example 4 : our', 'model analyses aus in two ways, either as a prefix aus + or as a separate word aus ( part of a compound', '), whereas the reference analysis always treats it as a separate word aus. example 6 illustrates an oversegment', '##ation error, caused by encountering two similar forms of the verb giy, giymeyi', '##n and giymeyi']",5
"['', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important']","['affix occurrence frequencies as used by', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important']","['', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important for english ( + 3']","['every language, and is a clear improvement over the original morphochains. 8 lang method to see', 'where the benefit is coming from, we performed ablation tests ( table 7 ). results show the importance of the lse - based affix features ( model - a ). using these features gives gains of + 1. 0 %, 3. 8 % and 0. 6', '% f - 1 absolute on english, german and turkish respectively over using the raw affix occurrence frequencies as used by', ' #TAUTHOR_TAG. we can see that our data selection scheme ( model - d ) is important for english ( + 3. 5', '% ) and german ( + 1. 1 % ).', 'although we expected that the data selection scheme would have the biggest impact on turkish because of its small training data, it has very little effect on this language. as expected, the compounding transformation ( model - c', ') has a prominent impact on german ( + 2. 7 % ) and a modest effect on english and turkish. the three features preflist, suflist, compound ( model -', ""b ) have the least impact on the model's performance ( on average 0. 5 % f - 1 absolute ), however the effect is substantial considering that this gain is achieved their hyperparameters separately for each language. finally, it"", 'is not clear how they tuned the frequency - related hyperparameters for morfessor. we found that morfessor performed better than morphochains when either low frequency', 'words are pruned from its input, or its log - frequency option is used rather than raw frequency.', 'by merely 3 features as opposed to a new feature type with many instantiations. table 8 shows some example outputs for english, german and turkish', '. these analyses include some correctly identified spe', '##lling changes ( example 1 ) compounds ( example 4 ), and purely concatenative morphology ( example 6', '). in example 2, + ble is counted as incorrect because our model predicts + ble both for deplorable and reproducible while the reference analysis', 'uses able s and ible s, respectively. since emma uses one - to - one alignment, it', 'deems one of the alignments wrong. the opposite problem occurs in example 4 : our', 'model analyses aus in two ways, either as a prefix aus + or as a separate word aus ( part of a compound', '), whereas the reference analysis always treats it as a separate word aus. example 6 illustrates an oversegment', '##ation error, caused by encountering two similar forms of the verb giy, giymeyi', '##n and giymeyi']",5
['in morphochains :  #TAUTHOR_TAG concluded that up to'],['in morphochains :  #TAUTHOR_TAG concluded that up to'],"['embeddings  #AUTHOR_TAG.', 'semantic similarity was an important feature in morphochains :  #TAUTHOR_TAG concluded that up to 25 percent of their model']","['want features that signal which parents are valid words.', "" #AUTHOR_TAG used each word's log frequency."", 'however the majority of words in the training data ( word frequency lists ) occur only once, which makes their frequency information unreliable.', ""3 instead, we use an out - of - vocabulary feature ( oov ) for parents that don't occur in the training data."", 'semantic similarity morphologically related words exhibit semantic similarity among their word embeddings  #AUTHOR_TAG.', ""semantic similarity was an important feature in morphochains :  #TAUTHOR_TAG concluded that up to 25 percent of their model's precision was due to the semantic similarity feature."", 'we use the same feature here ( cos ).', 'for a child - parent pair ( w a, w b ) with word embeddings v w a and v w b respectively we compute semantic similarity as :', 'affixes candidate pairs where the child contains a frequently occurring affix are more likely to be correct.', 'to identify possible affixes to use as features,  #TAUTHOR_TAG counted the number of words that end ( or start ) with each substring table 3 : examples illustrating which of the binary features in the model are active for various potential child - parent pairs.', 'not shown here is the real - valued semantic similarity feature cos, used in all examples except 9 and 10, where it is replaced by the binary feature stopcos = y, for y in increments of 0. 1.', 'al, ar, ba, be, bo, ca, car, co, de, dis, en, ha, ho, in, inter, la, le, li, lo, ma, mar, mc, mi, mis, mo, out, over, pa, po, pre, pro, ra, re, ro, se, ta, to, un, under, up suffixes a, age, al, an, ar, ary, as, ation, b, ble, ch, e, ed, el, en, er, ers, es, est, et, ful, i, ia, ic, ie, ies, in, ing, ings, is, ism, ist, ists, land, le, led, les, less, ley, ling, ly, m, man, ment, ments, ner, ness, o, or, p, s, se, son, t, ted, ter, ters, th, ting, ton, ts, y and selected the most frequent ones.', 'however, all words that end with ing also end with ng and g, which means that']",0
['in morphochains :  #TAUTHOR_TAG concluded that up to'],['in morphochains :  #TAUTHOR_TAG concluded that up to'],"['embeddings  #AUTHOR_TAG.', 'semantic similarity was an important feature in morphochains :  #TAUTHOR_TAG concluded that up to 25 percent of their model']","['want features that signal which parents are valid words.', "" #AUTHOR_TAG used each word's log frequency."", 'however the majority of words in the training data ( word frequency lists ) occur only once, which makes their frequency information unreliable.', ""3 instead, we use an out - of - vocabulary feature ( oov ) for parents that don't occur in the training data."", 'semantic similarity morphologically related words exhibit semantic similarity among their word embeddings  #AUTHOR_TAG.', ""semantic similarity was an important feature in morphochains :  #TAUTHOR_TAG concluded that up to 25 percent of their model's precision was due to the semantic similarity feature."", 'we use the same feature here ( cos ).', 'for a child - parent pair ( w a, w b ) with word embeddings v w a and v w b respectively we compute semantic similarity as :', 'affixes candidate pairs where the child contains a frequently occurring affix are more likely to be correct.', 'to identify possible affixes to use as features,  #TAUTHOR_TAG counted the number of words that end ( or start ) with each substring table 3 : examples illustrating which of the binary features in the model are active for various potential child - parent pairs.', 'not shown here is the real - valued semantic similarity feature cos, used in all examples except 9 and 10, where it is replaced by the binary feature stopcos = y, for y in increments of 0. 1.', 'al, ar, ba, be, bo, ca, car, co, de, dis, en, ha, ho, in, inter, la, le, li, lo, ma, mar, mc, mi, mis, mo, out, over, pa, po, pre, pro, ra, re, ro, se, ta, to, un, under, up suffixes a, age, al, an, ar, ary, as, ation, b, ble, ch, e, ed, el, en, er, ers, es, est, et, ful, i, ia, ic, ie, ies, in, ing, ings, is, ism, ist, ists, land, le, led, les, less, ley, ling, ly, m, man, ment, ments, ner, ness, o, or, p, s, se, son, t, ted, ter, ters, th, ting, ton, ts, y and selected the most frequent ones.', 'however, all words that end with ing also end with ng and g, which means that']",0
"['( mert ) [ 2,  #TAUTHOR_TAG or a variant']","['( mert ) [ 2,  #TAUTHOR_TAG or a variant']","['( mert ) [ 2,  #TAUTHOR_TAG or a variant']","['of the art statistical machine translation ( smt ) models traditionally consist of a small number ( < 20 ) of sub - models whose scores are linearly combined to choose the best translation candidate.', 'the weights of this linear combination are usually trained to maximise some automatic translation metric ( e. g. bleu ) [ 1 ] using minimum error rate training ( mert ) [ 2,  #TAUTHOR_TAG or a variant of the margin infused relaxed algorithm ( mira ) [ 4, 5 ].', 'these algorithms are heavily adapted to exploit the properties of the translation search space.', 'in this paper we introduce generic, effective, and efficient bayesian optimisation ( bo ) algorithms [ 6, 7 ] for training the weights of smt systems for arbitrary metrics that outperform both mert and mira.', 'to our knowledge this is the first application of bo in natural language processing ( nlp ) and our results show that their may be significant scope for using bo to tune hyperparameter in a range of nlp models.', 'the linear model popular for smt systems [ 2 ] is parametrised in terms of a source sentence f, target translation e, feature weights w k and corresponding feature functions h k ( e, f ) ( including a language model, conditional translation probabilities, etc. ).', '']",0
"['( mert ) [ 2,  #TAUTHOR_TAG or a variant']","['( mert ) [ 2,  #TAUTHOR_TAG or a variant']","['( mert ) [ 2,  #TAUTHOR_TAG or a variant']","['of the art statistical machine translation ( smt ) models traditionally consist of a small number ( < 20 ) of sub - models whose scores are linearly combined to choose the best translation candidate.', 'the weights of this linear combination are usually trained to maximise some automatic translation metric ( e. g. bleu ) [ 1 ] using minimum error rate training ( mert ) [ 2,  #TAUTHOR_TAG or a variant of the margin infused relaxed algorithm ( mira ) [ 4, 5 ].', 'these algorithms are heavily adapted to exploit the properties of the translation search space.', 'in this paper we introduce generic, effective, and efficient bayesian optimisation ( bo ) algorithms [ 6, 7 ] for training the weights of smt systems for arbitrary metrics that outperform both mert and mira.', 'to our knowledge this is the first application of bo in natural language processing ( nlp ) and our results show that their may be significant scope for using bo to tune hyperparameter in a range of nlp models.', 'the linear model popular for smt systems [ 2 ] is parametrised in terms of a source sentence f, target translation e, feature weights w k and corresponding feature functions h k ( e, f ) ( including a language model, conditional translation probabilities, etc. ).', '']",0
"['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","[""comprehension is an intriguing task that assesses a machine's ability in understanding evidence contexts through question answering."", ""most previous work in reading comprehension has focused on either formal documents rajpurkar et al. [ 2016 ] or children's stories richardson, burges, and renshaw [ 2013 ]."", 'only few approaches have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with the explosive expansion of social media, data on dialogue has become dominant on the web.', 'inspired by various options of analytic models and the potential of the dialogue processing market, we extend the corpus presented by  #TAUTHOR_TAG for comprehensive predictions of personal entities in multiparty dialogue and develop deep learning models to make robust inference on their contexts.', 'passage completion on multiparty dialogue is one of the reading comprehension tasks that requires a model to match the conversational dialogues with the formal ( passage ) writings.', 'by building a robust model for this task, people can tell the status of their favorite characters by checking synopsis to see if their favorite characters appear in specific episodes without watching the entire series, thus allowing them an efficient way to decide whether to watch a particular episode.', 'involving matching contexts between colloquial ( dialog ) and formal ( passage ) writings makes this task extremely challenging.', 'distinguished from the previous work that only focused on a single variable per passage  #TAUTHOR_TAG, we propose two new passage completion tasks on multiparty dialogue which increase the task complexity by replacing more character mentions with variables with a better motivated data split.', 'the details of these tasks are in section.', 'several deep neural network models are developed to validate the three reading comprehension tasks.', 'based on the experimental results, we aim to identify main challenges in these tasks and suggest future research directions']",0
"['written in a similar writing style, the multiparty dialogue reading comprehension task introduced by  #TAUTHOR_TAG has a very different writing style between dialogues and queries.', 'however, their randomized assignment arxiv : 1911. 00']","['written in a similar writing style, the multiparty dialogue reading comprehension task introduced by  #TAUTHOR_TAG has a very different writing style between dialogues and queries.', 'however, their randomized assignment arxiv : 1911. 00773v1 [ cs. cl ] 2 nov 2019 of samples to training and test data']","['are written in a similar writing style, the multiparty dialogue reading comprehension task introduced by  #TAUTHOR_TAG has a very different writing style between dialogues and queries.', 'however, their randomized assignment arxiv : 1911. 00773v1 [ cs. cl ] 2 nov 2019 of samples to training and test data']","['cnn / daily mail dataset introduced by hermann et al. [ 2015 ] is to infer the missing entity ( answer a ) of a question q from all the possible entities which appear in a passage p while the passage is a news article, the question is a clozestyle task, in which one of entities is replaced by a placeholder, and the answer is this questioned entity.', 'many other models have been proposed to tackle this dataset, which are either rnn and attention based chen, bolton, and manning [ 2016 ] or cnn and rnn based trischler et al. [ 2016 ] or gated attention based dhingra et al. [ 2017 ] or attention over attention based cui et al. [ 2017 ].', 'finally, the pretrained bi - directional transformer encoder ( bert ) which was introduced by devlin et al. [ 2018 ] shows that the pretraining of the language representations can bring better performance in several downstream tasks including machine reading comprehension.', 'more datasets are available for another type of a reading comprehension task, that is multiple choice question answering, such as mctest richardson, burges, and renshaw [ 2013 ], triviaqa joshi et al. [ 2017 ], race lai et al. [ 2017 ] and dream sun et al. [ 2019 ].', 'unlike the above tasks where documents and queries are written in a similar writing style, the multiparty dialogue reading comprehension task introduced by  #TAUTHOR_TAG has a very different writing style between dialogues and queries.', 'however, their randomized assignment arxiv : 1911. 00773v1 [ cs. cl ] 2 nov 2019 of samples to training and test data substantially decreases the complexity of cloze - style reading comprehension.', 'in this paper, we address this issue by introducing a chronological data split and new variants of the cloze - style reading comprehension task to challenge even higher task complexity']",0
"['by  #TAUTHOR_TAG.', '']","['by  #TAUTHOR_TAG.', '']","['evaluate a document retrieval task.', 'the rest of the plot summaries were collected by  #TAUTHOR_TAG.', '']","['corpus comes from the transcripts of the tv show friends with ten seasons collected by the character mining project.', '1 each season contains about 24 episodes, each episode is split into about 13 scenes, where each scene comprises a sequence of about 21 utterances.', 'this dataset contains several layers of annotation.', 'the first two seasons of the show for an entity linking task was annotated by chen and choi [ 2016 ].', 'plot summaries of all episodes for the first eight seasons were collected by jurczyk and choi [ 2017 ] to evaluate a document retrieval task.', 'the rest of the plot summaries were collected by  #TAUTHOR_TAG.', 'table 1 shows the statistical data of the corpus from  #TAUTHOR_TAG.', ""based on the above corpus we created a new data split different from  #TAUTHOR_TAG's data split."", 'in the previous work of  #TAUTHOR_TAG, they used a random data split where 1, 187 of 1, 349 queries in the development set and 1, 207 of 1, 353 queries in the test set are generated from the same plot summaries as some queries in the training set with only masking the different character entities which makes the model can see the right answer in the training set.', 'to fix this issue, we created a new data split, the detail of which is in section.', 'tasks table 2a and table 2b show an example of a dialogue and its plots.', 'we propose three tasks, one is from  #TAUTHOR_TAG, and another two tasks are new tasks designed by us']",0
['single variable task from  #TAUTHOR_TAG consists a dialogue passage'],"['single variable task from  #TAUTHOR_TAG consists a dialogue passage p, a']",['single variable task from  #TAUTHOR_TAG consists a dialogue passage'],"['single variable task from  #TAUTHOR_TAG consists a dialogue passage p, a query q which is from plot summary of the dialogue passage and an answer a. in this 1 https : / / github. com / emorynlp / character - mining task, a query q replaces only one character entity with an unknown variable x and the machine is asked to infer the replaced character entity ( answer a ) from all the possible entities appear in the dialogue passage p. this task is evaluated by computing the accuracy of predictions ( see section ).', 'table 2c shows an example of this task']",0
"['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","[""comprehension is an intriguing task that assesses a machine's ability in understanding evidence contexts through question answering."", ""most previous work in reading comprehension has focused on either formal documents rajpurkar et al. [ 2016 ] or children's stories richardson, burges, and renshaw [ 2013 ]."", 'only few approaches have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with the explosive expansion of social media, data on dialogue has become dominant on the web.', 'inspired by various options of analytic models and the potential of the dialogue processing market, we extend the corpus presented by  #TAUTHOR_TAG for comprehensive predictions of personal entities in multiparty dialogue and develop deep learning models to make robust inference on their contexts.', 'passage completion on multiparty dialogue is one of the reading comprehension tasks that requires a model to match the conversational dialogues with the formal ( passage ) writings.', 'by building a robust model for this task, people can tell the status of their favorite characters by checking synopsis to see if their favorite characters appear in specific episodes without watching the entire series, thus allowing them an efficient way to decide whether to watch a particular episode.', 'involving matching contexts between colloquial ( dialog ) and formal ( passage ) writings makes this task extremely challenging.', 'distinguished from the previous work that only focused on a single variable per passage  #TAUTHOR_TAG, we propose two new passage completion tasks on multiparty dialogue which increase the task complexity by replacing more character mentions with variables with a better motivated data split.', 'the details of these tasks are in section.', 'several deep neural network models are developed to validate the three reading comprehension tasks.', 'based on the experimental results, we aim to identify main challenges in these tasks and suggest future research directions']",1
"['by  #TAUTHOR_TAG.', '']","['by  #TAUTHOR_TAG.', '']","['evaluate a document retrieval task.', 'the rest of the plot summaries were collected by  #TAUTHOR_TAG.', '']","['corpus comes from the transcripts of the tv show friends with ten seasons collected by the character mining project.', '1 each season contains about 24 episodes, each episode is split into about 13 scenes, where each scene comprises a sequence of about 21 utterances.', 'this dataset contains several layers of annotation.', 'the first two seasons of the show for an entity linking task was annotated by chen and choi [ 2016 ].', 'plot summaries of all episodes for the first eight seasons were collected by jurczyk and choi [ 2017 ] to evaluate a document retrieval task.', 'the rest of the plot summaries were collected by  #TAUTHOR_TAG.', 'table 1 shows the statistical data of the corpus from  #TAUTHOR_TAG.', ""based on the above corpus we created a new data split different from  #TAUTHOR_TAG's data split."", 'in the previous work of  #TAUTHOR_TAG, they used a random data split where 1, 187 of 1, 349 queries in the development set and 1, 207 of 1, 353 queries in the test set are generated from the same plot summaries as some queries in the training set with only masking the different character entities which makes the model can see the right answer in the training set.', 'to fix this issue, we created a new data split, the detail of which is in section.', 'tasks table 2a and table 2b show an example of a dialogue and its plots.', 'we propose three tasks, one is from  #TAUTHOR_TAG, and another two tasks are new tasks designed by us']",1
['by  #TAUTHOR_TAG are not helpful'],['by  #TAUTHOR_TAG are not helpful'],['the time the replaced entity needs to be decided by  #TAUTHOR_TAG are not helpful'],"['table 4 shows the results of our experiment.', 'bil - stm is good at capturing the sequence information of sentences ; however, since it only finds some kind of answer distributions on the sequence information, it cannot capture the information of the relation between query and utterance.', 'adding a cnn can achieve even lower accuracy because passing sequences to the cnn only keeps important information after the pooling operation, but for dialogue data, most of the time the replaced entity needs to be decided by  #TAUTHOR_TAG are not helpful for these tasks on our data split because dialogues contain so many informal expressions and the size of the corpus is small.', 'with limited data size, the attention mechanism does not perform well to match different expressions with the same meaning.', 'the bert model only uses attention mechanism to model the language feature, however, the pre - trained model is from formal text ( wikipeida, etc ) not from dialogue corpus, so it also performs poorly on our data split and tasks.', 'a counter - intuitive part is that the mvs task appears to be so much easier than the sv task.', 'the main reason is because the model can easily learn that the entity that appears in the query will not appear in the answer which will reduce many answer choices.', 'another counter - intuitive part is that bilstm without any additive method is the best model in two of the three tasks.', '']",1
"['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","['have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with']","[""comprehension is an intriguing task that assesses a machine's ability in understanding evidence contexts through question answering."", ""most previous work in reading comprehension has focused on either formal documents rajpurkar et al. [ 2016 ] or children's stories richardson, burges, and renshaw [ 2013 ]."", 'only few approaches have attempted comprehension on multiparty dialogue  #TAUTHOR_TAG.', 'however, with the explosive expansion of social media, data on dialogue has become dominant on the web.', 'inspired by various options of analytic models and the potential of the dialogue processing market, we extend the corpus presented by  #TAUTHOR_TAG for comprehensive predictions of personal entities in multiparty dialogue and develop deep learning models to make robust inference on their contexts.', 'passage completion on multiparty dialogue is one of the reading comprehension tasks that requires a model to match the conversational dialogues with the formal ( passage ) writings.', 'by building a robust model for this task, people can tell the status of their favorite characters by checking synopsis to see if their favorite characters appear in specific episodes without watching the entire series, thus allowing them an efficient way to decide whether to watch a particular episode.', 'involving matching contexts between colloquial ( dialog ) and formal ( passage ) writings makes this task extremely challenging.', 'distinguished from the previous work that only focused on a single variable per passage  #TAUTHOR_TAG, we propose two new passage completion tasks on multiparty dialogue which increase the task complexity by replacing more character mentions with variables with a better motivated data split.', 'the details of these tasks are in section.', 'several deep neural network models are developed to validate the three reading comprehension tasks.', 'based on the experimental results, we aim to identify main challenges in these tasks and suggest future research directions']",6
['by  #TAUTHOR_TAG are not helpful'],['by  #TAUTHOR_TAG are not helpful'],['the time the replaced entity needs to be decided by  #TAUTHOR_TAG are not helpful'],"['table 4 shows the results of our experiment.', 'bil - stm is good at capturing the sequence information of sentences ; however, since it only finds some kind of answer distributions on the sequence information, it cannot capture the information of the relation between query and utterance.', 'adding a cnn can achieve even lower accuracy because passing sequences to the cnn only keeps important information after the pooling operation, but for dialogue data, most of the time the replaced entity needs to be decided by  #TAUTHOR_TAG are not helpful for these tasks on our data split because dialogues contain so many informal expressions and the size of the corpus is small.', 'with limited data size, the attention mechanism does not perform well to match different expressions with the same meaning.', 'the bert model only uses attention mechanism to model the language feature, however, the pre - trained model is from formal text ( wikipeida, etc ) not from dialogue corpus, so it also performs poorly on our data split and tasks.', 'a counter - intuitive part is that the mvs task appears to be so much easier than the sv task.', 'the main reason is because the model can easily learn that the entity that appears in the query will not appear in the answer which will reduce many answer choices.', 'another counter - intuitive part is that bilstm without any additive method is the best model in two of the three tasks.', '']",4
"['2 while studies have shown that discourse usage of discourse connectives can be accurately identified for english [ 13,  #TAUTHOR_TAG, only a few studies have focused on the']","['2 while studies have shown that discourse usage of discourse connectives can be accurately identified for english [ 13,  #TAUTHOR_TAG, only a few studies have focused on the']","['while studies have shown that discourse usage of discourse connectives can be accurately identified for english [ 13,  #TAUTHOR_TAG, only a few studies have focused on']","['', '1 the cgt transport federation have risen against "" the lack of consultation "" and consider that employees have "" nothing positive to expect from this restructuring. "" 2 while studies have shown that discourse usage of discourse connectives can be accurately identified for english [ 13,  #TAUTHOR_TAG, only a few studies have focused on the disambiguation of discourse connectives in other languages.', 'in this paper, we investigate the usefulness of features proposed in the literature for the disambiguation of english discourse connectives for french discourse connectives.', '']",0
"['focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG.']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['discourse treebank ( fdtb ) [ 7 ], however to date, only discourse - usage and non - discourse - usage', 'of french discourse connectives have been annotated in the fdtb. most of previous work on the disambiguation of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest and pioneer work on the disambiguation of discourse connectives, pitler and nenkova  #TAUTHOR_TAG, showed that four syntactic features ( see section 3. 4 for details about the features ) and the connective itself can disambiguate discourse connectives with an accuracy of 95. 04 % within the pdtb [ 22 ]. their approach used these features', 'not only to disambiguate discourse connectives between discourse - usage and non - discourse - usage, but also to tag the discourse relation signalled by the discourse connectives. later, lin et al. [ 13', '] used the context of the connective ( i. e. the previous and the following word of the connective ) and added seven lexico - syntactic', 'features to the feature set proposed by pitler and nenk', '##ova  #TAUTHOR_TAG. in doing so, lin et al. achieved an accuracy of 97. 34 % for the disambiguation of discourse connectives in the pdtb', '. on the other hand, the disambiguation of discourse connectives in languages other than english has received much less attention. due to syntactic differences across languages and different discourse annotation methodologies, the techniques developed for one language may not be as effective', 'in another. for example, english discourse connectives include mostly subordinating conjunctions ( e. g. when ) or coordinating', 'conjunctions ( e. g. but ). in addition, only a few connectives are disjoint ( e. g. on the one hand... on the other hand ). this is not the case for chinese which uses many more disjoint connectives [ 26 ]. inspired by pitler and nenkova  #TAUTHOR_TAG, als', '##aif and markert [ 4 ] proposed an approach for the disambiguation of arabic discourse connectives. alsaif and markert have shown that the features proposed by pitler and nenk', '##ova  #TAUTHOR_TAG work well for arabic with an accuracy of 91. 2 %. moreover, they further improved the result of their system by considering arabic - specific morphological features and achieved an accuracy of 92. 4 %. today, due to the availability of discourse annotated corpora', 'such as the french discourse treebank [ 6 ], it is possible to analyse how the features developed for english behave when applied to french']",0
"['focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG.']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['discourse treebank ( fdtb ) [ 7 ], however to date, only discourse - usage and non - discourse - usage', 'of french discourse connectives have been annotated in the fdtb. most of previous work on the disambiguation of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest and pioneer work on the disambiguation of discourse connectives, pitler and nenkova  #TAUTHOR_TAG, showed that four syntactic features ( see section 3. 4 for details about the features ) and the connective itself can disambiguate discourse connectives with an accuracy of 95. 04 % within the pdtb [ 22 ]. their approach used these features', 'not only to disambiguate discourse connectives between discourse - usage and non - discourse - usage, but also to tag the discourse relation signalled by the discourse connectives. later, lin et al. [ 13', '] used the context of the connective ( i. e. the previous and the following word of the connective ) and added seven lexico - syntactic', 'features to the feature set proposed by pitler and nenk', '##ova  #TAUTHOR_TAG. in doing so, lin et al. achieved an accuracy of 97. 34 % for the disambiguation of discourse connectives in the pdtb', '. on the other hand, the disambiguation of discourse connectives in languages other than english has received much less attention. due to syntactic differences across languages and different discourse annotation methodologies, the techniques developed for one language may not be as effective', 'in another. for example, english discourse connectives include mostly subordinating conjunctions ( e. g. when ) or coordinating', 'conjunctions ( e. g. but ). in addition, only a few connectives are disjoint ( e. g. on the one hand... on the other hand ). this is not the case for chinese which uses many more disjoint connectives [ 26 ]. inspired by pitler and nenkova  #TAUTHOR_TAG, als', '##aif and markert [ 4 ] proposed an approach for the disambiguation of arabic discourse connectives. alsaif and markert have shown that the features proposed by pitler and nenk', '##ova  #TAUTHOR_TAG work well for arabic with an accuracy of 91. 2 %. moreover, they further improved the result of their system by considering arabic - specific morphological features and achieved an accuracy of 92. 4 %. today, due to the availability of discourse annotated corpora', 'such as the french discourse treebank [ 6 ], it is possible to analyse how the features developed for english behave when applied to french']",0
"['focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG.']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['discourse treebank ( fdtb ) [ 7 ], however to date, only discourse - usage and non - discourse - usage', 'of french discourse connectives have been annotated in the fdtb. most of previous work on the disambiguation of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest and pioneer work on the disambiguation of discourse connectives, pitler and nenkova  #TAUTHOR_TAG, showed that four syntactic features ( see section 3. 4 for details about the features ) and the connective itself can disambiguate discourse connectives with an accuracy of 95. 04 % within the pdtb [ 22 ]. their approach used these features', 'not only to disambiguate discourse connectives between discourse - usage and non - discourse - usage, but also to tag the discourse relation signalled by the discourse connectives. later, lin et al. [ 13', '] used the context of the connective ( i. e. the previous and the following word of the connective ) and added seven lexico - syntactic', 'features to the feature set proposed by pitler and nenk', '##ova  #TAUTHOR_TAG. in doing so, lin et al. achieved an accuracy of 97. 34 % for the disambiguation of discourse connectives in the pdtb', '. on the other hand, the disambiguation of discourse connectives in languages other than english has received much less attention. due to syntactic differences across languages and different discourse annotation methodologies, the techniques developed for one language may not be as effective', 'in another. for example, english discourse connectives include mostly subordinating conjunctions ( e. g. when ) or coordinating', 'conjunctions ( e. g. but ). in addition, only a few connectives are disjoint ( e. g. on the one hand... on the other hand ). this is not the case for chinese which uses many more disjoint connectives [ 26 ]. inspired by pitler and nenkova  #TAUTHOR_TAG, als', '##aif and markert [ 4 ] proposed an approach for the disambiguation of arabic discourse connectives. alsaif and markert have shown that the features proposed by pitler and nenk', '##ova  #TAUTHOR_TAG work well for arabic with an accuracy of 91. 2 %. moreover, they further improved the result of their system by considering arabic - specific morphological features and achieved an accuracy of 92. 4 %. today, due to the availability of discourse annotated corpora', 'such as the french discourse treebank [ 6 ], it is possible to analyse how the features developed for english behave when applied to french']",0
"['focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG.']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['discourse treebank ( fdtb ) [ 7 ], however to date, only discourse - usage and non - discourse - usage', 'of french discourse connectives have been annotated in the fdtb. most of previous work on the disambiguation of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest and pioneer work on the disambiguation of discourse connectives, pitler and nenkova  #TAUTHOR_TAG, showed that four syntactic features ( see section 3. 4 for details about the features ) and the connective itself can disambiguate discourse connectives with an accuracy of 95. 04 % within the pdtb [ 22 ]. their approach used these features', 'not only to disambiguate discourse connectives between discourse - usage and non - discourse - usage, but also to tag the discourse relation signalled by the discourse connectives. later, lin et al. [ 13', '] used the context of the connective ( i. e. the previous and the following word of the connective ) and added seven lexico - syntactic', 'features to the feature set proposed by pitler and nenk', '##ova  #TAUTHOR_TAG. in doing so, lin et al. achieved an accuracy of 97. 34 % for the disambiguation of discourse connectives in the pdtb', '. on the other hand, the disambiguation of discourse connectives in languages other than english has received much less attention. due to syntactic differences across languages and different discourse annotation methodologies, the techniques developed for one language may not be as effective', 'in another. for example, english discourse connectives include mostly subordinating conjunctions ( e. g. when ) or coordinating', 'conjunctions ( e. g. but ). in addition, only a few connectives are disjoint ( e. g. on the one hand... on the other hand ). this is not the case for chinese which uses many more disjoint connectives [ 26 ]. inspired by pitler and nenkova  #TAUTHOR_TAG, als', '##aif and markert [ 4 ] proposed an approach for the disambiguation of arabic discourse connectives. alsaif and markert have shown that the features proposed by pitler and nenk', '##ova  #TAUTHOR_TAG work well for arabic with an accuracy of 91. 2 %. moreover, they further improved the result of their system by considering arabic - specific morphological features and achieved an accuracy of 92. 4 %. today, due to the availability of discourse annotated corpora', 'such as the french discourse treebank [ 6 ], it is possible to analyse how the features developed for english behave when applied to french']",0
"['focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG.']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest']","['discourse treebank ( fdtb ) [ 7 ], however to date, only discourse - usage and non - discourse - usage', 'of french discourse connectives have been annotated in the fdtb. most of previous work on the disambiguation of discourse connectives have focused on english discourse connectives [', '13, 14,  #TAUTHOR_TAG. one of earliest and pioneer work on the disambiguation of discourse connectives, pitler and nenkova  #TAUTHOR_TAG, showed that four syntactic features ( see section 3. 4 for details about the features ) and the connective itself can disambiguate discourse connectives with an accuracy of 95. 04 % within the pdtb [ 22 ]. their approach used these features', 'not only to disambiguate discourse connectives between discourse - usage and non - discourse - usage, but also to tag the discourse relation signalled by the discourse connectives. later, lin et al. [ 13', '] used the context of the connective ( i. e. the previous and the following word of the connective ) and added seven lexico - syntactic', 'features to the feature set proposed by pitler and nenk', '##ova  #TAUTHOR_TAG. in doing so, lin et al. achieved an accuracy of 97. 34 % for the disambiguation of discourse connectives in the pdtb', '. on the other hand, the disambiguation of discourse connectives in languages other than english has received much less attention. due to syntactic differences across languages and different discourse annotation methodologies, the techniques developed for one language may not be as effective', 'in another. for example, english discourse connectives include mostly subordinating conjunctions ( e. g. when ) or coordinating', 'conjunctions ( e. g. but ). in addition, only a few connectives are disjoint ( e. g. on the one hand... on the other hand ). this is not the case for chinese which uses many more disjoint connectives [ 26 ]. inspired by pitler and nenkova  #TAUTHOR_TAG, als', '##aif and markert [ 4 ] proposed an approach for the disambiguation of arabic discourse connectives. alsaif and markert have shown that the features proposed by pitler and nenk', '##ova  #TAUTHOR_TAG work well for arabic with an accuracy of 91. 2 %. moreover, they further improved the result of their system by considering arabic - specific morphological features and achieved an accuracy of 92. 4 %. today, due to the availability of discourse annotated corpora', 'such as the french discourse treebank [ 6 ], it is possible to analyse how the features developed for english behave when applied to french']",0
"['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in the syntactic tree is very discriminating for the disambiguation of english discourse connectives.', 'they proposed four syntactic features :', '']",0
"['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in the syntactic tree is very discriminating for the disambiguation of english discourse connectives.', 'they proposed four syntactic features :', '']",0
"['2 while studies have shown that discourse usage of discourse connectives can be accurately identified for english [ 13,  #TAUTHOR_TAG, only a few studies have focused on the']","['2 while studies have shown that discourse usage of discourse connectives can be accurately identified for english [ 13,  #TAUTHOR_TAG, only a few studies have focused on the']","['while studies have shown that discourse usage of discourse connectives can be accurately identified for english [ 13,  #TAUTHOR_TAG, only a few studies have focused on']","['', '1 the cgt transport federation have risen against "" the lack of consultation "" and consider that employees have "" nothing positive to expect from this restructuring. "" 2 while studies have shown that discourse usage of discourse connectives can be accurately identified for english [ 13,  #TAUTHOR_TAG, only a few studies have focused on the disambiguation of discourse connectives in other languages.', 'in this paper, we investigate the usefulness of features proposed in the literature for the disambiguation of english discourse connectives for french discourse connectives.', '']",1
"['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in the syntactic tree is very discriminating for the disambiguation of english discourse connectives.', 'they proposed four syntactic features :', '']",5
"['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in']","['mentioned in section 2, pitler and nenkova  #TAUTHOR_TAG have shown that the context of discourse connectives in the syntactic tree is very discriminating for the disambiguation of english discourse connectives.', 'they proposed four syntactic features :', '']",6
['pitler and nenkova  #TAUTHOR_TAG for'],['pitler and nenkova  #TAUTHOR_TAG for'],['pitler and nenkova  #TAUTHOR_TAG for'],"['this paper, we have investigated the applicability of the syntactic and lexical features proposed by pitler and nenkova  #TAUTHOR_TAG for the disambiguation of english discourse connectives for french.', 'our experiments on the french discourse treebank ( fdtb ) show that even though the syntactic features are less informative for the disambiguation of french discourse connectives than for english discourse connectives, overall the features can effectively disambiguate french discourse connectives between discourse - usage and non - discourseusage as well in french as in english.', 'the fact that the local syntactic features proposed for english can be used almost as effectively for french and arabic [ 4 ] suggests that lexicalized discourse connectives share certain common structural features cross - linguistically and that these structures are potentially an important component in discourse processing.', 'however, our analysis also shows that the features are not as effective for all connectives.', ""some high entropy connectives such as'sinon'have a very high accuracy whereas others such as'effectivement'or'maintenant'require additional features."", 'as future work, we would like to investigate features that do not need parse trees ( such as the features proposed by lin et al. [ 13 ] ) for the disambiguation of discourse connectives.', 'we believe that such features would be useful for languages that lack robust syntactic parsers']",6
"['by pitler and nenkova  #TAUTHOR_TAG, however, separating these features gives the classifier more flexibility when building its model.', ""in example ( 1 ), these two features are'ainsi'and'not - at - the - beginning ', respectively""]","['by pitler and nenkova  #TAUTHOR_TAG, however, separating these features gives the classifier more flexibility when building its model.', ""in example ( 1 ), these two features are'ainsi'and'not - at - the - beginning ', respectively""]","['by pitler and nenkova  #TAUTHOR_TAG, however, separating these features gives the classifier more flexibility when building its model.', ""in example ( 1 ), these two features are'ainsi'and'not - at - the - beginning ', respectively""]","['two features are as informative as the case - sensitive connective string proposed by pitler and nenkova  #TAUTHOR_TAG, however, separating these features gives the classifier more flexibility when building its model.', ""in example ( 1 ), these two features are'ainsi'and'not - at - the - beginning ', respectively""]",3
"['to pitler and nenkova  #TAUTHOR_TAG, we report results using a maximum entropy']","['to pitler and nenkova  #TAUTHOR_TAG, we report results using a maximum entropy']","['to pitler and nenkova  #TAUTHOR_TAG, we report results using a maximum entropy classifier using ten - fold cross - validation over the extracted datasets.', 'we used the off - the - shelf implementation of the maximum entropy classifier available in weka [ 9 ]']","['to pitler and nenkova  #TAUTHOR_TAG, we report results using a maximum entropy classifier using ten - fold cross - validation over the extracted datasets.', 'we used the off - the - shelf implementation of the maximum entropy classifier available in weka [ 9 ] for our experiments.', 'table 5 shows the overall performance of the classifier for the disambiguation of french and english discourse connectives.', 'the results show that the classifier can distinguish between discourse - usage and non - discourse - usage of french discourse connectives with an accuracy of 94. 2 % and an fmeasure of 86. 2 %.', 'this is close to the results achieved for english discourse connectives over the pdtb ( accuracy of 93. 6 % and f - score of 88. 9 % )']",3
"['by pitler and nenkova  #TAUTHOR_TAG, however, separating these features gives the classifier more flexibility when building its model.', ""in example ( 1 ), these two features are'ainsi'and'not - at - the - beginning ', respectively""]","['by pitler and nenkova  #TAUTHOR_TAG, however, separating these features gives the classifier more flexibility when building its model.', ""in example ( 1 ), these two features are'ainsi'and'not - at - the - beginning ', respectively""]","['by pitler and nenkova  #TAUTHOR_TAG, however, separating these features gives the classifier more flexibility when building its model.', ""in example ( 1 ), these two features are'ainsi'and'not - at - the - beginning ', respectively""]","['two features are as informative as the case - sensitive connective string proposed by pitler and nenkova  #TAUTHOR_TAG, however, separating these features gives the classifier more flexibility when building its model.', ""in example ( 1 ), these two features are'ainsi'and'not - at - the - beginning ', respectively""]",4
['by  #TAUTHOR_TAG adopt deep'],"['by  #TAUTHOR_TAG adopt deep learning approaches to compute message', 'pair similarity, using a combination of message content and simple contextual features (']","['based on pairwise message compar', '- ison. some solutions use unsupervised clustering methods with hand - engineered features  #AUTHOR_TAG, while others use supervised approaches', 'with statistical  #AUTHOR_TAG or linguistic features  #AUTHOR_TAG wang and rose, 2010 ;  #AUTHOR_TAG 2011  #AUTHOR_TAG. recent work by  #TAUTHOR_TAG adopt deep learning approaches to compute message', 'pair similarity, using a combination of message content and simple contextual features (']","['threads. a recent study  #AUTHOR_TAG found that users most likely do not manually create threads. on average, only 15.', '3 threads were created per slack channel with 355 messages, when they discuss group projects. prior work on conversation thread disentanglement is often based on pairwise message compar', '- ison. some solutions use unsupervised clustering methods with hand - engineered features  #AUTHOR_TAG, while others use supervised approaches', 'with statistical  #AUTHOR_TAG or linguistic features  #AUTHOR_TAG wang and rose, 2010 ;  #AUTHOR_TAG 2011  #AUTHOR_TAG. recent work by  #TAUTHOR_TAG adopt deep learning approaches to compute message', 'pair similarity, using a combination of message content and simple contextual features ( e. g.', ', authorship and timestamps ). however, linguistic theories  #AUTHOR_TAG differentiate the following three concepts : register, genre and style,', 'to describe the text varieties. register refers to the linguistic features such as the', 'choice of words in content. genre and style refer to the conversational structure such as the sentence sequence and distribution.', 'all aforementioned thread disentanglement methods fail to take into account the contextual information of the thread,', ""or the conversational flow and genre. a thread's contextual information is a useful feature for thread - detection because considering the relationship between a single new input message and an existing"", 'message alone may not be enough to accurately determine thread membership. hence, using the full thread context history during comparison can improve pre - diction. additionally, the conversational flow and genre', ""may also be useful because  #AUTHOR_TAG suggests this represents a conversation's signature. for example, we observe that users act"", 'distinctively in public q & a ( stackoverflow ) and enterprise q', '& a ( ibm social q & a ) online community  #AUTHOR_TAG, even when they are', 'answering a similar question. based on these hypotheses, we propose two contextaware thread detection ( catd ) models. the first model ( cat', '##d - match ) captures contexts of existing threads and computes the distance between the context and the input message ; the second model ( catd - flow ) captures the conversational flow, and computes the', 'language genre consistency while attaching the input message to a thread. we also combine', 'them with a dynamic gate for further performance improvement, followed by an efficient beam search mechanism in the inference step. the', 'evaluation proves our approach improves over the existing methods. the contribution of this work is two - fold : 1 ) we propose context - aware deep learning models for thread detection and it advances the state - ofthe - art ; 2 )', 'based on the dataset in  #TAUTHOR_TAG, we develop and release a more realistic multi - party multi', '- thread conversation dataset for future research']",0
['- processing method in  #TAUTHOR_TAG :'],['pre - processing method in  #TAUTHOR_TAG :'],['in  #TAUTHOR_TAG :'],"['##hones politics nmi ari f1 nmi ari f1 nmi ari f1 table 2 : catd models are compared with baselines wrt.', 'metrics of nmi, ari and f1 for the three datasets sub - reddit to construct a synthetic dataset of interleaved conversations.', 'we take three sub - reddits to build three datasets, gadgets, iphones and politics.', '3 the data statistics and examples are shown in appendix b.', 'reddit dataset improvement : we use the same pre - processing method in  #TAUTHOR_TAG : we discard the messages which have less than 10 words or more than 100 words.', 'conversations less than 10 messages are also discarded.', 'we guarantee that no more than 10 conversations happen at the same time.', 'in their work, different message pairs of the same thread might be included in both train and test sets.', 'instead, we split the datasets on the thread level because in realistic settings, test threads should be completely unseen in train set.', '4', 'experimental setup : we use adam  #AUTHOR_TAG to optimize the training objective ( eq. 1 ).', 'during training, we fix in eq. 1 as 10.', 'in inference, this value may influence the search quality.', 'we set it as 20. 0 by the validation accuracy on politics.', 'we set lstm output dimensions to 400, the batch size to 10 and the beam size to 5 by default.', 'we train 50 epochs and select the model with the best validation - set performance.', 'baseline : ( 1 ) cisir - shcnn  #TAUTHOR_TAG : a recently proposed model based on cnn and ranking message pairs.', '( 2 ) cisir - use : we replace cnn encoder in cisir with a use to test the effect of different sentence encoders.', '( 3 ) gtm  #AUTHOR_TAG : a graph - theoretical model with chat and content specific features']",0
['by  #TAUTHOR_TAG adopt deep'],"['by  #TAUTHOR_TAG adopt deep learning approaches to compute message', 'pair similarity, using a combination of message content and simple contextual features (']","['based on pairwise message compar', '- ison. some solutions use unsupervised clustering methods with hand - engineered features  #AUTHOR_TAG, while others use supervised approaches', 'with statistical  #AUTHOR_TAG or linguistic features  #AUTHOR_TAG wang and rose, 2010 ;  #AUTHOR_TAG 2011  #AUTHOR_TAG. recent work by  #TAUTHOR_TAG adopt deep learning approaches to compute message', 'pair similarity, using a combination of message content and simple contextual features (']","['threads. a recent study  #AUTHOR_TAG found that users most likely do not manually create threads. on average, only 15.', '3 threads were created per slack channel with 355 messages, when they discuss group projects. prior work on conversation thread disentanglement is often based on pairwise message compar', '- ison. some solutions use unsupervised clustering methods with hand - engineered features  #AUTHOR_TAG, while others use supervised approaches', 'with statistical  #AUTHOR_TAG or linguistic features  #AUTHOR_TAG wang and rose, 2010 ;  #AUTHOR_TAG 2011  #AUTHOR_TAG. recent work by  #TAUTHOR_TAG adopt deep learning approaches to compute message', 'pair similarity, using a combination of message content and simple contextual features ( e. g.', ', authorship and timestamps ). however, linguistic theories  #AUTHOR_TAG differentiate the following three concepts : register, genre and style,', 'to describe the text varieties. register refers to the linguistic features such as the', 'choice of words in content. genre and style refer to the conversational structure such as the sentence sequence and distribution.', 'all aforementioned thread disentanglement methods fail to take into account the contextual information of the thread,', ""or the conversational flow and genre. a thread's contextual information is a useful feature for thread - detection because considering the relationship between a single new input message and an existing"", 'message alone may not be enough to accurately determine thread membership. hence, using the full thread context history during comparison can improve pre - diction. additionally, the conversational flow and genre', ""may also be useful because  #AUTHOR_TAG suggests this represents a conversation's signature. for example, we observe that users act"", 'distinctively in public q & a ( stackoverflow ) and enterprise q', '& a ( ibm social q & a ) online community  #AUTHOR_TAG, even when they are', 'answering a similar question. based on these hypotheses, we propose two contextaware thread detection ( catd ) models. the first model ( cat', '##d - match ) captures contexts of existing threads and computes the distance between the context and the input message ; the second model ( catd - flow ) captures the conversational flow, and computes the', 'language genre consistency while attaching the input message to a thread. we also combine', 'them with a dynamic gate for further performance improvement, followed by an efficient beam search mechanism in the inference step. the', 'evaluation proves our approach improves over the existing methods. the contribution of this work is two - fold : 1 ) we propose context - aware deep learning models for thread detection and it advances the state - ofthe - art ; 2 )', 'based on the dataset in  #TAUTHOR_TAG, we develop and release a more realistic multi - party multi', '- thread conversation dataset for future research']",5
"['datasets.', 'we strictly follow  #TAUTHOR_TAG to']","['datasets.', 'we strictly follow  #TAUTHOR_TAG to']","['##t datasets.', 'we strictly follow  #TAUTHOR_TAG to']","[': we conduct extensive experiments on three publicly available datasets from reddit datasets.', 'we strictly follow  #TAUTHOR_TAG to construct our data.', 'comments under a post can be treated as messages in a single conversational thread, and we merge all comments in']",5
['- processing method in  #TAUTHOR_TAG :'],['pre - processing method in  #TAUTHOR_TAG :'],['in  #TAUTHOR_TAG :'],"['##hones politics nmi ari f1 nmi ari f1 nmi ari f1 table 2 : catd models are compared with baselines wrt.', 'metrics of nmi, ari and f1 for the three datasets sub - reddit to construct a synthetic dataset of interleaved conversations.', 'we take three sub - reddits to build three datasets, gadgets, iphones and politics.', '3 the data statistics and examples are shown in appendix b.', 'reddit dataset improvement : we use the same pre - processing method in  #TAUTHOR_TAG : we discard the messages which have less than 10 words or more than 100 words.', 'conversations less than 10 messages are also discarded.', 'we guarantee that no more than 10 conversations happen at the same time.', 'in their work, different message pairs of the same thread might be included in both train and test sets.', 'instead, we split the datasets on the thread level because in realistic settings, test threads should be completely unseen in train set.', '4', 'experimental setup : we use adam  #AUTHOR_TAG to optimize the training objective ( eq. 1 ).', 'during training, we fix in eq. 1 as 10.', 'in inference, this value may influence the search quality.', 'we set it as 20. 0 by the validation accuracy on politics.', 'we set lstm output dimensions to 400, the batch size to 10 and the beam size to 5 by default.', 'we train 50 epochs and select the model with the best validation - set performance.', 'baseline : ( 1 ) cisir - shcnn  #TAUTHOR_TAG : a recently proposed model based on cnn and ranking message pairs.', '( 2 ) cisir - use : we replace cnn encoder in cisir with a use to test the effect of different sentence encoders.', '( 3 ) gtm  #AUTHOR_TAG : a graph - theoretical model with chat and content specific features']",5
"['##1 score, following  #TAUTHOR_TAG.', '']","['f1 score, following  #TAUTHOR_TAG.', '']","['##1 score, following  #TAUTHOR_TAG.', '']",[' #TAUTHOR_TAG'],5
"['', '( 2 ) time difference by mapping the time difference between m j and m i into 11 ranges ( from 1 minutes to 72 hours, details in appendix a ).', 'these two features are also used in  #TAUTHOR_TAG, and another baseline model gtm uses only these features  #AUTHOR_TAG.', 'given']","['', '( 2 ) time difference by mapping the time difference between m j and m i into 11 ranges ( from 1 minutes to 72 hours, details in appendix a ).', 'these two features are also used in  #TAUTHOR_TAG, and another baseline model gtm uses only these features  #AUTHOR_TAG.', 'given']","[') user - identity difference between m j and m i.', '( 2 ) time difference by mapping the time difference between m j and m i into 11 ranges ( from 1 minutes to 72 hours, details in appendix a ).', 'these two features are also used in  #TAUTHOR_TAG, and another baseline model gtm uses only these features  #AUTHOR_TAG.', 'given a message sequence m i 1,']","['first adopt the universal sentence encoder 2 with deep averaging network ( use )  #AUTHOR_TAG to get a static feature representation for each message in the form of sentence embeddings.', 'we encode each message m j as enc ( m j ), by concatenating the use output with two 20dimensional embeddings : ( 1 ) user - identity difference between m j and m i.', '( 2 ) time difference by mapping the time difference between m j and m i into 11 ranges ( from 1 minutes to 72 hours, details in appendix a ).', 'these two features are also used in  #TAUTHOR_TAG, and another baseline model gtm uses only these features  #AUTHOR_TAG.', 'given a message sequence m i 1, which has been detected with l threads', 'i 1 indicates that m i starts a new thread.', 'as shown in fig. 1, we adopt a message - level single directional lstm to encode each thread t l i 1, whose inputs are enc ( · ) of maximum k last messages ( set to 20 ) in the thread, denoted as { m ( l, k ) } k k = 1.', 'the messages outside that window are viewed as irrelevant to the prediction of m i.', 'in fig. 1, we propose two catd models, catd - flow and catd - match, each one capturing the semantic relationship between the new message and the existing thread contexts.', 'fig. 1 ) : this model considers each thread as a conversation flow for a particular topic with its own genre, and the current message should belong to the thread with which it is more likely to form a fluent conversation.', 'therefore, we concatenate the enc ( m i ) to each lstm sequence of t l i 1, and get the last output e l flow to dot - product a trainable vector w and compute the probability of m i being labeled with t l i 1']",3
"['datasets.', 'we strictly follow  #TAUTHOR_TAG to']","['datasets.', 'we strictly follow  #TAUTHOR_TAG to']","['##t datasets.', 'we strictly follow  #TAUTHOR_TAG to']","[': we conduct extensive experiments on three publicly available datasets from reddit datasets.', 'we strictly follow  #TAUTHOR_TAG to construct our data.', 'comments under a post can be treated as messages in a single conversational thread, and we merge all comments in']",3
['- processing method in  #TAUTHOR_TAG :'],['pre - processing method in  #TAUTHOR_TAG :'],['in  #TAUTHOR_TAG :'],"['##hones politics nmi ari f1 nmi ari f1 nmi ari f1 table 2 : catd models are compared with baselines wrt.', 'metrics of nmi, ari and f1 for the three datasets sub - reddit to construct a synthetic dataset of interleaved conversations.', 'we take three sub - reddits to build three datasets, gadgets, iphones and politics.', '3 the data statistics and examples are shown in appendix b.', 'reddit dataset improvement : we use the same pre - processing method in  #TAUTHOR_TAG : we discard the messages which have less than 10 words or more than 100 words.', 'conversations less than 10 messages are also discarded.', 'we guarantee that no more than 10 conversations happen at the same time.', 'in their work, different message pairs of the same thread might be included in both train and test sets.', 'instead, we split the datasets on the thread level because in realistic settings, test threads should be completely unseen in train set.', '4', 'experimental setup : we use adam  #AUTHOR_TAG to optimize the training objective ( eq. 1 ).', 'during training, we fix in eq. 1 as 10.', 'in inference, this value may influence the search quality.', 'we set it as 20. 0 by the validation accuracy on politics.', 'we set lstm output dimensions to 400, the batch size to 10 and the beam size to 5 by default.', 'we train 50 epochs and select the model with the best validation - set performance.', 'baseline : ( 1 ) cisir - shcnn  #TAUTHOR_TAG : a recently proposed model based on cnn and ranking message pairs.', '( 2 ) cisir - use : we replace cnn encoder in cisir with a use to test the effect of different sentence encoders.', '( 3 ) gtm  #AUTHOR_TAG : a graph - theoretical model with chat and content specific features']",3
"['##1 score, following  #TAUTHOR_TAG.', '']","['f1 score, following  #TAUTHOR_TAG.', '']","['##1 score, following  #TAUTHOR_TAG.', '']",[' #TAUTHOR_TAG'],3
"['model dynamically computes the weights of match and flow.', 'training procedure : following  #TAUTHOR_TAG, apart from a new thread, we consider the candidate threads ( active threads ) in']","['model dynamically computes the weights of match and flow.', 'training procedure : following  #TAUTHOR_TAG, apart from a new thread, we consider the candidate threads ( active threads ) in eq. 1 only from those appearing in']","['match will be considered equally for prediction.', 'otherwise, the model dynamically computes the weights of match and flow.', 'training procedure : following  #TAUTHOR_TAG, apart from a new thread, we consider the candidate threads ( active threads ) in']","['', 'where w 0 is a parameter vector.', 'g l is determined by the distance between n ( e l cxt ) and n ( h i ).', 'we use this dynamic gate g to linearly combine the two models.', 'g is computed based on the difference of the match vector of context and the input message.', 'intuitively, if they are close, both flow and match will be considered equally for prediction.', 'otherwise, the model dynamically computes the weights of match and flow.', 'training procedure : following  #TAUTHOR_TAG, apart from a new thread, we consider the candidate threads ( active threads ) in eq. 1 only from those appearing in one hour time - frame before m i.', 'during training, we treat the messages of a channel as a single sequence, and optimize eq. 1 with training examples, containing m i and its active threads.', 'though messages are sorted by time, the training examples are shuffled during training']",4
"['model dynamically computes the weights of match and flow.', 'training procedure : following  #TAUTHOR_TAG, apart from a new thread, we consider the candidate threads ( active threads ) in']","['model dynamically computes the weights of match and flow.', 'training procedure : following  #TAUTHOR_TAG, apart from a new thread, we consider the candidate threads ( active threads ) in eq. 1 only from those appearing in']","['match will be considered equally for prediction.', 'otherwise, the model dynamically computes the weights of match and flow.', 'training procedure : following  #TAUTHOR_TAG, apart from a new thread, we consider the candidate threads ( active threads ) in']","['', 'where w 0 is a parameter vector.', 'g l is determined by the distance between n ( e l cxt ) and n ( h i ).', 'we use this dynamic gate g to linearly combine the two models.', 'g is computed based on the difference of the match vector of context and the input message.', 'intuitively, if they are close, both flow and match will be considered equally for prediction.', 'otherwise, the model dynamically computes the weights of match and flow.', 'training procedure : following  #TAUTHOR_TAG, apart from a new thread, we consider the candidate threads ( active threads ) in eq. 1 only from those appearing in one hour time - frame before m i.', 'during training, we treat the messages of a channel as a single sequence, and optimize eq. 1 with training examples, containing m i and its active threads.', 'though messages are sorted by time, the training examples are shuffled during training']",6
"['##ze norms to be proportional to object presence, salience, or other potentially meaningful measures [ 20, 21 ]. we rely on a canonical visual qa pipeline  #TAUTHOR_TAG 9, 22, 23, 24, 25 ]', 'augmented with a hard attention mechanism']","['##ze norms to be proportional to object presence, salience, or other potentially meaningful measures [ 20, 21 ]. we rely on a canonical visual qa pipeline  #TAUTHOR_TAG 9, 22, 23, 24, 25 ]', 'augmented with a hard attention mechanism']","['##ze norms to be proportional to object presence, salience, or other potentially meaningful measures [ 20, 21 ]. we rely on a canonical visual qa pipeline  #TAUTHOR_TAG 9, 22, 23, 24, 25 ]', 'augmented with a hard attention mechanism']","['', '##propagated into the selection mechanism to support gradient - based optimization. there have been various efforts to address this shortcoming in visual attention [ 15 ], attention to text [ 16 ], and more general machine learning', 'domains [ 17, 18, 19 ], but this is still a very active area of research. here we explore a simple approach to hard attention that bootstraps on an interesting phenomenon [ 20 ] in the feature representations of convolutional neural networks (', 'cnns ) : learned features often carry an easily accessible signal for hard attentional selection. in particular, selecting those feature vectors with the', 'greatest l2 - norm values proves to be a heuristic that can facilitate hard attention - and provide the', 'performance and efficiency benefits associated with - without requiring specialized learning procedures ( see figure 1 ). this attentional signal results indirectly from a standard supervised task loss, and does not require explicit supervision to', 'incentivize norms to be proportional to object presence, salience, or other potentially meaningful measures [ 20, 21 ]. we rely on a canonical visual qa pipeline  #TAUTHOR_TAG 9, 22, 23, 24, 25 ]', 'augmented with a hard attention mechanism that uses the l2 - norms of the feature vectors to select subsets of', 'the information for further processing. the first version, called the hard attention network ( han ), selects a fixed number of feature vectors by choosing those with', 'the top norms. the second version, called the adaptive hard attention network ( adahan', '), selects a variable number of feature vectors that depends on the input. our results show that our algorithm can actually outperform comparable soft attention architectures on a', 'challenging visual qa task. this approach also produces interpretable hard attention masks, where the image regions which correspond to the selected features', 'often contain semantically meaningful information, such as coherent objects. we also show strong performance when combined with a form of non - local pairwise model [ 26, 25, 27, 28 ]. this algorithm computes features over pairs of input', 'features and thus scale quadratically with number of vectors in the feature map, highlighting the importance of feature selection']",5
"['reasoning problem head - on  #TAUTHOR_TAG 34, 35 ].', '']","['reasoning problem head - on  #TAUTHOR_TAG 34, 35 ].', 'thus, we focus on']","['exploiting spurious correlations, rather than tackling the reasoning problem head - on  #TAUTHOR_TAG 34, 35 ].', '']","['question answering, or more broadly the visual turing test, asks "" can machines understand a visual scene only from answering questions? "" [ 6, 23, 29, 30, 31, 32 ].', 'creating a good visual qa dataset has proved non - trivial : biases in the early datasets [ 6, 22, 23, 33 ] rewarded algorithms for exploiting spurious correlations, rather than tackling the reasoning problem head - on  #TAUTHOR_TAG 34, 35 ].', 'thus, we focus on the recently - introduced vqa - cp  #TAUTHOR_TAG and clevr [ 34 ] datasets, which aim to reduce the dataset biases, providing a more difficult challenge for rich visual reasoning.', 'one of the core challenges of visual qa is the problem of grounding language : that is, associating the meaning of a language term with a specific perceptual input [ 36 ].', 'many works have tackled this problem [ 37, 38, 39, 40 ], enforcing that language terms be grounded in the image.', 'in contrast, our algorithm does not directly use correspondence between modalities to enforce such grounding but instead relies on learning to find a discrete representation that captures the required information from the raw visual input, and question - answer pairs.', 'the most successful visual qa architectures build multimodal representations with a combined cnn + lstm architecture [ 22, 33, 41 ], and recently have begun including attention mechanisms inspired by soft and hard attention for image captioning [ 42 ].', 'however, only soft attention is used in the majority of visual qa works  #TAUTHOR_TAG 8, 9, 10, 11, 12, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52 ].', 'in these architectures, a full - frame cnn representation is used to compute a spatial weighting ( attention ) over the cnn grid cells.', 'the visual representation is then the weighted - sum of the input tensor across space.', 'the alternative is to select cnn grid cells in a discrete way, but due to many challenges in training non - differentiable architectures, such hard attention alternatives are severely under - explored.', 'notable exceptions include [ 6, 13, 14, 53, 54, 55 ], but these run state - of - the - art object detectors or proposals to compute the hard attention maps.', ""we argue that relying on such external tools is fundamentally limited : it requires costly annotations, and cannot easily adapt to new visual concepts that aren't previously labeled."", 'outside visual qa and captioning, some prior work in vision has explored limited forms of hard attention.', 'one line of work on discriminative patches builds a']",5
"[' #TAUTHOR_TAG 9, 22,']","[' #TAUTHOR_TAG 9, 22, 23, 24 ], the question is a sequence of words']","[' #TAUTHOR_TAG 9, 22,']","['questions about images is often formulated in terms of predictive models [ 24 ].', 'these architectures maximize a conditional distribution over answers a, given questions q and images x :', 'where a is a countable set of all possible answers.', 'as is common in question answering  #TAUTHOR_TAG 9, 22, 23, 24 ], the question is a sequence of words q = [ q 1,..., q n ], while the output is reduced to a classification problem between a set of common answers ( this is limited compared to approaches that generate answers [ 41 ], but works better in practice ).', 'our architecture for learning a mapping from image and question, to answer, is shown in figure 2.', 'we encode the image with a cnn [ 62 ] ( in our case, a pre - trained resnet - 101 [ 63 ], or a small cnn trained from scratch ), and encode the question to a fixed - length vector representation with an lstm [ 64 ].', 'we compute a combined representation by copying the question representation to every spatial location in the cnn, and concatenating it with ( or simply adding it to ) the visual features, like previous otherwise, we follow the canonical visual qa pipeline  #TAUTHOR_TAG 9, 22, 23, 24, 25 ].', 'questions and images are encoded into their vector representations.', 'next, the spatial encoding of the visual features is unraveled, and the question embedding is broadcasted and concatenated ( or added ) accordingly to form a multimodal representation of the inputs.', 'our attention mechanism selectively chooses a subset of the multimodal vectors that are next aggregated and processed by the answering module.', 'work [ 7, 9, 22, 23, 24, 25 ].', 'after a few layers of combined processing, we apply attention over spatial locations, following previous works which often apply soft attention mechanisms  #TAUTHOR_TAG 8, 9, 10 ] at this point in the architecture.', 'finally, we aggregate features, using either sum - pooling, or relational [ 25, 27, 65 ] modules.', 'we train the whole network end - to - end with a standard logistic regression loss over answer categories']",5
"[' #TAUTHOR_TAG 9, 22,']","[' #TAUTHOR_TAG 9, 22, 23, 24 ], the question is a sequence of words']","[' #TAUTHOR_TAG 9, 22,']","['questions about images is often formulated in terms of predictive models [ 24 ].', 'these architectures maximize a conditional distribution over answers a, given questions q and images x :', 'where a is a countable set of all possible answers.', 'as is common in question answering  #TAUTHOR_TAG 9, 22, 23, 24 ], the question is a sequence of words q = [ q 1,..., q n ], while the output is reduced to a classification problem between a set of common answers ( this is limited compared to approaches that generate answers [ 41 ], but works better in practice ).', 'our architecture for learning a mapping from image and question, to answer, is shown in figure 2.', 'we encode the image with a cnn [ 62 ] ( in our case, a pre - trained resnet - 101 [ 63 ], or a small cnn trained from scratch ), and encode the question to a fixed - length vector representation with an lstm [ 64 ].', 'we compute a combined representation by copying the question representation to every spatial location in the cnn, and concatenating it with ( or simply adding it to ) the visual features, like previous otherwise, we follow the canonical visual qa pipeline  #TAUTHOR_TAG 9, 22, 23, 24, 25 ].', 'questions and images are encoded into their vector representations.', 'next, the spatial encoding of the visual features is unraveled, and the question embedding is broadcasted and concatenated ( or added ) accordingly to form a multimodal representation of the inputs.', 'our attention mechanism selectively chooses a subset of the multimodal vectors that are next aggregated and processed by the answering module.', 'work [ 7, 9, 22, 23, 24, 25 ].', 'after a few layers of combined processing, we apply attention over spatial locations, following previous works which often apply soft attention mechanisms  #TAUTHOR_TAG 8, 9, 10 ] at this point in the architecture.', 'finally, we aggregate features, using either sum - pooling, or relational [ 25, 27, 65 ] modules.', 'we train the whole network end - to - end with a standard logistic regression loss over answer categories']",5
"['', 'in particular, we include previous results using a basic soft attention network  #TAUTHOR_TAG 9 ] with the']","['1.', 'in particular, we include previous results using a basic soft attention network  #TAUTHOR_TAG 9 ] with the']","['', 'in particular, we include previous results using a basic soft attention network  #TAUTHOR_TAG 9 ] with the same features used in other experiments.', 'surprisingly, soft attention does not']","['', 'even with just 16 units, the performance loss is less than 1 %, suggesting that hard attention is quite capable of capturing the important parts of the image.', 'table 1 : comparison between different number of attended cells ( percentage of the whole input ), and aggregation operation.', 'we consider a simple summation, and non - local pairwise computations as the aggregation tool.', 'the fact that hard attention can work is interesting itself, but it should be especially useful for models that devote significant processing to each attended cell.', 'we therefore repeat the above experiment with the non - local pairwise aggregation mechanism described in section 3, which computes activations for every pair of attended cells, and therefore scales quadratically with the number of at - tended cells.', 'these results are shown in the middle of table 1, where we can see that hard attention ( 48 entitties ) actually boosts performance over an analogous model without hard attention.', 'finally, we compare standard soft attention baselines in the bottom of table 1.', 'in particular, we include previous results using a basic soft attention network  #TAUTHOR_TAG 9 ] with the same features used in other experiments.', 'surprisingly, soft attention does not outperform basic sum pooling, even with careful implementation that outperforms the previously reported results with the same method on this dataset ; in fact, it performs slightly worse.', 'the nonlocal pairwise aggregation performs better than san on its own, although the best result includes hard attention.', 'our results overall are somewhat worse than the state - of - the - art  #TAUTHOR_TAG, but this is likely due to several architectural decisions not included here, such as a split pathway for different kinds of questions, special question embeddings, and the use of the question extractor.', 'table 2 : comparison between different adaptive hard - attention techniques with average number of attended parts, and aggregation operation.', '']",5
['9 ] results reported by  #TAUTHOR_TAG together with'],"['by rounding.', ""table 1 shows san's [ 9 ] results reported by  #TAUTHOR_TAG together with""]","['', ""table 1 shows san's [ 9 ] results reported by  #TAUTHOR_TAG together with""]","['our models use the same lstm size 512 for questions embeddings, and the last convolutional layer of the imagenet pre - trained resnet - 101 [ 63 ] ( yielding 10 - by - 10 spatial representation, each with 2048 dimensional cells ) for image embedding.', 'we also use mlp with 3 layers of sizes : 1024, 2048, 1000, as a classification module.', 'we use adam for optimization [ 66 ].', 'we use a distributed setting with two workers computing a gradient over a batch of 128 elements each.', 'we normalize images by dividing them by their norm.', 'we do not perform a hyper - parameter search as there is no separated validation set available.', 'instead, we rather choose default hyper - parameters based on our prior experience on visual qa datasets.', 'we trained our models until we notice a saturation on the training set.', 'then we evaluate these models on the test set.', 'our tables show the performance of all the methods wrt.', 'the second digits precision obtained by rounding.', 'table 1 shows san\'s [ 9 ] results reported by  #TAUTHOR_TAG together with our in - house implementation ( denoted as "" ours "" ).', 'our implementation has 2 attention hops, 1024 dimensional multimodal embedding size, a fixed learning rate 0. 0001, and resnet - 101.', 'in these experiments we pool the attended representations by weighted average with the attention weights.', 'our in - house implementation of the nonlocal pairwise mechanism strongly resembles implementations of [ 26 ], and [ 27 ].', 'we use 2 heads, with embedding size 512.', 'in equation 2 and equation 3, we use d : = 2048 ( the same as dimensionality as the image encoding ) and two linear layers with relu that follows up each layer']",5
"['', 'in particular, we include previous results using a basic soft attention network  #TAUTHOR_TAG 9 ] with the']","['1.', 'in particular, we include previous results using a basic soft attention network  #TAUTHOR_TAG 9 ] with the']","['', 'in particular, we include previous results using a basic soft attention network  #TAUTHOR_TAG 9 ] with the same features used in other experiments.', 'surprisingly, soft attention does not']","['', 'even with just 16 units, the performance loss is less than 1 %, suggesting that hard attention is quite capable of capturing the important parts of the image.', 'table 1 : comparison between different number of attended cells ( percentage of the whole input ), and aggregation operation.', 'we consider a simple summation, and non - local pairwise computations as the aggregation tool.', 'the fact that hard attention can work is interesting itself, but it should be especially useful for models that devote significant processing to each attended cell.', 'we therefore repeat the above experiment with the non - local pairwise aggregation mechanism described in section 3, which computes activations for every pair of attended cells, and therefore scales quadratically with the number of at - tended cells.', 'these results are shown in the middle of table 1, where we can see that hard attention ( 48 entitties ) actually boosts performance over an analogous model without hard attention.', 'finally, we compare standard soft attention baselines in the bottom of table 1.', 'in particular, we include previous results using a basic soft attention network  #TAUTHOR_TAG 9 ] with the same features used in other experiments.', 'surprisingly, soft attention does not outperform basic sum pooling, even with careful implementation that outperforms the previously reported results with the same method on this dataset ; in fact, it performs slightly worse.', 'the nonlocal pairwise aggregation performs better than san on its own, although the best result includes hard attention.', 'our results overall are somewhat worse than the state - of - the - art  #TAUTHOR_TAG, but this is likely due to several architectural decisions not included here, such as a split pathway for different kinds of questions, special question embeddings, and the use of the question extractor.', 'table 2 : comparison between different adaptive hard - attention techniques with average number of attended parts, and aggregation operation.', '']",4
"['67 ] ; the results are reported by  #TAUTHOR_TAG.', 'this']","['uses more complex and deeper visual architecture [ 67 ] ; the results are reported by  #TAUTHOR_TAG.', 'this']","['uses more complex and deeper visual architecture [ 67 ] ; the results are reported by  #TAUTHOR_TAG.', 'this result shows that the hard attention mechanism']","['', 'surprisingly, simple - han + sum achieves about 24 % performance on the same split, on - par with the performance of normal san that uses more complex and deeper visual architecture [ 67 ] ; the results are reported by  #TAUTHOR_TAG.', 'this result shows that the hard attention mechanism can indeed be tightly coupled within the training process, and that the whole procedure does not rely heavily on the properties of the imagenet pre - trained networks.', 'in a sense, we see that a discrete notion of entities also "" emerges "" through the learning process, leading to efficient training.', 'implementation details.', 'in our experiments we use a simple cnn built of : 1 layer with 64 filters and 7 - by - 7 filter size followed up by 2 layers with 256 filters and 2 layers with 512 filters, all with 3 - by - 3 filter size.', 'we use strides 2 for all the layers']",3
"['in a number of settings  #TAUTHOR_TAG.', 'as a complement to annotated training corpora, external lexicon']","['in a number of settings  #TAUTHOR_TAG.', 'as a complement to annotated training corpora, external lexicons']","['memms )  #AUTHOR_TAG and conditional random fields ( crfs )  #AUTHOR_TAG.', 'recently, neural approaches have reached very competitive accuracy levels, improving over the state of the art in a number of settings  #TAUTHOR_TAG.', 'as a complement to annotated training corpora, external lexicons can be']","['- of - speech tagging is now a classic task in natural language processing.', 'its aim is to associate each "" word "" with a morphosyntactic tag, whose granularity can range from a simple morphosyntactic category, or part - of - speech ( hereafter pos ), to finer categories enriched with morphological features ( gender, number, case, tense, mood, person, etc. ).', 'the use of machine learning algorithms trained on manually annotated corpora has long become the standard way to develop pos taggers.', 'a large variety of algorithms have been used, such as ( in approximative chronological order ) bigram and trigram hidden markov models  #AUTHOR_TAG brants,, 2000, decision trees  #AUTHOR_TAG, maximum entropy markov models ( memms )  #AUTHOR_TAG and conditional random fields ( crfs )  #AUTHOR_TAG.', 'recently, neural approaches have reached very competitive accuracy levels, improving over the state of the art in a number of settings  #TAUTHOR_TAG.', 'as a complement to annotated training corpora, external lexicons can be a valuable source of information.', 'first, morphosyntactic lexicons provide a large inventory of ( word, pos ) pairs.', 'such lexical information can be used in the form of constraints at tagging time  #AUTHOR_TAG hajic, 2000 ) or during the training process as additional features combined with standard features extracted from the training corpus ( chrupała et al., 2008 ;  #AUTHOR_TAG.', 'second, lexical information encoded in vector representations, known as word embeddings, have emerged more recently  #AUTHOR_TAG chrupała, 2013 ;  #AUTHOR_TAG muller and schutze, 2015 ).', 'such representations, often extracted from large amounts of raw text, have proved very useful for numerous tasks including pos tagging, in particular when used in recurrent neural networks ( rnns ) and more specifically in mono - or bi - directional, word - level or characterlevel long short - term memory networks ( lstms )  #TAUTHOR_TAG.', 'character - level embeddings are of particular interest for pos tagging as they generate vector representations that result from the internal characterlevel make - up of each word.', 'it can generalise over relevant sub - parts such as prefixes or suffixes, thus directly addressing the problem of unknown words.', 'however, unknown words do not always follow such generalisations.', 'in such cases, character - level models cannot bring any advantage.', 'this is a difference with external lexicons, which provides information about any word it contains, yet without any quantitative distinction between relevant and less relevant information.', 'therefore, a comparative assessment of the ad - vantages of using character - level embeddings']",0
"['in a number of settings  #TAUTHOR_TAG.', 'as a complement to annotated training corpora, external lexicon']","['in a number of settings  #TAUTHOR_TAG.', 'as a complement to annotated training corpora, external lexicons']","['memms )  #AUTHOR_TAG and conditional random fields ( crfs )  #AUTHOR_TAG.', 'recently, neural approaches have reached very competitive accuracy levels, improving over the state of the art in a number of settings  #TAUTHOR_TAG.', 'as a complement to annotated training corpora, external lexicons can be']","['- of - speech tagging is now a classic task in natural language processing.', 'its aim is to associate each "" word "" with a morphosyntactic tag, whose granularity can range from a simple morphosyntactic category, or part - of - speech ( hereafter pos ), to finer categories enriched with morphological features ( gender, number, case, tense, mood, person, etc. ).', 'the use of machine learning algorithms trained on manually annotated corpora has long become the standard way to develop pos taggers.', 'a large variety of algorithms have been used, such as ( in approximative chronological order ) bigram and trigram hidden markov models  #AUTHOR_TAG brants,, 2000, decision trees  #AUTHOR_TAG, maximum entropy markov models ( memms )  #AUTHOR_TAG and conditional random fields ( crfs )  #AUTHOR_TAG.', 'recently, neural approaches have reached very competitive accuracy levels, improving over the state of the art in a number of settings  #TAUTHOR_TAG.', 'as a complement to annotated training corpora, external lexicons can be a valuable source of information.', 'first, morphosyntactic lexicons provide a large inventory of ( word, pos ) pairs.', 'such lexical information can be used in the form of constraints at tagging time  #AUTHOR_TAG hajic, 2000 ) or during the training process as additional features combined with standard features extracted from the training corpus ( chrupała et al., 2008 ;  #AUTHOR_TAG.', 'second, lexical information encoded in vector representations, known as word embeddings, have emerged more recently  #AUTHOR_TAG chrupała, 2013 ;  #AUTHOR_TAG muller and schutze, 2015 ).', 'such representations, often extracted from large amounts of raw text, have proved very useful for numerous tasks including pos tagging, in particular when used in recurrent neural networks ( rnns ) and more specifically in mono - or bi - directional, word - level or characterlevel long short - term memory networks ( lstms )  #TAUTHOR_TAG.', 'character - level embeddings are of particular interest for pos tagging as they generate vector representations that result from the internal characterlevel make - up of each word.', 'it can generalise over relevant sub - parts such as prefixes or suffixes, thus directly addressing the problem of unknown words.', 'however, unknown words do not always follow such generalisations.', 'in such cases, character - level models cannot bring any advantage.', 'this is a difference with external lexicons, which provides information about any word it contains, yet without any quantitative distinction between relevant and less relevant information.', 'therefore, a comparative assessment of the ad - vantages of using character - level embeddings']",0
"['shown by  #TAUTHOR_TAG, state - of - the -']","['shown by  #TAUTHOR_TAG, state - of - the - art performance can be achieved using a bi - lstm']","['shown by  #TAUTHOR_TAG, state - of - the - art performance can be achieved using a bi - lstm architecture fed with word representations.', 'optimal performance is achieved representing words using the concatenation of ( i )']","['shown by  #TAUTHOR_TAG, state - of - the - art performance can be achieved using a bi - lstm architecture fed with word representations.', ""optimal performance is achieved representing words using the concatenation of ( i ) a word vector w built using a word embedding layer, called its word embedding, and ( ii ) a representation c of the word's characters, called its character - based embedding built using a character - level bi - lstm, which is trained jointly with the word - level layers."", 'further improvements can be obtained on most but not all languages by initialising the word embedding layer with pre - computed word embeddings.', 'we refer to  #TAUTHOR_TAG for further details']",0
"['shown by  #TAUTHOR_TAG, state - of - the -']","['shown by  #TAUTHOR_TAG, state - of - the - art performance can be achieved using a bi - lstm']","['shown by  #TAUTHOR_TAG, state - of - the - art performance can be achieved using a bi - lstm architecture fed with word representations.', 'optimal performance is achieved representing words using the concatenation of ( i )']","['shown by  #TAUTHOR_TAG, state - of - the - art performance can be achieved using a bi - lstm architecture fed with word representations.', ""optimal performance is achieved representing words using the concatenation of ( i ) a word vector w built using a word embedding layer, called its word embedding, and ( ii ) a representation c of the word's characters, called its character - based embedding built using a character - level bi - lstm, which is trained jointly with the word - level layers."", 'further improvements can be obtained on most but not all languages by initialising the word embedding layer with pre - computed word embeddings.', 'we refer to  #TAUTHOR_TAG for further details']",1
"['these words.', 'pre - computed embeddings whenever available and following  #TAUTHOR_TAG, we performed experiments using polyglot pre - computed embeddings ( al -']","['these words.', 'pre - computed embeddings whenever available and following  #TAUTHOR_TAG, we performed experiments using polyglot pre - computed embeddings ( al -']","['these words.', 'pre - computed embeddings whenever available and following  #TAUTHOR_TAG, we performed experiments using polyglot pre - computed embeddings ( al -']","['', 'we determine the best performing lexicon for each language based on tagging accuracy on the development set.', 'in the remainder of this paper, all information about the lexicons ( table 1 ) and accuracy results are restricted to these best performing lexicons.', 'coverage information on the test sets for both the training data and the best external lexicon for each dataset is provided in table 2 : coverage of the training set and of the best lexicon on the test set for each dataset of the ud 1. 3 corpora.', '"" ootc "" stands for "" out of training corpus "" and oolex for "" out of ( external ) lexicon "".', 'the "" ootc, in lex. "" column displays the percentage of words that are not in the training corpus but are covered by the lexicon.', 'best improvements are expected for these words.', 'pre - computed embeddings whenever available and following  #TAUTHOR_TAG, we performed experiments using polyglot pre - computed embeddings ( al -']",5
"['language in the baseline configuration ( the same as  #TAUTHOR_TAG and in the lexicon - enabled configuration.', 'for']","['language in the baseline configuration ( the same as  #TAUTHOR_TAG and in the lexicon - enabled configuration.', 'for']","['( + l ) w p + c ( + l ) table 3 : overall results.', 'pos accuracy scores are given for each language in the baseline configuration ( the same as  #TAUTHOR_TAG and in the lexicon - enabled configuration.', 'for each configuration, scores are given']","['best lexicon gain when using ( no lexicon ) ( selected on dev, cf.', 'tab.', '1 ) best lexicon w w + c w p + c w + l w + c + l w p + c + l w ( + l ) w + c ( + l ) w p + c ( + l ) table 3 : overall results.', 'pos accuracy scores are given for each language in the baseline configuration ( the same as  #TAUTHOR_TAG and in the lexicon - enabled configuration.', 'for each configuration, scores are given when using word embeddings only ( w ), word and character - based embeddings ( w + c ), and word and character - based embeddings with initialisation of word embeddings with polyglot vectors ( w p + c ).', 'the last columns show the difference between lexicon - enabled and baseline configurations']",5
"['"" by  #TAUTHOR_TAG.', 'we use its standard configuration, with one bi - ls']","['use as a baseline the state - of - the - art bi - lstm pos tagger bilty, a freely available 6 and "" significantly refactored version of the code originally used "" by  #TAUTHOR_TAG.', 'we use its standard configuration, with one bi - lstm layer, characterbased embeddings size']","['"" by  #TAUTHOR_TAG.', 'we use its standard configuration, with one bi - lstm layer, characterbased embeddings size']","['use as a baseline the state - of - the - art bi - lstm pos tagger bilty, a freely available 6 and "" significantly refactored version of the code originally used "" by  #TAUTHOR_TAG.', 'we use its standard configuration, with one bi - lstm layer, characterbased embeddings size of 100, word embedding size of 64 ( same as polyglot embeddings ), no multitask learning, 7 and 20 iterations for training.', 'we extended bilty for enabling integration of lexical morphosyntactic information, in the way described in the previous section.', '5  #AUTHOR_TAG oliver and tadic, 2004 ;  #AUTHOR_TAG mechura, 2014 ;  #AUTHOR_TAG.', ""6 https : / / github. com / bplank / bilstm - aux 7 plank et al.'s ( 2016 ) secondary task - predicting the frequency class of each word - results in better oov scores but virtually identical overall scores when averaged over all tested languages / corpora."", 'for each lexicon - related configuration, we trained three variants of the tagger : ( i ) a variant without using character - based embeddings and standard ( zero ) initialisation of word embeddings before training, ( ii ) a variant with character - based embeddings and standard initialisation of word embeddings, and ( iii ) when polyglot embeddings are available for the language at hand, a variant with character - based embeddings and initialisation of the word embeddings with the polyglot embeddings.', ""this is deliberately similar to plank et al.'s ( 2016 ) table 4 : accuracy of the best system using a lexicon for words out of the training corpus ( ootc ), and for words out of the training corpus that are present in the lexicon ( ootc in lex. ), as well as difference between the best system and the baseline without lexicon for these two subsets of words""]",5
['level models have been observed  #TAUTHOR_TAG'],['- level models have been observed  #TAUTHOR_TAG'],['- level models over word - level models have been observed  #TAUTHOR_TAG'],"['', 'e. g., embedding size, context size ). we focus on the task of parsing time normalizations  #AUTHOR_TAG b ), where large gains of character - level models over word - level models have been observed  #TAUTHOR_TAG. this task involves finding and composing pieces of a time expression to infer time intervals, so for example', ', the expression 3 days ago could be normalized to the interval [ 2019 - 03 - 01, 2019 - 03 - 02', '). we first take a state - of - the - art neural network for parsing time normalizations  #TAUTHOR_TAG and replace its randomly initialized character embeddings with pre - trained contextual character embeddings. after showing that this yields major performance improvements, we analyze the improvements to understand why pre - trained contextual character', 'embeddings are so useful. our contributions are : • we derive pre - trained contextual character embeddings from flair  #AUTHOR_TAG, apply them', '']",0
['level models have been observed  #TAUTHOR_TAG'],['- level models have been observed  #TAUTHOR_TAG'],['- level models over word - level models have been observed  #TAUTHOR_TAG'],"['', 'e. g., embedding size, context size ). we focus on the task of parsing time normalizations  #AUTHOR_TAG b ), where large gains of character - level models over word - level models have been observed  #TAUTHOR_TAG. this task involves finding and composing pieces of a time expression to infer time intervals, so for example', ', the expression 3 days ago could be normalized to the interval [ 2019 - 03 - 01, 2019 - 03 - 02', '). we first take a state - of - the - art neural network for parsing time normalizations  #TAUTHOR_TAG and replace its randomly initialized character embeddings with pre - trained contextual character embeddings. after showing that this yields major performance improvements, we analyze the improvements to understand why pre - trained contextual character', 'embeddings are so useful. our contributions are : • we derive pre - trained contextual character embeddings from flair  #AUTHOR_TAG, apply them', '']",0
"['', ' #TAUTHOR_TAG decomposes the parsing time']","['( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG decomposes the parsing time normalizations task into two']","['parsing time normalizations task is based on the semantically compositional annotation of time expressions ( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG decomposes the parsing time normalizations task into']","['parsing time normalizations task is based on the semantically compositional annotation of time expressions ( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG']",0
"['', ' #TAUTHOR_TAG decomposes the parsing time']","['( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG decomposes the parsing time normalizations task into two']","['parsing time normalizations task is based on the semantically compositional annotation of time expressions ( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG decomposes the parsing time normalizations task into']","['parsing time normalizations task is based on the semantically compositional annotation of time expressions ( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG']",0
['level models have been observed  #TAUTHOR_TAG'],['- level models have been observed  #TAUTHOR_TAG'],['- level models over word - level models have been observed  #TAUTHOR_TAG'],"['', 'e. g., embedding size, context size ). we focus on the task of parsing time normalizations  #AUTHOR_TAG b ), where large gains of character - level models over word - level models have been observed  #TAUTHOR_TAG. this task involves finding and composing pieces of a time expression to infer time intervals, so for example', ', the expression 3 days ago could be normalized to the interval [ 2019 - 03 - 01, 2019 - 03 - 02', '). we first take a state - of - the - art neural network for parsing time normalizations  #TAUTHOR_TAG and replace its randomly initialized character embeddings with pre - trained contextual character embeddings. after showing that this yields major performance improvements, we analyze the improvements to understand why pre - trained contextual character', 'embeddings are so useful. our contributions are : • we derive pre - trained contextual character embeddings from flair  #AUTHOR_TAG, apply them', '']",1
['level models have been observed  #TAUTHOR_TAG'],['- level models have been observed  #TAUTHOR_TAG'],['- level models over word - level models have been observed  #TAUTHOR_TAG'],"['', 'e. g., embedding size, context size ). we focus on the task of parsing time normalizations  #AUTHOR_TAG b ), where large gains of character - level models over word - level models have been observed  #TAUTHOR_TAG. this task involves finding and composing pieces of a time expression to infer time intervals, so for example', ', the expression 3 days ago could be normalized to the interval [ 2019 - 03 - 01, 2019 - 03 - 02', '). we first take a state - of - the - art neural network for parsing time normalizations  #TAUTHOR_TAG and replace its randomly initialized character embeddings with pre - trained contextual character embeddings. after showing that this yields major performance improvements, we analyze the improvements to understand why pre - trained contextual character', 'embeddings are so useful. our contributions are : • we derive pre - trained contextual character embeddings from flair  #AUTHOR_TAG, apply them', '']",5
['level models have been observed  #TAUTHOR_TAG'],['- level models have been observed  #TAUTHOR_TAG'],['- level models over word - level models have been observed  #TAUTHOR_TAG'],"['', 'e. g., embedding size, context size ). we focus on the task of parsing time normalizations  #AUTHOR_TAG b ), where large gains of character - level models over word - level models have been observed  #TAUTHOR_TAG. this task involves finding and composing pieces of a time expression to infer time intervals, so for example', ', the expression 3 days ago could be normalized to the interval [ 2019 - 03 - 01, 2019 - 03 - 02', '). we first take a state - of - the - art neural network for parsing time normalizations  #TAUTHOR_TAG and replace its randomly initialized character embeddings with pre - trained contextual character embeddings. after showing that this yields major performance improvements, we analyze the improvements to understand why pre - trained contextual character', 'embeddings are so useful. our contributions are : • we derive pre - trained contextual character embeddings from flair  #AUTHOR_TAG, apply them', '']",5
"['', ' #TAUTHOR_TAG decomposes the parsing time']","['( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG decomposes the parsing time normalizations task into two']","['parsing time normalizations task is based on the semantically compositional annotation of time expressions ( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG decomposes the parsing time normalizations task into']","['parsing time normalizations task is based on the semantically compositional annotation of time expressions ( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG']",5
['level models have been observed  #TAUTHOR_TAG'],['- level models have been observed  #TAUTHOR_TAG'],['- level models over word - level models have been observed  #TAUTHOR_TAG'],"['', 'e. g., embedding size, context size ). we focus on the task of parsing time normalizations  #AUTHOR_TAG b ), where large gains of character - level models over word - level models have been observed  #TAUTHOR_TAG. this task involves finding and composing pieces of a time expression to infer time intervals, so for example', ', the expression 3 days ago could be normalized to the interval [ 2019 - 03 - 01, 2019 - 03 - 02', '). we first take a state - of - the - art neural network for parsing time normalizations  #TAUTHOR_TAG and replace its randomly initialized character embeddings with pre - trained contextual character embeddings. after showing that this yields major performance improvements, we analyze the improvements to understand why pre - trained contextual character', 'embeddings are so useful. our contributions are : • we derive pre - trained contextual character embeddings from flair  #AUTHOR_TAG, apply them', '']",6
"['', ' #TAUTHOR_TAG decomposes the parsing time']","['( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG decomposes the parsing time normalizations task into two']","['parsing time normalizations task is based on the semantically compositional annotation of time expressions ( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG decomposes the parsing time normalizations task into']","['parsing time normalizations task is based on the semantically compositional annotation of time expressions ( scate ) schema  #AUTHOR_TAG, in which times are annotated as compositional time entities.', ' #TAUTHOR_TAG']",6
"[', corpus - based vector.', 'more recently,  #TAUTHOR_TAG put the']","['original, corpus - based vector.', 'more recently,  #TAUTHOR_TAG put the']","['combines the meanings of the base term ( e. g., to use ) and the affix ( e. g., ful ).', 'for evaluation, they compared the predicted vector of the complex word with the original, corpus - based vector.', 'more recently,  #TAUTHOR_TAG put the task of modeling derivation into the perspective of zero - shot - learning : instead of using cosine similarities']","['the first to apply distributional semantic models ( dsms ) to the task of deriving the meaning of morphologically complex words from their parts.', 'they relied on high - dimensional vector representations to model the derived term ( e. g., useful ) as a result of a compositional process that combines the meanings of the base term ( e. g., to use ) and the affix ( e. g., ful ).', 'for evaluation, they compared the predicted vector of the complex word with the original, corpus - based vector.', 'more recently,  #TAUTHOR_TAG put the task of modeling derivation into the perspective of zero - shot - learning : instead of using cosine similarities they predicted the derived term by learning a mapping function between the base term and the derived term.', 'once the predicted vector was computed, a nearest neighbor search was applied to validate if the prediction corresponded to the derived term.', 'in zero - shotlearning the task is to predict novel values, i. e., values that were never seen in training.', 'more formally, zero - shot - learning trains a classifier f : x → y that predicts novel values for y  #AUTHOR_TAG.', 'it is often applied across vector spaces, such as different domains  #AUTHOR_TAG.', 'the experiments by  #TAUTHOR_TAG were performed over six derivational patterns for german ( cf.', 'table 1 ), including particle verbs ( pvs ) with two different particle prefixes ( an and durch ), which were particularly difficult to predict.', 'pvs such as anfangen ( to start ) are compositions of a base verb ( bv ) such as fangen ( to catch ) and a verb particle such as an.', 'predicting pv meaning is challenging because german pvs are highly productive  #AUTHOR_TAG b ;  #AUTHOR_TAG a ), and the particles are notoriously ambiguous ( lechler and roßdeutscher, 2009 ;  #AUTHOR_TAG.', 'furthermore, the particles often trigger meaning shifts when they combine with base verbs  #AUTHOR_TAG b ), so the resulting pvs represent frequent cases of non - literal meaning.', 'in this paper, we focus on predicting the meanings of german pv derivations.', 'our models provide two contributions to the research field of predicting derivations : ( i ) we suggest a novel idea of restricting the available training data, which has a positive impact on the mapping quality.', '( ii ) we integrate a correction method for popular nearest neighbors into our models, so - called hubs ( radovanovic et al., 2010 ), to improve the prediction quality.', 'table 2 : new german pv derivation dataset']",0
"[', corpus - based vector.', 'more recently,  #TAUTHOR_TAG put the']","['original, corpus - based vector.', 'more recently,  #TAUTHOR_TAG put the']","['combines the meanings of the base term ( e. g., to use ) and the affix ( e. g., ful ).', 'for evaluation, they compared the predicted vector of the complex word with the original, corpus - based vector.', 'more recently,  #TAUTHOR_TAG put the task of modeling derivation into the perspective of zero - shot - learning : instead of using cosine similarities']","['the first to apply distributional semantic models ( dsms ) to the task of deriving the meaning of morphologically complex words from their parts.', 'they relied on high - dimensional vector representations to model the derived term ( e. g., useful ) as a result of a compositional process that combines the meanings of the base term ( e. g., to use ) and the affix ( e. g., ful ).', 'for evaluation, they compared the predicted vector of the complex word with the original, corpus - based vector.', 'more recently,  #TAUTHOR_TAG put the task of modeling derivation into the perspective of zero - shot - learning : instead of using cosine similarities they predicted the derived term by learning a mapping function between the base term and the derived term.', 'once the predicted vector was computed, a nearest neighbor search was applied to validate if the prediction corresponded to the derived term.', 'in zero - shotlearning the task is to predict novel values, i. e., values that were never seen in training.', 'more formally, zero - shot - learning trains a classifier f : x → y that predicts novel values for y  #AUTHOR_TAG.', 'it is often applied across vector spaces, such as different domains  #AUTHOR_TAG.', 'the experiments by  #TAUTHOR_TAG were performed over six derivational patterns for german ( cf.', 'table 1 ), including particle verbs ( pvs ) with two different particle prefixes ( an and durch ), which were particularly difficult to predict.', 'pvs such as anfangen ( to start ) are compositions of a base verb ( bv ) such as fangen ( to catch ) and a verb particle such as an.', 'predicting pv meaning is challenging because german pvs are highly productive  #AUTHOR_TAG b ;  #AUTHOR_TAG a ), and the particles are notoriously ambiguous ( lechler and roßdeutscher, 2009 ;  #AUTHOR_TAG.', 'furthermore, the particles often trigger meaning shifts when they combine with base verbs  #AUTHOR_TAG b ), so the resulting pvs represent frequent cases of non - literal meaning.', 'in this paper, we focus on predicting the meanings of german pv derivations.', 'our models provide two contributions to the research field of predicting derivations : ( i ) we suggest a novel idea of restricting the available training data, which has a positive impact on the mapping quality.', '( ii ) we integrate a correction method for popular nearest neighbors into our models, so - called hubs ( radovanovic et al., 2010 ), to improve the prediction quality.', 'table 2 : new german pv derivation dataset']",0
"['##add is a re - implementation of the best method in  #TAUTHOR_TAG :', '3 for']","['##add is a re - implementation of the best method in  #TAUTHOR_TAG :', '3 for']","['##add is a re - implementation of the best method in  #TAUTHOR_TAG :', '3 for each affix, the method learns a difference vector by computing the dimension - wise differences']","['##add is a re - implementation of the best method in  #TAUTHOR_TAG :', '3 for each affix, the method learns a difference vector by computing the dimension - wise differences between the vector representations of base term a and derived term b.', 'the method thus learns a centroid c for all relevant training pairs ( n ) with the same affix :', 'for each pv test instance with this affix, the learned centroid vector is added dimensionwise to the vector representation of the base term to predict a position for the derived term']",0
"['in  #TAUTHOR_TAG, we treat']","['in  #TAUTHOR_TAG, we treat']","['in  #TAUTHOR_TAG, we treat every derivation type as a specific learning problem : we take a set of word pairs with a particular derivation pattern (']","['in  #TAUTHOR_TAG, we treat every derivation type as a specific learning problem : we take a set of word pairs with a particular derivation pattern ( e. g., "" - in "", backer : : backerin ), and divide this set into training and test pairs by performing 10 - fold cross - validation.', 'for the test pairs, we predict the vectors of the derived terms ( e. g.,', 'the search space includes all corpus words across parts - of - speech, except for the base term.', 'the performance is measured in terms of recall - out - of - 5 ( mc  #AUTHOR_TAG, counting how often the correct derived term is found among the five nearest neighbors of the predicted vector']",3
"['resource as  #TAUTHOR_TAG,']","['resource as  #TAUTHOR_TAG,']","['created a new collection of german particle verb derivations 1 relying on the same resource as  #TAUTHOR_TAG, the semiautomatic derivational lexicon']","['created a new collection of german particle verb derivations 1 relying on the same resource as  #TAUTHOR_TAG, the semiautomatic derivational lexicon for german derivbase  #AUTHOR_TAG.', 'from derivbase, we induced all pairs of base verbs and particle verbs across seven different particles.', 'nonexisting verbs were manually filtered out.', 'in total, our collection contains 1 410 bv - pv combinations across seven particles, cf.', 'table 2.', 'in addition, we apply our models to two existing collections for derivational patterns, the german dataset from  #TAUTHOR_TAG, comprising six derivational patterns with 80 in - stances each ( cf.', 'table 3 : english dataset  #AUTHOR_TAG']",3
"['baseline method that simply guesses the derived term has a chance of approx.', '1 460 000 for german and 1 240 000 for english to predict the correct term.', 'we thus apply a more informed baseline, the same as in  #TAUTHOR_TAG, and predict']","['baseline method that simply guesses the derived term has a chance of approx.', '1 460 000 for german and 1 240 000 for english to predict the correct term.', 'we thus apply a more informed baseline, the same as in  #TAUTHOR_TAG, and predict']","['baseline method that simply guesses the derived term has a chance of approx.', '1 460 000 for german and 1 240 000 for english to predict the correct term.', 'we thus apply a more informed baseline, the same as in  #TAUTHOR_TAG, and predict the derived term at exactly the same position as the base term']","['baseline method that simply guesses the derived term has a chance of approx.', '1 460 000 for german and 1 240 000 for english to predict the correct term.', 'we thus apply a more informed baseline, the same as in  #TAUTHOR_TAG, and predict the derived term at exactly the same position as the base term']",3
"['in  #TAUTHOR_TAG, we treat']","['in  #TAUTHOR_TAG, we treat']","['in  #TAUTHOR_TAG, we treat every derivation type as a specific learning problem : we take a set of word pairs with a particular derivation pattern (']","['in  #TAUTHOR_TAG, we treat every derivation type as a specific learning problem : we take a set of word pairs with a particular derivation pattern ( e. g., "" - in "", backer : : backerin ), and divide this set into training and test pairs by performing 10 - fold cross - validation.', 'for the test pairs, we predict the vectors of the derived terms ( e. g.,', 'the search space includes all corpus words across parts - of - speech, except for the base term.', 'the performance is measured in terms of recall - out - of - 5 ( mc  #AUTHOR_TAG, counting how often the correct derived term is found among the five nearest neighbors of the predicted vector']",5
"['resource as  #TAUTHOR_TAG,']","['resource as  #TAUTHOR_TAG,']","['created a new collection of german particle verb derivations 1 relying on the same resource as  #TAUTHOR_TAG, the semiautomatic derivational lexicon']","['created a new collection of german particle verb derivations 1 relying on the same resource as  #TAUTHOR_TAG, the semiautomatic derivational lexicon for german derivbase  #AUTHOR_TAG.', 'from derivbase, we induced all pairs of base verbs and particle verbs across seven different particles.', 'nonexisting verbs were manually filtered out.', 'in total, our collection contains 1 410 bv - pv combinations across seven particles, cf.', 'table 2.', 'in addition, we apply our models to two existing collections for derivational patterns, the german dataset from  #TAUTHOR_TAG, comprising six derivational patterns with 80 in - stances each ( cf.', 'table 3 : english dataset  #AUTHOR_TAG']",5
"['baseline method that simply guesses the derived term has a chance of approx.', '1 460 000 for german and 1 240 000 for english to predict the correct term.', 'we thus apply a more informed baseline, the same as in  #TAUTHOR_TAG, and predict']","['baseline method that simply guesses the derived term has a chance of approx.', '1 460 000 for german and 1 240 000 for english to predict the correct term.', 'we thus apply a more informed baseline, the same as in  #TAUTHOR_TAG, and predict']","['baseline method that simply guesses the derived term has a chance of approx.', '1 460 000 for german and 1 240 000 for english to predict the correct term.', 'we thus apply a more informed baseline, the same as in  #TAUTHOR_TAG, and predict the derived term at exactly the same position as the base term']","['baseline method that simply guesses the derived term has a chance of approx.', '1 460 000 for german and 1 240 000 for english to predict the correct term.', 'we thus apply a more informed baseline, the same as in  #TAUTHOR_TAG, and predict the derived term at exactly the same position as the base term']",5
['rather than use a hierarchical attention neural network  #TAUTHOR_TAG to'],['rather than use a hierarchical attention neural network  #TAUTHOR_TAG to'],"['obtaining the contextual representation of a', 'conversation. rather than use a hierarchical attention neural network  #TAUTHOR_TAG to']","['', 'state - of - the - art models is the two attention mechanisms for obtaining the contextual representation of a', 'conversation. rather than use a hierarchical attention neural network  #TAUTHOR_TAG to obtain the contextual representation of a conversation, we propose two utterance - level attentions for weighting the', 'importance of each utterance in the context, which is more simple in structure and has less number of parameters than the hierarchical attention approach. meanwhile, rather than use a heuristic approach to weigh the importance of each utterance in the context  #AUTHOR_TAG,', 'in our proposed approach, the weights of utterance in the context are learned', 'by two attention mechanisms from the data, which is more reasonable and flexible than the heuristic based approach']",4
['rather than use a hierarchical attention neural network  #TAUTHOR_TAG to'],['rather than use a hierarchical attention neural network  #TAUTHOR_TAG to'],"['obtaining the contextual representation of a', 'conversation. rather than use a hierarchical attention neural network  #TAUTHOR_TAG to']","['', 'state - of - the - art models is the two attention mechanisms for obtaining the contextual representation of a', 'conversation. rather than use a hierarchical attention neural network  #TAUTHOR_TAG to obtain the contextual representation of a conversation, we propose two utterance - level attentions for weighting the', 'importance of each utterance in the context, which is more simple in structure and has less number of parameters than the hierarchical attention approach. meanwhile, rather than use a heuristic approach to weigh the importance of each utterance in the context  #AUTHOR_TAG,', 'in our proposed approach, the weights of utterance in the context are learned', 'by two attention mechanisms from the data, which is more reasonable and flexible than the heuristic based approach']",6
"['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different from syntactic structures']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['commonalities between different realizations of the same underlying predicate - argument structures. for example, present will still be', 'a1 in sentence "" john gave a nice present to his wonderful wife "", despite different surface', ""forms of the two sentences. we hypothesize that semantic roles can be especially beneficial in nmt, as'argument"", ""switching'( flipping arguments corresponding to different roles ) is one of frequent and severe mistakes made by nmt systems  #AUTHOR_TAG. there is a limited amount of work on incorporating graph structures into neural sequence models. though, unlike semantics"", 'in nmt, syntactically - aware nmt has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax  #TAUTHOR_TAG, our', '']",0
"['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different from syntactic structures']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['commonalities between different realizations of the same underlying predicate - argument structures. for example, present will still be', 'a1 in sentence "" john gave a nice present to his wonderful wife "", despite different surface', ""forms of the two sentences. we hypothesize that semantic roles can be especially beneficial in nmt, as'argument"", ""switching'( flipping arguments corresponding to different roles ) is one of frequent and severe mistakes made by nmt systems  #AUTHOR_TAG. there is a limited amount of work on incorporating graph structures into neural sequence models. though, unlike semantics"", 'in nmt, syntactically - aware nmt has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax  #TAUTHOR_TAG, our', '']",0
"['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different from syntactic structures']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['commonalities between different realizations of the same underlying predicate - argument structures. for example, present will still be', 'a1 in sentence "" john gave a nice present to his wonderful wife "", despite different surface', ""forms of the two sentences. we hypothesize that semantic roles can be especially beneficial in nmt, as'argument"", ""switching'( flipping arguments corresponding to different roles ) is one of frequent and severe mistakes made by nmt systems  #AUTHOR_TAG. there is a limited amount of work on incorporating graph structures into neural sequence models. though, unlike semantics"", 'in nmt, syntactically - aware nmt has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax  #TAUTHOR_TAG, our', '']",0
['cnn baseline  #TAUTHOR_TAG 16'],"['', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1']","['', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1 13. 7 + syn + sem 15. 8 14. 3']","['neural networks are a family of neural architectures  #AUTHOR_TAG specifically devised to induce representation of nodes in a graph relying on its graph structure.', 'graph convolutional networks ( gcns ) belong to this family.', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1 13. 7 + syn + sem 15. 8 14. 3 for modeling undirected unlabeled graphs  #AUTHOR_TAG, in this paper we use a formulation of gcns for labeled directed graphs, where the direction and the label of an edge are incorporated.', 'in particular, we follow the formulation of and  #TAUTHOR_TAG for syntactic graphs and apply it to dependency - based semantic - role structures  #AUTHOR_TAG ( as in figure 1 ).', 'more formally, consider a directed graph g = ( v, e ), where v is a set of nodes, and e is a set of edges.', 'each node v ∈ v is represented by a feature vector x v ∈ r d, where d is the latent space dimensionality.', 'the gcn induces a new representation h v ∈ r d of a node v while relying on representations h u of its neighbors :', '']",0
['cnn baseline  #TAUTHOR_TAG 16'],"['', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1']","['', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1 13. 7 + syn + sem 15. 8 14. 3']","['neural networks are a family of neural architectures  #AUTHOR_TAG specifically devised to induce representation of nodes in a graph relying on its graph structure.', 'graph convolutional networks ( gcns ) belong to this family.', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1 13. 7 + syn + sem 15. 8 14. 3 for modeling undirected unlabeled graphs  #AUTHOR_TAG, in this paper we use a formulation of gcns for labeled directed graphs, where the direction and the label of an edge are incorporated.', 'in particular, we follow the formulation of and  #TAUTHOR_TAG for syntactic graphs and apply it to dependency - based semantic - role structures  #AUTHOR_TAG ( as in figure 1 ).', 'more formally, consider a directed graph g = ( v, e ), where v is a set of nodes, and e is a set of edges.', 'each node v ∈ v is represented by a feature vector x v ∈ r d, where d is the latent space dimensionality.', 'the gcn induces a new representation h v ∈ r d of a node v while relying on representations h u of its neighbors :', '']",0
"['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different from syntactic structures']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['commonalities between different realizations of the same underlying predicate - argument structures. for example, present will still be', 'a1 in sentence "" john gave a nice present to his wonderful wife "", despite different surface', ""forms of the two sentences. we hypothesize that semantic roles can be especially beneficial in nmt, as'argument"", ""switching'( flipping arguments corresponding to different roles ) is one of frequent and severe mistakes made by nmt systems  #AUTHOR_TAG. there is a limited amount of work on incorporating graph structures into neural sequence models. though, unlike semantics"", 'in nmt, syntactically - aware nmt has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax  #TAUTHOR_TAG, our', '']",4
['cnn baseline  #TAUTHOR_TAG 16'],"['', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1']","['', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1 13. 7 + syn + sem 15. 8 14. 3']","['neural networks are a family of neural architectures  #AUTHOR_TAG specifically devised to induce representation of nodes in a graph relying on its graph structure.', 'graph convolutional networks ( gcns ) belong to this family.', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1 13. 7 + syn + sem 15. 8 14. 3 for modeling undirected unlabeled graphs  #AUTHOR_TAG, in this paper we use a formulation of gcns for labeled directed graphs, where the direction and the label of an edge are incorporated.', 'in particular, we follow the formulation of and  #TAUTHOR_TAG for syntactic graphs and apply it to dependency - based semantic - role structures  #AUTHOR_TAG ( as in figure 1 ).', 'more formally, consider a directed graph g = ( v, e ), where v is a set of nodes, and e is a set of edges.', 'each node v ∈ v is represented by a feature vector x v ∈ r d, where d is the latent space dimensionality.', 'the gcn induces a new representation h v ∈ r d of a node v while relying on representations h u of its neighbors :', '']",4
"['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different from syntactic structures']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['commonalities between different realizations of the same underlying predicate - argument structures. for example, present will still be', 'a1 in sentence "" john gave a nice present to his wonderful wife "", despite different surface', ""forms of the two sentences. we hypothesize that semantic roles can be especially beneficial in nmt, as'argument"", ""switching'( flipping arguments corresponding to different roles ) is one of frequent and severe mistakes made by nmt systems  #AUTHOR_TAG. there is a limited amount of work on incorporating graph structures into neural sequence models. though, unlike semantics"", 'in nmt, syntactically - aware nmt has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax  #TAUTHOR_TAG, our', '']",3
"['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different from syntactic structures']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['commonalities between different realizations of the same underlying predicate - argument structures. for example, present will still be', 'a1 in sentence "" john gave a nice present to his wonderful wife "", despite different surface', ""forms of the two sentences. we hypothesize that semantic roles can be especially beneficial in nmt, as'argument"", ""switching'( flipping arguments corresponding to different roles ) is one of frequent and severe mistakes made by nmt systems  #AUTHOR_TAG. there is a limited amount of work on incorporating graph structures into neural sequence models. though, unlike semantics"", 'in nmt, syntactically - aware nmt has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax  #TAUTHOR_TAG, our', '']",3
"['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different from syntactic structures']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['commonalities between different realizations of the same underlying predicate - argument structures. for example, present will still be', 'a1 in sentence "" john gave a nice present to his wonderful wife "", despite different surface', ""forms of the two sentences. we hypothesize that semantic roles can be especially beneficial in nmt, as'argument"", ""switching'( flipping arguments corresponding to different roles ) is one of frequent and severe mistakes made by nmt systems  #AUTHOR_TAG. there is a limited amount of work on incorporating graph structures into neural sequence models. though, unlike semantics"", 'in nmt, syntactically - aware nmt has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax  #TAUTHOR_TAG, our', '']",1
"['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different from syntactic structures']","['using treebank syntax  #TAUTHOR_TAG, our', 'graphs are different']","['commonalities between different realizations of the same underlying predicate - argument structures. for example, present will still be', 'a1 in sentence "" john gave a nice present to his wonderful wife "", despite different surface', ""forms of the two sentences. we hypothesize that semantic roles can be especially beneficial in nmt, as'argument"", ""switching'( flipping arguments corresponding to different roles ) is one of frequent and severe mistakes made by nmt systems  #AUTHOR_TAG. there is a limited amount of work on incorporating graph structures into neural sequence models. though, unlike semantics"", 'in nmt, syntactically - aware nmt has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax  #TAUTHOR_TAG, our', '']",5
['cnn baseline  #TAUTHOR_TAG 16'],"['', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1']","['', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1 13. 7 + syn + sem 15. 8 14. 3']","['neural networks are a family of neural architectures  #AUTHOR_TAG specifically devised to induce representation of nodes in a graph relying on its graph structure.', 'graph convolutional networks ( gcns ) belong to this family.', 'while gcns were introduced birnn cnn baseline  #TAUTHOR_TAG 16. 1 13. 7 + syn + sem 15. 8 14. 3 for modeling undirected unlabeled graphs  #AUTHOR_TAG, in this paper we use a formulation of gcns for labeled directed graphs, where the direction and the label of an edge are incorporated.', 'in particular, we follow the formulation of and  #TAUTHOR_TAG for syntactic graphs and apply it to dependency - based semantic - role structures  #AUTHOR_TAG ( as in figure 1 ).', 'more formally, consider a directed graph g = ( v, e ), where v is a set of nodes, and e is a set of edges.', 'each node v ∈ v is represented by a feature vector x v ∈ r d, where d is the latent space dimensionality.', 'the gcn induces a new representation h v ∈ r d of a node v while relying on representations h u of its neighbors :', '']",5
"['scores  #AUTHOR_TAG.', 'the settings and the framework ( neural monkey ( helcl and libovicky, 2017 ) ) used for experiments are the ones used in  #TAUTHOR_TAG, which we use as baselines.', 'as rnns,']","['of the models with ( cased ) bleu scores  #AUTHOR_TAG.', 'the settings and the framework ( neural monkey ( helcl and libovicky, 2017 ) ) used for experiments are the ones used in  #TAUTHOR_TAG, which we use as baselines.', 'as rnns,']","['( see appendix a ).', 'we measured the performance of the models with ( cased ) bleu scores  #AUTHOR_TAG.', 'the settings and the framework ( neural monkey ( helcl and libovicky, 2017 ) ) used for experiments are the ones used in  #TAUTHOR_TAG, which we use as baselines.', 'as rnns, we use grus  #AUTHOR_TAG.', 'we now discuss the impact that different architectures and linguistic information have on the translation quality']","['', 'we constructed the english vocabulary by taking all words with frequency higher than three, while for german we used byte - pair encodings ( bpe )  #AUTHOR_TAG.', 'all hyperparameter selection was performed on the validation set ( see appendix a ).', 'we measured the performance of the models with ( cased ) bleu scores  #AUTHOR_TAG.', 'the settings and the framework ( neural monkey ( helcl and libovicky, 2017 ) ) used for experiments are the ones used in  #TAUTHOR_TAG, which we use as baselines.', 'as rnns, we use grus  #AUTHOR_TAG.', 'we now discuss the impact that different architectures and linguistic information have on the translation quality']",5
"['1 ).', 'as in  #TAUTHOR_TAG,']","['1 ).', 'as in  #TAUTHOR_TAG,']","[', we start with experiments with the smaller news commentary training set ( see table 1 ).', 'as in  #TAUTHOR_TAG, we used the standard attention - based encoder - decoder model as a baseline.', 'we tested the impact of semantic gcns']","[', we start with experiments with the smaller news commentary training set ( see table 1 ).', 'as in  #TAUTHOR_TAG, we used the standard attention - based encoder - decoder model as a baseline.', 'we tested the impact of semantic gcns when used on top of cnn and birnn encoders.', 'as expected, birnn results are stronger than cnn ones.', 'in general, for both encoders we observe the same trend : using semantic gcns leads to an improvement over the baseline model.', '']",5
"['1 ).', 'as in  #TAUTHOR_TAG,']","['1 ).', 'as in  #TAUTHOR_TAG,']","[', we start with experiments with the smaller news commentary training set ( see table 1 ).', 'as in  #TAUTHOR_TAG, we used the standard attention - based encoder - decoder model as a baseline.', 'we tested the impact of semantic gcns']","[', we start with experiments with the smaller news commentary training set ( see table 1 ).', 'as in  #TAUTHOR_TAG, we used the standard attention - based encoder - decoder model as a baseline.', 'we tested the impact of semantic gcns when used on top of cnn and birnn encoders.', 'as expected, birnn results are stronger than cnn ones.', 'in general, for both encoders we observe the same trend : using semantic gcns leads to an improvement over the baseline model.', '']",7
"['1 ).', 'as in  #TAUTHOR_TAG,']","['1 ).', 'as in  #TAUTHOR_TAG,']","[', we start with experiments with the smaller news commentary training set ( see table 1 ).', 'as in  #TAUTHOR_TAG, we used the standard attention - based encoder - decoder model as a baseline.', 'we tested the impact of semantic gcns']","[', we start with experiments with the smaller news commentary training set ( see table 1 ).', 'as in  #TAUTHOR_TAG, we used the standard attention - based encoder - decoder model as a baseline.', 'we tested the impact of semantic gcns when used on top of cnn and birnn encoders.', 'as expected, birnn results are stronger than cnn ones.', 'in general, for both encoders we observe the same trend : using semantic gcns leads to an improvement over the baseline model.', '']",7
"['10, 11, 12, 13,  #TAUTHOR_TAG 15, 16, 17 ]']","['on acoustic word embeddings, focused on a number of embedding models, training approaches, and tasks [ 10, 11, 12, 13,  #TAUTHOR_TAG 15, 16, 17 ]']","['10, 11, 12, 13,  #TAUTHOR_TAG 15, 16, 17 ]']","['', 'an alternative to dtw that has begun to be explored is the use of acoustic word embeddings ( awes ), or vector representations of spoken word segments.', 'awes are representations that can be learned from data, ideally such that the embeddings of two segments corresponding to the same word are close, while embeddings of segments corresponding to different words are far apart.', 'once word segments are represented via fixed - dimensional embeddings, computing distances is as simple as measuring a cosine or euclidean distance between two vectors.', 'there has been some, thus far limited, work on acoustic word embeddings, focused on a number of embedding models, training approaches, and tasks [ 10, 11, 12, 13,  #TAUTHOR_TAG 15, 16, 17 ].', 'in this paper we explore new embedding models based on recurrent neural networks ( rnns )']",0
['.  #TAUTHOR_TAG compared'],['al.  #TAUTHOR_TAG compared'],['.  #TAUTHOR_TAG compared several types of acoustic word embeddings'],[' #TAUTHOR_TAG'],0
"['', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of']","['details.', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of']","['', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of the training segments']","['train the rnn - based embedding models using a set of pre - segmented spoken words.', 'we use two main training approaches, inspired by prior work but with some differences in the details.', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of the training segments and train the networks to classify the word.', '']",3
"[' #TAUTHOR_TAG, for']","[' #TAUTHOR_TAG, for']","['and test partitions as in prior work  #TAUTHOR_TAG, for']","['', 'by sweeping the threshold, we obtain a precision - recall curve from which we compute the ap.', 'the data used for this task is drawn from the switchboard conversational english corpus [ 32 ].', 'the word segments range from 50 to 200 frames in length.', 'the acoustic features in each frame ( the input to the word embedding models x t ) are 39 - dimensional mfccs + ∆ + ∆∆. we use the same train, development, and test partitions as in prior work  #TAUTHOR_TAG, for as direct a comparison as possible.', '']",3
"['', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of']","['details.', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of']","['', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of the training segments']","['train the rnn - based embedding models using a set of pre - segmented spoken words.', 'we use two main training approaches, inspired by prior work but with some differences in the details.', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of the training segments and train the networks to classify the word.', '']",5
"['', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of']","['details.', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of']","['', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of the training segments']","['train the rnn - based embedding models using a set of pre - segmented spoken words.', 'we use two main training approaches, inspired by prior work but with some differences in the details.', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of the training segments and train the networks to classify the word.', '']",5
"[' #TAUTHOR_TAG, for']","[' #TAUTHOR_TAG, for']","['and test partitions as in prior work  #TAUTHOR_TAG, for']","['', 'by sweeping the threshold, we obtain a precision - recall curve from which we compute the ap.', 'the data used for this task is drawn from the switchboard conversational english corpus [ 32 ].', 'the word segments range from 50 to 200 frames in length.', 'the acoustic features in each frame ( the input to the word embedding models x t ) are 39 - dimensional mfccs + ∆ + ∆∆. we use the same train, development, and test partitions as in prior work  #TAUTHOR_TAG, for as direct a comparison as possible.', '']",5
"[' #TAUTHOR_TAG, for']","[' #TAUTHOR_TAG, for']","['and test partitions as in prior work  #TAUTHOR_TAG, for']","['', 'by sweeping the threshold, we obtain a precision - recall curve from which we compute the ap.', 'the data used for this task is drawn from the switchboard conversational english corpus [ 32 ].', 'the word segments range from 50 to 200 frames in length.', 'the acoustic features in each frame ( the input to the word embedding models x t ) are 39 - dimensional mfccs + ∆ + ∆∆. we use the same train, development, and test partitions as in prior work  #TAUTHOR_TAG, for as direct a comparison as possible.', '']",5
"['', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of']","['details.', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of']","['', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of the training segments']","['train the rnn - based embedding models using a set of pre - segmented spoken words.', 'we use two main training approaches, inspired by prior work but with some differences in the details.', 'as in  #TAUTHOR_TAG 11 ], our first approach is to use the word labels of the training segments and train the networks to classify the word.', '']",7
['from  #TAUTHOR_TAG and'],['from  #TAUTHOR_TAG and'],"['on this task from  #TAUTHOR_TAG and the best prior result using dtw, obtained with frame features learned with']","['on development set results, our final embedding models are lstm networks with 3 stacked layers and 3 fully connected layers, with output dimensionality of 1024 in the case of siamese networks.', 'final test set results are given in table 1.', 'we include a comparison with the best prior results on this task from  #TAUTHOR_TAG and the best prior result using dtw, obtained with frame features learned with correlated autoencoders [ 22 ].', 'both classifier and siamese lstm embedding models outperform all prior results on this task of which we are aware.', '2 we next analyze the effects of model design choices, as well as the learned embeddings themselves.', 'table 2 shows the effect on development set performance of the number of stacked layers s, the number of fully connected layers f, and lstm vs. gru cells, for classifierbased embeddings.', 'the best performance in this experiment is achieved by the lstm network with s = f = 3.', 'however, performance still seems to be improving with additional layers, suggesting that we may be able to further improve performance by adding even more layers of either type.', '']",7
"['is not competitive  #TAUTHOR_TAG,']","['is not competitive  #TAUTHOR_TAG,']","['that is needed ; however, previous work has shown that this approach is not competitive  #TAUTHOR_TAG,']","['exploring a variety of stacked rnns, we fixed the stack to 3 layers and varied the number of fully connected layers.', 'the value of each additional fully connected layer is clearly greater than that of adding stacked layers.', 'all networks trained with 2 or 3 fully connected layers obtain more than 0. 4 ap on the development set, while stacked rnns with 1 fully connected layer are at around 0. 3 ap or less.', 'this may raise the question of whether some simple fully connected model may be all that is needed ; however, previous work has shown that this approach is not competitive  #TAUTHOR_TAG, and convolutional or recurrent layers are needed to summarize arbitrarylength segments into a fixed - dimensional representation']",7
"['allow all segments to serve as anchors.', 'this is a slight departure from earlier work  #TAUTHOR_TAG, which we found to improve stability in training and']","['allow all segments to serve as anchors.', 'this is a slight departure from earlier work  #TAUTHOR_TAG, which we found to improve stability in training and']","['allow all segments to serve as anchors.', 'this is a slight departure from earlier work  #TAUTHOR_TAG, which we found to improve stability in training and']","['experiments with siamese networks, we initialize ( warmstart ) the networks with the tuned classification network, removing the final log - softmax layer and replacing it with a linear layer of size equal to the desired embedding dimensionality.', 'we explored embeddings with dimensionalities between 8 and 2048.', 'we use a margin of 0. 4 in the cos - hinge loss.', 'in training the siamese networks, each training minibatch consists of 2b triplets.', 'b triplets are of the form ( x a, x s, x d ) where x a and x s are examples of the same class ( a pair from the 100k same - word pair set ) and x d is a randomly sampled example from a different class.', 'then, for each of these b triplets ( x a, x s, x d ), an additional triplet ( x s, x a, x d ) is added to the mini - batch to allow all segments to serve as anchors.', 'this is a slight departure from earlier work  #TAUTHOR_TAG, which we found to improve stability in training and performance on the development set.', 'in preliminary experiments, we compared two methods for choosing the negative examples x d during training, a uniform sampling approach and a non - uniform one.', 'in the case of uniform sampling, we sample x d uniformly at random from the full set of training examples with labels different from x a.', 'this sampling method requires only word - pair supervision.', 'in the case of non - uniform sampling, x d is sampled in two steps.', 'first, we construct a distribution p y | label ( xa ) over word labels y and sample a different label from it.', 'second, we sample an example uniformly from within the subset with the chosen label.', 'the goal of this method is to speed up training by targeting pairs that violate the margin constraint.', 'to construct the multinomial pmf p y | label ( xa ), we maintain an n × n matrix s, where n is the number of unique word labels in training.', 'each word label corresponds to an integer i ∈ [ 1, n ] and therefore a row in s. the values in a row of s are considered similarity scores, and we can retrieve the desired pmf for each row by normalizing by its sum.', ""at the start of each epoch, we initialize s with 0's along the diagonal and 1's elsewhere ( which reduces to uniform sampling )."", 'for each training pair ( d cos ( x a, x s ), d cos ( x a, x d ) ), we update']",4
['from  #TAUTHOR_TAG and'],['from  #TAUTHOR_TAG and'],"['on this task from  #TAUTHOR_TAG and the best prior result using dtw, obtained with frame features learned with']","['on development set results, our final embedding models are lstm networks with 3 stacked layers and 3 fully connected layers, with output dimensionality of 1024 in the case of siamese networks.', 'final test set results are given in table 1.', 'we include a comparison with the best prior results on this task from  #TAUTHOR_TAG and the best prior result using dtw, obtained with frame features learned with correlated autoencoders [ 22 ].', 'both classifier and siamese lstm embedding models outperform all prior results on this task of which we are aware.', '2 we next analyze the effects of model design choices, as well as the learned embeddings themselves.', 'table 2 shows the effect on development set performance of the number of stacked layers s, the number of fully connected layers f, and lstm vs. gru cells, for classifierbased embeddings.', 'the best performance in this experiment is achieved by the lstm network with s = f = 3.', 'however, performance still seems to be improving with additional layers, suggesting that we may be able to further improve performance by adding even more layers of either type.', '']",4
['with cnn - based embeddings  #TAUTHOR_TAG for'],['with cnn - based embeddings  #TAUTHOR_TAG for'],['with cnn - based embeddings  #TAUTHOR_TAG for all dimensionalities ≥ 16'],"['the siamese networks, we varied the output embedding dimensionality, as shown in fig. 2.', 'this analysis shows that the embeddings learned by the siamese rnn network are quite robust to reduced dimensionality, outperforming the classifier model for all dimensionalities 32 or higher and outperforming previously reported dev set performance with cnn - based embeddings  #TAUTHOR_TAG for all dimensionalities ≥ 16']",4
"['is backed by the easyccg parser  #TAUTHOR_TAG, slightly modified to allow for incorporating constraints, and other ccg parsers could be plugged in with similar modifications.', 'to do this,']","['is backed by the easyccg parser  #TAUTHOR_TAG, slightly modified to allow for incorporating constraints, and other ccg parsers could be plugged in with similar modifications.', 'to do this,']","['is backed by the easyccg parser  #TAUTHOR_TAG, slightly modified to allow for incorporating constraints, and other ccg parsers could be plugged in with similar modifications.', 'to do this,']","['', 'the current system is backed by the easyccg parser  #TAUTHOR_TAG, slightly modified to allow for incorporating constraints, and other ccg parsers could be plugged in with similar modifications.', '']",6
"['is backed by the easyccg parser  #TAUTHOR_TAG, slightly modified to allow for incorporating constraints, and other ccg parsers could be plugged in with similar modifications.', 'to do this,']","['is backed by the easyccg parser  #TAUTHOR_TAG, slightly modified to allow for incorporating constraints, and other ccg parsers could be plugged in with similar modifications.', 'to do this,']","['is backed by the easyccg parser  #TAUTHOR_TAG, slightly modified to allow for incorporating constraints, and other ccg parsers could be plugged in with similar modifications.', 'to do this,']","['', 'the current system is backed by the easyccg parser  #TAUTHOR_TAG, slightly modified to allow for incorporating constraints, and other ccg parsers could be plugged in with similar modifications.', '']",0
"['of natural language generation  #TAUTHOR_TAG.', 'narrative is generally acknowledged as a fundamental mode of presenting and communicating information between humans, with different manifestations across media but with a very significant presence in textual form.', 'yet efforts in natural language generation research have generally side stepped the issue.', 'aside']","['of natural language generation  #TAUTHOR_TAG.', 'narrative is generally acknowledged as a fundamental mode of presenting and communicating information between humans, with different manifestations across media but with a very significant presence in textual form.', 'yet efforts in natural language generation research have generally side stepped the issue.', 'aside']","['of natural language generation  #TAUTHOR_TAG.', 'narrative is generally acknowledged as a fundamental mode of presenting and communicating information between humans, with different manifestations across media but with a very significant presence in textual form.', 'yet efforts in natural language generation research have generally side stepped the issue.', 'aside']","['last few years have seen an increased interest in narrative within the field of natural language generation  #TAUTHOR_TAG.', 'narrative is generally acknowledged as a fundamental mode of presenting and communicating information between humans, with different manifestations across media but with a very significant presence in textual form.', 'yet efforts in natural language generation research have generally side stepped the issue.', 'aside from the pioneering work of  #AUTHOR_TAG and an early attempt to bridge the gap between narratology and natural language generation ( lonneker, 2005 ), the field had mostly avoided narrative until recent times.', '']",0
"['of natural language generation  #TAUTHOR_TAG.', 'narrative is generally acknowledged as a fundamental mode of presenting and communicating information between humans, with different manifestations across media but with a very significant presence in textual form.', 'yet efforts in natural language generation research have generally side stepped the issue.', 'aside']","['of natural language generation  #TAUTHOR_TAG.', 'narrative is generally acknowledged as a fundamental mode of presenting and communicating information between humans, with different manifestations across media but with a very significant presence in textual form.', 'yet efforts in natural language generation research have generally side stepped the issue.', 'aside']","['of natural language generation  #TAUTHOR_TAG.', 'narrative is generally acknowledged as a fundamental mode of presenting and communicating information between humans, with different manifestations across media but with a very significant presence in textual form.', 'yet efforts in natural language generation research have generally side stepped the issue.', 'aside']","['last few years have seen an increased interest in narrative within the field of natural language generation  #TAUTHOR_TAG.', 'narrative is generally acknowledged as a fundamental mode of presenting and communicating information between humans, with different manifestations across media but with a very significant presence in textual form.', 'yet efforts in natural language generation research have generally side stepped the issue.', 'aside from the pioneering work of  #AUTHOR_TAG and an early attempt to bridge the gap between narratology and natural language generation ( lonneker, 2005 ), the field had mostly avoided narrative until recent times.', '']",0
['earlier version  #TAUTHOR_TAG'],['earlier version  #TAUTHOR_TAG'],['earlier version  #TAUTHOR_TAG'],"['##bi 14 which has an f - score of 88 % for parsing biomedical text. biosimplify can also be used with penn trees produced from other parsers like stanford parser and link grammar that can', 'produce ptb - style 16 output and also from penn trees created apriori. our goal is to produce all possible grammatically correct simplified sentences,', 'assuming the available penn tree is completely accurate. table 1 describes the algorithm for syntactic simplification to produce grammatically correct sentences. the', 'algorithm has a time complexity of o ( n 2 * r ), where n is the number of tokens in the', ""sentence and r is the number of simplifications rules. the average time complexity is, however, o ( nlog ( n ) * r ). one of the features of biosimplify is avoidance of domainspecific rules. for example, we don't replace entity names ( like genes ) with"", 'shorter alternatives as is done with the noun phrases in the present version and with the gene names in our earlier version  #TAUTHOR_TAG. we also avoided hard - coding the words in the rules created to', '']",4
['older version  #TAUTHOR_TAG'],['older version  #TAUTHOR_TAG'],['with the older version  #TAUTHOR_TAG'],"['the purpose of evaluating the impact of sentence simplification, we use aimed 17 corpus ( which is extensively used in comparing ppi extraction methods ) and pie 18 ( a machine - learning based approach available as a web service that uses the parse tree information from the collins statistical parser as its key component ).', 'pie returns two kinds of results - one with a high precision, which we call tight pie ; and the other with low precision, which we call light pie.', 'we also compare the present version of biosimplify with the older version  #TAUTHOR_TAG which is limited in its functionality because it only implements the rules described by siddharthan 4.', 'the present version which has an average time complexity of o ( nlog ( n ) * r ) is faster than the older version which has a time complexity of o ( n 3 * r ), where n is the number of tokens in the sentence and r is the number of rules.', 'the older version has domain specific optimizations ( like replacing the gene names with single - word identifiers ), which were not used in the newer version for portability']",4
['older version  #TAUTHOR_TAG'],['older version  #TAUTHOR_TAG'],['with the older version  #TAUTHOR_TAG'],"['the purpose of evaluating the impact of sentence simplification, we use aimed 17 corpus ( which is extensively used in comparing ppi extraction methods ) and pie 18 ( a machine - learning based approach available as a web service that uses the parse tree information from the collins statistical parser as its key component ).', 'pie returns two kinds of results - one with a high precision, which we call tight pie ; and the other with low precision, which we call light pie.', 'we also compare the present version of biosimplify with the older version  #TAUTHOR_TAG which is limited in its functionality because it only implements the rules described by siddharthan 4.', 'the present version which has an average time complexity of o ( nlog ( n ) * r ) is faster than the older version which has a time complexity of o ( n 3 * r ), where n is the number of tokens in the sentence and r is the number of rules.', 'the older version has domain specific optimizations ( like replacing the gene names with single - word identifiers ), which were not used in the newer version for portability']",5
"['data set and evaluation metric as  #TAUTHOR_TAG, which reports results for learned policies based on maximum entropy models.', 'in this paper, we add a comparison to a hand - authored']","['data set and evaluation metric as  #TAUTHOR_TAG, which reports results for learned policies based on maximum entropy models.', 'in this paper, we add a comparison to a hand - authored']","['previous work.', 'as we summarize in section 2, this paper relies on the same data set and evaluation metric as  #TAUTHOR_TAG, which reports results for learned policies based on maximum entropy models.', 'in this paper, we add a comparison to a hand - authored policy ( rules ) and a new policy based on relevance models ( rm ).', 'these new policies are described in section 3.', 'we conclude with']","['', 'traditionally, designing a two step nlu + dm pipeline involves defining semantic representations for the dialogue domain and writing rules that constitute the dialogue policy.', 'this modular design has the benefit of making the dm policy easy to express in explicit rules, but carries the development cost of requiring significant linguistic expertise.', 'additionally, as we illustrate in this paper, its performance can depend critically on the reliability of the nlu module.', 'as an alternative, we contrast this design with a direct classification approach that relies only on textual examples and effectively combines the dialogue policy with nlu.', 'in our case study evaluation, we find that this approach offers superior performance, owing to the high frequency of nlu errors in the two step pipeline.', 'the research presented in this paper extends our previous work.', 'as we summarize in section 2, this paper relies on the same data set and evaluation metric as  #TAUTHOR_TAG, which reports results for learned policies based on maximum entropy models.', 'in this paper, we add a comparison to a hand - authored policy ( rules ) and a new policy based on relevance models ( rm ).', 'these new policies are described in section 3.', '']",3
"[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[', for an average of 15. 6 turns / dialogue. the task', ""of amani's dialogue manager ( dm )"", ""is to select the most appropriate system sa to use in response to a user utterance. in the experiments reported here, the user's utterance may be"", 'provided to the dm either directly as text or using a sa label', "". we call the dm's decision process a dialogue policy. the system builders'intended policy for amani is detailed in  #TAUTHOR_TAG"", '. because amani has only a fixed set of system responses, the policy problem looks like a traditional classification task. however, there are two sources of uncertainty that complicate the task. firstly', "", the mapping between the user's utterance and an appropriate system sa is often one - tomany. in our data set, 6 referees independently linked each user utterance to the best system sa"", 'response. in figure 1, we provide an example in which three different system sas were selected by the 6 referees. in other cases, up to 6 different system sas', '']",3
"[' #TAUTHOR_TAG, which counts']","[' #TAUTHOR_TAG, which counts']","[' #TAUTHOR_TAG, which counts']",[' #TAUTHOR_TAG'],3
"['data set and evaluation metric as  #TAUTHOR_TAG, which reports results for learned policies based on maximum entropy models.', 'in this paper, we add a comparison to a hand - authored']","['data set and evaluation metric as  #TAUTHOR_TAG, which reports results for learned policies based on maximum entropy models.', 'in this paper, we add a comparison to a hand - authored']","['previous work.', 'as we summarize in section 2, this paper relies on the same data set and evaluation metric as  #TAUTHOR_TAG, which reports results for learned policies based on maximum entropy models.', 'in this paper, we add a comparison to a hand - authored policy ( rules ) and a new policy based on relevance models ( rm ).', 'these new policies are described in section 3.', 'we conclude with']","['', 'traditionally, designing a two step nlu + dm pipeline involves defining semantic representations for the dialogue domain and writing rules that constitute the dialogue policy.', 'this modular design has the benefit of making the dm policy easy to express in explicit rules, but carries the development cost of requiring significant linguistic expertise.', 'additionally, as we illustrate in this paper, its performance can depend critically on the reliability of the nlu module.', 'as an alternative, we contrast this design with a direct classification approach that relies only on textual examples and effectively combines the dialogue policy with nlu.', 'in our case study evaluation, we find that this approach offers superior performance, owing to the high frequency of nlu errors in the two step pipeline.', 'the research presented in this paper extends our previous work.', 'as we summarize in section 2, this paper relies on the same data set and evaluation metric as  #TAUTHOR_TAG, which reports results for learned policies based on maximum entropy models.', 'in this paper, we add a comparison to a hand - authored policy ( rules ) and a new policy based on relevance models ( rm ).', 'these new policies are described in section 3.', '']",5
"[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[', for an average of 15. 6 turns / dialogue. the task', ""of amani's dialogue manager ( dm )"", ""is to select the most appropriate system sa to use in response to a user utterance. in the experiments reported here, the user's utterance may be"", 'provided to the dm either directly as text or using a sa label', "". we call the dm's decision process a dialogue policy. the system builders'intended policy for amani is detailed in  #TAUTHOR_TAG"", '. because amani has only a fixed set of system responses, the policy problem looks like a traditional classification task. however, there are two sources of uncertainty that complicate the task. firstly', "", the mapping between the user's utterance and an appropriate system sa is often one - tomany. in our data set, 6 referees independently linked each user utterance to the best system sa"", 'response. in figure 1, we provide an example in which three different system sas were selected by the 6 referees. in other cases, up to 6 different system sas', '']",5
"[' #TAUTHOR_TAG, which counts']","[' #TAUTHOR_TAG, which counts']","[' #TAUTHOR_TAG, which counts']",[' #TAUTHOR_TAG'],5
"[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[', for an average of 15. 6 turns / dialogue. the task', ""of amani's dialogue manager ( dm )"", ""is to select the most appropriate system sa to use in response to a user utterance. in the experiments reported here, the user's utterance may be"", 'provided to the dm either directly as text or using a sa label', "". we call the dm's decision process a dialogue policy. the system builders'intended policy for amani is detailed in  #TAUTHOR_TAG"", '. because amani has only a fixed set of system responses, the policy problem looks like a traditional classification task. however, there are two sources of uncertainty that complicate the task. firstly', "", the mapping between the user's utterance and an appropriate system sa is often one - tomany. in our data set, 6 referees independently linked each user utterance to the best system sa"", 'response. in figure 1, we provide an example in which three different system sas were selected by the 6 referees. in other cases, up to 6 different system sas', '']",0
"[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[', for an average of 15. 6 turns / dialogue. the task', ""of amani's dialogue manager ( dm )"", ""is to select the most appropriate system sa to use in response to a user utterance. in the experiments reported here, the user's utterance may be"", 'provided to the dm either directly as text or using a sa label', "". we call the dm's decision process a dialogue policy. the system builders'intended policy for amani is detailed in  #TAUTHOR_TAG"", '. because amani has only a fixed set of system responses, the policy problem looks like a traditional classification task. however, there are two sources of uncertainty that complicate the task. firstly', "", the mapping between the user's utterance and an appropriate system sa is often one - tomany. in our data set, 6 referees independently linked each user utterance to the best system sa"", 'response. in figure 1, we provide an example in which three different system sas were selected by the 6 referees. in other cases, up to 6 different system sas', '']",0
"[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[""##ers'intended policy for amani is detailed in  #TAUTHOR_TAG"", '']","[', for an average of 15. 6 turns / dialogue. the task', ""of amani's dialogue manager ( dm )"", ""is to select the most appropriate system sa to use in response to a user utterance. in the experiments reported here, the user's utterance may be"", 'provided to the dm either directly as text or using a sa label', "". we call the dm's decision process a dialogue policy. the system builders'intended policy for amani is detailed in  #TAUTHOR_TAG"", '. because amani has only a fixed set of system responses, the policy problem looks like a traditional classification task. however, there are two sources of uncertainty that complicate the task. firstly', "", the mapping between the user's utterance and an appropriate system sa is often one - tomany. in our data set, 6 referees independently linked each user utterance to the best system sa"", 'response. in figure 1, we provide an example in which three different system sas were selected by the 6 referees. in other cases, up to 6 different system sas', '']",0
"[' #TAUTHOR_TAG, which counts']","[' #TAUTHOR_TAG, which counts']","[' #TAUTHOR_TAG, which counts']",[' #TAUTHOR_TAG'],0
"['', 'as previously reported in  #TAUTHOR_TAG, a']","['on gold sa labels.', 'as previously reported in  #TAUTHOR_TAG, a']","['on gold sa labels.', 'as previously reported in  #TAUTHOR_TAG, a performance']",[' #TAUTHOR_TAG'],0
"[' #TAUTHOR_TAG further', 'showed that use of synthetic training data']","[' #TAUTHOR_TAG further', 'showed that use of synthetic training data can work']","[' #TAUTHOR_TAG further', 'showed that use of synthetic training data can work better than multitask training. in', 'this']",[' #TAUTHOR_TAG'],0
"['', 'following recent speech translation  #TAUTHOR_TAG and recognition']","['attention components, predict source and target phoneme sequences.', 'following recent speech translation  #TAUTHOR_TAG and recognition [ 28 ] models,']","['own attention components, predict source and target phoneme sequences.', 'following recent speech translation  #TAUTHOR_TAG and recognition [ 28 ] models, the encoder is composed of a stack of']","['overview of the proposed translatotron model architecture is shown in figure 1.', 'following [ 15, 26 ], it is composed of several separately trained components : 1 ) an attention - based sequence - to - sequence network ( blue ) which generates target spectrograms, 2 ) a vocoder ( red ) which converts target spectrograms to timedomain waveforms, and, 3 ) optionally, a pretrained speaker encoder ( green ) which can be used to condition the decoder on the identity of the source speaker, enabling cross - language voice conversion [ 27 ] simultaneously with translation.', 'the sequence - to - sequence encoder stack maps 80 - channel log - mel spectrogram input features into hidden states which are passed through an attention - based alignment mechanism to condition an autoregressive decoder, which predicts 1025 - dim log spectrogram frames corresponding to the translated speech.', 'two optional auxiliary decoders, each with their own attention components, predict source and target phoneme sequences.', 'following recent speech translation  #TAUTHOR_TAG and recognition [ 28 ] models, the encoder is composed of a stack of 8 bidirectional lstm layers.', '']",3
"['of parallel text and read speech pairs from  #TAUTHOR_TAG, and']","['of parallel text and read speech pairs from  #TAUTHOR_TAG, and']","['of parallel text and read speech pairs from  #TAUTHOR_TAG, and the spanish fisher corpus of telephone conversations']","['study two spanish - to - english translation datasets : the large scale "" conversational "" corpus of parallel text and read speech pairs from  #TAUTHOR_TAG, and the spanish fisher corpus of telephone conversations and corresponding english translations [ 38 ], which is smaller and more challenging due to the spontaneous and informal speaking style.', 'in sections 3. 1 and 3. 2, we synthesize target speech from the target transcript using a single ( female ) speaker english tts system ; in section 3. 4, we use real human target speech for voice transfer experiments on the conversational dataset.', 'models were implemented using the lingvo framework [ 39 ].', 'see table 1 for dataset - specific hyperparameters.', 'to evaluate speech - to - speech translation performance we compute bleu scores [ 40 ] as an objective measure of speech intelligibility and translation quality, by using a pretrained asr system to recognize the generated speech, and comparing the resulting transcripts to ground truth reference translations.', 'due to potential recognition errors ( see figure 2 ), this can be thought of as a lower bound on the underlying translation quality.', 'we use the 16k word - piece attention - based asr model from [ 41 ] trained on the 960 hour librispeech corpus [ 42 ], which obtained word error rates of 4. 7 % and 13. 4 % on the test - clean and testother sets, respectively.', 'in addition, we conduct listening tests to measure subjective speech naturalness mean opinion score ( mos ), as well as speaker similarity mos for voice transfer']",3
"['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model to synthesize target in addition, we augment the input source speech by adding background noise and reverberation in the same manner as  #TAUTHOR_TAG.', 'the resulting dataset contains 979k parallel utterance pairs, containing 1. 4k hours of source speech and 619 hours of synthesized target speech.', 'the total target speech duration is much smaller because the tts output is better endpointed, and contains fewer pauses.', '9. 6k pairs are held out for testing.', 'input feature frames are created by stacking 3 adjacent frames of an 80 - channel log - mel spectrogram as in  #TAUTHOR_TAG.', 'the speaker encoder was not used in these experiments since the target speech always came from the same speaker.', 'table 2 shows performance of the model trained using different combinations of auxiliary losses, compared to a baseline st → tts cascade model using a speech - to - text translation model  #TAUTHOR_TAG trained on the same data, and the same tacotron 2 tts model used to synthesize training targets.', '']",3
"['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model to synthesize target in addition, we augment the input source speech by adding background noise and reverberation in the same manner as  #TAUTHOR_TAG.', 'the resulting dataset contains 979k parallel utterance pairs, containing 1. 4k hours of source speech and 619 hours of synthesized target speech.', 'the total target speech duration is much smaller because the tts output is better endpointed, and contains fewer pauses.', '9. 6k pairs are held out for testing.', 'input feature frames are created by stacking 3 adjacent frames of an 80 - channel log - mel spectrogram as in  #TAUTHOR_TAG.', 'the speaker encoder was not used in these experiments since the target speech always came from the same speaker.', 'table 2 shows performance of the model trained using different combinations of auxiliary losses, compared to a baseline st → tts cascade model using a speech - to - text translation model  #TAUTHOR_TAG trained on the same data, and the same tacotron 2 tts model used to synthesize training targets.', '']",3
"['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model to synthesize target in addition, we augment the input source speech by adding background noise and reverberation in the same manner as  #TAUTHOR_TAG.', 'the resulting dataset contains 979k parallel utterance pairs, containing 1. 4k hours of source speech and 619 hours of synthesized target speech.', 'the total target speech duration is much smaller because the tts output is better endpointed, and contains fewer pauses.', '9. 6k pairs are held out for testing.', 'input feature frames are created by stacking 3 adjacent frames of an 80 - channel log - mel spectrogram as in  #TAUTHOR_TAG.', 'the speaker encoder was not used in these experiments since the target speech always came from the same speaker.', 'table 2 shows performance of the model trained using different combinations of auxiliary losses, compared to a baseline st → tts cascade model using a speech - to - text translation model  #TAUTHOR_TAG trained on the same data, and the same tacotron 2 tts model used to synthesize training targets.', '']",3
"[', as in  #TAUTHOR_TAG, we find that pretraining']","['conversational task, where both attention mechanisms had similar performance.', 'finally, as in  #TAUTHOR_TAG, we find that pretraining']","[', as in  #TAUTHOR_TAG, we find that pretraining the bottom 6 encoder layers on an st task improves bleu scores by over 5 points.', 'this is the best performing direct s2st model, obtaining 76 % of the baseline performance']","['dataset contains about 120k parallel utterance pairs 2, spanning 127 hours of source speech.', 'target speech is synthesized using parallel wavenet [ 43 ] using the same voice as the previous section.', 'the result contains 96 hours of synthetic target speech.', 'following [ 19 ], input features were constructed by stacking 80 - channel log - mel spectrograms, with deltas and accelerations.', 'given the small size of the dataset compared to that in sec. 3. 1, we found that obtaining good performance required significantly 2 this is a subset of the fisher data due to tts errors on target text.', 'more careful regularization and tuning.', 'as shown in table 1, we used narrower encoder dimension of 256, a shallower 4 - layer decoder, and added gaussian weight noise to all lstm weights as regularization, as in [ 19 ].', 'the model was especially sensitive to the auxiliary decoder hyperparameters, with the best performance coming when passing activations from intermediate layers of the encoder stack as inputs to the auxiliary decoders, using slightly more aggressive dropout of 0. 3, and decaying the auxiliary loss weight over the course of training in order to encourage the model training to fit the primary s2st task.', 'experiment results are shown in table 3.', 'once again using two auxiliary losses works best, but in contrast to section 3. 1, there is a large performance boost relative to using either one alone.', 'performance using only the source recognition loss is very poor, indicating that learning alignment on this task is especially difficult without strong supervision on the translation task.', 'we found that 4 - head attention works better than one head, unlike the conversational task, where both attention mechanisms had similar performance.', 'finally, as in  #TAUTHOR_TAG, we find that pretraining the bottom 6 encoder layers on an st task improves bleu scores by over 5 points.', 'this is the best performing direct s2st model, obtaining 76 % of the baseline performance']",3
"['', 'following recent speech translation  #TAUTHOR_TAG and recognition']","['attention components, predict source and target phoneme sequences.', 'following recent speech translation  #TAUTHOR_TAG and recognition [ 28 ] models,']","['own attention components, predict source and target phoneme sequences.', 'following recent speech translation  #TAUTHOR_TAG and recognition [ 28 ] models, the encoder is composed of a stack of']","['overview of the proposed translatotron model architecture is shown in figure 1.', 'following [ 15, 26 ], it is composed of several separately trained components : 1 ) an attention - based sequence - to - sequence network ( blue ) which generates target spectrograms, 2 ) a vocoder ( red ) which converts target spectrograms to timedomain waveforms, and, 3 ) optionally, a pretrained speaker encoder ( green ) which can be used to condition the decoder on the identity of the source speaker, enabling cross - language voice conversion [ 27 ] simultaneously with translation.', 'the sequence - to - sequence encoder stack maps 80 - channel log - mel spectrogram input features into hidden states which are passed through an attention - based alignment mechanism to condition an autoregressive decoder, which predicts 1025 - dim log spectrogram frames corresponding to the translated speech.', 'two optional auxiliary decoders, each with their own attention components, predict source and target phoneme sequences.', 'following recent speech translation  #TAUTHOR_TAG and recognition [ 28 ] models, the encoder is composed of a stack of 8 bidirectional lstm layers.', '']",5
"['of parallel text and read speech pairs from  #TAUTHOR_TAG, and']","['of parallel text and read speech pairs from  #TAUTHOR_TAG, and']","['of parallel text and read speech pairs from  #TAUTHOR_TAG, and the spanish fisher corpus of telephone conversations']","['study two spanish - to - english translation datasets : the large scale "" conversational "" corpus of parallel text and read speech pairs from  #TAUTHOR_TAG, and the spanish fisher corpus of telephone conversations and corresponding english translations [ 38 ], which is smaller and more challenging due to the spontaneous and informal speaking style.', 'in sections 3. 1 and 3. 2, we synthesize target speech from the target transcript using a single ( female ) speaker english tts system ; in section 3. 4, we use real human target speech for voice transfer experiments on the conversational dataset.', 'models were implemented using the lingvo framework [ 39 ].', 'see table 1 for dataset - specific hyperparameters.', 'to evaluate speech - to - speech translation performance we compute bleu scores [ 40 ] as an objective measure of speech intelligibility and translation quality, by using a pretrained asr system to recognize the generated speech, and comparing the resulting transcripts to ground truth reference translations.', 'due to potential recognition errors ( see figure 2 ), this can be thought of as a lower bound on the underlying translation quality.', 'we use the 16k word - piece attention - based asr model from [ 41 ] trained on the 960 hour librispeech corpus [ 42 ], which obtained word error rates of 4. 7 % and 13. 4 % on the test - clean and testother sets, respectively.', 'in addition, we conduct listening tests to measure subjective speech naturalness mean opinion score ( mos ), as well as speaker similarity mos for voice transfer']",5
"['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model to synthesize target in addition, we augment the input source speech by adding background noise and reverberation in the same manner as  #TAUTHOR_TAG.', 'the resulting dataset contains 979k parallel utterance pairs, containing 1. 4k hours of source speech and 619 hours of synthesized target speech.', 'the total target speech duration is much smaller because the tts output is better endpointed, and contains fewer pauses.', '9. 6k pairs are held out for testing.', 'input feature frames are created by stacking 3 adjacent frames of an 80 - channel log - mel spectrogram as in  #TAUTHOR_TAG.', 'the speaker encoder was not used in these experiments since the target speech always came from the same speaker.', 'table 2 shows performance of the model trained using different combinations of auxiliary losses, compared to a baseline st → tts cascade model using a speech - to - text translation model  #TAUTHOR_TAG trained on the same data, and the same tacotron 2 tts model used to synthesize training targets.', '']",5
"['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model to synthesize target in addition, we augment the input source speech by adding background noise and reverberation in the same manner as  #TAUTHOR_TAG.', 'the resulting dataset contains 979k parallel utterance pairs, containing 1. 4k hours of source speech and 619 hours of synthesized target speech.', 'the total target speech duration is much smaller because the tts output is better endpointed, and contains fewer pauses.', '9. 6k pairs are held out for testing.', 'input feature frames are created by stacking 3 adjacent frames of an 80 - channel log - mel spectrogram as in  #TAUTHOR_TAG.', 'the speaker encoder was not used in these experiments since the target speech always came from the same speaker.', 'table 2 shows performance of the model trained using different combinations of auxiliary losses, compared to a baseline st → tts cascade model using a speech - to - text translation model  #TAUTHOR_TAG trained on the same data, and the same tacotron 2 tts model used to synthesize training targets.', '']",5
"['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model to synthesize target in addition, we augment the input source speech by adding background noise and reverberation in the same manner as  #TAUTHOR_TAG.', 'the resulting dataset contains 979k parallel utterance pairs, containing 1. 4k hours of source speech and 619 hours of synthesized target speech.', 'the total target speech duration is much smaller because the tts output is better endpointed, and contains fewer pauses.', '9. 6k pairs are held out for testing.', 'input feature frames are created by stacking 3 adjacent frames of an 80 - channel log - mel spectrogram as in  #TAUTHOR_TAG.', 'the speaker encoder was not used in these experiments since the target speech always came from the same speaker.', 'table 2 shows performance of the model trained using different combinations of auxiliary losses, compared to a baseline st → tts cascade model using a speech - to - text translation model  #TAUTHOR_TAG trained on the same data, and the same tacotron 2 tts model used to synthesize training targets.', '']",4
"['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model']","['proprietary dataset described in  #TAUTHOR_TAG was obtained by crowdsourcing humans to read the both sides of a conversational spanish - english mt dataset.', 'in this section, instead of using the human target speech, we use a tts model to synthesize target in addition, we augment the input source speech by adding background noise and reverberation in the same manner as  #TAUTHOR_TAG.', 'the resulting dataset contains 979k parallel utterance pairs, containing 1. 4k hours of source speech and 619 hours of synthesized target speech.', 'the total target speech duration is much smaller because the tts output is better endpointed, and contains fewer pauses.', '9. 6k pairs are held out for testing.', 'input feature frames are created by stacking 3 adjacent frames of an 80 - channel log - mel spectrogram as in  #TAUTHOR_TAG.', 'the speaker encoder was not used in these experiments since the target speech always came from the same speaker.', 'table 2 shows performance of the model trained using different combinations of auxiliary losses, compared to a baseline st → tts cascade model using a speech - to - text translation model  #TAUTHOR_TAG trained on the same data, and the same tacotron 2 tts model used to synthesize training targets.', '']",6
"['includes utilizing weakly supervision to scale up training with synthetic data  #TAUTHOR_TAG or multitask learning [ 19, 20 ], and transferring prosody and other acoustic factors from the source']","['includes utilizing weakly supervision to scale up training with synthetic data  #TAUTHOR_TAG or multitask learning [ 19, 20 ], and transferring prosody and other acoustic factors from the source']","['include improving the speaker encoder by adding a language adversarial loss, or by incorporating a cycle - consistency term [ 13 ] into the s2st loss.', 'other future work includes utilizing weakly supervision to scale up training with synthetic data  #TAUTHOR_TAG or multitask learning [ 19, 20 ], and transferring prosody and other acoustic factors from the source speech to the translated speech following [ 45 ] [ 46 ] [ 47 ]']","['present a direct speech - to - speech translation model, trained end - to - end.', 'we find that it is important to use speech transcripts during training, but no intermediate speech transcription is necessary for inference.', 'exploring alternate training strategies which alleviate this requirement is an interesting direction for future work.', 'the model achieves high translation quality on two spanish - to - english datasets, although performance is not as good as a baseline cascade of st and tts models.', ""in addition, we demonstrate a variant which simultaneously transfers the source speaker's voice to the translated speech."", 'the voice transfer does not work as well as in a similar tts context [ 15 ], reflecting the difficulty of the cross - language voice transfer task, as well as evaluation [ 44 ].', 'potential strategies to improve voice transfer performance include improving the speaker encoder by adding a language adversarial loss, or by incorporating a cycle - consistency term [ 13 ] into the s2st loss.', 'other future work includes utilizing weakly supervision to scale up training with synthetic data  #TAUTHOR_TAG or multitask learning [ 19, 20 ], and transferring prosody and other acoustic factors from the source speech to the translated speech following [ 45 ] [ 46 ] [ 47 ]']",2
"[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']","['visual question  #TAUTHOR_TAG, [ 1 ], [ 5 ]']","[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']",[' #TAUTHOR_TAG'],0
"[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']","['visual question  #TAUTHOR_TAG, [ 1 ], [ 5 ]']","[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']",[' #TAUTHOR_TAG'],0
"[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']","['visual question  #TAUTHOR_TAG, [ 1 ], [ 5 ]']","[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']",[' #TAUTHOR_TAG'],0
"[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']","['visual question  #TAUTHOR_TAG, [ 1 ], [ 5 ]']","[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']",[' #TAUTHOR_TAG'],0
"['2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","['[ 2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","[',  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']",[' #TAUTHOR_TAG'],0
"['2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","['[ 2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","[',  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']",[' #TAUTHOR_TAG'],0
"['2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","['[ 2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","[',  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']",[' #TAUTHOR_TAG'],0
,,,,0
,,,,0
['visual question  #TAUTHOR_TAG'],['visual question  #TAUTHOR_TAG'],['either uniformly collect n answers for every visual question  #TAUTHOR_TAG'],"['', ""today's status quo is to either uniformly collect n answers for every visual question  #TAUTHOR_TAG or collect multiple answers where the number is determined by external crowdsourcing conditions [ 1 ]."", '']",0
"['of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive']","['of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a crowd. as observed, relying on', ""an algorithm's confidence in its answer offers a valuable indicator over today""]","['. figure 6b also illustrates the advantage of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a']","['', 'seconds to answer a visual question. our approach fills an important', 'gap in the crowdsour', '##cing answer collection literature for targeting the allocation of extra answers only to visual questions where a diversity of answers is expected. figure 6b also illustrates the advantage of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a crowd. as observed, relying on', ""an algorithm's confidence in its answer offers a valuable indicator over today's status quo of passively budgeting. while we acknowledge this method is not intended for"", 'our task specifically, it still serves as an important baseline ( as discussed above ). we attribute the further performance gains of our prediction', 'system to it directly predicting whether humans will disagree rather than predicting a property of a specific algorithm ( e. g., confidence of the antol et al. algorithm in its answer prediction )']",0
"[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']","['visual question  #TAUTHOR_TAG, [ 1 ], [ 5 ]']","[' #TAUTHOR_TAG, [ 1 ], [ 5 ]']",[' #TAUTHOR_TAG'],4
"['2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","['[ 2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","[',  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']",[' #TAUTHOR_TAG'],4
"['2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","['[ 2 ],  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']","[',  #TAUTHOR_TAG, [ 1 ], [ 4 ].', 'yet a commonality across these communities is they adopt a one - size - fits - all approach']",[' #TAUTHOR_TAG'],4
,,,,4
"['literature  #TAUTHOR_TAG, [ 22 ].']","['literature  #TAUTHOR_TAG, [ 22 ].']","['stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ].']","['', 'our overall finding that most of the predictive power stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ]. this does not mean, however, that the image', 'content is not predictive. further work improving visual content cues for vqa agreement is warranted. our findings suggest', '']",4
"['literature  #TAUTHOR_TAG, [ 22 ].']","['literature  #TAUTHOR_TAG, [ 22 ].']","['stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ].']","['', 'our overall finding that most of the predictive power stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ]. this does not mean, however, that the image', 'content is not predictive. further work improving visual content cues for vqa agreement is warranted. our findings suggest', '']",4
['visual question  #TAUTHOR_TAG'],['visual question  #TAUTHOR_TAG'],['either uniformly collect n answers for every visual question  #TAUTHOR_TAG'],"['', ""today's status quo is to either uniformly collect n answers for every visual question  #TAUTHOR_TAG or collect multiple answers where the number is determined by external crowdsourcing conditions [ 1 ]."", '']",4
"['of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive']","['of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a crowd. as observed, relying on', ""an algorithm's confidence in its answer offers a valuable indicator over today""]","['. figure 6b also illustrates the advantage of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a']","['', 'seconds to answer a visual question. our approach fills an important', 'gap in the crowdsour', '##cing answer collection literature for targeting the allocation of extra answers only to visual questions where a diversity of answers is expected. figure 6b also illustrates the advantage of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a crowd. as observed, relying on', ""an algorithm's confidence in its answer offers a valuable indicator over today's status quo of passively budgeting. while we acknowledge this method is not intended for"", 'our task specifically, it still serves as an important baseline ( as discussed above ). we attribute the further performance gains of our prediction', 'system to it directly predicting whether humans will disagree rather than predicting a property of a specific algorithm ( e. g., confidence of the antol et al. algorithm in its answer prediction )']",4
,,,,5
,,,,5
,,,,5
,,,,5
"['literature  #TAUTHOR_TAG, [ 22 ].']","['literature  #TAUTHOR_TAG, [ 22 ].']","['stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ].']","['', 'our overall finding that most of the predictive power stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ]. this does not mean, however, that the image', 'content is not predictive. further work improving visual content cues for vqa agreement is warranted. our findings suggest', '']",5
"['literature  #TAUTHOR_TAG, [ 22 ].']","['literature  #TAUTHOR_TAG, [ 22 ].']","['stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ].']","['', 'our overall finding that most of the predictive power stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ]. this does not mean, however, that the image', 'content is not predictive. further work improving visual content cues for vqa agreement is warranted. our findings suggest', '']",5
"['of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive']","['of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a crowd. as observed, relying on', ""an algorithm's confidence in its answer offers a valuable indicator over today""]","['. figure 6b also illustrates the advantage of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a']","['', 'seconds to answer a visual question. our approach fills an important', 'gap in the crowdsour', '##cing answer collection literature for targeting the allocation of extra answers only to visual questions where a diversity of answers is expected. figure 6b also illustrates the advantage of our system over a related vqa algorithm  #TAUTHOR_TAG for our novel application', 'of costsensitive answer', 'collection from a crowd. as observed, relying on', ""an algorithm's confidence in its answer offers a valuable indicator over today's status quo of passively budgeting. while we acknowledge this method is not intended for"", 'our task specifically, it still serves as an important baseline ( as discussed above ). we attribute the further performance gains of our prediction', 'system to it directly predicting whether humans will disagree rather than predicting a property of a specific algorithm ( e. g., confidence of the antol et al. algorithm in its answer prediction )']",5
"['literature  #TAUTHOR_TAG, [ 22 ].']","['literature  #TAUTHOR_TAG, [ 22 ].']","['stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ].']","['', 'our overall finding that most of the predictive power stems from language - based features parallels feature analysis findings in the automated vqa literature  #TAUTHOR_TAG, [ 22 ]. this does not mean, however, that the image', 'content is not predictive. further work improving visual content cues for vqa agreement is warranted. our findings suggest', '']",3
"['dataset  #TAUTHOR_TAG, our model exhibits better results than']","['dataset  #TAUTHOR_TAG, our model exhibits better results than']","['it reads a document.', 'evaluated on a recent large scale dataset  #TAUTHOR_TAG, our model exhibits better results than']","['propose a novel neural network model for machine reading, der network, which explicitly implements a reader building dynamic meaning representations for entities by gathering and accumulating information around the entities as it reads a document.', 'evaluated on a recent large scale dataset  #TAUTHOR_TAG, our model exhibits better results than previous research, and we find that max - pooling is suited for modeling the accumulation of information on entities.', 'further analysis suggests that our model can put together multiple pieces of information encoded in different sentences to answer complicated questions.', 'our code for the model is available at https : / / github.', 'com / soskek / der -']",5
"[' #TAUTHOR_TAG, our model estimates the conditional probability p (']","[' #TAUTHOR_TAG, our model estimates the conditional probability']","[' #TAUTHOR_TAG, our model estimates the conditional probability p (']","[' #TAUTHOR_TAG, our model estimates the conditional probability p ( e | d, q ), where q is a query and d is a document.', '']",5
['- qa dataset  #TAUTHOR_TAG'],['use the cnn - qa dataset  #TAUTHOR_TAG'],['use the cnn - qa dataset  #TAUTHOR_TAG'],"[""use the cnn - qa dataset  #TAUTHOR_TAG for evaluating our model's ability to answer questions about named entities."", 'the dataset consists of ( d, q, e ) - triples, where the document d is taken from online news articles, and the query q is formed by hiding a named entity e in a summarizing bullet point of the document ( figure 1 ).', '']",5
"['summaries  #TAUTHOR_TAG, by replacing named entities in']","['summaries  #TAUTHOR_TAG, by replacing named entities in']","['summaries  #TAUTHOR_TAG, by replacing named entities in']","['', 'recently, large scale datasets of document - queryanswer triples have been constructed from online newspaper articles and their summaries  #TAUTHOR_TAG, by replacing named entities in the summaries with placeholders to form cloze  #AUTHOR_TAG style questions ( figure 1 ).', 'these datasets have enabled training and testing of complicated neural network models of hypothesized machine readers  #TAUTHOR_TAG.', '( @ entity1 ) @ entity0 may be @ entity2 in the popular @ entity4 superhero films, but he recently dealt in some advanced bionic technology himself.', '@ entity0 recently presented a robotic arm to young @ entity7, a @ entity8 boy who is missing his right arm from just above his elbow.', 'the arm was made by @ entity12, a [UNK]! "" [ x ] "" star @ entity0 presents a young child with a bionic arm! figure 1 : a document - query - answer triple constructed from a news article and its bullet point summary.', '']",0
"['summaries  #TAUTHOR_TAG, by replacing named entities in']","['summaries  #TAUTHOR_TAG, by replacing named entities in']","['summaries  #TAUTHOR_TAG, by replacing named entities in']","['', 'recently, large scale datasets of document - queryanswer triples have been constructed from online newspaper articles and their summaries  #TAUTHOR_TAG, by replacing named entities in the summaries with placeholders to form cloze  #AUTHOR_TAG style questions ( figure 1 ).', 'these datasets have enabled training and testing of complicated neural network models of hypothesized machine readers  #TAUTHOR_TAG.', '( @ entity1 ) @ entity0 may be @ entity2 in the popular @ entity4 superhero films, but he recently dealt in some advanced bionic technology himself.', '@ entity0 recently presented a robotic arm to young @ entity7, a @ entity8 boy who is missing his right arm from just above his elbow.', 'the arm was made by @ entity12, a [UNK]! "" [ x ] "" star @ entity0 presents a young child with a bionic arm! figure 1 : a document - query - answer triple constructed from a news article and its bullet point summary.', '']",0
"['surface form of the entities  #TAUTHOR_TAG.', 'we, however, take']","['surface form of the entities  #TAUTHOR_TAG.', 'we, however, take']","['prevent additional world knowledge from being attached to the surface form of the entities  #TAUTHOR_TAG.', 'we, however, take']","['', 'this insight has been reflected by the anonymization process in construction of the dataset, in which coreferent entities ( e. g. "" robert downey jr. "" and "" downey "" ) are replaced by randomly permuted abstract entity markers ( e. g. "" @ en - tity0 "" ), in order to prevent additional world knowledge from being attached to the surface form of the entities  #TAUTHOR_TAG.', 'we, however, take it as a strong motivation to implement a reader that dynamically builds meaning representations for each entity, by gathering and accumulating information on that entity as it reads a document ( section 2 ).', 'evaluation of our model, der network, exhibits better results than previous research ( section 3 ).', 'in particular, we find that max - pooling of entity representations, which is intended to model the accumulation of information on entities, can drastically improve performance.', 'further analysis suggests that max - pooling can help our model draw multiple pieces of information from different sentences']",0
"['surface form of the entities  #TAUTHOR_TAG.', 'we, however, take']","['surface form of the entities  #TAUTHOR_TAG.', 'we, however, take']","['prevent additional world knowledge from being attached to the surface form of the entities  #TAUTHOR_TAG.', 'we, however, take']","['', 'this insight has been reflected by the anonymization process in construction of the dataset, in which coreferent entities ( e. g. "" robert downey jr. "" and "" downey "" ) are replaced by randomly permuted abstract entity markers ( e. g. "" @ en - tity0 "" ), in order to prevent additional world knowledge from being attached to the surface form of the entities  #TAUTHOR_TAG.', 'we, however, take it as a strong motivation to implement a reader that dynamically builds meaning representations for each entity, by gathering and accumulating information on that entity as it reads a document ( section 2 ).', 'evaluation of our model, der network, exhibits better results than previous research ( section 3 ).', 'in particular, we find that max - pooling of entity representations, which is intended to model the accumulation of information on entities, can drastically improve performance.', 'further analysis suggests that max - pooling can help our model draw multiple pieces of information from different sentences']",1
"[' #TAUTHOR_TAG, our model estimates the conditional probability p (']","[' #TAUTHOR_TAG, our model estimates the conditional probability']","[' #TAUTHOR_TAG, our model estimates the conditional probability p (']","[' #TAUTHOR_TAG, our model estimates the conditional probability p ( e | d, q ), where q is a query and d is a document.', '']",4
"[', we note that our model, full der network, shows the best results compared to several previous reader models  #TAUTHOR_TAG, endorsing our approach as promising.', 'the 99']","['encoded in ordinary words.', 'finally, we note that our model, full der network, shows the best results compared to several previous reader models  #TAUTHOR_TAG, endorsing our approach as promising.', 'the 99 % confidence intervals of the']","[', we note that our model, full der network, shows the best results compared to several previous reader models  #TAUTHOR_TAG, endorsing our approach as promising.', 'the 99 % confidence intervals of the results of full der network and the']","['', ' #AUTHOR_TAG and * * from  #AUTHOR_TAG.', '( @ entity1 ) @ entity0 may be @ entity2 in the popular @ entity4 superhero films, but he recently dealt in some advanced bionic technology himself.! [UNK]! @ entity7 received his robotic arm in the summer, then later had it upgraded to resemble a "" @ entity26 "" arm.! this past saturday, @ entity7 received an even more impressive gift, from "" @ entity2 "" himself.! [UNK]! the actor showed the child two arms, one from @ entity0\'s movies and one for @ entity7 : a real, working robotic @ entity2 arm.! clear effects, suggesting that the attention mechanism plays a key role in our model.', 'combining these two techniques helps more.', 'further, we note that initializing our model with pre - trained word vectors 10 is helpful, though world knowledge of entities has been prevented by the anonymization process.', 'this suggests that pre - trained word vectors may still bring extra linguistic knowledge encoded in ordinary words.', 'finally, we note that our model, full der network, shows the best results compared to several previous reader models  #TAUTHOR_TAG, endorsing our approach as promising.', 'the 99 % confidence intervals of the results of full der network and the one initialized by word2vec on the test set were [ 0. 700, 0. 740 ] and [ 0. 708, 0. 749 ], respectively ( measured by bootstrap tests ).', 'analysis in the example shown in figure 4, our basic model missed by paying little attention to the second and third sentences, probably because it does not mention @ entity0 ( downey ).', 'in contrast, maxpooling of @ entity2 ( iron man ) draws attention to the second and third sentences because iron man is said related to downey']",4
"[' #TAUTHOR_TAG.', 'we argue that this modified annotation scheme provides a better interface representation for semantic interpretation']","[' #TAUTHOR_TAG.', 'we argue that this modified annotation scheme provides a better interface representation for semantic interpretation']","[' #TAUTHOR_TAG.', 'we argue that this modified annotation scheme provides a better interface representation for semantic interpretation']","['this paper we present the development process of nlp - qt, a question treebank that will be used for data - driven parsing in the context of a domain - specific qa system for querying nlp resource metadata.', 'we motivate the need to build nlp - qt as a resource in its own right, by comparing the penn treebank - style annotation scheme used for questionbank  #AUTHOR_TAG with the modified np annotation for the penn treebank introduced by  #TAUTHOR_TAG.', 'we argue that this modified annotation scheme provides a better interface representation for semantic interpretation and show how it can be incorporated into the nlp - qt resource, without significant loss in parser performance.', 'the parsing experiments reported in the paper confirm the feasibility of an iterative, semi - automatic construction of the nlp - qt resource similar to the approach taken for questionbank.', ""at the same time, we propose to improve the iterative refinement technique used for questionbank by adopting  #AUTHOR_TAG's heuristics for selecting additional material to be handcorrected and added to the data set at each iteration""]",1
"[' #TAUTHOR_TAG.', 'we have argued that this modified annotation scheme provides a better interface representation for semantic interpretation']","[' #TAUTHOR_TAG.', 'we have argued that this modified annotation scheme provides a better interface representation for semantic interpretation']","[' #TAUTHOR_TAG.', 'we have argued that this modified annotation scheme provides a better interface representation for semantic interpretation']","['this paper we have presented the development process of the nlp - qt resource that will be used for data - driven parsing in the context of a domainspecific qa system for querying nlp resource metadata.', 'we have motivated the need to build nlp - qt as a resource in its own right by comparing the penn treebank - style annotation scheme used for questionbank with the modified np annotation for the penn treebank introduced by  #TAUTHOR_TAG.', 'we have argued that this modified annotation scheme provides a better interface representation for semantic interpretation and have shown how it can be incorporated into the nlp - qt resource, without significant loss in parser performance.', 'the parsing experiments reported in the paper confirm the feasibility of an iterative, semiautomatic construction of the nlp - qt resource similar to the approach taken for questionbank.', ""at the same time, we propose to improve the iterative refinement technique used for questionbank by adopting hwa's heuristics for selecting additional material to be hand - corrected and added to the data set at each iteration."", 'another important aspect in the creation of a treebank how to ensure a consistent and correct annotation of the linguistic material.', 'automatic error detection techniques that can be used to test the accuracy of the annotation have already been described in works like kveton and  #AUTHOR_TAG, for the part of speech annotation level, and  #AUTHOR_TAG, for the syntactic annotation level.', 'in future work on the nlp - qt, we plan to employ such methods in order to identify and to correct inconsistencies in the annotation']",1
"['##bank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation.']","['3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation.']","['3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation. section 3 will introduce the', ' #TAUTHOR_TAG annotation style and will']","['', '. in fact, it was this poor parser performance that led judge et al. to create questionbank, a special - purpose', 'treebank based on semeval data sets for question answering ( qa ). the data include the semeval qa data from 1999', '- 2001, part of the 2003 set ( 2000 questions ), and another 2000 questions provided by the cognitive computation group at the university of illinois, which were also test data for developing qa systems. training a statistical parser on', 'questionbank data, possibly in combination with penn treebank data, therefore seems to be an attractive alternative. in fact, this is precisely how judge et al. train their parser. however, for reasons explained in more detail in sections 2 and 3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation. section 3 will introduce the', ' #TAUTHOR_TAG annotation style and will motivate why it is appropriate for the qa system envisaged here. section 4 will present a set of parsing experiments for the berkeley parser trained on different combinations of treebank data discussed in sections 2 and 3. the final section summarizes the main results of this paper and discusses directions for future research']",5
['of shortcoming that led  #TAUTHOR_TAG to revise the penn'],['of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along'],"['each member of the compound.', 'it is precisely this type of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along the following lines :', '•']","['', 'the compound noun second language acquisition materials would be annotated in these resources as a single flat np, as shown in the left column of figure 1.', 'such a flat annotation does not provide sufficient information about the scope of each member of the compound.', 'it is precisely this type of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along the following lines :', '']",5
"['##bank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation.']","['3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation.']","['3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation. section 3 will introduce the', ' #TAUTHOR_TAG annotation style and will']","['', '. in fact, it was this poor parser performance that led judge et al. to create questionbank, a special - purpose', 'treebank based on semeval data sets for question answering ( qa ). the data include the semeval qa data from 1999', '- 2001, part of the 2003 set ( 2000 questions ), and another 2000 questions provided by the cognitive computation group at the university of illinois, which were also test data for developing qa systems. training a statistical parser on', 'questionbank data, possibly in combination with penn treebank data, therefore seems to be an attractive alternative. in fact, this is precisely how judge et al. train their parser. however, for reasons explained in more detail in sections 2 and 3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation. section 3 will introduce the', ' #TAUTHOR_TAG annotation style and will motivate why it is appropriate for the qa system envisaged here. section 4 will present a set of parsing experiments for the berkeley parser trained on different combinations of treebank data discussed in sections 2 and 3. the final section summarizes the main results of this paper and discusses directions for future research']",3
"['##bank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation.']","['3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation.']","['3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation. section 3 will introduce the', ' #TAUTHOR_TAG annotation style and will']","['', '. in fact, it was this poor parser performance that led judge et al. to create questionbank, a special - purpose', 'treebank based on semeval data sets for question answering ( qa ). the data include the semeval qa data from 1999', '- 2001, part of the 2003 set ( 2000 questions ), and another 2000 questions provided by the cognitive computation group at the university of illinois, which were also test data for developing qa systems. training a statistical parser on', 'questionbank data, possibly in combination with penn treebank data, therefore seems to be an attractive alternative. in fact, this is precisely how judge et al. train their parser. however, for reasons explained in more detail in sections 2 and 3, we will adopt annotation guidelines for questions that differ from the penn treebank - style annotation used in questionbank. rather, we will follow a more', 'hierarchical annotation style for nps that has been proposed by  #TAUTHOR_TAG and that provides an easier interface for semantic interpretation. section 3 will introduce the', ' #TAUTHOR_TAG annotation style and will motivate why it is appropriate for the qa system envisaged here. section 4 will present a set of parsing experiments for the berkeley parser trained on different combinations of treebank data discussed in sections 2 and 3. the final section summarizes the main results of this paper and discusses directions for future research']",3
['of shortcoming that led  #TAUTHOR_TAG to revise the penn'],['of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along'],"['each member of the compound.', 'it is precisely this type of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along the following lines :', '•']","['', 'the compound noun second language acquisition materials would be annotated in these resources as a single flat np, as shown in the left column of figure 1.', 'such a flat annotation does not provide sufficient information about the scope of each member of the compound.', 'it is precisely this type of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along the following lines :', '']",3
['of experiments that we have conducted with the  #TAUTHOR_TAG annotation style'],['of experiments that we have conducted with the  #TAUTHOR_TAG annotation style'],['the set of experiments that we have conducted with the  #TAUTHOR_TAG annotation style'],"['section summarizes the set of experiments that we have conducted with the  #TAUTHOR_TAG annotation style for nps and in particular with the nlp - qt data set.', 'we discuss two types of experiments :', '• comparing the performance of the parser using different annotation styles for base nps,', '• experiments for optimizing the language model of a statistical parser in order to assist with the semi - automatic creation of the treebank.', 'all the experiments were performed with the berkeley parser.', 'the results are summarized in table 2 and table 3']",3
['with nps annotated in the  #TAUTHOR_TAG style ) serves as a'],['( with nps annotated in the  #TAUTHOR_TAG style ) serves as a'],"['with nps annotated in the  #TAUTHOR_TAG style ) serves as a baseline ( the model is called np - wsj in the table ).', 'this model']","['creation of a treebank is a time - consuming and expensive task if all the annotation has to be performed manually.', 'it is therefore useful to investigate whether at least parts of the annotation can be performed automatically or by a combination of automatic analysis and manual post editing.', 'to this end, we performed a set of parsing experiments, again using the berkeley parser, where the test data are taken both from the questionbank and a seed set of 500 manually annotated questions from the nlp - qt.', 'the results are shown in table 3.', 'as in the experiments shown in the previous subsection, the performance with a model trained purely on penn treebank data ( with nps annotated in the  #TAUTHOR_TAG style ) serves as a baseline ( the model is called np - wsj in the table ).', 'this model is then enriched by first adding annotated data from question bank and then by adding the manually annotated questions from the nlp - qt.', 'we refer to these models as np - wsjqb and npwsjqblq 500, respectively.', 'the results are very encouraging on several dimensions :', '']",3
['of shortcoming that led  #TAUTHOR_TAG to revise the penn'],['of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along'],"['each member of the compound.', 'it is precisely this type of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along the following lines :', '•']","['', 'the compound noun second language acquisition materials would be annotated in these resources as a single flat np, as shown in the left column of figure 1.', 'such a flat annotation does not provide sufficient information about the scope of each member of the compound.', 'it is precisely this type of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along the following lines :', '']",0
['of shortcoming that led  #TAUTHOR_TAG to revise the penn'],['of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along'],"['each member of the compound.', 'it is precisely this type of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along the following lines :', '•']","['', 'the compound noun second language acquisition materials would be annotated in these resources as a single flat np, as shown in the left column of figure 1.', 'such a flat annotation does not provide sufficient information about the scope of each member of the compound.', 'it is precisely this type of shortcoming that led  #TAUTHOR_TAG to revise the penn treebank annotation style for nps along the following lines :', '']",0
"[""' s parser,  #TAUTHOR_TAG report that the parsing results slightly decrease when the parser is trained on""]","[""' s parser,  #TAUTHOR_TAG report that the parsing results slightly decrease when the parser is trained on""]","[""' s parser,  #TAUTHOR_TAG report that the parsing results slightly decrease when the parser is trained on""]","[""' s parser,  #TAUTHOR_TAG report that the parsing results slightly decrease when the parser is trained on the penn treebank with the modified annotation style for nps."", 'as table 2 shows, we obtain a similar result when testing on section 23 of the penn treebank, using the berkeley parser trained on sections 02 - 21 of the same treebank : there is minor drop in f - score from 90. 43 to 89. 96.', ""we also confirm gildea's finding that testing a parser on test sets from a different domain than the training sets results in a significant loss of performance : when using the same models that we used for the penn treebank experiments, the average f - score for test data from the question bank in a 10 - fold cross - validation experiment is 79. 944 for the model trained on the original penn treebank and 77. 607 for the model trained on the modified penn treebank."", 'the above experiments were designed as a baseline for comparing the performance of the parser trained only on penn treebank data.', 'but since our primary interest is in parsing questions as accurately as possible, we conducted a second set of experiments, summarized in the lower half of table 2.', 'here additional training data from the question bank was added to both the original and the modified penn treebank training data.', 'the decrease in performance caused by adding the questionbank training data together with the modified np annotation on section 23 is comparable to the one caused by adding the modified np annotation alone ( a decrease from 90. 263 to 90. 04, whereas for the original penn treebank data the f - score decreased from 90. 43 to 89. 96 ), but this slight decrease is more than offset by the increase in semantic information obtained from the  #TAUTHOR_TAG annotation for complex base nps.', 'even more noteworthy is the big jump in f - score from 77. 607 to 92. 658 when adding the questionbank data to the training data']",0
"[""' s parser,  #TAUTHOR_TAG report that the parsing results slightly decrease when the parser is trained on""]","[""' s parser,  #TAUTHOR_TAG report that the parsing results slightly decrease when the parser is trained on""]","[""' s parser,  #TAUTHOR_TAG report that the parsing results slightly decrease when the parser is trained on""]","[""' s parser,  #TAUTHOR_TAG report that the parsing results slightly decrease when the parser is trained on the penn treebank with the modified annotation style for nps."", 'as table 2 shows, we obtain a similar result when testing on section 23 of the penn treebank, using the berkeley parser trained on sections 02 - 21 of the same treebank : there is minor drop in f - score from 90. 43 to 89. 96.', ""we also confirm gildea's finding that testing a parser on test sets from a different domain than the training sets results in a significant loss of performance : when using the same models that we used for the penn treebank experiments, the average f - score for test data from the question bank in a 10 - fold cross - validation experiment is 79. 944 for the model trained on the original penn treebank and 77. 607 for the model trained on the modified penn treebank."", 'the above experiments were designed as a baseline for comparing the performance of the parser trained only on penn treebank data.', 'but since our primary interest is in parsing questions as accurately as possible, we conducted a second set of experiments, summarized in the lower half of table 2.', 'here additional training data from the question bank was added to both the original and the modified penn treebank training data.', 'the decrease in performance caused by adding the questionbank training data together with the modified np annotation on section 23 is comparable to the one caused by adding the modified np annotation alone ( a decrease from 90. 263 to 90. 04, whereas for the original penn treebank data the f - score decreased from 90. 43 to 89. 96 ), but this slight decrease is more than offset by the increase in semantic information obtained from the  #TAUTHOR_TAG annotation for complex base nps.', 'even more noteworthy is the big jump in f - score from 77. 607 to 92. 658 when adding the questionbank data to the training data']",4
"[')  #TAUTHOR_TAG and self - training  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'a preliminary']","['( scl )  #TAUTHOR_TAG and self - training  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'a preliminary']","[')  #TAUTHOR_TAG and self - training  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'a preliminary evaluation favors the use']","['paper evaluates two semi - supervised techniques for the adaptation of a parse selection model to wikipedia domains.', 'the techniques examined are structural correspondence learning ( scl )  #TAUTHOR_TAG and self - training  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'a preliminary evaluation favors the use of scl over the simpler self - training techniques']",0
"[' #TAUTHOR_TAG ; ).', 'an attempt was']","[' #TAUTHOR_TAG ; ).', 'an attempt was']","[' #TAUTHOR_TAG ; ).', 'an attempt was made in the conll 2007 shared task to']","['far, structural correspondence learning has been applied successfully to pos tagging and sentiment analysis  #TAUTHOR_TAG ; ).', 'an attempt was made in the conll 2007 shared task to apply scl to non - projective dependency parsing  #AUTHOR_TAG.', 'however, the system just ended up at rank 7 out of 8 teams.', 'based on annotation differences in the datasets and a bug in their system  #AUTHOR_TAG, their results are inconclusive.', 'a recent attempt  #AUTHOR_TAG shows promising results on applying scl to parse disambiguation.', 'in this paper, we extend that line of work and compare scl to bootstrapping approaches such as self - training.', 'studies on self - training have focused mainly on generative, constituent based parsing  #AUTHOR_TAG mc  #AUTHOR_TAG.', ' #AUTHOR_TAG as well as  #AUTHOR_TAG examine self - training for pcfg parsing in the small seed case ( < 1k labeled data ), with different results.', 'in contrast, mc  #AUTHOR_TAG focus on large seeds and exploit a reranking - parser.', 'improvements are obtained ( mc  #AUTHOR_TAG mc  #AUTHOR_TAG, showing that a reranker is necessary for successful self - training in such a high - resource scenario.', 'while they self - trained a generative model, we examine self - training and scl for semi - supervised adaptation of a discriminative parse selection system']",0
[' #TAUTHOR_TAG exploits unlabeled'],[' #TAUTHOR_TAG exploits unlabeled'],['correspondence learning  #TAUTHOR_TAG exploits unlabeled'],"['correspondence learning  #TAUTHOR_TAG exploits unlabeled data from both source and target domain to find correspondences among features from different domains.', 'these correspondences are then integrated as new features in the labeled data of the source domain.', 'the outline of scl is given in algorithm 1.', 'the key to scl is to exploit pivot features to automatically identify feature correspondences.', 'pivots are features occurring frequently and behaving similarly in both domains  #TAUTHOR_TAG.', 'they correspond to auxiliary problems in  #AUTHOR_TAG.', 'for every such pivot feature, a binary classifier is trained ( step 2 of algorithm 1 ) by masking the pivot feature in the data and trying to predict it with the remaining non - pivot features.', 'non - pivots that correlate with many of the same pivots are assumed to correspond.', 'these pivot predictor weight vectors thus implicitly align non - pivot features from source and target domain.', ""intuitively, if we are able to find good correspondences through'linking'pivots, then the augmented source data should transfer better to a target domain  #TAUTHOR_TAG""]",0
[' #TAUTHOR_TAG exploits unlabeled'],[' #TAUTHOR_TAG exploits unlabeled'],['correspondence learning  #TAUTHOR_TAG exploits unlabeled'],"['correspondence learning  #TAUTHOR_TAG exploits unlabeled data from both source and target domain to find correspondences among features from different domains.', 'these correspondences are then integrated as new features in the labeled data of the source domain.', 'the outline of scl is given in algorithm 1.', 'the key to scl is to exploit pivot features to automatically identify feature correspondences.', 'pivots are features occurring frequently and behaving similarly in both domains  #TAUTHOR_TAG.', 'they correspond to auxiliary problems in  #AUTHOR_TAG.', 'for every such pivot feature, a binary classifier is trained ( step 2 of algorithm 1 ) by masking the pivot feature in the data and trying to predict it with the remaining non - pivot features.', 'non - pivots that correlate with many of the same pivots are assumed to correspond.', 'these pivot predictor weight vectors thus implicitly align non - pivot features from source and target domain.', ""intuitively, if we are able to find good correspondences through'linking'pivots, then the augmented source data should transfer better to a target domain  #TAUTHOR_TAG""]",0
"['were used  #TAUTHOR_TAG ;.', 'however,']","['were used  #TAUTHOR_TAG ;.', 'however,']","['were used  #TAUTHOR_TAG ;.', 'however,']","['far, pivot features on the word level were used  #TAUTHOR_TAG ;.', 'however, for parse disambiguation based on a conditional model they are irrelevant.', 'hence, we follow  #AUTHOR_TAG and actually first parse the unlabeled data.', 'this allows a possibly noisy, but more abstract representation of the underlying data.', 'features thus correspond to properties of parses : application of grammar rules ( r1, r2 features ), dependency relations ( dep ), pos tags ( f1, f2 ), syntactic features ( s1 ), precedence ( mf ), bilexical preferences ( z ), apposition ( appos ) and further features for unknown words, temporal phrases, coordination ( h, in year and p1, respectively ).', 'these features are further described in van  #AUTHOR_TAG']",0
"['selection model.', 'we examine structural correspondence learning ( scl )  #TAUTHOR_TAG for this']","['selection model.', 'we examine structural correspondence learning ( scl )  #TAUTHOR_TAG for this task, and compare']","['a discriminative parse selection model.', 'we examine structural correspondence learning ( scl )  #TAUTHOR_TAG for this task, and compare']","['selection constitutes an important part of many parsing systems  #AUTHOR_TAG van  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'yet, there is little to no work focusing on the adaptation of parse selection models to novel domains.', 'this is most probably due to the fact that potential gains for this task are inherently bounded by the underlying grammar.', 'the few studies on adapting parse disambiguation models, like  #AUTHOR_TAG, have focused exclusively on supervised domain adaptation, i. e. one has access to a comparably small, but labeled amount of target data.', 'in contrast, in semisupervised domain adaptation one has only unlabeled target data.', 'it is a more realistic situation, but at the same time also considerably more difficult.', 'in this paper we evaluate two semi - supervised approaches to domain adaptation of a discriminative parse selection model.', 'we examine structural correspondence learning ( scl )  #TAUTHOR_TAG for this task, and compare it to several variants of self - training  #AUTHOR_TAG mc  #AUTHOR_TAG.', 'for empirical evaluation ( section 4 ) we use the alpino parsing system for dutch ( van  #AUTHOR_TAG.', 'as target domain, we exploit wikipedia as primary test and training collection']",3
[' #TAUTHOR_TAG exploits unlabeled'],[' #TAUTHOR_TAG exploits unlabeled'],['correspondence learning  #TAUTHOR_TAG exploits unlabeled'],"['correspondence learning  #TAUTHOR_TAG exploits unlabeled data from both source and target domain to find correspondences among features from different domains.', 'these correspondences are then integrated as new features in the labeled data of the source domain.', 'the outline of scl is given in algorithm 1.', 'the key to scl is to exploit pivot features to automatically identify feature correspondences.', 'pivots are features occurring frequently and behaving similarly in both domains  #TAUTHOR_TAG.', 'they correspond to auxiliary problems in  #AUTHOR_TAG.', 'for every such pivot feature, a binary classifier is trained ( step 2 of algorithm 1 ) by masking the pivot feature in the data and trying to predict it with the remaining non - pivot features.', 'non - pivots that correlate with many of the same pivots are assumed to correspond.', 'these pivot predictor weight vectors thus implicitly align non - pivot features from source and target domain.', ""intuitively, if we are able to find good correspondences through'linking'pivots, then the augmented source data should transfer better to a target domain  #TAUTHOR_TAG""]",3
"['.', 'in our empirical setup, we follow  #TAUTHOR_TAG and balance']","['gather domain - specific target data.', 'in our empirical setup, we follow  #TAUTHOR_TAG and balance']","['gather domain - specific target data.', 'in our empirical setup, we follow  #TAUTHOR_TAG and balance the size of source and target data.', '']","['', 'the score is obtained by comparing it with the gold standard ( if available ; otherwise the score is approximated through parse probability ).', 'the source domain is the alpino treebank ( van  #AUTHOR_TAG ( newspaper text ; approx. 7, 000 sentences ; 145k tokens ).', 'we use wikipedia both as testset and as unlabeled target data source.', 'we assume that in order to parse data from a very specific domain, say about the artist prince, then data related to that domain, like information about the new power generation, the purple rain movie, or other american singers and artists, should be of help.', ""thus, we exploit wikipedia's category system to gather domain - specific target data."", 'in our empirical setup, we follow  #TAUTHOR_TAG and balance the size of source and target data.', '']",3
['paper compares structural correspondence learning  #TAUTHOR_TAG with ('],['paper compares structural correspondence learning  #TAUTHOR_TAG with ( various instances of ) self - training  #AUTHOR_TAG mc  #AUTHOR_TAG'],['paper compares structural correspondence learning  #TAUTHOR_TAG with ( various instances of )'],"['paper compares structural correspondence learning  #TAUTHOR_TAG with ( various instances of ) self - training  #AUTHOR_TAG mc  #AUTHOR_TAG for the adaptation of a parse selection model to wikipedia domains.', 'the empirical findings show that none of the evaluated self - training variants ( delible / indelible, single versus multiple iterations, various selection techniques ) achieves a significant improvement over the baseline.', ""the more'indirect'exploitation of unlabeled data through scl is more fruitful than pure self - training."", 'thus, favoring the use of the more complex method, although the findings are not confirmed on all testsets.', 'of course, our results are preliminary and, rather than warranting yet many definite conclusions, encourage further investigation of scl ( varying size of target data, pivots selection, bigger testsets as well as other domains etc. ) as well as related semisupervised adaptation techniques.', 'figure 2 : self - training variants compared to supervised baseline and scl.', 'the effect of various selection techniques ( sec. 3. 2 ) in a single iteration is depicted ( non - solid lines ; fewer parses and no selection achieve identical results ).', 'for clarity, the figure shows the learning curve for the best selection technique only ( shorter sent ) versus no selection.', 'on average running multiple iterations is just the same as a single iteration.', 'in all cases scl still performs best']",3
"['.', 'in our empirical setup, we follow  #TAUTHOR_TAG and balance']","['gather domain - specific target data.', 'in our empirical setup, we follow  #TAUTHOR_TAG and balance']","['gather domain - specific target data.', 'in our empirical setup, we follow  #TAUTHOR_TAG and balance the size of source and target data.', '']","['', 'the score is obtained by comparing it with the gold standard ( if available ; otherwise the score is approximated through parse probability ).', 'the source domain is the alpino treebank ( van  #AUTHOR_TAG ( newspaper text ; approx. 7, 000 sentences ; 145k tokens ).', 'we use wikipedia both as testset and as unlabeled target data source.', 'we assume that in order to parse data from a very specific domain, say about the artist prince, then data related to that domain, like information about the new power generation, the purple rain movie, or other american singers and artists, should be of help.', ""thus, we exploit wikipedia's category system to gather domain - specific target data."", 'in our empirical setup, we follow  #TAUTHOR_TAG and balance the size of source and target data.', '']",5
['and sgns from the study of  #TAUTHOR_TAG for comparison'],['and sgns from the study of  #TAUTHOR_TAG for comparison'],"['we focus on vector spaces that directly weight a co - occurrence matrix and report', 'results for svd, glove and sgns from the study of  #TAUTHOR_TAG for comparison. the mismatch of recent experiments with', 'nondense models in vector dimensionality between lexical and compositional tasks gives']","['', ', transitive verbs are of rank 3 ; for coordinators, the rank can go up to 7. taking k = 200k already results', 'in a highly intractable tensor of 8 × 10 15 dimensions for a transitive verb. an alternative way of obtaining a vector space with few dimensions, usually with just 100 - 500, is the use of svd as a part of latent semantic analysis', ' #AUTHOR_TAG or another models such as sgns  #AUTHOR_TAG and glove  #AUTHOR_TAG. however, these models take more time to instantiate in comparison to weighting of a co', '- occurrence matrix, bring more parameters to explore and produce vector spaces with unin', '##terpretable dimensions ( vector space dimension interpretation is used by some lexical mod - els, for example, mc  #AUTHOR_TAG, and the', 'passage from formal semantics to tensor models relies on it  #AUTHOR_TAG ). in this work we focus on vector spaces that directly weight a co - occurrence matrix and report', 'results for svd, glove and sgns from the study of  #TAUTHOR_TAG for comparison. the mismatch of recent experiments with', '']",5
"['( neg ) following  #TAUTHOR_TAG, giving our third pmi variant ( abbrevi']","['( neg ) following  #TAUTHOR_TAG, giving our third pmi variant ( abbreviated as spmi ) : 2', 'when']","['not positively contribute to model performance and sparser matrices are more computationally tractable  #AUTHOR_TAG.', 'this can be generalised to an additional cutoff parameter k ( neg ) following  #TAUTHOR_TAG, giving our third pmi variant ( abbrevi']","['approaches use only positive pmi values, as negative pmi values may not positively contribute to model performance and sparser matrices are more computationally tractable  #AUTHOR_TAG.', 'this can be generalised to an additional cutoff parameter k ( neg ) following  #TAUTHOR_TAG, giving our third pmi variant ( abbreviated as spmi ) : 2', 'when k = 1 spmi is equivalent to positive pmi.', 'k > 1 increases the underlying matrix sparsity by keeping only highly associated co - occurrence pairs.', 'k < 1 decreases the underlying matrix sparsity by including some unassociated cooccurrence pairs, which are usually excluded due to unreliability of probability estimates  #AUTHOR_TAG.', 'we can apply the same idea to cpmi :', '2 spmi is different from cpmi because log', ').', 'figure 1 : effect of pmi variant ( discr ), smoothing ( cds ) and frequency weighting ( freq ) on simlex - 999.', 'error bars correspond to a 95 % confidence interval as the value is estimated by averaging over all the values of the omitted parameters : neg and similarity']",5
"['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['evaluate these heuristics by comparing the performance they give on simlex - 999 against that obtained using the best possible parameter selections ( determined via an exhaustive search at each dimensionality setting ).', 'we also compare them to the best scores reported by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and glove  #AUTHOR_TAG - see figure 3a, where only the betterperforming spmi and scpmi are shown.', 'for lognpmi and logncpmi, our heuristics pick the best possible models.', 'for lognspmi, where performance variance is low, the heuristics do well, giving a performance of no more than 0. 01 points below the best configuration.', 'for 1spmi and nspmi the difference is higher.', 'with lognscpmi and 1scpmi, the heuristics follow  #TAUTHOR_TAG.', 'we also give our best score, svd, sgns and glove numbers from that study for comparison.', 'on the right, our heuristic in comparison to the best and average results together with the models selected using the recommendations presented in  #TAUTHOR_TAG.', 'the best selection, but with a wider gap than the spmi models.', 'in general n - weighted models do not perform as well as others.', 'overall, log n weighting should be used with pmi, cpmi and scpmi.', 'high - dimensional spmi models show the same behaviour, but if d < 10k, no weighting should be applied.', 'spmi and scpmi should be preferred over cpmi and pmi.', 'as figure 3b shows, our heuristics give performance close to the optimum for any dimensionality, with a large improvement over both an average parameter setting and the parameters suggested by  #TAUTHOR_TAG in a high - dimensional setting.', '4 finally, to see whether the heuristics transfer robustly, we repeat this comparison on the men dataset ( see figures 3c, 3d ).', 'again, pmi and cpmi follow the best possible setup, with spmi and scpmi showing only a slight drop below ideal performance ; and again, the heuristic settings give performance close to the optimum, and significantly higher than average or standard parameters']",5
"['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['evaluate these heuristics by comparing the performance they give on simlex - 999 against that obtained using the best possible parameter selections ( determined via an exhaustive search at each dimensionality setting ).', 'we also compare them to the best scores reported by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and glove  #AUTHOR_TAG - see figure 3a, where only the betterperforming spmi and scpmi are shown.', 'for lognpmi and logncpmi, our heuristics pick the best possible models.', 'for lognspmi, where performance variance is low, the heuristics do well, giving a performance of no more than 0. 01 points below the best configuration.', 'for 1spmi and nspmi the difference is higher.', 'with lognscpmi and 1scpmi, the heuristics follow  #TAUTHOR_TAG.', 'we also give our best score, svd, sgns and glove numbers from that study for comparison.', 'on the right, our heuristic in comparison to the best and average results together with the models selected using the recommendations presented in  #TAUTHOR_TAG.', 'the best selection, but with a wider gap than the spmi models.', 'in general n - weighted models do not perform as well as others.', 'overall, log n weighting should be used with pmi, cpmi and scpmi.', 'high - dimensional spmi models show the same behaviour, but if d < 10k, no weighting should be applied.', 'spmi and scpmi should be preferred over cpmi and pmi.', 'as figure 3b shows, our heuristics give performance close to the optimum for any dimensionality, with a large improvement over both an average parameter setting and the parameters suggested by  #TAUTHOR_TAG in a high - dimensional setting.', '4 finally, to see whether the heuristics transfer robustly, we repeat this comparison on the men dataset ( see figures 3c, 3d ).', 'again, pmi and cpmi follow the best possible setup, with spmi and scpmi showing only a slight drop below ideal performance ; and again, the heuristic settings give performance close to the optimum, and significantly higher than average or standard parameters']",5
"['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['evaluate these heuristics by comparing the performance they give on simlex - 999 against that obtained using the best possible parameter selections ( determined via an exhaustive search at each dimensionality setting ).', 'we also compare them to the best scores reported by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and glove  #AUTHOR_TAG - see figure 3a, where only the betterperforming spmi and scpmi are shown.', 'for lognpmi and logncpmi, our heuristics pick the best possible models.', 'for lognspmi, where performance variance is low, the heuristics do well, giving a performance of no more than 0. 01 points below the best configuration.', 'for 1spmi and nspmi the difference is higher.', 'with lognscpmi and 1scpmi, the heuristics follow  #TAUTHOR_TAG.', 'we also give our best score, svd, sgns and glove numbers from that study for comparison.', 'on the right, our heuristic in comparison to the best and average results together with the models selected using the recommendations presented in  #TAUTHOR_TAG.', 'the best selection, but with a wider gap than the spmi models.', 'in general n - weighted models do not perform as well as others.', 'overall, log n weighting should be used with pmi, cpmi and scpmi.', 'high - dimensional spmi models show the same behaviour, but if d < 10k, no weighting should be applied.', 'spmi and scpmi should be preferred over cpmi and pmi.', 'as figure 3b shows, our heuristics give performance close to the optimum for any dimensionality, with a large improvement over both an average parameter setting and the parameters suggested by  #TAUTHOR_TAG in a high - dimensional setting.', '4 finally, to see whether the heuristics transfer robustly, we repeat this comparison on the men dataset ( see figures 3c, 3d ).', 'again, pmi and cpmi follow the best possible setup, with spmi and scpmi showing only a slight drop below ideal performance ; and again, the heuristic settings give performance close to the optimum, and significantly higher than average or standard parameters']",5
"['of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high -']","['of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable']","['paper presents a systematic study of cooccurrence quantification focusing on the selection of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable performance with spaces of']","['paper presents a systematic study of cooccurrence quantification focusing on the selection of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable performance with spaces of dimensionality of 1k to 50k, and propose a set of model selection heuristics that maximizes performance.', 'we foresee the results of the paper are generalisable to other experiments, since model selection was performed on a similarity dataset, and was additionally tested on a relatedness dataset.', 'in general, model performance depends on vector dimensionality ( the best setup with 50k dimensions is better than the best setup with 1k dimensions by 0. 03 on simlex - 999 ).', 'spaces with a few thousand dimensions benefit from being dense and unsmoothed ( k < 1, global context probability ) ; while high - dimensional spaces are better sparse and smooth ( k > 1, α = 0. 75 ).', 'however, for unweighted and n - weighted models, these heuristics do not guarantee the best possible result because table 2 : our model in comparison to the previous work.', 'on the similarity dataset our model is 0. 008 points behind a ppmi model, however on the relatedness dataset 0. 020 points above.', 'note the difference in dimensionality, source corpora and window size.', 'svd, sgns and glove numbers are given for comparison.', '* results reported by  #TAUTHOR_TAG.', 'of the high variance of the corresponding scores.', 'based on this we suggest to use lognspmi or lognscpmi with dimensionality of at least 20k to ensure good performance on lexical tasks.', '']",5
"['of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high -']","['of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable']","['paper presents a systematic study of cooccurrence quantification focusing on the selection of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable performance with spaces of']","['paper presents a systematic study of cooccurrence quantification focusing on the selection of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable performance with spaces of dimensionality of 1k to 50k, and propose a set of model selection heuristics that maximizes performance.', 'we foresee the results of the paper are generalisable to other experiments, since model selection was performed on a similarity dataset, and was additionally tested on a relatedness dataset.', 'in general, model performance depends on vector dimensionality ( the best setup with 50k dimensions is better than the best setup with 1k dimensions by 0. 03 on simlex - 999 ).', 'spaces with a few thousand dimensions benefit from being dense and unsmoothed ( k < 1, global context probability ) ; while high - dimensional spaces are better sparse and smooth ( k > 1, α = 0. 75 ).', 'however, for unweighted and n - weighted models, these heuristics do not guarantee the best possible result because table 2 : our model in comparison to the previous work.', 'on the similarity dataset our model is 0. 008 points behind a ppmi model, however on the relatedness dataset 0. 020 points above.', 'note the difference in dimensionality, source corpora and window size.', 'svd, sgns and glove numbers are given for comparison.', '* results reported by  #TAUTHOR_TAG.', 'of the high variance of the corresponding scores.', 'based on this we suggest to use lognspmi or lognscpmi with dimensionality of at least 20k to ensure good performance on lexical tasks.', '']",5
['and sgns from the study of  #TAUTHOR_TAG for comparison'],['and sgns from the study of  #TAUTHOR_TAG for comparison'],"['we focus on vector spaces that directly weight a co - occurrence matrix and report', 'results for svd, glove and sgns from the study of  #TAUTHOR_TAG for comparison. the mismatch of recent experiments with', 'nondense models in vector dimensionality between lexical and compositional tasks gives']","['', ', transitive verbs are of rank 3 ; for coordinators, the rank can go up to 7. taking k = 200k already results', 'in a highly intractable tensor of 8 × 10 15 dimensions for a transitive verb. an alternative way of obtaining a vector space with few dimensions, usually with just 100 - 500, is the use of svd as a part of latent semantic analysis', ' #AUTHOR_TAG or another models such as sgns  #AUTHOR_TAG and glove  #AUTHOR_TAG. however, these models take more time to instantiate in comparison to weighting of a co', '- occurrence matrix, bring more parameters to explore and produce vector spaces with unin', '##terpretable dimensions ( vector space dimension interpretation is used by some lexical mod - els, for example, mc  #AUTHOR_TAG, and the', 'passage from formal semantics to tensor models relies on it  #AUTHOR_TAG ). in this work we focus on vector spaces that directly weight a co - occurrence matrix and report', 'results for svd, glove and sgns from the study of  #TAUTHOR_TAG for comparison. the mismatch of recent experiments with', '']",1
['issue with pmi is its bias towards rare events  #TAUTHOR_TAG ; one way of solving this issue is'],['issue with pmi is its bias towards rare events  #TAUTHOR_TAG ; one way of solving this issue is'],['issue with pmi is its bias towards rare events  #TAUTHOR_TAG ; one way of solving this issue is'],"['issue with pmi is its bias towards rare events  #TAUTHOR_TAG ; one way of solving this issue is to weight the value by the co - occurrence frequency  #AUTHOR_TAG :', 'where n ( x, y ) is the number of times x was seen together with y. for clarity, we refer to n - weighted pmis as npmi, nspmi, etc.', 'when this weighting component is set to 1, it has no effect ; we can explicitly label it as 1pmi, 1spmi, etc.', 'in addition to the extreme 1 and n weightings, we also experiment with a log n weighting.', ' #AUTHOR_TAG show that performance is affected by smoothing the context distribution p ( x )']",1
"['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and']","['evaluate these heuristics by comparing the performance they give on simlex - 999 against that obtained using the best possible parameter selections ( determined via an exhaustive search at each dimensionality setting ).', 'we also compare them to the best scores reported by  #TAUTHOR_TAG for their model ( pmi and svd ), word2vec - sgns  #AUTHOR_TAG and glove  #AUTHOR_TAG - see figure 3a, where only the betterperforming spmi and scpmi are shown.', 'for lognpmi and logncpmi, our heuristics pick the best possible models.', 'for lognspmi, where performance variance is low, the heuristics do well, giving a performance of no more than 0. 01 points below the best configuration.', 'for 1spmi and nspmi the difference is higher.', 'with lognscpmi and 1scpmi, the heuristics follow  #TAUTHOR_TAG.', 'we also give our best score, svd, sgns and glove numbers from that study for comparison.', 'on the right, our heuristic in comparison to the best and average results together with the models selected using the recommendations presented in  #TAUTHOR_TAG.', 'the best selection, but with a wider gap than the spmi models.', 'in general n - weighted models do not perform as well as others.', 'overall, log n weighting should be used with pmi, cpmi and scpmi.', 'high - dimensional spmi models show the same behaviour, but if d < 10k, no weighting should be applied.', 'spmi and scpmi should be preferred over cpmi and pmi.', 'as figure 3b shows, our heuristics give performance close to the optimum for any dimensionality, with a large improvement over both an average parameter setting and the parameters suggested by  #TAUTHOR_TAG in a high - dimensional setting.', '4 finally, to see whether the heuristics transfer robustly, we repeat this comparison on the men dataset ( see figures 3c, 3d ).', 'again, pmi and cpmi follow the best possible setup, with spmi and scpmi showing only a slight drop below ideal performance ; and again, the heuristic settings give performance close to the optimum, and significantly higher than average or standard parameters']",4
"['of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high -']","['of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable']","['paper presents a systematic study of cooccurrence quantification focusing on the selection of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable performance with spaces of']","['paper presents a systematic study of cooccurrence quantification focusing on the selection of parameters presented in  #TAUTHOR_TAG.', 'we replicate their recommendation for high - dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable performance with spaces of dimensionality of 1k to 50k, and propose a set of model selection heuristics that maximizes performance.', 'we foresee the results of the paper are generalisable to other experiments, since model selection was performed on a similarity dataset, and was additionally tested on a relatedness dataset.', 'in general, model performance depends on vector dimensionality ( the best setup with 50k dimensions is better than the best setup with 1k dimensions by 0. 03 on simlex - 999 ).', 'spaces with a few thousand dimensions benefit from being dense and unsmoothed ( k < 1, global context probability ) ; while high - dimensional spaces are better sparse and smooth ( k > 1, α = 0. 75 ).', 'however, for unweighted and n - weighted models, these heuristics do not guarantee the best possible result because table 2 : our model in comparison to the previous work.', 'on the similarity dataset our model is 0. 008 points behind a ppmi model, however on the relatedness dataset 0. 020 points above.', 'note the difference in dimensionality, source corpora and window size.', 'svd, sgns and glove numbers are given for comparison.', '* results reported by  #TAUTHOR_TAG.', 'of the high variance of the corresponding scores.', 'based on this we suggest to use lognspmi or lognscpmi with dimensionality of at least 20k to ensure good performance on lexical tasks.', '']",6
"['sentence ranking models on multiple languages  #TAUTHOR_TAG.', 'this']","['of sentences by training image - sentence ranking models on multiple languages  #TAUTHOR_TAG.', 'this']","[', 2017 ).', 'in these approaches the visual world is taken as a naturally occurring meaning representation for linguistic utterances, grounding language in perceptual reality.', 'recent work has shown that we can learn better visually grounded representations of sentences by training image - sentence ranking models on multiple languages  #TAUTHOR_TAG.', 'this line']","['perceptual - motor system plays an important role in concept acquisition and representation, and in learning the meaning of linguistic expressions ( pulvermuller, 2005 ).', 'in natural language processing, many approaches have been proposed that integrate visual information in the learning of word and sentence representations, highlighting the benefits of visually grounded representations  #AUTHOR_TAG elliott and kadar, 2017 ).', 'in these approaches the visual world is taken as a naturally occurring meaning representation for linguistic utterances, grounding language in perceptual reality.', 'recent work has shown that we can learn better visually grounded representations of sentences by training image - sentence ranking models on multiple languages  #TAUTHOR_TAG.', 'this line of research has focused on training models on datasets where the same images are annotated with sentences in multiple languages.', 'this alignment has either been in the form of the translation pairs ( e. g. german, english, french, and czech in multi30k ) or independently collected sentences ( english and japanese in stair  #AUTHOR_TAG ).', 'in this paper, we consider the problem of training an image - sentence ranking model using imagecaption collections in different languages with nonoverlapping images drawn from different sources.', 'we call these collections disjoint datasets and argue that it is easier to find disjoint datasets than aligned datasets.', 'this is especially the case for datasets in different languages, e. g. digital museum collections 1, newspaper collections  #AUTHOR_TAG, or the the images used in wikipedia articles  #AUTHOR_TAG.', 'multilingual aligned datasets, by contrast, are small and expensive to collect : there is a need for methods that can train image - sentence ranking models on disjoint multilingual image datasets.', 'kadar et al. ( 2018 ) claim that a multilingual image - sentence ranking model trained on disjoint datasets performs on - par with a model trained on aligned data.', 'however, the disjoint datasets in their paper are artificial because they were formed by randomly splitting the multi30k dataset into two halves.', 'we examine whether the ranking model can benefit from multilingual supervision when it is trained using disjoint datasets drawn from different sources.', 'in experiments with the multi30k and coco datasets, we find substantial benefits from training with these disjoint sources, but the best performance comes from training on aligned datasets.', 'given the empirical benefits of training on aligned datasets, we explore two approaches to creating synthetically aligned training data in the disjoint scenario.', 'one approach to creating synthetically aligned data is to use an off - the - shelf machine translation system to generate new imagecaption pairs by translating the original captions.', 'this approach is very simple, but has the limitation that an external system needs to']",0
['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],"['adopt the model architecture and training procedure of  #TAUTHOR_TAG for the task of matching images with sentences.', 'this task is defined as learning to rank the sentences associated with an image higher than other sentences in the data set, and vice - versa  #AUTHOR_TAG.', 'the model is comprised of a recurrent neural network language model and a convolutional neural network image encoder.', 'the parameters of the language encoder are randomly initialized, while the image encoder is pre - trained, frozen during training and followed by a linear layer which is tuned for the task.', 'the model is trained to make true pairs < a, b > similar to each other, and contrastive pairs < a, b > and < a, b > dissimilar from each other in a joint embedding space by minimizing the max - violation loss function  #AUTHOR_TAG :', 'in our experiments, the < a, b > pairs are either image - caption pairs < i, c > or caption - caption pairs < c a, c b > ( following  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'when we train on < i, c > pairs, we sample a batch from an image - caption data set with uniform probability, encode the images and the sentences, and perform an update of the model parameters.', 'for the caption - caption objective, we follow  #TAUTHOR_TAG and generate a sentence pair data set by taking all pairs of sentences that belong to the same image and are written in different languages : 5 english and 5 german captions result in 25 english - german pairs.', 'the sentences are encoded and we perform an update of the model parameters using the same loss.', 'when training with both the image - caption and caption - caption ( c2c ) ranking tasks, we randomly select the task to perform with probability p = 0. 5']",0
['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],"['adopt the model architecture and training procedure of  #TAUTHOR_TAG for the task of matching images with sentences.', 'this task is defined as learning to rank the sentences associated with an image higher than other sentences in the data set, and vice - versa  #AUTHOR_TAG.', 'the model is comprised of a recurrent neural network language model and a convolutional neural network image encoder.', 'the parameters of the language encoder are randomly initialized, while the image encoder is pre - trained, frozen during training and followed by a linear layer which is tuned for the task.', 'the model is trained to make true pairs < a, b > similar to each other, and contrastive pairs < a, b > and < a, b > dissimilar from each other in a joint embedding space by minimizing the max - violation loss function  #AUTHOR_TAG :', 'in our experiments, the < a, b > pairs are either image - caption pairs < i, c > or caption - caption pairs < c a, c b > ( following  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'when we train on < i, c > pairs, we sample a batch from an image - caption data set with uniform probability, encode the images and the sentences, and perform an update of the model parameters.', 'for the caption - caption objective, we follow  #TAUTHOR_TAG and generate a sentence pair data set by taking all pairs of sentences that belong to the same image and are written in different languages : 5 english and 5 german captions result in 25 english - german pairs.', 'the sentences are encoded and we perform an update of the model parameters using the same loss.', 'when training with both the image - caption and caption - caption ( c2c ) ranking tasks, we randomly select the task to perform with probability p = 0. 5']",0
"['of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable']","['of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable']","['2. this finding contradicts the conclusion of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable performance. this is']","['', 'the out - of - domain english coco data. table 2 shows that there is an increase in performance when the model is trained', 'on the disjoint sets, as opposed to only the in - domain m30k german ( compare de', 'against de + coco ). this result is not too surprising as we have observed both the advantage of joint training on both languages in the aligned setting and the overlap between the different datasets. finally, we compare the performance of a', 'german model trained in the aligned and disjoint settings. we find that a model trained in the aligned setting ( de + en ) is better than a', 'model trained in the disjoint setting ( de + coco ), as shown in table 2. this finding contradicts the conclusion of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable performance. this is most likely because the disjoint setting in  #TAUTHOR_TAG is artificial, in the sense that they used different 50 % subsets of m30k. in our experiments the disjoint image - caption sets are', 'real, in the sense that we trained the models on the two different datasets. aligned plus disjoint our final baseline experiments explore the combination of disjoint and aligned data', 'settings. we train an english - german bilingual model with the c2c objective on m', '##30k, and we also train on the english coco data. table 3 shows that adding the disjoint data improves performance for both english and german compared to training solely the aligned model. summary', 'first we reproduced the findings of  #TAUTHOR_TAG showing that bilingual joint training improves over monolingual and using c2c', 'loss further improves performance. furthermore, we have found that adding the coco as additional training data both when only training on german, and training', 'on both german - english from m30k improves performance even if the model is trained on data drawn from a different dataset']",0
"['of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable']","['of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable']","['2. this finding contradicts the conclusion of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable performance. this is']","['', 'the out - of - domain english coco data. table 2 shows that there is an increase in performance when the model is trained', 'on the disjoint sets, as opposed to only the in - domain m30k german ( compare de', 'against de + coco ). this result is not too surprising as we have observed both the advantage of joint training on both languages in the aligned setting and the overlap between the different datasets. finally, we compare the performance of a', 'german model trained in the aligned and disjoint settings. we find that a model trained in the aligned setting ( de + en ) is better than a', 'model trained in the disjoint setting ( de + coco ), as shown in table 2. this finding contradicts the conclusion of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable performance. this is most likely because the disjoint setting in  #TAUTHOR_TAG is artificial, in the sense that they used different 50 % subsets of m30k. in our experiments the disjoint image - caption sets are', 'real, in the sense that we trained the models on the two different datasets. aligned plus disjoint our final baseline experiments explore the combination of disjoint and aligned data', 'settings. we train an english - german bilingual model with the c2c objective on m', '##30k, and we also train on the english coco data. table 3 shows that adding the disjoint data improves performance for both english and german compared to training solely the aligned model. summary', 'first we reproduced the findings of  #TAUTHOR_TAG showing that bilingual joint training improves over monolingual and using c2c', 'loss further improves performance. furthermore, we have found that adding the coco as additional training data both when only training on german, and training', 'on both german - english from m30k improves performance even if the model is trained on data drawn from a different dataset']",0
"['of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable']","['of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable']","['2. this finding contradicts the conclusion of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable performance. this is']","['', 'the out - of - domain english coco data. table 2 shows that there is an increase in performance when the model is trained', 'on the disjoint sets, as opposed to only the in - domain m30k german ( compare de', 'against de + coco ). this result is not too surprising as we have observed both the advantage of joint training on both languages in the aligned setting and the overlap between the different datasets. finally, we compare the performance of a', 'german model trained in the aligned and disjoint settings. we find that a model trained in the aligned setting ( de + en ) is better than a', 'model trained in the disjoint setting ( de + coco ), as shown in table 2. this finding contradicts the conclusion of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable performance. this is most likely because the disjoint setting in  #TAUTHOR_TAG is artificial, in the sense that they used different 50 % subsets of m30k. in our experiments the disjoint image - caption sets are', 'real, in the sense that we trained the models on the two different datasets. aligned plus disjoint our final baseline experiments explore the combination of disjoint and aligned data', 'settings. we train an english - german bilingual model with the c2c objective on m', '##30k, and we also train on the english coco data. table 3 shows that adding the disjoint data improves performance for both english and german compared to training solely the aligned model. summary', 'first we reproduced the findings of  #TAUTHOR_TAG showing that bilingual joint training improves over monolingual and using c2c', 'loss further improves performance. furthermore, we have found that adding the coco as additional training data both when only training on german, and training', 'on both german - english from m30k improves performance even if the model is trained on data drawn from a different dataset']",0
['using multilingual data  #TAUTHOR_TAG in'],['using multilingual data  #TAUTHOR_TAG in'],"[').', 'more recently, there has been a focus on solving this task using multilingual data  #TAUTHOR_TAG in']","['- sentence ranking is the task of retrieving the sentences that best describe an image, and vice - versa  #AUTHOR_TAG.', 'most recent approaches are based on learning to project image representations and sentence representations into a shared space using deep neural networks  #AUTHOR_TAG inter - alia ).', 'more recently, there has been a focus on solving this task using multilingual data  #TAUTHOR_TAG in the multi30k dataset ; an extension of the popular flickr30k dataset into german, french, and czech.', 'these works take a multi - view learning perspective in which images and their descriptions in multiple languages are different views of the same concepts.', 'the assumption is that common representations of multiple languages and perceptual stimuli can potentially exploit complementary information between views to learn better representations.', 'for example,  #AUTHOR_TAG improves bilingual sentence representations by in - ein jet jagt steil in die luft, viel rauch kommt aus dem rumpf.', '[ a jet goes steep up into the air, a lot of smoke is coming out of its hull. ]', 'ein jet jagt steil in die luft, viel rauch kommt aus dem rumpf.', '[ a jet goes steep up into the air, a lot of smoke is coming out of its hull. ] figure 1 : visualisation of the sentences transferred from multi30k to the coco data set using the pseudopair method.', '1 is transferred from a model trained on de + coco, whereas 2 is transferred from en + de + coco.', '[ english glosses of the sentences are included for ease of reading. ] corporating image information as a third view by deep partial canonical correlation analysis.', 'more similar to our work  #AUTHOR_TAG, propose a convolutional - recurrent architecture with both an image - caption and caption - caption loss to learn bilingual visually grounded representations.', 'their results were improved by the approach presented in  #TAUTHOR_TAG, who has also shown that the multilingual models outperform bilingual models, and that image - caption retrieval performance in languages with less resources can be improved with data from higher - resource languages.', 'we largely follow  #TAUTHOR_TAG, however, our main interest lies in learning multimodal and bilingual representations in the scenario where the images do not come from the same data set i. e. : the data is presented is two sets of image - caption tuples rather than image - caption - caption triples.', 'taking a broader perspective, images have been used as pivots in multilingual multimodal language processing.', 'on the word level this intuition is applied to visually grounded bilingual lexicon induction, which aims to learn cross - lingual word representations without aligned text using images']",0
['using multilingual data  #TAUTHOR_TAG in'],['using multilingual data  #TAUTHOR_TAG in'],"[').', 'more recently, there has been a focus on solving this task using multilingual data  #TAUTHOR_TAG in']","['- sentence ranking is the task of retrieving the sentences that best describe an image, and vice - versa  #AUTHOR_TAG.', 'most recent approaches are based on learning to project image representations and sentence representations into a shared space using deep neural networks  #AUTHOR_TAG inter - alia ).', 'more recently, there has been a focus on solving this task using multilingual data  #TAUTHOR_TAG in the multi30k dataset ; an extension of the popular flickr30k dataset into german, french, and czech.', 'these works take a multi - view learning perspective in which images and their descriptions in multiple languages are different views of the same concepts.', 'the assumption is that common representations of multiple languages and perceptual stimuli can potentially exploit complementary information between views to learn better representations.', 'for example,  #AUTHOR_TAG improves bilingual sentence representations by in - ein jet jagt steil in die luft, viel rauch kommt aus dem rumpf.', '[ a jet goes steep up into the air, a lot of smoke is coming out of its hull. ]', 'ein jet jagt steil in die luft, viel rauch kommt aus dem rumpf.', '[ a jet goes steep up into the air, a lot of smoke is coming out of its hull. ] figure 1 : visualisation of the sentences transferred from multi30k to the coco data set using the pseudopair method.', '1 is transferred from a model trained on de + coco, whereas 2 is transferred from en + de + coco.', '[ english glosses of the sentences are included for ease of reading. ] corporating image information as a third view by deep partial canonical correlation analysis.', 'more similar to our work  #AUTHOR_TAG, propose a convolutional - recurrent architecture with both an image - caption and caption - caption loss to learn bilingual visually grounded representations.', 'their results were improved by the approach presented in  #TAUTHOR_TAG, who has also shown that the multilingual models outperform bilingual models, and that image - caption retrieval performance in languages with less resources can be improved with data from higher - resource languages.', 'we largely follow  #TAUTHOR_TAG, however, our main interest lies in learning multimodal and bilingual representations in the scenario where the images do not come from the same data set i. e. : the data is presented is two sets of image - caption tuples rather than image - caption - caption triples.', 'taking a broader perspective, images have been used as pivots in multilingual multimodal language processing.', 'on the word level this intuition is applied to visually grounded bilingual lexicon induction, which aims to learn cross - lingual word representations without aligned text using images']",0
['using multilingual data  #TAUTHOR_TAG in'],['using multilingual data  #TAUTHOR_TAG in'],"[').', 'more recently, there has been a focus on solving this task using multilingual data  #TAUTHOR_TAG in']","['- sentence ranking is the task of retrieving the sentences that best describe an image, and vice - versa  #AUTHOR_TAG.', 'most recent approaches are based on learning to project image representations and sentence representations into a shared space using deep neural networks  #AUTHOR_TAG inter - alia ).', 'more recently, there has been a focus on solving this task using multilingual data  #TAUTHOR_TAG in the multi30k dataset ; an extension of the popular flickr30k dataset into german, french, and czech.', 'these works take a multi - view learning perspective in which images and their descriptions in multiple languages are different views of the same concepts.', 'the assumption is that common representations of multiple languages and perceptual stimuli can potentially exploit complementary information between views to learn better representations.', 'for example,  #AUTHOR_TAG improves bilingual sentence representations by in - ein jet jagt steil in die luft, viel rauch kommt aus dem rumpf.', '[ a jet goes steep up into the air, a lot of smoke is coming out of its hull. ]', 'ein jet jagt steil in die luft, viel rauch kommt aus dem rumpf.', '[ a jet goes steep up into the air, a lot of smoke is coming out of its hull. ] figure 1 : visualisation of the sentences transferred from multi30k to the coco data set using the pseudopair method.', '1 is transferred from a model trained on de + coco, whereas 2 is transferred from en + de + coco.', '[ english glosses of the sentences are included for ease of reading. ] corporating image information as a third view by deep partial canonical correlation analysis.', 'more similar to our work  #AUTHOR_TAG, propose a convolutional - recurrent architecture with both an image - caption and caption - caption loss to learn bilingual visually grounded representations.', 'their results were improved by the approach presented in  #TAUTHOR_TAG, who has also shown that the multilingual models outperform bilingual models, and that image - caption retrieval performance in languages with less resources can be improved with data from higher - resource languages.', 'we largely follow  #TAUTHOR_TAG, however, our main interest lies in learning multimodal and bilingual representations in the scenario where the images do not come from the same data set i. e. : the data is presented is two sets of image - caption tuples rather than image - caption - caption triples.', 'taking a broader perspective, images have been used as pivots in multilingual multimodal language processing.', 'on the word level this intuition is applied to visually grounded bilingual lexicon induction, which aims to learn cross - lingual word representations without aligned text using images']",0
"['training models jointly on multiple languages  #TAUTHOR_TAG.', 'here we presented a study on learning multimodal and multilingual representations in the disjoint setting, where images between languages do']","['training models jointly on multiple languages  #TAUTHOR_TAG.', 'here we presented a study on learning multimodal and multilingual representations in the disjoint setting, where images between languages do']","['training models jointly on multiple languages  #TAUTHOR_TAG.', 'here we presented a study on learning multimodal and multilingual representations in the disjoint setting, where images between languages do not overlap.', 'we found that learning visually grounded sentence embeddings in this setting is more challenging.', 'to close the gap, we developed a pseudopairing technique']","['work has demonstrated improved imagesentence ranking performance when training models jointly on multiple languages  #TAUTHOR_TAG.', 'here we presented a study on learning multimodal and multilingual representations in the disjoint setting, where images between languages do not overlap.', 'we found that learning visually grounded sentence embeddings in this setting is more challenging.', 'to close the gap, we developed a pseudopairing technique that creates synthetic pairs by annotating the images from one of the data sets with the image descriptions of the other using the sentence similarities of the model trained on both.', 'we showed that training with pseudopairs improves performance, without the need to augment training from additional data sources or other pipeline components.', 'however, our technique is outperformed by creating synthetic pairs using an off - the - shelf automatic machine translation system.', 'as such our results suggest that it is better to use translation, when a good translation system is available, however, in its absence, pseudopairs offer consistent improvements.', 'we have found that our pseudopairing method only transfers annotations from a small number of images and in the future we plan to substitute our naive matching algorithms with approaches developed to mitigate this hubness issue ( radovanovic et al., 2010 ) and to close the gap between translation and pseudopairs']",0
['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],"['adopt the model architecture and training procedure of  #TAUTHOR_TAG for the task of matching images with sentences.', 'this task is defined as learning to rank the sentences associated with an image higher than other sentences in the data set, and vice - versa  #AUTHOR_TAG.', 'the model is comprised of a recurrent neural network language model and a convolutional neural network image encoder.', 'the parameters of the language encoder are randomly initialized, while the image encoder is pre - trained, frozen during training and followed by a linear layer which is tuned for the task.', 'the model is trained to make true pairs < a, b > similar to each other, and contrastive pairs < a, b > and < a, b > dissimilar from each other in a joint embedding space by minimizing the max - violation loss function  #AUTHOR_TAG :', 'in our experiments, the < a, b > pairs are either image - caption pairs < i, c > or caption - caption pairs < c a, c b > ( following  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'when we train on < i, c > pairs, we sample a batch from an image - caption data set with uniform probability, encode the images and the sentences, and perform an update of the model parameters.', 'for the caption - caption objective, we follow  #TAUTHOR_TAG and generate a sentence pair data set by taking all pairs of sentences that belong to the same image and are written in different languages : 5 english and 5 german captions result in 25 english - german pairs.', 'the sentences are encoded and we perform an update of the model parameters using the same loss.', 'when training with both the image - caption and caption - caption ( c2c ) ranking tasks, we randomly select the task to perform with probability p = 0. 5']",5
['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],['adopt the model architecture and training procedure of  #TAUTHOR_TAG'],"['adopt the model architecture and training procedure of  #TAUTHOR_TAG for the task of matching images with sentences.', 'this task is defined as learning to rank the sentences associated with an image higher than other sentences in the data set, and vice - versa  #AUTHOR_TAG.', 'the model is comprised of a recurrent neural network language model and a convolutional neural network image encoder.', 'the parameters of the language encoder are randomly initialized, while the image encoder is pre - trained, frozen during training and followed by a linear layer which is tuned for the task.', 'the model is trained to make true pairs < a, b > similar to each other, and contrastive pairs < a, b > and < a, b > dissimilar from each other in a joint embedding space by minimizing the max - violation loss function  #AUTHOR_TAG :', 'in our experiments, the < a, b > pairs are either image - caption pairs < i, c > or caption - caption pairs < c a, c b > ( following  #AUTHOR_TAG ;  #TAUTHOR_TAG.', 'when we train on < i, c > pairs, we sample a batch from an image - caption data set with uniform probability, encode the images and the sentences, and perform an update of the model parameters.', 'for the caption - caption objective, we follow  #TAUTHOR_TAG and generate a sentence pair data set by taking all pairs of sentences that belong to the same image and are written in different languages : 5 english and 5 german captions result in 25 english - german pairs.', 'the sentences are encoded and we perform an update of the model parameters using the same loss.', 'when training with both the image - caption and caption - caption ( c2c ) ranking tasks, we randomly select the task to perform with probability p = 0. 5']",5
"['implementation, training protocol and parameter settings are based on the existing codebase of  #TAUTHOR_TAG.', '3.', 'in']","['implementation, training protocol and parameter settings are based on the existing codebase of  #TAUTHOR_TAG.', '3.', 'in']","['implementation, training protocol and parameter settings are based on the existing codebase of  #TAUTHOR_TAG.', '3.', 'in all experiments, we use the 2048 dimensional image features extracted from the last average - pooling layer']","['implementation, training protocol and parameter settings are based on the existing codebase of  #TAUTHOR_TAG.', '3.', 'in all experiments, we use the 2048 dimensional image features extracted from the last average - pooling layer of a pre - trained 4 resnet50 cnn  #AUTHOR_TAG.', 'the image representation used in our model is obtained by a single affine transformation that we train from scratch w i ∈ r 2048×1024.', '']",5
"['of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable']","['of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable']","['2. this finding contradicts the conclusion of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable performance. this is']","['', 'the out - of - domain english coco data. table 2 shows that there is an increase in performance when the model is trained', 'on the disjoint sets, as opposed to only the in - domain m30k german ( compare de', 'against de + coco ). this result is not too surprising as we have observed both the advantage of joint training on both languages in the aligned setting and the overlap between the different datasets. finally, we compare the performance of a', 'german model trained in the aligned and disjoint settings. we find that a model trained in the aligned setting ( de + en ) is better than a', 'model trained in the disjoint setting ( de + coco ), as shown in table 2. this finding contradicts the conclusion of  #TAUTHOR_TAG, who claimed that the aligned and disjoint conditions lead to', 'comparable performance. this is most likely because the disjoint setting in  #TAUTHOR_TAG is artificial, in the sense that they used different 50 % subsets of m30k. in our experiments the disjoint image - caption sets are', 'real, in the sense that we trained the models on the two different datasets. aligned plus disjoint our final baseline experiments explore the combination of disjoint and aligned data', 'settings. we train an english - german bilingual model with the c2c objective on m', '##30k, and we also train on the english coco data. table 3 shows that adding the disjoint data improves performance for both english and german compared to training solely the aligned model. summary', 'first we reproduced the findings of  #TAUTHOR_TAG showing that bilingual joint training improves over monolingual and using c2c', 'loss further improves performance. furthermore, we have found that adding the coco as additional training data both when only training on german, and training', 'on both german - english from m30k improves performance even if the model is trained on data drawn from a different dataset']",3
"['existing  #TAUTHOR_TAG', '.']","['the information from multiple utterances, we adapt an existing  #TAUTHOR_TAG', '.']","['existing  #TAUTHOR_TAG', '. the fusion technique is based on the idea of merging']","['', ': the project manager talked about the project finances and selling prices', '. to aggregate the information from multiple utterances, we adapt an existing  #TAUTHOR_TAG', '. the fusion technique is based on the idea of merging dependency', 'parse trees of the utterances. the trees are merged on the common nodes that are represented by the', 'word and parts - ofspeech ( pos ) combination. each edge of the merged structure is represented as a variable in the  #TAUTHOR_TAG objective function, and the solution will decide whether the edge has to be preserved or discarded. we modify the technique by introducing an anaphora resolution step and also an', 'ambiguity resolver that takes the context of words into account. further, to solve the  #TAUTHOR_TAG, we introduce several constraints,', 'such as desired length of the output, etc. to the best of our knowledge, our work is the first to address the', 'problems of readability, grammaticality and content selection jointly for meeting summary generation without employing a templatebased approach. we conduct experiments on the ami corpus 1 that consists of meeting transcripts and show that our best method outperforms extractive model significantly on rouge - 2 scores ( 0. 04', '##8 vs 0. 026 )']",5
"['existing  #TAUTHOR_TAG', '.']","['the information from multiple utterances, we adapt an existing  #TAUTHOR_TAG', '.']","['existing  #TAUTHOR_TAG', '. the fusion technique is based on the idea of merging']","['', ': the project manager talked about the project finances and selling prices', '. to aggregate the information from multiple utterances, we adapt an existing  #TAUTHOR_TAG', '. the fusion technique is based on the idea of merging dependency', 'parse trees of the utterances. the trees are merged on the common nodes that are represented by the', 'word and parts - ofspeech ( pos ) combination. each edge of the merged structure is represented as a variable in the  #TAUTHOR_TAG objective function, and the solution will decide whether the edge has to be preserved or discarded. we modify the technique by introducing an anaphora resolution step and also an', 'ambiguity resolver that takes the context of words into account. further, to solve the  #TAUTHOR_TAG, we introduce several constraints,', 'such as desired length of the output, etc. to the best of our knowledge, our work is the first to address the', 'problems of readability, grammaticality and content selection jointly for meeting summary generation without employing a templatebased approach. we conduct experiments on the ami corpus 1 that consists of meeting transcripts and show that our best method outperforms extractive model significantly on rouge - 2 scores ( 0. 04', '##8 vs 0. 026 )']",5
"['', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints']","['in order', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints']","['', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints. some of the constraints have been directly adapted from the original  #TAUTHOR_TAG. for example, we use the same constraints for restricting one']","['', '). this term assigns the importance of grammatical relations to a', ""node and only the relations that are more dominant from a node will be preferred. the term i ( d ) denotes the informativeness of a node calculated using hori and furui's formula [ 2 ]. the last term in equation ( 1"", ') is based on the idea of lexical cohesion. towards the end of any', 'segment, generally,', 'more important discussions might happen that will conclude a particular topic and then start another. in order to take this fact into account, we introduce the term px n, where n and px', 'denote the total number of extracted utterances in a segment and the position of the utterance ( the', 'edge x belongs to ) in the set of n utterances, respectively. in order', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints. some of the constraints have been directly adapted from the original  #TAUTHOR_TAG. for example, we use the same constraints for restricting one incoming edge per node, as well as we impose the connectivity constraint', '']",5
"['', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints']","['in order', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints']","['', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints. some of the constraints have been directly adapted from the original  #TAUTHOR_TAG. for example, we use the same constraints for restricting one']","['', '). this term assigns the importance of grammatical relations to a', ""node and only the relations that are more dominant from a node will be preferred. the term i ( d ) denotes the informativeness of a node calculated using hori and furui's formula [ 2 ]. the last term in equation ( 1"", ') is based on the idea of lexical cohesion. towards the end of any', 'segment, generally,', 'more important discussions might happen that will conclude a particular topic and then start another. in order to take this fact into account, we introduce the term px n, where n and px', 'denote the total number of extracted utterances in a segment and the position of the utterance ( the', 'edge x belongs to ) in the set of n utterances, respectively. in order', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints. some of the constraints have been directly adapted from the original  #TAUTHOR_TAG. for example, we use the same constraints for restricting one incoming edge per node, as well as we impose the connectivity constraint', '']",5
"['existing  #TAUTHOR_TAG', '.']","['the information from multiple utterances, we adapt an existing  #TAUTHOR_TAG', '.']","['existing  #TAUTHOR_TAG', '. the fusion technique is based on the idea of merging']","['', ': the project manager talked about the project finances and selling prices', '. to aggregate the information from multiple utterances, we adapt an existing  #TAUTHOR_TAG', '. the fusion technique is based on the idea of merging dependency', 'parse trees of the utterances. the trees are merged on the common nodes that are represented by the', 'word and parts - ofspeech ( pos ) combination. each edge of the merged structure is represented as a variable in the  #TAUTHOR_TAG objective function, and the solution will decide whether the edge has to be preserved or discarded. we modify the technique by introducing an anaphora resolution step and also an', 'ambiguity resolver that takes the context of words into account. further, to solve the  #TAUTHOR_TAG, we introduce several constraints,', 'such as desired length of the output, etc. to the best of our knowledge, our work is the first to address the', 'problems of readability, grammaticality and content selection jointly for meeting summary generation without employing a templatebased approach. we conduct experiments on the ami corpus 1 that consists of meeting transcripts and show that our best method outperforms extractive model significantly on rouge - 2 scores ( 0. 04', '##8 vs 0. 026 )']",6
"['', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints']","['in order', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints']","['', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints. some of the constraints have been directly adapted from the original  #TAUTHOR_TAG. for example, we use the same constraints for restricting one']","['', '). this term assigns the importance of grammatical relations to a', ""node and only the relations that are more dominant from a node will be preferred. the term i ( d ) denotes the informativeness of a node calculated using hori and furui's formula [ 2 ]. the last term in equation ( 1"", ') is based on the idea of lexical cohesion. towards the end of any', 'segment, generally,', 'more important discussions might happen that will conclude a particular topic and then start another. in order to take this fact into account, we introduce the term px n, where n and px', 'denote the total number of extracted utterances in a segment and the position of the utterance ( the', 'edge x belongs to ) in the set of n utterances, respectively. in order', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints. some of the constraints have been directly adapted from the original  #TAUTHOR_TAG. for example, we use the same constraints for restricting one incoming edge per node, as well as we impose the connectivity constraint', '']",6
"['', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints']","['in order', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints']","['', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints. some of the constraints have been directly adapted from the original  #TAUTHOR_TAG. for example, we use the same constraints for restricting one']","['', '). this term assigns the importance of grammatical relations to a', ""node and only the relations that are more dominant from a node will be preferred. the term i ( d ) denotes the informativeness of a node calculated using hori and furui's formula [ 2 ]. the last term in equation ( 1"", ') is based on the idea of lexical cohesion. towards the end of any', 'segment, generally,', 'more important discussions might happen that will conclude a particular topic and then start another. in order to take this fact into account, we introduce the term px n, where n and px', 'denote the total number of extracted utterances in a segment and the position of the utterance ( the', 'edge x belongs to ) in the set of n utterances, respectively. in order', 'to solve the above  #TAUTHOR_TAG problem, we', 'impose a number of constraints. some of the constraints have been directly adapted from the original  #TAUTHOR_TAG. for example, we use the same constraints for restricting one incoming edge per node, as well as we impose the connectivity constraint', '']",3
"['recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['of the fundamental properties of the language.', 'most importantly, it is clear from some recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['arising from the analyses performed with co - occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for', 'the success of the model. therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language.', 'most importantly, it is clear from some recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', 'should be introduced to capture a wider range of linguistic features. many of the applications relying on network analysis outperform other traditional shallow strategies', '']",0
"['recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['of the fundamental properties of the language.', 'most importantly, it is clear from some recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['arising from the analyses performed with co - occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for', 'the success of the model. therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language.', 'most importantly, it is clear from some recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', 'should be introduced to capture a wider range of linguistic features. many of the applications relying on network analysis outperform other traditional shallow strategies', '']",2
"['recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['of the fundamental properties of the language.', 'most importantly, it is clear from some recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['arising from the analyses performed with co - occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for', 'the success of the model. therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language.', 'most importantly, it is clear from some recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', 'should be introduced to capture a wider range of linguistic features. many of the applications relying on network analysis outperform other traditional shallow strategies', '']",1
"['recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['of the fundamental properties of the language.', 'most importantly, it is clear from some recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', '']","['arising from the analyses performed with co - occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for', 'the success of the model. therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language.', 'most importantly, it is clear from some recent studies  #TAUTHOR_TAG 9 ] that novel topological measurements', 'should be introduced to capture a wider range of linguistic features. many of the applications relying on network analysis outperform other traditional shallow strategies', '']",5
"['.  #TAUTHOR_TAG, and mohammadi and khasteh [ 19 ] are examples of']","['[ 17 ], xia et al.  #TAUTHOR_TAG, and mohammadi and khasteh [ 19 ] are examples of state - of - the - art models for']","['.  #TAUTHOR_TAG, and mohammadi and khasteh [ 19 ] are examples of']","['as a prevalent form of communication has a fundamental role in conducting knowledge and information between humans.', 'nevertheless, not all texts are equally intelligible and understandable for all people.', 'therefore, to ensure the clarity and understandability of the written information, it is crucial to measure its readability.', 'the significance of this measurement is apparent from its applications in different fields such as education [ 1, 2 ], medical instructions [ 3 ] [ 4 ] [ 5 ] [ 6 ] [ 7 ] [ 8 ], social media communications [ 9 ], marketing and advertising [ 10 ] [ 11 ] [ 12 ], and in some related fields of research like text simplification [ 13 ] [ 14 ] [ 15 ].', 'however, readability assessment entails some challenges.', 'the first attempt to quantify the readability of the text was the manual intuition - based evaluation, which was done by human readability experts.', 'such evaluation is not standardized or globally correct ; hence, researchers such as flesch [ 16 ] has developed readability measurement formulas.', 'these formulas use simple and manually calculable properties of the text, such as the number of syllables, words, or sentences in the text to assess its readability.', 'these formulas become so popular that they are even widely used nowadays.', 'nonetheless, the low accuracy of such formulas and their language dependency made way for more advanced and accurate readability assessment methods, which involve machine learning techniques.', 'these models are highly accurate for their use of sophisticated nlp features and machine intelligence to associate the extracted features to a proper readability level.', 'models proposed by vajjala and meurers [ 17 ], xia et al.  #TAUTHOR_TAG, and mohammadi and khasteh [ 19 ] are examples of state - of - the - art models for their target languages and target audience.', 'these models are using support vector machines trained on complex and proper feature sets extracted from related datasets.', 'still, their use of complicated and language - specific nlp features makes these models challenging to implement and heavily language - dependent.', 'furthermore, they do not offer any solution to the problem of finding the minimum portion of the text required to accurately assess the readability of a long text.', 'the feature extraction task from a long text is computationally heavy, and minimizing the required length of the text to assess its readability is vital in large collections of documents.', 'utilizing the recent advances in deep learning and deep reinforcement learning, a new approach to text readability assessment is introduced in this study.', 'word - to - vec and frequency language model are used to represent the input text']",0
,,,,0
"['##s dataset  #TAUTHOR_TAG.', 'this']","['to the cambridge exams dataset  #TAUTHOR_TAG.', 'this']","['to the cambridge exams dataset  #TAUTHOR_TAG.', 'this dataset contains texts from']","['datasets are used to evaluate three different aspects of the proposed model.', 'firstly, the weebit dataset [ 17 ] is used to assess the accuracy of the model on deciding the readability of english texts for native readers.', 'weebit dataset is gathered from articles in the weekly reader magazine and the bbc - bitesize website, which is targeted at readers of various ages.', 'weebit dataset comprises texts from five different readability levels arranged by age ( 8 - 9, 9 - 10, 10 - 12, 11 - 14, [ 14 ] [ 15 ] [ 16 ].', 'the total number of texts in the dataset is over ten thousand texts.', 'nonetheless, due to the significant imbalance in the dataset, some texts are randomly removed from some classes.', 'a sum of 3145 texts is used for evaluation purposes, which is similar to the original weebit paper [ 17 ].', 'prior to this study, distinct models have been used to assess the readability of english texts for second language readers.', 'since the drl model eliminates the need for specific feature engineering for different types of text readability assessment, the proposed model can be applied to second language datasets without any modifications.', 'to examine the proposed drl model regarding this ability, it is applied to the cambridge exams dataset  #TAUTHOR_TAG.', '']",5
"[' #TAUTHOR_TAG, we applied a dual rnn in']","[' #TAUTHOR_TAG, we applied a dual rnn in']","['the emotion of the speaker.', 'experimental evidence shows the potential of the approach.', 'in our previous work  #TAUTHOR_TAG, we applied a dual rnn in']","['this era of high - performance computing, human - computer interaction ( hci ) has become pervasive.', 'to enrich the user experience, the system is often required to detect human emotion and produce a response with proper emotional context [ 1, 2 ].', 'the first step in such an hci involves building a system that recognizes emotion from the speech utterance.', 'a speech emotional system aims to identify audio recording as belonging to one of the categories, like happy, sad, angry or neutral.', 'beside hci, the output of emotion recognition engine is beneficial in the paralinguistic area as well [ 3 ].', 'in this paper, we build a speech emotion recognition system that uses acoustic and textual information in tandem.', 'various approaches to address emotion recognition have been investigated in the literature.', 'most of the techniques involve extracting low - level or high - level acoustic features for this task [ 4 ].', 'in emotion recognition, the lexical content of the audio recording is an important source of information that is usually ignored.', 'for example, the presence of words such as "" gorgeous "" and "" stunning "" in the utterance would indicate that the person is happy.', 'recently researchers * most work was done while the author was an intern at adobe research. have also explored the application of textual content of the speech signal for this task.', 'in [ 5 ], frame and supra - segmental level features ( such as pitch and spectral contours ) are derived from the speech signal.', 'textual information is used by spotting keywords that emphases the emotional states of the speaker.', 'the work in [ 6 ] also presents an approach to exploit the acoustic and lexical content.', 'in particular, they explored conventional acoustic features from the speech signal while the textual information is derived from the bag of word representation.', 'recently, deep neural network ( dnn ) has shown to provide good results for modeling acoustic and textual information for emotion identification.', 'in [ 5 ], textual and acoustic information of the utterance are used by a dnn to obtain hidden feature representations for both the modality.', 'these features are then concatenated to represent the utterance and subsequently used to classify the emotion of the speaker.', 'experimental evidence shows the potential of the approach.', 'in our previous work  #TAUTHOR_TAG, we applied a dual rnn in order to obtain a richer representation by blending the content and acoustic knowledge.', 'in this paper, we improve upon our earlier work by incorporating an attention mechanism in the emotion recognition framework.', 'the proposed attention mechanism is trained to exploit both textual and acoustic information in tandem.', 'we refer to this attention method as the multi - hop.', 'the']",0
"['5 ] identified emotional key phrases and salience of verbal cues from both phoneme sequences and words.', 'recently,  #TAUTHOR_TAG 18 ] combined acoustic information and conversation transcripts using a neural']","['[ 16, 17 ].', 'multi - modal approaches using acoustic features and textual information have been investigated.', '[ 5 ] identified emotional key phrases and salience of verbal cues from both phoneme sequences and words.', 'recently,  #TAUTHOR_TAG 18 ] combined acoustic information and conversation transcripts using a neural network - based model to']","['5 ] identified emotional key phrases and salience of verbal cues from both phoneme sequences and words.', 'recently,  #TAUTHOR_TAG 18 ] combined acoustic information and conversation transcripts using a neural network - based model to']","['with classical algorithms based models such as support vector machine ( svm ), hidden markov model ( hmm ) and decision tree [ 9, 10, 11 ], various neural network architectures have been recently introduced for the speech emotion recognition task.', 'for exam - ple, convolutional neural network ( cnn ) - based models were trained on spectrograms or audio features such as mel - frequency cepstral coefficients ( mfccs ) and low - level descriptors ( llds ) [ 12, 13, 14 ].', 'more complex models such as [ 15 ] were designed to better learn nonlinear decision boundaries of emotional speech and achieved the best - recorded performance in audio modality models on iemocap dataset [ 8 ].', 'several neural network models with attention mechanism have been proposed to efficiently focus on a prominent part of speech and learn temporal dependency within whole utterance [ 16, 17 ].', 'multi - modal approaches using acoustic features and textual information have been investigated.', '[ 5 ] identified emotional key phrases and salience of verbal cues from both phoneme sequences and words.', 'recently,  #TAUTHOR_TAG 18 ] combined acoustic information and conversation transcripts using a neural network - based model to improve emotion classification accuracy.', 'however, none of these studies utilized attention method over audio and text modality in tandem for contextual understanding of the emotion in audio recording']",0
"['modality  #TAUTHOR_TAG 21 ].', 'as opposed to this']","['modality  #TAUTHOR_TAG 21 ].', 'as opposed to this approach,']","['proposed mha model.', 'previous research used multi - modal information independently using neural network model by concatenating features from each modality  #TAUTHOR_TAG 21 ].', 'as opposed to this approach,']","['propose a novel multi - hop attention method to predict the importance of audio and text, referred to multi - hop attention ( mha ).', 'figure 1 shows the architecture of the proposed mha model.', 'previous research used multi - modal information independently using neural network model by concatenating features from each modality  #TAUTHOR_TAG 21 ].', 'as opposed to this approach, we propose a neural network architecture that exploits information in each modality by extracting relevant segments of the speech data using information from the lexical content ( and vice - versa ).', 'first, the acoustic and textual data are encoded with the audio - bre and text - bre, respectively, using equation ( 1 ).', '']",0
"[' #TAUTHOR_TAG, we applied a dual rnn in']","[' #TAUTHOR_TAG, we applied a dual rnn in']","['the emotion of the speaker.', 'experimental evidence shows the potential of the approach.', 'in our previous work  #TAUTHOR_TAG, we applied a dual rnn in']","['this era of high - performance computing, human - computer interaction ( hci ) has become pervasive.', 'to enrich the user experience, the system is often required to detect human emotion and produce a response with proper emotional context [ 1, 2 ].', 'the first step in such an hci involves building a system that recognizes emotion from the speech utterance.', 'a speech emotional system aims to identify audio recording as belonging to one of the categories, like happy, sad, angry or neutral.', 'beside hci, the output of emotion recognition engine is beneficial in the paralinguistic area as well [ 3 ].', 'in this paper, we build a speech emotion recognition system that uses acoustic and textual information in tandem.', 'various approaches to address emotion recognition have been investigated in the literature.', 'most of the techniques involve extracting low - level or high - level acoustic features for this task [ 4 ].', 'in emotion recognition, the lexical content of the audio recording is an important source of information that is usually ignored.', 'for example, the presence of words such as "" gorgeous "" and "" stunning "" in the utterance would indicate that the person is happy.', 'recently researchers * most work was done while the author was an intern at adobe research. have also explored the application of textual content of the speech signal for this task.', 'in [ 5 ], frame and supra - segmental level features ( such as pitch and spectral contours ) are derived from the speech signal.', 'textual information is used by spotting keywords that emphases the emotional states of the speaker.', 'the work in [ 6 ] also presents an approach to exploit the acoustic and lexical content.', 'in particular, they explored conventional acoustic features from the speech signal while the textual information is derived from the bag of word representation.', 'recently, deep neural network ( dnn ) has shown to provide good results for modeling acoustic and textual information for emotion identification.', 'in [ 5 ], textual and acoustic information of the utterance are used by a dnn to obtain hidden feature representations for both the modality.', 'these features are then concatenated to represent the utterance and subsequently used to classify the emotion of the speaker.', 'experimental evidence shows the potential of the approach.', 'in our previous work  #TAUTHOR_TAG, we applied a dual rnn in order to obtain a richer representation by blending the content and acoustic knowledge.', 'in this paper, we improve upon our earlier work by incorporating an attention mechanism in the emotion recognition framework.', 'the proposed attention mechanism is trained to exploit both textual and acoustic information in tandem.', 'we refer to this attention method as the multi - hop.', 'the']",6
"['this research is extended work from previous research  #TAUTHOR_TAG, we use the']","['this research is extended work from previous research  #TAUTHOR_TAG, we use the']","['this research is extended work from previous research  #TAUTHOR_TAG, we use the same feature extraction method as done in our']","['this research is extended work from previous research  #TAUTHOR_TAG, we use the same feature extraction method as done in our previous work.', 'after extracting 40 - dimensional mel - frequency cepstral coefficients ( mfcc ) feature ( frame size is set to 25 ms at a rate of 10 ms with the hamming window ) using kaldi [ 22 ], we concatenate it with its first, second order derivates, making the feature dimension to 120.', 'we also extract prosodic features by using opensmile toolkit [ 23 ] and appending it to the audio feature vector.', 'in preparing the textual dataset, we first use the ground - truth transcripts of the iemocap dataset.', 'in a practical scenario where we may not access to transcripts of the audio, we obtain all of the transcripts from the speech signal using a commercial asr system [ 24 ] ( the performance of the asr system is word error rate ( wer ) of 5. 53 % ).', 'we apply word - tokenizer to the transcripts and obtain sequential data for textual input.', 'the maximum length of an audio segment is set to 750 based on the implementation choices presented in [ 25 ] and 128 for the textual input which covers the maximum length of the tokenized transcripts.', 'we minimize the cross - entropy loss function using ( equation ( 2 ) ) the adam optimizer [ 26 ] with a learning rate of 1e - 3 and gradients clipped with a norm value of 1.', 'for the purposes of regularization, we apply the dropout method, 30 %.', 'the number of hidden units and the number of layers in the rnn for each model ( bre and mha ) are optimized on the development set']",6
"['5 ] identified emotional key phrases and salience of verbal cues from both phoneme sequences and words.', 'recently,  #TAUTHOR_TAG 18 ] combined acoustic information and conversation transcripts using a neural']","['[ 16, 17 ].', 'multi - modal approaches using acoustic features and textual information have been investigated.', '[ 5 ] identified emotional key phrases and salience of verbal cues from both phoneme sequences and words.', 'recently,  #TAUTHOR_TAG 18 ] combined acoustic information and conversation transcripts using a neural network - based model to']","['5 ] identified emotional key phrases and salience of verbal cues from both phoneme sequences and words.', 'recently,  #TAUTHOR_TAG 18 ] combined acoustic information and conversation transcripts using a neural network - based model to']","['with classical algorithms based models such as support vector machine ( svm ), hidden markov model ( hmm ) and decision tree [ 9, 10, 11 ], various neural network architectures have been recently introduced for the speech emotion recognition task.', 'for exam - ple, convolutional neural network ( cnn ) - based models were trained on spectrograms or audio features such as mel - frequency cepstral coefficients ( mfccs ) and low - level descriptors ( llds ) [ 12, 13, 14 ].', 'more complex models such as [ 15 ] were designed to better learn nonlinear decision boundaries of emotional speech and achieved the best - recorded performance in audio modality models on iemocap dataset [ 8 ].', 'several neural network models with attention mechanism have been proposed to efficiently focus on a prominent part of speech and learn temporal dependency within whole utterance [ 16, 17 ].', 'multi - modal approaches using acoustic features and textual information have been investigated.', '[ 5 ] identified emotional key phrases and salience of verbal cues from both phoneme sequences and words.', 'recently,  #TAUTHOR_TAG 18 ] combined acoustic information and conversation transcripts using a neural network - based model to improve emotion classification accuracy.', 'however, none of these studies utilized attention method over audio and text modality in tandem for contextual understanding of the emotion in audio recording']",1
"['by the architecture used in  #TAUTHOR_TAG 17, 19 ], we train']","['by the architecture used in  #TAUTHOR_TAG 17, 19 ], we train']","['by the architecture used in  #TAUTHOR_TAG 17, 19 ], we train a recurrent encoder to predict the categorical class of']","['by the architecture used in  #TAUTHOR_TAG 17, 19 ], we train a recurrent encoder to predict the categorical class of a given audio signal.', 'to model the sequential nature of the speech signal, we use a bidirectional recurrent encoder ( bre ) as shown in the figure 1 ( a ).', 'we also added a residual connection to the model for promoting convergence during training [ 20 ].', 'a sequence of feature vectors is fed as input to the bre, which leads to the formation of hidden states of the model as given by the following equation :', 'where f θ, f θ are the forward and backward long short - term memory ( lstm ) with weight parameter θ, ht represents the hidden state at t - th time step, and xt represents the t - th mfcc features in audio signal.', 'the hidden representations ( − → h t, ← − h t ) from forward / backward lstms are concatenated for produce the feature, ot.', 'to follow previous research  #TAUTHOR_TAG, we also add another prosodic feature vector, p, with each ot to generate a more informative vector representation of the signal, o a t.', '']",1
"['by the architecture used in  #TAUTHOR_TAG 17, 19 ], we train']","['by the architecture used in  #TAUTHOR_TAG 17, 19 ], we train']","['by the architecture used in  #TAUTHOR_TAG 17, 19 ], we train a recurrent encoder to predict the categorical class of']","['by the architecture used in  #TAUTHOR_TAG 17, 19 ], we train a recurrent encoder to predict the categorical class of a given audio signal.', 'to model the sequential nature of the speech signal, we use a bidirectional recurrent encoder ( bre ) as shown in the figure 1 ( a ).', 'we also added a residual connection to the model for promoting convergence during training [ 20 ].', 'a sequence of feature vectors is fed as input to the bre, which leads to the formation of hidden states of the model as given by the following equation :', 'where f θ, f θ are the forward and backward long short - term memory ( lstm ) with weight parameter θ, ht represents the hidden state at t - th time step, and xt represents the t - th mfcc features in audio signal.', 'the hidden representations ( − → h t, ← − h t ) from forward / backward lstms are concatenated for produce the feature, ot.', 'to follow previous research  #TAUTHOR_TAG, we also add another prosodic feature vector, p, with each ot to generate a more informative vector representation of the signal, o a t.', '']",5
"['works  #TAUTHOR_TAG 18 ],']","['works  #TAUTHOR_TAG 18 ],']","['consistent comparison with previous works  #TAUTHOR_TAG 18 ], all utterances labeled "" excitement "" are merged with']","['train and evaluate our model, we use the interactive emotional dyadic motion capture ( iemocap ) [ 8 ] dataset, which includes five sessions of utterances between two speakers ( one male and one female ).', 'total 10 unique speakers participated in this work.', 'for consistent comparison with previous works  #TAUTHOR_TAG 18 ], all utterances labeled "" excitement "" are merged with those labeled "" happiness "".', 'we assign single categorical emotion to the utterance with majority of annotators agreed on the emotion labels.', '']",5
"['as neutral class, supporting the claims of  #TAUTHOR_TAG 25 ]']","['neutral class, supporting the claims of  #TAUTHOR_TAG 25 ]. the', 'text - bre shows improvement in classifying']","['class, supporting the claims of  #TAUTHOR_TAG 25 ]']","['', ') in terms of wa. figure 2 shows the confusion matrices of the proposed systems. in audio - bre ( fig. 2 ( a', ') ),', 'most of the emotion', 'labels are frequently misclassified as neutral class, supporting the claims of  #TAUTHOR_TAG 25 ]. the', 'text - bre shows improvement in classifying most of the labels in fig. 2 ( b ). in', '']",5
"['modality  #TAUTHOR_TAG 21 ].', 'as opposed to this']","['modality  #TAUTHOR_TAG 21 ].', 'as opposed to this approach,']","['proposed mha model.', 'previous research used multi - modal information independently using neural network model by concatenating features from each modality  #TAUTHOR_TAG 21 ].', 'as opposed to this approach,']","['propose a novel multi - hop attention method to predict the importance of audio and text, referred to multi - hop attention ( mha ).', 'figure 1 shows the architecture of the proposed mha model.', 'previous research used multi - modal information independently using neural network model by concatenating features from each modality  #TAUTHOR_TAG 21 ].', 'as opposed to this approach, we propose a neural network architecture that exploits information in each modality by extracting relevant segments of the speech data using information from the lexical content ( and vice - versa ).', 'first, the acoustic and textual data are encoded with the audio - bre and text - bre, respectively, using equation ( 1 ).', '']",4
"['as neutral class, supporting the claims of  #TAUTHOR_TAG 25 ]']","['neutral class, supporting the claims of  #TAUTHOR_TAG 25 ]. the', 'text - bre shows improvement in classifying']","['class, supporting the claims of  #TAUTHOR_TAG 25 ]']","['', ') in terms of wa. figure 2 shows the confusion matrices of the proposed systems. in audio - bre ( fig. 2 ( a', ') ),', 'most of the emotion', 'labels are frequently misclassified as neutral class, supporting the claims of  #TAUTHOR_TAG 25 ]. the', 'text - bre shows improvement in classifying most of the labels in fig. 2 ( b ). in', '']",3
['on this task  #TAUTHOR_TAG'],['on this task  #TAUTHOR_TAG'],"['has made significant progress on this task  #TAUTHOR_TAG.', 'however,']","['', 'previous work has made significant progress on this task  #TAUTHOR_TAG.', '']",0
"['within a log - linear framework  #TAUTHOR_TAG.', 'recent']","['within a log - linear framework  #TAUTHOR_TAG.', 'recent']","['the use of tree conditional random fields  #AUTHOR_TAG and template extraction within a log - linear framework  #TAUTHOR_TAG.', 'recent work seeks to solve the full selective generation problem through a single framework.', ' #AUTHOR_TAG and  #AUTHOR_TAG learn alignments']","['', ' #AUTHOR_TAG propose a language generation system that uses the widl - representation, a formalism used to compactly represent probability distributions over finite sets of strings.', ' #AUTHOR_TAG and  #AUTHOR_TAG use synchronous context - free grammars to generate natural language sentences from formal meaning representations.', ' #AUTHOR_TAG employs probabilistic context - free grammars to perform surface realization.', 'other effective approaches include the use of tree conditional random fields  #AUTHOR_TAG and template extraction within a log - linear framework  #TAUTHOR_TAG.', 'recent work seeks to solve the full selective generation problem through a single framework.', '']",0
"['within a log - linear framework  #TAUTHOR_TAG.', 'recent']","['within a log - linear framework  #TAUTHOR_TAG.', 'recent']","['the use of tree conditional random fields  #AUTHOR_TAG and template extraction within a log - linear framework  #TAUTHOR_TAG.', 'recent work seeks to solve the full selective generation problem through a single framework.', ' #AUTHOR_TAG and  #AUTHOR_TAG learn alignments']","['', ' #AUTHOR_TAG propose a language generation system that uses the widl - representation, a formalism used to compactly represent probability distributions over finite sets of strings.', ' #AUTHOR_TAG and  #AUTHOR_TAG use synchronous context - free grammars to generate natural language sentences from formal meaning representations.', ' #AUTHOR_TAG employs probabilistic context - free grammars to perform surface realization.', 'other effective approaches include the use of tree conditional random fields  #AUTHOR_TAG and template extraction within a log - linear framework  #TAUTHOR_TAG.', 'recent work seeks to solve the full selective generation problem through a single framework.', '']",0
"['previous work found on this dataset  #TAUTHOR_TAG.', 'as an alternative,']","['previous work found on this dataset  #TAUTHOR_TAG.', 'as an alternative,']","['previous work found on this dataset  #TAUTHOR_TAG.', 'as an alternative,']","['considered beam search as an alternative to greedy search in our primary setup ( eqn. 1 ), but this performs worse, similar to what previous work found on this dataset  #TAUTHOR_TAG.', 'as an alternative, we consider a beam filter based on a knearest neighborhood.', 'see supplementary material for details.', 'table 9 shows that this k - nn beam filter improves results over the primary greedy results.', 'aligner ablation first, we evaluate the contribution of our proposed coarse - to - fine aligner by comparing our model with the basic encoder - alignerdecoder model introduced by  #AUTHOR_TAG.', '']",0
['on this task  #TAUTHOR_TAG'],['on this task  #TAUTHOR_TAG'],"['has made significant progress on this task  #TAUTHOR_TAG.', 'however,']","['', 'previous work has made significant progress on this task  #TAUTHOR_TAG.', '']",1
['on this task  #TAUTHOR_TAG'],['on this task  #TAUTHOR_TAG'],"['has made significant progress on this task  #TAUTHOR_TAG.', 'however,']","['', 'previous work has made significant progress on this task  #TAUTHOR_TAG.', '']",1
"['work  #TAUTHOR_TAG.', 'we later discuss an alternative k - nearest neighbor - based beam filter ( see sec 6. 2 )']","['work  #TAUTHOR_TAG.', 'we later discuss an alternative k - nearest neighbor - based beam filter ( see sec 6. 2 )']","['inference, we perform greedy search starting with the first word x 1.', 'beam search offers a way to perform approximate joint inference - however, we empirically found that beam search does not perform any better than greedy search on the datasets that we consider, an observation that is shared with previous work  #TAUTHOR_TAG.', 'we later discuss an alternative k - nearest neighbor - based beam filter ( see sec 6. 2 )']","['train the model using the database - record pairs ( r 1 : n, x 1 : t ) from the training corpora so as to maximize the likelihood of the ground - truth language description x * 1 : t ( eqn. 1 ).', 'additionally, we introduce a regularization term ( n j = 1 p j − γ ) 2 that enables the model to influence the pre - selector weights based on the aforementioned relationship between the output of the preselector and the number of selected records.', 'moreover, we also introduce the term ( 1. 0 − max ( p j ) ), which accounts for the fact that at least one record should be pre - selected.', 'note that when γ is equal to n, the pre - selector is forced to select all the records ( p j = 1. 0 for all j ), and the coarse - to - fine alignment reverts to the standard alignment introduced by  #AUTHOR_TAG.', 'together with the negative loglikelihood of the ground - truth description x * 1 : t, our loss function becomes', 'having trained the model, we generate the natural language description by finding the maximum a posteriori words under the learned model ( eqn. 1 ).', 'for inference, we perform greedy search starting with the first word x 1.', 'beam search offers a way to perform approximate joint inference - however, we empirically found that beam search does not perform any better than greedy search on the datasets that we consider, an observation that is shared with previous work  #TAUTHOR_TAG.', 'we later discuss an alternative k - nearest neighbor - based beam filter ( see sec 6. 2 )']",3
"[""data - starved robocup dataset to demonstrate the model's generalizability."", 'following  #TAUTHOR_TAG, we use']","[""data - starved robocup dataset to demonstrate the model's generalizability."", 'following  #TAUTHOR_TAG, we use weathergov training, development,']","[""use the data - starved robocup dataset to demonstrate the model's generalizability."", 'following  #TAUTHOR_TAG, we use']","[""we analyze our model on the benchmark weathergov dataset, and use the data - starved robocup dataset to demonstrate the model's generalizability."", 'following  #TAUTHOR_TAG, we use weathergov training, development, and test splits of size 25000, 1000, and 3528, respectively.', 'for robocup, we follow the evaluation methodology of previous work  #AUTHOR_TAG, performing three - fold cross - validation whereby we train on three games ( approximately 1000 scenarios ) and test on the fourth.', 'within each split, we hold out 10 % of the training data as the development set to tune the early - stopping criterion and γ.', 'we then report the standard average performance ( weighted by the number of scenarios ) over these four splits.', '']",5
"['cbleu of  #TAUTHOR_TAG, respectively ( sec. 5 ).', 'table 1 compares our test results against']","['cbleu of  #TAUTHOR_TAG, respectively ( sec. 5 ).', 'table 1 compares our test results against']","['- 1 and two bleu scores ( standard sbleu and the customized cbleu of  #TAUTHOR_TAG, respectively ( sec. 5 ).', 'table 1 compares our test results against previous methods']","['report the performance of content selection and surface realization using f - 1 and two bleu scores ( standard sbleu and the customized cbleu of  #TAUTHOR_TAG, respectively ( sec. 5 ).', 'table 1 compares our test results against previous methods that include kl12  #AUTHOR_TAG, kl13  #AUTHOR_TAG, and alk10  #TAUTHOR_TAG.', 'our method achieves the best results reported to - date on all three metrics, with relative improvements of 11. 94 % ( f - 1 ), 58. 88 % ( sbleu ), and 36. 68 % ( cbleu ) over the previous state - of - the - art']",5
"['cbleu of  #TAUTHOR_TAG, respectively ( sec. 5 ).', 'table 1 compares our test results against']","['cbleu of  #TAUTHOR_TAG, respectively ( sec. 5 ).', 'table 1 compares our test results against']","['- 1 and two bleu scores ( standard sbleu and the customized cbleu of  #TAUTHOR_TAG, respectively ( sec. 5 ).', 'table 1 compares our test results against previous methods']","['report the performance of content selection and surface realization using f - 1 and two bleu scores ( standard sbleu and the customized cbleu of  #TAUTHOR_TAG, respectively ( sec. 5 ).', 'table 1 compares our test results against previous methods that include kl12  #AUTHOR_TAG, kl13  #AUTHOR_TAG, and alk10  #TAUTHOR_TAG.', 'our method achieves the best results reported to - date on all three metrics, with relative improvements of 11. 94 % ( f - 1 ), 58. 88 % ( sbleu ), and 36. 68 % ( cbleu ) over the previous state - of - the - art']",4
"['previous work found on this dataset  #TAUTHOR_TAG.', 'as an alternative,']","['previous work found on this dataset  #TAUTHOR_TAG.', 'as an alternative,']","['previous work found on this dataset  #TAUTHOR_TAG.', 'as an alternative,']","['considered beam search as an alternative to greedy search in our primary setup ( eqn. 1 ), but this performs worse, similar to what previous work found on this dataset  #TAUTHOR_TAG.', 'as an alternative, we consider a beam filter based on a knearest neighborhood.', 'see supplementary material for details.', 'table 9 shows that this k - nn beam filter improves results over the primary greedy results.', 'aligner ablation first, we evaluate the contribution of our proposed coarse - to - fine aligner by comparing our model with the basic encoder - alignerdecoder model introduced by  #AUTHOR_TAG.', '']",4
"['build classifiers. in a recent work  #TAUTHOR_TAG, a new corpus was constructed from']","['together with content - based features to build classifiers. in a recent work  #TAUTHOR_TAG, a new corpus was constructed from the pun of the day website.  #TAUTHOR_TAG explained and computed stylistic features']","['together with content - based features to build classifiers. in a recent work  #TAUTHOR_TAG, a new corpus was constructed from']","['instances while using formal writing resources ( e. g., news titles ) to obtain non - humorous instances.', 'three humor - specific stylistic features, including alliteration, antonymy, and', 'adult slang were utilized together with content - based features to build classifiers. in a recent work  #TAUTHOR_TAG, a new corpus was constructed from the pun of the day website.  #TAUTHOR_TAG explained and computed stylistic features based on the following four aspects : ( a ) incongru', '##ity, ( b ) ambiguity, ( c ) interpersonal effect, and ( d ) phonetic style. in addition, word2vec  #AUTHOR_TAG distributed representations were utilized in the model', ""building. beyond lexical cues from text inputs, other research has also utilized speakers'acoustic cues  #AUTHOR_TAG"", ""b ). these studies have typically used audio tracks from tv shows and their corresponding captions in order to categorize characters'speaking turns as humorous or non - humorous based on cann"", '##ed laughter. convolutional neural networks ( cnns ) have recently been successfully', '']",1
"[""' sentences."", "" #AUTHOR_TAG and  #TAUTHOR_TAG, we selected the same numbers ( n = 4726 ) of'lau""]","[""defined as'no - laughter'sentences."", "" #AUTHOR_TAG and  #TAUTHOR_TAG, we selected the same numbers ( n = 4726 ) of'laughter'and'nolaughter'sentences."", 'to minimize possible topic shifts between positive and negative instances, for']","[""' sentences."", "" #AUTHOR_TAG and  #TAUTHOR_TAG, we selected the same numbers ( n = 4726 ) of'lau""]","['talks 2 are recordings from ted conferences and other special ted programs.', ""many effects in a presentation can cause audience laugh, such as speaking content, presenters'nonverbal behaviors, and so on."", 'in the present study, we focused on the transcripts of the talks.', ""most transcripts of the talks contain the markup'( laughter ) ', which represents where audiences laughed aloud during the talks."", 'this special markup was used to determine utterance labels.', 'we collected 1, 192 ted talk transcripts 3.', 'an example transcription is given in figure 1.', 'the collected transcripts were split into sentences using the stanford corenlp tool  #AUTHOR_TAG.', ""in this study, sentences containing or immediately followed by'( laughter )'were used as'laughter'sentences, as shown in figure 1 ; all other sentences were defined as'no - laughter'sentences."", "" #AUTHOR_TAG and  #TAUTHOR_TAG, we selected the same numbers ( n = 4726 ) of'laughter'and'nolaughter'sentences."", 'to minimize possible topic shifts between positive and negative instances, for each positive instance, we randomly picked one negative instance nearby ( the context window was 7 sentences in this study ).', ""for example, in figure 1, a negative instance ( corresponding to'sent - 2') was selected from the nearby sentences ranging from'sent - 7'to'sent + 7 '."", 'more details about this data set can refer to  #AUTHOR_TAG.', 'the ted data set can be obtained by contacting the authors']",5
"[' #TAUTHOR_TAG, we applied random forest  #AUTHOR_TAG to perform humor recognition by using the following two groups of features.', '']","[' #TAUTHOR_TAG, we applied random forest  #AUTHOR_TAG to perform humor recognition by using the following two groups of features.', '']","[' #TAUTHOR_TAG, we applied random forest  #AUTHOR_TAG to perform humor recognition by using the following two groups of features.', '']","[' #TAUTHOR_TAG, we applied random forest  #AUTHOR_TAG to perform humor recognition by using the following two groups of features.', 'the first group are humor - specific stylistic features covering the following 4 categories 4 : incongruity ( 2 ), ambiguity ( 6 ), interpersonal effect ( 4 ), and phonetic pattern ( 4 ).', 'the second group are semantic distance features, including the humor label classes from 5 sentences in the training set that are closest to the sentence being evaluated ( found by using a k - nearest neighbors ( knn']",5
"['reported in  #TAUTHOR_TAG.', 'in our experiment, we firstly divided']","['reported in  #TAUTHOR_TAG.', 'in our experiment, we firstly divided']","['reported in  #TAUTHOR_TAG.', 'in our experiment, we firstly divided each corpus into two parts.', '']","['used two corpora : the ted talk corpus ( denoted as ted ) and the pun of the day corpus 5 ( denoted as pun ).', 'note that we normalized words in the pun data to lowercase to avoid a possibly elevated result caused by a special pattern : in the original format, all negative instances started with capital letters.', 'the pun data allows us to verify that our implementation of the conventional model is consistent with the work reported in  #TAUTHOR_TAG.', 'in our experiment, we firstly divided each corpus into two parts.', 'the smaller part ( the dev set ) was used for setting various hyper - parameters used in text classifiers.', 'the larger portion ( the cv set ) was then formulated as a 10 - fold crossvalidation setup for obtaining a stable and comprehensive model evaluation result.', 'for the pun data, the dev contains 482 sentences, while the cv set contains 4344 sentences.', 'for the ted data, the dev set contains 1046 utterances, while the cv set contains 8406 utterances.', 'note that, with a goal of building a speaker - independent humor detector, when partitioning our ted data set, we always kept all utterances of a single talk within the same partition.', 'when building conventional models, we developed our own feature extraction scripts and used the skll 6 python package for building random forest models.', 'when implementing cnn,  #AUTHOR_TAG.', 'after running 200 iterations of tweaking, we ended up with the following selection : f w is 6 ( entailing that the various filter sizes are ( 5, 6, 7 ) ), n f is 100, dropout 1 is 0. 7 and dropout 2 is 0. 35, optimization uses adam  #AUTHOR_TAG.', 'when training the cnn model, we randomly selected 10 % of the training data as the validation set for using early stopping to avoid over - fitting.', 'on the pun data, the cnn model shows consistent improved performance over the conventional model, as suggested in  #TAUTHOR_TAG.', '']",3
"['reported in  #TAUTHOR_TAG.', 'in our experiment, we firstly divided']","['reported in  #TAUTHOR_TAG.', 'in our experiment, we firstly divided']","['reported in  #TAUTHOR_TAG.', 'in our experiment, we firstly divided each corpus into two parts.', '']","['used two corpora : the ted talk corpus ( denoted as ted ) and the pun of the day corpus 5 ( denoted as pun ).', 'note that we normalized words in the pun data to lowercase to avoid a possibly elevated result caused by a special pattern : in the original format, all negative instances started with capital letters.', 'the pun data allows us to verify that our implementation of the conventional model is consistent with the work reported in  #TAUTHOR_TAG.', 'in our experiment, we firstly divided each corpus into two parts.', 'the smaller part ( the dev set ) was used for setting various hyper - parameters used in text classifiers.', 'the larger portion ( the cv set ) was then formulated as a 10 - fold crossvalidation setup for obtaining a stable and comprehensive model evaluation result.', 'for the pun data, the dev contains 482 sentences, while the cv set contains 4344 sentences.', 'for the ted data, the dev set contains 1046 utterances, while the cv set contains 8406 utterances.', 'note that, with a goal of building a speaker - independent humor detector, when partitioning our ted data set, we always kept all utterances of a single talk within the same partition.', 'when building conventional models, we developed our own feature extraction scripts and used the skll 6 python package for building random forest models.', 'when implementing cnn,  #AUTHOR_TAG.', 'after running 200 iterations of tweaking, we ended up with the following selection : f w is 6 ( entailing that the various filter sizes are ( 5, 6, 7 ) ), n f is 100, dropout 1 is 0. 7 and dropout 2 is 0. 35, optimization uses adam  #AUTHOR_TAG.', 'when training the cnn model, we randomly selected 10 % of the training data as the validation set for using early stopping to avoid over - fitting.', 'on the pun data, the cnn model shows consistent improved performance over the conventional model, as suggested in  #TAUTHOR_TAG.', '']",3
,,,,3
"[') by  #TAUTHOR_TAG.', '']","['( svd ) by  #TAUTHOR_TAG.', '']","[') by  #TAUTHOR_TAG.', 'the skip - gram model ( sgns ) is one of the two word2vec architectures that predicts based on']","['our experiments, we use the implementations of word2vec skip - gram with negative sampling ( sgns ) and pmi matrix factorization via singular value decomposition ( svd ) by  #TAUTHOR_TAG.', 'the skip - gram model ( sgns ) is one of the two word2vec architectures that predicts based on a target word one of its context words at a time.', 'error of prediction is calculated in the output via softmax and back - propagated to update two 1 the paradigmatic task can also be defined based on higherlevel taxonomic relations.', ""for example, given the grammar in table 1, we expect models to cluster verbs and nouns because each of these higher - level word types share some within - category contextual similarities and betweencategory differences ( e. g., all nouns in the grammar have a verb in context, whereas verbs don't have verbs in their context )."", 'in section 3. 5 where semantic spaces are visualized we will return to this important point, but for the rest of our experiments model performance is evaluated based on the two basic tasks defined above.', '']",3
"[') by  #TAUTHOR_TAG.', '']","['( svd ) by  #TAUTHOR_TAG.', '']","[') by  #TAUTHOR_TAG.', 'the skip - gram model ( sgns ) is one of the two word2vec architectures that predicts based on']","['our experiments, we use the implementations of word2vec skip - gram with negative sampling ( sgns ) and pmi matrix factorization via singular value decomposition ( svd ) by  #TAUTHOR_TAG.', 'the skip - gram model ( sgns ) is one of the two word2vec architectures that predicts based on a target word one of its context words at a time.', 'error of prediction is calculated in the output via softmax and back - propagated to update two 1 the paradigmatic task can also be defined based on higherlevel taxonomic relations.', ""for example, given the grammar in table 1, we expect models to cluster verbs and nouns because each of these higher - level word types share some within - category contextual similarities and betweencategory differences ( e. g., all nouns in the grammar have a verb in context, whereas verbs don't have verbs in their context )."", 'in section 3. 5 where semantic spaces are visualized we will return to this important point, but for the rest of our experiments model performance is evaluated based on the two basic tasks defined above.', '']",5
['5 and 1 eig ( for more details refer to  #TAUTHOR_TAG'],"['indicates the number of negative samples ( we try between zero and 6 negative samples ).', 'finally, a parameter in svd determines the asymmetry of factorization, which was simulated with 0, 0. 5 and 1 eig ( for more details refer to  #TAUTHOR_TAG']",['5 and 1 eig ( for more details refer to  #TAUTHOR_TAG'],"['comparative experiments on small vs. big data, we generate 5 independent corpora of each size ( between 1k and 30k sentences ) according to the sampling procedure described in section 2. 1.', 'there are three important parameters that strongly affect the performance of the models, but since they are not the focus of our study we chose their values through a performance maximization procedure in all our experiments.', 'one parameter called dim is the number of reduced dimensions or the size of final vectors, which is enumerated between 2 and 14 in our experiments.', 'the other parameter neg is only applicable to sgns and indicates the number of negative samples ( we try between zero and 6 negative samples ).', 'finally, a parameter in svd determines the asymmetry of factorization, which was simulated with 0, 0. 5 and 1 eig ( for more details refer to  #TAUTHOR_TAG']",0
['a w + c equivalent setting proposed by  #TAUTHOR_TAG in'],['a w + c equivalent setting proposed by  #TAUTHOR_TAG in'],"['a w + c equivalent setting proposed by  #TAUTHOR_TAG in performing the syntagmatic task, however the enhancement is tightly bounded for this model.', 'for the paradigmatic task, we expected']","['', 'this enhancement is more pronounced in the sgns model : more data increases the accuracy of syntagmatic similarity inference consistently when the w + c option is used.', 'svd also benefits from a w + c equivalent setting proposed by  #TAUTHOR_TAG in performing the syntagmatic task, however the enhancement is tightly bounded for this model.', ""for the paradigmatic task, we expected an inverse pattern : explicit inclusion of first - order co - occurrence information in similarity measurement by considering both word and context vectors should hurt model's performance because only second - order information is important for the paradigmatic task."", 'we can see in figure 2 that our hypothesis is supported for svd, where the accuracy declines significantly with the inclusion of the context vectors ( compare the red and blue dotted lines ).', 'however, the sgns model does not exhibit a dramatic change of performance in the paradigmatic task with or without the w + c option ( compare the solid lines ).', 'in fact, the performance in the paradigmatic task was slightly enhanced too.', 'putting this together with what we saw above regarding sgns performance in the syntagmatic task brings us to an interesting conclusion about the "" optimal parameter setting "" for this model : using the w + c option is a good choice adding to the robustness of sgns, particularly when unsure of which type of similarity inference we would like the model to perform at the end.', 'the svd model, on the other hand, does not show the capability to learn both tasks at the same time ; it gets better in one at the expense of the other.', 'in the next section we try to explain this difference by looking into the way the two models distribute words within the high dimensional vector space']",4
['similarity suggested by  #TAUTHOR_TAG enhanced'],['explicit inclusion of firstorder similarity suggested by  #TAUTHOR_TAG enhanced'],['explicit inclusion of firstorder similarity suggested by  #TAUTHOR_TAG enhanced'],"['proposed a methodology based on artificial language generation for studying distributional semantic models.', 'this methodology was inspired by the prominent study of  #AUTHOR_TAG and we mainly selected that to bring confound factors in natural languages under control while assessing the effect of model parameters on produced word vectors.', 'the experiments in this paper revealed an interaction between the training corpus size and a variety of parameter settings of two opponent dsms in word similarity / relatedness evaluation.', 'confirming previous findings with small training data, we showed that svd could easily organize words based on paradigmatic similarities obtained from second - order co - occurrence information, whereas sgns needed more data to acquire the same type of knowledge.', 'when it comes to syntagmatic relatedness between words, both models required accurate parameter settings.', 'in particular, the default configuration of both svd and sgns aims at optimizing the space in a way that paradigmatically similar words are put together.', 'the optimal setting of the sgns for an overall superior performance in both paradigmatic and syntagmatic tasks involved the inclusion of context vectors, which is not the typically tested setting of word2vec in previous studies.', 'our analysis of similarity scores between vectors generated for all words in the artificial language showed that averaging word and context vectors would result in a more organized sgns vector space.', 'the equivalent post - processing of the matrices in svd for explicit inclusion of firstorder similarity suggested by  #TAUTHOR_TAG enhanced the performance of this model in the syntagmatic ( relatedness ) task only in the expense of making it worse for the paradigmatic ( similarity ) task.', 'our observations suggest that svd has some limitations in populating the distributional space as evenly as sgns ; thus it always comes up with vectors that are on average closer to one another.', 'further study is needed to explain this finding in a fundamental way perhaps via mathematical derivations.', 'the trade - off between performance in paradigmatic and syntagmatic task, specially for the svd model, can explain the occasional superiority and inferiority of this model against the neural opponents in previous studies : similarity and relatedness rankings for words in natural languages manifest a mixture of paradigmatic and syntagmatic relations among words, thus a certain svd model ( with its postprocessing optimized for reflecting either type of relation ) might outperform sgns in one task and not in the other.', 'our experiments were a first step towards understanding the differences between classic and neural distributional models in a more controlled setting.', 'the proposed methodology can be used in future research, e. g. to assess the effect of vocabulary and grammar size on resulting word vectors by different models, and in turn to select the right distributional approach in specific']",4
['similarity suggested by  #TAUTHOR_TAG enhanced'],['explicit inclusion of firstorder similarity suggested by  #TAUTHOR_TAG enhanced'],['explicit inclusion of firstorder similarity suggested by  #TAUTHOR_TAG enhanced'],"['proposed a methodology based on artificial language generation for studying distributional semantic models.', 'this methodology was inspired by the prominent study of  #AUTHOR_TAG and we mainly selected that to bring confound factors in natural languages under control while assessing the effect of model parameters on produced word vectors.', 'the experiments in this paper revealed an interaction between the training corpus size and a variety of parameter settings of two opponent dsms in word similarity / relatedness evaluation.', 'confirming previous findings with small training data, we showed that svd could easily organize words based on paradigmatic similarities obtained from second - order co - occurrence information, whereas sgns needed more data to acquire the same type of knowledge.', 'when it comes to syntagmatic relatedness between words, both models required accurate parameter settings.', 'in particular, the default configuration of both svd and sgns aims at optimizing the space in a way that paradigmatically similar words are put together.', 'the optimal setting of the sgns for an overall superior performance in both paradigmatic and syntagmatic tasks involved the inclusion of context vectors, which is not the typically tested setting of word2vec in previous studies.', 'our analysis of similarity scores between vectors generated for all words in the artificial language showed that averaging word and context vectors would result in a more organized sgns vector space.', 'the equivalent post - processing of the matrices in svd for explicit inclusion of firstorder similarity suggested by  #TAUTHOR_TAG enhanced the performance of this model in the syntagmatic ( relatedness ) task only in the expense of making it worse for the paradigmatic ( similarity ) task.', 'our observations suggest that svd has some limitations in populating the distributional space as evenly as sgns ; thus it always comes up with vectors that are on average closer to one another.', 'further study is needed to explain this finding in a fundamental way perhaps via mathematical derivations.', 'the trade - off between performance in paradigmatic and syntagmatic task, specially for the svd model, can explain the occasional superiority and inferiority of this model against the neural opponents in previous studies : similarity and relatedness rankings for words in natural languages manifest a mixture of paradigmatic and syntagmatic relations among words, thus a certain svd model ( with its postprocessing optimized for reflecting either type of relation ) might outperform sgns in one task and not in the other.', 'our experiments were a first step towards understanding the differences between classic and neural distributional models in a more controlled setting.', 'the proposed methodology can be used in future research, e. g. to assess the effect of vocabulary and grammar size on resulting word vectors by different models, and in turn to select the right distributional approach in specific']",6
['methods  #TAUTHOR_TAG zhou et al'],"['methods  #TAUTHOR_TAG zhou et al.,, 2018, demonstrating the']",['- art methods  #TAUTHOR_TAG zhou et al'],"['', 'training and test, which can appear when the training set is particularly smaller or from a different domain. certainly, the robustness', 'holds as long as the word embeddings are pretrained on a very large set', 'of documents, e. g. the entire wikipedia. we plug the vlawe representation, which is learned in an unsupervised manner, into a classifier, namely support vector machines ( svm ), and show that it is useful for a', 'diverse set of text classification tasks. we consider five benchmark data sets : reuters - 21578  #AUTHOR_TAG, rt - 2k  #AUTHOR_TAG, mr  #AUTHOR_TAG, trec  #AUTHOR_TAG and subj  #AUTHOR_TAG. we compare vl', '##awe with recent stateof - the - art methods  #TAUTHOR_TAG zhou et al.,, 2018, demonstrating the effectiveness of our approach. furthermore, we obtain a', 'considerable improvement on the movie review ( mr ) data set, surpassing the state - of - the - art approach of  #AUTHOR_TAG by almost 10 %', '. the rest of the paper is organized as follows. we present related works on learning documentlevel representations in section 2. we describe the vector of locally - aggregated word embeddings in section 3. we present experiments and results', '']",0
['methods  #TAUTHOR_TAG zhou et al'],"['methods  #TAUTHOR_TAG zhou et al.,, 2018, demonstrating the']",['- art methods  #TAUTHOR_TAG zhou et al'],"['', 'training and test, which can appear when the training set is particularly smaller or from a different domain. certainly, the robustness', 'holds as long as the word embeddings are pretrained on a very large set', 'of documents, e. g. the entire wikipedia. we plug the vlawe representation, which is learned in an unsupervised manner, into a classifier, namely support vector machines ( svm ), and show that it is useful for a', 'diverse set of text classification tasks. we consider five benchmark data sets : reuters - 21578  #AUTHOR_TAG, rt - 2k  #AUTHOR_TAG, mr  #AUTHOR_TAG, trec  #AUTHOR_TAG and subj  #AUTHOR_TAG. we compare vl', '##awe with recent stateof - the - art methods  #TAUTHOR_TAG zhou et al.,, 2018, demonstrating the effectiveness of our approach. furthermore, we obtain a', 'considerable improvement on the movie review ( mr ) data set, surpassing the state - of - the - art approach of  #AUTHOR_TAG by almost 10 %', '. the rest of the paper is organized as follows. we present related works on learning documentlevel representations in section 2. we describe the vector of locally - aggregated word embeddings in section 3. we present experiments and results', '']",0
['methods  #TAUTHOR_TAG zhou et al'],"['methods  #TAUTHOR_TAG zhou et al.,, 2018, demonstrating the']",['- art methods  #TAUTHOR_TAG zhou et al'],"['', 'training and test, which can appear when the training set is particularly smaller or from a different domain. certainly, the robustness', 'holds as long as the word embeddings are pretrained on a very large set', 'of documents, e. g. the entire wikipedia. we plug the vlawe representation, which is learned in an unsupervised manner, into a classifier, namely support vector machines ( svm ), and show that it is useful for a', 'diverse set of text classification tasks. we consider five benchmark data sets : reuters - 21578  #AUTHOR_TAG, rt - 2k  #AUTHOR_TAG, mr  #AUTHOR_TAG, trec  #AUTHOR_TAG and subj  #AUTHOR_TAG. we compare vl', '##awe with recent stateof - the - art methods  #TAUTHOR_TAG zhou et al.,, 2018, demonstrating the effectiveness of our approach. furthermore, we obtain a', 'considerable improvement on the movie review ( mr ) data set, surpassing the state - of - the - art approach of  #AUTHOR_TAG by almost 10 %', '. the rest of the paper is organized as follows. we present related works on learning documentlevel representations in section 2. we describe the vector of locally - aggregated word embeddings in section 3. we present experiments and results', '']",0
['are various works  #TAUTHOR_TAG that propose to build effective sentence - level or'],"['are various works  #TAUTHOR_TAG that propose to build effective sentence - level or document - level representations based on word embeddings.', 'while']",['are various works  #TAUTHOR_TAG that propose to build effective sentence - level or'],"['are various works  #TAUTHOR_TAG that propose to build effective sentence - level or document - level representations based on word embeddings.', 'while most of these approaches are based on deep learning  #TAUTHOR_TAG, there have been some approaches that are inspired by computer vision research, namely by the bag - of - visual - words and by fisher vectors  #AUTHOR_TAG.', 'the relationship between the bag - of - visual - words, fisher vectors and vlad is discussed in ( jegou et al., 2012 ).', 'the discussion can be transferred to describe the relantionship of our work and the closely - related works of and  #AUTHOR_TAG']",0
['are various works  #TAUTHOR_TAG that propose to build effective sentence - level or'],"['are various works  #TAUTHOR_TAG that propose to build effective sentence - level or document - level representations based on word embeddings.', 'while']",['are various works  #TAUTHOR_TAG that propose to build effective sentence - level or'],"['are various works  #TAUTHOR_TAG that propose to build effective sentence - level or document - level representations based on word embeddings.', 'while most of these approaches are based on deep learning  #TAUTHOR_TAG, there have been some approaches that are inspired by computer vision research, namely by the bag - of - visual - words and by fisher vectors  #AUTHOR_TAG.', 'the relationship between the bag - of - visual - words, fisher vectors and vlad is discussed in ( jegou et al., 2012 ).', 'the discussion can be transferred to describe the relantionship of our work and the closely - related works of and  #AUTHOR_TAG']",0
['methods  #TAUTHOR_TAG zhou'],['approach ( vlawe ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou'],['##e ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou'],"['the experiments, we used the pre - trained word embeddings computed with the glove toolkit provided by  #AUTHOR_TAG.', 'the pre - trained glove model contains 300 - dimensional vectors for 2. 2 million words and phrases.', 'most of the steps required for building the vlawe representation, such as the k - means clustering and the randomized forest of k - d trees, are implemented using the vlfeat library  #AUTHOR_TAG.', 'we set the number of clusters ( size of the codebook ) to k = 10, leading to a vlawe representation of k · d = 10 · 300 = 3000 components.', 'similar to jegou et al. ( 2012 ), we set α = 0. 5 for the power normalization step in equation ( 4 ), which consistently leads to near - optimal results on all data sets.', 'in the learning stage, we employ the support vector machines ( svm ) implementation provided by libsvm  #AUTHOR_TAG table 1 : performance results ( in % ) of our approach ( vlawe ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou et al.,, 2018 on the reuters - 21578, rt - 2k, mr, trec and subj data sets.', '']",0
"['methods  #TAUTHOR_TAG zhou et al.,, 2018 as']","['methods  #TAUTHOR_TAG zhou et al.,, 2018 as']","['##e with several state - of - theart methods  #TAUTHOR_TAG zhou et al.,, 2018 as']","['compare vlawe with several state - of - theart methods  #TAUTHOR_TAG zhou et al.,, 2018 as well as two baseline methods, namely the average of word embeddings and the standard bag - of - words ( bow ).', 'the corresponding results are presented in table 1.', '']",0
['methods  #TAUTHOR_TAG zhou'],['approach ( vlawe ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou'],['##e ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou'],"['the experiments, we used the pre - trained word embeddings computed with the glove toolkit provided by  #AUTHOR_TAG.', 'the pre - trained glove model contains 300 - dimensional vectors for 2. 2 million words and phrases.', 'most of the steps required for building the vlawe representation, such as the k - means clustering and the randomized forest of k - d trees, are implemented using the vlfeat library  #AUTHOR_TAG.', 'we set the number of clusters ( size of the codebook ) to k = 10, leading to a vlawe representation of k · d = 10 · 300 = 3000 components.', 'similar to jegou et al. ( 2012 ), we set α = 0. 5 for the power normalization step in equation ( 4 ), which consistently leads to near - optimal results on all data sets.', 'in the learning stage, we employ the support vector machines ( svm ) implementation provided by libsvm  #AUTHOR_TAG table 1 : performance results ( in % ) of our approach ( vlawe ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou et al.,, 2018 on the reuters - 21578, rt - 2k, mr, trec and subj data sets.', '']",3
['methods  #TAUTHOR_TAG zhou'],['approach ( vlawe ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou'],['##e ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou'],"['the experiments, we used the pre - trained word embeddings computed with the glove toolkit provided by  #AUTHOR_TAG.', 'the pre - trained glove model contains 300 - dimensional vectors for 2. 2 million words and phrases.', 'most of the steps required for building the vlawe representation, such as the k - means clustering and the randomized forest of k - d trees, are implemented using the vlfeat library  #AUTHOR_TAG.', 'we set the number of clusters ( size of the codebook ) to k = 10, leading to a vlawe representation of k · d = 10 · 300 = 3000 components.', 'similar to jegou et al. ( 2012 ), we set α = 0. 5 for the power normalization step in equation ( 4 ), which consistently leads to near - optimal results on all data sets.', 'in the learning stage, we employ the support vector machines ( svm ) implementation provided by libsvm  #AUTHOR_TAG table 1 : performance results ( in % ) of our approach ( vlawe ) versus several state - of - the - art methods  #TAUTHOR_TAG zhou et al.,, 2018 on the reuters - 21578, rt - 2k, mr, trec and subj data sets.', '']",5
"['methods  #TAUTHOR_TAG zhou et al.,, 2018 as']","['methods  #TAUTHOR_TAG zhou et al.,, 2018 as']","['##e with several state - of - theart methods  #TAUTHOR_TAG zhou et al.,, 2018 as']","['compare vlawe with several state - of - theart methods  #TAUTHOR_TAG zhou et al.,, 2018 as well as two baseline methods, namely the average of word embeddings and the standard bag - of - words ( bow ).', 'the corresponding results are presented in table 1.', '']",4
"[')  #TAUTHOR_TAG, or']","['( rnn )  #TAUTHOR_TAG, or']","[')  #TAUTHOR_TAG, or']",[' #TAUTHOR_TAG'],0
"[' #AUTHOR_TAG, and later using rnns  #AUTHOR_TAG.', 'rnns enable generating variable - length sequences, conditioning each token on the tokens generated in previous time steps.', 'we leverage this characteristic in our approximation model ( § 4. 1 ).', 'a main challenge in applying gans for text is that generating discrete symbols is a nondifferentiable operation.', 'one solution is to perform a continuous relaxation of the gan output, which leads to generators that emit a nearly discrete continuous distribution  #TAUTHOR_TAG.', 'this keeps the model differentiable']","[' #AUTHOR_TAG, and later using rnns  #AUTHOR_TAG.', 'rnns enable generating variable - length sequences, conditioning each token on the tokens generated in previous time steps.', 'we leverage this characteristic in our approximation model ( § 4. 1 ).', 'a main challenge in applying gans for text is that generating discrete symbols is a nondifferentiable operation.', 'one solution is to perform a continuous relaxation of the gan output, which leads to generators that emit a nearly discrete continuous distribution  #TAUTHOR_TAG.', 'this keeps the model differentiable']","['the success of gans in image generation, several works applied the same idea to texts using convolutional neural networks  #AUTHOR_TAG, and later using rnns  #AUTHOR_TAG.', 'rnns enable generating variable - length sequences, conditioning each token on the tokens generated in previous time steps.', 'we leverage this characteristic in our approximation model ( § 4. 1 ).', 'a main challenge in applying gans for text is that generating discrete symbols is a nondifferentiable operation.', 'one solution is to perform a continuous relaxation of the gan output, which leads to generators that emit a nearly discrete continuous distribution  #TAUTHOR_TAG.', 'this keeps the model differentiable']","['the success of gans in image generation, several works applied the same idea to texts using convolutional neural networks  #AUTHOR_TAG, and later using rnns  #AUTHOR_TAG.', 'rnns enable generating variable - length sequences, conditioning each token on the tokens generated in previous time steps.', 'we leverage this characteristic in our approximation model ( § 4. 1 ).', 'a main challenge in applying gans for text is that generating discrete symbols is a nondifferentiable operation.', 'one solution is to perform a continuous relaxation of the gan output, which leads to generators that emit a nearly discrete continuous distribution  #TAUTHOR_TAG.', 'this keeps the model differentiable and enables end - to - end training through the discriminator.', 'alternatively, seqgan and leak - gan  #AUTHOR_TAG used policy gradient methods to overcome the differentiablity requirement.', 'we apply our approximation to both model types.', '3 evaluating gans and lms lm evaluation.', 'text generation from lms is commonly evaluated using probabilistic metrics.', 'specifically, given a test sequence of symbols ( t 1,..., t n ), and a lm q, the average crossentropy over the entire test set is computed :', 'for word - based models, the standard metric is perplexity : p p = 2 ace, while for character - based models it is bp c = ace directly.', 'intrinsic improvement in perplexity does not guarantee an improvement in an extrinsic downstream task that uses a language model.', 'however, perplexity often correlates with extrinsic measures  #AUTHOR_TAG, and is the de - facto metric for evaluating the quality of language models today']",0
['gram overlap :  #TAUTHOR_TAG : inspired'],"['been proposed :', '• n - gram overlap :  #TAUTHOR_TAG : inspired']",['gram overlap :  #TAUTHOR_TAG : inspired'],"['definition, a text gan outputs a discrete sequence of symbols rather than a probability distribution.', 'as a result, lm metrics cannot be applied to evaluate the generated text.', 'consequently, other metrics have been proposed :', '• n - gram overlap :  #TAUTHOR_TAG : inspired by bleu  #AUTHOR_TAG, this measures whether n - grams generated by the model appear in a held - out corpus.', 'a major drawback is that this metric favors conservative models that always generate very common text ( e. g., "" it is "" ).', 'to mitigate this, self - bleu has been proposed  #AUTHOR_TAG as an additional metric, where overlap is measured between two independently sampled texts from the model.', '• lm score : the probability of generated text according to a pre - trained lm.', 'this has the same problem of favoring conservative models.', '•  #AUTHOR_TAG suggested an indirect score by training a lm on gan - generated text, and evaluating it using perplexity.', 'the drawback in this setting is the coupling of the performance of the gan with that of the proxy lm.', '•  #AUTHOR_TAG used frechet infersent distance ( fid ) to compute the distance between distributions of features extracted from real and generated samples.', 'however, this approach relies on a problematic assumption that features are normally distributed.', '']",0
"['t  #TAUTHOR_TAG.', 'in contrast,']","['t  #TAUTHOR_TAG.', 'in contrast,']","['token is used at inference time as the input x t  #TAUTHOR_TAG.', 'in contrast,']","['inputs to an rnn at time step t, are the state vector h t and the current input token x t.', 'the output token ( one - hot ) is denoted by o t.', 'in rnnbased gans, the previous output token is used at inference time as the input x t  #TAUTHOR_TAG.', 'in contrast, when evaluating with bpc or perplexity, the gold token x t is given as input.', 'hence, lm - based evaluation neutralizes the problem of exposure bias addressed by gans.', 'nevertheless, this allows us to compare the quality of text produced by gans and lms on an equal footing.', 'figure 1 illustrates the difference between inference time and during lm approximation.', 'we can therefore define the generator function at time step t as a function of the initial state h 0 and the past generated tokens ( x 0...', 'x t ), which we denote as o t = g t ( h 0, x 0... x t ) ( x 0 is a start token ).', 'given a past sequence ( x 0...', 'x t ), g t is a stochastic function : the stochasticity of g t']",0
"[' #TAUTHOR_TAG, 1000 for ).', 'we']","[' #TAUTHOR_TAG, 1000 for ).', 'we']","[' #TAUTHOR_TAG, 1000 for ).', 'we chose']","['compare to prior work in lm, we follow the common setup and train on the text8 dataset.', '2 the dataset is derived from wikipedia, and includes 26 english characters plus spaces.', 'we use the standard 90 / 5 / 5 split to train / validation / test.', 'finally, we measure performance with bpc.', 'we tuned hyper - parameters on the validation set, including sequence length to generate at test time ( 7 for  #TAUTHOR_TAG, 1000 for ).', 'we chose the number of samples n empirically for each model, as described in section 4. 2.', 'we set α to 10, and the boundary to γ = 10 −3 as a good trade - off between accuracy and run - time.', 'figure 2 plots the approximate error g t, n −α −g t, n ∞ as a function of n.', 'for both models, n > 1600 satisfies this condition ( red line in figure 2 ).', 'to be safe, we used n = 2000.', ' #AUTHOR_TAG 1. 27 large rhn  #AUTHOR_TAG 1. 27 layernorm hm - lstm  #AUTHOR_TAG 1. 29 bn lstm  #AUTHOR_TAG 1. 36 unregularised mlstm  #AUTHOR_TAG 1.']",7
"['the bpc of  #TAUTHOR_TAG.', 'it is difficult to assess the quality of generation with such short sequences.', 'in table 2 we present a few randomly generated samples from']","['as adversarial training continues.', 'finally, we note that generating sequences larger than 7 characters hurts the bpc of  #TAUTHOR_TAG.', 'it is difficult to assess the quality of generation with such short sequences.', 'in table 2 we present a few randomly generated samples from']","['the bpc of  #TAUTHOR_TAG.', 'it is difficult to assess the quality of generation with such short sequences.', 'in table 2 we present a few randomly generated samples from each model.', 'we']","['', 'gan - based models perform worse than stateof - the - art lms by a large margin.', 'moreover, in seqgan, the pre - trained lm performs better than the fully trained model with approximate bpc scores of 1. 95 and 2. 06, respectively, and the bpc deteriorates as adversarial training continues.', 'finally, we note that generating sequences larger than 7 characters hurts the bpc of  #TAUTHOR_TAG.', 'it is difficult to assess the quality of generation with such short sequences.', 'in table 2 we present a few randomly generated samples from each model.', 'we indeed observe that adversarial training slightly reduces the quality of generated text for seqgan, and find that the quality of 100 - character long sequences generated from  #TAUTHOR_TAG is low']",7
"['the bpc of  #TAUTHOR_TAG.', 'it is difficult to assess the quality of generation with such short sequences.', 'in table 2 we present a few randomly generated samples from']","['as adversarial training continues.', 'finally, we note that generating sequences larger than 7 characters hurts the bpc of  #TAUTHOR_TAG.', 'it is difficult to assess the quality of generation with such short sequences.', 'in table 2 we present a few randomly generated samples from']","['the bpc of  #TAUTHOR_TAG.', 'it is difficult to assess the quality of generation with such short sequences.', 'in table 2 we present a few randomly generated samples from each model.', 'we']","['', 'gan - based models perform worse than stateof - the - art lms by a large margin.', 'moreover, in seqgan, the pre - trained lm performs better than the fully trained model with approximate bpc scores of 1. 95 and 2. 06, respectively, and the bpc deteriorates as adversarial training continues.', 'finally, we note that generating sequences larger than 7 characters hurts the bpc of  #TAUTHOR_TAG.', 'it is difficult to assess the quality of generation with such short sequences.', 'in table 2 we present a few randomly generated samples from each model.', 'we indeed observe that adversarial training slightly reduces the quality of generated text for seqgan, and find that the quality of 100 - character long sequences generated from  #TAUTHOR_TAG is low']",7
"['is based on the recently released  #TAUTHOR_TAG in the fashion domain.', 'we introduce a multimodal extension to']","['is based on the recently released  #TAUTHOR_TAG in the fashion domain.', 'we introduce a multimodal extension to']","['is based on the recently released  #TAUTHOR_TAG in the fashion domain.', 'we introduce a multimodal extension to']","['this work, we investigate the task of textual response generation in a multimodal task - oriented dialogue system.', 'our work is based on the recently released  #TAUTHOR_TAG in the fashion domain.', 'we introduce a multimodal extension to the hierarchical recurrent encoder - decoder ( hred ) model and show that this extension outperforms strong baselines in terms of text - based similarity metrics.', ""we also showcase the shortcomings of current vision and language models by performing an error analysis on our system's output""]",6
[' #TAUTHOR_TAG consists of 100 / 11 / 11k'],[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising'],[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising 3. 5m context'],"[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising 3. 5m context - response pairs for the model.', 'each session contains an average of 40 dialogue turns ( average of 8 words per textual response, 4 images per image response ).', 'the data contains complex user queries, which pose new challenges for multimodal, task - based dialogue, such as quantitative inference ( sorting, counting and filtering ) : "" show me more images of the 3rd product in some different directions "", inference using domain knowledge and long term context : "" will the 5th result go well with a large sized messenger bag? "", inference over aggregate of images : "" list more in the upper material of the 5th image and style as the 3rd and the 5th "", co - reference resolution.', 'note that we started with the raw transcripts of dialogue sessions to create our own version of  #TAUTHOR_TAG for the model.', 'this is done since  #TAUTHOR_TAG originally consider each image as a different context, while we consider all the images in a single turn as one concatenated context ( cf. figure 3 )']",6
"['output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however,']","['decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however, for']","['softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they""]","['a dialogue. for each m = 1,..., m n, we', 'have hidden states of each module defined as : where f text θ, f cxt θ and f dec θ are gru cells  #AUTHOR_TAG. θ represent model parameters, w n', ', m is the m - th word in the n - th utterance and g enc θ is a convolutional neural network ( cnn ) ; here', 'we use vggnet  #AUTHOR_TAG. we pass multiple images in a context through the cnn in order to get encoded image representations g enc θ ( img k', '). then these are combined together and passed through a linear layer l img to get the aggregated', 'image representation for one turn of context, denoted by h are subsequently concatenated and passed as input to the context rnn. h cx', '##t n, the final hidden state of the context rnn, acts as the initial hidden state of the decoder rnn. finally', ', output is generated by passing h dec n, m through an affine transformation followed by a softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they'unroll'multiple images in a single utterance to include only one image"", 'per utterance', '. while computationally leaner, this approach ultimately loses the objective of capturing multimodality over the context of multiple images and text. in contrast, we combine all the image representations in the utterance using a linear', 'layer. we argue that modelling all images is necessary to answer questions that address previous agent', 'responses. for example in figure 3, when the user asks "" what about the 4', '##th image? "", it is impossible to give a correct response without reasoning over all images in the previous response. in the following, we empirically show that our extension leads', 'to better results in terms of text - based similarity measures, as well as quality of generated dialogues. example contexts for a', 'given system utterance ; note the difference in our approach from', ' #TAUTHOR_TAG when extracting the training data from the original chat logs. for', ""simplicity, in this illustration we consider a context size of 2 previous utterances.'|'differentiates turns for a"", 'given context. we concatenate the representation vector of all images in one turn of a dialogue to', 'form the image context. if there is no image in the utterance, we consider a 0 4096 vector to form the image context. in this work, we focus only on the textual response of the agent']",5
"['l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","[' #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","['l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","['report sentence - level bleu - 4  #AUTHOR_TAG, meteor  #AUTHOR_TAG and rouge - l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG are on a different version of the corpus, hence not directly comparable.', 'table 1 provides results for different configurations of our model ( "" t "" stands for text - only in the encoder, "" m "" for multimodal, and "" attn "" for using attention in the decoder ).', 'we experimented with different context sizes and found that output quality improved with increased context size ( models with 5 - turn context perform better than those with a 2 - turn context ), confirming the observation by  #AUTHOR_TAG serban et al. (, 2017.', '5 using attention clearly helps : even t - hred - attn outperforms m - hred ( without attention ) for the same context size.', 'we also tested whether multimodal input has an impact on the generated outputs.', 'however, there was only a slight increase in bleu score ( m - hred - attn vs t - hred - attn ).', 'to summarize, our best performing model ( m - hred - attn ) outperforms the model of  #TAUTHOR_TAG by 7 bleu points.', '6 this can be primarily attributed to the way we created the input for our model from raw chat logs, as well as incorporating more information during decoding via attention.', 'figure 4 provides example output utterances using m - hred - attn with a context size of 5.', 'our model is able to accurately map the response to previous textual context turns as shown in ( a ) and ( c ).', 'in ( c ), it is able to capture that the user is asking about the style in the 1st and 2nd image.', ""( d ) shows an example where our model is able to relate that the corresponding product is'jeans'from visual features, while it is not able to model finegrained details like in ( b ) that the style is'casual fit'but resorts to'woven '""]",5
"['output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however,']","['decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however, for']","['softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they""]","['a dialogue. for each m = 1,..., m n, we', 'have hidden states of each module defined as : where f text θ, f cxt θ and f dec θ are gru cells  #AUTHOR_TAG. θ represent model parameters, w n', ', m is the m - th word in the n - th utterance and g enc θ is a convolutional neural network ( cnn ) ; here', 'we use vggnet  #AUTHOR_TAG. we pass multiple images in a context through the cnn in order to get encoded image representations g enc θ ( img k', '). then these are combined together and passed through a linear layer l img to get the aggregated', 'image representation for one turn of context, denoted by h are subsequently concatenated and passed as input to the context rnn. h cx', '##t n, the final hidden state of the context rnn, acts as the initial hidden state of the decoder rnn. finally', ', output is generated by passing h dec n, m through an affine transformation followed by a softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they'unroll'multiple images in a single utterance to include only one image"", 'per utterance', '. while computationally leaner, this approach ultimately loses the objective of capturing multimodality over the context of multiple images and text. in contrast, we combine all the image representations in the utterance using a linear', 'layer. we argue that modelling all images is necessary to answer questions that address previous agent', 'responses. for example in figure 3, when the user asks "" what about the 4', '##th image? "", it is impossible to give a correct response without reasoning over all images in the previous response. in the following, we empirically show that our extension leads', 'to better results in terms of text - based similarity measures, as well as quality of generated dialogues. example contexts for a', 'given system utterance ; note the difference in our approach from', ' #TAUTHOR_TAG when extracting the training data from the original chat logs. for', ""simplicity, in this illustration we consider a context size of 2 previous utterances.'|'differentiates turns for a"", 'given context. we concatenate the representation vector of all images in one turn of a dialogue to', 'form the image context. if there is no image in the utterance, we consider a 0 4096 vector to form the image context. in this work, we focus only on the textual response of the agent']",0
"['output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however,']","['decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however, for']","['softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they""]","['a dialogue. for each m = 1,..., m n, we', 'have hidden states of each module defined as : where f text θ, f cxt θ and f dec θ are gru cells  #AUTHOR_TAG. θ represent model parameters, w n', ', m is the m - th word in the n - th utterance and g enc θ is a convolutional neural network ( cnn ) ; here', 'we use vggnet  #AUTHOR_TAG. we pass multiple images in a context through the cnn in order to get encoded image representations g enc θ ( img k', '). then these are combined together and passed through a linear layer l img to get the aggregated', 'image representation for one turn of context, denoted by h are subsequently concatenated and passed as input to the context rnn. h cx', '##t n, the final hidden state of the context rnn, acts as the initial hidden state of the decoder rnn. finally', ', output is generated by passing h dec n, m through an affine transformation followed by a softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they'unroll'multiple images in a single utterance to include only one image"", 'per utterance', '. while computationally leaner, this approach ultimately loses the objective of capturing multimodality over the context of multiple images and text. in contrast, we combine all the image representations in the utterance using a linear', 'layer. we argue that modelling all images is necessary to answer questions that address previous agent', 'responses. for example in figure 3, when the user asks "" what about the 4', '##th image? "", it is impossible to give a correct response without reasoning over all images in the previous response. in the following, we empirically show that our extension leads', 'to better results in terms of text - based similarity measures, as well as quality of generated dialogues. example contexts for a', 'given system utterance ; note the difference in our approach from', ' #TAUTHOR_TAG when extracting the training data from the original chat logs. for', ""simplicity, in this illustration we consider a context size of 2 previous utterances.'|'differentiates turns for a"", 'given context. we concatenate the representation vector of all images in one turn of a dialogue to', 'form the image context. if there is no image in the utterance, we consider a 0 4096 vector to form the image context. in this work, we focus only on the textual response of the agent']",0
"['output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however,']","['decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however, for']","['softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they""]","['a dialogue. for each m = 1,..., m n, we', 'have hidden states of each module defined as : where f text θ, f cxt θ and f dec θ are gru cells  #AUTHOR_TAG. θ represent model parameters, w n', ', m is the m - th word in the n - th utterance and g enc θ is a convolutional neural network ( cnn ) ; here', 'we use vggnet  #AUTHOR_TAG. we pass multiple images in a context through the cnn in order to get encoded image representations g enc θ ( img k', '). then these are combined together and passed through a linear layer l img to get the aggregated', 'image representation for one turn of context, denoted by h are subsequently concatenated and passed as input to the context rnn. h cx', '##t n, the final hidden state of the context rnn, acts as the initial hidden state of the decoder rnn. finally', ', output is generated by passing h dec n, m through an affine transformation followed by a softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they'unroll'multiple images in a single utterance to include only one image"", 'per utterance', '. while computationally leaner, this approach ultimately loses the objective of capturing multimodality over the context of multiple images and text. in contrast, we combine all the image representations in the utterance using a linear', 'layer. we argue that modelling all images is necessary to answer questions that address previous agent', 'responses. for example in figure 3, when the user asks "" what about the 4', '##th image? "", it is impossible to give a correct response without reasoning over all images in the previous response. in the following, we empirically show that our extension leads', 'to better results in terms of text - based similarity measures, as well as quality of generated dialogues. example contexts for a', 'given system utterance ; note the difference in our approach from', ' #TAUTHOR_TAG when extracting the training data from the original chat logs. for', ""simplicity, in this illustration we consider a context size of 2 previous utterances.'|'differentiates turns for a"", 'given context. we concatenate the representation vector of all images in one turn of a dialogue to', 'form the image context. if there is no image in the utterance, we consider a 0 4096 vector to form the image context. in this work, we focus only on the textual response of the agent']",0
[' #TAUTHOR_TAG consists of 100 / 11 / 11k'],[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising'],[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising 3. 5m context'],"[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising 3. 5m context - response pairs for the model.', 'each session contains an average of 40 dialogue turns ( average of 8 words per textual response, 4 images per image response ).', 'the data contains complex user queries, which pose new challenges for multimodal, task - based dialogue, such as quantitative inference ( sorting, counting and filtering ) : "" show me more images of the 3rd product in some different directions "", inference using domain knowledge and long term context : "" will the 5th result go well with a large sized messenger bag? "", inference over aggregate of images : "" list more in the upper material of the 5th image and style as the 3rd and the 5th "", co - reference resolution.', 'note that we started with the raw transcripts of dialogue sessions to create our own version of  #TAUTHOR_TAG for the model.', 'this is done since  #TAUTHOR_TAG originally consider each image as a different context, while we consider all the images in a single turn as one concatenated context ( cf. figure 3 )']",0
"['output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however,']","['decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however, for']","['softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they""]","['a dialogue. for each m = 1,..., m n, we', 'have hidden states of each module defined as : where f text θ, f cxt θ and f dec θ are gru cells  #AUTHOR_TAG. θ represent model parameters, w n', ', m is the m - th word in the n - th utterance and g enc θ is a convolutional neural network ( cnn ) ; here', 'we use vggnet  #AUTHOR_TAG. we pass multiple images in a context through the cnn in order to get encoded image representations g enc θ ( img k', '). then these are combined together and passed through a linear layer l img to get the aggregated', 'image representation for one turn of context, denoted by h are subsequently concatenated and passed as input to the context rnn. h cx', '##t n, the final hidden state of the context rnn, acts as the initial hidden state of the decoder rnn. finally', ', output is generated by passing h dec n, m through an affine transformation followed by a softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they'unroll'multiple images in a single utterance to include only one image"", 'per utterance', '. while computationally leaner, this approach ultimately loses the objective of capturing multimodality over the context of multiple images and text. in contrast, we combine all the image representations in the utterance using a linear', 'layer. we argue that modelling all images is necessary to answer questions that address previous agent', 'responses. for example in figure 3, when the user asks "" what about the 4', '##th image? "", it is impossible to give a correct response without reasoning over all images in the previous response. in the following, we empirically show that our extension leads', 'to better results in terms of text - based similarity measures, as well as quality of generated dialogues. example contexts for a', 'given system utterance ; note the difference in our approach from', ' #TAUTHOR_TAG when extracting the training data from the original chat logs. for', ""simplicity, in this illustration we consider a context size of 2 previous utterances.'|'differentiates turns for a"", 'given context. we concatenate the representation vector of all images in one turn of a dialogue to', 'form the image context. if there is no image in the utterance, we consider a 0 4096 vector to form the image context. in this work, we focus only on the textual response of the agent']",3
"['output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however,']","['decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', '##eds to include the visual modality. however, for']","['softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they""]","['a dialogue. for each m = 1,..., m n, we', 'have hidden states of each module defined as : where f text θ, f cxt θ and f dec θ are gru cells  #AUTHOR_TAG. θ represent model parameters, w n', ', m is the m - th word in the n - th utterance and g enc θ is a convolutional neural network ( cnn ) ; here', 'we use vggnet  #AUTHOR_TAG. we pass multiple images in a context through the cnn in order to get encoded image representations g enc θ ( img k', '). then these are combined together and passed through a linear layer l img to get the aggregated', 'image representation for one turn of context, denoted by h are subsequently concatenated and passed as input to the context rnn. h cx', '##t n, the final hidden state of the context rnn, acts as the initial hidden state of the decoder rnn. finally', ', output is generated by passing h dec n, m through an affine transformation followed by a softmax activation. the model is trained using cross entropy on next - word prediction', '. during generation, the decoder conditions on the previous output token.  #TAUTHOR_TAG dataset, extending hr', ""##eds to include the visual modality. however, for simplicity's sake, they'unroll'multiple images in a single utterance to include only one image"", 'per utterance', '. while computationally leaner, this approach ultimately loses the objective of capturing multimodality over the context of multiple images and text. in contrast, we combine all the image representations in the utterance using a linear', 'layer. we argue that modelling all images is necessary to answer questions that address previous agent', 'responses. for example in figure 3, when the user asks "" what about the 4', '##th image? "", it is impossible to give a correct response without reasoning over all images in the previous response. in the following, we empirically show that our extension leads', 'to better results in terms of text - based similarity measures, as well as quality of generated dialogues. example contexts for a', 'given system utterance ; note the difference in our approach from', ' #TAUTHOR_TAG when extracting the training data from the original chat logs. for', ""simplicity, in this illustration we consider a context size of 2 previous utterances.'|'differentiates turns for a"", 'given context. we concatenate the representation vector of all images in one turn of a dialogue to', 'form the image context. if there is no image in the utterance, we consider a 0 4096 vector to form the image context. in this work, we focus only on the textual response of the agent']",4
[' #TAUTHOR_TAG consists of 100 / 11 / 11k'],[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising'],[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising 3. 5m context'],"[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising 3. 5m context - response pairs for the model.', 'each session contains an average of 40 dialogue turns ( average of 8 words per textual response, 4 images per image response ).', 'the data contains complex user queries, which pose new challenges for multimodal, task - based dialogue, such as quantitative inference ( sorting, counting and filtering ) : "" show me more images of the 3rd product in some different directions "", inference using domain knowledge and long term context : "" will the 5th result go well with a large sized messenger bag? "", inference over aggregate of images : "" list more in the upper material of the 5th image and style as the 3rd and the 5th "", co - reference resolution.', 'note that we started with the raw transcripts of dialogue sessions to create our own version of  #TAUTHOR_TAG for the model.', 'this is done since  #TAUTHOR_TAG originally consider each image as a different context, while we consider all the images in a single turn as one concatenated context ( cf. figure 3 )']",4
"['l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","[' #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","['l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","['report sentence - level bleu - 4  #AUTHOR_TAG, meteor  #AUTHOR_TAG and rouge - l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG are on a different version of the corpus, hence not directly comparable.', 'table 1 provides results for different configurations of our model ( "" t "" stands for text - only in the encoder, "" m "" for multimodal, and "" attn "" for using attention in the decoder ).', 'we experimented with different context sizes and found that output quality improved with increased context size ( models with 5 - turn context perform better than those with a 2 - turn context ), confirming the observation by  #AUTHOR_TAG serban et al. (, 2017.', '5 using attention clearly helps : even t - hred - attn outperforms m - hred ( without attention ) for the same context size.', 'we also tested whether multimodal input has an impact on the generated outputs.', 'however, there was only a slight increase in bleu score ( m - hred - attn vs t - hred - attn ).', 'to summarize, our best performing model ( m - hred - attn ) outperforms the model of  #TAUTHOR_TAG by 7 bleu points.', '6 this can be primarily attributed to the way we created the input for our model from raw chat logs, as well as incorporating more information during decoding via attention.', 'figure 4 provides example output utterances using m - hred - attn with a context size of 5.', 'our model is able to accurately map the response to previous textual context turns as shown in ( a ) and ( c ).', 'in ( c ), it is able to capture that the user is asking about the style in the 1st and 2nd image.', ""( d ) shows an example where our model is able to relate that the corresponding product is'jeans'from visual features, while it is not able to model finegrained details like in ( b ) that the style is'casual fit'but resorts to'woven '""]",4
"['l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","[' #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","['l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG']","['report sentence - level bleu - 4  #AUTHOR_TAG, meteor  #AUTHOR_TAG and rouge - l  #AUTHOR_TAG using the evaluation scripts provided by  #AUTHOR_TAG.', 'we compare our results against  #TAUTHOR_TAG and data - generation scripts.', '4 note that the results reported in  #TAUTHOR_TAG are on a different version of the corpus, hence not directly comparable.', 'table 1 provides results for different configurations of our model ( "" t "" stands for text - only in the encoder, "" m "" for multimodal, and "" attn "" for using attention in the decoder ).', 'we experimented with different context sizes and found that output quality improved with increased context size ( models with 5 - turn context perform better than those with a 2 - turn context ), confirming the observation by  #AUTHOR_TAG serban et al. (, 2017.', '5 using attention clearly helps : even t - hred - attn outperforms m - hred ( without attention ) for the same context size.', 'we also tested whether multimodal input has an impact on the generated outputs.', 'however, there was only a slight increase in bleu score ( m - hred - attn vs t - hred - attn ).', 'to summarize, our best performing model ( m - hred - attn ) outperforms the model of  #TAUTHOR_TAG by 7 bleu points.', '6 this can be primarily attributed to the way we created the input for our model from raw chat logs, as well as incorporating more information during decoding via attention.', 'figure 4 provides example output utterances using m - hred - attn with a context size of 5.', 'our model is able to accurately map the response to previous textual context turns as shown in ( a ) and ( c ).', 'in ( c ), it is able to capture that the user is asking about the style in the 1st and 2nd image.', ""( d ) shows an example where our model is able to relate that the corresponding product is'jeans'from visual features, while it is not able to model finegrained details like in ( b ) that the style is'casual fit'but resorts to'woven '""]",4
"['multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to the hierarchical recurrent encoder - decoder ( hred ) model  #AUTHOR_TAG and show that our implementation significantly outperforms the model of  #TAUTHOR_TAG by modelling the full multimodal context.', 'contrary to  #TAUTHOR_TAG, our generation outputs improved by adding attention and increasing context size.', 'however, we also show that multimodal hred does not improve significantly over text - only hred, similar to observations by  #AUTHOR_TAG and  #AUTHOR_TAG.', 'our model learns to handle textual correspondence between the questions and answers, while mostly ignoring the visual context.', 'this indicates that we need better visual models to en - code the image representations when he have multiple similar - looking images, e. g., black hats in figure 3.', 'we believe that the results should improve with a jointly trained or fine - tuned cnn for generating the image representations, which we plan to implement in future work']",4
"['multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to the hierarchical recurrent encoder - decoder ( hred ) model  #AUTHOR_TAG and show that our implementation significantly outperforms the model of  #TAUTHOR_TAG by modelling the full multimodal context.', 'contrary to  #TAUTHOR_TAG, our generation outputs improved by adding attention and increasing context size.', 'however, we also show that multimodal hred does not improve significantly over text - only hred, similar to observations by  #AUTHOR_TAG and  #AUTHOR_TAG.', 'our model learns to handle textual correspondence between the questions and answers, while mostly ignoring the visual context.', 'this indicates that we need better visual models to en - code the image representations when he have multiple similar - looking images, e. g., black hats in figure 3.', 'we believe that the results should improve with a jointly trained or fine - tuned cnn for generating the image representations, which we plan to implement in future work']",4
[' #TAUTHOR_TAG consists of 100 / 11 / 11k'],[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising'],[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising 3. 5m context'],"[' #TAUTHOR_TAG consists of 100 / 11 / 11k train / validation / test chat sessions comprising 3. 5m context - response pairs for the model.', 'each session contains an average of 40 dialogue turns ( average of 8 words per textual response, 4 images per image response ).', 'the data contains complex user queries, which pose new challenges for multimodal, task - based dialogue, such as quantitative inference ( sorting, counting and filtering ) : "" show me more images of the 3rd product in some different directions "", inference using domain knowledge and long term context : "" will the 5th result go well with a large sized messenger bag? "", inference over aggregate of images : "" list more in the upper material of the 5th image and style as the 3rd and the 5th "", co - reference resolution.', 'note that we started with the raw transcripts of dialogue sessions to create our own version of  #TAUTHOR_TAG for the model.', 'this is done since  #TAUTHOR_TAG originally consider each image as a different context, while we consider all the images in a single turn as one concatenated context ( cf. figure 3 )']",1
"['multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to']","['this research, we address the novel task of response generation in search - based multimodal dialogue by learning from the recently released  #TAUTHOR_TAG.', 'we introduce a novel extension to the hierarchical recurrent encoder - decoder ( hred ) model  #AUTHOR_TAG and show that our implementation significantly outperforms the model of  #TAUTHOR_TAG by modelling the full multimodal context.', 'contrary to  #TAUTHOR_TAG, our generation outputs improved by adding attention and increasing context size.', 'however, we also show that multimodal hred does not improve significantly over text - only hred, similar to observations by  #AUTHOR_TAG and  #AUTHOR_TAG.', 'our model learns to handle textual correspondence between the questions and answers, while mostly ignoring the visual context.', 'this indicates that we need better visual models to en - code the image representations when he have multiple similar - looking images, e. g., black hats in figure 3.', 'we believe that the results should improve with a jointly trained or fine - tuned cnn for generating the image representations, which we plan to implement in future work']",1
"['increase trust ; 2 ) explaining plans [ 2, 13 ] ; 3 ) verbalising robot [ 12 ] or agent rationalisation  #TAUTHOR_TAG.', 'however, humans']","['increase trust ; 2 ) explaining plans [ 2, 13 ] ; 3 ) verbalising robot [ 12 ] or agent rationalisation  #TAUTHOR_TAG.', 'however, humans']","['11 ] who showed that they can increase trust ; 2 ) explaining plans [ 2, 13 ] ; 3 ) verbalising robot [ 12 ] or agent rationalisation  #TAUTHOR_TAG.', 'however, humans']","['systems ( axv ) now routinely operate in regions that are dangerous or impossible for humans to reach, such as the deep underwater environment.', 'typically, remote robots instil less trust than those co - located [ 1, 6 ].', 'this combined with high vulnerability in hazardous, high - stakes environments, such as that described in [ 7 ], means that the interface between operator and axv is key in maintaining situation awareness and understanding.', 'specifically, axvs need to be able to maintain a continuous communication with regards to what they are doing ; and increase transparency through explaining their actions and behaviours.', 'explanations can help formulate clear and accurate mental models of autonomous systems and robots.', 'mental models, in cognitive theory, provide one view on how humans reason either functionally ( understanding what the robot does ) or structurally ( understanding how it works ).', 'mental models are important as they strongly impact how and whether robots and systems are used.', 'in previous work, explanations have been categorised as either explaining 1 ) machine learning as in [ 11 ] who showed that they can increase trust ; 2 ) explaining plans [ 2, 13 ] ; 3 ) verbalising robot [ 12 ] or agent rationalisation  #TAUTHOR_TAG.', 'however, humans do not present a constant verbalisation of their actions but they do need to be able to provide information on - demand about what they are doing and why during a live mission.', 'we present here, miriam, ( multimodal intelligent interaction for autonomous systems ), as seen in figure 1.', ""miriam allows for these'on - demand'queries for status and explanations of behaviour."", 'miriam interfaces with the neptune autonomy software provided by seebyte ltd and runs alongside their seetrack interface.', 'in this paper, we focus on explanations of behaviours and describe a method that is agnostic to the type of autonomy method.', 'with respect to providing communication for monitoring, please refer to [ 5 ] for further details and an overview of the system']",0
"['of deep neural models for game play  #TAUTHOR_TAG.', 'an interpretable model of autonomy was then']","['of deep neural models for game play  #TAUTHOR_TAG.', 'an interpretable model of autonomy was then']","['of deep neural models for game play  #TAUTHOR_TAG.', 'an interpretable model of autonomy was then']","[""of explanations include why to provide a trace or reasoning and why not to elaborate on the system's control method or strategy [ 4 ]."", ' #AUTHOR_TAG [ 10 ] show that both why and why not explanations increase understanding but only why increases trust.', ""we adopt here the'speak - aloud'method whereby an expert provides rationalisation of the axv behaviours while watching videos of missions on the seetrack software."", 'this has the advantage of being agnostic to the method of autonomy and could be used to describe rule - based autonomous behaviours but also complex deep models.', 'similar human - provided rationalisation has been used to generate explanations of deep neural models for game play  #TAUTHOR_TAG.', 'an interpretable model of autonomy was then derived from the expert, as partially shown in figure 2.', 'if a why request is made, the decision tree is checked against the current mission status and history and the possible reasons are determined, along with a probability.', 'as we can see from example outputs in figure 3a, there may be multiple reasons with varying levels of certainty depending on the information available at a given point in the mission.', '']",0
"['', 'the peerread dataset  #TAUTHOR_TAG is an excellent']","['forms with objective questionnaires, etc.', 'gaining momentum.', 'the peerread dataset  #TAUTHOR_TAG is an excellent']","['##s 2, author response periods / rebuttals, increased effective communications between authors and reviewers, open access initiatives, peer review workshops, review forms with objective questionnaires, etc.', 'gaining momentum.', 'the peerread dataset  #TAUTHOR_TAG is an excellent resource towards research and study on this very']","['', 'moreover, even a preliminary study into the inners of the peer review system is itself very difficult because of data confidentiality and copyright issues of the publishers.', 'however, the silver lining is that the peer review system is evolving with the likes of openreviews 2, author response periods / rebuttals, increased effective communications between authors and reviewers, open access initiatives, peer review workshops, review forms with objective questionnaires, etc.', 'gaining momentum.', 'the peerread dataset  #TAUTHOR_TAG is an excellent resource towards research and study on this very impactful and crucial problem.', 'with our ongoing effort towards the development of an artificial intelligence ( ai ) - assisted peer review system, we are intrigued with : what if there is an additional ai reviewer which predicts decisions by learning the high - level interplay between the review texts and the papers? how would the sentiment embedded within the review texts empower such decision - making?', 'although editors / program chairs usually go by the majority of the reviewer recommendations, they still need to go through all the review texts corresponding to all the submissions.', 'a good use case of this research would be : slot -']",0
['to  #TAUTHOR_TAG'],['to  #TAUTHOR_TAG'],"['to  #TAUTHOR_TAG.', 'we further use the submissions of']","['peerread dataset consists of papers, a set of associated peer reviews, and corresponding accept / reject decisions with aspect specific scores of papers collected from several top - tier artificial intelligence ( ai ), natural language processing ( nlp ) and machine learning ( ml ) conferences.', 'table 1 shows the data we consider in our experiments.', 'we could not consider nips and arxiv portions of peerread due to the lack of aspect scores and reviews, respectively.', 'for more details on the dataset creation and the task, we request the readers to refer to  #TAUTHOR_TAG.', 'we further use the submissions of iclr 2018, corresponding reviews and aspect scores to boost our training set for the decision prediction task.', 'one motivation of our work stems from the finding that aspect scores for certain factors like impact, originality, soundness / correctness which are seemingly central to the merit of the paper, often have very low correlation with the final recommendation made by the reviewers as is made evident in  #TAUTHOR_TAG.', ""however, from the heatmap in figure 1 we can see that the reviewer's sentiments ( compound / positive ) embedded within the review texts have visible correlations with the aspects like recommendation, appropriateness and overall decision."", 'this also seconds our recent finding that determining the scope or appropriateness of an article to a venue is the first essential step in peer review  #AUTHOR_TAG a ).', 'since our study aims at deciding the fate of the paper, we take predicting recommendation score and overall decision as the objectives of our investigation.', 'thus our proposal to augment sentiment of reviews to the deep neural architecture seems intuitive']",0
"['##read dataset  #TAUTHOR_TAG.', 'study towards automated']","['peerread dataset  #TAUTHOR_TAG.', 'study towards automated']","['##read dataset  #TAUTHOR_TAG.', 'study towards automated']","['intelligence in academic peer review is an important yet less explored territory.', 'however, with the recent progress in ai research, the topic is gradually gaining attention from the community.', ' #AUTHOR_TAG did a thorough study of the various means of computational support to the peer review system.', ' #AUTHOR_TAG explored an evolutionary algorithm to improve editorial strategies in peer review.', 'the famous toronto paper matching system  #AUTHOR_TAG was developed to match paper with reviewers.', 'recently we  #AUTHOR_TAG b, a ) investigated the impact of various features in the editorial pre - screening process.', ' #AUTHOR_TAG explored a multi - instance learning framework for sentiment analysis from the peer review texts.', 'we carry our current investigations on a portion of the recently released peerread dataset  #TAUTHOR_TAG.', 'study towards automated support for peer review was otherwise not possible due to the lack of rejected paper instances and corresponding reviews.', 'our approach achieves significant performance improvement over the two tasks defined in  #TAUTHOR_TAG.', 'we attribute this to the use of deep neural networks and augmentation of review sentiment information in our architecture']",5
"[' #TAUTHOR_TAG, rmse→']","[' #TAUTHOR_TAG, rmse→root mean squared error.', 'cnn variant as in  #TAUTHOR_TAG is used as the comparing system.', 'representation as', 'where θ predict represents the parameters']","[' #TAUTHOR_TAG, rmse→root mean squared error.', 'cnn variant as in  #TAUTHOR_TAG is used as the comparing system.', 'representation as', 'where θ predict represents the parameters']",[' #TAUTHOR_TAG'],5
"[' #TAUTHOR_TAG, rmse→']","[' #TAUTHOR_TAG, rmse→root mean squared error.', 'cnn variant as in  #TAUTHOR_TAG is used as the comparing system.', 'representation as', 'where θ predict represents the parameters']","[' #TAUTHOR_TAG, rmse→root mean squared error.', 'cnn variant as in  #TAUTHOR_TAG is used as the comparing system.', 'representation as', 'where θ predict represents the parameters']",[' #TAUTHOR_TAG'],5
"['( classification ).', 'to compare with  #TAUTHOR_TAG,']","['( classification ).', 'to compare with  #TAUTHOR_TAG,']","[') and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup (']","['we mention earlier, we undertake two tasks : task 1 : predicting the overall recommendation score ( regression ) and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup ( train vs test ratio ) identical and re - implement their codes to generate the comparing figures.', 'however,  #TAUTHOR_TAG performed task 2 on iclr 2017 dataset with handcrafted features, and task 1 in a deep learning setting.', 'since our approach is a deep neural network based, we crawl additional paper + reviews from iclr 2018 to boost the training set.', 'for task 1, n 1 is 666 and n 2 is 98 while for task 2, n 1 is 1494 and n 2 is 525.', 'we employ a grid search for hyperparameter optimization.', 'for task 1, f is 256, l is 5. relu is the non - linear function g ( ), learning rate is 0. 007.', 'we train the model with sgd optimizer, set momentum as 0. 9  #TAUTHOR_TAG is feature - based and considers only paper, and not the reviews.', 'and batch size as 32.', 'we keep dropout at 0. 5.', '']",5
"['( classification ).', 'to compare with  #TAUTHOR_TAG,']","['( classification ).', 'to compare with  #TAUTHOR_TAG,']","[') and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup (']","['we mention earlier, we undertake two tasks : task 1 : predicting the overall recommendation score ( regression ) and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup ( train vs test ratio ) identical and re - implement their codes to generate the comparing figures.', 'however,  #TAUTHOR_TAG performed task 2 on iclr 2017 dataset with handcrafted features, and task 1 in a deep learning setting.', 'since our approach is a deep neural network based, we crawl additional paper + reviews from iclr 2018 to boost the training set.', 'for task 1, n 1 is 666 and n 2 is 98 while for task 2, n 1 is 1494 and n 2 is 525.', 'we employ a grid search for hyperparameter optimization.', 'for task 1, f is 256, l is 5. relu is the non - linear function g ( ), learning rate is 0. 007.', 'we train the model with sgd optimizer, set momentum as 0. 9  #TAUTHOR_TAG is feature - based and considers only paper, and not the reviews.', 'and batch size as 32.', 'we keep dropout at 0. 5.', '']",5
"['##read dataset  #TAUTHOR_TAG.', 'study towards automated']","['peerread dataset  #TAUTHOR_TAG.', 'study towards automated']","['##read dataset  #TAUTHOR_TAG.', 'study towards automated']","['intelligence in academic peer review is an important yet less explored territory.', 'however, with the recent progress in ai research, the topic is gradually gaining attention from the community.', ' #AUTHOR_TAG did a thorough study of the various means of computational support to the peer review system.', ' #AUTHOR_TAG explored an evolutionary algorithm to improve editorial strategies in peer review.', 'the famous toronto paper matching system  #AUTHOR_TAG was developed to match paper with reviewers.', 'recently we  #AUTHOR_TAG b, a ) investigated the impact of various features in the editorial pre - screening process.', ' #AUTHOR_TAG explored a multi - instance learning framework for sentiment analysis from the peer review texts.', 'we carry our current investigations on a portion of the recently released peerread dataset  #TAUTHOR_TAG.', 'study towards automated support for peer review was otherwise not possible due to the lack of rejected paper instances and corresponding reviews.', 'our approach achieves significant performance improvement over the two tasks defined in  #TAUTHOR_TAG.', 'we attribute this to the use of deep neural networks and augmentation of review sentiment information in our architecture']",4
"['( classification ).', 'to compare with  #TAUTHOR_TAG,']","['( classification ).', 'to compare with  #TAUTHOR_TAG,']","[') and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup (']","['we mention earlier, we undertake two tasks : task 1 : predicting the overall recommendation score ( regression ) and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup ( train vs test ratio ) identical and re - implement their codes to generate the comparing figures.', 'however,  #TAUTHOR_TAG performed task 2 on iclr 2017 dataset with handcrafted features, and task 1 in a deep learning setting.', 'since our approach is a deep neural network based, we crawl additional paper + reviews from iclr 2018 to boost the training set.', 'for task 1, n 1 is 666 and n 2 is 98 while for task 2, n 1 is 1494 and n 2 is 525.', 'we employ a grid search for hyperparameter optimization.', 'for task 1, f is 256, l is 5. relu is the non - linear function g ( ), learning rate is 0. 007.', 'we train the model with sgd optimizer, set momentum as 0. 9  #TAUTHOR_TAG is feature - based and considers only paper, and not the reviews.', 'and batch size as 32.', 'we keep dropout at 0. 5.', '']",4
"['( classification ).', 'to compare with  #TAUTHOR_TAG,']","['( classification ).', 'to compare with  #TAUTHOR_TAG,']","[') and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup (']","['we mention earlier, we undertake two tasks : task 1 : predicting the overall recommendation score ( regression ) and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup ( train vs test ratio ) identical and re - implement their codes to generate the comparing figures.', 'however,  #TAUTHOR_TAG performed task 2 on iclr 2017 dataset with handcrafted features, and task 1 in a deep learning setting.', 'since our approach is a deep neural network based, we crawl additional paper + reviews from iclr 2018 to boost the training set.', 'for task 1, n 1 is 666 and n 2 is 98 while for task 2, n 1 is 1494 and n 2 is 525.', 'we employ a grid search for hyperparameter optimization.', 'for task 1, f is 256, l is 5. relu is the non - linear function g ( ), learning rate is 0. 007.', 'we train the model with sgd optimizer, set momentum as 0. 9  #TAUTHOR_TAG is feature - based and considers only paper, and not the reviews.', 'and batch size as 32.', 'we keep dropout at 0. 5.', '']",4
['handcrafted feature - based system by  #TAUTHOR_TAG performs inferior compared to'],['handcrafted feature - based system by  #TAUTHOR_TAG performs inferior compared to'],['handcrafted feature - based system by  #TAUTHOR_TAG performs inferior compared to'],"['task 2, we observe that the handcrafted feature - based system by  #TAUTHOR_TAG performs inferior compared to the baselines.', 'this is because the features were very naive and did not 4 https : / / github. com / aritzzz / deepsentipeer address the complexity involved in such a task.', 'we perform better with a relative improvement of 28 % in terms of accuracy, and also our system is end - toend trained.', 'presumably, to some extent, our deep neural network learned to distinguish between the probable accept versus probable reject by extracting useful information from the paper and review data']",4
"['reported in  #TAUTHOR_TAG relies on elementary handcrafted features extracted only from the paper ; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture.', 'however, we also find that our']","['reported in  #TAUTHOR_TAG relies on elementary handcrafted features extracted only from the paper ; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture.', 'however, we also find that our']","['the work reported in  #TAUTHOR_TAG relies on elementary handcrafted features extracted only from the paper ; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture.', 'however, we also find that our']","['', 'the reason is that the work reported in  #TAUTHOR_TAG relies on elementary handcrafted features extracted only from the paper ; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture.', 'however, we also find that our approach with only review + sentiment performs inferior to the paper + review method in  #TAUTHOR_TAG for acl 2017.', 'this again seconds that inclusion of paper is vital in recommendation decisions.', 'only paper is enough for a human reviewer, but with the current state of ai, an ai reviewer would need the supervision of her human counterparts to arrive at a recommendation.', 'so our system is suited to cases where the editor needs an additional judgment regarding a submission ( such as dealing with missing / non - responding reviewers, an added layer of confidence with an ai which is aware of the past acceptances / rejections of a specific venue )']",4
"['reported in  #TAUTHOR_TAG relies on elementary handcrafted features extracted only from the paper ; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture.', 'however, we also find that our']","['reported in  #TAUTHOR_TAG relies on elementary handcrafted features extracted only from the paper ; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture.', 'however, we also find that our']","['the work reported in  #TAUTHOR_TAG relies on elementary handcrafted features extracted only from the paper ; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture.', 'however, we also find that our']","['', 'the reason is that the work reported in  #TAUTHOR_TAG relies on elementary handcrafted features extracted only from the paper ; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture.', 'however, we also find that our approach with only review + sentiment performs inferior to the paper + review method in  #TAUTHOR_TAG for acl 2017.', 'this again seconds that inclusion of paper is vital in recommendation decisions.', 'only paper is enough for a human reviewer, but with the current state of ai, an ai reviewer would need the supervision of her human counterparts to arrive at a recommendation.', 'so our system is suited to cases where the editor needs an additional judgment regarding a submission ( such as dealing with missing / non - responding reviewers, an added layer of confidence with an ai which is aware of the past acceptances / rejections of a specific venue )']",4
['to  #TAUTHOR_TAG'],['to  #TAUTHOR_TAG'],"['to  #TAUTHOR_TAG.', 'we further use the submissions of']","['peerread dataset consists of papers, a set of associated peer reviews, and corresponding accept / reject decisions with aspect specific scores of papers collected from several top - tier artificial intelligence ( ai ), natural language processing ( nlp ) and machine learning ( ml ) conferences.', 'table 1 shows the data we consider in our experiments.', 'we could not consider nips and arxiv portions of peerread due to the lack of aspect scores and reviews, respectively.', 'for more details on the dataset creation and the task, we request the readers to refer to  #TAUTHOR_TAG.', 'we further use the submissions of iclr 2018, corresponding reviews and aspect scores to boost our training set for the decision prediction task.', 'one motivation of our work stems from the finding that aspect scores for certain factors like impact, originality, soundness / correctness which are seemingly central to the merit of the paper, often have very low correlation with the final recommendation made by the reviewers as is made evident in  #TAUTHOR_TAG.', ""however, from the heatmap in figure 1 we can see that the reviewer's sentiments ( compound / positive ) embedded within the review texts have visible correlations with the aspects like recommendation, appropriateness and overall decision."", 'this also seconds our recent finding that determining the scope or appropriateness of an article to a venue is the first essential step in peer review  #AUTHOR_TAG a ).', 'since our study aims at deciding the fate of the paper, we take predicting recommendation score and overall decision as the objectives of our investigation.', 'thus our proposal to augment sentiment of reviews to the deep neural architecture seems intuitive']",1
"['( classification ).', 'to compare with  #TAUTHOR_TAG,']","['( classification ).', 'to compare with  #TAUTHOR_TAG,']","[') and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup (']","['we mention earlier, we undertake two tasks : task 1 : predicting the overall recommendation score ( regression ) and task 2 : predicting the accept / reject decision ( classification ).', 'to compare with  #TAUTHOR_TAG, we keep the experimental setup ( train vs test ratio ) identical and re - implement their codes to generate the comparing figures.', 'however,  #TAUTHOR_TAG performed task 2 on iclr 2017 dataset with handcrafted features, and task 1 in a deep learning setting.', 'since our approach is a deep neural network based, we crawl additional paper + reviews from iclr 2018 to boost the training set.', 'for task 1, n 1 is 666 and n 2 is 98 while for task 2, n 1 is 1494 and n 2 is 525.', 'we employ a grid search for hyperparameter optimization.', 'for task 1, f is 256, l is 5. relu is the non - linear function g ( ), learning rate is 0. 007.', 'we train the model with sgd optimizer, set momentum as 0. 9  #TAUTHOR_TAG is feature - based and considers only paper, and not the reviews.', 'and batch size as 32.', 'we keep dropout at 0. 5.', '']",6
"['with  #TAUTHOR_TAG,']","['with  #TAUTHOR_TAG,']","['class label. to compare our work with  #TAUTHOR_TAG, we also applied a three -', 'class annotation scheme. in this method of annotation, we merge the citation context into a single sentence. since the context', 'introduces more than one sentiment per citation, we marked the citation sentiment with the last sentiment mentioned in the context window as', 'this is pragmatically most likely to be']","['such an approach would lead to the wrong prediction of praise or neutral sentiment', '. in this paper, we address the problem of contextenhanced citation sentiment detection. we present a new citation sentiment corpus where each citation has been annotated according to the dominant sentiment in the corresponding citation', 'context. we claim that this corpus is closer to the truth than annotation that considers only the citation sentence itself. we', 'show that it increases citation sentiment coverage, particularly for negative sentiment. using this gold standard, we explore the effect of assuming context windows of different but fixed lengths on the performance of a state - of', '- the - art citation sentiment detection system where the sentiment of citation is considered', 'in the entire context of the citation and more than one single sentiment can', 'be assigned. previous approaches neither detect citation sentiment and context simultaneously', 'nor use as large a corpus as we do. we selected a four - class scheme for annotation. every sentence that is in a window of 4 sentences of the citation and does not', 'contain any direct or indirect mention of the citation was labelled', 'as being excluded ( x ). the window length was motivated by recent research  #AUTHOR_TAG which shows', 'the best score', 'for a four - sentence boundary when detecting non - explicit citation. the rest of the sentences were marked', 'either positive ( p ), negative ( n ) or objective / neutral ( o ). a total of 1, 741 citations were annotated. although this annotation was performed by the first', 'author only, we know from previous work that similar styles of annotation can achieve acceptable interannotator agreement  #AUTHOR_TAG. an example annotation for  #AUTHOR_TAG is given in figure', '2, where the first column shows the line number and the second one shows the class label. to compare our work with  #TAUTHOR_TAG, we also applied a three -', 'class annotation scheme. in this method of annotation, we merge the citation context into a single sentence. since the context', 'introduces more than one sentiment per citation, we marked the citation sentiment with the last sentiment mentioned in the context window as', 'this is pragmatically most likely to be the real intention ( macroberts and', 'mac  #AUTHOR_TAG. as is evident from table 1, including the 4 sentence window around the citation more than doubles the instances', 'of subjective sentiment, and in the case of negative sentiment, this proportion rises to 3. in light', 'of the overall sparsity of detectable citation sentiment in a paper, and of', 'the envisaged applica - tions, this is a very positive result. the reason for this effect is most likely "" sweetened criticism "" - authors\'strategic behaviour of softening the effect of criticism among their peers  #AUTHOR_TAG']",5
"['earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous']","['earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous']","['( failed, method ) is represented as nsubj failed method.', 'this setup has been shown to produce good results earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous detection of']","['represent each citation as a feature set in a support vector machine ( svm )  #AUTHOR_TAG framework and use n - grams of length 1 to 3 as well as dependency triplets as features.', 'the dependency triplets are constructed by merging the relation, governor and dependent in a single string, for instance, the relation nsubj ( failed, method ) is represented as nsubj failed method.', 'this setup has been shown to produce good results earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous detection of sentiment and context sentences.', 'for this purpose, we use the four - class annotated corpus described earlier.', 'while the original annotations were performed for a window of length 4, we also experiment with asymmetrical windows of l sentences preceding the citation and r sentences succeeding it.', 'the detailed results are given in table 2.', 'table 2 : results for joint context and sentiment detection.', 'because of the skewed class distribution, we use both the f macro and f micro scores with 10 - fold cross - validation.', 'the baseline score, shown in bold, is obtained with no context window and is comparable to the results reported by  #TAUTHOR_TAG.', '']",0
"['using a relatively large corpus is by  #TAUTHOR_TAG.', 'however, this']","['using a relatively large corpus is by  #TAUTHOR_TAG.', 'however, this']","['-  #AUTHOR_TAG, the only recent work on citation sentiment detection using a relatively large corpus is by  #TAUTHOR_TAG.', 'however, this work does not handle citation context.', ' #AUTHOR_TAG proposed a system to attach sentiment information to the citation links']","['different schemes have been proposed for annotating citations according to their function ( spiegel -  #AUTHOR_TAG, the only recent work on citation sentiment detection using a relatively large corpus is by  #TAUTHOR_TAG.', 'however, this work does not handle citation context.', ' #AUTHOR_TAG proposed a system to attach sentiment information to the citation links between biomedical papers by using existing semantic lexical resources.', 'a common approach for sentiment detection is to use a labelled lexicon to score sentences ( hatzivassiloglou and mc  #AUTHOR_TAG.', 'however, such approaches have been found to be highly topic dependent ( engstrom, 2004 ;  #AUTHOR_TAG.', ' #AUTHOR_TAG worked on a 2, 829 sentence citation corpus using a 12 - class classification scheme.', ""although they used context in their annotation, their focus was on determining the author's reason for citing a given paper."", 'this task differs from citation sentiment, which is in a sense a "" lower level "" of analysis.', 'for implicit citation extraction,  #AUTHOR_TAG explore co - reference chains for citation extraction using a combination of co - reference resolution techniques.', 'however, their corpus consists of only 94 sentences of citations to 4 papers which is likely to be too small to be representative.', 'the most relevant work is by  #AUTHOR_TAG who extract only the non - explicit citations for a given paper.', 'they model each sentence as a node in a graph and experiment with various window boundaries to create edges between neighbouring nodes.', 'however, their dataset consists of only 10 papers and their annotation scheme differs from our four - class annotation as they do not deal with any sentiment']",0
"['earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous']","['earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous']","['( failed, method ) is represented as nsubj failed method.', 'this setup has been shown to produce good results earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous detection of']","['represent each citation as a feature set in a support vector machine ( svm )  #AUTHOR_TAG framework and use n - grams of length 1 to 3 as well as dependency triplets as features.', 'the dependency triplets are constructed by merging the relation, governor and dependent in a single string, for instance, the relation nsubj ( failed, method ) is represented as nsubj failed method.', 'this setup has been shown to produce good results earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous detection of sentiment and context sentences.', 'for this purpose, we use the four - class annotated corpus described earlier.', 'while the original annotations were performed for a window of length 4, we also experiment with asymmetrical windows of l sentences preceding the citation and r sentences succeeding it.', 'the detailed results are given in table 2.', 'table 2 : results for joint context and sentiment detection.', 'because of the skewed class distribution, we use both the f macro and f micro scores with 10 - fold cross - validation.', 'the baseline score, shown in bold, is obtained with no context window and is comparable to the results reported by  #TAUTHOR_TAG.', '']",3
"['earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous']","['earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous']","['( failed, method ) is represented as nsubj failed method.', 'this setup has been shown to produce good results earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous detection of']","['represent each citation as a feature set in a support vector machine ( svm )  #AUTHOR_TAG framework and use n - grams of length 1 to 3 as well as dependency triplets as features.', 'the dependency triplets are constructed by merging the relation, governor and dependent in a single string, for instance, the relation nsubj ( failed, method ) is represented as nsubj failed method.', 'this setup has been shown to produce good results earlier as well  #TAUTHOR_TAG.', 'the first set of experiments focuses on simultaneous detection of sentiment and context sentences.', 'for this purpose, we use the four - class annotated corpus described earlier.', 'while the original annotations were performed for a window of length 4, we also experiment with asymmetrical windows of l sentences preceding the citation and r sentences succeeding it.', 'the detailed results are given in table 2.', 'table 2 : results for joint context and sentiment detection.', 'because of the skewed class distribution, we use both the f macro and f micro scores with 10 - fold cross - validation.', 'the baseline score, shown in bold, is obtained with no context window and is comparable to the results reported by  #TAUTHOR_TAG.', '']",4
"['as', ' #TAUTHOR_TAG to']","['##s. moreover, we empirically show that ( 1 ) the three - player framework on its own helps cooperative games such as', ' #TAUTHOR_TAG to']","['moreover, we empirically show that ( 1 ) the three - player framework on its own helps cooperative games such as', ' #TAUTHOR_TAG to improve']","['', 'for the two cooperative methods. in order to prevent degenerate rationales', ', we propose a three - player game that renders explicit control over the unselected parts. in addition to the generator and the predictor', 'as in conventional cooperative rationale selection schemes, we add a third adversarial player, called the complement predictor, to regularize the cooperative communication between the generator and the predictor. the goal of', 'the complement predictor is to predict the correct label using only words left out of the rationale. during training,', 'the generator aims to fool the complement predictor while still maintaining high accuracy for the', 'predictor. this ensures that the selected rationale must contain all / most of the', 'information about the target label, leaving out irrelevant parts, within size constraints imposed on the rationales. we also theoretically show that the equilibrium', 'of the three - player game guarantees good properties for the extracted rationales. moreover, we empirically show that ( 1 ) the three - player framework on its own helps cooperative games such as', ' #TAUTHOR_TAG to improve both predictive accuracy and rationale quality ; (', '2 ) by combining the two solutions - introspective generator and', 'the three player game - we can achieve high predictive accuracy and non - degenerate rationales']",5
"['as', ' #TAUTHOR_TAG to']","['##s. moreover, we empirically show that ( 1 ) the three - player framework on its own helps cooperative games such as', ' #TAUTHOR_TAG to']","['moreover, we empirically show that ( 1 ) the three - player framework on its own helps cooperative games such as', ' #TAUTHOR_TAG to improve']","['', 'for the two cooperative methods. in order to prevent degenerate rationales', ', we propose a three - player game that renders explicit control over the unselected parts. in addition to the generator and the predictor', 'as in conventional cooperative rationale selection schemes, we add a third adversarial player, called the complement predictor, to regularize the cooperative communication between the generator and the predictor. the goal of', 'the complement predictor is to predict the correct label using only words left out of the rationale. during training,', 'the generator aims to fool the complement predictor while still maintaining high accuracy for the', 'predictor. this ensures that the selected rationale must contain all / most of the', 'information about the target label, leaving out irrelevant parts, within size constraints imposed on the rationales. we also theoretically show that the equilibrium', 'of the three - player game guarantees good properties for the extracted rationales. moreover, we empirically show that ( 1 ) the three - player framework on its own helps cooperative games such as', ' #TAUTHOR_TAG to improve both predictive accuracy and rationale quality ; (', '2 ) by combining the two solutions - introspective generator and', 'the three player game - we can achieve high predictive accuracy and non - degenerate rationales']",5
"['method in  #TAUTHOR_TAG. training during training, the three players']","['method in  #TAUTHOR_TAG. training during training, the three players']","['method in  #TAUTHOR_TAG. training during training, the three players']","['y conditioned on r c, denoted asp c (', 'y | r ). both predictors are trained using the cross entropy loss, i. e. where h ( p ; q ) denotes the', 'cross entropy between p and q. p ( · | · ) denotes the empirical distribution. it is worth emphasizing that lp and lc are both', 'functions of the generator. generator : the generator extracts r and r c by generating the rationale mask, z ( · ), as shown in eqs. ( 1 - 2 ). specifically,', 'z ( · ) is determined by minimizing the weighted combination of four losses : where lg encourages the gap between lp and lc to be', 'large, i. e. it stipulates the comprehensiveness property of the rationale ( eq. ( 5 ) ). intuitively, if the complement rationale is less informative of', 'y than the rationale, then lc should be larger than lp. ls and lc impose the sparsity and continuity respectively, which correspond to eq. ( 6 ) : from eq.', '( 7 ), we can see that the generator plays a', 'cooperative game with the predictor, because both tries to maximize', 'the predictive performance of r. on the other hand, the generator plays an adversarial game with the complement predictor, because the latter tries to maximize the', 'predictive performance of r c, but the former tries to reduce it. without the complement predictor, and thus the loss lg, the framework reduces to the method in  #TAUTHOR_TAG. training during training, the three players perform gradient descent steps with respect to their own losses. for the generator,', 'since z ( x ) is a set of binary variables, we cannot apply the regular gradient descent algorithm. instead we will use policy gradient  #AUTHOR_TAG to optimize', 'the models. we maximize the reward that is defined as the negative loss in eq. (', '8 ). in order to have bounded rewards for training stability, the negative losses lp and lc are replaced with accuracy. theoretical', 'guarantees the proposed framework is able to obtain a rationale that simultane - ously satisfies the conditions in eqs', '. ( 4 ) to ( 6 ), as stated in the following theorem : theorem 1. a rationalization', 'scheme z ( x ) that simultaneously satisfies eqs. ( 4', ') - ( 6 ) is the global optimizer of eq. ( 8 ). the proof is given in appendix a. the basic idea', 'is that there is a correspondence between each term in eq. ( 8 )', 'and each of the properties eqs. ( 4 ) - (', '6 ). the minimization of each loss term is equivalent to satisfying the', 'corresponding property']",5
"['text matching benchmark askubuntu, following  #TAUTHOR_TAG.', 'the experimental setting and results are reported in appendix']","['text matching benchmark askubuntu, following  #TAUTHOR_TAG.', 'the experimental setting and results are reported in appendix']","[', as suggested by an anonymous reviewer, we evaluate on the text matching benchmark askubuntu, following  #TAUTHOR_TAG.', 'the experimental setting and results are reported in']","['construct three text classification tasks, including two sentiment classification tasks from the beeradvocate review dataset ( mc  #AUTHOR_TAG 4, and a more complex relation classification task from semeval 2010 task 8  #AUTHOR_TAG.', 'table 2 gives examples of the above tasks.', 'finally, as suggested by an anonymous reviewer, we evaluate on the text matching benchmark askubuntu, following  #TAUTHOR_TAG.', 'the experimental setting and results are reported in appendix f.', 'multi - aspect beer review this is the same data used in  #TAUTHOR_TAG.', 'each review evaluates multiple aspects of a kind of beer, including appearance, smell, palate, and an overall score.', '']",5
"['text matching benchmark askubuntu, following  #TAUTHOR_TAG.', 'the experimental setting and results are reported in appendix']","['text matching benchmark askubuntu, following  #TAUTHOR_TAG.', 'the experimental setting and results are reported in appendix']","[', as suggested by an anonymous reviewer, we evaluate on the text matching benchmark askubuntu, following  #TAUTHOR_TAG.', 'the experimental setting and results are reported in']","['construct three text classification tasks, including two sentiment classification tasks from the beeradvocate review dataset ( mc  #AUTHOR_TAG 4, and a more complex relation classification task from semeval 2010 task 8  #AUTHOR_TAG.', 'table 2 gives examples of the above tasks.', 'finally, as suggested by an anonymous reviewer, we evaluate on the text matching benchmark askubuntu, following  #TAUTHOR_TAG.', 'the experimental setting and results are reported in appendix f.', 'multi - aspect beer review this is the same data used in  #TAUTHOR_TAG.', 'each review evaluates multiple aspects of a kind of beer, including appearance, smell, palate, and an overall score.', '']",5

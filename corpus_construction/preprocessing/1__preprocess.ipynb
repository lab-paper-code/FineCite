{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import os \n",
    "from xml.etree import ElementTree as ET\n",
    "import json\n",
    "from lxml import etree as ET\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining XML Namespaces: to process TEI(a form of XML Markup language) doc\n",
    "ns = {\n",
    "    'tei': 'http://www.tei-c.org/ns/1.0',\n",
    "    'xsi': 'http://www.w3.org/2001/XMLSchema-instance',\n",
    "    'xlink': 'http://www.w3.org/1999/xlink'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dir name\n",
    "\n",
    "#inport settings\n",
    "sample = True\n",
    "\n",
    "#set input and output dir\n",
    "if sample:\n",
    "    input_dir = 'sample/grobid_full_text'\n",
    "    output_dir = '../data/sample/1_json'\n",
    "    error_log_dir = 'sample/error'\n",
    "else:\n",
    "    input_dir = '/home/deallab/jisulee/CCE/data/grobid_full_text/'\n",
    "    output_dir = '../data/result/1_json'\n",
    "    error_log_dir = '../data/result/error'\n",
    "    \n",
    "#set ouput path if not exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "#set ouput path if not exists\n",
    "if not os.path.exists(error_log_dir):\n",
    "    os.makedirs(error_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save file name which has an error\n",
    "error_files_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to count the number of files\n",
    "total_files = 0\n",
    "files_processed = 0\n",
    "error_files_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert ref tags to [REF] format\n",
    "def convert_ref_tags(text):\n",
    "    if re.search(r'<ref type=\"bibr\">(.*?)</ref>',text):\n",
    "        pattern = r'<ref type=\\\"bibr\\\">(.*?)<\\/ref>'\n",
    "        replacement = r'<ref type=\"single\" target=\"#n999\">\\1</ref>'\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    pattern = r'<ref type=\\\"bibr\\\" target=\\\"#(.*?)\\\">(.*?)<\\/ref>'\n",
    "    replacement = r'<ref type=\"single\" target=\"#\\1\">\\2</ref>'\n",
    "    return re.sub(pattern, replacement, text)\n",
    "\n",
    "\n",
    "def replace_with_gref(match):\n",
    "    all_refs = match.group(0)\n",
    "    matches = re.findall(r'<ref type=\"single\" target=\"(#[a-z]\\d+)\">(.*?)</ref>', all_refs)\n",
    "    ids = ';'.join([match[0] for match in matches])\n",
    "    content = ' '.join([match[1] for match in matches])\n",
    "    return f'<ref type=\"group\" target=\"{ids}\">{content}</ref>'\n",
    "# convert paragraphs\n",
    "def process_paragraphs(paragraphs):\n",
    "    processed_paragraphs = []\n",
    "    for paragraph in paragraphs:\n",
    "\n",
    "            \n",
    "        processed_paragraph = convert_ref_tags(paragraph) # conver <ref> into [REF:#id]\n",
    "        pattern = r'(<ref type=\"single\"[^\\>]+>[^\\<]+<\\/ref> ?)+<ref type=\"single\"[^\\>]+>[^\\<]+<\\/ref>' # pattern of consecutive [REF:#id] tag\n",
    "        \n",
    "        clean_paragraph = re.sub(pattern, replace_with_gref, processed_paragraph)\n",
    "        \n",
    "        clean_paragraph = re.sub(r'<p[^\\>]+>(.*?)<\\/p>', r'\\1', clean_paragraph)\n",
    "    \n",
    "        clean_paragraph = re.sub(r'<(?=(?!\\/))(?!ref)[^\\>]+>[^\\<]+<[^\\>]+>', '', clean_paragraph)\n",
    "        \n",
    "        processed_paragraphs.append(clean_paragraph)\n",
    "    return processed_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_div(div):\n",
    "    \n",
    "    #remove other ref tags (without removing content)\n",
    "    cleaned_div = re.sub(r'<ref type=\"(?!bibr)[^\\>]+>([^\\<]+)<\\/ref>', r'\\1', div)\n",
    "\n",
    "    #remove p tags surrounding formulas\n",
    "    cleaned_div = re.sub(r'<\\/p><formula[^\\>]+>([^\\<]+)<\\/formula><p>',r'\\1', cleaned_div)\n",
    "    cleaned_div = re.sub(r'(<\\/p>)?<formula[^\\>]+>([^\\<]+)<\\/formula>(<p>)?',r'\\3\\2\\1', cleaned_div)\n",
    "    \n",
    "    #clean <div> and <head> tags\n",
    "    cleaned_div = re.findall(r'<p>(.*?)<\\/p>', cleaned_div)\n",
    "    \n",
    "    return cleaned_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.xml'):\n",
    "        total_files += 1\n",
    "        xml_file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        try:\n",
    "            # Parsing XML file\n",
    "            tree = ET.parse(xml_file_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Extract <Title>\n",
    "            title_element = root.find(\".//tei:teiHeader//tei:title[@type='main']\", ns)\n",
    "            title = title_element.text if title_element is not None else None\n",
    "\n",
    "            # Extract <authors (authors of master documents only)>\n",
    "            authors = []\n",
    "            for author in root.findall('.//tei:teiHeader//tei:author/tei:persName', ns):\n",
    "                first_name = author.find('tei:forename', ns).text if author.find('tei:forename', ns) is not None else None\n",
    "                last_name = author.find('tei:surname', ns).text if author.find('tei:surname', ns) is not None else None\n",
    "                authors.append({'first_name': first_name, 'last_name': last_name})\n",
    "\n",
    "            # Extract <year of publication>\n",
    "            doc_pub_year_element = filename.split('.')[0]\n",
    "            doc_pub_year = int(doc_pub_year_element) if doc_pub_year_element.isnumeric() else None\n",
    "\n",
    "            # Extract <abstract>\n",
    "            abstract_element = root.find('.//tei:teiHeader//tei:abstract//tei:p', ns)\n",
    "            abstract = abstract_element.text if abstract_element is not None else None\n",
    "            \n",
    "            #Extract langage\n",
    "            text_lang = root.find('tei:text', ns).get('{http://www.w3.org/XML/1998/namespace}lang')\n",
    "\n",
    "            # Extracted <section>\n",
    "            sections = []\n",
    "            for div in root.findall('.//tei:body/tei:div', ns):\n",
    "                paragraphs = clean_div(ET.tostring(div, encoding='unicode', method='xml'))\n",
    "                section_name = div.find('.//tei:head', ns).text if div.find('.//tei:head', ns) is not None else None\n",
    "                # paragraphs = [ET.tostring(p, encoding='unicode', method='xml') for p in div.findall('.//tei:p', ns)]\n",
    "                processed_paragraphs = process_paragraphs(paragraphs)\n",
    "                sections.append({'section_name': section_name, 'paragraphs': processed_paragraphs})\n",
    "\n",
    "            # Extract <references>\n",
    "            references = []\n",
    "            biblStruct_elements = root.findall('.//tei:listBibl/tei:biblStruct', ns)\n",
    "            for biblStruct in biblStruct_elements:\n",
    "                ref_id = biblStruct.get('{http://www.w3.org/XML/1998/namespace}id', \"Unknown ID\")\n",
    "                ref_title_element = biblStruct.find(\".//tei:title[@type='main']\", ns)\n",
    "                ref_title = ref_title_element.text if ref_title_element is not None else None\n",
    "                \n",
    "                ref_authors = []\n",
    "                for author in biblStruct.findall('.//tei:author/tei:persName', ns):\n",
    "                    first_name_element = author.find('tei:forename', ns)\n",
    "                    last_name_element = author.find('tei:surname', ns)\n",
    "                    first_name = first_name_element.text if first_name_element is not None else None\n",
    "                    last_name = last_name_element.text if last_name_element is not None else None\n",
    "                    ref_authors.append({'first_name': first_name, 'last_name': last_name})\n",
    "                \n",
    "                pub_year_element = biblStruct.find('.//tei:date[@type=\"published\"]', ns)\n",
    "                if pub_year_element is None:\n",
    "                    pub_year = None\n",
    "                else: \n",
    "                    match = re.search(r'[1-2][0,9]\\d{2}', pub_year_element.get('when'))\n",
    "                    pub_year = int(match.group(0)) if match else None\n",
    "                \n",
    "\n",
    "                \n",
    "                idno_element = biblStruct.find('.//tei:idno', ns)\n",
    "                idno_type = idno_element.get('type') if idno_element is not None else None\n",
    "                idno = idno_element.text.strip() if idno_element is not None else None\n",
    "                \n",
    "                reference = {\n",
    "                    'id': ref_id,\n",
    "                    'title': ref_title,\n",
    "                    'authors': ref_authors,\n",
    "                    'pub_year': pub_year,\n",
    "                }\n",
    "                if (idno_type and idno):\n",
    "                    reference['IDNO'] = {'type': idno_type, 'content': idno}\n",
    "                \n",
    "                references.append(reference)\n",
    "\n",
    "            document_data = {\n",
    "                'title': title,\n",
    "                'authors': authors,\n",
    "                'pub_year': doc_pub_year,\n",
    "                'lang': text_lang,\n",
    "                'abstract': abstract,\n",
    "                'IDNO': {'type': 'acl', 'content': 'aclanthology.org/' + filename[0:-8]},\n",
    "                'sections': sections,\n",
    "                'references' : references\n",
    "            }\n",
    "\n",
    "            json_output_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}.json\")\n",
    "            with open(json_output_path, 'w', encoding='utf-8') as json_file:\n",
    "                json.dump(document_data, json_file, indent=4, ensure_ascii=False)\n",
    "            \n",
    "            files_processed += 1\n",
    "                \n",
    "        except ET.ParseError:\n",
    "            error_files_count += 1\n",
    "            error_files_list.append(filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing. Check 'error_files.txt' for list of problematic files.\n"
     ]
    }
   ],
   "source": [
    "#set ouput path if not exists\n",
    "if not os.path.exists(error_log_dir):\n",
    "    os.makedirs(error_log_dir)\n",
    "    \n",
    "with open(error_log_dir + 'log.txt', 'w', encoding='utf-8') as f:\n",
    "    for file in error_files_list:\n",
    "        f.write(f\"{file}\\n\")\n",
    "\n",
    "print(\"Finished processing. Check 'error_files.txt' for list of problematic files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total XML files loaded: 82\n",
      "Total XML files processed: 80\n",
      "Total error files: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total XML files loaded: {total_files}\")\n",
    "print(f\"Total XML files processed: {files_processed}\")\n",
    "print(f\"Total error files: {error_files_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

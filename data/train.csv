id,citing_title,citing_year,citing_authors,cited_title,cited_year,cited_authors,citation_type,paragraph,target_reference_location,context_location_1
00bcb525-6b6f-48be-8bd6-60852038c995,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,"[""Google's multilingual neural machine translation system: Enabling zero-shot translation""]",['2017'],['Melvin Johnson;Mike Schuster;Quoc Le;Maxim Krikun;Yonghui Wu;Zhifeng Chen;Nikhil Thorat;Fernanda Viégas;Martin Wattenberg;Greg Corrado;Macduff Hughes;Jeffrey Dean'],single,"['Neural', 'Machine', 'Translation', '(NMT)', 'has', 'opened', 'several', 'research', 'directions', 'to', 'exploit', 'as', 'many', 'and', 'diverse', 'data', 'as', 'possible.', 'Massive', 'multilingual', 'NMT', 'models,', 'for', 'instance,', 'take', 'advantage', 'of', 'several', 'language-pair', 'datasets', 'in', 'a', 'single', 'system', '<ref type=""single"">(Johnson et al., 2017).</ref>', 'This', 'offers', 'several', 'advantages,', 'such', 'as', 'a', 'simple', 'training', 'process', 'and', 'enhanced', 'performance', 'of', 'the', 'language-pairs', 'with', 'little', 'data', '(although', 'sometimes', 'detrimental', 'to', 'the', 'high-resource', 'language-pairs).', 'However,', 'massive', 'models', 'of', 'dozens', 'of', 'languages', 'are', 'not', 'necessarily', 'the', 'best', 'outcome,', 'as', 'it', 'is', 'demonstrated', 'that', 'smaller', 'clusters', 'still', 'offer', 'the', 'same', 'benefits', '<ref type=""group"">(Tan et al., 2019, Oncevay et al., 2020).</ref>']",34,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
010f860b-24d4-4e94-b0d2-593693d657e6,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Experiments on Domain Adaptation for English-Hindi SMT'],['2009'],['R Haque;S Naskar;J Van Genabith;A Way'],single,"['As', 'shown', 'in', 'Table', '1,', 'the', 'size', 'of', 'the', ""'in-domain'"", 'TED', 'training', 'data', 'is', 'much', 'smaller', 'than', 'the', ""'out-of-domain'"", 'Multi-UN', 'training', 'data.', 'Since', 'adding', 'a', 'significant', 'amount', 'of', 'out-ofdomain', 'data', 'to', 'an', 'in-domain', 'corpus', 'reduces', 'the', 'quality', 'of', 'translation', 'for', 'in-domain', 'sentences', '<ref type=""single"">[23],</ref>', 'we', 'decided', 'to', 'use', 'only', 'a', 'part', 'of', 'the', 'out-of-domain', 'data', 'to', 'enhance', 'the', 'translation', 'quality.', 'In', 'order', 'to', 'achieve', 'this,', 'we', 'constructed', 'a', 'language', 'model', 'on', 'the', 'TED', 'monolingual', 'data', 'and', 'computed', 'sentence-level', 'perplexity', 'score', 'for', 'all', 'the', 'sentences', 'in', 'Multi-UN,', 'with', 'respect', 'to', 'the', 'TED', 'language', 'model.', 'After', 'sorting', 'the', 'sentences', 'in', 'the', 'ascending', 'order', 'of', 'the', 'perplexity', 'values,', 'only', 'sentences', 'below', 'a', 'specific', 'threshold', 'were', 'selected.', 'This', 'method', 'provided', 'us', 'with', 'the', 'most', ""'TED-like'"", 'sentences', 'from', 'the', 'Multi-UN', 'corpora.']",42,"[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
014223dd-b870-48b7-9281-c9fbacf18f6f,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,"['Query based event extraction along a timeline', 'Event graphs for information retrieval and multi-document summarization. Expert systems with applications']","['2004', '2014']","['Hai Leong Chieu;Yoong Keok Lee', 'Goran Glavaš']",group,"['Automatic', 'extraction', 'of', 'events', 'has', 'gained', 'sizable', 'attention', 'in', 'subfields', 'of', 'NLP', 'and', 'information', 'retrieval', 'such', 'as', 'automatic', 'summarization,', 'question', 'answering', 'and', 'knowledge', 'graph', 'embeddings', '<ref type=""group"">(Chieu and Lee, 2004, Glavaš and Šnajder, 2014),</ref>', 'as', 'events', 'are', 'a', 'representation', 'of', 'temporal', 'information', 'and', 'sequences', 'in', 'text.', 'Various', 'developments', 'in', 'guidelines', 'and', 'datasets', 'for', 'event', 'detection', 'have', 'been', 'met', 'with', 'equally', 'fast', 'paced', 'evolution', 'of', 'automatic', 'event', 'annotation', 'and', 'detection', 'methodologies', 'in', 'the', 'last', 'few', 'years', '<ref type=""group"">(Doddington et al., 2004, Pustejovsky et al., 2010, O\'Gorman et al., 2016).</ref>', 'On', 'a', 'larger', 'scale,', 'event', 'extraction', 'has', 'extended', 'to', 'many', 'languages', 'beyond', 'English,', 'including', 'French', '<ref type=""single"">(Bittar et al., 2011),</ref>', 'Spanish', '<ref type=""single"">(Saurı, 2010),</ref>', 'Italian', '<ref type=""single"">(Caselli et al., 2011a)</ref>', 'and', 'very', 'recently,', 'Hindi', '<ref type=""single"">(Goud et al., 2019b).</ref>', 'Event', 'detection', 'architectures', 'have', 'their', 'origins', 'in', 'statistical', 'models', 'such', 'as', 'K-means', 'and', 'hierarchical', 'clustering', 'methods', '<ref type=""single"">(Arnulphy et al., 2015),</ref>', 'which', 'have', 'more', 'recently', 'given', 'way', 'to', 'neural', 'models.', 'Deep', 'neural', 'architectures', 'on', 'event', 'annotation', 'vary', 'based', 'on', 'the', 'approach', 'taken', 'to', 'identifying', 'and', 'handling', 'the', 'data.']",25,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0157b9a7-b148-4d34-8d56-a4d827539085,A Parameter-Based Message-Passing Parser for MT of Korean and English,1994,Bonnie Dorr;Jye-Hoon Lee;Sungki Suh,['unknown'],['unknown'],['unknown'],single,"['The', 'subject', 'NP', ""'Bill'"", 'is', 'coindexed', 'with', 'the', 'trace', 'in', 'the', 'more', 'deeply', 'embedded', 'relative', 'clause.', 'If', 'we', 'assume,', 'following', '<ref type=""single"">Chomsky (1986a),</ref>', 'that', 'relative', 'clause', 'formation', 'involves', 'movement', 'from', 'an', 'inner', 'clause', 'into', 'an', 'outer', 'subject', 'position,', 'then', 'the', 'grammaticality', 'of', 'the', 'above', 'example', 'suggests', 'that', 'the', 'Trace', 'theory', 'must', 'be', 'parameterized', 'so', 'that', 'crossing', 'more', 'than', 'one', 'barrier', 'is', 'allowed', 'in', 'Korean.', 'Our', 'formulation', 'of', 'this', 'parametric', 'distinction', 'is', 'as', 'follows:']",20,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
01b0446b-330d-4218-b91f-5a0e9e702d81,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['unknown'],['unknown'],['unknown'],group,"['Self-training', '<ref type=""group"">(He et al., 2019, Chen et al., 2020)</ref>', 'uses', 'a', 'source-to-target', 'model', 'to', 'generate', 'synthetic', 'pairs', 'from', 'source-side', 'monolingual', 'data', 'to', 'augment', 'the', 'original', 'parallel', 'corpus.', 'We', 'combined', '2M', 'Chinese', 'monolingual', 'data', 'with', '2M', 'Chinese', 'sentences', 'randomly', 'sampled', 'from', 'the', 'CWMT', 'parallel', 'corpus,', 'yielding', 'a', 'total', 'of', '4M', 'monolingual', 'for', 'forward', 'translation.']",1,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
01d94d2b-6f78-4845-8d3c-2fb8077bdbad,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,"['Understanding in an instant: Neurophysiological evidence for mechanistic language circuits in the brain', 'Words in Context: The Effects of Length, Frequency, and Predictability on Brain Responses During Natural Reading', 'Effects of word length and frequency on the human event-related potential']","['2009', '2016', '2004']","['Friedemann Pulvermüller;Yury Shtyrov;Olaf Hauk', 'Sarah Schuster;Stefan Hawelka;Florian Hutzler', 'Olaf Hauk;Friedemann Pulvermüller']",group,"['Results.', 'Figure', '2', '(top', 'rows', 'of', 'A,', 'B,', 'C)', 'shows', 'butterfly', 'plots', 'for', 'the', 'effects', 'of', 'word', 'length,', 'frequency', 'and', 'class', 'across', '64', 'electrodes.', 'Our', 'linear', 'SVM', 'decoding', 'analysis', 'replicates', 'the', 'temporal', 'cascade', 'of', 'word', 'length,', 'frequency', 'and', 'class', 'effects', 'previously', 'reported', 'for', 'EEG', 'responses', 'averaged', 'across', 'a', 'large', 'number', 'of', 'trials.', 'The', 'word', 'length', 'effect', 'arises', 'early', 'at', 'about', '100', 'ms,', 'previously', 'associated', 'with', 'visual', 'word', 'processing', 'in', 'occipitotemporal', 'cortices', '<ref type=""group"">(Hauk and Pulvermüller, 2004, Pulvermüller et al., 2009, Schuster et al., 2016).</ref>', 'Word', 'frequency', 'influenced', 'neural', 'processing', 'later', 'from', '200', 'ms', 'onwards', 'with', 'a', 'slight', 'left-hemispheric', 'predominance', '<ref type=""single"">(Griffiths et al., 2012).</ref>', 'The', 'word', 'class', 'effect', 'emerged', 'in', 'early', 'and', 'late', 'time', 'windows', 'with', 'the', 'effect', 'at', 'about', '550', 'ms', 'in', 'line', 'with', 'the', 'wellknown', 'P600', 'as', 'an', 'ERP', 'indicator', 'for', 'syntactic', 'processing', '<ref type=""group"">(Osterhout and Holcomb, 1992, Hagoort et al., 1993, ter Keurs et al., 1999).</ref>', 'Word', 'length', 'and', 'frequency', 'effects', 'were', 'stronger', 'than', 'the', 'word', 'class', 'effect,', 'see', '<ref type=""single"">King et al. (2020).</ref>', 'As', 'expected,', 'decoding', 'accuracy', 'increased', 'when', 'EEG', 'signals', 'were', 'averaged', 'across', 'trials.', 'Thus,', 'carefully', 'controlling', 'each', 'comparison', 'of', 'interest', '(e.g.', 'word', 'class)', 'for', 'the', 'effects', 'of', 'no', 'interest', '(e.g.', 'word', 'length', 'and', 'gressively', 'generates', 'dependencies', 'amongst', 'training', 'samples', 'thereby', 'limiting', 'their', 'additional', 'benefit', 'beyond', '250k.', 'We', 'formally', 'assessed', 'whether', 'the', 'Transformer', 'that', 'scored', 'best', 'on', 'the', 'dev', 'set', 'obtained', 'better', 'decoding', 'accuracy', 'for', '250K', 'than', 'for', 'the', 'original', '20k', 'training', 'set', '(n.b.', 'we', 'performed', 'this', 'statistical', 'test', 'on', 'the', 'test', 'set,', 'because', 'the', '3', 'and', '10', 'trial', 'averages', 'within', 'the', 'dev', 'set', 'were', 'not', 'independent', 'from', 'one', 'another', 'as', 'a', 'result', 'of', 'boostrapping).', 'Indeed,', 'for', 'both', '3', 'and', '10', 'trial', 'averages', 'the', ""Transformer's"", '(but', 'not', 'the', ""SVM's)"", 'decoding', 'accuracy', 'was', 'significantly', 'better', 'for', '250k', 'than', 'the', 'original', '20k', 'training', 'set', '(p', '&lt,', '0.01,', 'Wilcoxon', 'signed-rank', 'test).']",71,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
01e43ee9-7f60-43b5-bce5-82282dbb981d,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['A syntax and semantics for feature-structure transfer'],['1990'],['D Estival;A Ballim;G Russell;S Warwick'],single,"['For', 'the', 'dynamic', 'programming', 'algorithm,', 'costs', 'are', 'taken', 'into', 'account.', 'In', 'compilers,', 'this', 'value', 'is', 'related', 'to', 'the', 'cost', 'of', 'the', 'instructions', 'corresponding', 'to', 'the', 'pattern', 'tree.', 'For', 'this', 'example,', 'the', 'costs', 'are', 'not', 'a', 'function', 'of', 'anything', 'external,', 'they', 'do,', 'however,', 'capture', 'the', 'preference', 'of', 'larger', 'pattern', 'trees', 'over', 'combinations', 'of', 'smaller', 'trees,', 'which', 'is', 'desireable,', 'see', '<ref type=""single"">Estival et al. (1990).</ref>', 'Tracing', 'through', 'the', 'example', 'again,', 'then,', 'this', 'time', 'with', 'costs,', 'at', 'the', 'lowest', 'node', 'the', 'annotation', '«', 'has', 'cost', '3,', 'the', 'other', 'two', 'annotations', '«', '½', '½', 'and', '«', '½,', 'being', 'partial', 'pattern', 'trees,', 'have', 'no', 'cost.', 'At', 'the', 'next', 'higher', 'node,', 'the', 'annotations', '¬', '½', '«', '½', '½', 'and', '¬', '½', '«', '½', 'have', 'cost', '3,', '«', '¿', 'has', 'cost', '6', '(3', 'for', 'the', 'pattern', 'tree', '«', '¿,', 'and', '3', 'for', 'the', 'left', 'child', 'as', 'annotated', 'in', 'the', 'previous', 'step),', '«', 'has', 'cost', '5.', 'As', 'both', '«', 'alternatives', 'span', 'the', 'same', 'subtree', 'from', 'this', 'node', 'down,', 'and', 'have', 'the', 'same', 'return', 'type', '(sub),', 'it', 'is', 'possible', 'to', 'discard', 'the', 'annotation', '«', '¿,', 'as', 'it', 'will', 'always', 'be', 'cheaper', 'to', 'use', '«', 'at', 'this', 'point,', 'regardless', 'of', 'what', 'happens', 'further', 'up', 'the', 'tree.', 'At', 'the', 'next', 'higher', 'node,', 'the', 'annotations', '¬', '½', '«', '½', '½', 'and', '¬', '½', '«', '½', 'have', 'cost', '6,', 'and', '«', '¿', 'has', 'cost', '8.', 'Finally,', 'at', 'the', 'top', 'Ë', 'node,', '«', '¾', 'has', 'cost', '13', '(5', 'for', 'the', 'pattern', 'tree,', '8', 'for', 'the', 'left', 'child:', 'as', 'the', 'pattern', 'tree', 'can', 'only', 'accept', 'an', 'initial', 'tree', 'as', 'the', 'left', 'child,', 'only', '«', '¿', 'is', 'a', 'suitable', 'candidate),', 'but', '«', '½', 'has', 'cost', '10', '(4', 'for', 'the', 'pattern', 'tree,', '6', 'for', 'the', 'intervening', 'auxiliary', 'trees).', 'The', 'algorithm', 'in', 'Figure', '8', 'is', 'modified', 'so', 'that', 'any', 'annotation', 'in', 'an', 'annotation', 'set', 'with', 'the', 'same', 'type', 'but', 'non-minimal', 'cost', 'is', 'discarded.', 'Thus', 'the', 'derivation', 'of', 'the', 'optimal', 'tree', 'parse,', 'top-down,', 'would', 'be', '«', '½', 'with', 'an', 'adjunction', 'of', '¬', '½', 'which', 'in', 'turn', 'has', 'an', 'adjunction', 'of', '¬', '½.']",58,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
02756584-bfba-49b7-bcf4-76fd4668c044,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['The BECauSE Corpus 2.0: Annotating causality and overlapping relations'],['2017'],['Jesse Dunietz;Lori Levin;Jaime Carbonell'],single,"['Our', 'training', 'data', 'include', 'four', 'datasets', 'about', 'causal', 'and', 'temporal', 'relations', 'between', 'event', 'texts.', 'PDTB', '3.0', '<ref type=""single"">(Webber et al., 2006)</ref>', 'is', 'WSJ', 'articles', 'annotated', 'with', 'four', 'high-level', 'discourse', 'relations,', 'and', 'we', 'map', 'the', 'sub-relations', 'of', ""'Temporal'"", 'to', 'our', 'classes.', '5', 'BECauSE', '2.0', '<ref type=""single"">(Dunietz et al., 2017)</ref>', 'is', 'news', 'articles', 'annotated', 'with', 'linguistically', 'marked', 'causality.', 'WIQA', '<ref type=""single"">(Tandon et al., 2019)</ref>', 'is', 'scientific', 'event', 'texts', 'annotated', 'with', 'causality', 'between', 'events.', 'ConceptNet', '<ref type=""single"">(Speer et al., 2017)</ref>', 'is', 'a', 'knowledge', 'graph', 'between', 'phrases,', 'and', 'relations', 'about', 'causality', 'are', 'mapped', 'to', 'our', 'classes.', 'To', 'prevent', 'overfitting', 'to', 'corpus-specific', 'characteristics,', 'we', 'add', 'adversarial', 'data', 'by', 'swapping', 'two', 'input', 'texts', '(PDTB-R,', 'BECauSE-R,', 'ConceptNet-R)', 'or', 'pairing', 'random', 'texts', '(WIQA-P).', 'The', 'mapping', 'between', 'corpus-specific', 'labels', 'and', 'ours', 'is', 'in', 'Table', '3,', 'and', 'the', 'module', 'accuracy', 'in', 'Table', '2', 'rows', '11-19.', '5', 'We', 'use', 'explicit', 'relations', 'only', 'for', 'pretraining,', 'since', 'they', 'often', 'capture', 'linguistically', 'marked,', 'rather', 'than', 'true,', 'relations', 'between', 'events.', 'We', 'also', 'exclude', 'the', 'Contingency', 'relations', 'as', 'causal', 'and', 'non-causal', 'relations', '(e.g.,', 'justification)', 'are', 'mixed.']",39,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
03121d9f-4dc3-46bf-8926-94c2ba0c29df,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['unknown'],['unknown'],['unknown'],single,"['The', 'four', 'languages', 'are', 'highly', 'agglutinative', 'or', 'polysynthetic,', 'meaning', 'that', 'they', 'usually', 'express', 'a', 'large', 'amount', 'of', 'information', 'in', 'just', 'one', 'word', 'with', 'several', 'joint', 'morphemes.', 'This', 'is', 'a', 'real', 'challenge', 'for', 'MT', 'and', 'subword', 'segmentation', 'methods,', 'given', 'the', 'high', 'probability', 'of', 'addressing', 'a', '""rare', 'word""', 'for', 'the', 'system.', 'We', 'also', 'note', 'that', 'each', 'language', 'belongs', 'to', 'a', 'different', 'language', 'family,', 'but', 'that', 'is', 'not', 'a', 'problem', 'for', 'multilingual', 'models,', 'as', 'usually', 'the', 'family-based', 'clusters', 'are', 'not', 'the', 'most', 'effective', 'ones', '<ref type=""single"">(Oncevay et al., 2020</ref>', 'Pre-processing', 'The', 'datasets', 'were', 'noisy', 'and', 'not', 'cleaned.', 'Lines', 'are', 'reduced', 'according', 'to', 'several', 'heuristics:', 'Arabic', 'numbers', 'or', 'punctuation', 'do', 'not', 'match', 'in', 'the', 'parallel', 'sentences,', 'there', 'are', 'more', 'symbols', 'or', 'numbers', 'than', 'words', 'in', 'a', 'sentence,', 'the', 'ratio', 'of', 'words', 'from', 'one', 'side', 'is', 'five', 'times', 'larger', 'or', 'shorter', 'than', 'the', 'other,', 'among', 'others.', 'Table', '5', 'in', 'the', 'Appendix', 'includes', 'the', 'original', 'and', 'cleaned', 'data', 'size', 'per', 'language-pair,', 'whereas', 'Table', '1', 'presents', 'the', 'final', 'sizes.']",81,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0374ebac-b7a0-4cda-a62a-ff2965a7e9fc,Entity Attribute Relation Extraction with Attribute-Aware Embeddings,2020,Dan Iter;Xiao Yu;Fangtao Li,['The role of documents vs. queries in extracting class attributes from text'],['2007'],['Marius Pas;Benjamin Van Durme;Nikesh Garera'],single,"['We', 'sample', 'sentences', 'from', 'a', 'subset', 'of', 'online', 'news', 'articles', 'and', 'label', 'them', 'with', 'our', 'distant', 'supervision', 'knowledge', 'base', '<ref type=""single"">(Mintz et al., 2009)</ref>', 'using', 'a', 'query', 'streams', 'as', 'the', 'source', 'of', 'supervision,', 'as', 'in', '<ref type=""single"">(Pas ¸ca et al., 2007).</ref>', 'We', 'sample', '12.6', 'million', 'entityattribute', 'pairs', 'from', 'a', 'knowledge', 'base,', 'finding', '6', 'million', 'unique', 'entities', 'and', '788', 'thousand', 'unique', 'attributes.', 'Each', 'sentence', 'that', 'contains', 'an', 'entityattribute', 'pair', 'from', 'our', 'knowledge', 'base', 'is', 'used', 'as', 'the', 'support', 'set', 'for', 'that', 'pair.']",31,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
038bcd81-56ab-48fc-abe3-b99741f587c0,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['unknown'],['2001'],['George Kiraz'],single,"['10', 'An', 'example', 'of', 'this', 'type', 'of', 'work', 'is', '<ref type=""single"">Kiraz (2001).</ref>', 'In', 'Arabic', 'a', 'root', 'such', 'as', 'ktb', 'is', 'combined', 'with', 'a', 'vowel', 'pattern', 'to', 'produce', 'words', 'such', 'as', 'kitaab', ""('book')"", 'and', 'kutub', ""('books')."", 'It', 'is', 'interesting', 'to', 'note', 'that', 'the', 'traditional', 'approach', 'to', 'Arabic', 'roots', 'results', 'in', 'approximately', '10,000', 'different', 'items.', 'This', 'number', 'corresponds', 'more', 'closely', 'to', 'the', 'number', 'of', 'simple', 'lexemes', 'to', 'be', 'expected', 'in', 'the', 'lexicon', 'of', 'a', 'language', 'than', 'to', 'the', 'number', 'of', 'lexemes.', 'It', 'is', 'then', 'not', 'surprising', 'to', 'find', 'items', 'such', 'as', 'kaatib', ""('writer'),"", 'kutib', ""('be"", ""written')"", 'with', 'the', 'same', 'root.', '11', 'In', 'principle', 'we', 'could', 'of', 'course', 'reverse', 'the', 'entire', 'system.', 'Thus,', 'languages', 'such', 'as', 'Navajo,', 'which', 'use', 'only', 'prefixation,', 'are', 'not', 'a', 'major', 'problem.', '12', 'There', 'is', 'of', 'course', 'a', 'different', 'prefixation', 'process', 'attaching', 'un-to', 'a', 'verb', 'as', 'in', 'undo,', 'but', 'it', 'would', 'yield', 'the', 'wrong', 'analysis', 'for', 'unacceptable.', 'The', 'word', 'means', ""'which"", 'cannot', 'be', ""accepted',"", 'not', ""'which"", 'can', 'be', ""unaccepted'.""]",9,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0398aae2-5054-4ed3-b12f-25f38be79e3e,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models'],['2021'],['Hannah Kirk;Yennie Jun;Haider Iqbal;Elias Benussi;Filippo Volpin;Frederic Dreyer;Aleksandar Shtedritski;Yuki Asano'],single,"['In', 'this', 'paper,', 'we', 'focus', 'on', 'measuring', 'and', 'mitigating', 'gender-biased', 'language', 'in', 'machine-generated', 'job', 'ads,', 'a', 'use', 'case', 'of', 'large-scale', 'language', 'models', 'which', 'risks', 'representational', 'and', 'allocational', 'harms', '<ref type=""single"">(Blodgett et al., 2020).</ref>', 'Representational', 'harms', 'come', 'from', 'the', 'conditioning', 'of', 'a', ""job's"", 'suitability', 'to', 'a', 'given', 'individual', 'based', 'on', 'their', 'gender.', 'When', 'jobs', 'are', 'valued', 'unequally', '(either', 'by', 'financial,', 'social', 'or', 'intellectual', 'status),', 'this,', 'in', 'turn,', 'can', 'reinforce', 'gendered', 'power', 'hierarchies', 'and', 'negative', 'societal', 'divisions.', 'Gender-biased', 'language', 'may', 'result', 'in', 'an', 'unequal', 'distribution', 'of', 'job', 'applications', 'if', 'it', 'dissuades', 'gender-diverse', 'candidates', 'from', 'applying', '<ref type=""single"">(Gaucher et al., 2011).</ref>', 'Thus,', 'allocational', 'harms', 'are', 'relevant', 'where', 'labour', 'market', 'opportunities,', 'financial', 'remuneration', 'or', 'job', 'stability', 'are', 'preferentially', 'granted', 'based', 'on', 'gender.', 'We', 'know', 'from', 'prior', 'NLP', 'research', 'that', 'GPT', 'models', 'reflect', 'occupational', 'stereotypes', 'in', 'society', '<ref type=""single"">(Kirk et al., 2021),</ref>', 'confirming', 'the', 'risk', 'of', 'representational', 'harm,', 'but', 'not', 'how', 'this', 'translates', 'into', 'allocational', 'harms', 'in', 'applied', 'settings.', 'To', 'measure', 'bias,', 'our', 'experiment', 'employs', 'lists', 'of', 'gender-coded', 'words.', 'These', 'lists', 'are', 'potentially', 'in', 'themselves', 'biased,', 'having', 'been', 'defined', 'by', 'a', 'research', 'group', 'under', 'a', 'particular', 'cultural', 'bias', 'or', 'as', 'the', 'result', 'of', 'biased', 'data.', 'To', 'mitigate', 'this', 'concern,', 'we', 'use', 'multiple', 'measures', 'to', 'cover', 'the', 'blind', 'spots', 'or', 'specific', 'biases', 'present', 'in', 'any', 'single', 'list.', 'However,', 'our', 'proposed', 'metric', 'may', 'better', 'capture', 'the', 'most', 'obvious,', 'text-level', 'aspects', 'of', 'gender-biased', 'language', 'and', 'will', 'be', 'less', 'effective', 'to', 'find', 'covert,', 'but', 'equally', 'as', 'damaging,', 'forms', 'of', 'gender', 'bias', 'in', 'job', 'ads,', 'or', 'job', 'search', 'more', 'broadly.']",124,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
04391904-fa5d-4403-be75-ab490e07b577,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters'],['2020'],['Jeff Rasley;Samyam Rajbhandari;Olatunji Ruwase;Yuxiong He'],single,"['Leveraging', 'sparsity', 'of', 'matrices', 'We', 'considered', 'the', 'option', 'of', 'performing', 'matrix', 'products', 'involving', 'large', 'sparse', 'matrices', '(Lines', '8,', '15,', '21,', '25', 'in', 'our', 'pseudo-code', '(§2.2))', 'by', 'representing', 'them', 'in', ""PyTorch's"", 'torch.sparse_coo_tensor', 'format', 'and', 'using', 'the', 'torch.sparse', 'framework', 'to', 'explicitly', 'leverage', 'their', 'sparsity', 'for', 'saving', 'compute.', 'Unfortunately,', 'the', 'results', 'were', 'not', 'encour-', 'aging', 'even', 'for', 'k', '=', '1%', 'of', 'number', 'of', 'keys', '(Figure', '4).', 'While', 'future', 'devices', 'might', 'allow', 'faster', 'sparsedense', 'products,', 'in', 'the', 'immediate', 'future,', 'one', 'can', 'leverage', 'block-sparse', 'kernels', '<ref type=""group"">(Child et al., 2019, Tillet et al., 2019)</ref>', 'which', 'have', 'been', 'successfully', 'used', 'for', 'such', 'products', '<ref type=""single"">(Rasley et al., 2020).</ref>']",89,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
049f1ee0-c587-4ac0-aba1-fc75f686f73a,A User-Based Usability Assessment of Raw Machine Translated Technical Instructions,2012,Stephen Doherty;Sharon O'brien,['Eye Tracking Methodology: Theory and Practice'],['2007'],['A Duchowski'],single,"['We', 'have', 'also', 'collated', 'eye', 'tracking', 'measurements', 'such', 'as', 'total', 'fixation', 'counts,', 'average', 'fixation', 'duration', 'and', 'percentage', 'change', 'in', 'pupil', 'dilation,', 'all', 'of', 'which', 'are', 'shown', 'to', 'be', 'indicators', 'of', 'cognitive', 'load', '<ref type=""single"">(Duchowski, 2007).</ref>']",32,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
04c5b379-d47b-4491-adde-3ad18bcfbb2c,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['The', 'Symlink', 'track', 'at', 'SemEval-2022', 'received', '4', 'system', 'description', 'paper', 'submissions', 'presented', 'in', 'Table', '2.', 'Overall,', 'all', 'submitted', 'systems', 'are', 'based', 'on', 'BERT', 'architecture', '<ref type=""single"">(Devlin et al., 2019).</ref>', 'Among', 'those,', 'two', 'out', 'of', 'four', 'systems', 'use', 'SciBERT', '<ref type=""single"">(Beltagy et al., 2019),</ref>', 'while', 'two', 'remaining', 'systems', 'use', 'other', 'variants', 'of', 'BERT', 'such', 'as', 'original', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'and', 'mBERT', '<ref type=""single"">(Devlin et al., 2019).</ref>']",48,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3]"
05134017-3dff-4d67-8ef1-9385c1586b3b,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,['Microsoft coco: Common objects in context'],['2014'],['Tsung-Yi Lin;Michael Maire;Serge Belongie;James Hays;Pietro Perona;Deva Ramanan;Piotr Dollár;C Lawrence Zitnick'],single,"['We', 'perform', 'pretraining', 'on', 'two', 'widely-used', 'indomain', 'datasets:', 'MSCOCO', 'Caption', '<ref type=""single"">(Lin et al., 2014)</ref>', 'and', 'Visual', 'Genome', '<ref type=""single"">(Krishna et al., 2016),</ref>', 'and', 'validate', 'the', 'learned', 'multi-modal', 'representations', 'on', 'five', 'well-known', 'visual-language', 'tasks:', 'Visual', 'Question', 'Answering', '(VQA),', 'Imagetext', 'retrieval,', 'Nature', 'Language', 'Visual', 'Reasoning', '(NLVR', '2', '),', 'Visual', 'Entailment', '(VE)', 'and', 'Visual', 'Commonsense', 'Reasoning', '(VCR).', 'Empirical', 'results', 'show', 'that', 'our', 'method', 'outperforms', 'the', 'state-of-theart', 'end-to-end', 'approaches', 'by', 'a', 'sizeable', 'margin.', 'To', 'better', 'understand', 'our', 'method,', 'we', 'also', 'provide', 'a', 'detailed', 'ablation', 'study', 'and', 'visualization.']",10,"[3, 3, 3, 2, 2, 2, 3, 3, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
05404c91-fa18-4f54-aae7-192d87bbccfa,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['unknown'],['2020'],['Dorottya Demszky;Dana Movshovitz-Attias;Jeongwoo Ko;Alan Cowen;Gaurav Nemade;Sujith Ravi'],single,"['Binary', 'refers', 'to', 'positive', 'and', 'negative,', 'and', 'ternary', 'refers', 'to', 'positive,', 'negativeand', 'neutral.', 'For', 'binary', 'evaluations', 'we', 'categorized', 'anger,', 'disgust,', 'fear,', 'and', 'sadness', 'as', 'negative,', 'and', 'anticipation,', 'joy,', 'and', 'trust', 'as', 'positive.', 'Surprise', 'was', 'either', 'discarded', 'or', 'included', 'as', 'a', 'separate', 'category', '(see', 'table', '7).', 'For', 'this', 'classification', 'task', 'BERT', 'achieved', 'macro', 'f1', 'scores', 'of', '0.536', 'and', 'accuracies', 'of', '0.544.', 'This', 'is', 'comparable', 'to', 'other', 'similar', 'datasets', 'when', 'classes', 'are', 'merged', '(e.g.', '<ref type=""single"">Demszky et al. (2020)</ref>', ').']",72,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1]"
062d7b40-3fc9-45ea-8dca-b119795c3c0e,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,['A Generic Model for Reusable Lexicons: The Genelex Project'],['1994'],['M Antoni-Lay;G Francopoulo;L Zaysser'],single,"['Model:', 'The', 'PAROLE', 'Lexicon', 'model', 'for', 'Morphosyntax', 'and', 'Syntax', 'is', 'based', 'on', 'the', 'results', 'of', 'EAGLES', '<ref type=""single"">(Sanfilippo et al. 1996)</ref>', 'and', 'EUREKA', 'GENELEX', '<ref type=""single"">(Antoni-Lay et al. 1994),</ref>', 'further', 'developed', 'within', 'the', 'PAROLE', 'project', '<ref type=""single"">(Calzolari, Montemagni, Pirrelli 1996).</ref>', 'Thanks', 'to', 'that', 'all', 'the', 'lexical', 'resources', 'are', 'declarative,', 'theory', 'and', 'application', 'independent,', 'harmonised,', 'multifunctional,', 'and', 'able', 'to', 'evolve', 'easily,', 'for', 'example', 'to', 'incorporate', 'other', 'levels', 'of', 'information', 'or', 'to', 'become', 'multilingual.', 'This', 'approach,', 'which', 'answers', 'to', 'the', 'requisites', 'of', 'generality,', 'explicitness,', 'and', 'variability', 'of', 'granularity,', 'guarantees', 'a', 'large', 'scale', 'reusability.']",20,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
06567b6e-2654-4f02-a8fe-3aebf9bcc855,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,"['Are sixteen heads really better than one?', ""What does bert look at? an analysis of bert's attention"", 'unknown', 'What do neural machine translation models learn about morphology?']","['2019', '2019', 'unknown', '2017']","['Paul Michel;Omer Levy;Graham Neubig', 'Kevin Clark;Urvashi Khandelwal;Omer Levy;Christopher D Manning', 'unknown', 'Yonatan Belinkov;Nadir Durrani;Fahim Dalvi;Hassan Sajjad;James Glass']",group,"['The', 'acclaimed', 'success', 'of', 'Transformer-based', 'models', 'across', 'NLP', 'tasks', 'has', 'been', 'followed', 'by', 'two', 'important', 'directions', 'of', 'research.', 'In', 'the', 'first', 'direction,', 'interpretability', 'studies', 'aim', 'to', 'understand', 'how', 'these', 'models', 'work.', 'Given', 'that', 'multi-headed', 'attention', 'is', 'an', 'important', 'feature', 'of', 'these', 'models,', 'researchers', 'have', 'focused', 'on', 'attention', 'heads', 'as', 'the', 'units', 'of', 'interpretation.', 'These', 'studies', 'comment', 'on', 'the', 'role', 'of', 'each', 'attention', 'head', 'and', 'the', 'relation', 'between', 'a', ""head's"", 'position', 'and', 'its', 'significance', '<ref type=""group"">(Clark et al., 2019, Michel et al., 2019, Voita et al., 2019b,a, Liu et al., 2019, Belinkov et al., 2017).</ref>', 'These', 'studies', 'show', 'that', 'certain', 'heads', 'are', 'more', 'important', 'based', 'on', '(i)', 'their', 'position', 'in', 'the', 'network', '(top,', 'middle,', 'bottom),', 'or', '(ii)', 'the', 'component', 'to', 'which', 'they', 'belong', '(encoder', 'self-attention,', 'decoder', 'self-attention,', 'encoder-decoder', 'cross', 'attention),', 'or', '(iii)', 'the', 'functional', 'role', 'they', 'play', '(e.g.,', 'syntactic/semantic).']",73,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3]"
0712b528-4adf-40ef-9cae-d4de17a6825f,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['Curriculum', 'Diversity.', 'The', 'variations', 'in', 'the', 'combinations', 'of', 'quests', 'and', 'worlds', 'themselves', 'seen', 'at', 'training', 'time', 'has', 'potential', 'to', 'effect', 'zero-shot', 'performance', '<ref type=""single"">(Samvelyan et al., 2021).</ref>', 'We', 'introduce', 'two', 'baselines', 'that', 'change', 'the', 'relative', 'diversities', 'of', 'resulting', 'quests', 'in', 'the', 'curriculums,', 'to', 'contrast', 'with', 'our', 'proposed', 'procedural', 'generation', 'pipeline.', 'Generated', 'quest', 'details', 'are', 'found', 'in', 'Appendix', 'A.5.']",22,"[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
07e1efd0-b4a4-4d31-9e70-2c4af8b833f0,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Emonet: Fine-grained emotion detection with gated recurrent neural networks'],['2017'],['Muhammad Abdul;-Mageed unk;Lyle Ungar'],single,"['In', 'table', '1', 'we', 'have', 'gathered', 'some', 'of', 'the', 'most', 'significant', 'emotion', 'datasets', 'in', 'relation', 'to', 'this', 'study.', 'The', 'table', 'lists', 'the', 'paper', 'in', 'which', 'the', 'dataset', 'was', 'released', '(study),', 'what', 'the', 'source', 'data', 'that', 'was', 'used', 'was', '(source),', 'what', 'model', 'was', 'used', 'to', 'obtain', 'the', 'best', 'evaluation', 'scores', '(model),', 'the', 'number', 'of', 'categories', 'used', 'for', 'annotation', '(cat),', 'whether', 'the', 'system', 'was', 'multilabel', 'or', 'not', '(multi),', 'and', 'the', 'macro', 'f1', 'scores', 'and', 'accuracy', 'score', 'as', 'reported', 'by', 'the', 'paper', '(macro', 'f1', 'and', 'accuracy', 'respectively).', 'Some', 'papers', 'only', 'reported', 'a', 'micro', 'f1', 'and', 'no', 'macro', 'f1', 'score.', 'These', 'scores', 'have', 'been', 'marked', 'with', 'a', 'µ.', 'The', 'datasets', 'in', 'table', '1', 'differ', 'from', 'each', 'so', 'much', 'in', 'content,', 'structure,', 'and', 'manner', 'of', 'annotation', 'that', 'direct', 'comparisons', 'are', 'hard', 'to', 'make.', 'Typically,', 'the', 'fewer', 'the', 'number', 'of', 'categories,', 'the', 'easier', 'the', 'classification', 'task', 'and', 'the', 'higher', 'the', 'evaluation', 'scores.', 'It', 'stands', 'to', 'reason', 'that', 'the', 'easier', 'it', 'is', 'to', 'detect', 'emotions', 'in', 'the', 'source', 'data,', 'the', 'easier', 'it', 'is', 'for', 'annotators', 'to', 'identify', 'and', 'agree', 'upon', 'annotation', 'labels', 'and', 'therefore', 'it', 'becomes', 'easier', 'for', 'the', 'system', 'or', 'model', 'to', 'correctly', 'classify', 'the', 'test', 'data', 'as', 'well.', 'The', 'outlier', 'in', 'these', 'datasets', 'is', 'EmoNet', '<ref type=""single"">(Abdul-Mageed and Ungar, 2017)</ref>', 'which', 'achieved', 'astonishing', 'accuracies', 'by', 'using', '665', 'different', 'hashtags', 'to', 'automatically', 'categorize', '1.6', 'million', 'tweets', 'into', '24', 'categories', ""(Plutchik's"", '8', 'at', '3', 'different', 'intensities),', 'unfortunately', 'neither', 'the', 'dataset', 'or', 'their', 'model', 'has', 'been', 'made', 'available', 'for', 'closer', 'inspection.']",200,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
0882b8fb-ec05-44b9-bc00-4b7078c2e368,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['chrF: character n-gram F-score for automatic MT evaluation'],['2015'],['Maja Popović'],single,"['ChrF', '<ref type=""single"">(Popović, 2015)</ref>', 'a', 'character', 'n-gram', 'precision', 'and', 'recall', 'enhanced', 'with', 'word', 'n-grams.', 'Since', 'answers', 'are', 'largely', 'made', 'up', 'of', 'entities,', 'ChrF', 'score', 'integration', 'is', 'only', 'performed', 'when', 'the', 'answer', 'span', 'is', 'not', 'present', 'in', 'the', 'related', 'context.', 'In', 'order', 'to', 'evaluate', 'the', 'quality', 'of', 'the', 'translation,', 'we', 'manually', 'corrected', 'the', 'translation', 'errors', 'in', 'the', 'output', 'of', 'a', 'subset', 'of', 'the', 'corpus', 'composed', 'of', '890', 'QA', 'pairs', 'and', '107', 'contexts.', 'We', 'obtain', 'a', 'BLEU', 'score', '<ref type=""single"">(Papineni et al., 2002)</ref>', 'We', 'also', 'explore', 'mixed', 'datasets', 'training', 'strategy', 'with', 'SQuAD-en', 'train', '+', 'FQuAD', 'train', 'for', 'training', 'models', 'on', 'a', 'concatenation', 'of', 'the', 'training', 'data', 'covering', 'French-English', 'language', 'pairs', 'to', 'test', 'the', 'crosslingual', 'transfer', 'ability', 'of', 'multilingual', 'models.']",1,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0918f617-140a-46b7-99fc-e9e4b2634017,SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering,2020,Aishwarya Ashok;Ganapathy Natarajan;Ramez Elmasri;Laurel Smith-Stvan,"['Addressing complex and subjective product-related queries with customer reviews', 'Aware answer prediction for product-related questions incorporating aspects', 'Reading customer reviews to answer product-related questions']","['2016', '2018', '2019']","['Julian Mcauley;Alex Yang', 'Qian Yu;Wai Lam', 'Chao Miao Fan;Mingming Feng;Ping Sun;Haifeng Li;unk Wang']",group,"['The', 'correct', 'answer', 'and', 'at', 'least', '50%', 'were', 'inspired', 'by', 'the', 'accuracy', '@', 'x%', 'approach', 'used', 'by', 'different', 'authors', 'working', 'with', 'the', 'Amazon', 'dataset', 'and', 'performing', 'similar', 'tasks', '<ref type=""group"">(Fan et al., 2019, McAuley and Yang, 2016, Yu and Lam, 2018).</ref>', 'In', 'accuracy', '@', 'x%', 'the', 'commonly', 'used', 'measure', 'is', 'accuracy', '@', '50%.', 'This', 'approach', 'helps', 'in', 'identifying', 'the', 'top', 'answers', 'crossing', 'a', 'threshold', 'and', 'has', 'better', 'relationship', 'in', 'real', 'world', 'applications', '<ref type=""single"">(Fan et al., 2019).</ref>']",28,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
092339e6-33e1-4333-99e6-223e745a4b19,Themes in the work of Margaret Masterman,1988,Yorick Wilks,"['Bar-Hillel, Y. The present state of research on mechanical translation']",['1953'],['R Amsler'],single,"['In', 'recent', 'years', 'there', 'has', 'been', 'some', 'revival', 'of', 'interest', 'in', 'computational', 'lexicography', 'that', 'has', 'fulfilled', 'some', 'of', ""MMB's"", 'hopes', 'and', 'dreams.', 'It', 'has', 'been', 'driven', 'to', 'some', 'extent', 'by', 'the', 'availability', 'from', 'publishers', 'of', 'machine-readable', 'English', 'dictionaries,', 'such', 'as', ""Longman's"", 'dictionary', 'of', 'contemporary', 'English', '(LDOCE)', 'and', 'Collins-Birmingham', 'University', 'International', 'Language', 'Database', '(COBUILD),', 'with', 'definitions', 'written', 'in', 'a', 'semi-formal', 'way.', 'This', 'makes', 'it', 'much', 'easier', 'for', 'a', 'computational', 'parser', 'to', 'extract', 'information', 'from', 'them.', 'But', 'the', 'initial', 'work', 'in', 'the', 'current', 'wave', 'was', 'done', 'by', '<ref type=""single"">Amsler (1980)</ref>', 'at', 'Texas', 'using', ""Webster's,"", 'an', 'oldfashioned', 'dinosaur', 'of', 'a', 'dictionary.', 'He', 'developed', 'a', 'notion', 'of', ""'tangled"", ""hierarchies'"", 'which', 'captures', 'the', 'notion', 'MMB', 'promoted', 'so', 'as', 'to', 'get', 'away', 'from', 'straightforward', 'tree-like', 'hierarchies.']",85,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
09242a6b-0b17-4069-be28-ada153a96937,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['Assessing the benchmarking capacity of machine reading comprehension datasets'],['2020'],['Saku Sugawara;Pontus Stenetorp;Kentaro Inui;Akiko Aizawa'],single,"['Random', 'named', 'entity:', 'the', 'majority', 'of', 'answers', 'in', 'Quoref', 'are', 'person', 'names.', 'To', 'evaluate', 'this', 'artifact,', 'we', 'randomly', 'select', 'a', 'PERSON', 'named', 'entity', 'from', 'the', 'context', 'as', 'the', 'answer.', '3', 'Wh-word', '<ref type=""single"">(Weissenborn et al., 2017):</ref>', 'to', 'recognize', 'the', 'QA', 'pairs', 'that', 'can', 'be', 'answered', 'by', 'only', 'using', 'the', 'interrogative', 'adverbs', 'from', 'the', 'question,', 'we', 'train', 'a', 'model', 'on', 'a', 'variation', 'of', 'the', 'training', 'dataset', 'in', 'which', 'questions', 'only', 'contain', 'interrogative', 'adverbs.', 'Empty', 'question', '<ref type=""single"">(Sugawara et al., 2020):</ref>', 'to', 'recognize', 'QA', 'pairs', 'that', 'are', 'answerable', 'without', 'considering', 'the', 'question,', '4', 'we', 'train', 'a', 'QA', 'model', 'only', 'on', 'the', 'contexts', 'and', 'without', 'questions.', 'Semantic', 'overlap', '<ref type=""single"">(Jia and Liang, 2017):</ref>', 'for', 'this', 'artifact,', 'we', 'report', 'the', 'ratio', 'of', 'the', 'QA', 'pairs', 'whose', 'answers', 'lie', 'in', 'the', 'sentence', 'of', 'the', 'context', 'that', 'has', 'the', 'highest', 'semantic', 'similarity', 'to', 'the', 'question.', 'We', 'use', 'sentence-BERT', '<ref type=""single"">(Reimers and Gurevych, 2019)</ref>', 'to', 'find', 'the', 'most', 'similar', 'sentence.', 'Short', 'distance', 'reasoning:', 'for', 'this', 'bias,', 'we', 'train', 'a', 'model', 'only', 'using', 'the', 'sentence', 'of', 'the', 'context', 'that', 'is', 'the', 'most', 'similar', 'to', 'the', 'question,', 'instead', 'of', 'the', 'whole', 'context.', 'We', 'exclude', 'the', 'question-answer', 'pairs', 'in', 'which', 'the', 'most', 'similar', 'sentence', 'does', 'not', 'contain', 'the', 'answer.', 'This', 'model', 'will', 'not', 'learn', 'to', 'perform', 'coreference', 'reasoning', 'when', 'the', 'related', 'coreferring', 'pairs', 'are', 'not', 'in', 'the', 'same', 'sentence.']",70,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
092bd072-8d20-4162-aea7-1fdb9fbe8e1a,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Character-aware neural language models'],['2016'],['Yoon Kim;Yacine Jernite;David Sontag;Alexander M Rush'],single,"['In', 'order', 'to', 'generate', 'character', 'embeddings', 'from', 'the', 'input', 'sentence,', 'we', 'first', 'use', 'a', 'CharCNN', '<ref type=""single"">(Kim et al., 2016).</ref>', 'Let', 'C', 'be', 'the', 'dictionary', 'of', 'all', 'the', 'characters', 'in', 'the', 'language', 'and', 'V', 'be', 'all', 'the', 'words', 'in', 'the', 'language.', 'We', 'first', 'define', 'the', 'character', 'embeddings', 'matrix', 'E', '∈', 'R', 'd×|C', '|,', 'where', 'd', 'is', 'the', 'dimensionality', 'of', 'the', 'character', 'embeddings,', 'with', 'the', 'constraint', 'that', 'd', '&lt,', '|C', '|.', 'Let', 'word', 'w', 'i', '∈', 'V', 'c', 'w', 'i', '=', '[c', 'w', 'i', '1,', 'c', 'w', 'i', '2', ',...,', 'c', 'w', 'i', 'n', '].', 'The', 'character', 'representation', 'of', 'w', 'i', 'is', 'therefore', 'given', 'by', 'E', 'w', 'i', '∈', 'R', 'd×n.']",15,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
095a1d93-99b1-47e4-90d8-a93c40b0daf4,A Parameter-Based Message-Passing Parser for MT of Korean and English,1994,Bonnie Dorr;Jye-Hoon Lee;Sungki Suh,['Interlingual machine translation: a parameterized approach'],['1993'],['B Dorr'],single,"['We', 'have', 'just', 'seen', 'that', 'certain', 'types', 'of', 'syntactic', 'parameterization', 'may', 'be', 'captured', 'in', 'the', 'grammar', 'network', '(e.g.,', 'Xbar', 'parameters', 'such', 'as', 'constituent', 'order).', 'In', 'addition', 'to', 'these,', 'there', 'are', 'syntactic', 'parameters', 'that', 'must', 'be', 'programmed', 'into', 'the', 'message-passing', 'mechanism', 'itself,', 'not', 'just', 'into', 'the', 'grammar', 'network.', 'Figure', '2', 'shows', 'the', 'syntactic', 'parameter', 'settings', 'for', 'English', 'and', 'Korean.', 'The', 'English', 'settings', 'are', 'drawn', 'from', '<ref type=""single"">Dorr (1993b).</ref>', 'The', 'same', 'paradigm', 'was', 'followed', 'in', 'our', 'analysis', 'of', 'Korean', 'parameters.', 'The', 'remainder', 'of', 'this', 'paper', 'will', 'focus', 'on', 'how', 'we', 'automatically', 'precompile', 'the', 'English', 'and', 'Korean', 'parameter', 'settings', 'concerning', 'Xbar', 'theory', 'into', 'the', 'grammar', 'network', '(i.e.,', 'Basic', 'Categories,', 'Pre-tenninals,', 'Constituent', 'Order,', 'Specifiers,', 'and', 'Adjunction).']",64,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
09946730-d0ff-4972-8910-70cdbe86d9b0,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Pointer sentinel mixture models'],['2016'],['Stephen Merity;Caiming Xiong;James Bradbury;Richard Socher'],single,"['language', 'features,', 'which', 'can', 'be', 'fine-tuned', 'for', 'applications', 'like', 'semantic', 'analysis', 'and', 'question', 'answering.', 'Multi-lingual-BERT', '(mBERT)', 'is', 'a', 'BERT', 'model', 'pre-trained', 'using', 'the', 'Wikipedia', 'text', 'corpus', '<ref type=""single"">(Merity et al., 2016)</ref>', 'in', 'more', 'than', '100', 'languages', 'around', 'the', 'world.', 'XLM-RoBERTa', '<ref type=""single"">(Conneau et al., 2020)</ref>', 'scaled', 'this', 'idea', 'with', 'more', 'than', '2', 'terabytes', 'of', 'common', 'crawl', 'data.']",26,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
099c645b-10b7-47e1-963f-1a9aaa776bc1,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Hiring now: A skill-aware multi-attention model for job posting generation'],['2020'],['Liting Liu;Jie Liu;Wenzheng Zhang;Ziming Chi;Wenxuan Shi;Yalou Huang'],single,"['On', 'realism,', 'while', 'we', 'proxied', 'realism', 'with', 'a', 'classifier', 'and', 'validated', 'these', 'results', 'in', 'a', 'small-scale', 'experiment', 'with', 'human', 'annotators,', 'more', 'work', 'is', 'needed', 'to', 'assess', 'reactions', 'to', 'machine-written', 'ads', '""in', 'the', 'wild"".', 'Furthermore,', 'while', 'fine-tuning', 'and', 'prompt-engineering', 'increased', 'realism', 'in', 'the', 'aggregate,', 'some', 'job', 'ads', 'were', 'still', 'nonsensical', 'or', 'simply', 'parroted', 'the', 'prompt', 'text,', 'e.g.,', '""The', 'job', 'ad', 'should', 'not', 'have', 'any', 'biases', 'in', 'it."".', 'We', 'briefly', 'assess', 'some', 'outputs', 'qualitatively', 'in', 'Appendix', 'F', 'but', 'make', 'our', 'bias', 'measure', 'generation', 'process', 'publicly', 'available', 'to', 'encourage', 'more', 'human-directed', 'assessments', 'of', 'bias', 'and', 'realism.', '9', 'It', 'remains', 'to', 'be', 'seen', 'whether', 'realism', '(as', 'measured', 'by', 'similarity', 'to', 'human-authored', 'ads)', 'is', 'a', 'necessary', 'characteristic', 'for', 'success', '(as', 'measured', 'by', 'the', 'number', 'of', 'applications).', 'Prior', 'research', 'identifies', 'fluency', 'and', 'a', 'clear', 'presentation', 'of', 'relevant', 'skills', 'and', 'experience', 'as', 'relevant', 'to', 'the', 'creation', 'of', 'a', '""good""', 'job', 'ad', '<ref type=""single"">(Liu et al., 2020),</ref>', 'but', 'it', 'is', 'not', 'clear', 'whether', 'an', 'ad', 'must', 'appear', 'human-written', 'to', 'achieve', 'this.', 'Our', 'assumption', 'for', 'this', 'project', 'is', 'that', 'human-written', 'job', 'ads', 'follow', 'styles,', 'conventions', 'and', 'a', 'level', 'of', 'detail', 'that', 'effectively', 'encourage', 'prospective', 'employees', 'to', 'apply,', 'but', 'further', 'research', 'is', 'required', 'to', 'understand', 'whether', 'ads', 'clearly', 'identified', 'as', 'machine-written', 'can', 'be', 'equally', 'or', 'more', 'effective', 'in', 'this', 'regard.']",144,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
09b50114-c9a9-4583-9ed6-9798d995ae7e,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['Billion-scale similarity search with gpus'],['2019'],['Jeff Johnson;Matthijs Douze;Hervé Jégou'],single,"['Inference', 'In', 'our', 'implementation,', 'we', 'use', 'FAISS', '<ref type=""single"">(Johnson et al., 2019)</ref>', 'to', 'index', 'the', 'dense', 'representations', 'of', 'all', 'passages.', 'Specifically,', 'we', 'use', 'IndexFlatIP', 'for', 'indexing', 'and', 'the', 'exact', 'maximum', 'inner', 'product', 'search', 'for', 'querying.']",7,"[0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0a1bada6-98d3-461f-9ac1-1e41c2d641f8,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,"['BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension']",['2020'],['Mike Lewis;Yinhan Liu;Naman Goyal ; Abdelrahman Mohamed;Omer Levy;Veselin Stoyanov;Luke Zettlemoyer'],single,"['We', 'train', 'two', 'BART', '<ref type=""single"">(Lewis et al., 2020)</ref>', 'models', 'that', 'encodes', 'input', 'information', 'via', 'a', 'bidirectional', 'transformer', 'encoder', 'and', 'decodes', 'autoregressively:', 'the', 'first', 'takes', 'as', 'input', 'character', 'and', 'location', 'information', 'and', 'produces', 'a', 'short', 'motivation', '(Section', '2),', 'the', 'second', 'takes', 'as', 'input', 'character,', 'location', 'information,', 'short', 'motivation', 'and', 'produces', 'the', 'sequence', 'of', 'LIGHT', 'game', 'engine', 'executable', 'actions', 'needed', 'to', 'achieve', 'the', 'motivation.', 'This', 'sequence', 'of', 'actions', 'is', 'provided', 'by', 'the', 'human', 'expert', 'demonstrations', 'as', 'mentioned', 'in', 'Section', '2.']",4,"[2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0a41bef5-c4ec-45b4-bb27-eb0391a40b4a,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Phonologically aware neural model for named entity recognition in low resource transfer settings'],['2016'],['Akash Bharadwaj;David Mortensen;Chris Dyer;Jaime Carbonell'],single,"['There', 'have', 'been', 'a', 'series', 'of', 'attempts', 'to', 'utilize', 'phonetic', 'representations', 'of', 'language', 'to', 'improve', 'or', 'extend', 'automatic', 'speech', 'recognition', '(ASR)', 'models.', 'Some', 'of', 'these', 'jointly', 'model', 'text', 'and', 'audio', 'data', 'using', 'sequences', 'of', 'phonemes', 'combined', 'with', 'sequences', 'of', 'text', 'characters.', '<ref type=""single"">Sundararaman et al. (2021),</ref>', 'for', 'example,', 'uses', 'a', 'joint', 'transformer', 'architecture', 'that', 'encodes', 'sequences', 'of', 'phonemes', 'and', 'sequences', 'of', 'text', 'simultaneously.', 'However,', 'this', 'joint', 'model', 'is', 'utilized', 'to', 'learn', 'representations', 'that', 'are', 'more', 'robust', 'to', 'transcription', 'errors.', 'The', 'architecture', 'still', 'requires', 'text', 'inputs', '(from', 'ASR', 'transcriptions)', 'and', 'generates', 'outputs', 'in', 'both', 'text', 'and', 'phoneme', 'representations.', 'In', 'contrast,', 'our', 'approach', 'allows', 'for', 'text', 'input,', 'audio', 'input,', 'or', 'text', 'plus', 'audio', 'input', 'to', 'language', 'models.', 'Similarly,', 'in', '<ref type=""single"">(Chaudhary et al., 2018)</ref>', 'and', '<ref type=""single"">(Bharadwaj et al., 2016)</ref>', 'investigate', 'the', 'potential', 'of', 'phoneme-based', 'or', 'phoneme', 'aware', 'representations', 'and', 'models,', 'showing', 'gains', 'in', 'performance,', 'language', 'transfer,', 'and', 'flexibility', 'across', 'written', 'scripts.', 'These', 'works', 'conduct', 'training', 'on', 'text-based', 'data', 'only,', 'using', 'Epitran', 'to', 'convert', 'to', 'phonemes.', '<ref type=""single"">Baevski et al. (2021)</ref>', 'transforms', 'unlabeled', 'text', '(i.e.,', 'not', 'aligned', 'with', 'corresponding', 'audio', 'files)', 'into', 'phonemes', 'in', 'a', 'scheme', 'to', 'train', 'speech', 'recognition', 'models', 'without', 'any', 'labeled', 'data.', 'This', 'scheme', 'involves', 'a', 'generator', 'model', 'trained', 'jointly', 'with', 'a', 'discriminator', 'model.', 'The', 'generator', 'model', 'converts', 'audio,', 'segmented', 'into', 'phonetic', 'units', 'into', 'predicted', 'phonemes,', 'and', 'the', 'discriminator', 'model', 'attempts', 'to', 'discriminate', 'between', 'these', 'predicted', 'phonemes', 'and', 'the', 'phonemes', 'transliterated', 'from', 'unlabeled', 'text.', 'Although', 'both', 'text', 'and', 'audio', 'are', 'utilized', 'in', 'this', 'work,', 'they', 'are', 'not', 'input', 'to', 'the', 'same', 'model', 'and', 'the', 'primary', 'output', 'of', 'the', 'training', 'scheme', 'is', 'a', 'model', 'that', 'creates', 'good', 'phonetic', 'speech', 'representations', 'from', 'input', 'audio.']",115,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0a580572-1242-490a-8010-9c7d91226b8f,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Mixture content selection for diverse sequence generation'],['2019'],['Jaemin Cho;Minjoon Seo;Hannaneh Hajishirzi'],single,"['Generating', 'multiple', 'valid', 'outputs', 'given', 'a', 'source', 'sequence', 'has', 'a', 'wide', 'range', 'of', 'applications,', 'such', 'as', 'machine', 'translation', '<ref type=""single"">(Shen et al., 2019),</ref>', 'paraphrase', 'generation', '<ref type=""single"">(Gupta et al., 2018),</ref>', 'question', 'generation', '<ref type=""single"">(Cho et al., 2019),</ref>', 'dialogue', 'system', '<ref type=""single"">(Dou et al., 2021),</ref>', 'and', 'story', 'generation', '<ref type=""single"">(Yu et al., 2021).</ref>', 'For', 'example,', 'in', 'machine', 'translation,', 'there', 'are', 'often', 'many', 'plausible', 'and', 'semantically', 'equivalent', 'translations', 'due', 'to', 'information', 'asymmetry', 'between', 'different', 'languages', '<ref type=""single"">(Lachaux et al., 2020).</ref>']",24,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0a5fef3d-0b6d-425f-8c6b-861799eab3dd,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Opensubtitles2016: Extracting large parallel corpora from movie and tv subtitles'],['2016'],['Pierre Lison;Jörg Tiedemann ; Khalid;Thierry Choukri;Sara Declerck;Marko Goggi;Bente Grobelnik;Joseph Maegaard;unk Mariani'],single,"['We', 'use', 'the', 'OPUS', '<ref type=""single"">(Lison and Tiedemann, 2016)</ref>', 'parallel', 'movie', 'subtitle', 'corpus', 'of', 'subtitles', 'collected', 'from', 'opensubtitles.org', 'as', 'a', 'multi-domain', 'proxy.', 'As', 'the', 'movies', 'we', 'use', 'for', 'source', 'data', 'cover', 'several', 'different', 'genres', 'and,', 'although', 'scripted,', 'represents', 'real', 'human', 'language', 'used', 'in', 'a', 'multitude', 'of', 'situations', 'similar', 'to', 'many', 'social', 'media', 'platforms.']",4,"[2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0a82e811-90c7-4744-a503-ce6c5d21efb6,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,"[""An integrated lexicon for the analysis of complex words' to appear in Proceedings of EURALEX""]",['2002'],['Anke Lüdeling;Arne Fitschen'],single,"['The', 'DeKo', 'rules', 'can', 'only', 'work', 'if', 'they', 'can', 'refer', 'to', 'detailed', 'information', 'on', 'lexical', 'items', '-therefore', 'the', 'DeKo', 'team', 'and', 'other', 'researchers', 'at', 'the', 'IMS', 'in', 'Stuttgart', 'developed', 'a', 'highly', 'flexible', 'lexicon', 'concept', 'where', 'different', 'kinds', 'of', 'information', 'are', 'stored', 'together', 'with', 'morphological', 'elements', '(see', '<ref type=""single"">Lüdeling &amp, Fitschen 2002</ref>', 'for', 'more', 'details).', 'At', 'the', 'moment', 'the', 'relevant', 'information', 'is', 'still', 'being', 'collected', 'and', 'encoded', 'into', 'the', 'IMSLex.', 'Therefore,', 'the', 'DeKo', 'rules', 'as', 'they', 'stand', 'now', 'are', 'much', 'less', 'specific', 'than', 'they', 'should', 'be.']",46,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
0b198d64-13db-4486-b9b4-d45c5ad6a9e3,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,"['Neural speaker diarization with speaker-wise chain rule', 'Sequence to multisequence learning via conditional chain mapping for mixture signals']","['2020', '2020']","['Y Fujita;S Watanabe;S Horiguchi;Y Xue;J Shi;K Nagamatsu', 'J Shi;X Chang;P Guo;S Watanabe;Y Fujita;J Xu;B Xu;L Xie']",group,"['The', 'O2O', 'model', 'trained', 'with', 'a', 'conditional', 'chain', 'mapping', '<ref type=""group"">(Fujita et al., 2020a, Shi et al., 2020)</ref>', 'can', 'also', 'be', 'used', 'to', 'maximize', 'Eq.', '(3).', '4))', 'used', 'in', 'the', 'O2M', 'model,', 'the', 'O2O', 'conditional', 'chain', 'mapping', 'model', 'is', 'trained', 'to', 'maximize', 'the', 'joint', 'log-likelihood', '(Eq.', '(3))', 'via', 'a', 'recursive', 'expansion', 'of', 'the', 'probabilistic', 'chain', 'rule.', 'This', 'model', 'does', 'not', 'require', 'or', 'assume', 'conditional', 'independence', 'between', 'sequence', 'types.', 'Formally,', 'the', 'O2O', 'model', 'is', 'trained', 'to', 'maximize', 'the', 'following', 'loss', 'function:']",9,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0b22cdf6-04f8-4985-9145-1c7bf750ddb1,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['Processing Comparable Corpora with Bilingual Suffix Trees'],['2002'],['D Munteanu;D Marcu'],single,"['The', 'Champollion', 'system', 'was', 'developed', 'by', '<ref type=""single"">Smadja et al. (1996)</ref>', 'to', 'specifically', 'address', 'translation', 'of', 'collocations,', 'including', 'non-compositional', 'expressions.', 'They', 'used', 'aligned', 'sentences', 'from', 'the', 'Canadian', 'Hansards', 'corpus', '(as', 'did', '<ref type=""single"">Kupiec).</ref>', 'They', 'used', 'a', 'tool', 'they', 'had', 'previously', 'developed', '(XTRACT)', 'to', 'identify', 'collocations', 'and', 'they', 'translated', 'approximately', '900', 'medium', 'frequency', 'English', 'phrases', 'to', 'French.', 'Manual', 'evaluation', 'by', 'bilingual', 'speakers', 'revealed', 'accuracies', 'between', '65', 'and', '78%.', 'Champollion', 'works', 'by', 'iteratively', 'fusing', 'together', 'target', 'language', 'words', 'that', 'are', 'strongly', 'correlated', 'to', 'the', 'source', 'language', 'collocation', 'for', 'which', 'translation', 'is', 'attempted.', 'Dice', 'scores', 'are', 'used', 'to', 'filter', 'out', 'unlikely', 'word', 'combinations.', '<ref type=""single"">Munteanu and Marcu (2002)</ref>', 'ambitiously', 'produce', 'alignments', 'from', 'comparable', 'corpora,', 'corpora', 'where', 'exact', 'translations', 'may', 'not', 'be', 'available,', 'but', 'in', 'which', 'the', 'same', 'topics', 'or', 'entities', 'are', 'being', 'discussed', 'such', 'as', 'contemporaneous', 'newswire.', 'They', 'use', 'suffix', 'trees', 'in', 'both', 'languages', 'and', 'a', 'bilingual', 'lexicon', 'to', 'provide', 'points', 'of', 'correspondence', 'between', 'the', 'two', 'languages.', 'Not', 'only', 'to', 'they', 'successfully', 'create', 'alignments', 'in', 'the', 'comparable', 'data,', 'thus', 'creating', 'a', 'parallel', 'corpus,', 'they', 'create', 'phrasal', 'alignments', 'of', 'a', 'restricted', 'sort.', 'Namely,', 'their', 'parallel', 'phrases', 'have', 'the', 'same', 'number', 'of', 'tokens', '(i.e.,', 'words)', 'in', 'each', 'language', 'and', 'the', 'word', 'order', 'of', 'the', 'source', 'and', 'target', 'languages', 'must', 'be', 'the', 'same.', 'Some', 'examples', 'of', 'English/French', 'alignments', 'that', 'they', 'identified', 'are:']",95,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
0b3356f7-23c9-4807-ba1d-cc52b114f09d,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['unknown'],['unknown'],['unknown'],single,"['From', 'our', 'source', 'data', 'we', 'can', 'extract', 'parallel', 'sentences', 'for', '43', 'languages.', 'For', '12', 'of', 'these', 'languages', 'we', 'have', 'over', '10,000', 'sentences', 'available', 'for', 'projection', 'as', 'per', 'table', '4.', 'We', 'removed', 'some', 'of', 'these', 'languages', 'for', 'having', 'fewer', 'than', '950', 'lines,', 'resulting', 'in', 'a', 'total', 'of', '32', 'languages', '5', 'including', 'the', 'annotated', 'English', 'and', 'Finnish', 'data.', 'We', 'have', 'made', 'all', '32', 'datasets', 'available', 'on', 'GitHub', 'plus', 'the', 'raw', 'data', 'for', 'all', '43', 'languages', 'including', 'the', '11', 'datasets', 'that', 'had', 'fewer', 'than', '950', 'lines.', '<ref type=""single"">10,582 11,128 11,503 11,885 12,559 12,836 14,831 15,712 15,713 16,217 16,608 22,194</ref>', 'Table', '4:', 'Languages', '(ISO', 'code)', 'with', 'over', '10k', 'parallel', 'sentences', 'with', 'our', 'annotated', 'English', 'data.']",83,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
0b435777-180b-4e1c-8990-2be845a1c199,Comparison of post-editing productivity between professional translators and lay users,2014,Nora Aranberri;Gorka Labaka,['Simple or Complex? Assessing the readability of Basque texts'],['2014'],['I Gonzalez-Dios;M Aranzabe;A Diaz De Ilarraza;H Salaberri'],single,"['Even', 'when', 'we', 'are', 'aware', 'that', 'many', 'other', 'factors', 'are', 'involved', 'in', 'the', 'process,', 'we', 'turned', 'to', 'a', 'readability', '-reading', 'difficulty', '-measurement', 'as', 'a', 'proxy', 'for', 'translation', 'difficulty.', 'We', 'calculated', 'the', 'number', 'of', 'hard', 'words', '9,', 'lexical', 'density', '10', 'and', 'Gunning', 'Fog', 'Index', '<ref type=""single"">(Gunning, 1952)</ref>', '(see', 'Table', '7).', '11', 'When', 'comparing', 'both', 'texts,', 'we', 'see', 'that', 'Text', 'A', 'has', 'a', 'slightly', 'lower', 'number', 'of', 'hard', 'words,', '11.94%', 'as', 'opposed', 'to', '13.64%', 'for', 'Text', 'B.', 'Lexical', 'density', 'is', 'considerably', 'higher', 'for', 'Text', 'B,', 'which', 'means', 'that', 'repetitions', 'are', 'lower.', 'Given', 'that', 'both', 'Text', 'A', 'and', 'Text', 'B', 'have', 'very', 'similar', 'number', 'of', 'words,', 'we', 'conclude,', 'therefore,', 'that', 'Text', 'B', 'has', 'a', 'higher', 'number', 'of', 'different', 'words,', 'making', 'it', 'more', 'complex.', 'Finally,', 'the', 'Fog', 'Index', 'confirms', 'that', 'more', 'years', 'of', 'education', 'are', 'necessary', 'to', 'read', 'Text', 'B.', 'Overall,', 'readability', 'features', 'suggest', 'that', 'Text', 'B', 'is', 'more', 'difficult', 'to', 'read.', 'Understanding', 'the', 'source', 'text', 'is', 'a', 'vital', 'step', 'in', 'translation,', 'but', 'other', 'factors', 'such', 'as', 'the', 'mapping', 'of', 'the', 'concepts', 'and', 'grammatical', 'features', 'pay', 'an', 'important', 'role.', 'In', 'an', 'attempt', 'to', 'measure', 'both', 'sides', 'of', 'the', 'translation', 'process', 'in', 'terms', 'of', 'complexity,', 'we', 'have', 'also', 'analysed', 'the', 'linguistic', 'complexity', 'of', 'the', 'translations', 'produced', 'by', 'the', 'participants.', 'Based', 'on', 'the', 'linguistic', 'analysis', 'presented', 'in', '<ref type=""single"">Gonzalez-Dios, et al. (2014),</ref>', 'we', 'have', 'calculated', 'the', 'average', 'occurrences', 'of', 'a', 'number', 'of', 'linguistic', 'features', '(including', 'lexical,', 'morphological,', 'syntactic', 'and', 'pragmatic', 'features)', 'present', 'in', 'the', 'translations', 'and', 'post-edited', 'versions', 'of', 'Texts', 'A', 'and', 'B', '(see', 'Table', '8).', 'We', 'observe', 'that', 'out', 'of', 'the', '96', 'features', 'studied,', 'Text', 'B', 'has', 'a', 'higher', 'number', 'of', 'occurrences', 'for', '63', 'for', 'both', 'translators', 'and', 'users,', 'and', 'Text', 'A', 'for', '25', 'and', '17,', 'for', 'translators', 'and', 'users,', 'respectively,', 'having', 'no', 'occurrences', 'for', '8', 'and', '6', 'features.', 'Additioanlly,', 'we', 'have', 'considered', 'the', '10', 'most', 'predictive', 'features', 'for', 'complexity', 'according', 'to', 'the', 'same', 'authors,', 'which', 'include', 'a', 'number', 'of', 'the', 'most', 'predictive', 'features', 'according', 'to', '<ref type=""single"">Feng et al. (2010),</ref>', 'namely,', 'partof-speech', 'ratios', 'for', 'nouns.', 'We', 'see', 'that', 'Text', 'B', 'appears', 'to', 'be', 'more', 'complex,', 'scoring', 'higher', 'in', '7', 'out', 'of', 'the', '10', 'features.', 'A', 'final', 'aspect', 'that', 'is', 'worth', 'noting', 'is', 'text', 'expansion', 'rates.', 'English', 'is', 'an', 'analytic', 'language', 'and', 'Basque', 'is', 'an', 'agglutinative', 'language,', 'which', 'usually', 'means', 'that', 'word-counts', 'contract', 'when', 'translating', 'into', 'Basque.', 'For', 'translators,', 'on', 'average,', 'Text', 'A', 'has', 'contracted', 'to', '90.25%', 'and', 'Text', 'B', 'has', 'expanded', 'to', '103.85%', 'with', 'respect', 'to', 'the', 'English', 'source.', 'For', 'users,', 'both', 'texts', 'contract', 'but', 'whereas', 'Text', 'A', 'goes', 'down', 'to', '85.21%,', 'Text', 'B', 'still', 'remains', 'at', 'a', 'high', '98.21%.', 'The', 'fact', 'that', 'an', 'expansion', 'has', 'occurred', 'in', 'Text', 'B', 'might', 'be', 'due', 'to', 'participants', 'tending', 'to', 'over-explain', 'or', 'paraphrase.', 'This', 'might', 'be', 'a', 'result', 'of', 'the', 'complexity', 'of', 'the', 'content.']",209,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0b4ab0af-e084-4f4d-af0f-3ee6a8305a17,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Overview of the iwslt 2011 evaluation campaign'],['2011'],['M Federico;L Bentivogli;M Paul;S Stueker'],single,"['Phrase-based', 'SMT', 'systems', '<ref type=""single"">[2]</ref>', 'are', 'the', 'most', 'commonly', 'used', 'technique', 'in', 'statistical', 'machine', 'translation', 'nowadays.', 'In', 'this', 'approach,', 'source', 'and', 'target', 'phrase', 'pairs', 'consistent', 'with', 'the', 'word', 'alignment', 'are', 'extracted', 'from', 'the', 'parallel', 'training', 'data.', 'Phrases', 'in', 'PBSMT', 'are', 'just', 'contiguous', 'chunks', 'of', 'text,', 'and', 'are', 'not', 'linguistically', 'motivated.', 'The', 'extracted', 'source-target', 'phrase', 'pairs', 'along', 'with', 'their', 'translation', 'probabilities', '(computed', 'from', 'the', 'same', 'training', 'data)', 'are', 'stored', 'in', 'a', 'structure', 'known', 'as', 'the', ""'phrase"", ""table'."", 'During', 'translation,', 'an', 'input', 'sentence', 'is', 'split', 'up', 'into', 'phrases', 'and', 'their', 'corresponding', 'translations', 'are', 'looked', 'up', 'from', 'the', 'phrase', 'table', 'to', 'create', 'a', 'set', 'of', 'translated', 'sentences', 'in', 'the', 'target', 'language.', 'The', 'target', 'phrases', 'in', 'each', 'such', 'translation', 'are', 'subsequently', 'reordered', 'using', 'a', 'statistical', 're-ordering', 'model', 'that', 'assigns', 'a', 'probability', 'based', 'on', 'the', 'orientation', 'between', 'a', 'phrase', 'and', 'the', 'previously', 'translated', 'phrase.', 'A', 'language', 'model', 'is', 'further', 'used', 'for', 'better', 'fluency', 'and', 'grammaticality', 'of', 'the', 'translation.', 'The', 'phrase', 'translation', 'probabilities', 'along', 'with', 'reordering', 'and', 'language', 'model', 'probabilities', 'are', 'combined', 'in', 'a', 'log-linear', 'fashion', 'to', 'assign', 'a', 'score', 'to', 'each', 'possible', 'translation', 'of', 'an', 'input', 'sentence.', 'Finally', 'the', 'best', 'scoring', 'translation', 'is', 'searched', 'for', 'by', 'the', 'decoding', 'algorithm', 'and', 'is', 'presented', 'as', 'the', 'best', 'translation', 'for', 'the', 'corresponding', 'input', 'sentence.', 'Formally', 'this', 'task', 'can', 'be', 'expressed', 'as', 'in', '<ref type=""single"">(1):</ref>']",213,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
0b96aa48-744b-4f0e-9270-d9fb54f797c1,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,"['ChiSquareX at TextGraphs 2020 Shared Task: Leveraging Pretrained Language Models for Explanation Regeneration', 'Red Dragon AI at TextGraphs 2019 Shared Task: Language Model Assisted Explanation Generation', 'Chains-of-Reasoning at TextGraphs 2019 Shared Task: Reasoning over Chains of Facts for Explainable Multi-hop Inference', 'Autoregressive Reasoning over Chains of Facts with Transformers']","['2020', '2019', '2019', '2020']","['Aditya Girish Pawate;Varun Madhavan;Devansh Chandak', 'Ken Yew;Sam Chia;Martin Witteveen;unk Andrews', 'Rajarshi Das;Ameya Godbole;Manzil Zaheer;Shehzaad Dhuliawala;Andrew Mccallum', 'Ruben Cartuyvels;Graham Spinks;Marie-Francine Moens']",group,"['WorldTree.', 'A', 'number', 'of', 'approaches', 'have', 'been', 'proposed', 'for', 'the', 'explanation', 'regeneration', 'task', 'on', 'WorldTree,', 'including', 'those', 'from', 'previous', 'iterations', 'of', 'this', 'shared', 'task.', 'These', 'approaches', 'adopt', 'a', 'set', 'of', 'diverse', 'techniques', 'ranging', 'from', 'graph-based', 'learning', '<ref type=""single"">(Li et al., 2020),</ref>', 'to', 'Transformer-based', 'language', 'models', '<ref type=""group"">(Cartuyvels et al., 2020, Das et al., 2019, Pawate et al., 2020, Chia et al., 2019),</ref>', 'Integer', 'Linear', 'Programming', '<ref type=""single"">(Gupta and Srinivasaraghavan, 2020),</ref>', 'and', 'sparse', 'retrieval', 'models', '<ref type=""group"">(Valentino et al., 2021, Chia et al., 2019).</ref>']",41,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
0be697c9-cd46-492b-b300-dbc475d020dd,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['unknown'],['unknown'],['unknown'],single,"['The', 'vast', 'majority', 'of', 'the', 'dataset', 'was', 'annotated', 'by', 'university', 'students', 'learning', 'about', 'sentiment', 'analysis', 'with', 'some', 'annotations', 'provided', 'by', 'expert', 'annotators', 'for', 'reliability', 'measurements', '<ref type=""single"">( Öhman et al., 2018).</ref>', 'The', ""students'"", 'annotation', 'process', 'was', 'monitored', 'and', 'evaluated.', 'They', 'received', 'only', 'minimal', 'instructions.', 'These', 'instructions', 'included', 'that', 'they', 'were', 'to', 'focus', 'on', 'the', 'quality', 'of', 'annotations', 'rather', 'than', 'quantity,', 'and', 'to', 'annotate', 'from', 'the', 'point', 'of', 'view', 'of', 'the', 'speaker.', 'We', 'also', 'asked', 'for', 'feedback', 'on', 'the', 'annotation', 'process', 'to', 'improve', 'the', 'user-friendliness', 'of', 'the', 'platform', 'for', 'future', 'use.', 'In', 'tables', '2', 'and', '5', 'the', 'number', 'of', 'active', 'annotators', 'have', 'been', 'included.', 'All', 'in', 'all', 'over', '100', 'students', 'annotated', 'at', 'least', 'some', 'sentences', 'with', 'around', '60', 'active', 'annotators,', 'meaning', 'students', 'who', 'annotated', 'more', 'than', '300', 'sentences', '<ref type=""single"">( Öhman, 2020).</ref>']",25,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0cafbd9d-be24-4e57-9f5b-13b44699c005,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['unknown'],['unknown'],['unknown'],single,"['A', 'set', 'of', '30', 'high-level', 'instructions', 'specific', 'to', 'semantic', 'network', 'processing', 'are', 'implemented', 'directly', 'in', 'hardware.', 'These', 'include', 'associative', 'search,', 'marker', 'setting', 'and', 'propagation,', 'logical/arithmetic', 'operations', 'involving', 'markers,', 'create', 'and', 'delete', 'nodes', 'and', 'relations,', 'and', 'collect', 'a', 'list', 'of', 'nodes', 'with', 'a', 'certain', 'marker', 'set.', 'Currently,', 'the', 'instruction', 'set', 'can', 'be', 'called', 'from', 'C', 'language', 'so', 'that', 'users', 'can', 'develop', 'applications', 'with', 'an', 'extended', 'version', 'of', 'C', 'language.', 'From', 'the', 'programming', 'level,', 'SNAP', 'provides', 'data-parallel', 'programming', 'environment', 'similar', 'to', 'C*', 'of', 'the', 'Connection', 'Machine', '<ref type=""single"">[Thinking Machine Corp., 1989</ref>', '],', 'but', 'specialized', 'for', 'semantic', 'network', 'processing', 'with', 'marker', 'passing.']",84,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2]"
0d047316-e1bc-4506-a374-2fe99e460436,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,['Microsoft coco: Common objects in context'],['2014'],['Tsung-Yi Lin;Michael Maire;Serge Belongie;James Hays;Pietro Perona;Deva Ramanan;Piotr Dollár;C Lawrence Zitnick'],single,"['MS', 'COCO', '<ref type=""single"">(Lin et al., 2014</ref>', '):', 'an', 'object', 'detection', 'and', 'captioning', 'dataset', 'with', '&gt,200', 'K', 'labeled', 'images', 'and', '5', 'captions', 'in', 'a', 'sentence', 'form', 'for', 'each', 'image', 'Flicker30k', '<ref type=""single"">(Plummer et al., 2015):</ref>', '31', 'K', 'images', 'collected', 'from', 'Flickr,', 'together', 'with', '5', 'reference', 'sentences', 'ImageNET', '<ref type=""single"">(Deng et al., 2009):</ref>', '14', 'M', 'annotated', 'images,', 'hierarchically', 'organized', '(w.r.t.', 'WordNet)', 'MVSO', '<ref type=""single"">(Jou et al., 2015):</ref>', '15', 'K', 'visual', 'concepts', 'across', '12', 'languages,', '7.36', 'M', 'images', 'Additionally,', 'there', 'are', 'multimodal', 'datasets', 'that', 'were', 'created', 'for', 'a', 'specific', 'task:']",2,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0d890a23-237e-4930-bb69-bbeb550f6369,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['unknown'],['2021'],['Karolina Stanczak;Isabelle Augenstein'],single,"['n', 'positive', 'signifiers', 'n', 'words', 'NCR', 'VAD', 'Lexicon', 'This', 'measure', 'is', 'based', 'on', 'a', 'list', 'of', 'words', 'rated', 'on', 'the', 'emotional', 'dimensions', 'of', 'valence,', 'arousal,', 'and', 'dominance', 'which', 'has', 'been', 'used', 'in', 'gender', 'bias', 'research.', 'In', 'particular,', 'weakness', '(low', 'dominance),', 'passiveness', '(low', 'arousal', 'or', 'agency),', 'and', 'badness', '(valence)', 'may', 'be', 'associated', 'with', 'a', 'female', 'stereotype', '<ref type=""single"">(Stanczak and Augenstein, 2021).</ref>', 'Given', 'the', 'size', 'of', 'the', 'lexicon', 'and', 'its', 'overlap', 'of', 'up', 'to', '100%', 'with', 'other', 'word', 'lists,', 'we', 'only', 'counted', 'words', 'with', 'either', 'a', 'valence,', 'arousal,', 'or', 'dominance', 'rating', '&gt,', '0.75', 'on', 'a', 'scale', 'from', '0', 'to', '1.', 'The', 'calculation', 'is:']",55,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0db63059-0925-4372-9de0-76e410bd9af4,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['unknown'],['unknown'],['unknown'],single,"['Naturally,', 'the', 'WMT', 'Metrics', 'task,', 'most', 'recently', 'run', 'in', '2020', '<ref type=""single"">(Mathur et al., 2020b)</ref>', 'is', 'one', 'such', 'forum', 'for', 'the', 'evaluation', 'of', 'metrics.', 'In', 'this', 'last', 'iteration,', 'metrics', 'were', 'evaluated', 'based', 'on', 'their', 'correlation', 'with', 'human', 'judgment', 'scores', 'on', 'the', 'sentence,', 'paragraph,', 'and', 'document', 'level.', 'BERTScore', 'was', 'not', 'included', 'even', 'in', 'the', 'most', 'recent', 'iteration', 'of', 'the', 'metrics', 'task.']",10,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
0dfa5468-9f66-4fb6-810b-5a93b0d01d71,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,"['Beyond accuracy: Behavioral testing of nlp models with checklist', 'Do ImageNet classifiers generalize to ImageNet?']","['2020', '2019']","['Tongshuang Marco Tulio Ribeiro;Carlos Wu;Sameer Guestrin;unk Singh', 'Benjamin Recht;Rebecca Roelofs;Ludwig Schmidt;Vaishaal Shankar']",group,"['Intended', 'use.', 'One', 'primary', 'goal', 'of', 'NLP', 'models', 'is', 'the', 'generalization', 'to', 'real-world', 'inputs.', 'However,', 'existing', 'test', 'datasets', 'and', 'templates', 'are', 'often', 'not', 'comprehensive,', 'and', 'thus', 'it', 'is', 'difficult', 'to', 'evaluate', 'real-world', 'performance', '<ref type=""group"">(Recht et al., 2019, Ribeiro et al., 2020).</ref>', 'Our', 'work', 'sheds', 'a', 'light', 'on', 'quantifying', 'performance', 'for', 'inputs', 'beyond', 'the', 'test', 'dataset', 'and', 'help', 'uncover', 'model', 'weaknesses', 'prior', 'to', 'the', 'realworld', 'deployment.', 'Misuse', 'potential.', 'Similar', 'to', 'other', 'existing', 'adversarial', 'attack', 'methods', '<ref type=""group"">(Ebrahimi et al., 2018, Jin et al., 2019, Zhao et al., 2018b),</ref>', 'our', 'second-order', 'attacks', 'can', 'be', 'used', 'for', 'finding', 'vulnerable', 'examples', 'to', 'a', 'NLP', 'system.', 'Therefore,', 'it', 'is', 'essential', 'to', 'study', 'how', 'to', 'improve', 'the', 'robustness', 'of', 'NLP', 'models', 'second-order', 'attacks.', 'Limitations.', 'While', 'the', 'core', 'idea', 'about', 'the', 'double', 'perturbation', 'framework', 'is', 'general,', 'in', '§4,', 'we', 'consider', 'only', 'binary', 'gender', 'in', 'the', 'analysis', 'of', 'counterfactual', 'fairness', 'due', 'to', 'the', 'restriction', 'of', 'the', 'English', 'corpus', 'we', 'used,', 'which', 'only', 'have', 'words', 'associated', 'with', 'binary', 'gender', 'such', 'as', 'he/she,', 'waiter/waitress,', 'etc.']",33,"[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0e8baf19-6c22-46b3-9161-54951d0ed82c,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Bleu: a method for automatic evaluation of machine translation'],['2002'],['Kishore Papineni;Salim Roukos;Todd Ward;Wei-Jing Zhu'],single,"['We', 'use', 'MultiWOZ', '<ref type=""single"">(Budzianowski et al., 2018),</ref>', 'a', 'multi-domain', 'human-human', 'conversational', 'dataset', 'in', 'our', 'experiments.', 'It', 'contains', 'in', 'total', '8438', 'dialogues', 'spanning', 'over', 'seven', 'domains,', 'and', 'each', 'dialogue', 'has', '13.7', 'turns', 'on', 'average.', 'We', 'use', 'the', 'separation', 'of', 'training,', 'validation', 'and', 'testing', 'data', 'as', 'original', 'MultiWOZ', 'dataset.', 'We', 'use', 'the', 'evaluation', 'metrics', 'as', '<ref type=""single"">Budzianowski et al. (2018)</ref>', 'to', 'measure', 'dialogue', 'task', 'completion,', 'which', 'are', 'how', 'often', 'the', 'system', 'provides', 'a', 'correct', 'entity', '(Inform)', 'and', 'answers', 'all', 'the', 'requested', 'information', '(Success).', 'We', 'use', 'BLEU', '<ref type=""single"">(Papineni et al., 2002)</ref>', 'to', 'measure', 'the', 'language', 'quality', 'of', 'generated', 'responses.']",77,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]"
0ef6e06f-b63a-4660-95c1-7806810db828,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['We', 'utilize', 'a', 'standard', 'Transformer', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'as', 'our', 'generation', 'model.', 'It', 'takes', 'the', 'concatenation', 'of', 'the', 'sequence', 'x', 'and', 'all', 'the', 'selected', 'concepts', 'v', '1,', '...,', 'v', 'N', 'as', 'input', 'and', 'auto-regressively', 'generates', 'the', 'outputs', 'y.', 'We', 'adopt', 'the', 'cross-entropy', 'loss,', 'which', 'can', 'be', 'written', 'as:L', 'generation', '=', '−', 'log', 'p(y|x,', 'v', '1,', '•,', 'v', 'N)', '(5)', '=', '−', '|y|', 't=1', 'log', 'p(y', 't', '|x,', 'v', '1,', '•,', 'v', 'N,', 'y', '&lt,t', ').Note', 'that', 'since', 'the', 'selected', 'concepts', 'do', 'not', 'have', 'a', 'rigorous', 'order,', 'we', 'only', 'apply', 'positional', 'encodings', '(used', 'in', 'Transformer)', 'to', 'the', 'input', 'sequence', 'x.']",5,"[2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0f11c20d-d5f7-438f-82a3-bd4c687a251a,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,['Deep residual learning for image recognition'],['2016'],['Kaiming He;Xiangyu Zhang;Shaoqing Ren;Jian Sun'],single,"['Visual', 'Embedding', 'We', 'adopt', 'a', 'CNN', 'backbone', 'to', 'extract', 'image', 'features', 'V', '=', '{v', 'i}', 'L', 'i=1', 'for', 'each', 'image', 'I', 'where', 'L', 'is', 'the', 'size', 'of', 'feature', 'grids', 'and', 'v', 'i', '∈', 'R', 'dv', 'is', 'a', 'feature', 'vector', 'with', 'dimension', 'd', 'v.', 'In', 'addition,', 'each', 'feature', 'is', 'further', 'concatenated', 'with', 'its', '2-D', 'sine', 'position', 'embedding', '<ref type=""single"">(Carion et al., 2020).</ref>', 'Following', 'SOHO,', 'we', 'use', 'a', 'ResNet-101', '<ref type=""single"">(He et al., 2016)</ref>', 'as', 'the', 'visual', 'backbone,', 'followed', 'by', 'additional', '1x1', 'Conv', 'and', '2x2', 'strides', 'Max-pooling', 'to', 'reduce', 'the', 'memory', 'footprint.']",63,"[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
0f50a73d-e74d-4342-bfe0-1d768b2cb02b,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,"['A passage-based approach to learning to rank documents', 'Utilizing passage-based language models for ad hoc document retrieval', 'Deeper text understanding for IR with contextual neural language modeling', 'Cross-domain modeling of sentence-level evidence for document retrieval']","['2020', '2009', '2019', '2019']","['Eilon Sheetrit;Anna Shtok;Oren Kurland', 'Michael Bendersky;Oren Kurland', 'Zhuyun Dai;Jamie Callan', 'Wei Zeynep Akkalyoncu Yilmaz;Haotian Yang;Jimmy Zhang;unk Lin']",group,"['To', 'explore', 'the', 'generality', 'of', 'our', 'LTR', 'approach,', 'we', 'also', 'conduct', 'experiments', 'on', 'the', 'MS', 'MARCO', 'document', 'ranking', 'task.', 'We', 'emphasize', 'here', 'that', 'all', 'experiments', 'are', 'conducted', 'in', 'a', 'zero-shot', 'manner,', 'over', 'paragraph', 'extracts', 'from', 'the', 'collection,', 'what', 'is', 'commonly', 'known', 'as', 'the', 'MaxP', 'approach', '<ref type=""group"">(Bendersky and Kurland, 2009, Dai and Callan, 2019, Akkalyoncu Yilmaz et al., 2019, Sheetrit et al., 2020).</ref>', 'Both', 'the', 'final-stage', 'neural', 'reranker', 'and', 'our', 'LTR', 'module', 'are', 'trained', 'on', 'MS', 'MARCO', 'passage', 'data', 'only.', 'However,', 'comparing', 'our', 'effectiveness', 'results', 'with', 'the', 'official', 'leaderboard', 'reveals', 'that', 'our', 'configurations', 'are', 'competitive', 'compared', 'to', 'other', 'single-stage', 'rerankers.']",45,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
0f9aaecd-1e0c-422f-93f6-b6cb4c82770b,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,"['Multilingual tokenisation, tagging, and lemmatisation with totale']",['2006'],['Erjavec Tomaž'],single,"['POS', 'tagger', 'from', 'Totale', '<ref type=""single"">(Erjavec 2006)</ref>', 'was', 'also', 'used', 'as', 'the', 'disambiguation', 'module', 'instead', 'of', 'the', 'original', 'apertium', 'tagger.']",4,"[1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
101a11cc-ec0c-46ae-b594-8d3f64391c51,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['A meta-level grammar: redefining Synchronous TAG for translation and paraphrase'],['1999'],['M Dras'],single,"['In', 'general,', 'for', 'linguistic', 'representation', 'it', 'is', 'the', 'derived', 'tree', 'that', 'is', 'used', 'as', 'the', 'primary', 'structure', 'of', 'representation,', 'so', 'the', 'labels', 'would', 'represent', 'words', 'in', 'a', 'typical', 'lexicalised', 'grammar', 'and', 'the', 'trees', '«', '½,', '«', '¾', 'and', '¬', '½', 'would', 'represent', 'argument', 'structure', 'of', 'these', 'words.', 'However,', 'we', 'will', 'use', 'a', 'TAG', 'grammar', 'as', 'a', 'way', 'of', 'characterising', 'other', 'sorts', 'of', 'trees,', 'such', 'as', 'TAG', 'derivation', 'trees', 'or', 'dependency', 'trees,', 'this', 'is', 'thus', 'in', 'a', 'sense', 'an', 'extension', 'of', 'the', 'notion', 'of', 'the', 'meta-level', 'grammar', 'of', '<ref type=""single"">Dras (1999).</ref>', 'The', 'idea', 'is', 'then', 'to', 'use', 'a', 'TAG', 'grammar', 'to', 'break', 'down', 'some', 'tree', 'representation-which', 'may', 'be', 'a', 'dependency', 'tree,', 'a', 'TAG', 'derivation', 'tree,', '6', 'or', 'other-into', 'component', 'trees', 'possibly', 'representing', 'non-contiguous', 'groupings.', 'The', 'aim', 'is', 'not', 'to', 'describe', 'every', 'decomposition', 'into', 'non-contiguous', 'groupings,', 'only', 'those', 'such', 'as', 'the', 'language-related', 'cases', 'presented', 'in', 'Section', '2,', 'and', 'the', 'use', 'of', 'TAG', 'as', 'representation', 'allows', 'for', 'the', 'complexity', 'results', 'below.', 'We', 'now', 'present', 'an', 'algorithm', 'for', 'the', 'decomposition', 'in', 'Section', '4.']",87,"[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1057e173-d360-4717-bcc5-b56b512b79b7,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,['unknown'],['unknown'],['unknown'],group,"['Proposed', 'model', 'I', 'propose', 'a', 'log-bilinear', 'model', '<ref type=""group"">(Mnih and Hinton, 2007, 2008)</ref>', 'using', 'word', 'embeddings', 'as', 'input:', '1']",7,"[2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 0]"
107e482a-318a-4905-8f58-73c1e8d3b206,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,"[""CONDOR, a new parallel, constrained extension of powell's UOBYQA algorithm: Experimental results and comparison with the DFO algorithm""]",['2005'],['F Berghen;H Bersini'],single,"['The', 'system', 'is', 'based', 'on', 'the', 'Moses', 'SMT', 'toolkit', '<ref type=""single"">[3]</ref>', 'and', 'constructed', 'as', 'follows.', 'First,', 'Giza++', 'is', 'used', 'to', 'perform', 'word', 'alignments', 'in', 'both', 'directions.', 'Second,', 'phrases', 'and', 'lexical', 'reorderings', 'are', 'extracted.', 'Both', 'steps', 'use', 'the', 'default', 'settings', 'of', 'the', 'Moses', 'SMT', 'toolkit.', 'A', '4-gram', 'back-off', 'target', 'LM', 'is', 'then', 'constructed', 'as', 'detailed', 'in', 'section', '3.2.', 'The', 'translation', 'itself', 'is', 'performed', 'in', 'two', 'passes:', 'first,', 'Moses', 'is', 'run', 'and', 'a', '1000-best', 'list', 'is', 'generated', 'for', 'each', 'sentence.', 'The', 'parameters', 'of', 'this', 'first', 'pass', 'are', 'tuned', 'on', 'development', 'data', 'using', 'the', 'cmert', 'tool.', 'These', '1000-best', 'lists', 'are', 'then', 'rescored', 'with', 'a', 'continuous', 'space', '4-gram', 'LM', 'and', 'the', 'weights', 'of', 'the', 'feature', 'functions', 'are', 'again', 'optimized', 'using', 'the', 'open', 'source', 'numerical', 'optimization', 'toolkit', 'Condor', '<ref type=""single"">[7].</ref>', 'The', 'details', 'of', 'this', 'optimization', 'procedure', 'are', 'as', 'follows:']",122,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
10897b03-b4e3-4f89-8b0f-01134949268a,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['Improving Transformer-based end-to-end speech recognition with connectionist temporal classification and language model integration'],['2019'],['S Karita;N Soplin;S Watanabe;M Delcroix;A Ogawa;T Nakatani'],single,"['For', 'the', 'training', 'of', 'Transformer+CTC,', 'we', 'applied', 'joint', 'CTC', 'training', 'to', 'improve', 'performance', '<ref type=""single"">(Karita et al., 2019).</ref>', 'For', 'CTC-based', 'decoding,', 'we', 'used', 'the', 'greedy', 'search', 'algorithm.', 'For', 'Transformer', 'decoding,', 'we', 'used', 'the', 'beam', 'search', 'algorithm', 'and', 'tuned', 'search', 'parameters', 'using', 'the', 'development', 'set.', 'For', 'the', 'Transformer+CTC', 'model,', 'we', 'applied', 'Transformer/CTC', 'joint', 'decoding', '<ref type=""single"">(Karita et al., 2019).</ref>', 'and', 'tuned', 'the', 'weights', 'of', 'the', 'objective', 'using', 'the', 'development', 'set.', 'Note', 'that', 'the', 'language', 'model', 'shallow', 'fusion', '<ref type=""single"">(Hori et al., 2018)</ref>', 'is', 'not', 'applied', 'since', 'we', 'could', 'not', 'find', 'effectiveness', 'in', 'our', 'preliminary', 'experiment.']",49,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
10db6e79-23e4-4e1d-b0e7-9be761293266,A Parameter-Based Message-Passing Parser for MT of Korean and English,1994,Bonnie Dorr;Jye-Hoon Lee;Sungki Suh,['Context-free grammar parsing by message passing'],['1993'],['D Lin;R Goebel'],single,"['Our', 'GB', 'parser', 'is', 'an', 'extension', 'of', 'the', 'message-passing', 'approach', 'proposed', 'by', '<ref type=""single"">Lin (1993)</ref>', 'and', '<ref type=""single"">Lin and Goebel (1993),</ref>', 'which', 'uses', 'a', 'network', 'to', 'encode', 'the', 'grammar.', 'The', 'nodes', 'in', 'the', 'grammar', 'network', 'represent', 'grammatical', 'categories', '(e.g.,', 'NP,', 'Nbar,', 'N)', 'or', 'subcategories,', 'such', 'as', 'V:NP', '(i.e.,', 'a', 'transitive', 'verb', 'that', 'takes', 'an', 'NP', 'as', 'complement).', 'Figure', 'l.a', 'depicts', 'a', 'portion', 'of', 'the', 'grammar', 'network', 'for', 'English.']",14,"[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
113cce68-b4e5-4758-b8c1-caaf1d4ba83a,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['unknown'],['unknown'],['unknown'],single,"['By', 'contrast,', 'engineering', 'applications', 'mainly', 'aim', 'to', 'maximise', 'performance', 'accuracy,', 'utilising', 'all', 'available', 'information', 'and', 'more', 'powerful', 'nonlinear', 'classifiers.', 'Intriguingly,', 'recent', 'studies', 'have', 'shown', 'that', 'adding', 'human', 'eye', 'tracking', 'data', '<ref type=""single"">(Barrett et al., 2016)</ref>', 'or', 'morphosyntactic', 'information', 'extracted', 'from', 'human', 'functional', 'magnetic', 'resonance', 'imaging', '(fMRI)', 'signals', 'during', 'sentence', 'reading,', 'can', 'substantially', 'improve', 'PoS', 'induction', '<ref type=""single"">(Bingel et al., 2016</ref>', ').', 'Yet,', 'morphosynactic', 'information', 'obtained', 'from', 'fMRI', 'is', 'limited,', 'because', 'fMRI', 'measures', 'only', 'the', 'slow', 'changes', 'in', 'blood', 'oxygenation,', 'peaking', '5-6', 's', 'after', 'stimulus', 'onset,', 'rather', 'than', 'the', 'rapid', 'neural', 'activity', 'during', 'language', 'processing.']",30,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
117b6024-d843-43e4-96f2-7b3ac02c7f4c,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Text chunking using transformation-based learning'],['1995'],['Lance Ramshaw;Mitch Marcus'],single,"['Task', 'Definition', 'The', 'Text-based', 'NP', 'Enrichment', 'task', 'is', 'deceptively', 'simple:', 'For', 'each', 'ordered', 'pair', '(n', '1,', 'n', '2)', 'of', 'non-pronominal', 'base-NP', '3', 'spans', 'in', 'an', 'input', 'text,', 'determine', 'if', 'there', 'exists', 'a', 'preposition-mediated', 'relation', 'between', 'n', '1', 'and', 'n', '2,', 'and', 'if', 'there', 'is', 'one,', 'determine', 'the', 'preposition', 'that', 'best', 'describes', 'their', 'relation.', '4', 'The', 'output', 'is', 'a', 'list', '3', 'We', 'follow', 'the', 'definition', 'of', 'Base-NPs', 'as', 'defined', 'by', '<ref type=""single"">Ramshaw and Marcus (1995):</ref>', 'initial', 'portions', 'of', 'non-recursive', 'noun-phrases,', 'including', 'pre-modifiers', 'such', 'as', 'determiners,', 'adjectives', 'and', 'noun-compounds,', 'but', 'not', 'including', 'post-modifiers', 'such', 'as', 'prepositional', 'phrases', 'and', 'clauses.', 'These', 'are', 'also', 'known', 'in', 'the', 'NLP', 'literature', 'as', ""''NP"", ""Chunks''."", '4', 'During', 'annotation,', 'we', 'noticed', 'that', 'annotators', 'often', 'tried', 'to', 'express', 'set-membership', 'using', 'prepositions,', 'which', 'resulted', 'in', 'awkward', 'and', 'unclear', 'annotations.', 'To', 'remedy', 'this,', 'we', 'found', 'it', 'effective', 'to', 'add', 'an', 'explicit', ""''member-of''"", 'relation', 'as', 'an', 'allowed', 'annotation', 'option.', 'This', 'significantly', 'reduced', 'of', 'tuples', 'of', 'the', 'form', '(n', 'i,', 'prep,', 'n', 'j', '),', 'where', 'n', 'i', 'is', 'called', 'the', 'anchor', 'and', 'n', 'j', 'is', 'called', 'the', 'complement', 'of', 'the', 'relation.', 'Figure', '2', 'shows', 'an', 'example', 'of', 'text', 'where', 'each', 'NP', 'n', '1', 'is', 'annotated', 'with', 'its', '(prep,', 'n', '2)', 'NP-enrichments.']",69,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1248a723-2831-4842-92fc-41a26a73a61b,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Swahili : News classification dataset. The news version contains both train and test sets'],['2020'],['Davis David'],single,"['We', 'would', 'also', 'like', 'to', 'validate', 'our', 'methods', 'on', 'a', 'variety', 'of', 'other', 'data', 'sets', 'and', 'tasks.', 'We', 'selected', 'the', 'MasakhaNER', 'dataset', 'for', 'evaluation', 'because', 'we', 'specifically', 'wished', 'to', 'evaluate', 'results', 'on', 'ac-tual', 'low-resource', 'languages', 'supported', 'by', 'both', 'Allosaurus', 'and', 'Epitran.', 'While', 'there', 'are', 'still,', 'we', 'argue,', 'detectable', 'improvements', 'in', 'downstream', 'results', 'with', 'our', 'method,', 'further', 'work', 'would', 'benefit', 'from', 'additional', 'evaluations', 'on', 'other', 'data', 'sets', 'or', 'tasks.', 'In', 'particular,', 'the', 'Swahili', 'News', 'Classification', 'corpus', '<ref type=""single"">(David, 2020)</ref>', 'corpus', 'may', 'provide', 'a', 'useful', 'evaluation.']",75,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
1257587a-a31a-46fa-8886-03d847259ec8,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['unknown'],['unknown'],['unknown'],single,"['GLOVE', '<ref type=""single"">(Chen et al., 2019)</ref>', '71.9', 'ELMO', '<ref type=""single"">(Chen et al., 2019)</ref>', '80.2', 'BERT', 'BASE', '→', 'LR', '<ref type=""single"">(Chen et al., 2019)</ref>', '80.6', 'BERT', 'LARGE', '→', 'LR', '<ref type=""single"">(Chen et al., 2019)</ref>', '79', 'BERT-base', 'by', 'adding', 'an', 'internal', 'entity', 'linker.']",4,"[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1298f98c-416a-45fd-9f28-27d136dfec11,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Decoupled box proposal and featurization with ultrafine-grained semantic labels improve image captioning and visual question answering'],['1909'],['Soravit Changpinyo;Bo Pang;Piyush Sharma;Radu Soricut'],single,"['The', 'Baseline', 'method', 'only', 'takes', 'image', 'feature', 'as', 'input', 'while', 'the', '+Trace', 'model', 'take', 'image', 'feature', 'and', 'trace', 'both', 'as', 'input.', 'They', 'employ', 'the', 'architecture', 'in', '<ref type=""single"">Changpinyo et al. (2019)</ref>', 'with', 'a', 'few', 'minor', 'differences.', 'First,', 'they', 'set', 'the', 'number', 'of', ""Transformers'"", 'layers', 'for', 'both', 'the', 'encoder', 'and', 'the', 'decoder', 'to', '2', 'instead', 'of', '6.', 'Second,', 'their', 'projection', 'layers', 'also', 'consist', 'of', 'layer', 'normalization', '<ref type=""single"">(Ba et al., 2016).</ref>', 'Third,', 'they', 'set', 'the', 'maximum', 'number', 'of', 'iterations', 'to', '150k.', 'Finally,', 'they', 'allow', 'the', 'maximum', 'number', 'of', 'target', 'captions', 'to', 'be', 'as', 'long', 'as', '225', 'to', 'account', 'for', 'the', ""narration's"", 'longer', 'nature.', 'LoopCAG', 'methods', 'Our', 'model', 'comprises', 'of', 'four', 'components:', '1)', 'the', 'transformer', 'encoderdecoder', 'framework,', '2)', 'the', 'trace', 'input,', '3)', 'Attention', 'Guidance(+AG', 'for', 'short)', 'grounding', 'loss,', '4)', 'Contrastive', 'constraints(+C', 'for', 'short).']",26,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
12c93147-f4cd-4f50-aa3c-78621dfef731,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['unknown'],['unknown'],['unknown'],single,"['To', 'select', 'candidate', 'jobs', 'for', 'experiments,', 'we', 'use', 'the', 'list', 'of', 'jobs', 'in', 'the', 'UK', 'ASHE', 'report', '<ref type=""single"">(ONS, 2018).</ref>']",17,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
1329336a-81f5-49ec-8285-8fe1d21ade8e,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,"['Discriminative reranking for grammatical error correction with statistical machine translation', 'unknown', 'Multi-document summarization via discriminative summary reranking']","['2016', 'unknown', '2015']","['Tomoya Mizumoto;Yuji Matsumoto', 'unknown', 'Xiaojun Wan;Ziqiang Cao;Furu Wei;Sujian Li;M Zhou']",group,"['One', 'main', 'challenge', 'of', 'directly', 'optimizing', 'a', 'Seq2Seq', 'model', 'with', 'quality', 'scores', 'of', 'the', 'output', 'is', 'that', 'the', 'discrete', 'sampling', 'process', 'makes', 'the', 'loss', 'non-differentiable.', 'To', 'circumvent', 'this', 'problem,', 'reinforcement', 'learning', 'has', 'been', 'used', 'to', 'reformulate', 'the', 'conditional', 'text', 'generation', 'tasks', '<ref type=""group"">(Ranzato et al., 2016, Bahdanau et al., 2016, Li et al., 2016, Paulus et al., 2018, Li et al., 2019).</ref>', 'Compared', 'to', 'this', 'school', 'of', 'methods,', 'our', 'method', 'is', 'based', 'on', 'supervised', 'learning,', 'and', 'it', 'is', 'more', 'stable', 'and', 'less', 'sensitive', 'to', 'the', 'design', 'choices', '(e.g.', 'reward', 'shaping),', 'which', 'are', 'well-known', 'challenges', 'of', 'reinforcement', 'learning', 'methods.', 'Minimum', 'risk', 'training', '<ref type=""group"">(Shen et al., 2016, Wieting et al., 2019)</ref>', 'and', 'other', 'online', 'sampling', 'based', 'methods', '<ref type=""group"">(Bengio et al., 2015, Norouzi et al., 2016, Zhang et al., 2019)</ref>', 'belong', 'to', 'another', 'school', 'of', 'methods', 'used', 'to', 'circumvent', 'the', 'problem', 'of', 'non-differentiability.', 'However,', 'they', 'also', 'exhibit', 'similar', 'problems', 'of', 'stability', 'as', 'reinforcement', 'learning.', 'Contrastive', 'Learning', 'Recently,', 'contrastive', 'learning', '<ref type=""single"">(Hadsell et al., 2006)</ref>', 'has', 'been', 'introduced', 'into', 'several', 'conditional', 'text', 'generation', 'tasks,', 'such', 'as', 'machine', 'translation', '<ref type=""group"">(Yang et al., 2019, Pan et al., 2021),</ref>', 'text', 'summarization', '<ref type=""group"">(Cao and Wang, 2021, Xu et al., 2021, Sun and Li, 2021),</ref>', 'and', 'other', 'tasks', '<ref type=""group"">(Uehara et al., 2020, Cho et al., 2021, Lee et al., 2021b).</ref>', 'Among', 'these', 'application', 'scenarios,', 'most', 'work', 'deployed', 'contrastive', 'learning', 'in', 'the', 'latent', 'representation', 'space,', 'following', 'the', 'framework', 'proposed', 'in', '<ref type=""single"">Chen et al. (2020).</ref>', 'However,', 'in', 'this', 'work', 'we', 'adopt', 'contrastive', 'learning', 'over', 'the', 'discrete', 'space', 'of', 'the', 'generated', 'texts.', 'Besides,', 'instead', 'of', 'constructing', 'the', 'contrastive', 'learning', 'examples', 'by', 'rule-based', 'methods', '(e.g.', 'perturbing', 'the', 'reference', 'output),', 'we', 'use', 'the', 'generation', 'models', 'to', 'construct', 'the', 'examples,', 'which', 'makes', 'the', 'contrastive', 'learning', 'task', 'closer', 'to', 'the', 'generation', 'task.', 'Sun', 'and', 'Li', '(2021)', 'also', 'adopted', 'contrastive', 'learning', 'on', 'the', 'generated', 'texts.', 'However,', 'their', 'formulation', 'belongs', 'to', 'the', 'margin-based', 'losses.', 'We', 'have', 'discussed', 'the', 'difference', 'between', 'our', 'method', 'and', 'the', 'margin-based', 'losses', 'in', 'the', 'previous', 'paragraphs.', 'Discriminative', 'Reranking', 'Discriminative', 'reranking', 'has', 'been', 'widely', 'studied', 'for', 'conditional', 'generation', 'tasks', '<ref type=""group"">(Shen et al., 2004, Och et al., 2004, Wan et al., 2015, Mizumoto and Matsumoto, 2016).</ref>', 'Some', 'recent', 'works', '<ref type=""group"">(Liu and Liu, 2021, Lee et al., 2021a)</ref>', 'have', 'also', 'explored', 'discriminative', 'reranking', 'of', 'candidates', 'from', 'neural', 'natural', 'language', 'generation', 'models,', 'which', 'adopt', 'large', 'pre-trained', 'language', 'models', '(e.g.', 'BERT', '<ref type=""single"">(Devlin et al., 2019))</ref>', 'as', 'the', 'reranker.', 'In', 'this', 'work,', 'we', 'factorize', 'the', 'Seq2Seq', 'model', '(e.g.,', 'BART)', 'trained', 'on', 'the', 'same', 'dataset', 'as', 'the', 'reranking', 'model,', 'which', 'maximizes', 'the', 'parameter', 'sharing', 'across', 'two', 'stages.', 'Besides,', 'our', 'approach', 'contributes', 'an', 'instance', 'of', 'leveraging', 'large', 'pre-trained', 'Seq2Seq', 'models', 'as', 'a', 'quality', 'estimation', 'model', '<ref type=""single"">(Yuan et al., 2021).</ref>']",260,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
13953d36-f056-42de-885e-ab1722e0651c,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics'],['2004'],['Chin-Yew Lin;Franz Josef Och'],single,"['This', 'generation', 'task', 'adopts', 'the', 'traditional', 'image', 'captioning', 'evaluation', 'metric', 'using', 'the', 'open-source', 'tool', '2', 'with', 'a', 'minor', 'modification', '3', 'to', 'suit', 'with', 'LN-COCO,', 'including', 'BLEU', '<ref type=""single"">(Papineni et al., 2002),</ref>', 'METEOR', '<ref type=""single"">(Banerjee and Lavie, 2005),</ref>', 'ROUGE-L', '<ref type=""single"">(Lin and Och, 2004),</ref>', 'ROUGE-1-F1(Pont-Tuset', 'et', 'al.,', '2020),', 'and', 'CIDEr-D', '<ref type=""single"">(Vedantam et al., 2015).</ref>']",30,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3]"
147acd2a-9cb4-416b-8eca-8f76b2e3e2fc,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Counter-fitting word vectors to linguistic constraints'],['2016'],['Nikola Mrkšić;Ó Diarmuid;Blaise Séaghdha;Milica Thomson;Lina Gašić;Pei-Hao Rojas-Barahona;David Su;Tsung-Hsien Vandyke;Steve Wen;unk Young'],single,"['For', 'each', 'potential', 'shortcut', 'token,', 'we', 'extract', 'N', 'synonyms', 'by', 'leveraging', 'the', 'word', 'embeddings', 'curated', 'for', 'synonym', 'extraction', '<ref type=""single"">(Mrkšić et al., 2016),</ref>', 'plus', 'WordNet', '<ref type=""single"">(Miller, 1995)</ref>', 'and', 'DBpedia', '<ref type=""single"">(Auer et al., 2007).</ref>', 'More', 'specifically,', 'for', 'each', 'top', 'token', 't', 'in', 'the', 'list', 'generated', 'by', 'the', 'previous', 'step,', 'we', 'first', 'search', 'counter-fitting', 'word', 'vectors', 'to', 'find', 'synonyms', 'with', 'cosine', 'similarity', 'larger', 'than', 'a', 'threshold', '4', 'τ.', 'Additionally', 'we', 'search', 'in', 'WordNet', 'and', 'DBpedia', 'to', 'obtain', 'a', 'maximum', 'of', 'N', 'synonyms', 'for', 'each', 'token', 't.', 'Then', 'we', 'extract', 'a', 'subset', 'S', 't', 'from', 'D,', 'which', 'consists', 'of', 'sentences', 'containing', 't.', 'We', 'perturb', 'all', 'sentences', 'in', 'S', 't', 'by', 'replacing', 't', 'with', 'its', 'synonyms.', 'The', 'resulted', 'perturbed', 'set', 'S', '′', 't', 'is', 'N', 'times', 'of', 'the', 'original', 'set', 'S', 't.', 'We', 'apply', 'model', 'f', 'on', 'S', 't', 'and', 'S', '′', 't', 'and', 'obtain', 'accuracy', 'acc', 't', 'and', 'acc', '′', 't.', 'Since', 'we', 'only', 'perturb', 'S', 't', 'with', ""t's"", 'synonyms,', 'the', 'semantic', 'meaning', 'of', 'perturbed', 'sentences', 'should', 'stay', 'close', 'to', 'the', 'original', 'sentences.', 'Thus,', 'if', 't', 'is', 'a', 'genuine', 'token,', 'acc', '′', 't', 'is', 'expected', 'to', 'be', 'close', 'to', 'acc', 't.', 'On', 'the', 'other', 'hand,', 'if', 't', 'is', 'a', 'shortcut,', 'model', 'prediction', 'can', 'be', 'different', 'even', 'the', 'semantic', 'meaning', 'of', 'the', 'sentence', 'does', 'not', 'change', 'a', 'lot', '(see', 'examples', 'in', 'Table', '2).', 'Thus,', 'we', 'assume', 'tokens', 'with', 'larger', 'differences', 'between', 'acc', 't', 'and', 'acc', '′', 't', 'are', 'more', 'likely', 'to', 'be', 'shortcuts', 'and', 'tokens', 'with', 'smaller', 'differences', 'are', 'more', 'likely', 'to', 'be', 'domain', 'specific', '""genuine""', 'words.', 'From', 'the', 'potential', 'shortcut', 'token', 'list', 'computed', 'in', 'Sec', '3.2,', 'we', 'remove', 'tokens', 'with', 'performance', 'difference', 'smaller', 'than', 'δ', 'to', 'further', 'filter', 'domain', 'specific', '""geniue""', 'tokens.']",18,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1497c2f8-c428-4304-93bc-091abc79d71c,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Ultra-Fine Entity Typing'],['2018'],['Eunsol Choi;Omer Levy;Yejin Choi;Luke Zettlemoyer'],single,"['In', 'this', 'work,', 'we', 'explore', 'a', 'set', 'of', 'interpretable', 'entity', 'representations', 'that', 'are', 'simultaneously', 'human', 'and', 'machine', 'readable.', 'The', 'key', 'idea', 'of', 'this', 'approach', 'is', 'to', 'use', 'fine-grained', 'entity', 'typing', 'models', 'with', 'large', 'type', 'inventories', '<ref type=""group"">(Ling and Weld, 2012, Gillick et al., 2014, Choi et al., 2018, Onoe and Durrett, 2020).</ref>', 'Given', 'an', 'entity', 'mention', 'and', 'context', 'words,', 'our', 'typing', 'model', 'outputs', 'a', 'highdimensional', 'vector', 'whose', 'values', 'are', 'associated', 'with', 'predefined', 'fine-grained', 'entity', 'types.', 'Each', 'value', 'ranges', 'between', '0', 'and', '1,', 'corresponding', 'to', 'the', 'confidence', 'of', 'the', ""model's"", 'decision', 'that', 'the', 'entity', 'has', 'the', 'property', 'given', 'by', 'the', 'corresponding', 'type.', 'We', 'use', 'pre-trained', 'Transformer-based', 'entity', 'typing', 'models,', 'trained', 'either', 'on', 'a', 'supervised', 'entity', 'typing', 'dataset', '<ref type=""single"">(Choi et al., 2018)</ref>', 'or', 'on', 'a', 'distantlysupervised', 'dataset', 'derived', 'from', 'Wikipedia', 'categories', '<ref type=""single"">(Onoe and Durrett, 2020).</ref>', 'The', 'type', 'vectors', 'from', 'these', 'models,', 'which', 'contain', 'tens', 'of', 'thousands', 'of', 'types,', 'are', 'then', 'used', 'as', 'contextualized', 'entity', 'embeddings', 'in', 'downstream', 'tasks.']",100,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
14a9cca7-b623-4bb7-a3c3-cbad2ce4b2b1,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,"['YAGO: A Core of Semantic Knowledge', 'unknown']","['2007', 'unknown']","['Fabian Suchanek;Gjergji Kasneci;Gerhard Weikum', 'unknown']",group,"['Therefore,', 'we', 'additionally', 'use', 'two', 'distantly', 'labeled', 'entity', 'typing', 'datasets', 'derived', 'from', 'Wikipedia.', 'We', 'leverage', 'past', 'work', 'in', 'using', 'types', 'derived', 'from', 'Wikipedia', 'categories', '<ref type=""group"">(Suchanek et al., 2007, Onoe and Durrett, 2020, inter alia),</ref>', 'which', 'contain', 'type', 'information', 'and', 'are', 'widely', 'annotated', 'across', 'Wikipedia', 'articles.', 'We', 'select', 'the', 'appropriate', 'dataset', 'for', 'each', 'setting', 'depending', 'on', 'task-specific', 'requirements', '(see', 'Section', '6).', 'For', 'all', 'datasets,', 'we', 'compute', 'entity', 'typing', 'macro', 'F1', 'using', 'development', 'examples', '(1k)', 'to', 'check', 'model', 'convergence.']",24,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
14be9216-7fea-41d6-b7b8-19b04b0bf143,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,['A new decoder for spoken language translation based on confusion networks'],['2005'],['N Bertoldi;M Federico'],single,"['We', 'have', 'started', 'working', 'on', 'these', 'issues,', 'but', 'none', 'of', 'it', 'was', 'finally', 'used', 'in', 'our', 'system,', 'mainly', 'due', 'to', 'the', 'fact', 'that', 'no', 'native', 'speaker', 'of', 'the', 'Arabic', 'language', 'was', 'available.', 'The', 'submitted', 'system', 'was', 'only', 'retuned', 'on', 'the', 'ASR', '1-best', 'development', 'data.', 'Table', '5', 'compares', 'the', 'BLEU', 'score', 'on', 'various', 'data', 'sets', 'of', 'the', 'text', 'and', 'ASR', 'condition.', 'We', 'observe', 'a', 'degradation', 'of', 'about', '11%', 'relative', 'when', 'translating', 'the', 'ASR', 'output', 'of', 'Dev5', 'and', 'of', '16%', 'for', 'Dev6', 'respectively.', 'Unfortunately,', 'translation', 'of', 'the', 'ASR', 'output', 'did', 'not', 'work', 'very', 'well', 'on', 'this', ""year's"", 'test', 'data.', 'High', 'word', 'error', 'rates', 'of', 'the', 'speech', 'recognition', 'module', 'favor', 'the', 'translation', 'of', 'consensus', 'networks', '<ref type=""single"">[18]</ref>', 'since', 'the', 'oracle', 'error', 'rate', 'of', 'such', 'data', 'structures', 'is', 'usually', 'two', 'to', 'three', 'times', 'smaller.', 'However,', 'this', 'data', 'structure', 'is', 'incompatible', 'with', ""SYSTRAN's"", 'tokenization', 'that', 'operates', 'at', 'the', 'sentence', 'level.']",112,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
15037448-2238-4f79-8267-bcb1abef3dc5,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['In', 'our', 'system,', 'we', 'train', 'a', 'Transformer', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'with', 'a', 'deep', 'encoder', '<ref type=""single"">(Meng et al., 2020)</ref>', 'as', 'baseline', 'for', 'abtaining', 'rich', 'source', 'representations,', 'besides', 'we', 'initialize', 'the', 'model', 'with', 'the', 'method', 'mentioned', 'in', 'DeepNet', '<ref type=""single"">(Wang et al., 2022)</ref>', 'in', 'order', 'to', 'stabilize', 'the', 'training', 'of', 'the', 'deeper', 'model.', 'At', 'the', 'pre-training', 'stage,', 'we', 'firstly', 'pretrain', 'our', 'model', 'on', 'a', 'large', 'general', 'corpus,', 'then', 'we', 'utilize', 'data', 'synthesis', 'methods', 'such', 'as', 'self-training', 'and', 'back-translation', 'to', 'improve', 'model', 'quality.']",7,"[2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
153e8912-59e4-4ced-8602-cdc6dd3dab44,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Morphology and Computation'],['1992'],['Richard Sproat'],single,"['From', 'a', 'technical', 'point', 'of', 'view,', 'the', 'domain', 'of', 'inflectional', 'morphology', 'is', 'a', 'rather', 'well-explored', 'area,', 'in', 'which', 'most', 'efforts', 'are', 'devoted', 'to', 'development', 'rather', 'than', 'research.', 'Techniques', 'used', 'are', 'based', 'on', 'finite-state', 'transducers', 'as', 'used', 'originally', 'in', 'two-level', 'morphology,', 'cf.', '<ref type=""single"">Sproat (1992)</ref>', 'for', 'an', 'overview.', 'Research', 'concentrates', 'to', 'a', 'large', 'extent', 'on', 'complicated', 'phenomena', 'such', 'as', 'Arabic', 'nonlinear', 'morphology.', '10', 'Transferring', 'the', 'finite-state', 'approach', 'from', 'inflection', 'to', 'word', 'formation', 'does', 'not', 'by', 'itself', 'cause', 'many', 'additional', 'problems,', 'but', 'it', 'does', 'exacerbate', 'a', 'number', 'of', 'well-known', 'problems', 'of', 'finite-state', 'mechanisms:']",41,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
155fb05a-0c93-4a0d-adb3-22bc696201c8,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Corpus creation and initial SMT experiments between Spanish and Shipibo-konibo'],['2017'],['Ana-Paula Galarreta;Andrés Melgar;Arturo Oncevay'],single,"['In', 'Peru,', 'before', 'NMT,', 'there', 'were', 'studies', 'in', 'rulebased', 'MT,', 'based', 'on', 'the', 'Apertium', 'platform', '<ref type=""single"">(Forcada et al., 2011),</ref>', 'for', 'Quechua', 'Eastern', 'Apurimac', '(qve)', 'and', 'Quechua', 'Cuzco', '(quz)', '<ref type=""single"">(Cavero and Madariaga, 2007).</ref>', 'Furthermore,', '<ref type=""single"">Ortega and Pillaipakkamnatt (2018)</ref>', 'improved', 'alignments', 'for', 'quz', 'by', 'using', 'an', 'agglutinative', 'language', 'as', 'Finnish', 'as', 'a', 'pivot.', 'Apart', 'from', 'the', 'Quechua', 'variants,', 'only', 'Aymara', '<ref type=""single"">(Coler and Homola, 2014)</ref>', 'and', 'Shipibo-Konibo', '<ref type=""single"">(Galarreta et al., 2017)</ref>', 'have', 'been', 'addressed', 'with', 'rule-based', 'and', 'statistical', 'MT,', 'respectively.', '<ref type=""single"">Ortega et al. (2020b)</ref>', 'for', 'Southern', 'Quechua,', 'and', 'Gómez', '<ref type=""single"">Montoya et al. (2019)</ref>', 'for', 'Shipibo-Konibo,', 'are', 'the', 'only', 'studies', 'that', 'employed', 'sequence-tosequence', 'NMT', 'models.', 'They', 'also', 'performed', 'transfer', 'learning', 'experiments', 'with', 'potentially', 'related', 'language', 'pairs', '(e.g.', 'Finnish', 'or', 'Turkish,', 'which', 'are', 'agglutinative', 'languages).', 'However,', 'as', 'far', 'as', 'we', 'know,', 'this', 'is', 'the', 'first', 'study', 'that', 'trains', 'a', 'multilingual', 'model', 'for', 'some', 'language', 'spoken', 'in', 'Peru.', 'For', 'related', 'work', 'on', 'multilingual', 'NMT,', 'we', 'refer', 'the', 'readers', 'to', 'the', 'survey', 'of', '<ref type=""single"">Dabre et al. (2020).</ref>']",52,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
15939aaa-3347-4f7d-bffb-c274a2df767c,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Common voice: A massivelymultilingual speech corpus'],['2019'],['Rosana Ardila;Megan Branson;Kelly Davis;Michael Henretty;Michael Kohler;Josh Meyer;Reuben Morais;Lindsay Saunders;Francis Tyers;Gregor Weber'],single,"['We', 'demonstrate', 'our', 'phonetic', 'approach', 'by', 'training', 'Named', 'Entity', 'Recognition', '(NER)', 'models', 'for', 'Swahili', '[swh]', '3', 'using', 'various', 'combinations', 'of', 'Swahili', 'text', 'data,', 'Swahili', 'audio', 'data,', 'Kinyarwanda', '[kin]', 'text', 'data,', 'and', 'Kinyarwanda', 'audio', 'data.', 'These', 'two', 'languages', 'both', 'originate', 'from', 'from', 'the', 'same', 'language', 'family,', 'Bantu,', 'and', 'are', 'spoken', 'by', 'millions', 'of', 'people', 'in', 'Eastern', 'Africa,', 'often', 'within', 'the', 'same', 'country,', 'resulting', 'in', 'some', 'overlap', 'in', 'loan', 'words,', 'etc.', '4', 'However,', 'they', 'are', 'both', 'considered', 'low-resource', 'languages.', 'Kinyarwanda', 'in', 'particular,', 'though', 'spoken', 'by', 'approximately', '13-22', 'million', 'people', '5,', 'has', 'very', 'little', 'text', 'data', 'available', 'in', 'that', 'language,', 'with', 'fewer', 'than', '3,000', 'articles', 'on', 'the', 'Kinyarwanda-language', 'Wikipedia,', 'and', 'Swahili', 'comparatively', 'ahead', 'but', 'still', 'poorly', 'resourced', 'at', 'approximately', '68,000', 'articles,', 'far', 'less', 'than', 'many', 'European', 'languages.', '6,', 'though', 'some', 'datasets', 'have', 'been', 'created', 'such', 'as', 'KINNEWS', '<ref type=""single"">(Niyongabo et al., 2020).</ref>', 'On', 'the', 'other', 'hand,', 'Kinyarwanda', 'is', 'uniquely', 'placed', 'as', 'a', 'language', 'to', 'leverage', 'speech-based', 'technologies,', 'due', 'to', 'well-organized', 'efforts', '7', 'to', 'collect', 'voice', 'data', 'for', 'that', 'language.', 'It', 'is', 'in', 'fact', 'one', 'of', 'the', 'largest', 'subsets', 'available', 'on', 'the', 'Common', 'Voice', 'Dataset', '<ref type=""single"">(Ardila et al., 2019),</ref>', 'with', '1,183', 'hours', 'of', 'voice', 'clips', 'collected', 'and', 'validated.', 'Choosing', 'these', 'two', 'languages', 'allowed', 'us', 'to', 'test', 'the', 'use', 'of', 'the', 'technique', 'on', 'legitimately', 'low-resourced', 'languages', 'that', 'could', 'benefit', 'from', 'improved', 'NLP', 'technology,', 'and', 'which', 'as', 'part', 'of', 'the', 'same', 'family', 'of', 'languages', '5', 'Sources', 'vary:', 'Ethnologue', 'cites', '""Total', 'users', 'in', 'all', 'countries:', '13,133,980"",', 'but', 'there', 'are', '22', 'million', 'according', 'to', 'WorldData.info', '(https://www.worlddata.info/languages/kinyarwanda.php).']",177,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
15ee468b-068d-4575-9a5b-3ba33853b428,Themes in the work of Margaret Masterman,1988,Yorick Wilks,"['unknown', 'Classification, concept formation and language']","['1956', '1959']","['M Masterman;unk Words', 'M Masterman']",group,"['MMB', 'believed', '30', 'years', 'ago', 'that', 'constructed', 'entities', 'such', 'as', 'dictionaries', 'and', 'thesauri', '(especially', 'the', 'latter)', 'constituted', 'real', 'resources', 'for', 'computational', 'language', 'processing', '<ref type=""group"">(Masterman, 1956 (Masterman, , 1959b)).</ref>', 'That', 'was', 'at', 'a', 'time', 'when', 'any', 'computational', 'operations', 'on', 'such', 'entities', 'were', 'often', 'dismissed', 'by', 'those', 'working', 'in', 'other', 'areas', 'of', 'computational', 'linguistics', 'as', 'low-grade', 'concordance', 'work.', 'Betty', 'May', 'compacted', 'the', 'whole', 'of', ""Roget's"", 'thesaurus', 'for', 'MMB,', 'from', '1,000', ""'heads'"", 'to', '800,', 'and', 'had', 'them', 'cardpunched.', 'That', 'formed', 'the', 'basis', 'for', 'a', 'range', 'of', 'experiments', 'on', 'Hollerith', 'sorting', 'machines', 'which', 'contributed', 'to', 'Karen', 'Sparck', ""Jones'"", 'seminal', 'thesis', 'work', 'Synonymy', 'and', 'semantics', 'classification', '<ref type=""group"">(1964, 1986).</ref>', 'MMB', 'believed', 'that', 'thesauri', 'such', 'as', ""Roget's"", 'were', 'not', 'just', 'fallible', 'human', 'constructs', 'but', 'real', 'resources', 'with', 'some', 'mathematical', 'structure', 'that', 'was', 'also', 'a', 'guide', 'to', 'the', 'structures', 'which', 'humans', 'use', 'to', 'process', 'language.', 'She', 'would', 'often', 'refer', 'to', ""'Roget's"", ""unconscious'"", 'by', 'which', 'she', 'meant', 'that', 'the', 'patterns', 'of', 'cross-references', 'from', 'word', 'to', 'word', 'across', 'the', 'thesaurus', 'had', 'underlying', 'generalisations', 'and', 'patterns.']",23,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
15feb3c0-b1f8-4266-9edf-e422b9203b33,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,['Contextual analysis of mathematical expressions for advanced mathematical search'],['2011'],['Keisuke Yokoi;Minh-Quoc Nghiem'],single,"['Prior', 'to', 'this', 'shared', 'task,', 'some', 'studies', 'have', 'created', 'datasets', 'for', 'similar', 'tasks', '<ref type=""group"">(Yokoi et al., 2011, Schubotz et al., 2016, Alexeeva et al., 2020).</ref>', 'However,', 'one', 'of', 'them', 'is', 'created', 'for', 'publications', 'written', 'in', 'Japanese', '<ref type=""single"">(Yokoi et al., 2011),</ref>', 'making', 'it', 'nearly', 'impossible', 'to', 'transfer', 'to', 'English', 'literature.', 'While', 'two', 'other', 'datasets', '<ref type=""group"">(Schubotz et al., 2016, Alexeeva et al., 2020)</ref>', 'only', 'annotate', 'small-scale', 'golden', 'datasets', 'for', 'evaluation', 'purposes.', 'As', 'the', 'result,', 'no', 'training', 'data', 'is', 'available', 'for', 'training', 'deep', 'neural', 'network', 'models.', 'In', 'this', 'shared', 'task,', 'we', 'provide', 'a', 'large-scale', 'dataset', 'for', 'English', 'literature', 'that', 'we', 'believe', 'will', 'provide', 'enough', 'supervision', 'for', 'the', 'promising', 'deep', 'neural', 'network-based', 'models.']",25,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
164b3859-e683-4b0a-a2c0-7b1cc67d9281,Corpora and Machine Translation,1993,Yorick Wilks,['A preferential pattern-matching semantics for natural language understanding'],['1975'],['Y Wilks'],single,"['There', 'remain,', 'too,', 'crucial', 'classes', 'of', 'cases', 'that', 'seem', 'to', 'need', 'symbolic', 'inference:', 'an', 'old,', 'self-serving,', 'one', 'will', 'do', 'such', 'as', '""The', 'soldiers', 'fired', 'at', 'the', 'women', 'and', 'I', 'saw', 'several', 'fall""', '<ref type=""single"">(Wilks 1975).</ref>']",32,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
165dd43a-f4c3-4940-a4bd-ddd39c037009,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,['The RWTH statistical machine translation system for the IWSLT 2006 evaluation'],['2007'],['A Mauser;R Zens;E Matusov;S Hasan;H Ney'],single,"['The', 'organizers', 'of', 'IWSLT', 'provide', 'several', 'task', 'specific', 'corpora', 'that', 'can', 'be', 'used', 'to', 'train', 'and', 'optimize', 'the', 'translation', 'system.', 'The', 'characteristics', 'of', 'these', 'corpora', 'are', 'summarized', 'in', 'Table', '1.', 'It', 'is', 'known', 'that', 'the', 'choice', 'of', 'the', 'development', 'and', 'internal', 'test', 'data', 'may', 'have', 'an', 'important', 'impact', 'on', 'the', 'quality', 'of', 'the', 'system,', 'in', 'particular', 'when', 'the', 'available', 'corpora', 'have', 'different', 'characteristics', '(for', 'instance', 'what', 'concerns', 'the', 'average', 'sentence', 'length).', 'We', 'decided', 'to', 'develop.', 'Therefore,', 'we', 'decided', 'to', 'add', 'the', 'last', 'two', 'corpora', 'to', 'the', 'training', 'material', 'after', 'optimizing', 'the', 'system', 'and', 'to', 'retrain', 'the', 'full', 'system', 'keeping', 'all', 'settings', 'unmodified.', 'This', 'idea', 'was', 'already', 'successfully', 'proposed', 'in', 'previous', 'IWSLT', 'evaluations', '<ref type=""single"">[12].</ref>']",112,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]"
16d50365-841a-4bc8-9391-187a3ebb45d2,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,"['Zeses Pitenis, and C ¸agrı C ¸öltekin. 2020. SemEval-2020 Task 12: Multilingual Offensive Language Identification in Social Media']",['2020'],['Marcos Zampieri;Preslav Nakov;Sara Rosenthal;Pepa Atanasova;Georgi Karadzhov;Hamdy Mubarak;Leon Derczynski'],single,"['A', 'dataset', 'for', 'classification', 'tasks', 'is', 'useful', 'only', 'if', 'the', 'accuracy', 'of', 'its', 'annotations', 'can', 'be', 'confirmed.', 'To', 'this', 'end', 'we', 'use', 'BERT', 'to', 'evaluate', 'our', 'annotations', 'as', 'it', 'has', 'consistently', 'outperformed', 'other', 'models', 'in', 'recent', 'classification', 'tasks', '(see', 'e.g', '<ref type=""single"">Zampieri et al. (2020)</ref>', '),', 'and', 'Support', 'Vector', 'Machines', 'for', 'its', 'simplicity', 'and', 'effectiveness.', 'We', 'use', 'a', 'stratified', 'split', 'of', '70:20:10', 'for', 'training,', 'dev,', 'and', 'test', 'data.']",40,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
171a7909-05ca-4ac8-8908-7620837b8a97,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Islamophobia and twitter: A typology of online hate against muslims on social media'],['2014'],['I Awan'],single,"['Prevailing', 'stereotypes.', 'Previous', 'research', 'has', 'shown', 'that', 'prevailing', 'stereotypes', 'often', 'form', 'the', 'basis', 'and', 'justification', 'of', 'abuse.', 'For', 'example,', 'many', 'twitter', 'accounts', 'were', 'open', 'about', 'their', 'anger', 'and', 'hatred', 'for', 'Muslims', 'in', 'the', 'wake', 'of', 'the', 'Rochdale', 'scandal', 'that', 'involved', 'several', 'British-Asian', 'men', 'getting', 'convicted', 'for', 'child', 'grooming', '<ref type=""single"">(Awan, 2014).</ref>', 'Stereotypes', 'are', 'not', 'only', 'explicit', 'but', 'implicit', 'too', '<ref type=""single"">(Hinton, 2017),</ref>', 'which', 'often', 'show', 'up', 'as', 'implicit', 'and', 'subtle', 'abuse', 'in', 'the', 'form', 'of', 'sarcasm,', 'racist', 'jokes,', 'or', 'unnecessary', 'associations.', 'While', 'explicit', 'stereotypes', 'are', 'consciously', 'endorsed,', 'and', 'may', 'be', 'controllable,', 'implicit', 'stereotypes', 'are', 'thought', 'to', 'be', 'shaped', 'by', 'experience', 'and', 'based', 'on', 'learned', 'associations', '<ref type=""single"">(Byrd, 2019).</ref>', 'User', 'and', 'community', 'information', 'plays', 'an', 'important', 'role', 'in', 'the', 'identification', 'of', 'such', 'stereotypes.', 'For', 'example,', 'if', 'the', 'location', 'of', 'users', 'is', 'available', 'alongside', 'linguistic', 'features', 'of', 'the', 'comments', 'they', 'post,', 'one', 'can', 'quickly', 'discover', 'the', 'presence', '(or', 'absence)', 'of', 'correlations', 'between', 'specific', 'regions', 'and', 'specific', 'kinds', 'of', 'abuse.', 'Moreover,', 'shared', 'stereotypes', 'may', 'unconsciously', 'bring', 'users', 'together', 'on', 'online', 'platforms', 'to', 'form', 'communities.', 'Hence,', 'having', 'linguistic', 'information', 'of', 'a', 'community,', 'such', 'as', 'the', 'topics', 'users', 'in', 'that', 'community', 'interact', 'with', 'and', 'the', 'stance', 'of', 'users', 'towards', 'different', 'pieces', 'of', 'news,', 'can', 'help', 'capture', 'the', 'prevailing', 'stereotypes', 'that', 'form', 'the', 'motivation', 'behind', 'abusive', 'comments', 'from', 'such', 'users.']",48,"[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
175538a3-b824-4a11-8608-cc7b82bb193d,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,"[""Google's neural machine translation system""]",['2016'],['Yonghui Wu;Mike Schuster;Zhifeng Chen;V Quoc;Mohammad Le;Wolfgang Norouzi;Maxim Macherey;Yuan Krikun;Qin Cao;Klaus Gao;unk Macherey'],single,"['Linguistic', 'Embedding', 'For', 'the', 'language', 'D,', 'we', 'first', 'tokenize', 'the', 'sentence', 'into', 'a', 'sequence', 'of', 'word', 'tokens', 'using', 'WordPiece', '<ref type=""single"">(Wu et al., 2016),</ref>', 'then', 'encode', 'them', 'into', 'word', 'embeddings', 'W', '=', '{w', 'j}', 'T', 'j=1', 'where', 'w', 'j', '∈', 'R', 'dw', 'is', 'the', 'feature', 'vector.', 'Similarly,', 'an', 'index', 'position', '<ref type=""single"">(Devlin et al., 2018)</ref>', 'embedding', 'is', 'supplemented', 'to', 'each', 'word', 'embedding.']",19,"[3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
17e76819-95a3-4afc-a60c-5b02acadec0e,Can Semantic Role Labeling Improve SMT?,2009,Dekai Wu;Pascale Fung,['unknown'],['unknown'],['unknown'],single,"['We', 'use', 'the', 'Chinese', 'sentences', 'as', 'system', 'input', 'and', 'their', 'corresponding', 'English', 'translations', 'as', 'the', 'reference', 'translations.', 'We', 'use', 'the', 'open', 'source', 'statistical', 'machine', 'translation', 'decoder', 'Moses', '(?)', 'for', 'the', 'experiments,', 'translating', 'the', 'PropBank', 'Chinese', 'sentences', 'into', 'English', 'with', 'the', 'same', 'model', 'trained', 'for', 'our', 'participation', 'in', 'the', 'IWSLT', '2007', 'evaluation', 'campaign', '<ref type=""single"">(Shen et al., 2007)</ref>', '.The', 'English', 'translations', 'generated', 'by', 'the', 'decoder', 'are', 'the', 'system', 'output.', 'Based', 'on', 'the', 'system', 'input', 'and', 'the', 'reference', 'We', 'first', 'randomly', 'select', '50', 'bi-sentences,', 'without', 'any', 'constraint', 'on', 'the', 'translation', 'accuracy', 'of', 'the', 'predicate', 'verbs,', 'to', 'form', 'the', 'first', 'observation', 'data', 'set', '(data', 'set', 'A).']",52,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
18048577-d84c-4db3-a351-c956d072c53c,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,"['Pytorch: An imperative style, high-performance deep learning library']",['2019'],['Adam Paszke;Sam Gross;Francisco Massa;Adam Lerer;James Bradbury;Gregory Chanan;Trevor Killeen;Zeming Lin;Natalia Gimelshein;Luca Antiga;Alban Desmaison;Andreas Kopf;Edward Yang;Zachary Devito;Martin Raison;Alykhan Tejani;Sasank Chilamkurthy;Benoit Steiner;Lu Fang;Junjie Bai;Soumith Chintala'],single,"['The', 'backbone', 'of', 'our', 'PyTorch', '<ref type=""single"">(Paszke et al., 2019)</ref>', 'implementation', 'is', 'the', 'Transformer', 'and', 'WordpieceTokenizer', 'classes', 'offered', 'by', 'Hugging', 'Face', '<ref type=""single"">(Wolf et al., 2019).</ref>', 'We', 'use', 'pre-trained', 'BERT', 'models', 'provided', 'on', 'huggingface.co:', 'bert-base-cased,', 'dbmz/bert-base-german-cased,', 'dbmz/bert-base-italian-cased,', 'and', 'Geotrend/BERT-base-nl-cased', '<ref type=""single"">(Abdaoui et al., 2020),</ref>', 'keeping', 'their', 'default', 'configuration.', 'The', 'only', 'hyperparameters', 'we', 'choose', 'ourselves', 'are', 'the', 'batch', 'size', '(24),', 'the', 'learning', 'rate,', 'and', 'the', 'number', 'of', 'epochs.', 'We', 'used', 'the', 'Adam', 'optimizer', 'to', 'train', 'all', 'the', 'parameters', 'in', 'our', 'model', 'including', 'the', 'pretrained', 'BERT.', 'To', 'ensure', 'stability', 'and', 'avoid', 'overfitting,', 'we', 'used', 'a', 'linear', 'scheduler', 'with', 'no', 'warm-up', 'step,', 'which', 'gradually', 'reduces', 'the', 'learning', 'rate', 'from', '0.0015', 'to', '0', 'for', 'each', 'training', 'iteration.', 'During', 'preliminary', 'experiments', 'on', 'the', 'development', 'set,', 'we', 'found', 'that', 'training', 'loss', 'barely', 'changed', 'after', 'five', 'epochs.']",5,"[2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
182f4102-6abc-49aa-8deb-db6ebb7dbe3c,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,"['A system for diacritizing four varieties of arabic', 'Farasa: A fast and furious segmenter for arabic', 'Highly effective arabic diacritization using sequence to sequence modeling']","['2019', '2016', '2019']","['Hamdy Mubarak;Ahmed Abdelali;Kareem Darwish;Mohamed Eldesouki;Younes Samih;Hassan Sajjad', 'Ahmed Abdelali;Kareem Darwish;Nadir Durrani;Hamdy Mubarak', 'Hamdy Mubarak;Ahmed Abdelali;Hassan Sajjad;Younes Samih;Kareem Darwish']",group,"['Since', 'the', 'removal', 'of', 'diacritics', 'also', 'clearly', 'leads', 'to', 'a', 'potential', 'ambiguity', 'as', 'explained', 'in', 'Section', '(2.1)', 'there', 'has', 'been', 'some', 'work', 'on', 'automatic', 'diacritization', 'of', 'partially', 'diacritized', 'or', 'undiacritized', 'text', '<ref type=""group"">(Mubarak et al., 2019a, Mubarak et al., 2019b, Abdelali et al., 2016).</ref>']",31,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
186beee9-b17d-4dbc-aed1-a3bb6178283b,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,"['Rule-based translation with statistical phrase-based post-editing', ""Statistical post-editing on SYSTRAN's rule-based translation system""]","['2007', '2007']","['M Simard;N Ueffing;P Isabelle;R Kuhn', 'L Dugast;J Senellart;P Koehn']",group,"['In', 'the', 'last', 'years,', 'there', 'is', 'increasing', 'interest', 'in', 'the', 'interaction', 'between', 'rule-based', 'and', 'statistical', 'machine', 'translation.', 'A', 'popular', 'and', 'successful', 'idea', 'is', 'statistical', 'post', 'editing', '<ref type=""group"">[16, 17].</ref>', 'The', 'principle', 'idea', 'is', 'to', 'train', 'an', 'SMT', 'system', 'to', 'correct', 'the', 'outputs', 'of', 'a', 'rule-based', 'translation', 'system.']",26,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
186ee4a3-16c0-40c4-b697-5664050234e0,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Probabilistic part-of-speech tagging using decision trees'],['1994'],['Helmut Schmid'],single,"['Data', 'acquisition', 'in', 'DeKo', 'was', 'done', 'on', 'the', 'basis', 'of', 'a', 'corpus:', 'we', 'used', 'German', 'newspaper', 'corpora,', 'which', 'were', 'tagged', 'with', 'the', 'TreeTagger', '<ref type=""single"">(Schmid 1994)</ref>', 'and', 'lemmatized', 'with', 'DMOR', '<ref type=""single"">(Schiller 1996),</ref>', 'for', 'searching', 'and', 'pre-processing', 'we', 'used', 'the', 'Corpus', 'Query', 'Processor', '<ref type=""single"">(Schiller 1996)</ref>', 'and', 'a', 'number', 'of', 'Perl', 'scripts.', 'In', 'acquiring', 'and', 'systematizing', 'the', 'data', 'we', 'made', 'a', 'distinction', 'between', 'word', 'formation', 'involving', 'selecting', 'elements', '(roughly', 'derivation)', 'and', 'word', 'formation', 'involving', 'only', 'categories', '(compounding).', 'For', 'expository', 'purposes', 'we', 'concentrate', 'on', 'a', 'derivation', 'process', 'here', 'and', 'only', 'briefly', 'describe', 'a', 'compounding', 'process', 'below.']",23,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
187c22eb-00e5-42d7-af86-7de8fb679b7f,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['Feverous: Fact extraction and verification over unstructured and structured information'],['2021'],['Rami Aly;Zhijiang Guo;M Schlichtkrull;James Thorne'],single,"['The', 'task', 'of', 'fact', 'extraction', 'and', 'verification', 'aims', 'to', 'extract', 'evidence', 'and', 'verify', 'a', 'given', 'claim.', 'Previous', 'efforts', 'focus', 'on', 'dealing', 'with', 'text', 'format', 'evidence', 'from', 'unstructured', 'documents', '<ref type=""group"">(Nie et al., 2019, Zhong et al., 2020, Kruengkrai et al., 2021)</ref>', 'or', 'evidence', 'from', 'a', 'single', 'given', 'table', '<ref type=""group"">(Chen et al., 2020, Yang et al., 2020, Eisenschlos et al., 2020).</ref>', 'Recently,', '<ref type=""single"">Aly et al. (2021)</ref>', 'propose', 'a', 'new', 'realistic', 'setting,', 'FEVEROUS,', 'i.e.,', 'fact', 'extraction', 'and', 'verification', 'over', 'unstructured', 'and', 'structured', 'information.', 'In', 'FEVEROUS,', 'models', 'should', 'not', 'only', 'extract', 'evidence', 'sentences/table', 'cells', 'from', 'millions', 'of', 'passages,', 'but', 'also', 'combine', 'the', 'evidence', 'in', 'different', 'formats', 'to', 'verify', 'a', 'given', 'claim.']",38,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
18ec840a-47c6-47fd-b385-576cc8e93bab,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['BURS automata generation'],['1995'],['T Proebsting'],single,"['The', 'process', 'of', 'breaking', 'down', 'an', 'input', 'abstract', 'syntax', 'tree', '(AST)', 'into', 'component', 'pattern', 'trees,', 'in', 'order', 'to', 'generate', 'an', 'instruction', 'set,', 'is', 'a', 'standard', 'one', 'in', 'compilers.', 'The', 'standard', 'technique', 'involves', 'a', 'bottom-up', 'rewriting', 'system', '(BURS),', 'with', 'the', 'optimal', 'instruction', 'set', 'constructed', 'by', 'the', 'dynamic', 'programming', 'algorithm', 'of', '<ref type=""single"">Proebsting (1995),</ref>', 'see', 'for', 'example', '<ref type=""single"">Grune et al. (2000).</ref>', 'Because', 'of', 'the', 'natureA', '(¬½', '•«½', '½', '¬', '½', '«', '½,', '«', '¿)', 'A', '(¬½', '•«½', '½', '¬', '½', '«', '½,', '«', '¿,', '«)', 'A', '(«½', '½,«,', '«', '½)', 'a', 'b', 'b', 'b', 'c', '«', '½', '´', 'µ:', 'S', 'A', 'a', 'b', 'c', '«', '´', 'µ:', 'A', 'NA', 'A', 'a', 'b', 'b', '«', '¾', '´', '¿µ:', 'S', 'A', 'c', '¬', '½', '´', '¿µ:', 'A', 'A', '£', 'NA', 'b', '«', '¿', '´', '¿µ:', 'A', 'A', 'b', '«', '´', '¿µ:', 'A', 'NA', 'a', 'bFigure', '7:', 'Abstract', 'Syntax', 'Tree', 'and', 'pattern', 'trees', 'of', 'programming', 'languages,', 'the', 'sort', 'of', 'pattern', 'trees', 'that', 'are', 'allowed', 'are', 'only', 'groupings', 'of', 'contiguous', 'nodes,', 'in', 'effect,', 'tree', 'parsing', 'is', 'allowed', 'with', 'a', 'tree', 'grammar', 'consisting', 'of', 'trees', 'of', 'possibly', 'multiple', 'levels', 'and', 'allowing', 'only', 'concatenation:', 'this', 'is', 'equivalent', 'to', 'a', 'TSG.', 'Consider', 'an', 'AST', 'in', 'Figure', '7', '(ignoring', 'the', 'annotations', 'on', 'the', 'nodes,', 'in', 'parentheses),', 'and', 'take', 'for', 'pattern', 'trees', 'only', 'those', 'initial', 'trees', 'of', 'Figure', '7', '(«', '½', '«', ').', 'It', 'can', 'be', 'seen', 'that', 'the', 'AST', 'can', 'be', 'decomposed', 'in', 'several', 'ways,', 'for', 'example', 'by', 'the', 'set', 'of', 'pattern', 'trees', '«', '¾', '«', '¿', '«', '¿', '«', 'or', 'the', 'set', '«', '¾', '«', '¿', '«.', 'If', 'the', 'numbers', 'in', 'parentheses', 'after', 'the', 'labels', '()', 'are', 'considered', 'as', 'costs,', 'an', 'optimal', 'decomposition', 'can', 'be', 'determined', '(here,', '«', '¾', '«', '¿', '«', ').', 'Now', 'in', 'Section', '4.2', 'we', 'develop', 'an', 'algorithm', 'based', 'on', 'this', 'which', 'allows', 'an', 'input', 'AST', '(for', 'us,', 'a', 'derivation', 'or', 'dependency', 'structure,', 'for', 'example)', 'to', 'be', 'broken', 'into', 'component', 'non-contiguous', ""'trees'"", 'efficiently.', 'From', 'a', 'theoretical', 'point', 'of', 'view', 'this', 'is', 'interesting,', 'as', 'the', 'expectation', 'would', 'be', 'that', 'some', 'more', 'complex', 'mechanism', 'would', 'be', 'necessary,', 'in', 'much', 'the', 'same', 'way', 'that', 'allowing', 'stretching', 'of', 'paired', 'characters', 'in', 'strings', '(say,', 'in', 'the', 'language', 'of', 'nested', 'strings', 'Ò', 'Ò', 'Ò', '¼,', 'where', 'the', 'th', 'is', 'matched', 'with', 'the', '´Ò', '½', 'µ', 'th)', 'cannot', 'be', 'performed', 'by', 'a', 'finite', 'state', 'automaton', 'but', 'requires', 'a', 'pushdown', 'automaton', 'through', 'the', 'addition', 'of', 'a', 'stack,', 'here,', 'it', 'might', 'be', 'expected', 'that', 'a', 'stack', 'is', 'similarly', 'necessary', 'to', 'keep', 'track', 'of', 'the', 'unbounded', 'elements.']",49,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1902a247-750a-45de-b0c7-6108890e3149,Diverse dialogue generation with context dependent dynamic loss function,2020,Ayaka Ueyama;Yoshinobu Kano,['Another diversity promoting objective function for neural dialogue generation'],['2018'],['Ryo Nakamura;Katsuhito Sudoh;Koichiro Yoshino;Satoshi Nakamura'],single,"['The', 'SCE', 'loss,', 'which', 'is', 'often', 'used', 'to', 'train', 'a', 'sequence-to-sequence', '(Seq2Seq)', 'model', '<ref type=""single"">(Sutskever et al., 2014),</ref>', 'is', 'expressed', 'as', '𝐿', '𝑆𝐶𝐸', '=', '−𝑙𝑜𝑔{𝑠𝑜𝑓𝑡𝑚𝑎𝑥', '𝑐', '},', 'where𝑠𝑜𝑓𝑡𝑚𝑎𝑥', '𝑐', '=', '𝑒', '𝑑', '𝑐', '∑', '𝑒', '𝑑', '𝑘', '|𝑉|', '𝑘.', 'Therein,', '𝑉', 'represents', 'the', 'lexicon,', '𝑑', '𝑘', 'denotes', 'the', '𝑘-th', 'element', 'of', 'the', 'output', '𝑑', '∈', 'ℝ', '|𝑉|.', '<ref type=""single"">Nakamura et al. (2018)</ref>', 'defined', 'Inverse', 'Token', 'Frequency', '(ITF)', 'loss', 'as', 'shown', 'below.']",53,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3]"
19382018-a2fd-48e3-b36f-13e9d9199fcf,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Abusive language detection with graph convolutional networks'],['2019'],['Pushkar Mishra;Marco Tredici;Helen Yannakoudakis;Ekaterina Shutova'],single,"['Across', 'the', 'three', 'categories', 'of', 'methods,', 'we', 'note', 'that', 'the', 'general', 'setup', 'is', 'to', 'create', 'representations,', 'called', 'profiles,', 'for', 'users', 'or', 'communities', 'and', 'utilize', 'them', 'alongside', 'linguistic', 'features.', 'In', 'social', 'feature', 'engineering', 'based', 'methods,', 'these', 'profiles', 'are', 'manually', 'constructed', 'vectors', 'of', 'features', 'that', 'capture', 'the', 'relevant', 'traits,', 'such', 'as', 'age', 'in', 'the', 'case', 'of', 'cyber-bullying', 'and', 'gender', 'in', 'the', 'case', 'of', 'sexism.', 'In', 'user', 'embeddings', 'and', 'social', 'graph', 'based', 'methods,', 'the', 'profiles', 'are', 'instead', 'generated', 'by', 'neural', 'network', 'architectures', 'to', 'capture', 'the', 'linguistic', 'behavior', 'or', 'community', 'traits', 'of', 'users.', 'That', 'said,', 'across', 'all', 'three', 'categories,', 'the', 'profiles', 'essentially', 'provide', 'a', 'wider', 'context', 'to', 'the', 'comment', 'being', 'classified', 'for', 'abuse.', 'For', 'example,', 'having', 'the', 'gender', 'of', 'the', 'user', 'who', 'produces', 'a', 'comment', 'such', 'as', '""Had', 'an', 'accident,', 'women', ""can't"", 'drive', 'it', 'seems!""', 'can', 'help', 'to', 'classify', 'the', 'comment', 'as', 'sexist', 'or', 'not', 'by', 'differentiating', 'benign', 'self-deprecating', 'humor', 'from', 'intent', 'to', 'degrade.', 'The', 'context', 'that', 'the', 'profiles', 'encode', 'increases', 'as', 'we', 'go', 'from', 'social', 'feature', 'engineering', 'based', 'methods', 'to', 'user', 'embeddings', 'based', 'methods', 'and', 'further', 'to', 'social', 'graph', 'based', 'methods.', 'This', 'is', 'also', 'evident', 'from', 'the', 'magnitude', 'of', 'gains', 'that', 'the', 'profiles', 'provide', 'on', 'top', 'of', 'linguistic', 'features.', 'For', 'example,', 'the', 'gender', 'feature', 'only', 'increases', 'the', 'F', '1', 'from', '73.89%', 'to', '73.93%', 'over', 'character', 'n-gram', 'counts', 'on', 'the', 'dataset', 'by', '<ref type=""single"">Waseem and Hovy (2016),</ref>', 'while', 'the', 'social', 'graph', 'based', 'method', 'of', '<ref type=""single"">Mishra et al. (2019)</ref>', 'increases', 'the', 'F', '1', 'to', 'above', '80%.', 'The', 'example', 'aside,', 'it', 'makes', 'intuitive', 'sense', 'that', 'profiles', 'from', 'social', 'graph', 'based', 'methods', 'encode', 'the', 'most', 'amount', 'of', 'context,', 'since', 'these', 'profiles', 'are', 'able', 'to', 'capture', 'the', 'various', 'phenomena', 'that', 'occur', 'in', 'social', 'networks,', 'the', 'most', 'prominent', 'ones', 'of', 'which', 'are:']",226,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
193db12c-e687-499f-9de0-83449c1a483d,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['Machine learning classifiers and fMRI: A tutorial overview'],['2009'],['Francisco Pereira;Tom Mitchell;Matthew Botvinick'],single,"['Results.', 'For', 'the', 'SVM,', 'the', '3-1', 'pretraining', 'without', 'data', 'augmentation', 'resulted', 'in', 'the', 'highest', 'dev', 'set', 'accuracy', '(32.03%),', 'though', 'accuracy', 'was', 'only', 'slightly', 'better', 'than', 'for', 'direct', 'single-trial', 'training', '(31.93%).', 'For', 'the', 'Transformer,', 'the', '3-1', 'pretraining', 'scheme', 'with', '250k', 'data', 'augmentation', 'obtained', 'the', 'highest', 'single-trial', 'decoding', 'accuracy', '(39.41%)', 'on', 'the', 'dev', 'set.', 'Indeed,', 'Wilcoxon', 'signed-rank', 'test', '<ref type=""single"">(Pereira et al., 2009)</ref>', 'confirmed', 'that', 'the', 'best', 'dev', 'set', 'Transformer', 'performed', 'significantly', 'better', 'on', 'the', 'test', 'set', 'after', '3-1', 'pretraining', 'than', 'after', 'direct', 'single-trial', 'training', '(p', '&lt,', '0.01).']",56,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
1951dc93-f7c0-446e-8515-967145633a58,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,"['BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension']",['2020'],['Mike Lewis;Yinhan Liu;Naman Goyal ; Abdelrahman Mohamed;Omer Levy;Veselin Stoyanov;Luke Zettlemoyer'],single,"['Second,', 'we', 'propose', 'to', 'directly', 'use', 'coreference', 'resolution', 'datasets', 'for', 'training', 'MRC', 'models', 'to', 'improve', 'their', 'coreference', 'reasoning.', 'We', 'automatically', 'create', 'a', 'question', 'whose', 'answer', 'is', 'a', 'coreferring', 'expression', 'm', '1', 'using', 'the', 'BART', 'model', '<ref type=""single"">(Lewis et al., 2020).</ref>', 'We', 'then', 'consider', 'this', 'question,', 'm', '1', ""'s"", 'antecedent,', 'and', 'the', 'corresponding', 'document', 'as', 'a', 'new', '<ref type=""single"">(question, answer, context)</ref>', 'tuple.', 'This', 'data', 'helps', 'the', 'model', 'learning', 'to', 'resolve', 'the', 'coreference', 'relation', 'between', 'm', '1', 'and', 'its', 'antecedent', 'to', 'answer', 'the', 'question.', 'We', 'show', 'that', 'incorporating', 'these', 'additional', 'data', 'improves', 'the', 'performance', 'of', 'the', 'state-of-the-art', 'models', 'on', 'our', 'new', 'evaluation', 'set.']",35,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
19b3727e-4dd0-412a-bdaf-7edd2fab4b56,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Rethinking action spaces for reinforcement learning in end-to-end dialog agents with latent variable models'],['2019'],['Tiancheng Zhao;Kaige Xie;Maxine Eskenazi'],single,"['To', 'deal', 'with', 'the', 'absence', 'of', 'action', 'annotations,', 'latent', 'action', 'learning', 'has', 'been', 'introduced', '<ref type=""group"">(Zhao et al., 2018, Yarats and Lewis, 2018).</ref>', 'System', 'utterances', 'are', 'represented', 'as', 'low-dimensional', 'latent', 'variables', 'by', 'an', 'auto-encoding', 'task', '<ref type=""single"">(Zhao et al., 2019),</ref>', 'and', 'utterances', 'with', 'the', 'same', 'representations', 'are', 'considered', 'to', 'convey', 'similar', 'meanings.', 'Such', 'action', 'representations', 'might', 'be', 'prone', 'to', 'overdependence', 'on', 'the', 'training', 'data,', 'which', 'restricts', 'the', 'model', 'generalization', 'capability,', 'especially', 'when', 'multiple', 'domains', 'are', 'considered.', 'This', 'is', 'because,', 'without', 'explicit', 'supervision,', 'the', 'desired', 'property', 'of', 'capturing', 'the', 'intentions', 'of', 'system', 'utterances', 'in', 'the', 'latent', 'space', 'cannot', 'be', 'enforced', '<ref type=""single"">(Locatello et al., 2019),</ref>', 'which', 'in', 'turn', 'is', 'due', 'to', 'the', 'implicit', 'nature', 'of', 'latent', 'variables.', 'For', 'example,', 'variational', 'auto-encoder', '(VAE),', 'which', 'is', 'often', 'used', 'for', 'latent', 'action', 'learning,', 'tends', 'to', 'produce', 'a', 'balanced', 'distribution', 'over', 'the', 'latent', 'variables', '<ref type=""single"">(Zhao et al., 2018),</ref>', 'while', 'the', 'true', 'distribution', 'of', 'system', 'actions', 'is', 'highly', 'imbalanced', '<ref type=""single"">(Budzianowski et al., 2018).</ref>', 'The', 'resulting', 'misaligned', 'action', 'representations', 'would', 'confuse', 'the', 'model', 'of', 'both', 'steps', 'and', 'degenerate', 'the', 'sample', 'efficiency', 'in', 'training.']",27,"[2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
19bbf577-3280-4bdb-89c7-ceed7f892fc4,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Language as an abstraction for hierarchical deep reinforcement learning'],['2019'],['Yiding Jiang;Shixiang Gu;Kevin Murphy;Chelsea Finn'],single,"['To', 'address', 'the', 'above', 'issues,', 'we', 'propose', 'to', 'learn', 'natural', 'language', 'actions', 'that', 'represent', 'system', 'utterances', 'as', 'a', 'span', 'of', 'words,', 'which', 'explicitly', 'reveal', 'the', 'underlying', 'intentions.', 'Natural', 'language', 'provides', 'unique', 'compositional', 'structure', 'while', 'retaining', 'the', 'representation', 'flexibility.', 'These', 'properties', 'promote', 'model', 'generalization', 'and', 'thus', 'make', 'natural', 'language', 'a', 'flexible', 'representation', 'for', 'capturing', 'characteristics', 'with', 'minimal', 'assumptions', '<ref type=""single"">(Jiang et al., 2019).</ref>', 'Motivated', 'by', 'these', 'advantages,', 'we', 'learn', 'natural', 'language', 'actions', 'by', 'identifying', 'salient', 'words', 'of', 'system', 'utterances.', 'Salient', 'refers', 'to', 'indicative', 'for', 'a', 'prediction', 'task', '(e.g.,', 'sentiment', 'analysis)', 'that', 'takes', 'as', 'input', 'the', 'original', 'utterance.', 'The', 'main', 'rationale', 'is', 'that', 'the', 'principal', 'information', 'that', 'the', 'task', 'concerns', 'can', 'be', 'preserved', 'by', 'just', 'the', 'salient', 'words.', 'For', 'example,', 'the', 'sentiment', 'of', 'sentence', '""The', 'movie', 'starts', 'out', 'as', 'competent', 'but', 'turn', 'bland""', 'can', 'be', 'revealed', 'by', 'the', 'word', '""bland""', 'when', 'it', 'is', 'identified', 'salient', 'by', 'considering', 'the', 'complete', 'context.', 'In', 'our', 'scenarios,', 'we', 'consider', 'measuring', 'word', 'saliency', 'in', 'terms', 'of', 'state', 'transitions.', 'This', 'is', 'because', 'state', 'transitions', 'reflect', 'how', 'the', 'intentions', 'of', 'a', 'system', 'utterance', 'influence', 'the', 'dialogue', 'progress,', 'and', 'action', 'representations', 'that', 'capture', 'such', 'influences', 'can', 'well', 'reveal', 'the', 'intentions', '<ref type=""group"">(Chandak et al., 2019, Tennenholtz and Mannor, 2019, Huang et al., 2020b).</ref>', 'By', 'considering', 'salient', 'words', 'for', 'state', 'tracking', 'tasks', 'as', 'actions,', 'we', 'obtain', 'action', 'representations', 'that', 'enjoy', 'the', 'merits', 'of', 'natural', 'language', 'and', 'indeed', 'capture', 'the', 'characteristics', 'of', 'interest,', 'i.e.,', 'intentions', 'of', 'system', 'utterances.']",57,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
19ebd7e7-e109-4438-868c-40e52ad2b8b4,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Prospects for practical parsing of unrestricted text: robust statistical parsing techniques'],['1994'],['E Briscoe'],single,"['of', 'features', 'not', 'incorporated', 'into', 'the', 'backbone', 'is', 'performed', 'at', 'parse', 'time', 'in', 'conjunction', 'with', 'reduce', 'operations.', 'Unification', 'failure', 'results', 'in', 'the', 'associated', 'derivation', 'being', 'assigned', 'a', 'probability', 'of', 'zero.', 'Probabilities', 'are', 'assigned', 'to', 'transitions', 'in', 'the', 'LALR(', '1)', 'action', 'table', 'via', 'a', 'proc�', 'of', 'supervised', 'training', 'based', 'on', 'computing', 'the', 'frequency', 'with', 'which', 'transitions', 'are', 'traversed', 'in', 'a', 'corpus', 'of', 'parse', 'histories.', 'The', 'result', 'is', 'a', 'probabilistic', 'parser', 'which,', 'unlike', 'a', 'PCFG,', 'is', 'capable', 'of', 'probabilistically', 'discriminating', 'derivations', 'which', 'differ', 'only', 'in', 'terms', 'of', 'order', 'of', 'application', 'of', 'the', 'same', 'set', 'of', 'CF', 'backbone', 'rules,', 'due', 'to', 'the', 'parse', 'context', 'defined', 'by', 'the', 'LR', 'table.', 'Experiments', 'with', 'this', 's', 'ys', 'tem', 'revealed', 'three', 'major', 'problems', 'which', 'our', 'current', 'research', 'is', 'addressing.', 'Firstly,', 'although', 'the', 'system', 'is', 'able', 'to', 'rank', 'parses', 'with', 'a', '75%', 'chance', 'that', 'the', 'correct', 'anal', 'ys', 'is', 'will', 'be', 'the', 'most', 'highly', 'ranked,', 'further', 'improvement', 'will', 'require', 'a', ""'lexicalised'"", 'system', 'in', 'which', '(minimally)', 'probabilities', 'are', 'associated', 'with', 'alternative', 'subcategorisation', 'possibilities', 'of', 'individual', 'lexical', 'items.', 'Currently,', 'the', 'relative', 'frequency', 'of', 'subcategorisation', 'possibilities', 'for', 'individual', 'lexical', 'items', 'is', 'not', 'recorded', 'in', 'wide-coverage', 'lexicons,', 'such', 'as', 'ANLT', 'or', 'COMLEX', '<ref type=""single"">(Grishman et al., 1994).</ref>', 'Secondly,', 'removal', 'of', 'punctuation', 'from', 'the', 'input', '(after', 'segmentation', 'int.o', 'text', 'sentences)', 'worsens', 'performance', 'as', 'punctuation', 'both', 'reduces', 'syntactic', 'ambiguity', '<ref type=""single"">(Jones, 1994) and signals non-syntactic (discourse)</ref>', 'relations', 'between', 'text', 'units', '<ref type=""single"">(Nun berg, 1990).</ref>', 'Thirdly,', 'the', 'largest', 'source', 'of', 'error', 'on', 'unseen', 'input', 'is', 'the', 'omission', 'of', 'appropriate', 'subcategorisation', 'values', 'for', 'lexical', 'items', '(mostly', 'verbs),', 'preventing', 'the', 'system', 'from', 'finding', 'the', 'correct', 'analysis.', 'The', 'current', 'coverage', 'of', 'this', 'system', 'on', 'a', 'general', 'corpus', '(e.g.', 'Brown', 'or', 'LOB)', 'is', 'estimated', 'to', 'be', 'around', '20%', 'by', '<ref type=""single"">Briscoe (1994).</ref>', 'We', 'have', 'developed', 'a', 'variant', 'probabilistic', 'LR', 'parser', 'which', 'does', 'not', 'rely', 'on', 'subcategorisation', 'and', 'uses', 'punctuation', 'to', 'reduce', 'ambiguity.', 'The', 'anal', 'ys', 'es', 'produced', 'by', 'this', 'parser', 'could', 'be', 'utilised', 'for', 'phrase-finding', 'applications,', 'recovery', 'of', 'subcategorisation', 'frames,', 'and', 'other', ""'intermediate'"", 'level', 'parsing', 'problems.']",267,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1a23249c-0aa3-465b-abce-3f2e916d145f,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,"['Revisiting fewsample {bert} fine-tuning', 'On the stability of fine-tuning {bert}: Misconceptions, explanations, and strong baselines']","['2021', '2021']","['Tianyi Zhang;Felix Wu;Arzoo Katiyar;Q Kilian;Yoav Weinberger;unk Artzi', 'Marius Mosbach;Maksym Andriushchenko;Dietrich Klakow']",group,"['Effect', 'of', 'hyperparameter', 'tuning', 'A', 'generally', 'unstated', 'assumption', 'is', 'that', 'pre-trained', 'linguistic', 'models', 'are', 'under-optimized', 'and', 'that', 'practices', 'commonly', 'adopted', 'for', 'the', 'fine-tuning', 'stage', 'can', 'be', 'detrimental', 'to', 'performance', '<ref type=""group"">(Zhang et al., 2021, Mosbach et al., 2021).</ref>', 'This', 'is', 'quite', 'apparent', 'in', 'all', 'settings,', 'with', 'better', 'gains', 'through', 'hyperparameter', 'optimization', 'stages.', 'Fine-tuning', 'CamemBERT', 'large', 'on', 'the', 'French', 'dataset', 'yields', '90.2', '/', '75.5', 'F1', '/', 'EM', 'on', 'the', 'FQuAD', 'dev', 'set.', 'By', 'means', 'of', 'comparison,', 'CamemBERT', 'large', 'scores', 'were', '81.2', '/', '55.9', 'F1', '/', 'EM', 'on', 'the', 'same', 'set', 'with', 'no', 'hyperparameter', 'tuning.']",29,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1a6f5495-0c9d-4a62-be81-5fc89bfa65f2,Entity Attribute Relation Extraction with Attribute-Aware Embeddings,2020,Dan Iter;Xiao Yu;Fangtao Li,['Improving hypernymy detection with an integrated path-based and distributional method'],['2016'],['Vered Shwartz;Yoav Goldberg;Ido Dagan'],single,"['Our', 'baseline', 'model', 'is', 'inspired', 'by', 'a', 'hypernym', 'classification', 'model', 'proposed', 'by', '<ref type=""single"">Shwartz et al. (2016),</ref>', 'also', 'using', 'a', 'pair', 'of', 'terms', 'with', 'a', 'set', 'of', 'support', 'sentences', 'where', 'the', 'terms', 'co-occur.']",12,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
1a85e328-bf4d-4134-9493-6f62561499fe,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Retrieving word associations with a simple neighborhood algorithm in a graph-based resource'],['2014'],['Gemma Bel-Enguix'],single,"['Although', 'many', 'NLP', 'methods', 'have', 'already', 'been', 'used', 'to', 'generate', 'distance', 'matrices,', 'others', 'are', 'worth', 'trying.', 'Examples', 'include', 'graph', 'embedding', 'of', 'associations', '<ref type=""single"">(Bel-Enguix, 2014)</ref>', 'and', 'GraphGlove', '<ref type=""single"">(Ryabinin et al., 2020).</ref>']",22,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3]"
1a8a5992-3076-4f52-b309-b97eb133c793,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Connecting vision and language with localized narratives'],['2020'],['Jordi Pont-Tuset;Jasper Uijlings;Beer Changpinyo;Radu Soricut;Vittorio Ferrari'],single,"['To', 'reduce', 'the', 'deviation', 'caused', 'by', 'different', 'implementation', 'details,', 'we', 'first', 'present', 'our', ""implementations'"", 'performance', '(with', '*),', 'which', 'have', 'a', 'higher', 'score', 'than', '<ref type=""single"">Pont-Tuset et al. (2020)</ref>', 'reported.', 'Thus,', 'we', 'have', 'a', 'more', 'strict', 'baseline', 'to', 'evaluate', 'the', 'improvement', 'purely', 'coming', 'from', 'our', 'innovative', 'method.', 'Compared', 'to', 'Baseline*', 'method,', 'the', 'performance', 'on', 'all', 'metrics', 'improves', 'significantly', 'when', 'controlling', 'captioning', 'using', 'the', 'mouse', 'trace', '(+Trace*),', 'it', 'indicates', 'that', 'using', 'the', 'mouse', 'trace', 'enables', 'the', 'system', 'to', 'describe', 'better', 'those', 'user', 'intended', 'parts', 'of', 'the', 'image.']",23,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1acae304-83c2-423e-b81d-2e3d4d36d8a6,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Language models are few-shot learners'],['2020'],['Tom Brown;Benjamin Mann;Nick Ryder;Melanie Subbiah;Jared Kaplan;Prafulla Dhariwal;Arvind Neelakantan;Pranav Shyam;Girish Sastry;Amanda Askell'],single,"['GPT-3', 'displays', 'strong', 'zero-shot', 'abilities', '<ref type=""single"">(Brown et al., 2020),</ref>', 'i.e.,', 'using', 'a', 'simple', 'instruction', 'or', '""prompt""', 'as', 'input,', 'the', 'model', 'will', 'extend', 'or', 'complete', 'the', 'text', 'accordingly', 'without', 'any', 'pre-defined', 'examples.', 'Prompt-engineering', 'thus', 'refers', 'to', 'manipulations', 'and', 'perturbations', 'of', 'this', 'prompt', 'to', 'context-force', 'the', 'desired', 'output', 'behaviour', '<ref type=""single"">(Liu et al., 2021a).</ref>', 'In', 'contrast', 'to', 'zero-shot,', 'GPT-3', 'can', 'be', 'fine-tuned', 'over', 'a', 'dataset', 'with', 'desired', 'inputoutput', 'pairs', '<ref type=""single"">(Brown et al., 2020).</ref>', 'To', 'conduct', 'the', 'experiment', 'to', 'compare', 'neutral', 'and', 'diversityencouraging', 'prompts,', 'we', 'compile', 'a', 'list', 'of', '18', 'prompts.', 'Nine', 'of', 'them', 'are', 'designated', '""neutral""', 'and', 'used', 'as', 'our', '""zero-shot""', 'prompts.', 'These', 'simply', 'specify', 'a', 'task', 'of', 'generating', 'an', 'ad', 'for', 'a', 'given', 'job', 'but', 'are', 'syntactically', 'varied.', 'The', 'other', 'nine', 'prompts', 'are', '""equality', 'and', 'diversity', 'prompts"",', 'which', 'we', 'call', '""engineered""', 'prompts.', 'Tab.', '3', 'displays', 'all', '18', 'prompts', 'with', 'their', 'respective', 'bias', 'and', 'realism', 'scores.']",60,"[3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1b55a66f-4e55-4132-b9f9-1a9d957d53c8,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,"['End-to-End Named Entity Recognition from English Speech', 'Joint Speech Recognition and Speaker Diarization via Sequence Transduction', 'Endto-end named entity and semantic concept extraction from speech', 'Building competitive direct acoustics-to-word models for english conversational speech recognition']","['2020', '2019', '2018', '2018']","['H Yadav;S Ghosh;Y Yu;R Shah', 'Laurent Shafey;Hagen Soltau;Izhak Shafran', 'S Ghannay;A Caubrière;Y Estève;N Camelin;E Simonnet;A Laurent;E Morin', 'K Audhkhasi;B Kingsbury;B Ramabhadran;G Saon;M Picheny']",group,"['(b)', 'One-to-one', 'model', 'with', 'a', 'conditional', 'chain', 'mapping.""', '!""#', '#', '""', '#""#', '#', '$', '#', '""', '$', '""#', '!!', '""', '!""!', '#', '""', '#""!', '#', '""', '!""#', '#', '""', '#""#', '#', '$', '#', '""', '$', '""', '""!', '#', '""', '$!', '""#!', '!""+##\',*', '!""#$%#&amp,\'#(-(.()*!', '""', '#', '""', '#', '$', '#', '""(c)', 'One-to-one', 'model', 'with', 'a', 'single', 'sequence.', 'data,', 'including', 'spoken', 'dialogue', 'systems', '<ref type=""single"">(Jurafsky and Martin, 2008).</ref>', 'This', 'study', 'aims', 'to', 'endow', 'existing', 'E2E', 'ASR', 'models', 'with', 'the', 'ability', 'to', 'produce', 'such', 'linguistic', 'annotations.', 'Prior', 'work', 'explored', 'using', 'E2E', 'ASR', 'systems', 'to', 'predict', 'multiple', 'kinds', 'of', 'labels.', 'Fig.', '1', 'shows', 'a', 'diagram', 'of', 'these', 'systems.', 'These', 'approaches', 'use', 'one', 'of', 'the', 'following', 'models:', 'a', 'one-to-many', '(O2M)', 'model', '<ref type=""group"">(Kubo and Bacchiani, 2020, Ueno et al., 2018, Gowda et al., 2019, Sanabria and Metze, 2018, Adams et al., 2019),</ref>', 'a', 'one-to-one', '(O2O)', 'model', 'with', 'a', 'conditional', 'chain', 'mapping', '<ref type=""single"">(Shi et al., 2020),</ref>', 'or', 'an', 'O2O', 'model', 'with', 'a', 'single', 'sequence', '<ref type=""group"">(Audhkhasi et al., 2018, Ghannay et al., 2018, Shafey et al., 2019, Yadav et al., 2020).</ref>']",131,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1]"
1b9301b6-96c4-4071-a5dd-1e9552cf4de3,A Parameter-Based Message-Passing Parser for MT of Korean and English,1994,Bonnie Dorr;Jye-Hoon Lee;Sungki Suh,['Solving thematic divergences in machine translation'],['1990'],['B Dorr'],single,"['The', 'parameterized', 'framework', 'described', 'above', 'has', 'been', 'implemented', 'in', 'C++', 'and', 'successfully', 'tested', 'on', 'well', 'known,', 'translationally', 'divergent', 'sentences.', '<ref type=""single"">Dorr (1990)</ref>', 'We', 'ran', 'the', 'parameterized', 'parser', 'on', 'both', 'the', 'English', 'and', 'Korean', 'sentences', 'shown', 'here.', 'The', 'results', 'shown', 'in', 'Figure', '5', 'which', 'were', 'obtained', 'from', 'running', 'the', 'program', 'on', 'a', 'Sparcstation', 'ELC.', '3', 'In', 'general,', 'the', 'times', 'demonstrate', 'a', 'speedup', 'of', '2', 'to', '3', 'orders', 'of', 'magnitude', 'over', 'previous', 'principlebased', 'parsers', 'on', 'analogous', 'examples', 'such', 'as', 'those', 'given', 'in', '<ref type=""single"">Dorr (1993a).</ref>', 'Even', 'more', 'significant', 'is', 'the', 'negligible', 'difference', 'in', 'processing', 'time', 'between', 'the', 'two', 'languages,', 'despite', 'radical', 'differences', 'in', 'structure,', 'particularly', 'with', 'respect', 'to', 'head-complement', 'positioning.', 'This', 'is', 'an', 'improvement', 'over', 'previous', 'parameterized', 'approaches', 'in', 'which', 'cross-linguistic', 'divergences', 'frequently', 'induced', 'timing', 'discrepancies', 'of', '1-2', 'orders', 'of', 'magnitude', 'due', 'to', 'the', 'head-initial', 'bias', 'that', 'underlies', 'most', 'parsing', 'designs.']",19,"[1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1b9cde1c-a609-407d-806f-b65a4057b188,A User-Based Usability Assessment of Raw Machine Translated Technical Instructions,2012,Stephen Doherty;Sharon O'brien,"[""Dropbox: The Inside Story of Tech's Hottest Startup""]",['2011'],['V Barret'],single,"['To', 'ensure', 'the', 'task', 'was', 'as', 'realistic', 'as', 'possible,', 'we', 'selected', 'English', 'documentation', 'for', 'a', 'well-known', 'online', 'file', 'storage', 'and', 'sharing', 'service.', 'We', 'made', 'an', 'initial', 'assumption', 'that', 'the', 'original', 'English', 'instructions', 'published', 'by', 'the', 'developer', 'were', 'reasonably', 'usable,', 'given', 'that', 'the', 'service', 'has', 'over', '50', 'million', 'users', '<ref type=""single"">(Barret, 2011).</ref>', 'As', 'native', 'speakers', 'of', 'English,', 'both', 'authors', 'judged', 'the', 'documentation', 'to', 'be', 'of', 'reasonable', 'quality', 'and', 'well-formed.', 'These', 'were', 'initial', 'assumptions', 'which', 'would', 'be', 'tested', 'in', 'the', 'project.']",48,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1bbb6cfd-319a-43d9-8f55-a439b681dd76,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,"['Sv000gg at semeval-2016 task 11: Heavy gauge complex word identification with system voting', 'Ltg at semeval-2016 task 11: Complex word identification with classifier ensembles']","['2016', '2016']","['Gustavo Paetzold;Lucia Specia', 'Shervin Malmasi;Mark Dras;Marcos Zampieri']",group,"['In', 'CWI', '2016', '<ref type=""single"">(Paetzold and Specia, 2016a),</ref>', 'complexity', 'was', 'defined', 'as', 'whether', 'or', 'not', 'a', 'word', 'is', 'difficult', 'to', 'understand', 'for', 'non-native', 'English', 'speakers', 'and', 'the', 'words', 'in', 'the', 'dataset', 'are', 'tagged', 'as', 'complex', 'or', 'non-complex', 'by', '400', 'non-native', 'English', 'speakers.', 'The', 'results', 'highlight', 'the', 'effectiveness', 'of', 'Decision', 'Trees', '<ref type=""group"">(Quijada and Medero, 2016, Mukherjee et al., 2016)</ref>', 'and', 'Ensemble', 'methods', '<ref type=""group"">(Paetzold and Specia, 2016b, Malmasi et al., 2016)</ref>', 'for', 'the', 'task.']",50,"[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 2, 2, 2]"
1c180aca-79f4-4dbb-84f8-917f98c78227,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Leveraging multilingual resources for open-domain event detection'],['2019'],['Jaipal Goud;Pranav Goel;Allen Antony;Manish Shrivastava'],single,"['In', 'the', 'domain', 'of', 'multi-lingual', 'and', 'cross', 'lingual', 'event', 'detection,', '<ref type=""single"">Feng et al. (2018)</ref>', 'uses', 'a', 'combination', 'of', 'both', 'LSTMs', 'and', 'CNNs', 'for', 'creating', 'a', 'language', 'independent', 'architecture', 'for', 'capturing', 'events,', 'while', '<ref type=""single"">Goud et al. (2019a)</ref>', 'used', 'stacked', 'RNNs', 'for', 'sequence', 'labeling', 'and', 'a', 'language', 'discriminator', 'to', 'learn', 'language', 'features.', 'The', 'latter', 'architecture', 'implements', 'the', 'use', 'of', 'the', 'character', 'embeddings,', 'but', 'does', 'not', 'identify', 'the', 'relevant', 'features', 'independent', 'of', 'the', 'word', 'embeddings.']",29,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
1c8c9753-497d-4cf6-a3a9-1a7eebadf756,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['WordNet: An Electronic Lexical Database'],['1998'],['Christiane Fellbaum'],single,"['We', 'use', 'KnowBert-W+W,', 'which', 'has', 'been', 'trained', 'on', 'Wikipedia', 'and', 'WordNet', '<ref type=""single"">(Fellbaum, 1998)</ref>', 'as', 'an', 'embedding', 'model', 'that', 'incorporates', 'external', 'information,', 'note', 'that', 'we', 'are', 'not', 'using', 'this', 'as', 'an', 'entity', 'linking', 'system,', 'even', 'for', 'NED.', 'Similar', 'to', 'other', 'BERT', 'baselines,', 'we', 'feed', 'a', 'mention', 'span', 'm', 'and', 'context', 's,', 'and', 'we', 'use', 'the', 'weighted', 'sum', 'of', 'the', '[CLS]', 'vectors', 'from', 'all', '15', 'layers.']",11,"[2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1c9cba91-b9c6-49da-af45-bb0ebd4dc58f,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,['unknown'],['unknown'],['unknown'],single,"['Other', 'Monolingual', 'Since', 'there', 'were', 'less', 'training', 'data', 'available', 'for', 'non-English', 'monolingual', 'datasets,', 'we', 'followed', 'a', 'few-shot', 'learning', 'approach', 'mentioned', 'in', '<ref type=""single"">Ranasinghe et al. (2020c,b).</ref>', 'When', 'we', 'are', 'starting', 'the', 'training', 'for', 'non-English', 'monolingual', 'language', 'pairs,', 'rather', 'than', 'training', 'a', 'model', 'from', 'scratch,', 'we', 'initialised', 'the', 'weights', 'saved', 'from', 'the', 'English-English', 'experiment.', 'Then', 'we', 'performed', 'training', 'on', 'the', 'dev', 'data', 'for', 'each', 'language', 'pair', 'separately.', 'Similar', 'to', 'English-English', 'experiments,', 'during', 'the', 'training', 'process,', 'the', 'parameters', 'of', 'the', 'transformer', 'model,', 'as', 'well', 'as', 'the', 'parameters', 'of', 'the', 'subsequent', 'layers,', 'were', 'updated.']",21,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1ce8175c-9e3e-42a6-b80a-6b5f64dd8327,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Lexical Analysis'],['2000'],['Richard Sproat'],single,"['The', 'marginal', 'position', 'of', 'word', 'formation', 'is', 'illustrated', 'by', 'the', 'treatment', 'in', 'general', 'surveys', 'of', 'computational', 'linguistics.', 'Surveys', 'such', 'as', '<ref type=""single"">Karlsson &amp, Karttunen (1997)</ref>', 'and', '9', 'Stem', 'changes', 'have', 'been', 'analysed', 'in', 'a', 'number', 'of', 'different', 'ways', 'in', 'the', 'literature.', 'Since', 'many', 'forms', 'look', 'like', 'inflected', 'forms', '(the', 'so-called', 'paradigmic', 'forms)', 'it', 'is', 'sometimes', 'argued', 'that', 'these', 'are', 'inflected', 'forms', 'in', 'word', 'formation.', 'There', 'are', 'good', 'arguments', 'against', 'this', 'view:', '(a)', 'there', 'are', 'many', 'stems', 'that', 'do', 'not', 'change', 'in', 'word', 'formation,', '(b)', 'changed', 'stems', 'do', 'not', 'necessarily', 'have', 'the', 'semantics', 'of', 'the', 'corresponding', 'plural', 'form', 'and', 'unchanged', 'stems', 'do', 'not', 'necessarily', 'have', 'the', 'semantics', 'of', 'the', 'singular,', 'and', '(c)', 'there', 'are', 'also', 'non-paradigmic', 'forms.', 'See', 'the', 'discussions', 'in', '<ref type=""single"">Fuhrhop (1998)</ref>', 'and', '<ref type=""single"">Eisenberg (1998).</ref>', 'The', 'existence', 'of', 'stem', 'changes', 'is', 'often', 'used', 'as', 'an', 'argument', 'against', 'the', 'IA', 'model,', 'e.g.', 'by', '<ref type=""single"">Anderson (1992).</ref>', 'An', 'analysis', 'in', 'terms', 'of', '""stem', 'formation""', 'is', 'elaborated', 'by', 'ten', 'Hacken', '(1994).', '<ref type=""single"">Sproat (2000a)</ref>', 'do', 'not', 'even', 'mention', 'inflection', 'and', 'word', 'formation', 'as', 'terms,', 'let', 'alone', 'make', 'the', 'conceptual', 'distinction.', 'The', 'starting', 'point', 'of', 'the', 'approaches', 'they', 'describe', 'is', 'clearly', 'inflection.', 'As', 'far', 'as', 'word', 'formation', 'phenomena', 'are', 'treated,', 'e.g.', '<ref type=""single"">Sproat (2000a:50),</ref>', 'they', 'are', 'not', 'considered', 'from', 'the', 'perspective', 'of', 'the', 'creation', 'of', 'new', 'lexemes,', 'but', 'as', 'examples', 'of', 'more', 'difficult', 'combinations', 'of', 'formatives.']",150,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1d106a89-f31a-45de-a844-945400bff185,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,"['Space efficient linear time construction of suffix arrays', 'Simple linear work suffix array construction']","['2003', '2003']","['P Ko;S Aluru', 'J Kärkkäinen;P Sanders']",group,"['Suffix', 'arrays', 'were', 'introduced', 'by', 'Manber', 'and', 'Myers', 'who', 'gave', 'a', 'Θ(N', 'log', 'N)', 'construction', 'algorithm', '<ref type=""single"">(1991).</ref>', 'While', 'several', 'linear', 'time', 'suffix', 'array', 'construction', 'algorithms', 'have', 'now', 'been', 'introduced', '<ref type=""group"">(Kärkkäinen and Sanders, 2003, Ko and Aluru. 2003)</ref>', 'it', 'is', 'not', 'clear', 'that', 'their', 'asymptotic', 'gains', 'make', 'them', 'a', 'better', 'choice', 'than', 'well-tuned', 'supralinear', 'methods', 'on', 'corpora', 'of', 'interest', '<ref type=""single"">(Puglisi et al., 2005).</ref>']",29,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
1d2f6ee9-a1f1-406f-bf6c-6995a99d75ae,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,"['BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension']",['2020'],['Mike Lewis;Yinhan Liu;Naman Goyal ; Abdelrahman Mohamed;Omer Levy;Veselin Stoyanov;Luke Zettlemoyer'],single,"['To', 'understand', 'whether', 'existing', 'models', 'can', 'accurately', 'perform', 'such', 'relative', 'comparisons,', 'we', 'conducted', 'a', 'preliminary', 'study', 'on', 'pre-trained', 'BART', '<ref type=""single"">(Lewis et al., 2020),</ref>', 'first', 'generating', 'two', 'candidate', 'summaries', 'from', 'the', 'model', 'and', 'observing', 'whether', 'a', 'higher', 'probability', 'is', 'assigned', 'to', 'the', 'candidate', 'with', 'a', 'higher', 'ROUGE', '<ref type=""single"">(Lin, 2004)</ref>', 'score.', 'As', 'Tab.', '1', 'shows,', 'the', 'accuracy', 'is', 'far', 'from', 'ideal.', 'This', 'is', 'likely', 'due', 'to', 'the', 'fact', 'that', 'MLE', 'training', 'only', 'encourages', 'the', 'model', 'to', 'assign', 'high', 'probability', 'to', 'the', 'reference', 'summary,', 'and', 'is', 'agnostic', 'about', 'any', 'relative', 'comparison', 'between', 'non-reference', 'summaries.', 'However,', 'we', 'argue', 'that', 'it', 'is', 'also', 'important', 'for', 'the', 'order', 'of', 'model', 'scores', 'to', 'be', 'coordinated', 'with', 'the', 'actual', 'quality', 'metrics', 'by', 'which', 'the', 'summaries', 'will', 'be', 'evaluated', '-higher', 'model', 'scores', 'should', 'indicate', 'better', 'quality', 'summaries.', 'In', 'the', 'following', 'we', 'will', 'refer', 'to', 'models', 'that', 'have', 'such', 'scores', 'as', '""coordinated""', 'for', 'conciseness.']",19,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1dc7049b-53e5-4467-9863-815b7437495d,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,"['Certified robustness to adversarial word substitutions', 'Automatic perturbation analysis for scalable certified robustness and beyond']","['2019', '2020']","['Robin Jia;Aditi Raghunathan;Kerem Göksel;Percy Liang', 'Kaidi Xu;Zhouxing Shi;Huan Zhang;Yihan Wang;Kai-Wei Chang;Minlie Huang;Bhavya Kailkhura;Xue Lin;Cho-Jui Hsieh']",group,"['We', 'follow', 'the', 'setup', 'from', 'the', 'robust', 'training', 'literature', '<ref type=""group"">(Jia et al., 2019, Xu et al., 2020)</ref>', 'and', 'experiment', 'with', 'both', 'the', 'base', '(non-robust)', 'and', 'robustly', 'trained', 'models.', 'We', 'train', 'the', 'binary', 'sentiment', 'classifiers', 'on', 'the', 'SST-2', 'dataset', 'with', 'bag-ofwords', '(BoW),', 'CNN,', 'LSTM,', 'and', 'attention-basedOriginal:', '70%', 'Negative', 'Input', 'Example:in', 'its', 'best', 'moments,', 'resembles', 'a', 'bad', 'high', 'school', 'production', 'of', 'grease,', 'without', 'benefit', 'of', 'song.']",9,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1dc82b73-3fe3-451f-bb98-af9ce11a33cb,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Connotation frames of power and agency in modern films'],['2017'],['Maarten Sap;Marcella Prasettio;Ari Holtzman;Hannah Rashkin;Yejin Choi'],single,"['Gendered', 'Word', 'Lists', 'We', 'develop', 'our', 'bias', 'measure', 'using', 'dimensionality-reduction', 'over', 'six', 'existing', 'lists', 'of', 'gender-laden', 'words:', '(1,', '2)', 'Gender-Coded', 'Word', 'Prevalence:', '<ref type=""single"">Gaucher et al. (2011)</ref>', 'define', 'masculine-and-feminine-themed', 'words', 'from', 'an', 'experiment', 'on', 'job', 'ads', 'that', 'discouraged', 'female', 'applicants.', '(3)', 'Superlative', 'Prevalence', '<ref type=""single"">: Schmader et al. (2007)</ref>', 'assess', 'the', 'relative', 'frequency', 'of', 'positive', 'and', 'negative', 'superlatives', 'used', 'to', 'describe', 'male', 'versus', 'female', 'job', 'candidates', 'in', 'recommendation', 'letters.', 'We', 'use', 'an', 'established', 'set', 'of', 'superlative', 'words', '<ref type=""single"">(Veale, 2016).</ref>', '(4)', 'Gender-Laden', 'Scoring:', '<ref type=""single"">Sap et al. (2017)</ref>', 'analyse', '32', 'properties', 'related', 'to', 'a', 'set', 'of', 'norms', 'to', 'score', '2,311', 'words', 'based', 'on', 'their', '""gender-ladenness"".', '(5)', 'Connotation', 'Frames:', 'Sap', 'et', 'al.', '(2017)', 'define', 'linguistic', 'markers', 'of', 'power', 'and', 'agency', 'associated', 'with', 'female', 'versus', 'male', 'characters', 'in', 'modern', 'films.', '(6)', 'NRC', 'VAD', 'Lexicon:', 'Mohammad', '(2018)', 'presents', 'a', 'lexicon', 'of', 'words', 'coded', 'by', 'valence,', 'arousal,', 'and', 'dominance', 'whose', 'interpretation', 'may', 'interact', 'with', 'gender.', '5', 'Dimensionality', 'Reduction', 'We', 'employ', 'principal', 'component', 'analysis', '(PCA)', 'on', 'the', 'six', 'bias', 'measures', 'on', 'real-world', 'job', 'ads', 'to', 'collapse', 'them', 'into', 'interpretable', 'components.', 'We', 'then', 'replicate', 'the', 'PCA', 'on', 'synthetic', 'job', 'ads', '(zero-shot)', 'and', 'project', 'all', 'data', 'points', 'onto', 'the', 'first', 'two', 'principal', 'components', 'of', 'real', 'job', 'ads', 'and', 'vice', 'versa.']",72,"[3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1e298cd5-80bc-4cd8-8c68-4a5c715c5474,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['Sparse, dense, and attentional representations for text retrieval. CoRR, abs']",['unknown'],['Yi Luan;Jacob Eisenstein;Kristina Toutanova;Michael Collins'],single,"['Natural', 'Questions', 'Test', 'MRR@10', 'R@50', 'R@1000', 'R@5', 'R@20', 'R@100', 'BM25', '(anserini)', '<ref type=""single"">(Yang et al., 2017</ref>', '<ref type=""single"">(Karpukhin et al., 2020)</ref>', 'BERTbase', '----78.4', '85.4', 'ANCE', '(single)', '<ref type=""single"">(Xiong et al., 2020)</ref>', 'RoBERTabase', '33.0', '-95.9', '-81.9', '87.5', 'ME-BERT', '<ref type=""single"">(Luan et al., 2020)</ref>', 'BERTlarge', '33.8', '-----RocketQA', 'ERNIEbase', '37.0', '85.5', '97.9', '74.0', '82.7', '88.5']",25,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1e61ceab-5f51-41fc-b045-59c9a8c3941c,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['unknown'],['unknown'],['unknown'],single,"['Dagan', 'and', 'Church', 'developed,', 'Termight,', 'a', 'tool', 'that', 'was', 'meant', 'assist', 'professional', 'translators', 'and', 'terminologists', 'develop', 'bilingual', 'term', 'lists', 'and', 'technical', 'terminology', 'in', 'particular', '<ref type=""single"">(1997).</ref>', 'Like', ""Kupiec's"", 'work,', 'they', 'also', 'presume', 'the', 'availability', 'of', 'POS-tagging', 'and', 'work', 'with', 'noun', 'phrases', 'extracted', 'from', 'sentence-aligned', 'corpora.', 'A', 'distinctive', 'feature', 'of', 'their', 'approach', 'is', 'using', 'word-level', 'alignments', 'to', 'score', 'translations,', 'this', 'enables', 'identification', 'of', 'correct', 'translations', 'even', 'with', 'the', 'correct', 'source', 'term', '/', 'target', 'term', 'correspondence', 'is', 'observed', 'once', 'or', 'twice', 'in', 'the', 'bilingual', 'data.', '(This', 'scenario,', 'when', 'term', 'frequency', 'is', 'small,', 'makes', 'translation', 'using', 'contingency', 'table', 'methods', 'such', 'as', 'Dice', 'coefficients', 'problematic.)', 'They', 'report', 'finding', 'a', 'correct', 'translation', 'at', 'rank', '1', '40%', 'of', 'the', 'time', 'and', 'at', 'rank', '2', 'an', 'additional', '7%', 'of', 'the', 'time', 'for', 'a', 'list', 'of', '192', 'English/German', 'technical', 'terms.']",24,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
1e61d4e1-95d3-46e9-8926-99de93556cdd,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['unknown'],['unknown'],['unknown'],single,"['Quoref', '<ref type=""single"">(Dasigi et al., 2019)</ref>', 'is', 'a', 'dataset', 'that', 'is', 'particularly', 'designed', 'for', 'evaluating', 'coreference', 'understanding', 'of', 'MRC', 'models.', 'Figure', '1', 'shows', 'a', 'QA', 'sample', 'from', 'Quoref', 'in', 'which', 'the', 'model', 'needs', 'to', 'resolve', 'the', 'coreference', 'relation', 'between', '""his""', 'and', '""John', 'Motteux""', 'to', 'answer', 'the', 'question.', 'Recent', 'large', 'pre-trained', 'language', 'models', 'reached', 'high', 'performance', 'on', 'Quoref.', 'However,', 'our', 'results', 'and', 'analyses', 'suggest', 'that', 'this', 'dataset', 'contains', 'artifacts', 'and', 'does', 'not', 'reflect', 'the', 'natural', 'distribution', 'and,', 'therefore,', 'the', 'challenges', 'of', 'coreference', 'reasoning.', 'As', 'a', 'result,', 'high', 'performances', 'on', 'Quoref', 'do', 'not', 'necessarily', 'reflect', 'the', 'coreference', 'reasoning', 'capabilities', 'of', 'the', 'examined', 'models', 'and', 'answering', 'questions', 'that', 'require', 'coreference', 'reasoning', 'might', 'be', 'a', 'greater', 'challenge', 'than', 'current', 'scores', 'suggest.']",1,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1e9494c5-fae9-44d6-b944-39945b7597c7,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Ultra-Fine Entity Typing'],['2018'],['Eunsol Choi;Omer Levy;Yejin Choi;Luke Zettlemoyer'],single,"['We', 'compute', 'our', 'embeddings', 'from', 'an', 'entity', 'typing', 'model', 'trained', 'on', 'the', 'UFET', 'dataset', '<ref type=""single"">(Choi et al., 2018)</ref>', 'for', 'CAP', '(10k', 'types).', 'We', 'choose', 'this', 'dataset', 'because', 'many', 'of', 'mention', 'spans', 'in', 'the', 'CAP', 'examples', 'are', 'nominal', 'expressions', 'or', 'pronouns,', 'and', 'the', 'Wiki-Context', 'dataset', 'includes', 'almost', 'entirely', 'mentions', 'of', 'proper', 'nouns.', 'To', 'make', 'a', 'prediction', 'if', 'two', 'mentions', 'are', 'coreferent,', 'we', 'compute', 'sim', 'cos', '(t', '1,', 't', '2)', 'over', 'the', 'type', 'vectors', 'for', 'each', 'mention', 'and', 'check', 'if', 'this', 'is', 'greater', 'than', 'a', 'threshold,', 'which', 'we', 'set', 'to', '0.5.', 'Only', 'our', 'baselines', 'use', 'the', 'CAP', 'training', 'set,', 'our', 'model', 'does', 'not', 'train', 'on', 'this', 'data.', 'We', 'compare', 'our', 'approach', 'with', 'the', 'baselines', 'described', 'above', 'as', 'reported', 'in', '<ref type=""single"">Chen et al. (2019).</ref>', 'Note', 'that', 'they', 'use', 'two', 'different', 'types', 'of', 'entity', 'representations:', 'one', 'based', 'on', 'entity', 'descriptions', 'and', 'another', 'based', 'on', 'entity', 'names', 'only.']",14,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1e9681fd-8281-4cc7-9195-a0145b17ae5e,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Machine translation and monolingual postediting: The AFRL WMT-14 system'],['2014'],['L Schwartz;T Anderson;J Gwinnup;K Young'],single,"['For', 'this', 'study,', 'we', 'developed', 'a', 'novel', 'post-editing', 'interface,', 'based', 'on', 'the', 'open', 'source', 'software', 'used', 'and', 'released', 'by', '<ref type=""single"">Schwartz et al. (2014).</ref>', 'Our', 'software', 'is', 'written', 'using', 'Scala', '<ref type=""single"">(Odersky, 2014),</ref>', 'and', 'is', 'released', 'as', 'open', 'source', '(see', 'the', 'software', 'supplement', 'that', 'accompanies', 'this', 'work).', 'This', 'code', 'constitutes', 'a', 'ground-up', 'rewrite', 'of', 'the', 'Java-based', 'post-editing', 'interface', 'of', '<ref type=""single"">Schwartz et al. (2014),</ref>', 'written', 'using', 'a', 'strict', 'model-view-controller', 'software', 'design', 'pattern', 'to', 'be', 'easy', 'for', 'other', 'researchers', 'to', 'use', 'and', 'extend.']",53,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1ed3d3de-5136-4286-a12e-bc5857ed6e7a,SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering,2020,Aishwarya Ashok;Ganapathy Natarajan;Ramez Elmasri;Laurel Smith-Stvan,['Amazonqa: A review-based question answering task'],['2019'],['Mansi Gupta;Nitish Kulkarni;Raghuveer Chanda;Anirudha Rayasam;Zachary Lipton'],single,"['Our', 'system', 'outperforms', 'the', 'R-Net', 'baseline', '(Rouge-L:', '40.22)', 'used', 'by', '<ref type=""single"">Gupta et al. (2019).</ref>', 'Our', 'system', 'is', 'supposed', 'to', 'be', 'applied', 'at', 'the', 'sentence', 'level', 'and', 'the', 'results', 'indicate', 'that', 'a', 'unsupervised', 'system', 'such', 'as', 'ours', 'could', 'outperform', 'more', 'complicated', 'deep', 'learning', 'models.', 'If', 'there', 'is', 'a', 'trade-off', 'sought', 'between', 'computing', 'time', 'and', 'accuracy,', 'our', 'system', 'performs', 'similar', 'to', 'or', 'better', 'than', 'the', 'baseline', 'used', 'by', '<ref type=""single"">Gupta et al. (2019)</ref>', 'ROUGE', 'score', 'is', 'not', 'the', 'best', 'metric', 'for', 'tasks', 'such', 'as', 'opinion', 'question', 'answering.', 'We', 'believe', 'the', 'cosine', 'similarity', 'is', 'a', 'better', 'metric', 'to', 'measure', 'how', 'close', 'the', 'retrieved', 'answer', 'is', 'to', 'the', 'gold', 'standard.', 'Overall', 'the', 'sim', 'method', 'is', 'able', 'to', 'provide', 'an', 'answer', 'more', 'than', '70%', 'similar', 'to', 'the', 'gold', 'standard', 'answer', '91.5%', 'of', 'the', 'time.', 'From', 'the', 'sentences', 'returned', 'by', 'our', 'system', 'as', 'candidate', 'answers,', '72%', 'of', 'the', 'time', 'at', 'least', 'half', 'the', 'candidate', 'sentences', 'are', 'good', 'answers.', 'This', 'shows', 'that', 'our', 'system', 'is', 'consistent', 'and', 'accurate', 'at', 'providing', 'good', 'answers.']",63,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1efebe1a-5098-4d62-8c8c-4a01a029d3ad,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['Linguistic input features improve neural machine translation'],['2016'],['R Sennrich;B Haddow'],single,"['For', 'future', 'work,', 'we', 'would', 'like', 'to', 'include', 'linguistic', 'features', 'at', 'the', 'source', 'language.', 'It', 'is', 'known', 'that', 'this', 'can', 'be', 'helpful', 'for', 'NMT', '<ref type=""single"">[15].</ref>', 'Extending', 'the', 'approach', 'with', 'input', 'factors', 'could', 'make', 'the', 'target', 'language', 'factors', 'generation', 'better.', 'Furthermore,', 'different', 'attention', 'mechanisms', 'for', 'each', 'output', 'will', 'be', 'explored', 'because', 'they', 'could', 'be', 'aligned', 'to', 'different', 'source', 'words.', 'The', 'proposed', 'FNMT', 'architecture', 'could', 'even', 'show', 'better', 'performance', 'if', 'applied', 'when', 'we', 'translate', 'to', 'highly', 'inflected', 'languages', 'like', 'German,', 'Arabic,', 'Czech', 'or', 'Russian.', 'Finally,', 'FNMT', 'approach', 'will', 'be', 'explored', 'in', 'multimodal', 'and', 'multilingual', 'tasks.']",24,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
1fa4a02f-8ee1-41c5-8218-3ae1a7d07225,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,['TextGraphs 2019 Shared Task on Multi-Hop Inference for Explanation Regeneration'],['2019'],['Peter Jansen;Dmitry Ustalov'],single,"['Following', 'the', 'previous', 'editions', 'of', 'the', 'shared', 'task,', 'we', 'frame', 'explanation', 'generation', 'as', 'a', 'ranking', 'problem.', 'Specifically,', 'for', 'a', 'given', 'science', 'question,', 'a', 'model', 'is', 'supplied', 'both', 'the', 'question', 'and', 'correct', 'answer', 'text,', 'and', 'must', 'then', 'selectively', 'rank', 'all', 'the', 'atomic', 'scientific', 'and', 'world', 'knowledge', 'facts', 'in', 'the', 'knowledge', 'base', 'such', 'that', 'those', 'that', 'were', 'labelled', 'as', 'most', 'relevant', 'to', 'building', 'an', 'explanation', 'by', 'a', 'human', 'annotator', 'are', 'ranked', 'the', 'highest.', 'Additional', 'details', 'on', 'the', 'ranking', 'problem', 'are', 'described', 'in', 'the', '2019', 'shared', 'task', 'summary', 'paper', '<ref type=""single"">(Jansen and Ustalov, 2019).</ref>']",86,"[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1]"
1ff103d3-0ce4-48bc-935d-64b2c93f9170,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['unknown'],['unknown'],['unknown'],group,"['Comparing', 'this', 'relatedness', 'measure', 'to', 'data', 'obtained', 'from', 'humans', '<ref type=""group"">(MEN, Bruni et al., 2012 and WS-353 relatedness, Agirre et al., 2009),</ref>', 'we', 'found', 'that', 'taking', 'the', 'square', 'root', 'of', 'PMI', 'norm', 'increases', 'the', 'Pearson', 'correlation', 'coefficient', 'between', 'human', 'annotations', 'and', 'our', 'calculated', 'relatedness', 'from', '0.72', 'to', '0.76', 'for', 'MEN,', 'and', 'from', '0.57', 'to', '0.63', 'for', 'WS-353.', 'Additionally,', 'in', 'our', 'following', 'methods,', 'it', 'is', 'beneficial', 'if', 'the', 'values', 'do', 'not', 'concentrate', 'around', 'zero,', 'therefore', 'we', 'use', 'the', 'square', 'root', 'of', 'normalized', 'PMI', 'hereinafter:', 'NPMI(x,', 'y)', '=', 'PMI', 'norm', '(x,', 'y).']",9,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
20034b01-748e-433e-affb-82158149430c,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,"['Practical unification-based parsing of natural language', 'Relating complexity to practical performance in parsing with wide-coverage unification grammars']","['1993', '1994']","['J Carroll', 'J Carroll']",group,"['This', 'work', 'is', 'part', 'of', 'an', 'effort', 'to', 'develop', 'a', 'robust,', 'domain-independent', 'syntactic', 'parser', 'capable', 'of', 'yielding', 'the', 'one', 'correct', 'analysis', 'for', 'unrestricted', 'naturally-occurring', 'input.', 'Our', 'goal', 'is', 'to', 'develop', 'a', 'system', 'with', 'performance', 'comparable', 'to', 'extant', 'part-of-speech', 'taggers,', 'returning', 'a', 'syntactic', 'analysis', 'from', 'which', 'predicate-argument', 'structure', 'can', 'be', 'recovered,', 'and', 'which', 'can', 'support', 'semantic', 'interpretation.', 'The', 'requirement', 'for', 'a', 'domain-independent', 'analyser', 'favours', 'statistical', 'techniques', 'to', 'resolve', 'ambiguities,', 'whilst', 'the', 'latter', 'goal', 'favours', 'a', 'more', 'sophisticated', 'grammatical', 'formalism', 'than', 'is', 'typical', 'in', 'statistical', 'approaches', 'to', 'robust', 'analysis', 'of', 'corpus', 'material.', '<ref type=""single"">Briscoe and Carroll (1993)</ref>', 'describe', 'a', 'probablistic', 'parser', 'using', 'a', 'wide-coverage', 'unification', 'based', 'grammar', 'of', 'English', 'written', 'in', 'the', 'Alvey', 'Natural', 'Language', 'To', 'ols', '(ANLT)', 'meta', 'g', 'rammat', 'ical', 'formalism', '<ref type=""single"">(Briscoe et al. , 1987),</ref>', 'generating', 'around', '800', 'rules', 'in', 'a', 'syntactic', 'variant', 'of', 'the', 'Definite', 'Clause', 'Grammar', 'formalism', '(DCG,', '<ref type=""single"">Pereira &amp, Warren, 1980)</ref>', 'extended', 'with', 'iterative', '(Kleene)', 'operators.', 'The', 'ANLT', 'grammar', 'is', 'linked', 'to', 'a', 'lexicon', 'containing', 'about', '64K', 'entries', 'for', '40K', 'lexemes,', 'including', 'detailed', 'subcategorisation', 'information', 'appropriate', 'for', 'the', 'grammar,', 'built', 'semi-automatically', 'from', 'a', ""learners'"", 'dictionary', '<ref type=""single"">(Carroll &amp, Grover, 1989).</ref>', 'The', 'resulting', 'parser', 'is', 'efficient,', 'capable', 'of', 'constructing', 'a', 'parse', 'forest', 'in', 'what', 'seems', 'to', 'be', 'roughly', 'quadratic', 'time,', 'and', 'efficiently', 'returning', 'the', 'ranked', 'n-most', 'likely', 'analyses', '<ref type=""group"">(Carroll, 1993 (Carroll, , 1994)).</ref>', 'The', 'probabilistic', 'model', 'is', 'a', 'refinement', 'of', 'probabilistic', 'context-free', 'grammar', '(PCFG)', 'conditioning', 'CF', ""'backbone'"", 'rule', 'application', 'on', 'LR', 'state', 'and', 'lookahead', 'item.', 'Unification', 'of', 'the', ""'residue'""]",196,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
20b3310d-e84a-43ab-9182-130203a09788,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Fast semantic parsing with welltypedness guarantees'],['2020'],['Matthias Lindemann;Jonas Groschwitz;Alexander Koller'],single,"['State-of-the-art', 'DRS', 'parsers', 'follow', 'the', 'encoderdecoder', 'paradigm', 'pioneered', 'for', 'machine', 'translation', 'by', '<ref type=""single"">Sutskever et al. (2014):</ref>', 'the', 'input', 'sequence', 'is', 'encoded', 'by', 'a', 'neural', 'network', 'into', 'a', 'vector,', 'then', 'another', 'network', 'predicts', 'the', 'output', 'sequence', '(or', 'in', 'this', 'case:', 'output', 'DRS)', 'from', 'that', 'vector.', 'Rather', 'than', 'improve', 'upon', 'the', 'accuracy', 'of', 'such', 'parsers', 'on', 'standard', 'benchmarks,', 'our', 'aim', 'in', 'this', 'paper', 'is', 'to', 'achieve', 'some', 'of', 'their', 'benefits', '(ability', 'to', 'learn', 'from', 'examples,', 'high', 'accuracy,', 'low', 'computational', 'complexity,', 'robustness', 'to', 'atypical', 'input,', 'utilization', 'of', 'off-the-shelf', 'language', 'models,', 'conceptual', 'simplicity)', 'while', 'also', 'having', 'a', 'degree', 'of', 'compositionality,', 'traditionally', 'a', 'property', 'of', 'grammar-based', 'systems.', 'Specifically,', 'our', 'system', 'learns', 'to', 'assign', 'each', 'token', 'of', 'an', 'utterance', 'one', 'of', 'a', 'finite', 'set', 'of', 'abstract', 'meaning', 'fragments', 'that', 'are', 'deterministically', 'combined', 'to', 'give', 'the', 'meaning', 'of', 'the', 'whole', 'utterance.', 'While', 'our', 'system', 'may', 'not', 'fulfill', 'all', 'criteria', 'of', 'compositionality', 'according', 'to', 'some', 'definitions,', 'it', 'can', 'arguably', 'reap', 'some', 'of', ""compositionality's"", 'benefits,', 'which', 'make', 'it', 'suitable', 'for', 'use', 'in', 'semi-automatic', 'annotation', 'workflows.', 'We', 'discuss', 'this', 'further', 'in', 'Section', '5.', 'Previous', 'work', 'has', 'introduced', 'trainable', 'compositional', 'semantic', 'parsers', 'for', 'AMR', '<ref type=""single"">(Lindemann et al., 2020)</ref>', 'and', 'DRS', '<ref type=""group"">(Evang, 2019, Bladier et al., 2021).</ref>', 'In', 'this', 'paper,', 'we', 'improve', 'upon', 'the', 'latter', 'parser', 'using', 'a', 'novel', 'way', 'to', 'encode', 'anchored', 'DRSs', 'as', 'sequences,', 'and', 'thereby', 'cast', 'DRS', 'parsing', 'simply', 'as', 'a', 'sequence', 'labeling', 'task', '(§2).', 'We', 'use', 'a', 'standard', 'transformer-based', 'model', 'to', 'learn', 'this', 'task,', 'followed', 'by', 'post-processing', 'to', 'ensure', 'well-formed', 'DRSs', '(§3).', 'We', 'use', 'training', 'data', 'from', 'the', 'Parallel', 'Meaning', 'Bank', '(§4).', 'The', 'accuracy', 'of', 'our', 'model', 'approaches', 'the', 'state', 'of', 'the', 'art', 'with', 'the', 'additional', 'benefit', 'of', 'being,', 'to', 'a', 'degree,', 'compositional', '(§5).', 'We', 'give', 'an', 'error', 'analysis', 'in', '§6', 'and', 'conclude', 'in', '§7.']",180,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
20c46e4c-57b3-4519-b34f-342a903bd53f,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,"['Augmenting self-attention with persistent memory', 'GLU variants improve transformer. ArXiv, abs', 'Transformer feed-forward layers are key-value memories']","['2019', '2002', '2020']","['Sainbayar Sukhbaatar;Edouard Grave;Guillaume Lample;H Jégou;Armand Joulin', 'Noam Shazeer', 'R Mor Geva;Jonathan Schuster;Omer Berant;unk Levy']",group,"['Feed-forward', 'as', 'attention', 'In', 'the', 'feed-forward', 'layer,', 'a', '1-hidden', 'layer', 'fully-connected', 'network', 'is', 'applied', 'identically', 'to', 'every', 'input', 'token.', 'As', 'observed', 'in', 'past', 'work', '<ref type=""group"">(Sukhbaatar et al., 2019, Shazeer, 2020, Geva et al., 2020),</ref>', 'a', 'feed-forward', 'layer', 'can', 'be', 'cast', 'into', 'the', 'query-key-value', 'framework', 'as:']",24,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
20e27eee-c89b-4d2f-8d0a-2fa6514c763c,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Robustness may be at odds with accuracy'],['2019'],['Dimitris Tsipras;Shibani Santurkar;Logan Engstrom;Alexander Turner;Aleksander Madry'],single,"['We', 'also', 'study', 'mitigating', 'shortcuts', 'by', 'masking', 'out', 'the', 'identified', 'shortcuts.', 'RM),', 'and', 'both', '(Train', '&amp,', 'Test', 'RM)', 'as', 'described', 'in', 'Sec', '3.4.', 'We', 'evaluate', 'these', 'three', 'approaches', 'in', 'multiple', 'settings:', '1)', 'domain', 'generalization,', '2)', 'challenging', 'datasets,', '3)', 'gender', 'bias.', 'As', 'shown', 'in', 'Table', '5,', 'masking', 'out', 'shortcuts,', 'especially', 'in', 'training', 'data,', 'can', 'improve', ""model's"", 'generalization', 'to', 'out-of-distribution', 'data.', 'Note', 'in', 'this', 'setting,', 'different', 'from', 'existing', 'domain', 'transfer', 'work', '(Pan', 'and', 'Yang,', '2010),', 'we', 'do', 'not', 'assume', 'access', 'to', 'labeled', 'data', 'in', 'the', 'target', 'domain', 'during', 'training,', 'instead', 'we', 'use', 'our', 'proposed', 'approach', 'to', 'identify', 'potential', 'shortcuts', 'that', 'can', 'generalize', 'to', 'unseen', 'target', 'domains.', 'As', 'a', 'result,', 'we', 'also', 'observe', ""model's"", 'performance', 'improvement', 'on', 'challenging', 'datasets', '(Table', '7).', 'fairer', 'model.', 'Note', 'the', 'original', 'performance', 'might', 'degrade', 'slightly', 'due', 'to', 'models', 'learning', 'different', 'but', 'more', 'robust', 'feature', 'representations,', 'consistent', 'with', 'findings', 'in', 'existing', 'work', '<ref type=""single"">(Tsipras et al., 2019).</ref>']",143,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]"
2112b391-985d-4715-b911-035114f05a28,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['unknown'],['2022'],['Hongyu Wang;Shuming Ma;Li Dong;Shaohan Huang;Dongdong Zhang;Furu Wei'],single,"['In', 'addition,', 'in', 'order', 'to', 'have', 'both', 'the', 'high', 'performance', 'of', 'post-norm', 'and', 'the', 'stable', 'training', 'of', 'pre-norm', '(Nguyen', 'and', 'Salazar,', '2019),', 'we', 'use', 'the', 'methods', 'mentioned', 'in', 'DeepNet', '<ref type=""single"">(Wang et al., 2022)</ref>', 'For', 'training', 'the', 'full-sentence', 'translation', 'model,', 'given', 'the', 'source', 'sentence', 'x,', 'the', 'probability', 'of', 'predicting', 'the', 'target', 'sentence', 'y', 'is', 'as', 'shown', 'in', 'Eq.', '1,', 'and', 'the', 'training', 'objective', 'is', 'to', 'minimize', 'the', 'negative', 'log-likelihood', 'as', 'shown', 'in', 'Eq.', '2.p(y|x)', '=', '|y|', 't=1', 'p(y', 't', '|x,', 'y', '&lt,t,', 'θ)(1)loss', 'f', 'ull', '(θ)', '=', '−', '(x,y)∈D', 'logp', 'g', '(y|x,', 'θ)', '(2)The', 'batch', 'size', 'for', 'training', 'is', '4,096', 'tokens', 'per', 'GPU,', 'and', 'we', 'trained', 'our', 'model', 'for', '7', 'epochs', 'on', '4', 'NVIDIA', 'V100', 'GPUs', 'for', 'about', '10', 'hours.']",29,"[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2135c5db-4f7a-437c-b516-e86be15f86cb,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,['A Three-step Method for Multi-Hop Inference Explanation Regeneration'],['2021'],['Yuejia Xiang;Yunyan Zhang;Xiaoming Shi;Bo Liu;Wandi Xu;Xi Chen'],single,"['Google-BERT.', '<ref type=""single"">Xiang et al. (2021)</ref>', 'propose', 'a', 'framework', 'composed', 'of', 'three', 'main', 'steps.', 'In', 'the', 'first', 'step,', 'the', 'model', 'adopts', 'a', 'simple', 'tf.idf', 'model', 'with', 'cosine', 'similarity', 'to', 'retrieve', 'the', 'top-K', 'relevant', 'explanation', 'sentences', '(K', '=', '50)', 'for', 'each', 'question', 'and', 'correct', 'answer', 'pair.', 'In', 'the', 'second', 'step,', 'the', 'authors', 'employ', 'an', 'autoregressive', 'model', 'which', 'selects', 'the', 'most', 'relevant', 'facts', 'in', 'a', 'iterative', 'manner.', 'Specifically,', 'the', 'authors', 'propose', 'the', 'adoption', 'of', 'a', 'BERT-based', 'model', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'that', 'selects', 'the', 'facts', 'at', 'iteration', 'n', 'given', 'the', 'facts', 'retrieved', 'in', 'the', 'previous', 'step.', 'The', 'model', 'uses', 'up', 'to', '4', 'iterations.', 'Finally,', 'the', 'authors', 'employ', 'a', 're-ranking', 'module', 'to', 're-score', 'the', 'retrieved', 'candidate', 'explanations', 'computing', 'the', 'relevance', 'between', 'each', 'fact', 'and', 'the', 'question-answer', 'pairs.', 'The', 're-ranking', 'model', 'is', 'implemented', 'using', 'a', 'BERT', 'model', 'for', 'binary', 'classification.', 'The', 'ablation', 'study', 'shows', 'that', 'the', 'first', 'two', 'steps', 'allow', 'achieving', 'a', 'performance', 'of', '0.679', 'NDCG,', 'that', 'is', 'improved', 'up', 'to', '0.700', 'NDCG', 'using', 'the', 're-ranking', 'model.', 'Moreover,', 'the', 'experiments', 'show', 'that', 'the', 'best', 'performance', 'is', 'achieved', 'when', 'the', 're-ranking', 'model', 'is', 'adopted', 'to', 're-score', 'the', 'top', 'K', '=', '30', 'facts.']",1,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
219ae21f-dc99-426c-83cf-dafa9e1e8484,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,['Modeling the unigram distribution'],['2021'],['Irene Nikkarinen;Tiago Pimentel;Damián Blasi;Ryan Cotterell'],single,"['Recently', '<ref type=""single"">Nikkarinen et al. (2021)</ref>', 'introduced', 'a', 'neural-Bayesian', 'nonparametric', 'estimator', 'for', 'probability', 'distributions', 'on', 'single', 'words.', 'Their', 'setting', 'has', 'an', 'unknown', 'and', 'generally', 'infinite', 'vocabulary', 'V,', 'and', 'their', 'model', 'generalizes', 'using', 'a', 'characterlevel', 'LSTM.', 'In', 'contrast,', 'the', 'current', 'model', 'assumes', 'a', 'pre-existing', 'known', 'vocabulary', 'V', 'with', 'embeddings,', 'and', 'generalizes', 'based', 'on', 'those', 'embeddings.', 'A', 'hybrid', 'model', 'may', 'be', 'possible', 'in', 'future', 'work.']",1,"[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
21d57dc0-c879-406c-9e3d-acf240c9c655,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['Embedding-based retrieval in facebook search'],['2020'],['Jui-Ting Huang;Ashish Sharma;Shuying Sun;Li Xia;David Zhang;Philip Pronin;Janani Padmanabhan;Giuseppe Ottaviano;Linjun Yang'],single,"['As', 'shown', 'in', 'Figure', '3,', 'we', 'organize', 'the', 'above', 'three', 'training', 'strategies', 'into', 'an', 'effective', 'training', 'pipeline', 'for', 'the', 'dual-encoder.', 'It', 'makes', 'an', 'analogy', 'to', 'a', 'multi-stage', 'rocket,', 'where', 'the', 'performance', 'of', 'the', 'dual-encoder', 'is', 'consecutively', 'improved', 'at', 'three', 'steps', '(STEP', '1,', '3', 'and', '4).', 'That', 'is', 'why', 'we', 'call', 'our', 'approach', 'RocketQA.', 'Next,', 'we', 'will', 'describe', 'the', 'details', 'of', 'the', 'whole', 'training', 'procedure', 'of', 'RocketQA.', 'D', 'from', 'C', 'for', 'each', 'question', 'q', '∈', 'Q', 'L.', 'This', 'design', 'is', 'to', 'let', 'the', 'cross-encoder', 'adjust', 'to', 'the', 'distribution', 'of', 'the', 'results', 'retrieved', 'by', 'the', 'dualencoder,', 'since', 'the', 'cross-encoder', 'will', 'be', 'used', 'in', 'the', 'following', 'two', 'steps', 'for', 'optimizing', 'the', 'dualencoder.', 'This', 'design', 'is', 'important,', 'and', 'there', 'is', 'similar', 'observation', 'in', 'Facebook', 'Search', '<ref type=""single"">(Huang et al., 2020).</ref>']",121,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]"
21dd12bf-64e1-41f3-9197-3f8bf9648797,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['A simple and effective model for answering multi-span questions'],['2020'],['Elad Segal;Avia Efrat;Mor Shoham;Amir Globerson;Jonathan Berant'],single,"['For', 'wh-word,', 'empty', 'question,', 'and', 'short', 'distance', 'reasoning,', 'we', 'use', 'the', 'TASE', 'model', '<ref type=""single"">(Segal et al., 2020)</ref>', 'We', 'also', 'investigate', 'whether', 'these', 'biases', 'have', 'similar', 'ratios', 'in', 'a', 'coreference', 'resolution', 'dataset.', 'We', 'use', 'the', 'CoNLL-2012', 'coreference', 'resolution', 'dataset', '<ref type=""single"">(Pradhan et al., 2012a)</ref>', 'and', 'convert', 'it', 'to', 'a', 'reading', 'comprehension', 'format,', 'i.e.,', 'CoNLL', 'bart', 'in', 'Section', '5.', '5', 'This', 'data', 'contains', 'question-answer', 'pairs', 'in', 'which', 'the', 'question', 'is', 'created', 'based', 'on', 'a', 'coreferring', 'expression', 'in', 'CoNLL-2012,', 'and', 'the', 'answer', 'is', 'its', 'closest', 'antecedent.', 'We', 'split', 'this', 'data', 'into', 'training', 'and', 'test', 'sets', 'and', 'train', 'bias', 'models', 'on', 'the', 'training', 'split.', 'The', 'CoNLL', 'bart', 'column', 'in', 'Table', '1', 'shows', 'the', 'bias', 'proportions', 'on', 'this', 'data.']",13,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
21f1f90b-71c6-4c9f-b7b0-761601806da1,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,"['Indicnlpsuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for indian languages']",['2020'],['Divyanshu Kakwani;Anoop Kunchukuttan;Satish Golla;N C Gokul;Avik Bhattacharyya;M Mitesh;Pratyush Khapra;unk Kumar'],single,"['Despite', 'the', 'inclusion', 'of', 'translations', 'and', 'contrastive', 'loss,', 'we', 'observed', 'that', 'there', 'is', 'only', 'a', 'marginal', 'improvement', 'in', 'the', 'QA', 'performance.', 'This', 'can', 'be', 'attributed', 'to', 'the', 'smaller', 'size', 'of', 'the', 'ChAII', 'dataset', 'with', '1114', 'instances', '<ref type=""single"">(Tamil and Hindi combined, Train, Validation, and Test combined),</ref>', 'which', 'is', 'clearly', 'insufficient', 'to', 'fine-tune', 'a', '177M', 'parameter', 'model.', 'Hence,', 'the', 'proposed', 'techniques', 'have', 'to', 'be', 'evaluated', 'on', 'other', 'larger', 'datasets', 'as', 'well', 'as', 'using', 'other', 'multilingual', 'models', 'like', 'XLM-RoBERTa', '<ref type=""single"">(Conneau et al., 2020),</ref>', 'Distill-mBERT', '<ref type=""single"">(Sanh et al., 2019),</ref>', 'MURIL', '<ref type=""single"">(Khanuja et al., 2021)</ref>', 'and', 'Indic-BERT', '<ref type=""single"">(Kakwani et al., 2020).</ref>', 'We', 'hope', 'that', 'the', 'proposed', 'techniques', 'will', 'motivate', 'further', 'research', 'in', 'this', 'field,', 'including', 'exploration', 'of', 'the', 'same', 'phenomenon', 'of', 'cross-lingual', 'transfer', 'in', 'other', 'language', 'families', 'and', 'multilingual', 'tasks.']",75,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
222decd8-6ae3-4271-84e1-64aecae3eda6,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,['Are we pretraining it right? Digging deeper into visio-linguistic pretraining'],['2020'],['Amanpreet Singh;Vedanuj Goswami;Devi Parikh'],single,"['In', 'this', 'research', 'proposal,', 'we', 'focus', 'on', 'three', 'factors', 'that', 'can', 'enhance', 'the', 'communication', 'between', 'humans', 'and', 'assistive', 'technologies.', 'The', 'first', 'one', 'is', 'the', 'encoding', 'of', 'the', 'referential', 'complexity', 'of', 'the', 'situated', 'settings', 'while', 'creating', 'multimodal', 'embeddings.', 'As', 'pointed', 'out', 'in', '<ref type=""single"">(Singh et al., 2020),</ref>', 'pre-trained', 'models,', 'that', 'were', 'created', 'by', 'fusing', 'the', 'modalities', 'without', 'constraints,', 'are', 'expected', 'to', 'be', 'an', 'out-of-the-box', 'solution', 'and', 'work', 'well', 'for', 'a', 'variety', 'of', 'simpler', 'tasks.', 'In', 'this', 'research,', 'we', 'propose', 'to', 'encode', 'referential', 'complexity', 'during', 'the', 'training', 'phase', 'to', 'see', 'whether', 'the', 'complexity-sensitive', 'embeddings', 'will', 'improve', 'the', 'tasks', 'of', 'crossmodal', 'mapping', 'and', 'meaning', 'recovery.', 'We', 'believe', 'that', 'this', 'will', 'implicitly', 'direct', 'the', 'model', 'to', 'focus', 'on', 'various', 'textual', 'and', 'visual', 'forms', 'of', 'the', 'same', 'concepts.']",41,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
228facc6-1348-42cf-bb1c-f43c35d8694f,Themes in the work of Margaret Masterman,1988,Yorick Wilks,['Conceptual information processing'],['1975'],['R Schank'],single,"['MMB', 'was', 'much', 'associated', 'with', 'the', 'use', 'of', 'interlinguas', 'for', 'MT', '(machine', 'translation)', 'and', 'for', 'meaning', 'representation', '<ref type=""single"">(Masterman, 1967),</ref>', 'and', 'her', 'reply', 'to', ""Bar-Hillel's"", 'criticism', 'of', 'their', 'use', 'has', 'been', 'much', 'quoted.', 'The', 'notion', 'of', 'a', 'uniform', 'and', 'universal', 'meaning', 'representation', 'for', 'translating', 'between', 'languages', 'has', 'continued', 'to', 'be', 'a', 'strategy', 'within', 'the', 'field:', 'it', 'had', 'a', 'significant', 'role', 'in', 'AI', '(artificial', 'intelligence)', 'systems', 'such', 'as', 'conceptual', 'dependency', '<ref type=""single"">(Schank, 1975)</ref>', 'and', 'preference', 'semantics', '<ref type=""single"">(Wilks, 1973),</ref>', 'and', 'is', 'now', 'to', 'be', 'found', 'in', 'recent', 'attempts', 'to', 'use', 'Esperanto', 'as', 'an', 'interlingua', 'for', 'MT.']",67,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
22903351-6d7b-4775-9a75-cba6c5340540,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,['Executive summary world robotics 2019 service robots'],['2018'],['unk Ifr'],single,"['In', 'recent', 'years,', 'we', 'have', 'witnessed', 'a', 'considerable', 'increase', 'in', 'the', 'use', 'of', 'assistive', 'technologies', 'that', 'can', 'engage', 'in', 'communication', 'and', 'perform', 'tasks.', 'These', 'can', 'come', 'in', 'different', 'forms', 'like', 'smart', 'speakers', 'and', 'mobile', 'devices', 'that', 'you', 'can', 'command', 'with', 'audio,', 'or', 'more', 'specialized', 'task-oriented', 'robots', 'that', 'can', 'actually', 'realize', ""users'"", 'command', 'in', '3D', 'environments.', 'The', 'steady', 'increase', 'in', 'the', 'use', 'of', 'collaborative', 'robots', '<ref type=""single"">(IFR, 2018)</ref>', 'in', 'daily', 'life', 'brings', 'along', 'another', 'important', 'Human-Computer', 'Interaction', 'theme:', 'the', 'capability', 'of', 'engaging', 'in', 'a', 'natural', 'and', 'smooth', 'spoken', 'dialog', 'with', 'humans,', 'which', 'is', 'a', 'major', 'scientific', 'and', 'technological', 'challenge.', 'Particularly,', 'being', 'able', 'to', 'follow', 'a', 'communication', 'that', 'conveys', 'thoughts', 'and', 'intentions', 'expressed', 'in', 'a', 'flexible', 'manner', 'without', 'the', 'restrictions', 'of', 'a', 'close-set', 'of', 'commands', 'is', 'a', 'crucial', 'component', 'of', 'assistive', 'robots', 'for', 'the', 'handicapped', 'and', 'elderly', 'people', 'and', 'for', 'the', 'education', '/', 'entertainment', 'purposes.']",64,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
22bd3af6-e828-404e-89b5-b8c365fef334,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,"['Analyzing multihead self-attention: Specialized heads do the heavy lifting, the rest can be pruned']",['2019'],['Elena Voita;David Talbot;Fedor Moiseev;Rico Sennrich;Ivan Titov'],single,"['Pruning', 'Based', 'on', 'Component.', 'Some', 'studies', 'show', 'that', 'heads', 'in', 'the', 'ED', 'component', 'are', 'most', 'important', 'while', 'those', 'in', 'the', 'ES', 'module', 'are', 'least', 'important', '<ref type=""single"">(Voita et al., 2019b).</ref>', 'We', 'choose', '4', 'different', 'pruning', 'percentages', 'and', 'in', 'each', 'case', 'consider', 'three', 'configurations', 'where', 'the', 'number', 'of', 'attention', 'heads', 'is', 'least', 'in', 'one', 'chosen', 'component', '(ES,', 'ED,', 'DS).', 'The', 'configurations', 'and', 'corresponding', 'BLEU', 'scores', 'on', 'the', 'EN-RU', 'dataset', 'are', 'shown', 'in', 'Table', '3.', 'We', 'identify', 'no', 'consistent', 'preference', 'in', 'the', 'pruning', 'strategy:', 'In', 'the', '4', 'cases', 'considered,', 'each', 'of', 'the', '3', 'configurations', 'has', 'the', 'highest', 'BLEU', 'score', 'in', 'at', 'least', 'one', 'case.', 'Note', 'that', 'we', 'chose', 'the', 'number', 'of', 'heads', 'in', 'each', 'layer', '<ref type=""single"">(14, 31, etc)</ref>', 'to', 'be', 'consistent', 'with', 'those', 'used', 'in', '<ref type=""single"">(Voita et al., 2019b).</ref>', 'Varying', 'Pruning', 'Percentage.', 'We', 'vary', 'the', 'pruning', 'percentage', 'from', '10', 'to', '90%', 'and', 'report', 'the', 'accuracy', 'on', 'the', '4', 'GLUE', 'tasks:', 'MNLI-M,', 'QQP,', 'QNLI,', 'and', 'SST-2', '(Table', '4).', 'We', 'observe', 'that', 'half', 'of', 'the', 'attention', 'heads', 'can', 'be', 'pruned', 'with', 'an', 'average', 'accuracy', 'drop', 'of', 'under', '1%.', 'As', 'shown', 'in', 'Figure', '1,', 'beyond', '50%', 'pruning,', 'the', 'accuracy', 'drop', 'is', 'sharper.']",25,"[3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
22f0478c-5eab-4828-975f-6eb106cb9094,ROI Analysis model for Language Service Providers,2013,Ekaterina Stambolieva,"[""Hunnect's Use Case. TAUS Machine Translation Showcase at Localization World""]",['2013'],['Saándor Sojnóczky'],single,"['Not', 'much', 'relevant', 'literature', 'can', 'be', 'found', 'on', 'the', 'specific', 'topic', 'of', 'estimating', 'ROI', 'in', 'a', 'LSP', 'context.', 'Nonetheless,', 'different', 'language', 'and', 'translation', 'technology', 'professionals', 'have', 'invested', 'time', 'and', 'effort', 'into', 'discussing', 'business', 'and', 'pricing', 'models,', 'which', 'shed', 'more', 'light', 'on', 'ROI', 'calculation.', '<ref type=""single"">Sojnóczky (2013)</ref>', 'emphasizes', 'on', 'margin', 'calculation', 'and', ""stakeholders'"", 'satisfaction', 'in', 'the', 'case', 'when', 'MT', 'output', 'is', 'post-edited', 'and', 'delivered', 'to', 'the', 'clients.', 'Sojnóczky,', 'the', 'managing', 'director', 'of', 'Hunnect', '1,', 'implements', 'a', 'business', 'model,', 'which', 'concentrates', 'on', 'margin', 'shrinking', 'benefits', 'and', 'its', 'results', 'are', 'directly', 'projected', 'to', ""clients'"", 'and', ""translators'"", 'satisfaction.', '<ref type=""single"">Sojnóczky (2013)</ref>', 'does', 'not', 'discuss', 'LSP', 'costs', 'for', 'internal', 'MT', 'development.', 'He', 'emphasizes', 'on', 'margin', 'shrinking,', 'which', 'is', 'directly', 'linked', 'to', 'investment', 'gain.', ""Hunnect's"", 'translation', 'provision', 'process', 'involves', 'three', 'tasks', '-translation,', 'bilingual', 'editing', 'and', 'proofing.', 'The', 'time', 'estimation', 'of', 'these', 'tasks', 'per', 'order,', 'shown', 'in', 'percentage,', 'is', 'the', 'following:', 'translation', 'requires', '50%', 'of', 'the', 'time,', 'editing', '-20%,', 'proofing', '-5%,', 'and', 'the', 'rest', '25%', 'is', 'the', 'marginal', 'buffer', 'time.', 'The', 'time', 'management', 'planning', 'for', 'the', 'post-edited', 'MT', 'output', 'is', 'as', 'follows:', '20%', 'of', 'the', 'time', 'is', 'devoted', 'to', 'translation,', '30%', '-for', 'post-editing', '(PE),', '5%', 'for', 'proofing.', 'The', 'other', '45%', 'of', 'the', 'time', 'is', 'the', 'margin', 'time', 'until', 'delivery.', 'In', 'reality,', 'Sojnóczky', '(2013)', 'observes', 'the', 'margin', 'time', 'left', 'after', 'translation,', 'postediting', 'and', 'proofing', 'for', ""Hunnect's"", 'case', 'is', '50%.', 'Therefore,', 'the', 'use', 'of', 'MT', 'in', 'the', 'translation', 'process', 'reduced', 'the', 'delivery', 'time', 'or', '35%', 'savings', 'of', 'time.', '35%', 'savings', 'of', 'time', 'results', 'in', '…', 'quicker', 'potential', 'ROI.', 'The', 'vendor', 'pricing', 'scheme', 'implemented', 'by', '<ref type=""single"">Sojnóczky (2013)</ref>', 'is', 'that', 'postedited', 'MT', 'is', 'paid', '60%', 'of', 'the', 'original', 'price.', 'Consequently,', 'the', 'company', 'cost', 'for', 'delivering', 'an', 'order', 'is', 'reduced', 'by', '40%', 'and', 'time', 'to', 'delivery', 'is', 'increased', 'by', '35%.', 'As', 'mentioned', 'in', 'Section', '7,', 'managers', 'need', 'to', 'be', 'careful', 'when', 'developing', 'vendor', 'pricing', 'model', 'strategies', 'as', 'it', 'is', 'a', 'sensitive', 'matter.', 'Additionally,', 'Sojnóczky', '(2013)', 'observes', '68%', 'increase', 'of', 'productivity', 'among', 'trained', 'to', 'post-edit', 'translators,', 'which', 'reflects', 'directly', 'the', ""translators'"", 'pay.', 'The', 'statistics', '<ref type=""single"">Sojnóczky (2013)</ref>', 'observes', 'show', 'that', 'the', ""translators'"", 'pay', 'has', 'increased', 'with', 'at', 'least', '1%', 'instead', 'of', 'decreasing', 'as', 'feared.']",326,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]"
23336cc2-a7d6-4382-ab4d-b572593325f3,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['The syntactic process'],['2000'],['M Steedman'],single,"['Once', 'the', 'best', 'performing', 'adapted', 'language', 'models', 'were', 'identified,', 'we', 'tried', 'to', 'further', 'boost', 'the', 'performance', 'by', 'providing', 'the', 'HPB', 'SMT', 'system', 'with', 'target-side', 'syntactic', 'information', 'extracted', 'using', 'CCG', 'resources', '<ref type=""single"">[5].</ref>', 'We', 'used', 'CCG', 'categories', 'to', 'label', 'non-terminals', 'in', 'hierarchical', 'rules.', 'Different', 'CCG-based', 'labeling', 'approaches', 'were', 'explored,', 'each', 'focussing', 'on', 'a', 'different', 'aspect', 'of', 'information', 'reflected', 'in', 'CCG', 'categories.', 'The', 'best', 'performing', 'system', 'was', 'a', 'CCGaugmented', 'HPB', 'system', 'for', 'both', 'language', 'pairs', 'providing', 'a', 'statistically', 'significant', 'improvement', 'of', '0.93', 'absolute', 'BLEU', 'points', '(3.25%', 'relative)', 'and', '0.44', 'absolute', 'BLEU', 'points', '(3.7%', 'relative)', 'over', 'the', 'Ar-En', 'and', 'Zh-En', 'mixture-adapted', 'PB-SMT', 'baselines,', 'respectively.']",30,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0]"
23972ba3-c07a-4163-8f5b-354926150014,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,"['A Theoretical Analysis of NDCG Type Ranking Measures', 'Cumulated Gain-Based Evaluation of IR Techniques']","['2013', '2002']","['Yining Wang;Liwei Wang;Yuanzhi Li;Di He;Tie-Yan Liu', 'Kalervo Järvelin;Jaana Kekäläinen']",group,"['Evaluation', 'Metrics:', 'Historically,', 'performance', 'on', 'the', 'explanation', 'regeneration', 'task', 'was', 'evaluated', 'using', 'Mean', 'Average', 'Precision', '(MAP),', 'using', 'the', 'binary', 'ratings', '(gold', 'or', 'not', 'gold)', 'associated', 'with', 'each', 'fact', 'for', 'a', 'given', 'explanation.', 'To', 'leverage', 'the', 'new', 'graded', 'annotation', 'schema,', 'here', 'we', 'switch', 'to', 'evaluate', 'system', 'performance', 'using', 'Normalized', 'Discounted', 'Cumulative', 'Gain', '(NDCG)', '<ref type=""group"">(Järvelin and Kekäläinen, 2002, Wang et al., 2013).</ref>']",52,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]"
23ab0f96-aed1-42b9-b134-1d5bf34a6f80,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['unknown'],['unknown'],['unknown'],single,"['The', 'same', 'approach', 'is', 'applied', 'on', 'diacritic', 'model', 'instead', 'of', 'using', 'character', 'information', 'we', 'use', 'diacritics', 'and', 'instead', 'of', 'using', 'C-Bi-LSTM', 'we', 'use', 'D-Bi-LSTM.', 'We', 'extract', 'the', 'forward', 'and', 'backward', 'outputs', 'of', 'the', 'trained', 'D-Bi-LSTM', 'as', 'individually-trained', 'diacritic', 'embeddings.', 'It', 'is', 'worth', 'noting', 'that', 'both', 'of', 'these', 'models', 'are', 'trained', 'on', 'diacritized', 'version', 'of', 'the', 'datasets.', 'Also', 'it', 'is', 'important', 'to', 'mention', 'that', 'the', 'output', 'from', 'this', 'step', 'are', 'weights', 'to', 'initialize', 'the', 'character', 'and', 'diacritic', 'embedding', 'layers', 'in', 'the', 'combination', 'model', 'and', 'both', 'of', 'these', 'sets', 'of', 'weights', 'have', 'been', 'trained', 'individually', 'in', 'separate', 'models.', 'The', 'justification', 'of', 'this', 'step', 'can', 'be', 'found', 'in', 'Section', '(6)', '<ref type=""single"">Table (2)</ref>', 'where', 'the', 'experiments', 'showed', 'that', 'training', 'these', 'embeddings', 'separately', 'and', 'using', 'them', 'as', 'individually-trained', 'embedding', 'in', 'the', 'final', 'model', 'improves', 'the', 'performance.']",107,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
23b51f34-ef91-454c-a447-138c67705d6a,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['unknown'],['unknown'],['unknown'],single,"['In', 'order', 'to', 'accomplish', 'the', 'high-performance', 'natural', 'language', 'processing,', 'we', 'have', 'designed', 'a', 'highly', 'parallel', 'machine', 'called', 'Semantic', 'Network', 'Array', 'Processor', '(SNAP)', '[Moldovan', 'and', '<ref type=""single"">Lee, 1990]</ref>', '<ref type=""single"">[Lee and Moldovan, 1990],</ref>', 'and', 'implemented', 'an', 'experimental', 'machine', 'translation', 'system', '*This', 'research', 'is', 'funded', 'by', 'the', 'National', 'Science', 'Foundation', 'Grant', 'No..', 'A', 'version', 'of', 'this', 'paper', 'will', 'appear', 'in', 'the', 'International', 'Joint', 'Conference', 'on', 'Artificial', 'Intelligence', '(IJCAI-91).']",25,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
23e34678-62e1-4d4e-8b44-1f5225221bd5,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['To', 'this', 'end,', 'the', 'alignment', 'process', 'involves', 'training', 'three', '<ref type=""single"">BERT-based (Devlin et al., 2018)</ref>', 'biencoder', 'retrieval', 'models', 'to', 'retrieve', 'the', 'most', 'likely', 'characters,', 'locations,', 'and', 'objects', 'required', 'flesh', 'the', 'environment', 'out', 'and', 'make', 'the', 'quest', 'achievable.', 'We', 'use', 'the', 'same', 'biencoder', 'architecture', 'proposed', 'by', '<ref type=""single"">Urbanek et al. (2019)</ref>', 'which', 'encodes', 'context', 'using', 'one', 'transformer', 'and', 'candidates', 'with', 'anotherscoring', 'candidates', 'via', 'inner', 'product', 'between', 'the', 'two', 'encoded', 'vectors.', 'The', 'character', 'retrieval', 'model', 'is', 'conditioned', 'on', 'the', 'initial', 'character,', 'quest,', 'and', 'location-producing', 'additional', 'characters', 'required', 'to', 'complete', 'the', 'world.']",40,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
24726e53-1586-4fb3-be5d-8b78739fa560,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,"['To test machine comprehension, start by defining comprehension']",['2020'],['Jesse Dunietz;Greg Burnham;Akash Bharadwaj;Owen Rambow;Jennifer Chu-Carroll;Dave Ferrucci'],single,"['There', 'is', 'a', 'growing', 'trend', 'in', 'using', 'adversarial', 'models', 'for', 'data', 'creation', 'to', 'make', 'the', 'dataset', 'more', 'challenging', 'or', 'discard', 'examples', 'that', 'can', 'be', 'solved', 'using', 'surface', 'cues', '<ref type=""group"">(Bartolo et al., 2020, Nie et al., 2020, Yang et al., 2018a, Zellers et al., 2018, Yang et al., 2018b, Dua et al., 2019, Chen et al., 2019, Dasigi et al., 2019).</ref>', 'Quoref', 'is', 'also', 'created', 'using', 'an', 'adversarial', 'data', 'collection', 'method', 'to', 'discard', 'examples', 'that', 'can', 'be', 'solved', 'using', 'simple', 'lexical', 'cues.', 'The', 'assumption', 'is', 'that', 'it', 'is', 'hard', 'to', 'avoid', 'simple', 'lexical', 'cues', 'by', 'which', 'the', 'model', 'can', 'answer', 'questions', 'without', 'coreference', 'reasoning.', 'Therefore,', 'an', 'adversarial', 'model', '(A)', 'is', 'used', 'to', 'discard', 'examples', 'that', 'contain', 'such', 'lexical', 'cues.', 'While', 'this', 'adversarial', 'filtering', 'removes', 'examples', 'that', 'are', 'easy', 'to', 'solve', 'by', 'A,', 'it', 'does', 'not', 'ensure', 'that', 'the', 'remaining', 'examples', 'do', 'not', 'contain', 'shortcuts', 'that', 'are', 'not', 'explored', 'by', 'A.', 'First,', 'the', 'adversarial', 'model', 'in', 'Quoref', 'is', 'trained', 'on', 'another', 'dataset,', 'i.e.,', 'SQuAD.', 'Thus,', 'the', 'failure', 'of', 'A', 'on', 'Quoref', 'examples', 'may', 'be', 'due', 'to', '(1)', 'Quoref', 'having', 'different', 'lexical', 'cues', 'than', 'those', 'in', 'SQuAD,', 'or', '(2)', 'domain', 'shift.', 'Second,', 'and', 'more', 'importantly,', 'as', 'argued', 'by', '<ref type=""single"">Dunietz et al. (2020),</ref>', 'making', 'the', 'task', 'challenging', 'by', 'focusing', 'on', 'examples', 'that', 'are', 'more', 'difficult', 'for', 'existing', 'models', 'is', 'not', 'a', 'solution', 'for', 'more', 'useful', 'reading', 'comprehension.', '7', 'We', 'instead', 'propose', 'a', 'methodology', 'for', 'creating', 'question-answer', 'pairs', 'as', 'follows:']",164,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0]"
24a9b5c3-fd63-4fbe-bda1-ea7fc5fd8565,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['No data to crawl? monolingual corpus creation from PDF files of truly low-resource languages in Peru'],['2020'],['Gina Bustamante;Arturo Oncevay;Roberto Zariquiey'],single,"['Southern', 'Quechua:', 'with', '6+', 'millions', 'of', 'speakers', 'and', 'several', 'variants,', 'it', 'is', 'the', 'most', 'widespread', 'indigenous', 'language', 'in', 'Peru.', 'AmericasNLP', 'provides', 'evaluation', 'sets', 'in', 'the', 'standard', 'Southern', 'Quechua,', 'which', 'is', 'based', 'mostly', 'on', 'the', 'Quechua', 'Ayacucho', '(quy)', 'variant.', 'There', 'is', 'parallel', 'data', 'from', 'dictionaries', 'and', 'Jehovah', 'Witnesses', '<ref type=""single"">(Agić and Vulić, 2019).</ref>', 'There', 'is', 'parallel', 'corpus', 'aligned', 'with', 'English', 'too.', 'We', 'also', 'include', 'the', 'close', 'variant', 'of', 'Quechua', 'Cusco', '(quz)', 'to', 'support', 'the', 'multilingual', 'learning.', 'Aymara', '(aym):', 'with', '1.7', 'million', 'of', 'speakers', '(mostly', 'in', 'Bolivia).', 'The', 'parallel', 'and', 'monolingual', 'data', 'is', 'extracted', 'from', 'a', 'news', 'website', '(Global', 'Voices)', 'and', 'distributed', 'by', 'OPUS', '<ref type=""single"">(Tiedemann, 2012).</ref>', 'There', 'are', 'aligned', 'data', 'with', 'English', 'too.', 'Shipibo-Konibo', '(shp):', 'a', 'Panoan', 'language', 'with', 'almost', '30,000', 'speakers', 'in', 'the', 'Amazonian', 'region.', 'There', 'are', 'parallel', 'data', 'from', 'dictionaries,', 'educational', 'material', '<ref type=""single"">(Galarreta et al., 2017),</ref>', 'language', 'learning', 'flashcards', '(Gómez', '<ref type=""single"">Montoya et al., 2019),</ref>', 'plus', 'monolingual', 'data', 'from', 'educational', 'books', '<ref type=""single"">(Bustamante et al., 2020).</ref>', 'Ashaninka', '(cni):', 'an', 'Arawakan', 'language', 'with', '45,000', 'speakers', 'in', 'the', 'Amazon.', 'There', 'is', 'parallel', 'data', 'from', 'dictionaries,', 'laws', 'and', 'books', '<ref type=""single"">(Ortega et al., 2020a),</ref>', 'plus', 'monolingual', 'corpus', '<ref type=""single"">(Bustamante et al., 2020).</ref>']",139,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
24cd0192-3f54-469a-b77e-6ec41cb39232,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['Sentence simplification by monolingual machine translation'],['2012'],['Sander Wubben'],single,"['Researchers', 'usually', 'regard', 'the', 'sentence', 'simplification', 'task', 'as', 'a', 'monolingual', 'variant', 'of', 'machine', 'translation', '(MT)', '<ref type=""single"">(Wubben et al., 2012).</ref>', 'Benefiting', 'from', 'the', 'advancement', 'of', 'neural', 'machine', 'translation,', 'this', 'task', 'has', 'also', 'made', 'great', 'progress', 'in', 'recent', 'years.']",15,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
255c1009-cf0c-4829-a40c-b2d42b11e384,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['beta-vae: Learning basic visual concepts with a constrained variational framework'],['2017'],['Irina Higgins;Loïc Matthey;Arka Pal;Christopher Burgess;Xavier Glorot;Matthew Botvinick;Shakir Mohamed;Alexander Lerchner'],single,"['Algorithm', '1', 'Metric', 'of', '<ref type=""single"">Higgins et al. (2017)</ref>', '1:', 'D', '=', '∅', '2:', 'for', 'f', 'i', '∈', 'F', 'do', '3:', 'for', 'n', '=', '1,', '2,...,', 'N', 'do', '4:', 'Sample', 's', 'n', 'from', 'j', 'S', 'ij', '5:', 'Find', 'the', 'value', 'v', 'ij', 'on', 'f', 'i', 'for', 's', 'n', '6:', 'Sample', '(z', '(1)', '1', ',...,', 'z', '(1)', 'L)', 'from', 'R', 'ij', '7:', 'Sample', '(z', '(2)', '1', ',...,', 'z', '(2)', 'L)', 'from', 'R', 'ij', '8:', 'z', 'n', '=', '1', 'L', 'L', 'l=1', '|z', '(1)', 'l', '−', 'z', '(2)', 'l', '|', '9:', 'D', '=', '{(z', 'n,', 'f', 'i', ')}', 'D', '10:', 'Split', 'D', 'into']",4,"[3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
2579964a-617e-48a0-8847-28ad3107860f,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,"['Entity linking for mathematical expressions in scientific documents', 'Extracting textual descriptions of mathematical expressions in scientific papers. D-Lib Magazine', 'Mining coreference relations between formulas and text using Wikipedia']","['2016', '2014', '2010']","['Giovanni Kristianto;Goran Topić;Akiko Aizawa', 'Giovanni Kristianto;Akiko Aizawa', 'Minh Nghiem Quoc;Keisuke Yokoi']",group,"['Most', 'of', 'the', 'previous', 'studies', 'have', 'attempted', 'to', 'extract', 'and', 'link', 'at', 'formula', 'level', '<ref type=""group"">(Nghiem Quoc et al., 2010, Kristianto et al., 2014 Kristianto et al., , 2016)).</ref>', 'In', 'reality,', 'understanding', 'mathematical', 'formulae', 'requires', 'details', 'of', 'atomic', 'symbols', 'e.g.', 'superscript,', 'subscript,', 'function', 'arguments.', 'We', 'believe', 'that', 'addressing', 'the', 'problem', 'at', 'this', 'fine-grain', 'level', 'is', 'crucial', 'to', 'drive', 'future', 'research', 'toward', 'a', 'better', 'understanding', 'of', 'the', 'complex', 'symbol-description', 'extraction', 'task.']",14,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
25cb89b4-8d45-4a96-84ea-bd8fdeb7cf59,Entity Attribute Relation Extraction with Attribute-Aware Embeddings,2020,Dan Iter;Xiao Yu;Fangtao Li,"['Freebase: a collaboratively created graph database for structuring human knowledge', 'Knowledge vault: A web-scale approach to probabilistic knowledge fusion']","['2008', '2014']","['Kurt Bollacker;Colin Evans;Praveen Paritosh;Tim Sturge;Jamie Taylor', 'Xin Dong;Evgeniy Gabrilovich;Geremy Heitz;Wilko Horn;Ni Lao;Kevin Murphy;Thomas Strohmann;Shaohua Sun;Wei Zhang']",group,"['Modern', 'search', 'engines', 'often', 'attempt', 'to', 'provide', 'structured', 'search', 'results', 'that', 'reveal', 'more', 'facets', 'of', 'the', 'search', 'query', 'than', 'explicitly', 'requested.', 'These', 'results', 'rely', 'on', 'knowledge', 'bases', 'that', 'contain', 'tuples', 'of', 'the', 'form', '(entity,', 'attribute,', 'value).', 'However,', 'the', 'number', 'of', 'known', 'entities', 'and', 'attributes', 'in', 'these', 'knowledge', 'bases', 'is', 'limited', 'and', 'there', 'is', 'a', 'long', 'tail', 'of', 'both', 'entities', 'and', 'attributes', 'that', 'is', 'too', 'large', 'to', 'be', 'manually', 'curated.', 'The', 'goal', 'of', 'automatic', 'entityattribute', 'extraction', 'is', 'to', 'replace', 'manual', 'knowledge', 'acquisition', 'which', 'is', 'expensive', 'and', 'biased', 'towards', 'popular', 'entities', '<ref type=""group"">(Bollacker et al., 2008, Dong et al., 2014).</ref>', 'Previous', 'studies', 'have', 'proposed', 'model-based', 'approaches', 'that', 'use', 'various', 'NLP', 'features,', 'distant', 'supervision', 'and', 'traditional', 'machine', 'learning', 'methods', 'for', 'entity-attribute', 'extraction', 'but', '*', 'Work', 'done', 'during', 'an', 'internship', 'at', 'Google.', 'their', 'precision', 'has', 'not', 'been', 'high', 'enough', 'to', 'replace', 'manually', 'curated', 'knowledge', 'bases', '<ref type=""group"">(Auer et al., 2007, Carlson et al., 2010, Gupta et al., 2014).</ref>']",89,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
25e623a7-e342-49b6-a9fa-0cec1a3e85be,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,['Abstractive text summarization using lstm-cnn based deep learning'],['2019'],['Shengli Song;Haitao Huang;Tongxiao Ruan'],single,"['Model.', 'The', 'proposed', 'method', 'will', 'be', 'able', 'to', 'process', 'several', 'modalities', 'that', 'play', 'a', 'crucial', 'role', 'in', 'communication,', '(i)', 'Linguistic', 'Information', '(at', 'syntactic', 'and', 'semantic', 'level),', '(ii)', 'Situational', 'Information,', '(iii)', 'Prototypical', 'Knowledge', 'and', 'Relations,', 'and', '(iv)', 'Speech-accompanying', 'eye-movements', 'of', 'the', 'speaker.', 'The', 'initial', 'base', 'model', 'will', 'focus', 'on', 'the', 'first', 'three', 'capabilities', 'by', 'utilizing', 'data-driven', 'language', 'models', 'such', 'as', 'fasttext', '<ref type=""single"">(Bojanowski et al., 2017)</ref>', 'and', 'commonsense', 'knowledge-bases', 'like', 'ConceptNet', '<ref type=""single"">(Speer et al., 2017).</ref>', 'At', 'the', 'same', 'time,', 'two', 'modules', 'that', '(i)', 'incorporate', 'eye-movements', 'and', '(ii)', 'perform', 'situation-specific', 'feature', 'adaptation', 'will', 'be', 'developed', 'from', 'scratch.', 'In', 'brief,', 'vocabulary', 'obtained', 'from', 'the', 'pre-trained', 'embeddings', 'is', 'used', 'as', 'a', 'bridge', 'between', 'the', 'modalities.', 'For', 'each', 'vocabulary', 'item,', 'multimodal', 'embeddings', 'will', 'be', 'created', 'by', 'processing', 'every', 'input', 'channel,', 'see', 'Figure', '2.', 'For', 'each', 'modality', 'and', 'their', 'joint', 'training,', 'we', 'will', 'utilize', 'an', 'appropriate', 'encoder,', 'such', 'as', 'Fast-R-CNN', '<ref type=""single"">(Girshick, 2015)</ref>', 'for', 'images', 'and', 'attention-based', 'bi-directional', 'LSTMs', '(e.g.', '<ref type=""single"">Song et al. (2019),</ref>', 'for', 'text', 'and', 'eye-movement', 'data.', 'A', 'neural', 'network', 'ensemble', 'model', 'will', 'be', 'trained', 'on', 'the', 'embeddings', 'for', 'the', 'task', 'of', 'intended', 'object', 'or', 'action', 'prediction', 'from', 'situated', 'settings', 'with', 'masked', 'information.']",145,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
265eed67-b084-427c-8fb3-15fb0366b114,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['In', 'this', 'section,', 'we', 'discuss', 'individual', 'modules', 'for', 'operationalizing', 'the', 'PSL', 'rules.', 'For', 'each', 'module,', 'we', 'fine-tune', 'the', 'pretrained', 'uncased', 'BERT-base', '<ref type=""single"">(Devlin et al., 2019).</ref>', 'We', 'use', 'the', 'Transformers', 'library', 'v3.3.0', '<ref type=""single"">(Wolf et al., 2020)</ref>', 'for', 'high', 'reproducibility', 'and', 'low', 'development', 'costs.', 'But', 'any', 'other', 'models', 'could', 'be', 'used', 'instead.', 'Each', 'dataset', 'used', 'is', 'randomly', 'split', 'with', 'a', 'ratio', 'of', '9:1', 'for', 'training', 'and', 'test.', 'Cross-entropy', 'and', 'Adam', 'are', 'used', 'for', 'optimization.', 'To', 'address', 'the', 'imbalance', 'of', 'classes', 'and', 'datasets,', 'the', 'loss', 'for', 'each', 'training', 'instance', 'is', 'scaled', 'by', 'a', 'weight', 'inversely', 'proportional', 'to', 'the', 'number', 'of', 'its', 'class', 'and', 'dataset.']",21,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
267a1732-5688-45ce-b1d5-f6aad2c0ecd4,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,"['VCDM: Leveraging Variational Biencoding and Deep Contextualized Word Representations for Improved Definition Modeling', 'unknown']","['2020', 'unknown']","['Machel Reid;Edison Marrese-Taylor;Yutaka Matsuo', 'unknown']",group,"['We', 'follow', 'the', 'mainstream', 'method', '<ref type=""group"">(Yang et al., 2020, Kong et al., 2020, Reid et al., 2020)</ref>', 'to', 'concatenate', 'the', 'word', 'and', 'context', 'together', 'with', 'a', 'special', 'token', '[SEP]', 'as', 'x', '=', '(w', '*,', '[SEP],', 'c).', 'The', 'entire', 'sequence', 'is', 'then', 'fed', 'into', 'SimpDefiner,', 'and', 'the', 'definition', 'is', 'obtained', 'by', 'the', 'following', 'language', 'model:']",5,"[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
270898ca-bbc5-4d63-afef-c51e70da288c,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,"['Speech-Transformer: A no-recurrence sequence-to-sequence model for speech recognition', 'unknown', 'Attention-based models for speech recognition', 'Listen, attend and spell: A neural network for large vocabulary conversational speech recognition', 'Towards end-to-end speech recognition with recurrent neural networks']","['2018', '2012', '2015', '2016', '2014']","['L Dong;S Xu;B Xu', 'A Graves', 'J Chorowski;D Bahdanau;D Serdyuk;K Cho;Y Bengio', 'W Chan;N Jaitly;Q Le;O Vinyals', 'A Graves;N Jaitly']",group,"['End-to-end', 'automatic', 'speech', 'recognition', '(E2E', 'ASR),', 'which', 'transcribes', 'speech', 'using', 'a', 'single', 'neural', 'network', '(NN),', 'has', 'recently', 'gained', 'traction', '<ref type=""group"">(Graves and Jaitly, 2014, Chorowski et al., 2015, Chan et al., 2016, Graves, 2012, Dong et al., 2018).</ref>', 'Existing', 'E2E', 'ASR', 'models', 'generate', 'audio', 'transcripts', 'by', 'sequentially', 'producing', 'likely', 'graphemes,', 'or', 'multi-graphemic', 'units,', 'from', 'which', 'lexical', 'items', 'of', 'a', 'language', 'can', 'be', 'recovered.', 'However,', 'other', 'linguistic', 'annotations', 'such', 'as', 'phonemic', 'transcripts,', 'part-of-speech', '(POS)', 'tags,', 'or', 'word', 'boundaries,', 'help', 'understand', 'the', 'underlying', 'audio', 'characteristics', '<ref type=""single"">(Simonnet et al., 2017).</ref>', 'Such', 'linguistic', 'annotations', 'are', 'especially', 'important', 'in', 'natural', 'language', 'processing', '(NLP)', 'tasks', 'done', 'on', 'audio', '!!!', '""', '!""!', '#', '""', '#""!', '#', '$', '#', '""', '$!', '""!', '""', '!""#', '#', '""', '#""#', '#', '$', '#', '""', '$', '""', '""#', '""', '#', '""', '#', '""', '#', '""', '#', '$', '#', '""', '#', '""']",19,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
274a4ae9-80e8-43f8-b06f-c115bfbf88c8,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['LIBSVM: A library for support vector machines'],['2011'],['Chih-Chung Chang;Chih-Jen Lin'],single,"['For', 'linear', 'SVM,', 'we', 'used', 'an', 'online', 'learning', 'implementation', 'of', 'SCIKIT-LEARN', '<ref type=""group"">(Pedregosa et al., 2011, Zhang, 2004),</ref>', 'based', 'on', 'LIBSVM', '<ref type=""single"">(Chang and Lin, 2011),</ref>', 'with', 'hinge', 'loss', 'and', 'Stochastic', 'Gradient', 'Descent', '(SGD)', 'optimiser.', 'Hyperparameters', 'were', 'set', 'to', 'default', 'except', 'for', 'the', 'SGD', 'regularisation', 'parameter', 'that', 'was', 'increased', 'to', 'α', '=', '0.75,', 'which', 'provided', 'better', 'classification', 'accuracy', 'on', 'the', 'dev', 'set.', 'The', 'parameter', 'α', 'is', 'inversely', 'proportional', 'to', 'the', 'C', 'parameter', 'in', 'the', 'standard', 'SVM', 'implementation.', 'The', 'online', 'implementation', 'also', 'allowed', 'us', 'to', 'select', 'the', 'best', 'model', 'using', 'early', 'stopping.', 'The', 'SVM', 'was', 'provided', 'with', 'EEG', 'activity', 'vectors', 'as', 'inputs,', 'i.e.', '1', 'x', '(EEG', 'channels', '×', 'time', 'points).']",15,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
27ad00a2-aae6-411c-86df-5488f3606005,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Emotion classification using massive examples extracted from the web'],['2008'],['Ryoko Tokuhisa;Kentaro Inui;Yuji Matsumoto'],single,"['The', 'downside', 'of', 'datasets', 'trained', 'on', 'Twitter', 'is', 'that', 'they', 'are', 'likely', 'not', 'that', 'good', 'at', 'classifying', 'anything', 'other', 'than', 'tweets.', 'It', 'is', 'plausible', 'that', 'datasets', 'trained', 'on', 'less', 'specific', 'data', 'such', 'as', 'XED', 'and', 'those', 'created', 'by', '<ref type=""single"">Tokuhisa et al. (2008)</ref>', 'and', '<ref type=""single"">Demszky et al. (2020)</ref>', 'are', 'better', 'at', 'crossing', 'domains', 'at', 'the', 'cost', 'of', 'evaluation', 'metrics.']",38,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
27d7c260-35f9-4df8-a6ee-bd4554b8552f,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['Speech language translation'],['1989'],['M Steer;F Stentiford'],single,"['If', 'there', 'is', 'no', 'source', 'text,', 'the', 'focus', 'obviously', 'falls', 'upon', 'the', 'generation', 'of', 'the', 'target', 'text(s),', 'a', 'problem', 'in', 'MT', 'which', 'was', 'for', 'a', 'long', 'time', 'seriously', 'underestimated', '(cf.', '<ref type=""single"">[27]</ref>', ').', 'Our', 'present', 'approach', 'has', 'been', 'influenced', 'by', 'the', ""'phrasebook'"", 'approach', 'to', 'speech', 'translation', '<ref type=""single"">[44],</ref>', 'in', 'which', 'set', 'phrases', 'are', 'stored,', 'as', 'in', 'a', ""holidaymaker's"", 'phrasebook,', 'and', 'retrieved', 'by', 'the', 'fairly', 'crude,', 'though', 'effective,', 'technique', 'of', 'recognising', 'keywords', 'in', 'a', 'particular', 'order', 'in', 'the', 'input', 'speech', 'signal.', 'It', 'also', 'builds', 'on', 'research', 'on', 'interactive', 'generation', 'of', 'stereotypical', 'texts', '<ref type=""group"">([1, 19, 35]</ref>', '),', 'where', 'texts', 'in', 'certain', 'restricted', 'domains', 'are', 'stored', 'and', 'retrieved', 'as', 'appropriate', 'through', 'interaction', 'with', 'users,', 'and', 'are', 'reformulated', 'to', 'fulfill', 'the', 'specific', 'requirements', 'expressed', 'by', 'them.']",45,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
283ac499-5a7a-48da-933c-a376cb876cb3,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['Transformers: State-of-theart natural language processing'],['2020'],['Thomas Wolf'],single,"['All', 'models', 'are', 'implemented', 'based', 'on', 'the', 'opensource', 'transformers', 'library', 'of', 'hugging', 'face', '<ref type=""single"">(Wolf et al., 2020),</ref>', 'which', 'provides', 'thousands', 'of', 'pretrained', 'models', 'that', 'can', 'be', 'quickly', 'downloaded', 'and', 'fine-tuned', 'on', 'specific', 'tasks.', 'of', 'doing', 'this', 'in', 'Table', '3', 'and', 'we', 'can', 'find', 'that', 'it', 'is', 'very', 'effective', 'by', 'increasing', '0.02', 'from', 'base', 'models.']",13,"[3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
285e25e4-bd31-4b12-9fca-da525e631efb,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Language models are unsupervised multitask learners'],['2019'],['Alec Radford;Jeffrey Wu;Rewon Child;David Luan;Dario Amodei;Ilya Sutskever'],single,"['word', 'embeddings', 'extracted', 'from', 'the', 'first', 'layer', 'of', 'the', 'GPT2', 'language', 'model', '<ref type=""single"">(Radford et al., 2019).</ref>']",12,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]"
287d6e36-dd61-4117-a089-af9e83bb375a,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['Experiments and Prospects of Example-Based Machine Translation'],['1986'],['C Stanfill;D Waltz;E Sumita;H Iida;H Tomabechi;R Wilensky'],single,"['SNAP', 'provides', 'four', 'knowledge', 'representation', 'elements:', 'node,', 'link,', 'node', 'color', 'and', 'link', 'value.', '<ref type=""single"">, 1985],</ref>', 'Conceptual', 'Graphs', '<ref type=""single"">[Sowa, 1984],</ref>', 'KODIAK', '<ref type=""single"">[Wilensky, 1987],</ref>', 'etc.']",18,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3]"
29265126-45b5-4048-ac86-c26fd6284b64,ROI Analysis model for Language Service Providers,2013,Ekaterina Stambolieva,"[""Hunnect's Use Case. TAUS Machine Translation Showcase at Localization World"", 'Lionbridge Technology Overview: Technology Best Practice. Paper presented online']","['2013', '2009']","['Saándor Sojnóczky', 'Nicholas Mcmahon']",group,"['Opposed', 'to', '<ref type=""group"">Sojnóczky (2013 ), McMahon (2009)</ref>', 'estimates', 'the', 'post-editing', 'costs', 'of', 'a', 'commercial', 'business', 'for', 'instant', 'communication', 'messaging', 'translation.', 'Interestingly,', 'his', 'cost', 'estimations', 'cover', 'corpus', 'management', 'and', 'acquisition,', '5', 'to', '200', 'GBP', 'per', 'year,', 'customization', 'costs,', 'human', 'resources', 'training,', '5', 'to', '10', 'GBP', 'per', 'year,', 'among', 'others.', 'He', 'measures', 'investment', 'cost', 'of', 'product', 'licenses', 'to', '100', 'GBP', 'per', 'year.', 'Overall,', 'the', 'total', 'investment', 'costs', 'are', 'estimated', 'to', '180', 'GBP', 'per', 'year.', 'The', 'predicted', 'ROI', 'for', 'the', 'first', 'year', 'after', 'successful', 'MT', 'implementation', 'equals', 'to', 'minus', '30000', 'GBP,', 'therefore', 'is', 'negative', 'speaking', 'in', 'financial', 'terms.', 'The', 'vendor', 'pricing', 'models', 'is', 'estimated', 'to', '65-85%', 'of', 'the', 'original', 'pay', 'per', 'word.', 'What', 'is', 'intriguing', 'is', 'the', 'fact', 'benefits', 'are', 'not', 'only', 'measured', 'in', 'money.', '<ref type=""single"">McMahon (2009),</ref>', 'as', '<ref type=""single"">Sojnóczky (2013),</ref>', 'measures', 'the', 'user', 'satisfaction', 'rate,', 'which', 'in', 'the', 'case', 'of', 'Lionbridge', '2', 'has', 'increased', 'with', '30-50%.', 'The', 'success', 'rate', 'measured', 'varies', 'between', '5%', 'and', '25%.']",2,"[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
295ea4c7-e46c-44ac-9d95-0552c17e5085,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,"['A survey on automatic detection of hate speech in text', 'A survey on hate speech detection using natural language processing']","['2018', '2017']","['Paula Fortuna;Sérgio Nunes', 'Anna Schmidt;Michael Wiegand']",group,"['To', 'date,', 'several', 'approaches', 'to', 'automated', 'detection', 'of', 'abusive', 'language', 'have', 'been', 'proposed,', 'including', 'rule-based', '<ref type=""group"">(Spertus, 1997, Razavi et al., 2010, Wiegand et al., 2018),</ref>', 'linguistic', 'and', 'social', 'feature', 'engineering', '<ref type=""group"">(Yin et al., 2009, Sood et al., 2012, Warner and Hirschberg, 2012, Salminen et al., 2018),</ref>', 'utilizing', 'distributed', 'representations', 'from', 'neural', 'networks', '<ref type=""group"">(Djuric et al., 2015, Mehdad and Tetreault, 2016, Nobata et al., 2016)</ref>', 'or', 'applying', 'deep', 'neural', 'networks', 'directly', '<ref type=""group"">(Park and Fung, 2017, Pavlopoulos et al., 2017a, Mishra et al., 2018a).</ref>', 'Researchers', 'have', 'also', 'explored', 'multi-task', 'learning', 'settings', 'with', 'objectives', 'such', 'as', 'emotion', 'detection', '<ref type=""group"">(Rajamanickam et al., 2020, Samghabadi et al., 2019).</ref>', 'We', 'refer', 'the', 'reader', 'to', 'recent', 'surveys', 'of', 'the', 'field', '<ref type=""group"">(Schmidt and Wiegand, 2017, Fortuna and Nunes, 2018)</ref>', 'for', 'a', 'detailed', 'literature', 'review.']",60,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
2994f6b0-d299-4e8c-8a55-cde8f5ea8fff,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['Taking MT Evaluation Metrics to Extremes: Beyond Correlation with Human Judgments'],['2019'],['Marina Fomicheva;Lucia Specia'],single,"['The', 'most', 'common', 'method', 'of', 'measuring', 'the', 'quality', 'of', 'a', 'MT', 'metric', 'is', 'correlation', 'with', 'human', 'judgments', '<ref type=""single"">(Fomicheva and Specia, 2019),</ref>', 'however,', 'these', 'correlations', 'provide', 'little', 'information', 'regard-ing', 'when', 'and', 'why', 'an', 'MT', 'metric', 'differs', 'from', 'human', 'judgment.', 'In', 'this', 'paper,', 'we', 'consider', 'three', 'ways', 'of', 'examining', 'MT', 'metric', 'quality,', 'with', 'the', 'aim', 'of', 'determining', 'the', 'failure', 'cases', 'of', 'MT', 'metrics.']",17,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
299dd97f-5bc0-4748-bc9c-a4c1737a5e69,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,"['E2e-vlp: End-to-end vision-language pre-training enhanced by visual learning', 'Pixel-bert: Aligning image pixels with text by deep multi-modal transformers', 'unknown', 'Vilt: Vision-and-language transformer without convolution or region supervision']","['2021', '2020', 'unknown', '2021']","['Haiyang Xu;Ming Yan;Chenliang Li;Bin Bi;Songfang Huang;Wenming Xiao;Fei Huang', 'Zhicheng Huang;Zhaoyang Zeng;Bei Liu;Dongmei Fu;Jianlong Fu', 'unknown', 'Wonjae Kim;Bokyung Son;Ildoo Kim']",group,"['To', 'tackle', 'those', 'challenges,', 'most', 'existing', 'approaches', '<ref type=""group"">(Li et al., 2021, Gan et al., 2020, Chen et al., 2020, Lu et al., 2019)</ref>', 'adopt', 'a', 'two-step', 'pretraining', 'strategy', 'that', 'firstly', 'utilizes', 'off-the-shelf', 'detectors', 'to', 'parse', 'images', 'into', 'a', 'set', 'of', 'object', 'tokens,', 'and', 'then', 'builds', 'a', 'multi-layer', 'Transformer', 'to', 'learn', 'visual', 'and', 'language', 'embeddings', 'jointly.', 'In', 'order', 'to', 'facilitate', 'the', 'multi-modal', 'learning,', 'those', 'networks', 'are', 'typically', 'trained', 'via', 'a', 'set', 'of', 'carefully', 'designed', 'BERT-like', 'objectives', '(e.g.', 'Image-Text', 'Matching).', 'Despite', 'its', 'promising', 'performance,', 'the', 'two-step', 'strategy', 'suffers', 'from', 'several', 'limitations:', '1)', 'limited', 'visual', 'object', 'concepts', 'as', 'the', 'external', 'detectors', 'are', 'trained', 'on', 'a', 'predefined', 'set', 'of', 'object', 'categories,', '2)', 'lack', 'of', 'context', 'cues', 'outside', 'of', 'the', 'object', 'regions,', 'which', 'are', 'crucial', 'for', 'complex', 'reasoning', 'tasks,', '3)', 'sub-optimal', 'visual', 'representation', 'due', 'to', 'stage-wise', 'training,', 'and', '4)', 'computational', 'inefficiency', 'caused', 'by', 'additional', 'detection', 'modules.', 'To', 'overcome', 'those', 'limitations,', 'recent', 'works', 'attempt', 'to', 'learn', 'a', 'joint', 'visual-linguistic', 'representations', 'in', 'an', 'end-to-end', 'manner', '<ref type=""group"">(Huang et al., 2021 (Huang et al., , 2020,, Xu et al., 2021, Kim et al., 2021).</ref>', 'These', 'methods', 'directly', 'take', 'dense', 'visual', 'features', 'from', 'image', 'grids', 'as', 'inputs', 'to', 'a', 'multi-modal', 'Transformer', 'network,', 'and', 'hence', 'do', 'not', 'rely', 'on', 'external', 'object', 'detectors', 'in', 'both', 'pretraining', 'and', 'finetuning', 'stages.', 'Such', 'model', 'design', 'significantly', 'simplifies', 'overall', 'network', 'architecture', 'and', 'allows', 'deeper', 'integration', 'between', 'visual', 'and', 'language', 'features.', 'However,', 'using', 'grid-level', 'features', 'makes', 'it', 'difficult', 'to', 'capture', 'object-level', 'visual', 'concepts,', 'which', 'often', 'results', 'in', 'less', 'expressive', 'multi-modal', 'representations', 'and', 'inferior', 'performances', 'in', 'downstream', 'tasks.']",143,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
29b6cf93-1dbe-4640-91fe-e24ca237494a,SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering,2020,Aishwarya Ashok;Ganapathy Natarajan;Ramez Elmasri;Laurel Smith-Stvan,"['Modeling ambiguity, subjectivity, and diverging viewpoints in opinion question answering systems']",['2016'],['Mengting Wan;Julian Mcauley'],single,"['The', 'AmazonQA', 'dataset', 'was', 'used', 'in', 'this', 'study', '<ref type=""single"">(Gupta et al., 2019).</ref>', 'The', 'dataset', 'has', 'both', 'yes/no', '(binary)', 'and', 'open-ended', 'questions.', 'The', 'fields', 'we', 'used', 'are', 'question', 'id,', 'question', 'Type,', 'question', 'Text,', 'answers,', 'review', 'snippets,', 'asin/', 'product', 'id,', 'and', 'category.', 'The', 'dataset', 'was', 'built', 'based', 'on', 'previous', 'parallel', 'datasets', 'provided', 'by', '<ref type=""single"">Wan and McAuley (2016).</ref>']",48,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1]"
29cd8dea-e9d2-461a-865b-5a9ebb0ec8d8,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Improving DRS parsing with separately predicted semantic roles'],['2021'],['Tatiana Bladier;Gosse Minnema;Rik Van Noord;Kilian Evang'],single,"['The', 'results', 'in', 'Table', '6', 'show', 'that', 'our', 'best', 'model', 'beats', 'all', 'available', 'previous', 'scores', 'on', 'the', 'English', 'PMB', '3.0.0', 'test', 'set', 'except', 'for', 'Pro', '<ref type=""single"">Boxer and van Noord et al. (2020)</ref>', 'and', 'is', 'also', 'very', 'competitive', 'on', 'the', 'dev', 'set.', 'Its', 'difference', 'with', 'the', 'state-of-theart', 'model', 'on', 'the', 'test', 'set', 'is', 'within', '1%.', 'Compared', 'with', 'the', 'best', 'previous', 'fully', 'trainable', 'compositional', 'model', 'in', '<ref type=""single"">Bladier et al. (2021)</ref>', '2020),', 'shown', 'in', 'Table', '7.']",58,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3]"
2a09f227-33d0-4ecf-8d4e-032a3282485d,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Machine-Readable Dictionaries'],['1984'],['Robert Amsler'],single,"['To', 'illustrate', 'the', 'same', 'point,', '<ref type=""single"">Amsler (1984)</ref>', 'carried', 'out', 'a', 'comparison', 'between', 'the', 'vocabulary', 'found', 'in', 'a', 'college', 'dictionary', ""(Webster's"", '7th)', 'and', 'a', 'text', 'corpus', '(New', 'York', 'Times', 'News', 'Service)', 'and', 'noted', 'that', 'the', 'overlap', 'was', 'only', '23%', 'of', 'the', 'total', 'vocabulary', 'in', 'either', 'source.', 'Three', 'quarters', 'of', 'the', '41%', 'which', 'only', 'occurred', 'in', 'the', 'corpus', 'could', 'be', 'accounted', 'for', 'in', 'terms', 'of', 'inflection,', 'hyphenation', 'at', 'the', 'end', 'of', 'a', 'line,', 'proper', 'nouns,', 'and', 'obvious', 'misspellings.', 'Assuming', 'that', 'inflection', 'is', 'accounted', 'for', 'by', 'a', 'rule', 'system,', 'hyphenation', 'is', 'covered', 'in', 'a', 'trivial', 'pre-processing', 'step,', 'and', 'misspellings', 'are', 'treated', 'separately,', 'proper', 'nouns', 'constitute', 'an', 'important', 'source', 'of', 'incompleteness.', 'What', 'happens', 'with', 'the', 'remaining', 'quarter?', 'Amsler', 'states', 'that', 'these', 'cases', 'cannot', 'be', 'classified', 'without', 'individual', 'inspection.']",5,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2a16d7cf-1da9-471f-a8a0-c9164228bbe6,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Ultra-Fine Entity Typing'],['2018'],['Eunsol Choi;Omer Levy;Yejin Choi;Luke Zettlemoyer'],single,"['Training', 'Following', '<ref type=""single"">Choi et al. (2018),</ref>', 'the', 'loss', 'is', 'a', 'sum', 'of', 'binary', 'cross-entropy', 'losses', 'over', 'all', 'entity', 'types', 'T', 'over', 'all', 'training', 'examples', 'D.', 'That', 'is,', 'we', 'treat', 'each', 'type', 'prediction', 'for', 'each', 'example', 'as', 'an', 'independent', 'binary', 'decision,', 'with', 'shared', 'parameters', 'in', 'the', 'BERT', 'encoder.']",2,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2a22931e-7729-4972-a40d-a700e59a65de,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Revisiting fewsample {bert} fine-tuning'],['2021'],['Tianyi Zhang;Felix Wu;Arzoo Katiyar;Q Kilian;Yoav Weinberger;unk Artzi'],single,"['Recently,', '<ref type=""single"">Zhang et al. (2021)</ref>', 'and', '<ref type=""single"">Mosbach et al. (2021)</ref>', 'have', 'nevertheless', 'shown', 'that', 'the', 'commonly', 'adopted', 'practices', '(the', 'number', 'of', 'iterations,', 'the', 'choice', 'of', 'model', 'layers)', 'when', 'fine-tuning', 'Transformers-based', 'langage', 'models', 'are', 'inappropriate', 'under', 'resource', 'constrained', 'conditions', 'and', 'adversely', 'affect', 'the', 'stability', 'of', 'models', 'performances', 'as', 'overfitting,', 'label', 'noise', 'memorization', 'or', 'catastrophic', 'forgetting.', 'Added', 'to', 'this,', 'because', 'the', 'pretraining', 'process', 'is', 'particularly', 'constraining,', 'various', 'works', 'have', 'been', 'oriented', 'towards', 'the', 'research', 'and', 'training', 'of', 'efficient', 'models,', 'both', 'in', 'terms', 'of', 'available', 'capacities', 'and', 'resources', 'and', 'in', 'terms', 'of', 'environmental', 'footprint.']",1,"[1, 1, 3, 3, 1, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2a29611e-2040-46a6-a452-9851be5af9aa,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['Fabulous: Fact-checking based on understanding of language over unstructured and structured information'],['2021'],['Mostafa Bouziane;Hugo Perrin;Amine Sadeq;Thanh Nguyen;Aurélien Cluzeau;Julien Mardas'],single,"['We', 'get', 'an', 'increase', 'of', '5.77%', 'on', 'the', 'FEVEROUS', 'score', 'and', '7.91%', 'on', 'the', 'accuracy', 'over', 'the', 'previous', 'best', 'model', 'FaBULOUS', '<ref type=""single"">(Bouziane et al., 2021)</ref>', 'on', 'the', 'development', 'set.', 'For', 'the', 'test', 'set,', 'the', 'increase', 'is', '6.96%', 'and', '7.14%', 'in', 'Feverous', 'score', 'and', 'label', 'accuracy,', 'respectively.', 'These', 'results', 'suggest', 'the', 'effectiveness', 'of', 'our', 'proposed', 'DCUF', 'model.', 'The', 'evidence', 'format', 'of', 'a', 'global', 'evidence', 'table', 'is', 'consistent', 'to', 'the', 'input', 'of', 'pre-trained', 'table', 'models.', 'Thus,', 'DCUF', 'can', 'make', 'better', 'use', 'of', 'the', 'internal', 'ability', 'of', 'pre-trained', 'models', 'than', 'previous', 'works', 'which', 'concatenate', 'linearized', 'tables', 'or', 'max-pool', 'lots', 'of', 'claim-table', 'pair', 'encoding', '<ref type=""single"">(Bouziane et al., 2021).</ref>', 'Moreover,', 'DCUF', 'also', 'performs', 'better', 'than', 'another', 'well-performing', 'model,', 'CARE', '<ref type=""single"">(Kotonya et al., 2021b).</ref>', 'DCUF', 'converts', 'cells', 'to', 'meaningful', 'sentences', 'that', 'are', 'similar', 'to', 'the', 'inputs', 'of', 'PLMs', 'pre-training', 'stage,', 'which', 'makes', 'better', 'use', 'of', 'the', 'PLMs', 'ability.']",97,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2a7a28a0-eb97-4ff3-b99a-4f3b8f8e9ce8,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Event detection and domain adaptation with convolutional neural networks'],['2015'],['Huu Thien;Ralph Nguyen;unk Grishman'],single,"['The', 'task', 'of', 'neural', 'event', 'detection', 'has', 'been', 'attempted', 'using', 'a', 'combination', 'of', 'networks,', 'but', 'mostly', 'revolving', 'around', 'the', 'use', 'of', 'convolutional', 'neural', 'architectures.', 'Work', 'in', 'this', 'approach', 'focused', 'on', 'various', 'aspects', 'such', 'as', 'max-pooling', 'to', 'retrieve', 'the', 'structure', 'of', 'event', 'nugget', 'information', '<ref type=""single"">(Nguyen and Grishman, 2015),</ref>', 'modeling', 'the', 'skipgram', 'architecture', 'to', 'learn', 'lexical', 'feature', 'representations', '<ref type=""single"">(Chen et al., 2015)</ref>', 'as', 'well', 'as', 'using', 'dynamic', 'CNNs', 'in', 'order', 'to', 'extract', 'lexical', 'and', 'syntactic', 'features', 'in', 'parallel', '<ref type=""single"">(Nguyen and Grishman, 2016).</ref>', 'Recurrent', 'neural', 'architectures', 'have', 'also', 'been', 'employed', 'for', 'this', 'task,', 'which', 'predict', 'the', 'location', 'of', 'the', 'trigger', 'based', 'on', 'combining', 'the', 'for-ward', 'and', 'backward', 'features', 'of', 'sentences', 'in', 'which', 'events', 'occur', '<ref type=""group"">(Nguyen et al., 2016, Ghaeini et al., 2016).</ref>', 'Note', 'that', 'in', 'both', 'cases', 'architectures', 'focused', 'on', 'dealing', 'with', 'structural,', 'lexical', 'and', 'contextual', 'features.']",43,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2ad0305e-be82-4196-85bd-91618eba21a6,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Character-level representations improve DRS-based semantic parsing even in the age of BERT'],['2020'],['Rik Van Noord;Antonio Toral;Johan Bos'],single,"['Post-processing', 'After', 'the', 'neural', 'model', 'predicts', 'a', 'fragment', 'and', 'a', 'word', 'sense', 'for', 'each', 'token,', 'we', 'assemble', 'these', 'predictions', 'into', 'a', 'complete', 'clause', 'list', 'by', 'choosing', 'unique', 'new', 'names', 'for', 'discourse', 'referents', 'with', 'index', '0', 'and', 'unifying', 'other', 'discourse', 'referents', 'with', 'them', 'according', 'to', 'their', 'relative', 'indices.', 'We', 'also', 'replace', 'DUMMY', 'strings', 'in', 'clauses', 'by', 'the', 'predicted', 'word', 'senses', 'and', 'by', 'symbols', 'for', 'names,', 'cardinalities,', 'and', 'date/time', 'expressions,', 'which', 'are', 'predicted', 'from', 'the', 'tokens', 'by', 'a', 'rule-based', 'system', 'similar', 'to', 'that', 'of', '<ref type=""single"">Evang (2019).</ref>', 'For', 'example,', 'for', 'the', 'proper', 'name', 'Tom', 'it', 'predicts', 'the', 'symbol', '""tom"",', 'for', 'the', 'numeral', 'two', 'it', 'predicts', '""2"",', 'and', 'for', 'the', 'time', 'expression', 'five', ""o'clock,"", 'it', 'predicts', '""17:00"".', 'Special', 'clauses', 'like', 'b1', '""speaker""', 'x1', 'and', 'b1', '""hearer""', 'x1', 'are', 'removed', 'and', 'the', 'corresponding', 'referent', '(x1', 'in', 'the', 'example)', 'replaced', 'by', 'the', 'symbols', '""speaker""', 'and', '""hearer"".', 'Finally,', 'we', 'use', 'a', 'set', 'of', 'postprocessing', 'rules', 'similar', 'to', 'that', 'of', '<ref type=""single"">van Noord et al. (2020)</ref>', 'to', 'ensure', 'the', 'validity', 'of', 'the', 'resulting', 'DRS:', 'if', 'there', 'is', 'a', 'loop', 'in', 'the', 'subordination', 'relation', 'among', 'boxes,', 'an', 'arbitrary', 'box', 'in', 'the', 'loop', 'is', 'chosen,', 'and', 'all', 'its', 'clauses', 'are', 'removed', 'to', 'break', 'the', 'loop', '(cf.', 'Figure', '9']",151,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
2b29e08f-e1e8-4e9c-a863-52f3156329f4,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,"[""HuggingFace's Transformers: State-of-the-art Natural Language Processing""]",['2019'],"[""Thomas Wolf;Lysandre Debut;Victor Sanh;Julien Chaumond;Clement Delangue;Anthony Moi;Pierric Cistac;Tim Rault;R'emi Louf;Morgan Funtowicz;Jamie Brew""]",single,"['We', 'use', 'pre-trained', 'BERT-large', 'uncased', '(24-layer,', '1024-hidden,', '16-heads,', '340M', 'parameters,', 'whole', 'word', 'masking)', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'for', 'our', 'mention', 'and', 'context', 'encoder.', 'All', 'BERT', 'hyperparameters', 'are', 'unchanged.', 'The', 'entity', 'embedding', 'matrix', 'contains', '10M', '(UFET', 'type', 'set)', 'or', '60M', '(Wiki', 'type', 'set)', 'parameters.', 'We', 'train', 'our', 'models', 'with', 'batch', 'size', '32', '(8', '×', '4', 'gradient', 'accumulation', 'steps)', 'using', 'one', 'NVIDIA', 'V100', 'GPU', 'for', 'a', 'week.', 'We', 'use', 'the', 'AdamW', 'optimizer', '<ref type=""group"">(Kingma and Ba, 2014, Loshchilov and Hutter, 2018)</ref>', 'with', 'learning', 'rate', '2e-5', 'for', 'BERT', 'parameters', 'and', 'learning', 'rate', '1e-3', 'for', 'the', 'type', 'embedding', 'matrix.', 'We', 'use', ""Hugging-Face's"", 'Transformers', 'library', '<ref type=""single"">(Wolf et al., 2019)</ref>', 'Table', '2:', '""Out-of-the-box""', 'accuracy', 'on', 'the', 'CAP', 'development', 'set.', 'We', 'compare', 'performance', 'of', 'BERT-base,', 'BERT-large,', 'and', 'the', 'mention', 'and', 'context', 'representation', 'of', 'the', 'embedding', 'model', 'with', 'ours,', 'using', 'just', 'cosine', 'similarity', 'and', 'no', 'classifier.']",89,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
2bce80a0-ce4f-421d-9c7a-1bc5f1eee206,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,"['unknown', 'Pixel-bert: Aligning image pixels with text by deep multi-modal transformers']","['unknown', '2020']","['unknown', 'Zhicheng Huang;Zhaoyang Zeng;Bei Liu;Dongmei Fu;Jianlong Fu']",group,"['In', 'this', 'work,', 'we', 'aim', 'to', 'design', 'an', 'E2E', 'pretraining', 'strategy', 'for', 'the', 'VLP', 'problem.', 'To', 'this', 'end,', 'we', 'adopt', 'a', 'modular', 'representation', 'network,', 'which', 'takes', 'image', 'grid', 'features', 'from', 'a', 'CNN-based', 'visual', 'network', 'and', 'the', 'corresponding', 'text', 'embeddings', 'into', 'a', 'multi-modal', 'Transformer', '<ref type=""group"">(Huang et al., 2020 (Huang et al., , 2021)).</ref>', 'Our', 'goal', 'is', 'to', 'learn', 'the', 'visual', 'network', 'and', 'the', 'Transformer', 'jointly,', 'and', 'yet', 'to', 'effectively', 'encode', 'object-level', 'visual', 'concepts', 'in', 'the', 'multimodal', 'representations.', 'This', 'enables', 'us', 'to', 'capture', 'rich', 'cross-modal', 'alignment', 'between', 'linguistic', 'entities', 'and', 'visual', 'semantic', 'concepts', 'for', 'the', 'downstream', 'tasks,', 'and', 'meanwhile', 'to', 'enjoy', 'the', 'benefits', 'of', 'an', 'efficient', 'E2E', 'network', 'design', 'without', 'relying', 'on', 'detectors', 'during', 'fine-tuning', 'and', 'inference.']",43,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2bd7d37b-6aef-4821-8996-02294cd1f425,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['Can spanish be simpler? lexsis: Lexical simplification for spanish'],['2012'],['Stefan Bott;Luz Rello'],single,"['Lexical', 'complexity', 'is', 'one', 'of', 'the', 'main', 'reasons', 'leading', 'to', 'overall', 'text', 'complexity', 'and', 'thus', 'result', 'in', 'poor', 'reading', 'comprehension', 'for', 'readers', '<ref type=""single"">(DuBay, 2004).</ref>', 'Different', 'from', 'the', 'Complex', 'Word', 'Identification', '(CWI)', '<ref type=""single"">(Shardlow, 2014)</ref>', 'task,', 'which', 'aims', 'to', 'predict', 'whether', 'a', 'given', 'word', 'is', 'complex', 'or', 'not,', 'the', 'goal', 'of', 'lexical', 'complexity', 'prediction', '(LCP)', 'is', 'to', 'predict', 'the', 'complexity', 'value', 'of', 'the', 'given', 'parts', 'from', 'contexts', 'as', 'shown', 'in', 'Figure', '1.', 'The', 'underlined', 'parts', 'of', 'the', 'sentence', 'are', 'the', 'words', 'that', 'need', 'to', 'be', 'predicted', 'and', 'the', 'same', 'words', 'in', 'different', 'contexts', 'may', 'have', 'different', 'complexity', 'scores.', 'LCP', 'plays', 'an', 'important', 'role', 'in', 'the', 'usual', 'Lexical', 'Simplification', '(LS)', '<ref type=""single"">(Bott et al., 2012)</ref>', 'pipeline', 'since', 'it', 'can', 'help', 'simplifiers', 'find', 'the', 'challenging', 'words', 'and', 'replace', 'them', 'with', 'appropriate', 'alternatives', 'that', 'easy', 'to', 'understand.', 'Either', 'LCP', 'or', 'CWI', 'can', 'not', 'only', 'be', 'used', 'as', 'a', 'component', 'of', 'LS', 'systems', 'but', 'also', 'as', 'a', 'stand-alone', 'application', 'within', 'intelligent', 'tutoring', 'systems', 'for', 'second', 'language', 'learners', 'or', 'in', 'reading', 'devices', 'for', 'people', 'with', 'low', 'literacy', 'skills', '<ref type=""single"">(Gooding and Kochmar, 2018).</ref>']",105,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
2bd8caf1-dd8a-4b9e-9a50-8ef1ab909059,A User-Based Usability Assessment of Raw Machine Translated Technical Instructions,2012,Stephen Doherty;Sharon O'brien,"['Can MT output be evaluated through eye tracking? MT Summit XII: Proceedings of the Twelfth Machine Translation Summit', 'Eye tracking as an MT evaluation technique']","['2009', '2010']","[""S Doherty;S O'brien"", ""S Doherty;S O'brien;M Carl""]",group,"['This', 'paper', 'reports', 'on', 'a', 'project', 'whose', 'aims', 'are', 'to', 'investigate', 'the', 'usability', 'of', 'raw', 'machine', 'translated', 'technical', 'support', 'documentation', 'for', 'a', 'commercial', 'online', 'service.', 'It', 'builds', 'on', 'previous', 'work', 'which', 'investigates', 'the', 'use', 'of', 'eye', 'tracking', 'as', 'a', 'machine', 'translation', 'evaluation', 'mechanism', '<ref type=""group"">(Doherty and O\'Brien, 2009, Doherty et al., 2010,</ref>', 'which', 'focused', 'on', 'the', 'readability', 'and', 'comprehension', 'of', 'machine-translated', 'technical', 'support', 'documentation', '<ref type=""single"">(Doherty, 2012),</ref>', 'and', 'on', 'the', 'impact', 'of', 'controlled', 'authoring', 'on', 'the', 'readability', 'of', 'MT', 'output', '<ref type=""single"">(O\'Brien, 2010).</ref>']",43,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
2c07bdb5-1e42-4a09-a0b1-f43429b10bf5,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['A survey of knowledge-enhanced text generation'],['2022'],['Wenhao Yu;Chenguang Zhu;Zaitang Li;Zhiting Hu;Qingyun Wang;Ji Heng;Meng Jiang'],single,"['Besides,', 'leveraging', 'knowledge', 'graph', 'is', 'not', 'the', 'only', 'way', 'to', 'promote', 'content', 'diversity', 'as', 'it', 'is', 'a', 'highly', 'knowledge-intensive', 'task.', 'Many', 'existing', 'knowledge-enhanced', 'methods', '<ref type=""single"">(Yu et al., 2022c)</ref>', 'can', 'be', 'used', 'to', 'acquire', 'different', 'external', 'knowledge', 'for', 'producing', 'diverse', 'outputs,', 'e.g.,', 'taking', 'different', 'retrieved', 'documents', 'as', 'conditions', 'for', 'generator.']",24,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
2c19138d-a200-48bb-8511-f539581a3bf0,Comparison of post-editing productivity between professional translators and lay users,2014,Nora Aranberri;Gorka Labaka,['Minimum Error Rate Training in Statistical Machine Translation'],['2003'],['F Och'],single,"['The', 'post-editing', 'environment', 'used', 'in', 'the', 'experiment', 'was', 'the', 'Bologna', 'Translation', 'Service', '(BTS),', 'the', 'product', 'of', 'an', 'EU-funded', 'ICT', 'PSP', '4', 'th', 'Call,', 'Theme', '6:', 'Multilingual', 'Web', 'project', '(ID', '270915).', '1', 'It', 'is', 'an', 'end-to-end', 'web-based', 'translation', 'management', 'tool', 'in', 'which', 'users', 'with', 'different', 'roles', '(manager,', 'requester,', 'reviewer,', 'etc.)', 'participate', 'on-line', 'at', 'different', 'stages', 'of', 'the', 'translation', 'workflow.', 'It', 'couples', 'translation', 'memory', '(TM)', 'and', 'machine', 'translation', '(MT)', 'capabilities', 'within', 'a', 'simple', 'work', 'environment.', 'BTS', 'was', 'designed', 'with', 'lay', 'users', 'in', 'mind.', 'The', 'work', 'environment', 'offers', 'a', 'simple', 'layout', 'with', 'a', 'top', 'bar', 'with', 'the', 'main', 'action', 'buttons', 'and', 'job', 'information', '(see', 'Figure', '1).', 'Below,', 'the', 'source', 'text', 'is', 'split', 'into', 'segments', 'and', 'the', 'target', 'side', 'is', 'filled', 'with', 'either', 'TM', '(fuzzy-)matches', 'or', 'MT', 'candidates', 'for', 'the', 'reviewer', 'to', 'work', 'on.', 'It', 'is', 'a', 'plain', 'tool', 'as', 'opposed', 'to', 'more', 'sophisticated', 'software', 'developed', 'in', 'the', 'CASCAMAT', '2', 'and', 'Ma-teCat', '3', 'projects', '<ref type=""group"">(Alabau et al. 2013, Federico et al., 2012),</ref>', 'which', 'include', 'interactive', 'translation', 'prediction', 'and', 'track', 'post-editing', 'operations.', 'For', 'the', 'current', 'experiment,', 'the', 'BTS', 'platform', 'was', 'enhanced', 'with', 'an', 'English', 'to', 'Basque', 'MT', 'system.', 'A', 'standard', 'phrase-based', 'statistical', 'machine', 'translation', 'system', 'was', 'built', 'based', 'on', 'Moses', 'using', 'a', 'parallel', 'corpus', 'of', '14.58', 'million', 'English', 'tokens', 'and', '12.50', 'million', 'Basque', 'tokens', '(1.3', 'million', 'parallel', 'sentences)', 'which', 'includes', 'localization', 'texts', '(graphic', 'user', 'interface', 'strings', 'and', 'user', 'documention),', 'academic', 'books', 'and', 'web', 'entertainment', 'data.', 'To', 'address', 'the', 'token', 'mismatch', 'between', 'English', '(analytic', 'language)', 'and', 'Basque', '(agglutinative', 'language)', 'tokens,', 'the', 'aligner', 'was', 'fed', 'with', 'segmented', 'words', 'for', 'the', 'agglutinative', 'language.', 'Several', 'segmentation', 'options', 'exist:', 'we', 'can', 'isolate', 'each', 'morpheme,', 'or', 'break', 'each', 'word', 'into', 'lemma', 'and', 'a', 'bag', 'of', 'suffixes,', 'we', 'can', 'establish', 'hand-written', 'rules', 'for', 'segmentation,', 'or', 'let', 'an', 'automatic', 'tool', 'define', 'and', 'process', 'the', 'words', 'unsupervised.', 'Based', 'on', 'the', 'results', 'from', 'Labaka', '(2010),', 'we', 'opted', 'for', 'the', 'second', 'option', 'and', 'joined', 'together', 'all', 'the', 'suffixes', 'attached', 'to', 'a', 'particular', 'lemma', 'in', 'one', 'separate', 'token.', 'Thus,', 'on', 'splitting', 'a', 'word,', 'we', 'generated,', 'at', 'most,', 'three', 'tokens', '(prefixes,', 'lemma', 'and', 'suffixes).', 'Moses', 'was', 'trained', 'and', 'optimized', 'on', 'segmented', 'text.', 'Note', 'that', 'when', 'using', 'segmented', 'text', 'for', 'training,', 'the', 'output', 'of', 'the', 'system', 'is', 'also', 'segmented', 'text.', 'Real', 'words', 'are', 'not', 'available', 'to', 'the', 'statistical', 'decoder.', 'This', 'means', 'that', 'a', 'generation', 'postprocess', '(unsegmentation', 'step)', 'is', 'needed', 'to', 'obtain', 'real', 'word', 'forms.', 'We', 'incorporated', 'a', 'second', 'language', 'model', '(LM)', 'based', 'on', 'real', 'word', 'forms', 'to', 'be', 'used', 'after', 'the', 'morphological', 'postprocess.', 'We', 'implemented', 'the', 'word', 'form-based', 'LM', 'by', 'using', 'an', 'n-best', 'list,', 'as', 'was', 'done', 'in', '<ref type=""single"">Oflazer and El-Kahlout (2007).</ref>', 'We', 'first', 'asked', 'Moses', 'to', 'generate', 'a', 'translation', 'candidate', 'ranking', 'based', 'on', 'the', 'segmented', 'training', 'explained', 'above.', 'Next,', 'these', 'candidates', 'were', 'postprocessed.', 'We', 'then', 'recalculated', 'the', 'total', 'cost', 'of', 'each', 'candidate', 'by', 'including', 'the', 'cost', 'assigned', 'by', 'the', 'new', 'word', 'form-based', 'LM', 'in', 'the', 'models', 'used', 'during', 'decoding.', 'Finally,', 'the', 'candidate', 'list', 'was', 're-ranked', 'according', 'to', 'this', 'new', 'total', 'cost.', 'This', 'somehow', 'revises', 'the', 'candidate', 'list', 'to', 'promote', 'the', 'ones', 'that', 'are', 'more', 'likely', 'to', 'be', 'real', 'word-form', 'sequences.', 'The', 'weight', 'for', 'the', 'word', 'formbased', 'LM', 'was', 'optimized', 'at', 'Minimum', 'Error', 'Rate', 'Training', '<ref type=""single"">(Och, 2003)</ref>', 'together', 'with', 'the', 'weights', 'for', 'the', 'rest', 'of', 'the', 'models.']",506,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
2c3e1a1f-3abf-47a5-8c27-751cba524f67,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['Enriching lexical transfer with cross-linguistic semantic features'],['1997'],['Alexis Nasr;Owen Rambow;Martha Palmer;Joseph Rosenzweig'],single,"['The', 'new', 'lexico-structural', 'transfer', 'approach', 'is', 'more', 'similar', 'to', 'the', 'interlingua', 'approach', 'in', 'that', 'they', 'both', 'have', 'a', 'predicate-argument', 'structure', 'representation', 'of', 'the', 'meaning', 'of', 'the', 'sentence,', 'which', 'gives', 'them', 'roughly', 'equivalent', 'semantic', 'depth.', 'Another', 'similarity', 'is', 'that', 'the', 'new', 'transfer', 'approach', 'can', 'also', 'combine', 'lexical', 'items', 'from', 'several', 'languages', 'together', 'into', 'a', 'single', 'transfer', 'lexicon', 'entry,', 'greatly', 'simplifying', 'the', 'task', 'of', 'adding', 'the', 'mapping', 'to', 'a', 'new', 'language', '<ref type=""single"">[10].</ref>', 'An', 'important', 'remaining', 'difference', 'is', 'that', 'the', 'interlingua', 'approach', 'would', 'claim', 'that', 'a', 'single', 'predicate-argument', 'structure', 'can', 'serve', 'as', 'a', 'common', 'representation', 'for', 'many', 'languages,', 'whereas', 'the', 'transfer', 'approach', 'allows', 'for', 'language-specific', 'predicate-argument', 'structures..', 'A', 'fundamental', 'assumption', 'of', 'either', 'approach,', 'and', 'the', 'most', 'important', 'similarity,', 'is', 'that', 'these', 'classifications', 'can', 'be', 'made', 'based', 'on', 'distinguished', 'semantic', 'features,', 'and', 'that', 'these', 'semantic', 'features', 'will', 'be', 'relevant', 'to', 'classification', 'schemes', 'in', 'other', 'languages.', 'Whether', 'the', 'classification', 'schemes', 'serve', 'as', 'a', 'means', 'of', 'associating', 'a', 'single', 'logical', 'form', 'composed', 'of', 'semantic', 'primitives', 'with', 'many', 'lexical', 'items,', 'as', 'in', 'the', 'LCS', 'approach,', 'or', 'as', 'a', 'means', 'of', 'enriching', 'a', 'set', 'of', 'logical', 'forms', 'with', 'a', 'collection', 'of', 'semantic', 'features,', 'the', 'classifications', 'still', 'have', 'to', 'be', 'determined,', 'and', 'the', 'associations', 'with', 'semantic', 'features', 'have', 'to', 'be', 'made.', 'The', 'rest', 'of', 'this', 'paper', 'discusses', 'specific', 'issues', 'with', 'respect', 'to', 'the', 'association', 'of', 'semantic', 'features', 'with', 'the', 'classifications', 'in', 'English', 'verbs.']",69,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2c41be4b-0d14-4315-a327-47045c4f5ed7,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Learning transferable visual models from natural language supervision'],['2021'],['Alec Radford;Jong Kim;Chris Hallacy;Aditya Ramesh;Gabriel Goh;Sandhini Agarwal;Girish Sastry;Amanda Askell;Pamela Mishkin;Jack Clark'],single,"['The', 'work', 'of', '<ref type=""single"">Bornea et al. (2020)</ref>', 'showed', 'that', 'large', 'pre-trained', 'multilingual', 'models', 'are', 'not', 'enough', 'for', 'question-answering', 'in', 'underrepresented', 'languages', 'and', 'presented', 'several', 'novel', 'strategies', 'to', 'improve', 'the', 'performance', 'of', 'mBERT', 'with', 'translations.', 'This', 'work', 'achieved', 'languageindependent', 'embeddings,', 'which', 'improved', 'the', 'cross-lingual', 'transfer', 'performance', 'with', 'additional', 'pre-training', 'on', 'adversarial', 'tasks.', 'It', 'also', 'introduced', 'a', 'Language', 'Arbitration', 'Framework', '(LAF),', 'which', 'consolidated', 'the', 'embedding', 'representations', 'across', 'languages', 'using', 'properties', 'of', 'translation.', 'Crosslingual', 'manifold', 'mixup', '(X-Mixup)', '<ref type=""single"">(Yang et al., 2021)</ref>', 'achieved', 'better', 'cross-lingual', 'transfer', 'by', 'calibrating', 'the', 'representation', 'discrepancy,', 'which', 'resulted', 'in', 'a', 'compromised', 'representation', 'for', 'target', 'languages.', 'It', 'was', 'shown', 'that', 'the', 'multilingual', 'pretraining', 'process', 'can', 'be', 'improved', 'by', 'implementing', 'X-Mixup', 'on', 'parallel', 'data.', 'Contrastive', 'Language-Image', 'pre-training', '(CLIP)', '<ref type=""single"">(Radford et al., 2021)</ref>', 'introduced', 'an', 'efficient', 'way', 'to', 'learn', 'scalable', 'image', 'representations', 'with', 'natural', 'language', 'supervision.', 'Drawing', 'inspiration', 'from', 'ConVIRT', '<ref type=""single"">(Zhang et al., 2020),</ref>', 'CLIP', 'used', 'a', 'contrastive', 'objective', 'that', 'maximizes', 'the', 'cosine', 'similarity', 'of', 'the', 'correct', 'pairs', 'of', 'images', 'and', 'text,', 'while', 'minimizing', 'the', 'same', 'for', 'incorrect', 'pairs.', 'Building', 'upon', 'the', 'work', 'of', '<ref type=""single"">(Bornea et al., 2020),</ref>', 'we', 'show', 'that', 'translations', 'of', 'a', 'small-scale', 'dataset', 'into', 'cross-family', 'languages', 'could', 'degrade', 'the', 'QA', 'performance.', 'To', 'overcome', 'this', 'problem,', 'we', 'propose', 'multilingual', 'contrastive', 'training', 'to', 'encourage', 'cross-lingual', 'invariance.', 'Our', 'approach', 'is', 'relatively', 'simpler', 'compared', 'to', 'adversarial', 'training', 'and', 'LAF', 'used', 'in', '<ref type=""single"">Bornea et al. (2020).</ref>', 'Though', 'the', 'proposed', 'contrastive', 'loss', 'has', 'a', 'similar', 'objective', 'to', 'the', 'pretraining', 'loss', 'in', '<ref type=""single"">(Guo et al., 2018),</ref>', 'there', 'are', 'subtle', 'differences', 'because', 'we', 'use', 'it', 'in', 'multi-task', 'learning', 'setup', 'along', 'with', 'the', 'original', 'task', 'loss', 'for', 'finetuning.']",111,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2c486aba-d2d2-4ca3-94df-362382d80fc8,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,"['Obsolescencia lingüística, descripción gramatical y documentación de lenguas en el perú: hacia un estado de la cuestión']",['2019'],['Roberto Zariquiey;Harald Hammarström;Mónica Arakaki;Arturo Oncevay;John Miller'],single,"['Peru', 'offers', 'a', 'rich', 'diversity', 'context', 'for', 'machine', 'translation', 'research', 'with', '47', 'native', 'languages', '<ref type=""single"">(Simons and Fenning, 2019).</ref>', 'All', 'of', 'them', 'are', 'highly', 'distinguishing', 'from', 'Castilian', 'Spanish,', 'the', 'primary', '1', 'Available', 'in:', 'https://github.com/aoncevay/mt-peru', 'official', 'language', 'in', 'the', 'country', 'and', 'the', 'one', 'spoken', 'by', 'the', 'majority', 'of', 'the', 'population.', 'However,', 'from', 'the', 'computational', 'perspective,', 'all', 'of', 'these', 'languages', 'do', 'not', 'have', 'enough', 'resources,', 'such', 'as', 'monolingual', 'or', 'parallel', 'texts,', 'and', 'most', 'of', 'them', 'are', 'considered', 'endangered', '<ref type=""single"">(Zariquiey et al., 2019).</ref>']",72,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1]"
2c8b4633-0992-4b6f-acd1-ea557f40e934,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Reusable Dictionaries for NLP: The Word Manager Approach'],['1996'],['unk Ten Hacken;& Pius;Marc Domenig'],single,"['The', 'originality', 'of', 'WM', 'lies', 'in', 'its', 'approach', 'to', 'reusability.', 'Ten', '<ref type=""single"">Hacken &amp, Domenig (1996)</ref>', 'present', 'this', 'approach', 'in', 'terms', 'of', 'the', 'diagram', 'in', 'Fig.', '1.']",11,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
2c970549-0f45-4e89-9c6e-5cc92bda999d,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,"['Babelnet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network']",['2012'],['Roberto Navigli;Simone Ponzetto'],single,"['Word', 'Sense', 'Disambiguation', '(WSD)-based', 'approaches', 'were', 'widely', 'used', 'by', 'previous', 'research', 'to', 'tackle', 'this', 'problem', '<ref type=""group"">(Loureiro and Jorge, 2019, Scarlini et al., 2020).</ref>', 'WSD', 'associates', 'the', 'word', 'in', 'a', 'text', 'with', 'its', 'correct', 'meaning', 'from', 'a', 'predefined', 'sense', 'inventory', '<ref type=""single"">(Navigli, 2009).</ref>', 'As', 'such', 'inventories,', 'WordNet', '<ref type=""single"">(Miller, 1995)</ref>', 'and', 'Babel-Net', '<ref type=""single"">(Navigli and Ponzetto, 2012)</ref>', 'were', 'commonly', 'used.', 'However,', 'these', 'approaches', 'fail', 'to', 'generalise', 'into', 'different', 'languages', 'as', 'these', 'inventories', 'are', 'often', 'limited', 'to', 'high', 'resource', 'languages.', 'Targeting', 'this', 'gap,', 'SemEval-2021', 'Task', '2:', 'Multilingual', 'and', 'Cross-lingual', 'Word-in-Context', 'Disambiguation', 'is', 'designed', 'to', 'capture', 'the', 'word', 'sense', 'without', 'relying', 'on', 'fixed', 'sense', 'inventories', 'in', 'both', 'monolingual', 'and', 'cross-lingual', 'setting.', 'In', 'summary,', 'this', 'task', 'is', 'designed', 'as', 'a', 'binary', 'classification', 'problem', 'which', 'predicts', 'whether', 'the', 'target', 'word', 'has', 'the', 'same', 'meaning', 'or', 'different', 'meaning', 'in', 'different', 'contexts', 'of', 'the', 'same', 'language', '(monolingual', 'setting)', 'or', 'different', 'languages', '(cross-lingual', 'setting).']",40,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2cc6cf73-1941-4dd2-abaf-4addf7c29cc4,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Simulated multiple reference training improves low-resource machine translation'],['2020'],['Huda Khayrallah;Brian Thompson;Matt Post;Philipp Koehn'],single,"['Eq.', '6', 'implies', 'that', 'the', 'abstractive', 'model', 'g', 'should', 'be', 'able', 'to', 'assign', 'higher', 'estimated', 'probability', 'to', 'the', 'better', 'candidate', 'summary', 'during', 'inference.', 'However,', 'this', 'intuition', 'is', 'not', 'directly', 'captured', 'in', 'the', 'standard', 'MLE', 'objective', 'used', 'in', 'training', '-a', 'model', 'obtaining', 'zero', 'MLE', 'loss', 'would', 'assign', 'zero', 'probability', 'to', 'any', 'candidate', 'summary', 'different', 'from', 'the', 'reference.', 'This', 'is', 'obviously', 'improper', 'for', 'any', 'task', 'where', 'multiple', 'reasonable', 'generations', 'may', 'exist', '<ref type=""single"">(Khayrallah et al., 2020),</ref>', 'and', 'also', 'does', 'not', 'say', 'anything', 'about', 'the', 'ordering', 'of', 'two', 'imperfect', 'references.', 'We', 'therefore', 'advocate', 'for', 'making', 'the', 'alternative', 'assumption', 'that', 'the', 'probability', 'of', 'one', 'candidate', 'should', 'be', 'well-correlated', 'with', 'its', 'quality', 'as', 'evaluated', 'by', 'an', 'automatic', 'metric', 'M.', 'Since', 'it', 'is', 'intractable', 'to', 'enumerate', 'all', 'the', 'possible', 'candidate', 'outputs,', 'we', 'only', 'require', 'our', 'model', 'to', 'be', 'able', 'to', 'accurately', 'predict', 'the', 'ranking', 'order', 'of', 'a', 'set', 'of', 'the', 'most', 'probable', 'candidate', 'summaries', 'Ŝ,', 'which', 'are', 'its', 'own', 'beam', 'search', 'results.', 'In', 'order', 'to', 'achieve', 'this', 'objective,', 'we', 'slightly', 'modify', 'the', 'conditions', 'of', 'Eq.', '5,', 'maintaining', 'the', 'general', 'functional', 'form,', 'but', 'instead', 'specifying', 'the', 'marginal', 'probability', 'of', 'the', 'non-reference', 'candidates', 'S', 'to', 'be', 'β,', 'and', 'encouraging', 'coordination', 'of', 'probabilities', 'and', 'qualities', 'among', 'non-reference', 'candidates', 'as', 'follows:']",69,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2ce468d7-7610-4425-964c-6d2995e87250,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,"['unknown', 'Graph-based semi-supervised learning']","['2007', '2014']","['Steven Abney', 'Amarnag Subramanya;Partha Talukdar']",group,"['In', 'this', 'paper,', 'we', 'developed', 'a', 'semi-supervised', 'strategy', 'to', 'detect', 'toxic', 'comments', 'in', 'the', 'Brazilian', 'Portuguese', 'language.', 'Semi-supervision', 'is', 'the', 'problem', 'of', 'learning', 'from', 'labeled', 'and', 'unlabeled', 'data', '<ref type=""group"">(Abney, 2007, Subramanya and Talukdar, 2014),</ref>', 'in', 'which', 'given', 'a', 'point', 'set', 'X', '=', '{x', '1,', '...,', 'x', 'l,', 'x', 'l+1,', '...,', 'x', 'n}', 'and', 'a', 'label', 'set', 'L', '=', '{1,', '...,', 'c},', 'the', 'first', 'l', 'points', 'have', 'labels', '{y', '1,', '...,', 'y', 'l}', '∈', 'L', 'and', 'the', 'remaining', 'points', 'are', 'unlabeled', '<ref type=""single"">(Zhou et al., 2004).</ref>']",28,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3]"
2d654ce0-5b9f-45bd-86e6-04629c556dec,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,['Discriminative training and maximum entropy models for statistical machine translation'],['2002'],['unknown'],single,"['The', 'feature', 'functions', 'h', 'i', 'are', 'the', 'system', 'models', 'and', 'the', 'λ', 'i', 'weights', 'are', 'typically', 'optimized', 'to', 'maximize', 'a', 'scoring', 'function', 'on', 'a', 'development', 'set', '<ref type=""single"">[6].</ref>', 'In', 'our', 'system', 'fourteen', 'features', 'functions', 'were', 'used,', 'namely', 'phrase', 'and', 'lexical', 'translation', 'probabilities', 'in', 'both', 'directions,', 'seven', 'features', 'for', 'the', 'lexicalized', 'distortion', 'model,', 'a', 'word', 'and', 'a', 'phrase', 'penalty', 'and', 'a', 'target', 'language', 'model', '(LM).']",26,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2d6bcd78-598e-40ce-9ce1-be0921b6c0fe,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,['Building a semantic lexicon: structuring and generating concepts'],['1999'],['F Busa;N Calzolari;A Lenci;J Pustejovsky'],single,"['In', 'the', 'specification', 'phase', 'of', 'the', 'project', 'the', 'formal', 'representation', 'of', 'the', '""conceptual', 'core""', 'of', 'the', 'lexicons', 'was', 'designed,', 'and', 'the', 'basic', 'structured', 'set', 'of', '""meaning-types""', '-i.e.', 'the', 'core', 'ontology', '-to', 'be', 'used', 'as', 'a', 'common', 'starting', 'point', 'and', 'a', 'shared', 'device', 'to', 'build', 'the', 'harmonised', 'language', 'specific', 'semantic', 'lexicons', 'was', 'defined', '(see', '<ref type=""single"">Busa et al. 1999).</ref>', 'Such', 'a', 'task', 'has', 'tackled', 'questions', 'that', 'are', 'at', 'the', 'core', 'of', 'lexical', 'semantics', 'research.', 'The', 'development', 'of', 'twelve', 'harmonised', 'semantic', 'lexicons', 'requires', 'strong', 'mechanisms', 'for', 'guaranteeing', 'uniformity', 'and', 'consistency', 'of', 'the', 'representations.', 'These', 'mechanisms,', 'in', 'turn,', 'guarantee', 'that', 'within', 'the', 'same', 'language', 'consistent', 'formal', 'devices', 'apply', 'cross-domain', 'and', 'cross-categorially.', 'Finally,', 'the', 'multilingual', 'component', 'translates', 'into', 'the', 'requirement', 'of', 'identifying', 'elements', 'of', 'the', 'semantic', 'vocabulary', 'for', 'structuring', 'word', 'meaning', 'which', 'are', 'at', 'the', 'same', 'time', 'independent', 'from', 'any', 'individual', 'language', 'but', 'able', 'to', 'capture', 'linguistically', 'useful', 'generalisations', 'for', 'different', 'NLP', 'tasks.']",53,"[0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2dab37b8-1a52-4114-a467-86ceb48c6d61,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Layers of interpretation: On grammar and compositionality'],['2015'],['Emily Bender;Dan Flickinger;Stephan Oepen;Woodley Packard;Ann Copestake'],single,"['Compositionality', 'and', 'Its', 'Benefits', 'Is', 'our', 'semantic', 'parser', 'compositional?', '<ref type=""single"">Bender et al. (2015)</ref>', 'provide', 'a', 'definition', 'of', 'compositionality', 'in', 'meaning', 'systems,', 'which', 'we', 'summarize', 'as', 'follows:', '(1)', 'there', 'is', 'a', 'finite', 'set', 'of', 'atomic', 'word-meaning', 'pairings,', '(2)', 'there', 'is', 'a', 'finite', 'number', 'of', 'rules', 'combining', 'constituent-meaning', 'pairings', 'into', 'larger', 'constituent-meaning', 'pairings,', 'and', 'any', 'non-atomic', 'constituent-meaning', 'pairing', 'is', 'a', 'function', 'of', 'the', 'constituent-meaning', 'pairings', 'from', 'which', 'it', 'is', 'created', 'and', 'of', 'the', 'rule', 'that', 'creates', 'it,', '(3)', 'meaning', 'representations', 'are', 'not', 'changed', 'destructively.', 'They', 'argue', 'that', 'compositional', 'aspects', 'of', 'meaning', 'such', 'as', 'predicate-argument', 'structure', 'should', 'be', 'processed', 'by', 'compositional', 'systems,', 'whereas', 'noncompositional', 'aspects', 'such', 'as', 'anaphora', 'or', 'word', 'senses', 'should', 'be', 'handled', 'by', 'different', 'mechanisms.']",9,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
2daf23fa-88d4-41bf-88b5-fcfb500b54db,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,['Universal Dependencies v2: An evergrowing multilingual treebank collection'],['2020'],['Joakim Nivre;Marie-Catherine De Marneffe;Filip Ginter;Jan Hajič;Christopher Manning;Sampo Pyysalo;Sebastian Schuster;Francis Tyers;Daniel Zeman'],single,"['Data', 'I', 'use', 'Universal', 'Dependencies', '(UD)', '2.8', '2', '<ref type=""single"">(Nivre et al., 2020)</ref>', 'and', 'the', 'automatically-parsed', 'Wikipedia', 'datasets', 'released', 'as', 'part', 'of', 'the', 'CoNLL', '2017', 'Shared', 'Task', '<ref type=""single"">(Zeman et al., 2017)</ref>', 'as', 'a', 'source', 'of', 'attributive', 'adjective-noun', 'pairs.', 'I', 'extract', 'all', 'pairs', 'of', 'words', 'linked', 'by', 'a', 'dependency', 'of', 'type', 'amod', 'where', 'the', 'head', 'has', 'universal', 'part-of-speech', '(UPOS)', 'NOUN', 'and', 'the', 'dependent', 'has', 'UPOS', 'ADJ.', 'I', 'represent', 'the', 'pair', 'using', 'the', 'downcased', 'wordforms', 'of', 'the', 'adjective', 'and', 'noun.']",8,"[0, 2, 2, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2e9ca574-0f76-4315-8c1d-fae6e354893e,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['A just and comprehensive strategy for using NLP to address online abuse'],['2019'],['David Jurgens;Libby Hemphill;Eshwar Chandrasekharan'],single,"['Explainability', 'is', 'an', 'important', 'concept', 'within', 'abusive', 'language', 'detection.', '<ref type=""single"">Jurgens et al. (2019)</ref>', 'noted', 'in', 'their', 'work', 'that', 'explainable', 'ML', 'techniques', 'can', 'promote', 'restorative', 'and', 'procedural', 'justice', 'by', 'surfacing', 'the', 'norms', 'that', 'have', 'been', 'violated', 'and', 'clarifying', 'how', 'they', 'have', 'been', 'violated.', 'That', 'said,', 'there', 'has', 'been', 'limited', 'discussion', 'of', 'the', 'issue', 'within', 'the', 'domain', 'of', 'abusive', 'language', 'detection.', 'In', 'this', 'section,', 'we', 'first', 'formalize', 'the', 'properties', 'that', 'an', 'explainable', 'detection', 'method', 'should', 'aim', 'to', 'exhibit', 'in', 'order', 'to', 'thoroughly', 'substantiate', 'its', 'decisions.', 'We', 'then', 'describe', 'how', 'user', 'and', 'community', 'information', 'play', 'an', 'important', 'role', 'in', 'the', 'realization', 'of', 'each', 'of', 'the', 'properties.', 'Finally,', 'we', 'discuss', 'what', 'it', 'means', 'to', 'operationalize', 'explainability', 'within', 'abusive', 'language', 'detection', 'in', 'an', 'effective', 'manner.']",9,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2ed89cb6-f9ee-44d4-b04a-d3d6f9111080,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Deep Contextualized Word Representations'],['2018'],['Matthew Peters;Mark Neumann;Mohit Iyyer;Matt Gardner;Christopher Clark;Kenton Lee;Luke Zettlemoyer'],single,"['Another', 'line', 'of', 'past', 'work', 'tests', 'if', 'type', 'information', 'or', 'other', 'knowledge', 'is', 'captured', 'by', 'pre-trained', 'LMs.', '<ref type=""single"">Peters et al. (2018)</ref>', 'report', 'that', 'ELMo', 'performs', 'well', 'on', 'word', 'sense', 'disambiguation', 'and', 'POS', 'tagging.', 'Some', 'other', 'work', 'also', 'investigates', ""models'"", 'ability', 'to', 'induce', 'syntactic', 'information', 'by', 'measuring', 'accuracy', 'of', 'a', 'probe', '<ref type=""group"">(Zhang and Bowman, 2018, Hewitt and Manning, 2019, Hewitt and Liang, 2019).</ref>', 'However,', 'there', 'is', 'significant', 'uncertainty', 'about', 'how', 'to', 'calibrate', 'such', 'probing', 'results', '<ref type=""single"">(Voita and Titov, 2020),</ref>', 'our', ""model's"", 'representations', 'are', 'more', 'directly', 'interpretable', 'and', ""don't"", 'require', 'posthoc', 'probing.']",17,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
2f0ac087-9978-4157-87d9-1bd6d35e6cb6,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['Very deep self-attention networks for end-to-end speech recognition'],['2019'],['N.-Q Pham;T.-S Nguyen;J Niehues;M Müller;A Waibel'],single,"['We', 'built', 'a', 'Transformer-based', 'ASR', 'system', 'using', 'the', 'ESPnet', 'toolkit', '<ref type=""single"">(Watanabe et al., 2018).</ref>', 'The', 'Transformer', 'architecture', 'and', 'hyper-parameters', 'for', 'training/decoding', 'are', 'based', 'on', 'existing', 'recipes', 'in', 'ESPnet.', 'We', 'investigated', 'three', 'models:', 'selfattention-based', 'CTC', '<ref type=""single"">(Pham et al., 2019),</ref>', 'the', 'Transformer', '<ref type=""single"">(Dong et al., 2018),</ref>', 'and', 'a', 'hybrid', 'Transformer', 'trained', 'with', 'an', 'auxiliary', 'CTC', 'objective', '(Transformer+CTC)', '<ref type=""single"">(Karita et al., 2019).</ref>', 'The', 'CTC', 'model', 'was', 'used', 'in', 'prior', 'studies', 'based', 'on', 'O2O', 'models,', 'e.g.,', '<ref type=""group"">(Audhkhasi et al., 2018, Yadav et al., 2020).</ref>', 'During', 'training,', 'the', 'CTC', 'model', 'was', 'regularized', 'with', 'the', 'Transformer', 'decoder', 'in', 'the', 'multitask', 'learning', 'fashion', 'similar', 'to', 'Transformer+CTC.', 'Such', 'regularization', 'techniques', 'yield', 'a', 'significant', 'improvement', 'over', 'a', 'pure', 'CTC', 'baseline', '<ref type=""single"">(Fujita et al., 2020b).</ref>']",31,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
2f18ce3d-4522-401a-911d-daf9d52e09d1,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['A Framework of a Mechanical Trans lation between Japanese and English by Analogy Principle'],['1968'],"['C Moldovan ; Lin;D Moldovan;"" Snap: Simulator Results ; Moldovan;D Lee;W Lin;C Nagao;M Pollard;C Sag;I Quillian;M Riesbeck;C Martin;C Riesbeck;C Schank;R Sato;S Nagao;M unk']",single,"['The', 'memory-based', 'approach', 'is', 'expected', 'to', 'offer', 'solutions', 'to', 'these', 'problems', 'by', 'allowing', 'large', 'numbers', 'of', 'cases', 'to', 'be', 'stored', 'in', 'the', 'memory,', 'and', 'make', 'translation', 'by', 'using', 'these', 'cases.', 'The', 'memory-based', 'translation', 'essentially', 'convert', 'lime-complexity', 'of', 'rule', 'application', 'into', 'space-complexity', 'by', 'preparing', 'large', 'examples', 'of', 'translation', 'pairs.', 'Since', 'each', 'case', 'can', 'be', 'represented', 'in', 'a', 'fairly', 'context-sensitive', 'manner', 'with', 'full', 'semantic', 'restrictions', 'incorporated,', 'the', 'memorybased', 'translation', 'avoids', 'expensive', 'computations', 'generally', 'takes', 'place', 'in', 'the', 'rule-based', 'translation', 'system.', 'In', 'addition,', 'the', 'memory-based', 'approach', 'is', 'expected', 'to', 'produce', 'high', 'quality', 'translation', 'due', 'to', 'its', 'capability', 'to', 'reuse', 'stylistic', 'translation', 'in', 'the', 'past.', 'Since,', 'detailed', 'mechanisms', 'and', 'rationale', 'for', 'the', 'memory-based', 'translation', 'approach', 'has', 'been', 'discussed', 'by', 'relevant', 'literatures', '(see', '<ref type=""single"">[Nagao, 1984],</ref>', '<ref type=""single"">[Riesbeck and Martin, 1985],</ref>', '<ref type=""single"">[Kitano, 1990a],</ref>', '<ref type=""single"">[Sumita and Iida, 1991],</ref>', '<ref type=""group"">[Kitano and Higuchi, 199la],</ref>', 'and', '<ref type=""group"">[Kitano and Higuchi, 199lb]</ref>', '),', 'we', 'will', 'simply', 'focus', 'on', 'its', 'massively', 'parallel', 'implementation', 'and', 'its', 'performance.']",119,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
2f65b053-600b-493e-a70b-342c7fc9f861,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,"['BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension']",['2020'],['Mike Lewis;Yinhan Liu;Naman Goyal ; Abdelrahman Mohamed;Omer Levy;Veselin Stoyanov;Luke Zettlemoyer'],single,"['CoNLL', 'bart:', 'we', 'use', 'a', 'fine-tuned', 'BART', 'model', '<ref type=""single"">(Lewis et al., 2020)</ref>']",8,"[3, 3, 2, 2, 2, 2, 1, 1, 1]"
2f7eb327-c396-4c72-8235-f310342400cd,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Generating sentences from a continuous space'],['2016'],['R Samuel;Luke Bowman;Oriol Vilnis;Andrew Vinyals;Rafal Dai;Samy Józefowicz;unk Bengio'],single,"['To', 'observe', 'the', 'effect', 'of', 'disentanglement', 'in', 'homotopy', '<ref type=""single"">(Bowman et al., 2016)</ref>', 'Additionally,', 'to', 'highlight', 'the', 'role', 'of', 'generative', 'factor', 'in', 'generation,', 'we', 'conduct', 'a', 'dimensionwise', 'homotopy,', 'transitioning', 'from', 'the', 'first', 'to', 'the', 'last', 'sentence', 'by', 'interpolating', 'between', 'the', 'dimensions', 'one-by-one.', 'This', 'is', 'implemented', 'as', 'follows:', '(i)', 'using', 'prior', 'distribution', '7', 'we', 'sample', 'two', 'latent', 'codes', 'denoted', 'by', 'z', '1', '=', '(z', '1,1,', 'z', '1,2', ',...,', 'z', '1,n', '),', 'z', '2', '=', '(z', '2,1,', 'z', '2,2', ',...,', 'z', '2,n', '),', '(ii)', 'for', 'i-th', 'dimension,', 'using', 'z', '1,i', '=', '(z', '2,1', ',...,', 'z', '2,i−1,', 'z', '1,i', ',...,', 'z', '1,n)', 'as', 'the', 'start,', 'we', 'interpolate', 'along', 'the', 'i-th', 'dimension', 'towards', 'z', '2,i', '=', '(z', '2,1', ',...,', 'z', '2,i,', 'z', '1,i+1', ',...,', 'z', '1,n', ').', 'Table', '6', 'illustrates', 'this', 'for', 'a', '3D', 'latent', 'code', 'example.']",8,"[2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
302e8762-1a72-4c43-824b-1cdfb4a14091,Corpora and Machine Translation,1993,Yorick Wilks,['Interpolated estimation of Markov source parameters from sparse data'],['1980'],['F Jelinek;R Mercer'],single,"['We', 'need', 'to', 'establish', 'a', 'ground', 'zero', 'on', 'what', 'the', 'IBM', 'system', 'is:', 'their', 'rhetorical', 'claim', 'is', '(or', 'perhaps', 'was)', 'that', 'they', 'are', 'a', 'pure', 'statistical', 'system,', 'different', 'from', 'their', 'competitors,', 'glorying', 'in', 'the', 'fact', 'that', 'they', 'did', 'not', 'even', 'need', 'French', 'speakers.', 'By', 'analogy', 'with', ""Searle's"", 'Chinese', 'Room,', 'one', 'could', 'call', 'this', 'theirs', 'a', 'French', 'Room', 'position:', 'MT', 'without', 'a', 'glimmering', 'of', 'understanding', 'or', 'even', 'knowing', 'that', 'French', 'was', 'the', 'language', 'they', 'were', 'working', 'on!', 'There', 'is', 'no', 'space', 'here', 'for', 'a', 'detailed', 'description', 'of', ""IBM's"", 'claims', '(see', '<ref type=""group"">Brown et al. 1990 Brown et al. , 1991a Brown et al. , 1991b)).</ref>', 'In', 'essence,', 'the', 'method', 'is', 'an', 'adaptation', 'of', 'one', 'that', 'worked', 'well', 'for', 'speech', 'decoding', '<ref type=""single"">(Jelinek and Mercer 1980).</ref>']",105,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]"
308797a4-1d80-4ac3-bb56-93527f52723d,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Machine translation and monolingual postediting: The AFRL WMT-14 system'],['2014'],['L Schwartz;T Anderson;J Gwinnup;K Young'],single,"['Professional', 'translations', 'of', 'Doc', 'A', 'into', 'English', 'and', 'Doc', 'B', 'into', 'Russian', 'were', 'commissioned', 'as', 'part', 'of', 'the', 'WMT-14', 'shared', 'translation', 'task', '<ref type=""single"">(Bojar et al., 2014).</ref>', 'The', 'Russian', 'version', 'of', 'each', 'text', 'was', 'translated', 'automatically', 'using', 'Moses', '<ref type=""single"">(Koehn et al., 2007)</ref>', 'by', '<ref type=""single"">Schwartz et al. (2014)</ref>', 'as', 'part', 'of', 'their', 'WMT14', 'shared', 'task', 'submission.', 'As', 'a', 'side', 'effect', 'of', 'the', 'phrase-based', 'MT', 'process,', 'Moses', 'can', 'be', 'configured', 'to', 'produce', 'alignment', 'links,', 'indicating', 'which', 'target', 'language', 'words', 'were', 'produced', 'from', 'which', 'source', 'language', 'words.', 'To', 'enable', 'maximal', 'comparability', 'with', 'the', 'post-editing', 'results', 'of', '<ref type=""single"">Schwartz et al. (2014),</ref>', 'we', 'make', 'use', 'of', 'Russian-English', 'machine', 'translation', 'results', 'and', 'alignments', 'from', 'that', 'work', 'here.']",36,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
30a10754-99c4-4706-9652-5962e6001094,ROI Analysis model for Language Service Providers,2013,Ekaterina Stambolieva,['Automatic Evaluation. Statistical Machine Translation'],['2010'],['Phillip Koehn'],single,"['Table', '2.', 'expands', 'the', 'overview', 'of', 'costs', 'to', 'cover', 'the', 'whole', 'translation', 'process', 'depending', 'on', 'the', 'different', 'services', 'a', 'LSP', 'offers', 'to', 'its', 'clients.', 'Scenario', '2', 'and', '3', 'share', 'some', 'of', 'the', 'listed', 'costs', 'in', 'Table', '2,', 'but', 'include', 'additional', 'ones.', 'The', 'total', 'cost', 'of', 'resources,', 'for', 'instance,', 'includes', 'human', 'resources', 'costs,', 'hardware', 'and', 'software', 'license', 'costs,', 'among', 'others.', 'As', 'LSPs', 'rely', 'on', 'technology,', 'the', 'minimal', 'requirements', 'in', 'place', 'are', 'the', 'presence', 'of', 'a', 'CAT', 'tool', 'system,', 'and', 'a', 'project', 'coordination', 'framework.', 'Personnel', 'training', 'on', 'CAT', 'tool', 'usage', 'as', 'well', 'as', 'project', 'coordination', 'usage', 'induction', 'are', 'not', 'regarded', 'as', 'costs', 'in', 'the', 'current', 'scenarios,', 'as', 'they', 'are', 'expected', 'to', 'have', 'been', 'completed.', 'However,', 'post-editing', 'training', 'and', 'MT', 'development', 'training,', 'among', 'others,', 'are', 'considered', 'as', 'investment', 'costs', 'since', 'they', 'depend', 'on', 'the', 'new', 'involvement', 'of', 'MT', 'technology', 'in', 'the', 'business', 'processes.', 'Therefore,', 'the', 'total', 'LSP', 'investment', 'cost', 'for', 'providing', 'pure', 'human', 'translation', 'services', 'is', 'presented', 'in', 'Figure', '2:', '3.', 'aims', 'to', 'provide', 'cost', 'overview', 'of', 'translation', 'within', 'the', 'context', 'of', 'Scenario', '2,', 'namely', 'when', 'a', 'LSP', 'incorporates', 'in-house', 'developed', 'MT', ""solution's"", 'output', 'in', 'the', 'translation', 'delivery', 'process.', 'The', 'emphasis', 'comes', 'down', 'to', 'the', 'cost', 'of', 'the', 'number', 'of', 'translated', 'segments,', 'which', 'is', 'marked', 'with', 'Comtsegm', 'instead', 'of', 'Cosegm', 'as', 'in', 'Table', '1.', 'For', 'good', 'language', 'and', 'translation', 'models,', 'when', 'overall', 'MT', 'output', 'BLEU', 'score', '<ref type=""single"">(Koehn 2010)</ref>', 'is', 'higher', 'than', '65%,', 'a', 'MT', 'pre-translated', 'segment', 'translation', 'is', 'paid', '50%', 'of', 'the', 'human', 'translation', 'rate', 'per', 'segment.', 'Consequently,', 'Comtsegm', '=', '50%', '*Cosegm.', 'To', 'our', 'knowledge,', 'our', 'internal', 'proofing', 'costs', 'do', 'not', 'change', 'according', 'to', 'recent', 'statistics.', 'With', 'time,', 'these', 'statistics', 'can', 'change', 'and', 'guide', 'better', 'pricing', 'model', 'development.', 'Table', '4.', 'shows', 'the', 'translation', 'process', 'investment', 'costs', 'when', 'MT', 'is', 'developed', 'internally', 'on', 'LSP', 'premises.', 'The', 'document', 'conversion,', 'project', 'coordination,', 'additional', 'services', 'costs,', 'along', 'with', 'the', 'cost', 'of', 'terminology', 'management,', 'and', 'resources,', 'are', 'identical', 'and', 'the', 'same', 'as', 'in', 'Scenario', '1.', 'It', 'is', 'interesting', 'to', 'note', 'the', 'costs', 'that', 'accompany', 'internal', 'MT', 'development.', 'These', 'costs', 'include', 'but', 'are', 'not', 'restricted', 'to', 'customization,', '6', 'equal', 'to', '50%', '*Cosegm', 'automation,', 'software', 'and', 'hardware', 'costs.', 'A', 'cost', 'for', 'trainings', 'is', 'introduced.', 'It', 'covers', 'project', 'coordinators', 'MT', 'training', 'expenses.', 'Additionally', 'it', 'includes', 'MT', 'specialist', 'new', 'methodology', 'and', 'approach', 'trainings.', 'These', 'costs', 'can', 'be', 'roughly', 'estimated', 'to', 'the', 'expenses', 'incurred', 'for', 'the', 'number', 'of', 'employees', 'required', 'per', 'day.', 'Depending', 'of', 'the', 'scale', 'of', 'the', 'MT', 'projects,', 'hardware', 'costs', 'for', 'two', 'servers', 'allowing', 'simultaneous', 'translation', 'requests', 'can', 'easily', 'reach', '60K', 'euros.', 'The', 'hardware', 'cost', 'is', 'repetitive', 'every', 'year', 'as', 'more', 'projects', 'and', 'users', 'are', 'expected', 'to', 'benefit', 'from', 'MT.', 'The', 'cost', 'of', 'customization', 'and', 'optimization', 'include', 'human', 'development', 'effort', 'and', 'is', 'measured', 'in', 'man-hours.', 'This', 'cost', 'is', 'directly', 'linked', 'to', 'the', 'software', 'licensing', 'expenses', 'as', 'licensed', 'tools', 'are', 'used', 'to', 'accelerate', 'the', 'MT', ""specialists'"", 'development', 'effort.', 'More', 'managerial', 'tasks', 'by', 'human', 'resources', 'are', 'required', 'such', 'as', 'risk', 'management', 'monitoring', 'and', 'development', 'of', 'prevention', 'plan', 'strategies.']",223,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
30b1d408-effb-4de7-a0c7-e4d723f1134b,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,"['Multi-level translation aids in a distributed system', 'The proper place of men and machines in language translation']","['1982', '1980']","['A Melby', 'M Kay']",group,"['Until', 'recently,', 'the', 'interactive', 'approach', 'to', 'MT', 'almost', 'inevitably', 'came', 'in', 'the', 'form', 'of', 'the', 'widely', 'promoted', ""Translator's"", ""Workbench'"", 'idea', '<ref type=""group"">[21, 29],</ref>', 'the', 'main', 'aims', 'of', 'which', 'are', 'to', 'help', 'translators', 'to', 'translate', 'texts.', 'Now', 'it', 'has', 'been', 'acknowledged', 'that', 'there', 'is', 'a', 'drawback', 'in', 'this', 'approach,', 'which', 'is', 'that', 'it', 'is', 'sometimes', 'difficult', 'to', 'see', 'where', 'the', 'most', 'appropriate', 'division', 'of', 'labour', 'between', 'the', 'computer', 'and', 'the', 'human', 'should', 'occur,', 'and', 'there', 'is', 'sometimes', 'even', 'a', 'conflict', 'between', 'what', 'the', 'system', 'offers', 'the', 'translator-user,', 'and', 'what', 'the', 'user', 'already', 'knows,', 'or', 'between', 'the', 'extent', 'to', 'which', 'the', 'system', 'or', 'the', 'user', 'should', 'take', 'the', 'initiative,', 'which', 'might', 'differ', 'from', 'occasion', 'to', 'occasion.']",20,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0]"
3120671c-c0ee-44fc-8cdb-a4b651e265cc,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['Label propagation for deep semi-supervised learning'],['2019'],['Ahmet Iscen;Giorgos Tolias'],single,"['Model', 'stacking', 'is', 'an', 'efficient', 'ensemble', 'method', 'to', 'improve', 'model', 'accuracy.', 'The', 'main', 'procedure', 'of', 'stacking', 'trained', 'models', 'in', 'our', 'method', 'including', 'five', 'steps.', 'First,', 'we', 'use', 'heterogeneous', 'PLMs', 'including', 'BERT,', 'RoBERTa,', 'ALBERT,', 'and', 'ERNIE', 'as', 'base', 'models.', 'Second,', 'we', 'generate', 'multiple', 'hyperparameter', 'sets', 'by', 'setting', 'different', 'values', 'of', 'dropout,', 'selecting', 'different', 'numbers', 'of', 'last', 'hidden', 'layers,', 'and', 'using', 'different', 'loss', 'functions.', 'Since', 'our', 'purpose', 'here', 'is', 'not', 'only', 'to', 'find', 'the', 'best', 'hyperparameter', 'sets', 'but', 'also', 'to', 'collect', 'diverse', 'sets', 'with', 'reasonable', 'performances,', 'we', 'keep', 'all', 'the', 'training', 'results', 'from', 'different', 'sets.', 'Third,', 'we', 'perform', '7fold', 'cross-validation', 'during', 'the', 'whole', 'training', 'process', 'to', 'avoid', 'overfitting', 'or', 'selection', 'bias.', 'Fourth,', 'we', 'adopt', 'several', 'training', 'strategies', 'including', 'using', 'pseudo-labelling', '<ref type=""single"">(Iscen et al., 2019)</ref>', 'and', 'data', 'augmentation', 'to', 'further', 'improve', 'the', 'diversity', 'of', 'trained', 'models.']",118,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2]"
31d55e62-e326-4da3-895e-38ed14d2f98d,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['On sense and reference'],['1960'],['Gottlob Frege'],single,"['Formal', 'Dataset', 'Description', 'An', 'input', 'text', 'is', 'composed', 'of', 'tokens', 'w', '1', ',...,', 'w', 't,', 'and', 'an', 'ordered', 'set', 'N', '=', 'n', '1', ',...,', 'n', 'k', 'of', 'base-NP', 'mentions.', 'The', 'underlying', 'text', 'is', 'often', 'arranged', 'into', 'paragraphs,', 'and', 'may', 'also', 'include', 'a', 'title.', 'A', 'base-NP', 'mention,', '7', 'Note', 'that', 'the', 'converse', 'does', 'not', 'hold:', 'prep(n', '1,', 'n', '2', '),', 'coref-to(n', '1,', 'n', '3)', 'does', 'not', 'necessarily', 'entail', 'prep(n', '3,', 'n', '2', ').', 'Consider', 'for', 'example:', ""''The"", 'race', 'began.', 'John,', 'the', 'organizer,', ""pleased''."", 'While', 'John', 'and', 'the', 'organizer', 'are', 'coreferring,', 'the', 'relation', 'organizer', 'of', 'the', 'race', 'holds,', 'while', 'John', 'of', 'the', 'race', 'does', 'not.', 'This', 'is', 'because', 'John', 'and', 'the', 'organizer', 'are', 'two', 'different', 'senses', 'for', 'the', 'same', 'reference,', 'and', 'the', 'relation', 'holds', 'only', 'for', 'one', 'of', 'the', 'senses', '(cf.', '<ref type=""single"">Frege, 1960).</ref>', 'Putting', 'it', 'differently,', 'when', 'John', 'and', 'organizer', 'serve', 'as', 'predicates,', 'their', 'selectional', 'preferences', 'are', 'different', 'despite', 'them', 'coreferring.', 'Such', 'examples', 'are', 'common,', 'consider', 'also', ""''John"", 'is', ""Jenny's"", 'father,', ""Mary's"", ""husband''"", 'where', 'father', 'of', 'Jenny', 'holds,', 'while', 'husband', 'of', 'Jenny', ""doesn't."", 'Similarly,', 'husband', 'of', 'Mary', 'holds,', 'while', 'father', 'of', 'Mary', ""doesn't."", 'also', 'known', 'as', 'NP', 'chunk,', 'is', 'the', 'smallest', 'noun', 'phrase', 'unit', 'that', 'does', 'not', 'contain', 'other', 'NPs,', 'prepositional', 'phrases,', 'or', 'relative', 'clauses.', '8', 'It', 'is', 'defined', 'as', 'a', 'contiguous', 'span', 'over', 'the', 'text,', 'indicated', 'by', 'start-token', 'and', 'end-token', 'positions', '(e.g.,', '(3,', '5)', ""''the"", 'young', ""boy'')."", 'The', 'output', 'is', 'a', 'set', 'R', 'of', 'relations', 'of', 'the', 'form', '(n', 'i,', 'prep,', 'n', 'j', '),', 'where', 'i', '=', 'j', 'and', 'prep', 'is', 'a', 'preposition', '(or', 'a', 'set-membership', 'symbol).', 'Each', 'text', 'is', 'also', 'associated', 'with', 'a', 'set', 'C', 'of', 'non-overlapping', 'coreference', 'clusters,', 'where', 'each', 'cluster', 'c', '⊆', 'N', 'is', 'a', 'non-empty', 'list', 'of', 'NP', 'mentions.', 'The', 'set', 'of', 'clusters', 'is', 'not', 'provided', 'as', 'input,', 'but', 'for', 'correct', 'sets', 'R', 'it', 'holds', 'that', '∀n', 'j', '∈', 'c(n', 'j', '),(n', 'i,', 'prep,', 'n', 'j)', '∈', 'R', '⇒', '(n', 'i,', 'prep,', 'n', 'j)', '∈', 'R,', 'where', 'c(n', 'j)', '∈', 'C', 'is', 'the', 'cluster', 'containing', 'n', 'j', '.Completeness', 'and', 'Uniformity', 'The', 'kinds', 'of', 'preposition-mediated', 'relations', 'we', 'cover', 'originate', 'from', 'different', 'linguistic', 'or', 'cognitive', 'phenomena,', 'and', 'some', 'of', 'them', 'can', 'be', 'resolved', 'by', 'employing', 'different', 'linguistic', 'constructs.', 'For', 'example,', 'some', 'within-sentence', 'relations', 'can', 'be', 'extracted', 'deterministically', 'from', 'dependency', 'trees,', 'for', 'example,', 'by', 'following', 'syntactic', 'prepositional', 'attachment.', 'Other', 'relations', 'can', 'be', 'inferred', 'based', 'on', 'pronominal', 'coreference', '(e.g.,', ""''his"", 'school', '[of', ""Adam]''"", 'above', 'can', 'be', 'resolved', 'by', 'first', 'resolving', ""''his''"", 'to', ""''Adam's''"", 'via', 'a', 'coreference', 'engine,', 'and', 'then', 'normalizing', ""''Adam's"", ""school''"", '→', ""''school"", 'of', ""Adam'')."", 'Many', 'others', 'are', 'substantially', 'more', 'involved.', 'We', 'deliberately', 'chose', 'not', 'to', 'distinguish', 'between', 'the', 'different', 'cases,', 'and', 'expose', 'all', 'the', 'relations', 'to', 'the', 'user', '(and', 'to', 'the', 'annotators)', 'via', 'the', 'same', 'uniform', 'interface.', 'This', 'approach', 'also', 'contributes', 'to', 'the', 'practical', 'usefulness', 'of', 'the', 'task:', 'Instead', 'of', 'running', 'several', 'different', 'processes', 'to', 'recover', 'different', 'kinds', 'of', 'links,', 'the', 'end-user', 'will', 'have', 'to', 'run', 'only', 'one', 'process', 'to', 'obtain', 'them', 'all.']",129,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
31dfabd8-f1e7-41f9-9e3c-a0ee072551e9,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['Monotonic infinite lookback attention for simultaneous machine translation'],['2019'],['Naveen Arivazhagan;Colin Cherry;Wolfgang Macherey;Chung-Cheng Chiu;Semih Yavuz;Ruoming Pang;Wei Li;Colin Raffel'],single,"['Recent', 'read-write', 'policies', 'can', 'be', 'divided', 'into', 'two', 'categories:', 'fixed', 'policies', 'such', 'as', 'wait-k', '<ref type=""single"">(Ma et al., 2018),</ref>', 'wait-if*', '<ref type=""single"">(Cho and Esipova, 2016),</ref>', 'and', 'adaptive', 'policies', 'such', 'as', 'MoChA', '<ref type=""single"">(Chiu and Raffel, 2017),</ref>', 'MILk', '<ref type=""single"">(Arivazhagan et al., 2019)</ref>', 'and', 'MU', '<ref type=""single"">(Zhang et al., 2020).</ref>', 'Fixed', 'policies', 'are', 'simple', 'to', 'implement,', 'but', 'they', 'neglect', 'contextual', 'information,', 'which', 'might', 'result', 'in', 'quality', 'reduction.', 'Dynamic', 'policies', 'are', 'more', 'flexible,', 'they', 'can', 'learn', 'from', 'data', 'to', 'achieve', 'better', 'quality/latency', 'trade-offs,', 'but', 'accordingly', 'difficult', 'to', 'train.']",25,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3211c3e4-6fda-4fde-a4ab-963cbb6b4dda,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,"['unknown', ""Facebook fair's wmt19 news translation task submission""]","['2020', '2019']","['Fandong Meng;Jianhao Yan;Yijin Liu;Yuan Gao;Xianfeng Zeng;Qinsong Zeng;Peng Li;Ming Chen;Jie Zhou;Sifan Liu', 'Nathan Ng;Kyra Yee;Alexei Baevski;Myle Ott;Michael Auli;Sergey Edunov']",group,"['Similar', 'to', '<ref type=""group"">(Ng et al., 2019, Meng et al., 2020),</ref>', 'we', 'preprocess', 'the', 'data', 'as', 'follows:']",2,"[2, 2, 1, 2, 2, 2, 2, 2, 2]"
322ad6ee-c78a-425a-94cf-5b7629a993c0,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['Multi-sample dropout for accelerated training and better generalization'],['2019'],['Hiroshi Inoue'],single,"['Since', 'PLMs', 'can', 'process', 'multiple', 'input', 'sentences,', 'we', 'add', 'a', 'query', 'sentence', 'before', 'the', 'context', 'to', 'emphasize', 'the', 'words', '(e.g.', 'river)', 'that', 'need', 'to', 'be', 'predicted', 'and', 'the', 'corpus', '(e.g.', 'Bible)', 'they', 'come', 'from.', 'We', 'add', 'special', 'tokens', '[CLS]', 'and', '[SEP]', 'to', 'separate', 'the', 'query', 'and', 'the', 'context', 'as', 'shown', 'in', 'Figure', '2.', 'BERT', 'first', 'tokenizes', 'the', 'input', 'contents', 'and', 'then', 'generates', 'contextualized', 'vector', 'representations', 'for', 'each', 'token', 'in', 'multiple', 'hidden', 'layers.', 'We', 'focus', 'on', 'the', 'output', 'of', 'only', 'the', 'first', 'position', 'that', 'we', 'passed', 'the', 'special', '[CLS]', 'token', 'to.', 'The', 'last', 'k', 'hidden', 'layers', 'are', 'selected', 'to', 'get', 'the', 'final', 'representation', 'of', 'token', '[CLS]', 'through', 'a', 'weighted', 'calculation', 'function', 'as', 'below,x', '[CLS]', '=', 'k', 'i=1', 'W', 'i', 'x', '[CLS]iwhere', 'W', 'i', 'is', 'the', 'learning', 'weight', 'for', 'each', 'hidden', 'layer.', 'The', 'calculated', 'representation', 'is', 'then', 'fed', 'into', 'a', 'dense', 'layer,', 'and', 'the', 'technique', 'of', 'multi-sample', 'dropout', '<ref type=""single"">(Inoue, 2019)</ref>', 'is', 'utilized', 'to', 'accelerate', 'training', 'and', 'finally', 'obtain', 'the', 'predicted', 'complexity', 'scores.', 'The', 'loss', 'function', 'can', 'be', 'chosen', 'among', 'several', 'options', 'including', 'Mean', 'Square', 'Error', '(MSE),', 'Root', 'Mean', 'Square', 'Error', '(RMSE),', 'and', 'Mean', 'Absolute', 'Error', '(MAE).']",146,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
326dc2a7-b307-4739-95de-336b862fc960,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['1', 'https://parl.ai/projects/light', 'Quests', 'in', 'LIGHT', '<ref type=""single"">(Ammanabrolu et al., 2021)</ref>', 'take', 'the', 'form', 'of', 'a', 'short', 'motivation', 'and', 'goal', 'action', 'that', 'is', 'required', 'reach', 'the', 'world', 'state', 'required', 'to', 'finish', 'the', 'game.', 'For', 'example,', 'if', 'the', 'short', 'motivation', 'is', '""Your', 'motivation', 'is', 'to', 'acquire', 'a', 'sword"",', 'then', 'the', 'corresponding', 'goal', 'state', 'would', 'be', 'for', 'the', 'character', 'to', 'have', 'a', 'sword', 'in', 'their', 'inventory', 'and', 'goal', 'action', 'would', 'be', 'get', 'sword.', 'This', 'environment', 'also', 'contains', 'a', 'set', 'of', 'human', 'expert', 'demonstration', 'of', 'people', 'speaking', 'and', 'acting', 'in', 'character', 'while', 'playing', 'the', 'quests', 'mentioned', 'above.', 'Further', 'details', 'are', 'found', 'in', 'Appendix', 'A.1.']",5,"[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3]"
330b46ff-b24d-41ae-bae1-1c17b29b1ef3,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,"['Macaon, an nlp tool suite for processing word lattices']",['2011'],['A Nasr;F Béchet;J.-F Rey;B Favre;J Roux'],single,"['The', 'Factored', 'neural', 'machine', 'translation', 'is', 'an', 'extension', 'of', 'the', 'standard', 'NMT', 'architecture', 'which', 'allows', 'us', 'generating', 'several', 'output', 'symbols', 'simultaneously', 'as', 'presented', 'in', 'For', 'simplicity', 'reasons,', 'only', 'two', 'symbols', 'are', 'generated:', 'the', 'lemma', 'and', 'the', 'concatenation', 'of', 'the', 'different', 'factors', 'that', 'we', 'consider.', 'For', 'example,', 'from', 'the', 'French', 'word', 'devient,', 'we', 'obtain', 'the', 'lemma', 'devenir', 'and', 'the', 'factors', 'VP3#S,', 'meaning', 'that', 'it', 'is', 'a', 'Verb,', 'in', 'Present,', '3rd', 'person,', 'irrelevant', 'gender', '(#)', 'and', 'Singular.', 'The', 'morphological', 'and', 'grammatical', 'analysis', 'is', 'performed', 'with', 'the', 'MACAON', 'toolkit', '<ref type=""single"">[17].</ref>', 'MACAON', 'POS-tagger', 'outputs', 'the', 'lemma', 'and', 'factors', 'for', 'each', 'word', 'taking', 'into', 'account', 'its', 'context.', 'For', 'the', 'very', 'few', 'cases', 'when', 'MACAON', 'proposes', 'multiple', 'factors,', 'the', 'first', 'proposition', 'is', 'taken.', 'The', 'decoder', 'of', 'the', 'FNMT', 'architecture', 'presented', 'in', 'Figure', '3', 'may', 'lead', 'to', 'sequences', 'with', 'different', 'length', 'since', 'lemmas', 'and', 'factors', 'are', 'generated', 'in', 'a', 'synchronous', 'stream,', 'but', 'in', 'separate', 'outputs.', 'Indeed,', 'each', 'sequence', 'of', 'symbols', 'ends', 'when', 'the', 'end-of-sequence', '(&lt,eos&gt,)', 'symbol', 'is', 'generated', 'with', 'this', 'architecture,', 'and', 'nothing', 'prevents', 'the', 'lemma', 'generator', 'to', 'output', 'the', '&lt,eos&gt,', 'symbol', 'before', 'or', 'after', 'the', 'factors', 'generator.', 'To', 'avoid', 'this', 'scenario,', 'the', 'length', 'of', 'the', 'factors', 'sequence', 'is', 'constricted', 'to', 'be', 'equal', 'to', 'the', 'length', 'of', 'the', 'lemma', 'sequence.', 'This', 'implies', 'that', 'to', 'ignore', 'the', '&lt,eos&gt,', 'symbol', 'for', 'factors', '(to', 'avoid', 'shorter', 'factors', 'sequence)', 'and', 'stop', 'the', 'generation', 'of', 'factors', 'when', 'the', 'lemma', 'sequence', 'has', 'ended', '(to', 'avoid', 'longer', 'factors', 'sequence).', 'This', 'is', 'motivated', 'by', 'the', 'fact', 'that', 'the', 'lemmas', 'are', 'closer', 'to', 'the', 'final', 'objective', '(a', 'sequence', 'of', 'words)', 'and', 'that', 'they', 'are', 'the', 'symbols', 'carrying', 'most', 'of', 'the', 'meaning.']",86,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
336c85b7-081b-4404-8779-d3c630934907,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['der', 'Goot', '(2022)', '(MaChAmp)', 'proposed', 'to', 'pretrain', 'a', 'language', 'model', 'and', 're-finetune', 'after', 'multitask', 'learning', 'for', 'a', 'pre-defined', 'set', 'of', 'semantically', 'focused', 'NLP', 'tasks.', 'They', 'trained', 'a', 'multi-task', 'model', 'for', 'all', 'text-based', 'SemEval', 'tasks', 'that', 'include', 'annotation', 'on', 'the', 'word,', 'sentence,', 'or', 'paragraph', 'level.', 'They', 'compared', 'the', 'performance', 'with', 'models', 'using', 'mBERT', '<ref type=""single"">(Devlin et al., 2019).</ref>', 'The', 'pretrained', 'multi-task', 'embedding', 'showed', 'a', 'consistent', 'improvement', 'across', 'many', 'tasks', 'against', 'the', 'mBERT', 'embedding.']",52,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
3406cd9e-89bb-4365-a856-bb42f4dc5c7a,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['Distilling the knowledge in a neural network'],['2015'],['Geoffrey Hinton;Oriol Vinyals;Jeffrey Dean'],single,"['Data', 'Augmentation', 'The', 'third', 'strategy', 'aims', 'to', 'alleviate', 'the', 'issue', 'of', 'limited', 'training', 'data.', 'Since', 'the', 'cross-encoder', 'is', 'more', 'powerful', 'in', 'measuring', 'the', 'similarity', 'between', 'questions', 'and', 'passages,', 'we', 'utilize', 'it', 'to', 'annotate', 'unlabeled', 'questions', 'for', 'data', 'augmentation.', 'Specifically,', 'we', 'incorporate', 'a', 'new', 'collection', 'of', 'unlabeled', 'questions,', 'while', 'reuse', 'the', 'passage', 'collection.', 'Then,', 'we', 'use', 'the', 'learned', 'crossencoder', 'to', 'predict', 'the', 'passage', 'labels', 'for', 'the', 'new', 'questions.', 'To', 'ensure', 'the', 'quality', 'of', 'the', 'automatically', 'labeled', 'data,', 'we', 'only', 'select', 'the', 'predicted', 'positive', 'and', 'negative', 'passages', 'with', 'high', 'confidence', 'scores', 'estimated', 'by', 'the', 'cross-encoder.', 'Finally,', 'the', 'automatically', 'labeled', 'data', 'is', 'used', 'as', 'augmented', 'training', 'data', 'to', 'learn', 'the', 'dual', 'encoder.', 'Another', 'view', 'of', 'the', 'data', 'augmentation', 'is', 'knowledge', 'distillation', '<ref type=""single"">(Hinton et al., 2015),</ref>', 'where', 'the', 'cross-encoder', 'is', 'the', 'teacher', 'and', 'the', 'dual-encoder', 'is', 'the', 'student.']",118,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
34c603da-dfc3-47d1-bd9d-31afa18dc65c,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,"['Multi-way, multilingual neural machine translation with a shared attention mechanism']",['2016'],['O Firat;K Cho;Y Bengio'],single,"['Moreover,', 'we', 'also', 'compared', 'the', 'FNMT', 'system', 'to', 'the', 'multiway,', 'multilingual', 'NMT', 'system', '<ref type=""single"">[16].</ref>', 'This', 'method', 'can', 'train', 'several', 'encoder', 'and', 'decoders', 'sharing', 'only', 'the', 'attention', 'mechanism', 'between', 'them.', 'In', 'order', 'to', 'reproduce', 'our', 'experiments', 'using', 'the', 'multilingual', 'architecture,', 'we', 'used', 'one', 'input', 'encoder', '(at', 'word-level)', 'for', 'English', 'and', 'two', 'separate', 'decoders:', 'French', 'lemmas', 'and', 'French', 'factors.', 'The', 'final', 'word', 'is', 'obtained', 'by', 'the', 'factors-to-word', 'process', 'as', 'used', 'with', 'our', 'FNMT', 'system.', 'As', 'presented', 'in', 'Table', '1,', 'Multilingual', 'approach', 'performs', 'better', 'than', 'all', 'other', 'systems', 'at', 'lemma', 'and', 'factors', 'level.', 'However,', 'the', 'performance', 'at', 'word', 'level', 'is', 'the', 'lowest', 'due', 'to', 'the', 'desyncronization', 'of', 'the', 'two', 'outputs', 'which', 'are', 'trained', 'independently.']",13,"[0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
34ef890c-ecf7-49af-af6f-b493b2f656d3,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Improving cyberbullying detection with user context'],['2013'],['Maral Dadvar;Dolf Trieschnigg;Roeland Ordelman;Franciska De;Jong unk'],single,"['These', 'methods', 'directly', 'incorporate', 'handengineered', 'features', 'and', 'personal', 'traits', 'of', 'users', 'or', 'their', 'communities', 'in', 'order', 'to', 'model', 'the', 'likelihood', 'of', 'abusive', 'language', 'in', 'the', ""users'"", 'comments,', 'a', 'process', 'known', 'as', 'profiling', '<ref type=""single"">(Zhang et al., 2018).</ref>', '<ref type=""single"">Dadvar et al. (2013)</ref>', 'included', 'the', 'age', 'of', 'users', 'alongside', 'other', 'traditional', 'lexicon-based', 'features', 'to', 'detect', 'cyber-bullying,', 'while', 'Galán-García', 'et', 'al.', '(2016)', 'utilized', 'the', 'time', 'of', 'publication,', 'geo-position,', 'and', 'language', 'in', 'the', 'profile', 'of', 'Twitter', 'users.', '<ref type=""single"">Waseem and Hovy (2016)</ref>', 'exploited', 'gender', 'of', 'Twitter', 'users', 'on', 'top', 'of', 'character', 'n-gram', 'counts', 'to', 'improve', 'detection', 'of', 'sexism', 'and', 'racism', 'in', 'a', 'dataset', 'comprising', 'racist,', 'sexist', 'and', 'benign', 'tweets', '-they', 'noted', 'that', 'the', 'F', '1', 'increased', 'slightly', 'from', '73.89%', 'to', '73.93%', 'when', 'the', 'gender', 'feature', 'was', 'included.', 'Using', 'the', 'same', 'setup,', 'Unsvåg', 'and', 'Gambäck', '(2018)', 'showed', 'that', 'the', 'inclusion', 'of', 'social', 'community', '(i.e.,', 'number', 'of', 'followers', 'and', 'friends)', 'and', 'activity', '(i.e.,', 'number', 'of', 'status', 'updates', 'and', 'favorites)', 'features', 'of', 'users', 'alongside', 'their', 'gender', 'further', 'enhanced', 'performance', 'by', '3', 'F', '1', 'points', 'over', 'the', 'n-gram', 'baseline.']",33,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
35921b7e-a1c6-4818-88ea-d9a8e51636ac,Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets,2021,George-Andrei Dima;Dumitru-Clementin Cercel;Mihai Dascalu,"['Self-supervised adversarial training', 'Virtual adversarial training: a regularization method for supervised and semisupervised learning']","['2020', '2018']","['Kejiang Chen;Yuefeng Chen;Hang Zhou;Xiaofeng Mao;Yuhong Li;Yuan He;Hui Xue;Weiming Zhang;Nenghai Yu', 'Takeru Miyato;Masanori Shin-Ichi Maeda;Shin Koyama;unk Ishii']",group,"['Our', 'model', 'achieved', 'the', 'highest', 'score', 'for', 'subtask', '1b', '(i.e.,', 'adverse', 'effect', 'span', 'detection)', 'with', 'an', 'F', '1', '-score', 'of', '51%,', 'arguing', 'that', 'MTL', 'can', 'enhance', 'adverse', 'effect', 'extraction', 'from', 'social', 'media', 'posts.', 'In', 'terms', 'of', 'future', 'work,', 'adversarial', 'training', '<ref type=""group"">(Miyato et al., 2018, Chen et al., 2020a)</ref>', 'will', 'be', 'considered', 'to', 'improve', 'the', 'robustness', 'of', 'our', 'approach.']",40,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
35b7ad85-897b-44cf-8860-5f7bb3cf3394,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['Convolutional neural networks for sentence classification'],['2014'],['Yoon Kim'],single,"['CNN-Text', '<ref type=""single"">(Kim, 2014)</ref>', 'is', 'the', 'use', 'of', '<ref type=""single"">CNN (LeCun et al., 1989)</ref>', 'network', 'on', 'word', 'embeddings', 'to', 'perform', 'the', 'classification', 'tasks.']",1,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
3603c3c4-dd33-4485-a60a-3d694f77b949,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Transition-based DRS parsing using stack-LSTMs'],['2019'],['Kilian Evang'],single,"['(1)', '(2)', 'the', 'integration', 'label', '[b-1', 'e0', 'n0', 'p0', 's0', 't0', 'x0]', 'indicates', 'that', '1', 'should', 'be', 'subtracted', 'from', 'that', 'to', 'get', 'to', 'the', 'actual', 'relative', 'index.', 'This', 'allows', 'was', 'in', 'our', 'example', 'to', 'have', 'the', 'same', 'fragment', 'as', 'in', 'Someone', 'was', 'tricked,', 'where', 'the', 'subject', 'does', 'not', 'introduce', 'a', 'presupposition', 'and', 'the', 'actual', 'index', 'is', 'thus', '-1', 'rather', 'than', '-2', 'because', 'there', 'is', 'one', 'less', 'box', 'intervening.', '2', 'Another', 'important', 'factorization', 'concerns', 'largeclass', 'and', 'open-class', 'symbols,', 'viz.', '(content-word)', 'word', 'senses,', 'names,', 'numbers,', 'and', 'time', 'expressions.', 'We', 'follow', '<ref type=""single"">Evang (2019)</ref>', 'in', 'replacing', 'these', 'with', 'dummy', 'expressions', 'in', 'the', 'fragments', 'and', 'predicting', 'them', 'separately,', 'as', 'explained', 'below', 'in', 'Section', '3.', 'We', 'also', 'follow', 'them', 'in', 'heuristically', 'changing', 'the', 'representation', 'of', 'first', 'and', 'second', 'person', 'pronouns,', 'which', 'introduce', '""speaker""', 'and', '""hearer""', 'constants', 'instead', 'of', 'discourse', 'referents', 'in', 'the', 'PMB,', 'for', 'more', 'consistent', 'representation', 'of', 'predicates.b0', 'REF', 'x0', 'b-1', 'Name', 'x-1', '""tom""', 'b-1', 'PRESUPPOSITION', 'b0', 'b-2', 'male', '""n.02""', 'x-1', 'b-2', 'REF', 't0', 'b-1', 'TPR', 't-1', '""now""', 'b-1', 'Time', 'e-1', 't-1', 'b-1', 'time', '""n.08""', 't-1', 'b-1', 'REF', 'e-1', 'b-1', 'Patient', 'e-1', 'x-1', 'b-1', 'trick', '""v.01""', 'e-1', '(3)', 'b0', 'REF', 'x0', 'b-1', 'Name', 'x-1', '""DUMMY""', 'b-1', 'PRESUPPOSITION', 'b0', 'b-2', 'male', '""n.02""', 'x-1', 'b-1', 'REF', 't0', 'b-1', 'TPR', 't-1', '""now""', 'b-1', 'Time', 'e-1', 't-1', 'b-1', 'time', '""n.08""', 't-1', 'b-1', 'REF', 'e-1', 'b-1', 'Patient', 'e-1', 'x-1', 'b-1', 'DUMMY', '""v.00""', 'e-1', '[b0', 'e0', 'n0', 'p0', 's0', 't0', 'x0]', '[b-1', 'e0', 'n0', 'p0', 's0', 't0', 'x0]', '[b0', 'e0', 'n0', 'p0', 's0', 't0', 'x0]', 'tom', '-', 'trick', '""v.01""']",88,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
361123f3-238b-4b33-892d-4d3b3338b91e,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Solving the correct-prefix property for TAGs'],['1997'],['M-J Nederhof'],single,"['Several', 'parsing', 'algorithms', 'have', 'been', 'proposed', 'for', 'TAG,', 'ranging', 'from', 'simple', 'bottom-up', 'algorithms,', 'like', 'CYK', '<ref type=""single"">(17],</ref>', 'to', 'sophisticated', 'extensions', 'of', 'the', 'Earley', ""'s"", 'algorithm', '<ref type=""single"">[9].</ref>', 'In', 'order', 'to', 'improve', 'efficiency,', 'it', 'is', 'usual', 'to', 'translate', 'the', 'source', 'tree', 'adjoining', 'grammar', 'into', 'a', 'linear', 'indexed', 'grammar', '<ref type=""single"">[1 6, 12, 13, 17].</ref>', 'However,', 'in', 'some', 'cases', 'is', 'not', 'possible', 'to', 'translate', 'the', 'parsing', 'strategy', 'from', 'TAG', 'to', 'LIG,', 'as', 'there', 'are', 'parsing', 'strategies', 'for', 'TAG', 'which', 'are', 'not', 'incorporated', 'in', 'any', 'parsing', 'algorithm', 'for', 'LIG.', 'To', 'eliminate', 'this', 'drawback,', 'we', 'present', 'in', 'this', 'paper', 'several', 'parsing', 'algorithms', 'for', 'LIG', 'which', 'mimic', 'the', 'most', 'popular', 'parsing', 'strategies', 'for', 'TAG', '<ref type=""single"">[1].</ref>']",24,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3645ec53-03ca-4891-b947-3fb94e761633,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Playing codenames with language graphs and word embeddings'],['2021'],['Divya Koyyalagunta;Anna Sun;Rachel Draelos;Cynthia Rudin'],single,"['In', 'addition', 'to', 'calculating', 'the', 'relatedness', 'between', 'words,', 'the', 'above', 'works', 'also', 'differ', 'in', 'the', 'scoring', 'functions', 'of', 'the', 'possible', 'clues.', 'Without', 'limiting', 'the', 'generality,', 'we', 'assume', 'that', 'our', 'agent', 'plays', 'in', 'the', 'blue', 'team,', 'that', 'is,', 'our', 'clues', 'refer', 'to', 'the', 'blue', 'words.', 'Using', 'the', 'notations', 'of', '<ref type=""single"">Koyyalagunta et al. (2021),</ref>', 'let', 'c', 'be', 'a', 'possible', 'clue', 'word,', 'I', 'n', 'a', 'set', 'of', 'targeted', '(intended)', 'words,', 'that', 'is,', 'the', 'n', 'closest', 'blue', 'words', 'to', 'c,', 'R', 'the', 'set', 'of', 'all', 'bad', 'words', 'that', 'do', 'not', 'belong', 'to', 'the', 'team', '(red', 'words),', 'and', 's(•,', '•)', 'a', 'function', 'that', 'calculates', 'the', 'similarity', 'or', 'relatedness', 'of', 'two', 'words.', 'The', 'scoring', 'function', 'of', '<ref type=""single"">Kim et al. (2019)</ref>', 'is', 'thengKim(c,', 'n)', '=', '\uf8f1', '\uf8f2', '\uf8f3', 'min', 'b∈In', 's(c,', 'b),', 'if', 'min', 'b∈In', 's(c,', 'b)', '&gt,', 'maxr∈R', 's(c,', 'r)', '0,', 'otherwise.(1)', '<ref type=""single"">Jaramillo et al. (2020)</ref>', 'takes', 'the', 'same', 'function,', 'but', 'adds', 'penalties', 'based', 'on', 'the', 'color', 'of', 'the', 'cards.', '<ref type=""single"">Koyyalagunta et al. (2021),</ref>', 'on', 'the', 'other', 'hand,', 'define', 'another', 'scoring', 'function:']",145,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 2, 1, 1, 1, 1]"
36748a8b-0998-4c74-bda5-2268b0e3d9cc,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Hiddencut: Simple data augmentation for natural language understanding with better generalizability'],['2021'],['Chen Jiaao;Chen Shen Dinghan;Yang Weizhu;unk Diyi'],single,"['In', 'this', 'step,', 'we', 'will', 'extract', 'both', 'genuine', 'tokens', 'and', 'shortcut', 'tokens', 'because', 'they', 'are', 'both', 'likely', 'to', 'affect', 'a', ""model's"", 'prediction.', 'We', 'rely', 'on', 'interpretability', 'techniques', 'to', 'collect', 'information', 'on', 'whether', 'a', 'certain', 'input', 'token', 'is', 'important', 'to', ""model's"", 'decision', 'making.', 'In', 'this', 'paper,', 'we', 'use', 'the', 'attention', 'score', 'in', 'BERT-based', 'models', 'as', 'an', 'explanation', 'of', 'model', 'predictions', '<ref type=""group"">(Clark et al., 2019b, Kovaleva et al., 2019),</ref>', 'due', 'to', 'its', 'simplicity', 'and', 'fast', 'computation.', 'Recent', 'work', '<ref type=""single"">(Jiaao et al., 2021)</ref>', 'also', 'reveals', 'that', 'attention', 'scores', 'outperform', 'other', 'explanation', 'techniques', 'in', 'regularizing', 'redundant', 'information.', 'Other', 'techniques', '<ref type=""group"">(Ribeiro et al., 2016, Sundararajan et al., 2017, Chen et al., 2020, Jacovi et al., 2021)</ref>', 'can', 'also', 'be', 'used', 'in', 'this', 'step.', 'As', 'an', 'example,', 'given', 'a', 'sentence', '""Spielberg', 'is', 'a', 'good', 'director."",', 'assuming', '""good""', 'is', 'a', 'genuine', 'token', 'and', '""Spielberg""', 'is', 'a', 'shortcut', 'token,', 'we', 'expect', 'that', 'in', 'a', 'BERT-based', 'sentiment', 'classification', 'model,', 'the', 'attention', 'scores', 'for', '""good""', 'and', '""Spielberg""', 'are', 'higher', 'and', 'thus', 'will', 'be', 'extracted', 'as', 'important', 'tokens.', 'On', 'the', 'other', 'hand,', 'for', '""is"",', '""a""', 'and', '""director""', 'the', 'attention', 'scores', 'would', 'be', 'lower', 'as', 'they', 'are', 'relatively', 'less', 'useful', 'to', 'the', 'model', 'decision.']",69,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
368cb02f-87bf-462d-a7f7-446cc1937185,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties'],['2021'],['Kathleen Siminyu;Xinjian Li;Antonios Anastasopoulos;David Mortensen;Michael Marlo;Graham Neubig'],single,"['We', 'compare', 'the', 'output', 'of', 'Epitran', 'and', 'Allosaurus', 'on', 'the', 'ALFFA', 'dataset.', 'Following', 'the', 'practice', 'of', '<ref type=""single"">(Li et al., 2020),</ref>', 'we', 'used', 'the', 'editdistance', '10', 'library', 'to', 'calculate', 'the', 'Phone', 'Error', 'Rate', '(PER).', 'Having', 'no', 'ground', 'truth', 'phone', 'annotations,', 'we', 'instead', 'take', ""Epitran's"", 'outputs', 'as', '""ground', 'truth""', 'for', 'comparison.', 'The', 'mean', 'PER', 'between', 'the', 'outputs', 'is', '23.7%.', 'This', 'result', 'is', 'consistent', 'with', '<ref type=""single"">Siminyu et al. (2021),</ref>', 'which', 'finds', 'PERs', 'as', 'high', 'as', '72.8%', 'when', 'testing', 'on', 'on', 'the', 'Bukusu', '(bxk),', 'Saamia', '(lsm)', 'and', 'East', 'Tusom', 'languages', '(an', 'endangered', 'subdialect', 'of', 'the', 'Tungkhulic', 'language', 'family).', 'However,', 'by', 'training', 'the', 'phone', 'recognizer', 'on', 'even', 'minimal', 'amounts', 'of', 'data', 'in', 'these', 'languages,', 'PERs', 'were', 'improved', 'significantly.']",59,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
369c7783-f682-47bc-8f2f-dd86bfaa2af6,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['Joint slot filling and intent detection via capsule neural networks'],['2019'],['Chenwei Zhang;Yaliang Li;Nan Du;Wei Fan;S Yu Philip'],single,"['Capsule', 'NN', '<ref type=""single"">(Zhang et al., 2019a)</ref>', 'is', 'a', 'capsule-based', 'neural', 'network', 'that', 'explicitly', 'captures', 'the', 'semantic', 'hierarchical', 'relationship', 'among', 'words,', 'slots', 'and', 'intents', 'via', 'a', 'dynamic', 'routing-by-agreement', 'schema.']",2,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
36b34d59-a34c-4929-b1f4-2410a7617864,Can Semantic Role Labeling Improve SMT?,2009,Dekai Wu;Pascale Fung,['Automatic learning of chinese-english semantic structure mapping'],['2006'],['Pascale Fung;Zhaojun Wu;Yongsheng Yang;Dekai Wu'],single,"['In', 'experiments', 'carried', 'out', 'on', 'PropBank', 'data', 'using', 'gold', 'standard', 'syntactic', 'parse', 'trees,', 'extended', 'syntactic', 'features', 'such', 'as', 'Path', 'Trigram', 'and', 'Path', 'Abbreviations', 'were', 'found', 'to', 'have', 'the', 'highest', 'contribution', 'to', 'system', 'performance', '<ref type=""single"">(Fung et al., 2006).</ref>', 'Another', 'feature,', 'Verb', 'Cluster,', 'was', 'also', 'found', 'to', 'be', 'most', 'useful', 'by', '<ref type=""single"">Xue and Palmer (2005).</ref>']",33,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
36b8160b-cdb9-4bfa-969f-16e3469adcee,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['Countering language drift via visual grounding'],['2019'],['Jason Lee;Kyunghyun Cho;Douwe Kiela'],single,"['Once', 'an', 'agent', 'acts', 'or', 'talks,', 'the', 'partner', 'agent-in', 'this', 'case', 'also', 'a', 'polyencoder', '<ref type=""single"">(Humeau et al., 2020)</ref>', 'trained', 'to', 'react', 'to', 'agents', 'with', 'motivations-also', 'acts', 'or', 'talks', 'and', 'this', 'information', 'is', 'processed', 'by', 'the', 'environment.', 'As', 'recommended', 'by', 'Prabhumoye', 'et', 'al.', '(2020),', '<ref type=""single"">Ammanabrolu et al. (2021),</ref>', 'we', 'keep', 'the', 'partner', 'model', 'fixed', 'during', 'the', 'episodes', 'where', 'the', 'LIGHT', 'agent', 'trains', 'to', 'ensure', 'that', 'it', 'retains', 'natural', 'English', 'semantics-avoiding', 'the', 'problem', 'of', 'language', 'drift', 'by', 'learning', 'an', 'emergent', 'language', 'with', 'that', 'must', 'agree', 'with', 'the', ""partner's"", 'usage', '<ref type=""single"">(Lee et al., 2019).</ref>']",81,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
372c85ac-7fc8-4c5d-a812-2299205075ae,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Against discrimination: equality act 2010 (UK)'],['2017'],['Elena Vladimirovna Fell;Maria Dyban'],single,"['Generalisability', 'While', 'we', 'have', 'established', 'methods', 'for', 'measuring', 'and', 'mitigating', 'binary', 'gender', 'bias,', 'we', 'have', 'not', 'achieved', 'the', 'same', 'for', 'nonbinary', 'genders', 'nor', 'for', 'any', 'other', 'protected', 'characteristics', 'defined', 'in', 'the', 'Equality', 'Act', '2010', '<ref type=""single"">(Fell and Dyban, 2017).</ref>', 'Practitioners', 'tackling', 'more', 'varied', 'presentations', 'of', 'identity-directed', 'bias', 'may', 'be', 'less', 'able', 'to', 'find', 'pre-existing', 'lists', 'of', 'biased', 'words', 'to', 'define', 'bias', 'measurements.']",34,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
37685f01-9521-424c-a055-5cfdde38cc50,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['unknown'],['1990'],['J Kim;D Moldovan'],single,"['The', 'Semantic', 'Network', 'Array', 'Processor', '(SNAP)', 'is', 'a', 'highly', 'parallel', 'array', 'processor', 'fully', 'optimized', 'for', 'semantic', 'network', 'processing', 'with', 'marker-passing', 'mechanism.', 'In', 'order', 'to', 'facilitate', 'efficient', 'propagation', 'of', 'markers', 'and', 'to', 'ease', 'development', 'of', 'applications,', 'a', 'set', 'of', 'marker', 'propagation', 'instructions', 'has', 'been', 'microcoded.', 'SNAP', 'supports', 'propagation', 'of', 'markers', 'containing', '(1)', 'bit-vectors.', '(2)', 'address,', 'and', '(3)', 'numeric', 'value.', 'By', 'limiting', 'content', 'of', 'markers,', 'significant', 'reduction', 'in', 'cost', 'and', 'resource', 'has', 'been', 'attained', 'without', 'undermining', 'performance', 'requirements', 'for', 'knowledge', 'processing.', 'Several', 'AI', 'applications', 'such', 'as', 'natural', 'language', 'processing', 'system,', 'classification', 'system', '<ref type=""single"">[Kim and Moldovan, 1990],</ref>', 'and', 'rule-based', 'system', 'has', 'been', 'developed', 'on', 'SNAP.']",90,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3]"
376ebc0e-173a-486f-affa-6468067738d0,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['A framework for the quantitative evaluation of disentangled representations'],['2018'],['Cian Eastwood;K Christopher;unk Williams'],single,"['In', 'this', 'section', 'we', 'provide', 'a', 'short', 'overview', 'of', 'six', 'widely', 'used', 'disentanglement', 'metrics,', 'highlighting', 'their', 'key', 'differences', 'and', 'commonalities,', 'and', 'refer', 'the', 'readers', 'to', 'the', 'corresponding', 'papers', 'for', 'exact', 'details', 'of', 'computations.', '<ref type=""single"">Eastwood and Williams (2018)</ref>', 'define', 'three', 'criteria', 'for', 'disentangled', 'representations:', 'disentanglement,', 'which', 'measures', 'the', 'degree', 'of', 'one', 'dimension', 'only', 'encoding', 'information', 'about', 'no', 'more', 'than', 'one', 'generative', 'factor,', 'completeness,', 'which', 'measures', 'whether', 'a', 'generative', 'factor', 'is', 'only', 'captured', 'by', 'one', 'latent', 'variable,', 'informativeness,', 'which', 'measures', 'the', 'degree', 'by', 'which', 'representations', 'capture', 'exact', 'values', 'of', 'the', 'generative', 'factors.', '2', 'They', 'design', 'a', 'series', 'of', 'classification', 'tasks', 'to', 'predict', 'the', 'value', 'of', 'a', 'generative', 'factor', 'based', 'on', 'the', 'latent', 'code,', 'and', 'extract', 'the', 'relative', 'importance', 'of', 'each', 'latent', 'code', 'for', 'each', 'task', 'to', 'calculate', 'disentanglement', 'and', 'completeness', 'scores.', 'Informativeness', 'score', 'is', 'measured', 'by', 'the', 'accuracy', 'of', 'the', 'classifier', 'directly.', 'Other', 'existing', 'metrics', 'reflect', 'at', 'least', 'one', 'of', 'these', 'three', 'criteria,', 'as', 'summarised', 'in', 'Table', '1', '<ref type=""single"">Higgins et al. (2017)</ref>', 'focus', 'on', 'disentanglement', 'and', 'propose', 'to', 'use', 'the', 'absolute', 'difference', 'of', 'two', 'groups', 'of', 'representations', 'with', 'the', 'same', 'value', 'on', 'one', 'generative', 'factor', 'to', 'predict', 'this', 'generative', 'factor.', 'For', 'perfectly', 'disentangled', 'representations,', 'latent', 'dimensions', 'not', 'encoding', 'information', 'about', 'this', 'generative', 'factor', 'would', 'have', 'zero', 'difference.', 'Hence,', 'even', 'simple', 'linear', 'classifiers', 'could', 'easily', 'identify', 'the', 'generative', 'factors', 'based', 'on', 'the', 'changes', 'of', 'values.', '<ref type=""single"">Kim and Mnih (2018)</ref>', 'consider', 'both', 'disentanglement', 'and', 'completeness', 'by', 'first', 'finding', 'the', 'dimension', 'which', 'has', 'the', 'largest', 'variance', 'when', 'fixing', 'the', 'value', 'on', 'one', 'generative', 'factor,', 'and', 'then', 'using', 'the', 'found', 'dimension', 'to', 'predict', 'that', 'generative', 'factor.', '<ref type=""single"">Kumar et al. (2018)</ref>', 'propose', 'a', 'series', 'of', 'classification', 'tasks', 'each', 'of', 'which', 'uses', 'a', 'single', 'latent', 'variable', 'to', 'predict', 'the', 'value', 'of', 'a', 'generative', 'factor', 'and', 'treat', 'the', 'average', 'of', 'the', 'difference', 'between', 'the', 'top', 'two', 'accuracy', 'scores', 'for', 'each', 'generative', 'factor', 'as', 'the', 'final', 'disentanglement', 'score.']",33,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
37a1935c-b17a-475e-ae29-cf1cf00d3eac,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,"[""What's in a name? are BERT named entity representations just as good for any other name?""]",['2020'],['Sriram Balasubramanian;Naman Jain;Gaurav Jindal;Abhijeet Awasthi;Sunita Sarawagi'],single,"['Moreover,', 'these', 'LLMs', 'are', 'known', 'to', 'have', 'flaws.', 'BERT', 'in', 'particular', 'has', 'been', 'shown', 'to', 'be,', 'in', 'certain', 'scenarios,', 'insensitive', 'to', 'negation', '<ref type=""single"">(Ettinger, 2020)</ref>', 'and', 'word', 'order', '<ref type=""single"">(Pham et al., 2020).</ref>', 'BERT', 'also', 'has', 'inexact', 'representations', 'of', 'numbers', '<ref type=""single"">(Wallace et al., 2019)</ref>', 'and', 'fails', 'to', 'be', 'robust', 'to', 'named', 'entities', '<ref type=""single"">(Balasubramanian et al., 2020).</ref>', 'All', 'of', 'these', 'phenomena', 'could', 'result', 'in', 'poor-quality', 'scores', 'from', 'BERTScore.', 'However,', 'it', 'is', 'difficult', 'to', 'say', 'for', 'certain', 'how', 'these', 'issues', 'might', 'manifest', 'in', 'BERTScore,', 'as', 'it', 'employs', 'BERT', 'in', 'an', 'unsupervised', 'scenario', 'distinct', 'from', 'that', 'of', 'these', 'analyses.']",43,"[0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0]"
37ae9613-35f6-485c-8f11-97dc211149f4,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,['unknown'],['unknown'],['unknown'],single,"['Hanu', 'and', 'Unitary', 'team', '(2020)', 'introduced', 'Detoxify,', 'a', 'comment', 'detection', 'library', 'modeled', 'using', ""HuggingFace's"", 'transformers', '<ref type=""single"">(Wolf et al., 2020)</ref>', 'to', 'identify', 'inappropriate', 'or', 'harmful', 'text', 'online', 'as', 'a', 'result', 'of', 'participation', 'in', 'three', 'such', 'challenges.', 'In', 'a', 'contemporary', 'work,', '<ref type=""single"">Pavlopoulos et al. (2020)</ref>', 'discuss', 'context', 'requirement', 'for', 'toxicity', 'detection.']",15,"[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3834abf2-9ea1-4f00-abdb-899a98fd422b,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,"['unknown', 'Long text generation via adversarial training with leaked information']","['2016', '2018']","['Lantao Yu;Weinan Zhang;Jun Wang;Yong Yu;unk Seqgan', 'Jiaxian Guo;Sidi Lu;Han Cai;Weinan Zhang;Yong Yu;Jun Wang']",group,"['The', 'syntax', 'discriminator', 'takes', 'as', 'input', 'either', 'a', 'real', 'sentence,', 'r', '=', '(r', '1', ',...,', 'r', 'n', '),', 'or', 'a', 'generated', 'one,g', '=', '(g', '1', ',...,', 'g', 'n', ').Similarly', 'to', 'many', 'other', 'works', '(e.g.,', '<ref type=""group"">[9, 23]</ref>', '),', 'the', 'discriminator', 'first', 'transforms', 'its', 'input', 'into', 'an', 'embedding', 'matrix.', 'This', 'embedding', 'allows', 'learning', 'a', 'transformation', 'that', 'condenses', 'the', 'information', 'brought', 'in', 'by', 'each', 'word', 'optimally', 'for', 'any', 'given', 'task.', 'The', 'syntax', 'discriminator', 'is', 'then', 'built', 'using', 'two', 'convolutional', 'layers', 'with', 'ReLU', 'activation', 'functions,', 'followed', 'by', 'a', 'self-attention', 'layer,', 'again', 'followed', 'by', 'two', 'other', 'convolutional', 'layers', 'with', 'ReLU', 'activation', 'functions.', 'The', 'selfattention', 'layer', 'is', 'used', 'to', 'attend', 'to', 'the', 'output', 'of', 'the', 'previous', 'convolutional', 'layer', 'and', 'select', 'the', 'most', 'useful', 'features.', 'The', 'final', 'layers', 'generate', 'the', 'decision.']",34,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3848be40-d7f3-4bbe-a519-21144af097b2,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['unknown'],['2017'],['Max Jaderberg;Valentin Dalibard;Simon Osindero;Wojciech Czarnecki;Jeff Donahue;Ali Razavi;Oriol Vinyals;Tim Green;Iain Dunning;Karen Simonyan'],single,"['To', 'address', 'our', 'considerations', 'related', 'to', 'resource', 'constraints', 'we', 'perform', 'a', 'hyperparameter', 'optimization,', 'that', 'has', 'proven', 'to', 'lead', 'to', 'better', 'solutions', 'in', 'less', 'time.', 'It', 'is', 'based', 'on', 'a', 'population-based', 'learning', '<ref type=""single"">(Jaderberg et al., 2017)</ref>', 'in', 'which', 'a', 'population', 'of', 'models', 'and', 'their', 'hyperparameters', 'are', 'jointly', 'optimized.', 'To', 'this', 'end,', 'we', 'build', 'a', 'validation', 'set', 'by', 'randomly', 'extracting', '10%', 'of', 'the', 'training', 'data.']",31,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
389ddc80-bad8-4408-bc36-7c03b84036a6,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['On using very large target vocabulary for neural machine translation'],['unknown'],['S Jean;K Cho;R Memisevic;Y Bengio'],single,"['In', '<ref type=""single"">[5],</ref>', 'authors', 'propose', 'to', 'carefully', 'organise', 'the', 'batches', 'so', 'that', 'only', 'a', 'subset', 'K', 'of', 'the', 'target', 'vocabulary', 'is', 'possibly', 'generated', 'at', 'training', 'time.', 'This', 'allows', 'the', 'system', 'to', 'train', 'a', 'model', 'with', 'much', 'larger', 'target', 'vocabulary', 'without', 'substantially', 'increasing', 'the', 'computational', 'complexity.', 'Another', 'alternative', 'is', 'proposed', 'by', '<ref type=""single"">[6]</ref>', 'where', 'a', 'structured', 'output', 'layer', '(SOUL)', 'is', 'defined', 'to', 'handle', 'the', 'words', 'not', 'appearing', 'in', 'the', 'shortlist.', 'This', 'allows', 'the', 'system', 'to', 'always', 'apply', 'the', 'softmax', 'normalization', 'on', 'a', 'layer', 'with', 'reduced', 'size.']",1,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
39672bdb-ec13-4e13-9c09-f3a1bd75225f,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Axiomatic attribution for deep networks'],['2017'],['Mukund Sundararajan;Ankur Taly;Qiqi Yan'],single,"['BERT-based', 'models', 'have', 'the', 'advantage', 'that', 'we', 'can', 'directly', 'use', 'the', 'attention', 'scores', 'as', 'explanations', 'of', 'model', 'decisions.', 'For', 'models', 'with', 'other', 'architectures,', 'we', 'can', 'use', 'explanation', 'techniques', 'such', 'as', 'LIME', '<ref type=""single"">(Ribeiro et al., 2016)</ref>', 'or', 'Path', 'Integrated', 'Gradient', 'approaches', '<ref type=""single"">(Sundararajan et al., 2017)</ref>', 'to', 'provide', 'explanations.']",37,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2]"
3abeb9fd-3b54-4c2f-98bf-5359ac433eab,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Models of tabulation for TAG parsing'],['1999'],['M-J Nederhof'],single,"['The', 'space', 'complexity', 'of', 'the', 'algorithm', 'with', 'respect', 'to', 'the', 'length', 'n', 'of', 'the', 'input', 'string', 'is', 'O(n', '5', '),', 'due', 'to', 'the', 'five', 'positions', 'of', 'the', 'input', 'string', 'stored', 'in', 'each', 'item.', 'The', 'time', 'complexity', 'is', 'O(n', '7)', 'due', 'to', 'deduction', 'steps', 'in', 'the', 'set', 'v�::?:},', '0', 'H', '00', '-Yl.', 'To', 'reduce', 'the', 'time', 'complexity', 'we', 'will', 'use', 'a', 'technique', 'similar', 'to', 'that', 'used', 'in', '<ref type=""group"">[5, 2]</ref>', 'to', 'reduce', 'the', 'complexity', 'of', 'the', 'tabular', 'interpretations', 'of', 'automata', 'for', 'tree', 'adjoining', 'languages.', 'In', 'this', 'case,', 'we', 'split', 'each', 'deduction', 'step', 'in', 'v�::?:},', '0', 'H', '00', '-Yl', 'into', 'two', 'different', 'steps', 'such', 'that', 'their', 'final', 'complexity', 'is', 'at', 'most', 'O(n', '6', ').', 'The', 'resulting', 'parsing', 'schema', 'is', 'defined', 'by', 'the', 'following', 'parsing', 'system.', '6)', 'for', 'a', 'linear', 'indexed', 'grammar', 'g', 'and', 'a', 'input', 'string', 'a', '1', '...', 'an', 'is', 'defined', 'as', 'fo', 'llows:,', '-,', '-],', 'The', 'LIG', 'so', 'generated', 'does', 'not', 'satisfy', 'our', 'definition', 'of', 'shared', 'forest', 'because', 'single', 'parse', 'trees', 'can', 'not', 'be', 'extracted', 'in', 'linear', 'time.', 'Vijay-Shanker', 'and', 'Weir', '<ref type=""single"">[18]</ref>', 'try', 'to', 'solve', 'this', 'problem', 'by', 'defining', 'a', 'non-deterministic', 'finite', 'state', 'automaton', 'that', 'determines', 'if', 'a', 'given', 'LIGed', 'forest', 'symbol', '(A,', 'i,', 'j)[a:]', 'derives', 'a', 'string', 'of', 'terminals.', 'A', 'similar', 'finite-state', 'automata', 'is', 'also', 'defined', 'by', 'Nederhof', 'in', '<ref type=""single"">[11].</ref>']",208,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
3b1d9793-0def-436a-8d1f-213082f8a9a1,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['Handling Structural Divergences and Recovering Dropped Arguments in a Korean/English Machine Translation System'],['2000'],['H Grune;C Bal;K Jacobs;unk Langendoen;U Chichester;B Han;M Lavoie;O Palmer;R Rambow;T Kittredge;N Korelsky;M Kim;unk Kim'],single,"['The', 'system', 'of', '<ref type=""single"">Han et al. (2000)</ref>', 'pairs', 'two', 'dependency', 'trees', 'based', 'on', 'a', 'Deep', 'Syntactic', 'Structure', '(DSyntS)', 'of', 'Meaning', 'Text', 'Theory', '(MTT)', '<ref type=""single"">(Mel\'čuk, 1988),</ref>', 'a', 'dependency', 'representation', 'composed', 'of', 'nodes', 'labeled', 'by', 'lexemes', 'that', 'correspond', 'to', 'meaning-bearing', 'words', '(nouns,', 'verbs,', 'adjectives,', 'adverbs)', 'and', 'directed', 'arcs', 'with', 'dependency', 'relation', 'labels.', 'Transfer', 'rules', 'are', 'also', 'represented', 'by', 'DSyntS', 'trees,', 'with', 'variables.', '3', 'The', 'goal', 'of', 'this', 'particular', 'dependency', 'representation', 'is', 'to', 'minimise', ""'spurious'"", 'structural', 'divergences,', 'such', 'as', 'when', 'a', 'preposition', 'in', 'one', 'language', 'is', 'represented', 'by', 'a', 'verbal', 'inflection', 'in', 'the', 'other.', 'However,', 'some', 'divergences', 'still', 'occur,', 'as', 'in', '(1).', 'The', 'transfer', 'rule', 'then', 'requires', 'that', 'the', 'two', 'nodes', 'is', 'and', 'small', 'pair', 'with', 'the', 'single', 'node', 'cakayo:', 'a', 'transfer', 'rule', 'for', 'Figure', '1,', 'treating', 'them', 'as', 'a', 'gCN,', 'would', 'be', 'as', 'in', 'the', 'righthand', 'side', 'of', 'that', 'figure.', '4', 'However,', 'there', 'are', 'constructions', 'which', 'cannot', 'be', 'handled', 'in', 'such', 'a', 'way.', 'Consider', 'the', 'translation', 'pair', 'in', '(3).']",3,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3b216670-843b-43f5-ab05-3fa73cc437f8,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Syntax augmented machine translation via chart parsing'],['2006'],['A Zollmann;A Venugopal'],single,"['Hierarchical', 'rules', 'are', 'extracted', 'from', 'the', 'training', 'corpus', 'by', 'subtracting', 'continuous', 'phrase-pairs', 'attested', 'in', 'the', 'translation', 'table', 'recursively', 'from', 'longer', 'phrases', 'and', 'replacing', 'them', 'with', 'the', 'non-terminal', 'symbol', 'X.', 'Non-terminals', 'in', 'hierarchical', 'rules', 'act', 'as', 'placeholders', 'that', 'are', 'replaced', 'with', 'other', 'phrases', 'during', 'translation', 'in', 'a', 'bottom-up', 'fashion.', 'Hierarchical', 'rules', 'are', 'extracted', 'from', 'the', 'training', 'corpus', 'without', 'using', 'any', 'syntactic', 'information.', 'As', 'the', 'resulting', 'system', 'is', 'syntactically', 'unaware,', 'the', 'HPB', 'SMT', 'system', 'can', 'produce', 'ungrammatical', 'translations.', 'Therefore,', 'several', 'approaches', 'have', 'tried', 'to', 'provide', 'the', 'HPB', 'SMT', 'system', 'with', 'syntactic', 'information.', 'Syntax', 'augmented', 'Machine', 'Translation', '(SAMT)', '<ref type=""single"">[11]</ref>', 'uses', 'target-side', 'phrase-structure', 'grammar', 'syntactic', 'trees', 'to', 'label', 'non-terminals', 'in', 'hierarchical', 'rules.', 'These', 'non-terminal', 'labels', 'represent', 'syntactic', 'constraints', 'imposed', 'on', 'target', 'phrase', 'replacements', 'during', 'translation', 'aiming', 'to', 'produce', 'more', 'grammatical', 'translations.']",95,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3beab6e0-900b-4032-a08f-7caf0f91cc74,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,"['End-to-end neural information status classification', 'Bridging', 'Collective classification for fine-grained information status', 'Probing for bridging inference in transformer language models', 'Which bridges for bridging definite descriptions', 'Bridging resolution: Making sense of the state of the art', 'Experimental pragmatics: Towards testing relevance-based predictions about anaphoric bridging inferences', 'A corpus-based investigation of definite description use', 'Bashi: A corpus of Wall Street Journal articles annotated with bridging links', 'Experiments on bridging across languages and genres', 'Towards bridging resolution in German: Data analysis and rule-based experiments', 'A rule-based system for unrestricted bridging resolution: Recognizing bridging anaphora and finding links to antecedents', 'Unrestricted bridging resolution', 'Integrating predictions from neural-network relation classifiers into coreference and bridging resolution', 'Rule-and learning-based methods for bridging resolution in the ARRAU corpus', 'unknown', 'Generic noun phrases and annotation of coreference and bridging relations in the Prague dependency treebank', 'A deterministic algorithm for bridging anaphora resolution', 'Definite associative anaphora']","['2021', '1975', '2012', '2021', '2003', '2021', '2001', '1998', '2018', '2016', '2018', '2014', '2018', '2018', '2018', 'unknown', '2013', '2018', '1998']","['Yufang Hou', 'H Herbert;unk Clark', 'Katja Markert;Yufang Hou;Michael Strube', 'Yufang Onkar Arun Pandit;unk Hou', 'Claire Gardent;Hélène Manuélian;Eric Kow', 'Hideo Kobayashi;Vincent Ng', 'Tomoko Matsui', 'Massimo Poesio;Renata Vieira', 'Ina Rösiger', 'Yulia Grishina', 'Janis Pagel;Ina Roesiger', 'Yufang Hou;Katja Markert;Michael Strube', 'Yufang Hou;Katja Markert;Michael Strube', 'Ina Roesiger;Maximilian Köper;Kim Nguyen;Sabine Schulte Im Walde', 'Ina Rösiger', 'unknown', 'Anna Nedoluzhko', 'Yufang Hou', 'Sebastian Loebner']",group,"['A', 'closely', 'related', 'linguistic', 'concept', 'and', 'an', 'established', 'task', 'in', 'the', 'last', 'decade', 'is', 'bridging', 'anaphora', 'resolution', '<ref type=""group"">(Clark, 1975, Loebner, 1998, Poesio and Vieira, 1998, Matsui, 2001, Gardent et al., 2003, Markert et al., 2012, Hou et al., 2013a,b, Nedoluzhko, 2013, Hou et al., 2014, Grishina, 2016, Rösiger, 2018a, Hou et al., 2018, Hou, 2018a Hou, ,b, 2020,, Pagel and Roesiger, 2018, Roesiger et al., 2018a, Rösiger, 2018b, Pandit and Hou, 2021, Kobayashi and Ng, 2021, Hou, 2021).</ref>', 'Both', 'bridging', 'anaphora', 'resolution', 'and', 'NP', 'Enrichment', 'relate', 'entities', 'mentioned', 'in', 'the', 'text', 'via', 'non-identity', 'relations.', 'However,', 'there', 'are', 'a', 'number', 'of', 'major', 'differences', 'between', 'bridging', 'and', 'NP', 'Enrichment.', 'These', 'differences', 'are', 'summarized', 'in', 'Table', '8,', 'and', 'expanded', 'upon', 'in', 'what', 'follows.']",17,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3c6bcfd4-a6d0-48e8-8772-44e766b159b0,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['Sparse, dense, and attentional representations for text retrieval. CoRR, abs']",['unknown'],['Yi Luan;Jacob Eisenstein;Kristina Toutanova;Michael Collins'],single,"['In', 'this', 'paper,', 'we', 'focus', 'on', 'addressing', 'these', 'challenges', 'so', 'as', 'to', 'effectively', 'train', 'a', 'dual-encoder', 'retriever', 'for', 'open-domain', 'QA.', 'We', 'propose', 'an', 'optimized', 'training', 'approach,', 'called', 'RocketQA,', 'to', 'improving', 'dense', 'passage', 'retrieval.', 'Considering', 'the', 'above', 'challenges,', 'we', 'make', 'three', 'major', 'technical', 'contributions', 'in', 'RocketQA.', 'First,', 'RocketQA', 'introduces', 'cross-batch', 'negatives.', 'Comparing', 'to', 'inbatch', 'negatives,', 'it', 'increases', 'the', 'number', 'of', 'available', 'negatives', 'for', 'each', 'question', 'during', 'training,', 'and', 'alleviates', 'the', 'discrepancy', 'between', 'training', 'and', 'inference.', 'Second,', 'RocketQA', 'introduces', 'denoised', 'hard', 'negatives.', 'It', 'aims', 'to', 'remove', 'false', 'negatives', 'from', 'the', 'top-ranked', 'results', 'retrieved', 'by', 'a', 'retriever,', 'and', 'derive', 'more', 'reliable', 'hard', 'negatives.', 'Third,', 'RocketQA', 'leverages', 'large-scale', 'unsupervised', 'data', '""labeled""', 'by', 'a', 'cross-encoder', '(as', 'shown', 'in', 'Figure', '1b)', 'for', 'data', 'augmentation.', 'Though', 'inefficient,', 'the', 'cross-encoder', 'architecture', 'has', 'been', 'found', 'to', 'be', 'more', 'capable', 'than', 'the', 'dual-encoder', 'architecture', 'in', 'both', 'theory', 'and', 'practice', '<ref type=""single"">(Luan et al., 2020).</ref>', 'Therefore,', 'we', 'utilize', 'a', 'cross-encoder', 'to', 'generate', 'highquality', 'pseudo', 'labels', 'for', 'unlabeled', 'data', 'which', 'are', 'used', 'to', 'train', 'the', 'dual-encoder', 'retriever.', 'The', 'contributions', 'of', 'this', 'paper', 'are', 'as', 'follows:']",139,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0]"
3cc60145-6873-48c5-844f-3009ebc4eec0,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Character-level convolutional networks for text classification'],['2015'],['Xiang Zhang;Junbo Zhao;Yann Lecun'],single,"['To', 'examine', 'the', 'performance', 'of', 'these', 'models', 'on', 'real-world', 'downstream', 'task', 'setting,', 'we', 'consider', 'the', 'classification', 'task.', 'For', 'our', 'classification', 'datasets,', 'we', 'use', 'DBpedia', '(14', 'classes)', 'and', 'Yahoo', 'Question', '(10', 'classes)', '<ref type=""single"">(Zhang et al., 2015).</ref>', 'Each', 'class', 'of', 'these', 'two', 'datasets', 'has', '(10k,', '1k,', '1k)', 'randomly', 'chosen', 'sentences', 'in', '(train,', 'dev,', 'test)', 'sets.', 'We', 'train', 'Vanilla-VAE,', 'β-VAE', '(β', '=', '0.2),', 'CCI-VAE', '(C', '=', '10),', 'and', 'MAT-VAE', '(β', '=', '0.01,', 'λ', '=', '0.1)', 'from', 'Table', '3', 'on', 'DBpedia', 'and', 'Yahoo', '(without', 'the', 'labels),', 'then', 'freeze', 'the', 'trained', 'encoders', 'and', 'place', 'a', 'classifier', 'on', 'top', 'to', 'use', 'the', 'mean', 'vector', 'representations', 'from', 'the', 'encoder', 'as', 'a', 'feature', 'to', 'train', 'a', 'classifier.']",31,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3ce3908a-1b08-425b-bd5e-b04c41286e0b,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['unknown'],['unknown'],['unknown'],single,"['In', 'all', 'configurations,', 'the', 'performance', 'in', 'terms', 'of', 'EM', 'and', 'F1', 'on', 'PIAF', 'remains', 'significantly', 'lower', 'than', 'that', 'obtained', 'on', 'FQuAD', 'since', 'the', 'PIAF', 'corpus', 'does', 'not', 'include', 'multiple', 'responses', 'as', 'pointed', 'out', 'by', 'd', '<ref type=""single"">\'Hoffschmidt et al. (2020).</ref>', 'Unsurprisingly,', 'PIAF', 'dev', 'offer', 'a', 'more', 'challenging', 'evaluation', 'set,', 'where', 'the', 'answer', 'extraction', 'performance', 'are', 'lower.', 'Indeed,', 'the', 'corpus', 'is', 'more', 'diversified', 'with', 'questions', 'on', '191', 'different', 'Wikipedia', 'articles,', 'whereas', 'on', 'FQuAD', 'dev', 'it', 'only', 'covers', '18.']",35,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3d02c644-ec6c-4297-b63f-fe920f6be8b8,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Enriching word vectors with subword information'],['2017'],['Piotr Bojanowski;Edouard Grave;Armand Joulin;Tomas Mikolov'],single,"['The', 'latest', 'article', 'on', 'the', 'topic', 'is', '<ref type=""single"">(Koyyalagunta et al., 2021),</ref>', 'in', 'which,', 'in', 'addition', 'to', 'the', 'previously', 'used', 'Skip-gram', 'and', 'GloVe', 'word', 'embeddings,', 'to', 'produce', 'their', 'similarity', 'matrices', 'they', 'use', 'FastText', '<ref type=""single"">(Bojanowski et al., 2017),</ref>']",29,"[3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1]"
3d8cf0cc-d078-44ae-b357-44e848ef41dc,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Bridging anaphora resolution as question answering'],['2020'],['Yufang Hou'],single,"['sufficient', 'to', 'solve', 'the', 'task,', 'as', 'was', 'also', 'argued', 'in', '<ref type=""single"">Hou (2020)</ref>', 'and', '<ref type=""single"">Pandit and Hou (2021).</ref>', 'Finally,', 'we', 'note', 'an', 'interesting', 'trend', 'that', 'the', 'decoupled', 'variant', 'favors', 'recall', 'whereas', 'the', 'coupled', 'variant', 'favors', 'precision,', 'across', 'all', 'models.', 'In', 'summary,', 'all', 'models', 'perform', 'substantially', 'below', 'human', 'agreement,', 'leaving', 'a', 'large', 'room', 'for', 'improvement.']",10,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3dc66c6c-5524-4872-9248-093f0622d9dc,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Towards hierarchical importance attribution: Explaining compositional semantics for neural sequence models'],['2020'],['Xisen Jin;Junyi Du;Zhongyu Wei;Xiangyang Xue;Xiang Ren'],single,"['Our', 'study', 'is', 'also', 'related', 'to', 'attribution', 'approaches,', 'which', 'aims', 'to', 'find', 'features', 'or', 'regions', 'of', 'input', 'that', 'are', 'important', 'for', 'tasks.', 'Different', 'types', 'of', 'techniques,', 'including', 'gradient-based', '<ref type=""group"">(Selvaraju et al., 2017) and post-hoc (Ribeiro et al., 2018),</ref>', 'are', 'applied', 'for', 'reinforcement', 'learning', '<ref type=""single"">(Mott et al., 2019),</ref>', 'computer', 'vision', '<ref type=""single"">(Adebayo et al., 2018),</ref>', 'and', 'text', 'classification', '<ref type=""single"">(Jin et al., 2020).</ref>', 'While', 'these', 'works', 'focus', 'on', 'interpreting', 'model', 'behaviors,', 'we', 'aim', 'to', 'find', 'salient', 'words', 'beyond', 'input', 'and', 'utilize', 'them', 'as', 'action', 'representations.']",41,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
3e0006fc-3207-4693-934d-8b6ac029b963,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['An open-source shallow-transfer machine translation engine for the romance languages of Spain'],['2005'],['Corbí-Bellot Antonio;M Mikel;L Forcada;Sergio Ortiz-Rojas;Juan Pérez-Ortiz;Gema Sánchez-Ramirez;Felipe Sánchez-Martínez;Iñaki Alegria;Aingeru Mayor;Kepa Sarasola'],single,"['All', 'methods', 'and', 'materials', 'discussed', 'in', 'this', 'paper', 'were', 'tested', 'on', 'a', 'fully', 'functional', 'machine', 'translation', 'system', 'based', 'on', 'Apertium', '<ref type=""single"">(Armentano-Oller et al., 2006)</ref>', 'and', '<ref type=""single"">(Corbí-Bellot et al., 2005),</ref>', 'an', 'opensource', 'RBMT', 'toolkit.']",22,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1]"
3e575477-fac5-45db-86c2-02f4fb005e5d,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,['Efficient estimation of word representations in vector space'],['2013'],['Tomas Mikolov;Kai Chen;Greg Corrado;Jeffrey Dean'],single,"['The', 'log-bilinear', 'model', 'for', 'conditional', 'word', 'probabilities', 'was', 'introduced', 'in', 'a', 'language', 'modeling', 'context', 'by', '<ref type=""group"">Mnih and Hinton (2007, 2008).</ref>', '<ref type=""single"">Mikolov et al. (2013a)</ref>', 'influentially', 'proposed', 'to', 'use', 'the', 'vector', 'representations', 'output', 'by', 'the', 'word', 'encoder', 'in', 'such', 'a', 'model', 'as', 'general', 'word', 'embeddings.', 'The', 'current', 'work', 'aims', 'to', 'return', 'log-bilinear', 'models', 'to', 'their', 'language', 'modeling', 'roots,', 'evaluating', 'the', 'capabilities', 'of', 'these', 'models', 'to', 'estimate', 'co-occurrence', 'probabilities', 'using', 'pretrained', 'embeddings', 'as', 'input,', 'with', 'a', 'focus', 'on', 'word', 'distributions', 'where', 'training', 'data', 'is', 'limited.', 'Here', 'the', 'target', 'word', 'vocabulary', 'is', 'typically', 'small', 'enough', 'that', 'the', 'partition', 'function', '(Eq.', '2)', 'can', 'be', 'computed', 'directly', 'on', 'modern', 'hardware,', 'so', 'that', 'approximations', 'such', 'as', 'noisecontrastive', 'estimation', '<ref type=""single"">(Mikolov et al., 2013b)</ref>', 'are', 'not', 'necessary.']",16,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3e8822c0-a9c5-4056-a38a-f8cc71d5dfd7,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Modeling frames in argumentation'],['2019'],['Yamen Ajjour;Milad Alshomary;Henning Wachsmuth;Benno Stein'],single,"['There', 'has', 'been', 'active', 'research', 'in', 'NLP', 'to', 'understand', 'different', 'mechanisms', 'of', 'argumentation', 'computationally.', 'Argumentative', 'relations', 'have', 'been', 'found', 'to', 'be', 'associated', 'with', 'various', 'statistics,', 'such', 'as', 'discourse', 'markers', '<ref type=""single"">(Opitz and Frank, 2019),</ref>', 'sentiment', '<ref type=""single"">(Allaway and McKeown, 2020),</ref>', 'and', 'use', 'of', 'negating', 'words', '<ref type=""single"">(Niven and Kao, 2019).</ref>', 'Further,', 'as', 'framing', 'plays', 'an', 'important', 'role', 'in', 'debates', '<ref type=""single"">(Ajjour et al., 2019),</ref>', 'different', 'stances', 'for', 'a', 'topic', 'emphasize', 'different', 'points,', 'resulting', 'in', 'strong', 'thematic', 'correlations', '<ref type=""single"">(Lawrence and Reed, 2017).</ref>', 'Such', 'thematic', 'associations', 'have', 'been', 'exploited', 'in', 'stance', 'detection', 'and', 'dis/agreement', 'classification.', 'Stance', 'detection', '<ref type=""group"">(Allaway and McKeown, 2020, Stab et al., 2018, Xu et al., 2018)</ref>', 'aims', 'to', 'classify', 'a', 'statement', 'as', 'pro', 'or', 'con', 'with', 'respect', 'to', 'a', 'topic,', 'while', 'dis/agreement', 'classification', '<ref type=""group"">(Chen et al., 2018, Hou and Jochim, 2017, Rosenthal and McKeown, 2015)</ref>', 'aims', 'to', 'decide', 'whether', 'two', 'statements', 'are', 'from', 'the', 'same', 'or', 'opposite', 'stance(s)', 'for', 'a', 'given', 'topic.', 'Topics', 'are', 'usually', 'discrete,', 'and', 'models', 'often', 'learn', 'thematic', 'correlations', 'between', 'a', 'topic', 'and', 'a', 'stance', '<ref type=""single"">(Xu et al., 2019).</ref>', 'Our', 'work', 'is', 'slightly', 'different', 'as', 'we', 'classify', 'the', 'direct', 'support', 'or', 'attack', 'relation', 'between', 'two', 'natural', 'statements.']",47,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
3ea81d3a-19f2-4906-9aa1-107466d3cc8c,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,"['Entity Linking via Joint Encoding of Types, Descriptions, and Context', 'Fine-Grained Entity Typing for Domain Independent Entity Linking']","['2017', '2020']","['Nitish Gupta;Sameer Singh;Dan Roth', 'Yasumasa Onoe;Greg Durrett']",group,"['The', 'MOST', 'FREQUENT', 'baseline', 'chooses', 'the', 'most', 'frequently', 'observed', 'entity', 'for', 'a', 'given', 'mention', 'as', 'a', 'prediction,', 'based', 'on', 'a', 'prior', 'probability', 'p', 'prior', 'computed', 'from', 'link', 'counts', 'on', 'Wikipedia.', 'All', 'baselines', 'except', 'MOST', 'FREQUENT', 'combine', 'the', 'classifier', 'output', 'and', 'the', 'prior', 'probability', 'to', 'make', 'a', 'prediction:', 'arg', 'max', 'c', 'p', 'prior', '(c)', '+', 'p', 'classifier', '(c).', '10', 'data.', 'Our', 'approach', 'outperforms', 'all', 'baselines,', 'indicating', 'that', 'our', 'entity', 'representations', 'include', 'useful', 'information', 'about', 'entities', 'out-of-the-box.', 'Such', 'a', 'performance', 'gap', 'is', 'expected', 'since', 'our', 'entity', 'representations', 'can', 'directly', 'encode', 'some', 'factual', 'knowledge', 'from', 'Wikipedia.', 'However,', 'these', 'results', 'also', 'imply', 'that', 'pre-trained', 'LMs', 'do', 'not', 'have', 'enough', 'factual', 'information', 'out-of-the-box,', 'they', 'may', 'rely', 'on', 'in-domain', 'fine-tuning', 'to', 'achieve', 'high', 'performance', 'in', 'the', 'target', 'domain,', 'and', 'often', 'fail', 'to', 'generalize', 'to', 'new', 'settings.', 'Note', 'that', 'while', 'these', 'accuracies', 'are', 'significantly', 'below', 'the', 'supervised', 'state-of-the-art', '(95%),', 'they', 'are', 'competitive', 'with', 'the', '""zero-shot""', 'entity', 'results', 'from', 'recent', 'past', 'work', '<ref type=""group"">(Gupta et al., 2017, Onoe and Durrett, 2020).</ref>']",154,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]"
3f17c099-54eb-4a33-94d2-128373dac908,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Common voice: A massivelymultilingual speech corpus'],['2019'],['Rosana Ardila;Megan Branson;Kelly Davis;Michael Henretty;Michael Kohler;Josh Meyer;Reuben Morais;Lindsay Saunders;Francis Tyers;Gregor Weber'],single,"['For', 'Kinyarwanda', 'pre-training', 'data,', 'we', 'use', 'the', 'Common', 'Voice', '(CV)', 'Kinyarwanda', '6.1', 'subset', '<ref type=""single"">(Ardila et al., 2019).</ref>', 'Again,', 'we', 'utilize', 'both', 'the', 'audio', 'files', 'and', 'transcriptions.', 'Due', 'to', 'the', 'large', 'size', 'of', 'the', 'CV', '6.1', 'Kinyarwanda', 'subset,', 'we', 'processed', 'only', 'about', '80%', 'of', 'the', 'audio', 'files.']",13,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
3f4c2197-2e17-4119-af99-0f6219d9b681,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['BAE: BERT-based adversarial examples for text classification'],['2020'],['Siddhant Garg;Goutham Ramakrishnan'],single,"['(2)', 'The', 'BAE', 'attack', '<ref type=""single"">(Garg and Ramakrishnan, 2020)</ref>', 'generates', 'coherent', 'adversarial', 'examples', 'by', 'masking', 'and', 'replacing', 'words', 'using', 'BERT.', 'For', 'both', 'methods', 'we', 'use', 'the', 'implementation', 'provided', 'by', 'TextAttack', '<ref type=""single"">(Morris et al., 2020).</ref>']",4,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
3f58355b-e8f5-44e9-b287-d200a83c0a2b,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['For', 'the', 'Transformer', '<ref type=""single"">(Vaswani et al., 2017),</ref>', 'we', 'conducted', 'a', 'model', 'architecture', 'and', 'hyperparameter', 'search', '(layers,', 'learning', 'rate,', 'MLP', 'dimensions,', 'dropout', 'rate,', 'Encoder', 'vs.', 'Encoder-Decoder)', 'on', 'the', 'dev', 'set.', 'The', 'selected', 'model', 'was', 'composed', 'of', 'four', 'encoder-blocks', 'and', 'a', 'final', 'dense', 'layer', 'that', 'projects', 'the', 'output', 'of', 'the', 'last', 'encoder-block', 'onto', 'the', 'PoS', 'tags', 'via', 'a', 'softmax', 'function.', 'We', 'used', 'the', 'Adam', 'optimiser', 'and', 'early', 'stopping.', 'The', 'implementation', 'is', 'based', 'on', 'the', 'WMT', 'example', '2', 'of', ""Google's"", 'novel', 'ML', 'frameworks', 'Flax/Jax.', 'Table', '2', 'lists', 'the', 'selected', 'hyperparameters.', 'The', 'Transformer', 'received', 'EEG', 'channels', 'x', 'time', 'points', 'as', 'inputs', 'and', 'provided', 'a', 'classification', 'response', 'for', 'the', 'entire', 'time', 'window.']",3,"[0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
3f63a9d7-2397-4cbf-b303-ae1b4eca420a,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['unknown'],['1987'],['Danielle Corbin'],single,"['The', 'relationship', 'between', 'productivity', 'and', 'regularity', 'is', 'discussed', 'by', '<ref type=""single"">Corbin (1987).</ref>', 'In', 'a', 'computational', 'context,', 'the', 'regularity', 'of', 'a', 'word', 'formation', 'rule', 'is', 'what', 'makes', 'it', 'possible', 'to', 'describe', 'it', 'in', 'the', 'form', 'of', 'a', 'procedure', 'which', 'can', 'be', 'used', 'to', 'recognize', 'new', 'words.']",9,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4094666a-afe7-4032-a908-5d7b626764de,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Modeling relational data with graph convolutional networks'],['2018'],['Michael Schlichtkrull;N Thomas;Peter Kipf;Rianne Bloem;unk Van Den;Ivan Berg;Max Titov;unk Welling'],single,"['To', 'model', 'the', 'relational', 'information', 'in', 'the', 'commonsen', 'KG,', 'we', 'employ', 'the', 'relational', 'graph', 'convolutional', 'network', '(R-GCN)', '<ref type=""single"">(Schlichtkrull et al., 2018)</ref>', 'which', 'generalizes', 'GCN', 'with', 'relation', 'specific', 'weight', 'matrices.', 'We', 'follow', '<ref type=""single"">Vashishth et al. (2020)</ref>', 'and', '<ref type=""single"">Ji et al. (2020)</ref>', 'to', 'use', 'a', 'non-parametric', 'compositional', 'operation', 'ϕ(•)', 'to', 'combine', 'the', 'concept', 'node', 'embedding', 'and', 'the', 'relation', 'embedding.', 'Specifically,', 'given', 'the', 'input', 'subgraph', 'G', 'x', '=', '{V', 'x,', 'E', 'x}', 'and', 'an', 'R-GCN', 'with', 'L', 'layers,', 'we', 'update', 'the', 'embedding', 'of', 'each', 'node', 'v', '∈', 'V', 'x', 'at', 'the', '(l+1)-th', 'layer', 'by', 'aggregating', 'information', 'from', 'the', 'embeddings', 'of', 'its', 'neighbours', 'in', 'N', '(v)', 'at', 'the', 'l-th', 'layer:']",17,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4120f023-8660-4b22-bd4d-ab0c1317e0b7,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['A semantico-syntactic approach to event-mention detection and extraction in hindi'],['2019'],['Jaipal Goud;Pranav Goel;Alok Debnath;Suhan Prabhu;Manish Shrivastava'],single,"['5.', 'For', 'Hindi,', 'we', 'use', 'the', 'gold-standard', 'corpus', 'of', '<ref type=""single"">Goud et al. (2019b),</ref>', 'which', 'consists', 'of', '810', 'event', 'annotated', 'news', 'articles', 'based', 'on', 'modified', 'TimeML', 'rules.', 'The', 'dataset', 'has', '242,201', 'tokens', 'and', '20,190', 'event', 'mentions.']",9,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
413b4549-3b7a-464c-baac-1958bcb8bce9,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Improving zero and few-shot abstractive summarization with intermediate fine-tuning and data augmentation'],['2021'],['Alexander Fabbri;Simeng Han;Haoyuan Li;Haoran Li;Marjan Ghazvininejad;Shafiq Joty;Dragomir Radev;Yashar Mehdad'],single,"['BART', 'movistar', 'rider', 'alejandro', 'valverde', 'won', 'fleche', 'wallonne', 'on', 'wednesday.', 'team', ""sky's"", 'chris', 'froome', 'fell', 'in', 'the', 'final', '12km', 'but', 'finished', 'the', 'race.', 'philippe', 'gilbert', 'pulled', 'out', 'of', 'the', 'race', 'after', 'a', 'bad', 'crash', '50km', 'from', 'the', 'end.', 'click', 'here', 'for', 'more', 'cycling', 'news.', '2021,', '<ref type=""single"">Fabbri et al., 2021)</ref>', 'has', 'shown', 'that', 'few-shot', 'learning', 'can', 'be', 'an', 'effective', 'fine-tuning', 'method', 'of', 'pre-trained', 'models', 'for', 'text', 'generation', 'tasks.', 'Therefore,', 'we', 'investigate', 'our', ""model's"", 'performance', 'in', 'a', 'few-shot', 'setting.', 'Specifically,', 'we', 'randomly', 'sample', '100/1000', 'examples', 'from', 'the', 'training', 'set', 'of', 'CNNDM/XSum,', 'and', 'fine-tune', 'the', 'models', 'that', 'are', 'pre-trained', 'using', 'MLE', 'loss', 'on', 'those', 'examples.', 'More', 'training', 'details', 'can', 'be', 'found', 'in', 'Appendix', 'C.', 'The', 'results', 'are', 'shown', 'in', 'Tab.', '11.', 'All', 'experiments', 'are', 'repeated', 'three', 'times,', 'and', 'the', 'reported', 'results', 'are', 'the', 'average', 'performance.', 'The', 'results', 'indicate', 'that', 'our', 'model', 'can', 'achieve', 'improvement', 'over', 'the', 'baseline', 'model', 'under', 'the', 'few-shot', 'learning', 'setting', 'with', 'a', 'small', 'computational', 'overhead.']",45,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
41648b62-3363-4ef4-ba4d-d705be2967ed,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Classical structured prediction losses for sequence to sequence learning'],['2018'],"[""Sergey Edunov;Myle Ott;Michael Auli;David Grangier;Marc'aurelio Ranzato""]",single,"['where', 'S', 'i', 'and', 'S', 'j', 'are', 'two', 'different', 'candidate', 'summaries', 'and', 'ROUGE(S', 'i,', 'S', '*)', '&gt,', 'ROUGE(S', 'j,', 'S', '*', '),', '∀i,', 'j,', 'i', '&lt,', 'j.', 'λ', 'ij', 'is', 'the', 'margin', 'multiplied', 'by', 'the', 'difference', 'in', 'rank', 'between', 'the', 'candidates,', 'i.e.,λ', 'ij', '=', '(j', '−', 'i)', '*', 'λ.', 'f', '(S', 'i)', 'is', 'the', 'length-normalized', 'estimated', 'log-probability', '3', 'f', '(S)', '=', 'l', 't=1', 'log', 'p', 'g', 'θ', '(s', 't', '|D,', 'S', '&lt,t,', 'θ)', '|S|', 'α', '(9)where', 'α', 'is', 'the', 'length', 'penalty', 'hyperparameter.', 'This', 'loss', 'gives', 'the', 'abstractive', 'model', 'a', 'dual', 'purpose,', 'first', 'as', 'a', 'reference-free', 'evaluation', 'model,', 'which', 'can', 'be', 'used', 'in', 'a', 'two-stage', 'summarization', 'pipeline,', 'where', 'it', 'is', 'used', 'to', 'score', 'the', 'candidates', 'generated', 'by', 'a', 'pre-trained', 'generation', 'model', 'and', 'select', 'the', 'final', 'output', 'from', 'them.', 'However,', 'since', 'the', 'autoregressive', 'generation', 'depends', 'on', 'both', 'the', 'token-level', 'prediction', 'accuracy', 'and', 'sequencelevel', 'coordination,', 'the', 'model', 'fine-tuned', 'with', 'the', 'contrastive', 'loss', 'alone', 'can', 'no', 'longer', 'be', 'used', 'as', 'a', 'generation', 'model.', 'Multi-task', 'Fine-tuning', 'Following', '<ref type=""single"">Edunov et al. (2018),</ref>', 'we', 'combine', 'the', 'contrastive', '(Eq.', '8)', 'and', 'cross-entropy', '(Eq.', '3)', 'losses', 'to', 'preserve', 'the', 'generation', 'ability', 'of', 'the', 'pre-trained', 'abstractive', 'model:']",162,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
426e4634-6cc5-4bcb-94bb-c4543837c3a7,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,"['Seven reasons why eyetracking will fundamentally change vr', 'The past, present, and future of gaze-enabled handheld mobile devices: survey and lessons learned', 'Hybrid eye-tracking on a smartphone with cnn feature extraction and an infrared 3d model']","['2019', '2018', '2020']","['Sol unk', 'Mohamed Khamis;Florian Alt;Andreas Bulling', 'Braiden Brousseau;Jonathan Rose']",group,"['Furthermore,', 'when', 'the', 'environment', 'is', 'noisy,', 'or', 'the', 'communication', 'partner', 'suffers', 'from', 'a', 'motor', 'or', 'cognitive', 'impairment,', 'multimodal', 'integration', 'plays', 'a', 'more', 'critical', 'role.', 'Noise', 'in', 'communication', 'can', 'originate', 'from', 'various', 'sources.', 'It', 'can', 'be', 'linguistic', 'noise', '(e.g.', 'spelling', 'mistakes,', 'complex', 'attachments),', 'visual', 'ambiguities', '(e.g.', 'clutter', 'in', 'the', 'environment,', 'occlusions)', 'or', 'an', 'acoustic', 'noise.', 'Instead', 'of', 'waiting', 'for', 'clarification,', 'combining', 'the', 'uncertain', 'information', 'from', 'the', 'linguistic', 'channel', 'with', 'information', 'from', 'the', 'other', 'ones', 'increases', 'the', 'fluency', 'and', 'the', 'effectiveness', 'of', 'the', 'communication', '<ref type=""single"">(Garay-Vitoria and Abascal, 2004).</ref>', 'One', 'of', 'the', 'most', 'well-known', 'examples', 'to', 'this', 'phenomenon', 'is', 'the', 'cocktail', 'party', 'effect,', 'that', 'highlights', 'the', 'human', 'ability', 'to', 'focus', 'on', 'one', 'particular', 'source', 'while', 'inhibiting', 'the', 'noisy', 'ones.', 'When', 'the', 'informativeness', 'of', 'one', 'modality', 'is', 'reduced', 'due', 'to', 'environmental', 'conditions,', 'the', 'human', 'language', 'processing', 'system', 'can', 'successfully', 'adjust', 'itself', 'by', 'relying', 'less', 'on', 'the', 'unclear', 'modality', 'and', 'using', 'other', 'cues', 'in', 'the', 'environment.', 'In', 'this', 'specific', 'scenario,', 'other', 'informative', 'cues', 'provide', 'more', 'reliable', 'information', 'compared', 'to', 'the', 'noisy', 'linguistic', 'input.', 'These', 'cues', 'can', 'come', 'from', 'the', 'surrounding', 'environment', 'and', 'from', 'the', 'communicational', 'partners,', 'and', 'include', 'eye-gaze', 'direction', 'or', 'representational', 'gestures', 'combined', 'with', 'their', 'referential', 'link', 'to', 'the', 'entities', 'in', 'the', 'environment.', 'Eye-tracking', 'is', 'attracting', 'considerable', 'interest', 'in', 'many', 'assistive', 'technologies', 'such', 'as', 'educational', 'VR', 'systems', 'that', 'provide', 'embodied', 'learning', 'environments', 'or', 'driver', 'monitoring', 'systems.', 'The', 'use', 'of', 'eye-tracking', 'in', 'daily', 'technological', 'products', 'such', 'as', 'mobile', 'phones,', 'laptops', 'and', 'virtual', 'reality', 'headsets', 'is', 'increasing', 'day', 'by', 'day', '<ref type=""group"">(Brousseau et al., 2020, Rogers, 2019, Khamis et al., 2018).</ref>', 'Therefore,', 'incorporating', 'eye-movements', 'in', 'our', 'language', 'comprehension', 'models', 'is', 'an', 'inevitable', 'outcome', 'of', 'these', 'latest', 'developments,', 'and', 'this', 'makes', 'the', 'systematic', 'research', 'on', 'the', 'combination', 'of', 'this', 'modality', 'with', 'others', 'very', 'crucial.']",241,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
42c82e0b-5e6c-48d5-9986-3807c0d65425,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,"[""Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization""]",['2018'],['Shashi Narayan;Shay Cohen;Mirella Lapata'],single,"['Our', 'main', 'contribution', 'is', 'to', 'change', 'the', 'target', 'distribution', 'of', 'abstractive', 'models', 'from', 'a', 'one-point', 'deterministic', 'distribution', 'assumed', 'by', 'MLE', 'training', 'to', 'a', 'non-deterministic', 'distribution', 'in', 'which', 'candidate', 'summaries', 'are', 'also', 'assigned', 'probability', 'mass', 'according', 'to', 'their', 'quality.', 'The', 'new', 'SOTA', 'performance', 'on', '<ref type=""single"">CNN/DailyMail (Hermann et al., 2015)</ref>', 'and', 'XSum', '<ref type=""single"">(Narayan et al., 2018)</ref>', 'datasets', 'demonstrated', 'the', 'effectiveness', 'of', 'our', 'method.', 'Our', 'in-depth', 'analysis', 'also', 'found', 'that', 'the', 'abstractive', 'models', 'trained', 'using', 'our', 'method', 'can', 'estimate', 'the', 'candidate', 'summary', 'quality', 'more', 'accurately,', 'in', 'concert', 'with', 'the', 'the', 'objective', 'of', 'our', 'training', 'paradigm.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
43138f94-cd75-4327-a5f9-2ecc00e48d79,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Argumentation schemes'],['2008'],['Douglas Walton;Chris Reed;Fabrizio Macagno'],single,"['In', 'argumentation', 'theory,', ""Walton's"", 'argumentation', 'schemes', 'specify', 'common', 'reasoning', 'patterns', 'used', 'in', 'arguments', '<ref type=""single"">(Walton et al., 2008).</ref>', 'We', 'focus', 'on', 'two', 'schemes', 'related', 'to', 'normative', 'arguments,', 'whose', 'claims', 'suggest', 'that', 'an', 'action', 'or', 'situation', 'be', 'brought', 'about.', 'Normative', 'claims', 'are', 'one', 'of', 'the', 'most', 'common', 'proposition', 'types', 'in', 'argumentation', '<ref type=""single"">(Jo et al., 2020)</ref>', 'and', 'have', 'received', 'much', 'attention', 'in', 'the', 'literature', '<ref type=""single"">(Park and Cardie, 2018).</ref>']",13,"[0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
434bf4fe-75df-4b04-905c-0ce4d5a8b71f,ROI Analysis model for Language Service Providers,2013,Ekaterina Stambolieva,"[""Hunnect's Use Case. TAUS Machine Translation Showcase at Localization World""]",['2013'],['Saándor Sojnóczky'],single,"['A', 'difficult', 'challenge', 'to', 'face', 'is', 'designing', 'a', 'winning', 'vendor', 'pricing', 'model.', 'Even', 'in', 'the', 'cases', 'of', 'google', '9', '-like', 'machine', 'translation', 'output,', 'it', 'is', 'arduous', 'to', 'benefit', 'from', 'vendor', 'involvement', 'with', 'MT.', 'The', 'reason', 'why', 'originates', 'from', 'the', 'fact', 'that', 'when', 'incorporating', 'MT', 'output', 'in', 'the', 'translation', 'process', 'workflow,', 'per', 'segment', 'rates', 'are', 'directly', 'affected', 'and', 'reduced', '(the', 'reductions', 'can', 'reach', '50%', 'of', 'the', 'normal', 'price).', 'From', ""vendors'"", 'point', 'of', 'view,', 'MT', 'threatens', 'to', 'reduce', 'per', 'segment', 'rates,', 'which', 'in', 'return', 'leads', 'to', 'hourly', 'rate', 'destabilization.', 'Regardless', 'of', 'MT', 'output', 'quality,', 'vendors', 'tend', 'to', 'decline', 'jobs', 'due', 'to', 'the', 'fact', 'MT', 'output', 'is', 'incorporated', 'in', 'pre-translated', 'documents.', 'This', 'decrease', 'of', 'vendor', 'involvement', 'leads', 'us', 'to', 'a', 'conclusion', 'that', 'purely', 'showing', 'good', 'MT', 'results', 'is', 'not', 'sufficient', 'and', 'more', 'work', 'is', 'required', 'to', 'be', 'done', 'in', 'order', 'to', 'start', 'gaining', 'investment', 'back', 'and', 'increasing', 'the', 'ROI', 'ratio.', 'What', 'we', 'discovered', 'on', 'our', 'own,', 'stated', 'additionally', 'by', '<ref type=""single"">Sojnóczky (2013),</ref>', 'is', 'that', 'human', ""translators'"", 'engagement', 'is', 'MT', 'development', 'is', 'vital.', 'People', 'are', 'the', 'key', 'factor', 'of', 'success', 'of', 'every', 'business', 'and', 'winning', 'strategies', 'must', 'actively', 'involve', 'employees', 'on', 'different', 'organizational', 'levels', 'in', 'technological', '(including', 'MT)', 'solution', 'processes.', 'In', 'euroscript', '10,', 'we', 'regularly', 'ask', 'for', 'in-house', ""translators'"", 'MT', 'evaluation', 'feedback', 'in', 'terms', 'of', 'different', 'categories', 'of', 'MT', 'output', 'errors.', 'We', 'devote', 'time', 'to', 'correcting', 'these', 'mistakes,', 'informing', 'the', 'in-house', 'translators', 'of', 'the', 'improvements', 'made', 'and', 'engaging', 'ourselves', 'into', 'increasing', ""translators'"", 'satisfaction', 'with', 'working', 'with', 'MT.', 'We', 'consider', 'different', 'options', 'of', 'post-editing', 'training', 'focused', 'on', 'translators', 'following', 'the', 'strategy', 'of', 'involving', 'translators', 'more', 'with', 'MT.', 'This', 'idea', 'is', 'also', 'supported', 'by:', 'Hernández-Lasa', '(2011)', 'and', '<ref type=""single"">Wiggins (2013).</ref>', 'Our', 'preliminary', 'results', 'show', 'that', 'roughly', '50%', 'of', 'our', 'in-house', 'translators,', 'who', 'work', 'with', 'MT,', 'consider', 'its', 'understandability', 'as', 'good', 'opposed', 'to', 'acceptable', 'or', 'bad', '(see', '<ref type=""group"">Avramidis et al., 2012, Vilar et al., 2006</ref>', 'for', 'MT', 'features', 'that', 'influence', 'MT', 'understandability).']",156,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
437b8748-98cc-4246-97fe-24e0a3233d49,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,"[""When is a bishop not like a rook? when it's like a rabbi! multiprototype BERT embeddings for estimating semantic relationships""]",['2020'],['Gabriella Chronis;Katrin Erk'],single,"['Choice', 'of', 'BERT', 'Output', 'Layer', 'and', 'Wordpiece', 'Embeddings', 'We', 'were', 'interested', 'in', 'how', 'the', 'choice', 'of', 'BERT', 'output', 'layers', 'and', 'word', 'piece', 'embeddings', 'impacts', 'performance', 'of', 'our', 'model.', 'Hence,', 'we', 'did', 'the', 'following', 'experiments', 'with', 'our', 'base', 'model,', 'shown', 'in', 'Table', '4.', 'First,', 'we', 'use', ""BERT's"", 'middle', '(7', 'th)', 'output', 'layer,', 'using', 'the', 'embedding', 'of', 'the', 'initial', 'word', 'piece', 'for', 'each', 'word', 'as', 'input', 'to', 'the', 'classifiers.', 'Second,', 'we', 'used', 'the', 'middle', 'layer,', 'but', 'with', 'the', 'mean', 'vector', 'of', 'all', 'word', 'pieces', '(this', 'is', 'the', 'method', 'we', 'used', 'in', 'all', 'previous', 'experiments).', 'Third,', 'we', 'used', 'the', 'mean', 'value', 'of', 'the', 'final', '(12', 'th)', 'BERT', 'output', 'layer,', 'which', 'helped', 'van', 'Noord', 'et', 'al.', '(2020)', 'build', 'their', 'best', 'model,', 'yet', 'according', 'to', '<ref type=""single"">Chronis and Erk (2020)</ref>', 'random', 'errors,', 'we', 'did', 'five', 'trials', 'on', 'each', 'of', 'these', 'embedding', 'approaches', 'and', 'averaged', 'the', 'results.', 'Although', 'the', 'differences', 'are', 'rather', 'small,', 'the', 'mean', 'vector', 'of', 'the', 'middle', 'layer', 'seems', 'to', 'provide', 'the', 'best', 'scores', 'across', 'the', 'board.', 'Therefore,', 'we', 'stuck', 'to', 'this', 'setting', 'for', 'subsequent', 'experiments.']",120,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4393edb8-65e2-4821-a762-64d6a9cff0e8,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['Slot-gated modeling for joint slot filling and intent prediction'],['2018'],['Guang Chih-Wen Goo;Yun-Kai Gao;Chih-Li Hsu;Tsung-Chieh Huo;Keng-Wei Chen;Yun-Nung Hsu;unk Chen'],single,"['Slot-gated', '<ref type=""single"">(Goo et al., 2018)</ref>', 'is', 'an', 'attentionbased', 'BiLSTM', 'model', 'which', 'builds', 'on', 'sepa-', 'rate', 'attended', 'context', 'for', 'slot', 'filling', 'and', 'intent', 'classification', 'while', 'explicitly', 'feeding', 'the', 'intent', 'context', 'into', 'the', 'process', 'of', 'slot', 'filling', 'via', 'a', 'gating', 'mechanism.Metrics', 'Model', 'UCA', 'U-F1(E)', 'U-F1(I)', 'U-F1(A)', 'U-F1(O)', 'T-F1', 'T-F1(T)', 'T-F1(S)', 'T-F1(C)', 'T-F1(D)', 'T-F1(P)', 'T-F1(O)', 'JSA', 'RNN-NLU', '(Liu•', 'Inter-BiLSTM', '<ref type=""single"">(Wang et al., 2018)</ref>', 'combines', 'two', 'inter-connected', 'BiLSTMs', 'performing', 'slot', 'filling', 'and', 'intent', 'classification', 'respectively.', 'The', 'information', 'flow', 'between', 'the', 'two', 'tasks', 'occurs', 'by', 'passing', 'the', 'hidden', 'states', 'at', 'each', 'time', 'step', 'from', 'each', 'side', 'to', 'the', 'other', 'to', 'support', 'the', 'decoding', 'process.']",1,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
43dfab3c-7cfd-4284-b1f5-3226b128db99,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Cooperation and codenames: Understanding natural language processing via codenames'],['2019'],['Andrew Kim;Maxim Ruzmaykin;Aaron Truong;Adam Summerville'],single,"['Say', 'that', 'the', 'agent', 'plays', 'in', 'the', 'blue', 'team,', 'i.e.', 'we', 'want', 'to', 'generate', 'clues', 'associated', 'to', 'the', 'blue', 'words,', 'based', 'on', 'the', 'distance', 'functions', 'above.', 'The', 'functions', 'of', '<ref type=""single"">Kim et al. (2019)</ref>', '(see', '(1))', 'determined', 'the', 'score', 'of', 'a', 'possible', 'reference', 'based', 'on', 'relatedness', 'of', 'the', 'clue', 'word', 'to', 'the', 'least', 'related', 'blue', 'word', 'targeted.', 'The', 'shortcoming', 'of', 'this,', 'however,', 'is', 'that', 'in', 'addition', 'to', 'blue', '(good)', 'words', 'that', 'are', 'similar', 'to', 'the', 'clue', 'word,', 'there', 'may', 'be', 'bad', 'words', 'of', 'a', 'different', 'color', 'that', 'are', 'only', 'very', 'slightly', 'less', 'similar', 'to', 'the', 'clue.', 'We', 'can', 'assume', 'that', 'in', 'this', 'case,', 'agents', 'are', 'less', 'likely', 'to', 'choose', 'the', 'targeted', 'words,', 'or', 'in', 'general,', 'the', 'smaller', 'the', 'difference', 'between', 'the', 'distances', 'of', 'two', 'words', 'from', 'the', 'clue', 'according', 'to', 'our', 'distance', 'function,', 'the', 'more', 'likely', 'the', 'human', 'player', 'will', 'perceive', 'the', 'order', 'of', 'the', 'two', 'words', 'reversed.']",29,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4474f252-18ed-4cb0-8e6d-5a13bf815809,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,"['Analyzing multihead self-attention: Specialized heads do the heavy lifting, the rest can be pruned']",['2019'],['Elena Voita;David Talbot;Fedor Moiseev;Rico Sennrich;Ivan Titov'],single,"['Varying', 'Pruning', 'Percentage.', 'We', 'randomly', 'prune', 'attention', 'heads', 'across', 'all', 'components', 'and', 'layers', 'varying', 'the', 'percentage', 'of', 'pruning', 'from', '25%', 'to', '87%', '(Table', '1).', 'We', 'observed', 'that', 'in', 'the', 'case', 'of', 'extreme', 'pruning,', 'i.e.,', 'keeping', 'just', 'one', 'head', 'in', 'each', 'layer', 'of', 'each', 'of', 'the', 'three', 'components', '(which', 'corresponds', 'to', 'a', 'pruning', 'percentage', 'of', '87%),', 'the', 'drop', 'in', 'BLEU', 'was', '1.62', '(EN-RU)', 'and', '1.03', '(EN-DE)', 'as', 'can', 'be', 'seen', 'from', 'Table', '1.', 'Across', 'both', 'EN-RU', 'and', 'EN-DE', 'tasks,', '60%', 'of', 'the', 'attention', 'heads', 'can', 'be', 'pruned', 'with', 'a', 'maximum', 'drop', 'in', 'BLEU', 'score', 'by', 'only', '0.15.', 'As', 'can', 'be', 'observed', 'from', 'Figure', '1,', 'the', 'drop', 'is', 'sharper', 'as', 'we', 'increase', 'the', 'pruning', 'percentage', 'beyond', '60%.', 'three', 'layers,', '3', 'in', 'the', 'fourth', 'layer', 'and', '2', 'each', 'in', 'the', 'last', 'two', 'layers.', 'For', 'each', 'pruning', 'percentage,', 'the', 'first', 'row', 'corresponds', 'to', 'the', 'configuration', 'in', 'which', 'heads', 'considered', 'important', '<ref type=""single"">(Voita et al., 2019b)</ref>', 'were', 'retained', 'and', 'the', 'second', 'row', 'corresponds', 'to', 'the', 'adversarial', 'configuration', 'in', 'which', 'heads', 'considered', 'important', 'were', 'pruned.', 'We', 'identify', 'no', 'preference', 'in', 'pruning', 'as', 'for', 'each', 'pruning', 'percentage', 'the', 'performance', 'of', 'both', 'configurations', 'is', 'very', 'similar.']",146,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
44bf0888-2835-4627-8523-1d0371f11d87,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['Pre-trained word2vec models for vietnamese'],['2016'],['Xuan-Son Vu'],single,"['Word2VecVN', '<ref type=""single"">(Vu, 2016)</ref>', 'x', 'Trained', 'on', '7GB', 'texts', 'of', 'Vietnamese', 'news', 'FastText', '(Vietnamese', 'version)', '<ref type=""single"">(Joulin et al., 2016)</ref>', 'x']",1,"[1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
44ec7730-9be1-42f7-89e6-27b1fa340499,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['As', 'seen', 'in', 'Figure', '1,', 'we', 'focus', 'on', 'creating', 'agents', 'in', '<ref type=""single"">LIGHT (Urbanek et al., 2019),</ref>', 'a', 'large-scale', 'crowdsourced', 'fantasy', 'text-adventure', 'game,', 'consisting', 'of', 'rich', 'textual', 'worlds-locations,', 'objects,', 'and', 'characters', 'with', 'personas,', 'and', 'quests-motivations', 'for', 'each', 'character.', 'To', 'complete', 'these', 'quests,', 'an', 'agent', 'must:', '(1)', 'maintain', 'character', 'via', 'its', 'persona,', 'and', '(2)', 'reason', 'in', 'a', 'partially', 'observable', 'world', 'about', 'potential', 'actions', 'and', 'utterances', 'based', 'on', 'incomplete', 'descriptions', 'of', 'the', 'locations,', 'objects,', 'and', 'other', 'characters.', 'This', 'requires', 'several', 'human', 'like', 'competencies', 'such', 'as', 'commonsense', 'reasoning,', 'dynamic', 'natural', 'language', 'understanding,', 'and', 'operating', 'in', 'combinatorially', 'sized', 'language-based', 'stateaction', 'spaces.', 'Although', 'recent', 'work', 'has', 'provided', 'evidence', 'showing', 'that', 'interactive', 'language', 'learning', 'via', 'reinforcement', 'learning', '(RL)', 'in', 'text', 'games', 'can', 'be', 'significantly', 'more', 'sample', 'efficient', 'than', 'static', 'supervised', 'learning', '<ref type=""single"">(Ammanabrolu et al., 2021)</ref>', 'when', 'creating', 'goal-driven', 'natural', 'language', 'agents,', 'their', 'ability', 'to', 'robustly', 'generalize', 'to', 'novel', 'scenarios', 'is', 'limited.']",11,"[3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
45078abb-8df9-4abb-b5d7-4224dee2258c,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['Character-aware neural networks for arabic named entity recognition for social media'],['2016'],['Mourad Gridach'],single,"['We', 'propose', 'a', 'three-step', 'approach', 'to', 'Arabic', 'sequence', 'labeling.', 'The', 'first', 'step', 'is', 'to', 'automatically', 'diacritize', 'the', 'text', 'using', 'the', 'state-of-the-art', 'automatic', 'diacritization', 'system', 'Shakkala', '<ref type=""single"">(Barqawi, 2017).</ref>', 'The', 'second', 'step', 'is', 'the', 'individual', 'training', 'of', 'character', 'and', 'diacritic', 'embeddings', 'using', 'the', 'architecture', 'proposed', 'by', '<ref type=""single"">Gridach (2016).</ref>', 'The', 'third', 'step', 'is', 'to', 'train', 'all', 'embedding', 'layers', 'together', 'using', 'a', 'combination', 'model', '(see', 'section', '4.3).', 'There', 'are', 'two', 'main', 'advantages', 'in', 'adopting', 'this', 'architecture', 'for', 'EMIL.', 'First,', 'it', 'is', 'based', 'on', 'a', 'standard', 'approach', 'in', 'NER', 'and', 'sequence', 'labeling', 'in', 'general,', 'which', 'remains', 'very', 'close', 'to', 'the', 'state-ofthe-art.', 'Second,', 'it', 'is', 'a', 'relatively', 'light-weight', 'architecture', 'requiring', 'less', 'computational', 'resources', 'than', 'other', 'alternatives', '(see', 'section', '5.3).', 'We', 'will', 'discuss', 'and', 'justify', 'our', 'design', 'choices', 'and', 'the', 'computational', 'aspects', 'of', 'the', 'architecture', 'further', 'in', 'Section', '(5.3)', 'and', 'Section', '(6).']",43,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
457691b7-656e-4f4e-ab06-8fd0d3ab7b40,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,['Glue: A multi-task benchmark and analysis platform for natural language understanding'],['2018'],['Alex Wang;Amanpreet Singh;Julian Michael;Felix Hill;Omer Levy;Samuel R Bowman'],single,"['In', 'all', 'experiments', 'involving', 'BERT,', 'we', 'use', 'the', 'BERT', 'Base-uncased', 'model', '<ref type=""single"">(Devlin et al., 2018).</ref>', 'It', 'has', '12', 'layers', 'and', 'each', 'layer', 'contains', '12', 'attention', 'heads,', 'summing', 'to', '144', 'attention', 'heads.', 'We', 'fine-tune', 'and', 'evaluate', 'the', 'pre-trained', 'model', '2', 'on', 'sentence', 'entailment', 'task', 'MNLI-M,', 'the', 'question', 'similarity', 'task', 'QQP,', 'the', 'question-answering', 'task', 'QNLI,', 'and', 'the', 'movie', 'review', 'task', 'SST-2', 'from', 'the', 'GLUE', 'Benchmark', '<ref type=""single"">(Wang et al., 2018).</ref>', 'We', 'report', 'accuracies', 'on', 'the', 'official', 'development', 'sets', 'of', 'the', 'considered', 'GLUE', 'tasks.', 'For', 'each', 'of', 'the', 'four', 'GLUE', 'tasks,', 'namely', 'MNLI-M,', 'QQP,', 'QNLI', 'and', 'SST-2,', 'we', 'tried', 'combinations', 'of', 'batch', 'size', 'and', 'learning', 'rate', 'from', '{8,', '16,', '32,', '64,', '128}', 'and', '{2,', '3,', '4,', '5}', '×', '10', '−5', 'respectively', 'and', 'selected', 'the', 'best', 'performing', 'configuration.', 'The', 'exact', 'hyperparameters', 'used', 'for', 'each', 'of', 'the', 'tasks', 'have', 'been', 'made', 'available', 'with', 'the', 'code', 'released', '3.', 'Each', 'BERT', 'experiment', 'was', 'run', 'on', 'a', 'single', 'Cloud', 'TPU', '(v2-8).']",60,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4580587a-8b18-4ee3-ab75-52d8ad70821e,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Mixture models for diverse machine translation: Tricks of the trade'],['2019'],"[""Tianxiao Shen;Myle Ott;Michael Auli;Marc'aurelio Ranzato""]",single,"['Diversity', 'in', 'NLG', 'has', 'been', 'extensively', 'studied', 'for', 'various', 'tasks', 'in', 'the', 'past', 'few', 'years,', 'such', 'as', 'machine', 'translation', '<ref type=""single"">(Shen et al., 2019)</ref>', 'and', 'paraphrase', '§', 'Codes', 'of', 'our', 'model', 'and', 'baselines', 'are', 'available', 'at', 'https://github.com/DM2-ND/MoKGE.']",19,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
45b7784f-553f-4d13-a26b-a316950d5180,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,"['unknown', 'Learning action representations for reinforcement learning']","['unknown', '2019']","['unknown', 'Yash Chandak;Georgios Theocharous;James Kostas;Scott Jordan;Philip Thomas']",group,"['After', 'obtaining', 'natural', 'language', 'actions,', 'we', 'enrich', 'the', 'dialogues', 'as', '{(c', 't,', 'l(x', 't', '),', 'x', 't', ')|1', '≤', 't', '≤', 'n', 'd', '},', 'where', 'l(x', 't)', 'is', 'the', 'natural', 'language', 'action', 'of', 'utterance', 'x', 't.', 'We', 'could', 'then', 'run', 'conditioned', 'response', 'generation', 'to', 'train', 'content', 'planning', 'and', 'language', 'generation', 'models', 'as', 'Eqn.', '1-3.', 'The', 'learning', 'efficiency', 'can', 'be', 'improved', 'by', 'the', 'more', 'compact', 'and', 'noise-free', 'action', 'space.', 'Moreover,', 'the', 'natural', 'language', 'actions', 'present', 'abundant', 'information', 'of', 'correlations', 'among', 'actions,', 'which', 'allows', 'for', 'better', 'generalization', 'over', 'actions', '<ref type=""group"">(Chandak et al., 2019, Hu et al., 2019).</ref>']",87,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
45bfd403-bf49-4957-94da-5e0259a93d0d,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Decompositional argument mining: A general purpose approach for argument graph construction'],['2019'],['Debela Gemechu;Chris Reed'],single,"['When', 'S', 'attacks', 'C,', 'they', 'may', 'express', 'opposite', 'sentiments', 'toward', 'the', 'same', 'target,', 'whereas', 'they', 'may', 'express', 'the', 'same', 'sentiment', 'if', 'S', 'supports', 'C', '<ref type=""single"">(Gemechu and Reed, 2019)</ref>', 'R4:', 'SentiConflict(S,', 'C)', '→', 'Attack(S,', 'C),', 'R5:', 'SentiCoherent(S,', 'C)', '→', 'Support(S,', 'C)', 's.t.', 'SentiConflict(S,', 'C)', '=', 'max', 'i,j', 'P', '(t', 'S', 'i', '=', 't', 'C', 'j)', 'P', '(s', 'S', 'i', '=', 'pos)P', '(s', 'C', 'j', '=', 'neg)', '+P', '(s', 'S', 'i', '=', 'neg)P', '(s', 'C', 'j', '=', 'pos),', 'SentiCoherent(S,', 'C)', '=', 'max', 'i,j', 'P', '(t', 'S', 'i', '=', 't', 'C', 'j)', 'P', '(s', 'S', 'i', '=', 'pos)P', '(s', 'C', 'j', '=', 'pos)', '+P', '(s', 'S', 'i', '=', 'neg)P', '(s', 'C', 'j', '=', 'neg)', '.In', 'this', 'work,', 'targets', 'are', 'all', 'noun', 'phrases', 'and', 'verb', 'phrases', 'in', 'C', 'and', 'S.', 'P', '(t', 'S', 'i', '=', 't', 'C', 'j)', 'is', 'computed', 'by', 'a', 'textual', 'entailment', 'module', '(§4.1),', 'and', 'P', '(s', 'S', 'i)', 'and', 'P', '(s', 'C', 'j)', 'by', 'a', 'target-based', 'sentiment', 'classifier', '(§4.2).']",24,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
45cdd009-6f69-480e-80b9-f6269ca55dd1,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['Europarl: A Multilingual Corpus for Evaluation of Machine Translation'],['2003'],['P Koehn'],single,"['We', 'require', 'aligned', 'parallel', 'text', 'to', 'fuel', 'our', 'methods', 'and', 'we', 'relied', 'on', 'the', 'Europarl', 'corpus', '<ref type=""single"">(Koehn, 2003)</ref>', 'which', 'is', 'comprised', 'of', 'EU', 'parliamentary', 'oration', 'that', 'has', 'been', 'manually', 'translated', 'into', 'other', 'EU', 'languages.', 'There', 'is', 'approximately', '160', 'MB', 'of', 'text', '(about', '24', 'million', 'words)', 'per', 'language.']",16,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
45cdfbbd-e098-431b-b49c-56efc15fbe77,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Choco: a multimodal corpus of the choctaw language. Language Resources and Evaluation'],['2021'],['Jacqueline Brixey;Ron Artstein'],single,"['1', 'https://commoncrawl.org/', 'Local', 'language', 'communities', 'that', 'are', 'working', 'to', 'develop', 'and', 'preserve', 'their', 'languages', 'are', 'producing', 'diverse', 'sets', 'of', 'data', 'beyond', 'pure', 'text.', 'The', 'Bloom', 'Library', 'project,', '2', 'for', 'example,', 'is', 'being', 'used', 'by', 'local', 'language', 'communities', 'to', 'create', 'and', 'translate', '""shell""', 'or', '""template""', 'books', 'into', 'many', 'languages', '(426', 'languages', 'at', 'the', 'time', 'this', 'paper', 'is', 'being', 'written).', 'However,', 'Bloom', 'allows', 'users', 'to', 'do', 'more', 'than', 'just', 'translate', 'text.', 'Users', 'are', 'also', 'recording', 'audio', 'tracks', 'and', 'sign', 'language', 'videos,', 'which', 'has', 'resulted', 'in', '1600+', 'oral', 'translations.', 'Other', 'examples', 'showing', 'the', 'multi-modal', 'nature', 'of', 'data', 'in', 'local', 'languages', 'include:', '(i)', 'the', 'creation', 'of', 'ChoCo:', 'a', 'multimodal', 'corpus', 'of', 'the', 'Choctaw', 'language', '<ref type=""single"">(Brixey and Artstein, 2021),</ref>', '(ii)', 'SIL', ""International's"", '50+', 'year', 'effort', 'to', 'document', 'endangered', 'Austronesian', 'languages', 'via', 'text,', 'audio,', 'and', 'video', '<ref type=""single"">(Quakenbush, 2007),</ref>', '(iii)', 'the', 'grassroots', 'Masakhane', 'effort', 'catalyzing', 'the', 'creation', 'and', 'use', 'of', 'diverse', 'sets', 'of', 'African', 'language', 'data', '<ref type=""single"">(∀ et al., 2020),</ref>', 'and', '(iv)', 'work', 'with', 'the', ""Me'phaa"", 'language', 'of', 'western', 'Mexico', 'that', 'is', 'producing', 'digital', 'recordings', '(video', 'and', 'audio)', 'along', 'with', 'vocabulary,', 'grammar', 'and', 'texts', '<ref type=""single"">(Marlett and Weathers, 2018).</ref>', 'These', 'diverse', 'data', 'sources', 'are', 'effectively', 'unusable', 'by', 'traditional', 'text-based', 'NLP', 'techniques.', 'In', 'the', 'light', 'of', 'data', 'scarcity', 'on', 'these', 'languages,', 'they', 'offer', 'significant', 'untapped', 'potential', 'to', 'unlock', 'improved', 'NLP', 'technology,', 'if', 'text', 'data', 'can', 'be', 'leveraged', 'along', 'with', 'audio,', 'image', 'and', 'video', 'data.', 'Furthermore,', 'flexible', 'multi-modal', 'technology', 'such', 'as', 'this', 'will', 'make', 'it', 'easier', 'to', 'include', 'diverse', 'people', 'and', 'communities', 'such', 'as', 'those', 'described', 'above', 'within', 'the', 'NLP', 'technology', 'development', 'process', '-audio-based', 'technology', 'reducing', 'the', 'need', 'for', 'literacy,', 'for', 'example.']",110,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
45d36906-8669-4594-b3de-8a1e2a1fd00c,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,"['unknown', 'Learn to combine linguistic and symbolic information for table-based fact verification']","['unknown', '2020']","['unknown', 'Qi Shi;Yu Zhang;Qingyu Yin;Ting Liu']",group,"['Benchmarks', 'for', 'fact', 'verification', 'on', 'structured', 'evidence', 'are', 'built', 'on', 'tables', 'collected', 'from', 'Wikipedia', '<ref type=""single"">(Chen et al., 2020)</ref>', 'or', 'scientific', 'articles', '<ref type=""single"">(Wang et al., 2021).</ref>', 'Many', 'previous', 'works', 'search', 'latent', 'programs', 'as', 'an', 'intermediary', 'to', 'reason', 'over', 'the', 'given', 'table.', 'They', 'directly', 'encode', 'programs', '<ref type=""single"">(Chen et al., 2020)</ref>', 'or', 'construct', 'heterogeneous', 'graphs', '<ref type=""group"">(Shi et al., 2020, Yang et al., 2020)</ref>', 'with', 'the', 'claim,', 'the', 'table', 'and', 'the', 'programs.', 'Another', 'way', 'is', 'to', 'linearize', 'the', 'input', 'table', 'and', 'perform', 'table', 'pre-training', '<ref type=""single"">(Chen et al., 2020)</ref>', 'and', 'add', 'additional', 'table-aware', 'embeddings', '<ref type=""group"">(Herzig et al., 2020, Eisenschlos et al., 2020)</ref>', 'to', 'enhance', 'the', 'table', 'encoding.', 'However,', 'in', 'these', 'datasets,', 'the', 'evidence', 'is', 'only', 'one', 'given', 'table,', 'and', 'models', 'are', 'not', 'requested', 'to', 'find', 'out', 'the', 'evidence', 'cells', 'explicitly.']",43,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
45df5ee0-94ec-4a96-b1ac-97fa3bb4ef5a,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['unknown', 'Learning dense representations for entity retrieval', 'Sparse, dense, and attentional representations for text retrieval. CoRR, abs']","['unknown', '2019', 'unknown']","['unknown', 'Daniel Gillick;Sayali Kulkarni;Larry Lansing;Alessandro Presta;Jason Baldridge;Eugene Ie;Diego García-Olano', 'Yi Luan;Jacob Eisenstein;Kristina Toutanova;Michael Collins']",group,"['First,', 'there', 'exists', 'the', 'discrepancy', 'between', 'training', 'and', 'inference', 'for', 'the', 'dual-encoder', 'retriever.', 'During', 'inference,', 'the', 'retriever', 'needs', 'to', 'identify', 'positive', '(or', 'relevant)', 'passages', 'for', 'each', 'question', 'from', 'a', 'large', 'collection', 'containing', 'millions', 'of', 'candidates.', 'However,', 'during', 'training,', 'the', 'model', 'is', 'learned', 'to', 'estimate', 'the', 'probabilities', 'of', 'positive', 'passages', 'in', 'a', 'small', 'candidate', 'set', 'for', 'each', 'question,', 'due', 'to', 'the', 'limited', 'memory', 'of', 'a', 'single', 'GPU', '(or', 'other', 'device).', 'To', 'reduce', 'such', 'a', 'discrepancy,', 'previous', 'work', 'tried', 'to', 'design', 'specific', 'mechanisms', 'for', 'selecting', 'a', 'few', 'hard', 'negatives', 'from', 'the', 'top-k', 'retrieved', 'candidates', '<ref type=""group"">(Gillick et al., 2019, Wu et al., 2020, Karpukhin et al., 2020, Luan et al., 2020, Xiong et al., 2020).</ref>', 'However,', 'it', 'suffers', 'from', 'the', 'false', 'negative', 'issue', 'due', 'to', 'the', 'following', 'challenge.']",92,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
46077b39-e131-42d2-8c22-a5c47c8cc0df,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,['TextGraphs 2020 Shared Task on Multi-Hop Inference for Explanation Regeneration'],['2020'],['Peter Jansen;Dmitry Ustalov'],single,"['This', '2021', 'instantiation', 'of', 'the', 'Shared', 'Task', 'on', 'Explanation', 'Regeneration', 'focuses', 'on', 'the', 'theme', 'of', 'determining', 'relevance', 'in', 'large', 'multi-hop', 'explanations.', 'To', 'this', 'end,', 'participants', 'were', 'given', 'access', 'to', 'a', 'large', 'pre-release', 'dataset', 'of', 'approximately', '250k', 'explanatory', 'relevancy', 'ratings', 'that', 'augment', 'the', '2020', 'shared', 'task', 'data', '<ref type=""single"">(Jansen and Ustalov, 2020),</ref>', 'and', 'were', 'tasked', 'with', 'ranking', 'the', 'facts', 'most', 'critical', 'to', 'assembling', 'large', 'explanations', 'for', 'a', 'given', 'question', 'highest.', 'Similarly', 'to', 'the', 'previous', 'instances', 'of', 'our', 'competition,', 'the', 'shared', 'task', 'has', 'been', 'organized', 'on', 'the', 'CodaLab', 'platform.', '1', 'We', 'released', 'train', 'and', 'development', 'datasets', 'along', 'with', 'the', 'baseline', 'solution', 'in', 'advance', 'to', 'allow', 'one', 'to', 'get', 'to', 'know', 'the', 'task', 'specifics.', '2', 'We', 'ran', 'the', 'practice', 'phase', 'from', 'February', '15', 'till', 'March', '9,', '2021.', 'Then', 'we', 'released', 'the', 'test', 'dataset', 'without', 'answers', 'and', 'ran', 'the', 'official', 'evaluation', 'phase', 'from', 'March', '10', 'till', 'March', '24,', '2021.', 'After', 'that', 'we', 'established', 'postcompetition', 'phase', 'to', 'enable', 'long-term', 'evaluation', 'of', 'the', 'methods', 'beyond', 'our', 'shared', 'task.', 'Participating', 'systems', 'substantially', 'increased', 'task', 'performance', 'compared', 'to', 'a', 'supplied', 'baseline', 'system', 'by', '32%,', 'while', 'achieving', 'moderate', 'overall', 'absolute', 'task', 'performance', '-highlighting', 'both', 'the', 'success', 'of', 'this', 'shared', 'task,', 'as', 'well', 'as', 'the', 'continued', 'challenge', 'of', 'determining', 'relevancy', 'in', 'large', 'multi-hop', 'inference', 'problems.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
460c7458-1992-4f54-a42c-c74e8923ef86,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,"['Unsupervised fake news detection on social media: A generative approach', 'unknown', 'Csi: A hybrid deep model for fake news detection']","['2019', 'unknown', '2017']","['Shuo Yang;Kai Shu;Suhang Wang;Renjie Gu;Fan Wu;Huan Liu', 'unknown', 'Natali Ruchansky;Sungyong Seo;Yan Liu']",group,"['This', 'challenge', 'aims', 'at', 'identifying', 'the', 'reliability', 'of', 'information', 'shared', 'on', 'social', 'network', 'sites', '(SNSs).', 'With', 'the', 'blazing-fast', 'spurt', 'of', 'SNSs', '(e.g.', 'Facebook,', 'Zalo', 'and', 'Lotus),', 'there', 'are', 'approximately', '65', 'million', 'Vietnamese', 'users', 'on', 'board', 'with', 'the', 'annual', 'growth', 'of', '2.7', 'million', 'in', 'the', 'recent', 'year,', 'as', 'reported', 'by', 'the', 'Digital', '2020', '1.', 'SNSs', 'have', 'become', 'widely', 'accessible', 'for', 'users', 'to', 'not', 'only', 'connect', 'friends', 'but', 'also', 'freely', 'create', 'and', 'share', 'diverse', 'content', '<ref type=""group"">(Shu et al., 2017, Zhou et al., 2019).</ref>', 'A', 'number', 'of', 'users,', '1', 'https://wearesocial.com/digital-2020', 'however,', 'has', 'exploited', 'these', 'social', 'platforms', 'to', 'distribute', 'fake', 'news', 'and', 'unreliable', 'information', 'to', 'fulfill', 'their', 'personal', 'or', 'political', 'purposes', '(e.g.', 'US', 'election', '2016', '<ref type=""single"">(Allcott and Gentzkow, 2017)</ref>', ').', 'It', 'is', 'not', 'easy', 'for', 'other', 'ordinary', 'users', 'to', 'realize', 'the', 'unreliability,', 'hence,', 'they', 'keep', 'spreading', 'the', 'fake', 'content', 'to', 'their', 'friends.', 'The', 'problem', 'becomes', 'more', 'seriously', 'once', 'the', 'unreliable', 'post', 'becomes', 'popular', 'and', 'gains', 'belief', 'among', 'the', 'community.', 'Therefore,', 'it', 'raises', 'an', 'urgent', 'need', 'for', 'detecting', 'whether', 'a', 'piece', 'of', 'news', 'on', 'SNSs', 'is', 'reliable', 'or', 'not.', 'This', 'task', 'has', 'gained', 'significant', 'attention', 'recently', '<ref type=""group"">(Ruchansky et al., 2017, Shu et al., 2019a,b, Yang et al., 2019).</ref>']",171,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]"
46198fc2-5f06-42e3-b890-54d9fbda8de7,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Semi-supervised learning with local and global consistency'],['2014'],['Jie Gui;Rongxiang Hu;Zhongqiu Zhao;Wei Jia'],single,"['We', 'used', 'the', 'learning', 'with', 'Local', 'and', 'Global', 'Consistence', '(LGC)', '<ref type=""single"">(Zhou et al., 2004)</ref>', 'as', 'a', 'regularization', 'method.', 'The', 'algorithm', 'designs', 'a', 'classi-fying', 'function', 'that', 'is', 'sufficiently', 'smooth', 'concerning', 'the', 'intrinsic', 'structure', 'collectively', 'revealed', 'by', 'known', 'labeled', 'and', 'unlabeled', 'points.', 'Thus,', 'the', 'LGC', 'lets', 'every', 'point', 'iteratively', 'spread', 'its', 'label', 'information', 'to', 'its', 'neighbors', 'until', 'a', 'global', 'stable', 'state', 'is', 'achieved', '<ref type=""single"">(Gui et al., 2014).</ref>', 'Also,', 'it', 'allows', 'the', 'class', 'information', 'of', 'the', 'labeled', 'objects', 'to', 'be', 'changed', 'during', 'the', 'classification', 'as', 'objects', 'may', 'be', 'erroneously', 'labeled', 'and,', 'consequently,', 'decrease', 'the', 'performance', 'of', 'the', 'classification.', 'More', 'than', 'that,', 'the', 'algorithm', 'diminished', 'the', 'influence', 'of', 'objects', 'with', 'a', 'high', 'degree', '(many', 'neighboring', 'objects),', 'therefore,', 'these', 'objects', 'do', 'not', 'have', 'excessive', 'influence', 'in', 'the', 'classification.']",58,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4647c75c-7a0e-4575-a466-fa328037ed6c,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Reformer: The efficient transformer'],['2020'],['Nikita Kitaev;Lukasz Kaiser;Anselm Levskaya'],single,"['Related', 'work', 'Our', 'work', 'follows', 'a', 'long', 'line', 'of', 'works', 'on', 'efficient', 'Transformers', '(see', '§1).', 'Our', 'method', 'employs', 'three', 'main', 'ideas:', '(a)', 'computing', 'the', 'top-k', 'attention', 'scores', 'for', 'each', 'query', '(b)', 'grouping', 'the', 'queries', 'into', 'chunks', 'and', 'processing', 'these', 'sequentially', '(c)', 'caching', 'only', 'a', 'part', 'of', 'the', 'activations', 'for', 'the', 'backward', 'pass.', 'Top-k', 'operation', 'was', 'used', 'at', 'self-attention', 'layers', 'by', '<ref type=""single"">(Zhao et al., 2019)</ref>', 'to', 'show', 'improved', 'model', 'performance,', 'attributed', 'to', 'the', 'removal', 'of', 'irrelevant', 'information', 'in', 'the', 'context.', 'We', 'use', 'it', 'to', 'reduce', 'the', 'resource', 'usage', 'of', 'multi-head', 'attention', 'and', 'feed-forward', 'layers.', 'Processing', 'query', 'chunks', 'sequentially', 'was', 'also', 'used', 'in', 'Reformer', '<ref type=""single"">(Kitaev et al., 2020)</ref>', 'as', 'activations', 'are', 'not', 'cached.', 'But', 'in', 'that', 'case,', 'by', 'replacing', 'vanilla', 'residual', 'connections', 'in', 'the', 'Transformer', 'with', 'reversible', 'connections', '<ref type=""single"">(Gomez et al., 2017).</ref>', 'Similar', 'to', 'the', 'explanation', 'provided', 'in', '§2.2,', 'these', 'require', 'an', 'extra', 'implicit', 'forward', 'pass', 'during', 'the', 'backward', 'pass', 'and', 'do', 'not', 'provide', 'the', 'compute', 'and', 'memory', 'savings', 'we', 'get', 'from', 'our', 'top-k', 'specific', 'backward', 'pass', '(§2.2).', 'Secondly,', 'replacing', 'residual', 'connections', 'with', 'reversible', 'ones', 'changes', 'the', 'function', 'computed', 'by', 'the', 'model', 'and', 'would', 'require', 'corrective', 'pre-training', 'to', 'be', 'used', 'with', 'BERT,', 'T5,', 'etc', '(§4.3-', '§4.5).']",99,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
46909607-aab1-4d54-b634-6922af8a2d68,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Cooperation and codenames: Understanding natural language processing via codenames'],['2019'],['Andrew Kim;Maxim Ruzmaykin;Aaron Truong;Adam Summerville'],single,"['They', 'found', 'that', 'the', 'behavior', 'of', 'human', 'players', 'is', 'best', 'modeled', 'on', 'the', 'probabilities', 'of', 'bigrams,', 'which', 'is', 'in', 'line', 'with', 'the', 'results', 'of', '(Spence', 'and', 'Owens,', '1990)', '(although', 'the', 'latter', 'calculated', 'cooccurrences', 'with', 'much', 'larger', 'window', 'size).', '<ref type=""single"">Kim et al. (2019)</ref>', 'were', 'the', 'first', 'to', 'build', 'agents', 'designed', 'explicitly', 'to', 'play', 'the', 'game.', 'As', 'a', 'background', 'to', 'their', 'relatedness', 'measure,', 'they', 'used', 'CBOW,', 'Skip-gram', 'and', 'GloVe', 'word', 'embeddings', '(in', 'multiple', 'configurations),']",38,"[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
46d36327-b7a1-4bab-acb6-5f6be12f4ae4,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,"['Word Manager: A system for the Specification, Use, and Maintenance of Morphological Knowledge, Habilitationsschrift']",['1989'],['Marc Domenig'],single,"['WM', 'is', 'a', 'long-term,', 'open-ended', 'project', 'which', 'originated', 'with', '<ref type=""single"">Domenig (1989).</ref>', 'Subsequently', 'it', 'was', 'developed', 'at', 'Universities', 'in', 'Basel,', 'Amsterdam', '(Vrije', 'Universiteit),', 'and', 'Lugano', '(SUPSI', 'and', 'USI),', 'funded', 'in', 'part', 'by', 'the', 'Swiss', 'federal', 'government', 'and', 'by', 'private', 'companies.']",9,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
476a6d41-38ef-4dd6-9087-3647860b4a6d,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,"['Characterizing and detecting hateful users on twitter', 'The road to success: Assessing the fate of linguistic innovations in online communities']","['2018', '2018']","['Manoel Ribeiro;Pedro Calais;Yuri Santos;Virgílio Almeida;Wagner Meira', 'Marco Del Tredici;Raquel Fernández']",group,"['Linguistic', 'variations.', 'Another', 'aspect', 'comes', 'from', 'looking', 'at', 'implicit', 'abuse,', 'whereby', 'a', 'user', 'may', 'utilize', 'novel', 'slangs', 'or', 'conventional', 'words', 'in', 'unconventional', 'ways,', 'e.g.,', 'as', 'a', 'racial', 'slur', 'or', 'as', 'a', 'name', 'for', 'some', 'specific', 'demographic', '<ref type=""single"">(Waseem et al., 2017).</ref>', 'Information', 'about', 'how', 'a', 'term', 'is', 'being', 'used', 'by', 'other', 'members', 'of', 'a', ""user's"", 'community,', 'e.g.,', 'in', 'abusive', 'contexts', 'or', 'otherwise,', 'can', 'help', 'decipher', 'linguistic', 'variations', 'that', 'come', 'up', 'from', 'time', 'to', 'time.', 'In', 'fact,', 'it', 'is', 'usually', 'the', 'users', 'with', 'strong', 'ties', 'who', 'are', 'responsible', 'for', 'popularizing', 'language', 'variations', 'as', 'well', 'as', 'for', 'spreading', 'hate', 'speech', '<ref type=""group"">(Del Tredici and Fernández, 2018, Ribeiro et al., 2018).</ref>', 'Therefore,', 'having', 'user', 'and', 'community', 'information', 'alongside', 'linguistic', 'features', 'helps', 'capture', 'linguistic', 'variations', 'and', 'their', 'diffusion.']",94,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
476aab87-c427-4ae9-81cf-09095a3cd302,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['The structure of task oriented dialogs'],['1974'],['B Grosz'],single,"['If', 'recombination', 'or', 'rephrasing', 'is', 'required', 'during', 'the', 'composition', 'process,', 'this', 'implies', 'consultation', 'with', 'the', 'user.', 'Therefore,', 'the', 'system', 'must', 'be', 'able', 'to', 'interact', 'in', 'an', 'intelligent', 'manner', 'with', 'the', 'user', 'and,', 'consequently,', 'an', 'additional', 'module', 'in', 'the', 'form', 'of', 'a', 'human-machine', 'interaction', 'dialogue', 'model', 'is', 'required.', 'In', 'order', 'for', 'the', 'system', 'to', 'interact', ""'intelligently',"", 'it', 'must', 'understand', 'the', 'communicative', 'intent', 'of', 'the', 'user', 'and', 'therefore', 'must', 'have', 'knowledge', 'of', 'the', 'domain.', 'We', 'will', 'not', 'address', 'here', 'this', 'aspect', 'of', 'the', 'proposed', 'system,', 'which', 'is', 'essentially', 'a', 'typical', 'problem', 'of', 'task-oriented', 'dialogue', '<ref type=""single"">([13]</ref>', ').']",92,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
4831b3e6-53fd-4d49-8d96-3ea5e2100a9c,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Recent', 'advances', 'in', 'the', 'field', 'of', 'Natural', 'Language', 'Processing', '(NLP)', 'have', 'been', 'made', 'with', 'the', 'development', 'of', 'transfer', 'learning', 'and', 'the', 'availability', 'of', 'pre-trained', 'language', 'models', 'based', 'on', 'Transformer', 'architectures', '<ref type=""single"">(Vaswani et al., 2017),</ref>', 'such', 'as', 'BERT', '<ref type=""single"">(Devlin et al., 2019).</ref>', 'As', 'they', 'provide', 'contextualized', 'semantic', 'representation', 'they', 'contribute', 'both', 'to', 'advance', 'the', 'state-of-the-art', 'on', 'several', 'NLP', 'tasks', 'and', 'also', 'to', 'evolve', 'training', 'practices', 'through', 'the', 'use', 'of', 'fine-tuning.']",34,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
48e1a480-08a1-49a6-9997-7e7f8824d27b,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Annotation of events and temporal expressions in french texts'],['2009'],['André Bittar'],single,"['4.', 'For', 'French,', 'we', 'did', 'not', 'find', 'systems', 'that', 'did', 'event', 'extraction', 'from', 'the', 'French', 'TimeBank', 'corpus.', 'The', 'existing', 'literature', 'either', 'creates', 'and', 'evaluates', 'on', 'a', 'modified', 'corpus', '<ref type=""single"">(Bittar, 2009)</ref>', 'or', 'provides', 'annotations', 'trained', 'on', 'the', 'TimeML', 'annotated', 'data', 'and', 'tested', 'on', 'Fr-TempEval2)', '<ref type=""single"">(Arnulphy et al., 2015).</ref>', 'Therefore,', 'we', 'compare', 'our', 'performance', 'to', 'those,', 'while', 'also', 'understanding', 'that', 'the', 'comparison', 'is', 'not', 'a', 'strict', 'metric.', 'We', 'hope', 'to', 'establish', 'the', 'scores', 'here', 'as', 'baseline', 'for', 'further', 'improvement', 'over', 'models', 'in', 'event', 'detection', 'in', 'French.']",28,"[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4914a18a-e1e2-4855-a3d4-3da70ef6ca58,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,"['Rethinking attention with performers', 'unknown']","['2021', 'unknown']","['Valerii Krzysztof Marcin Choromanski;David Likhosherstov;Xingyou Dohan;Andreea Song;Tamas Gane;Peter Sarlos;Jared Hawkins;Afroz Davis;Lukasz Mohiuddin;David Kaiser;Lucy Belanger;Adrian Colwell;unk Weller', 'unknown']",group,"['Experimental', 'details', 'For', 'all', 'models,', 'we', 'benchmark', 'by', 'running', 'a', 'forward', 'and', 'backward', 'pass', 'over', 'random', 'inputs.', 'Each', 'measurement', 'is', 'an', 'average', 'over', '3', 'runs', 'on', 'an', 'Nvidia', 'A100', 'GPU', 'and', 'is', 'discarded', 'if', 'memory', 'usage', 'exceeds', '30GiB.', 'We', 'use', 'causal', 'masking', 'for', 'self-attention', 'layers', 'to', 'highlight', 'the', 'simplicity', 'of', 'our', 'approach', 'that', 'can', 'seamlessly', 'handle', 'arbitrary', 'attention', 'masks,', 'unlike', 'other', 'methods', '<ref type=""group"">(Wang et al., 2020, Katharopoulos et al., 2020, Choromanski et al., 2021),</ref>', 'where', 'implementing', 'causal', 'masking', 'requires', 'customized', 'CUDA', 'implementations.', 'For', 'Performer,', 'we', 'use', '256', 'random', 'features,', 'and', 'the', 'CUDA', 'implementation', 'from', '<ref type=""single"">(Katharopoulos et al., 2020).</ref>']",62,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4a020263-16d2-4bea-a8d7-d0f44cf1a2d6,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['unknown'],['2007'],['Day Robert;A unk'],single,"['The', 'rest', 'of', 'the', 'article', 'is', 'organized', 'according', 'to', '<ref type=""single"">(Day, 2007)</ref>', 'as', 'follows:']",9,"[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]"
4a86c4ba-0e7b-4781-a1af-e8566830cac2,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['unknown'],['unknown'],['unknown'],group,"['While', 'we', 'do', 'not', 'have', 'access', 'to', 'many', 'coreference', 'annotations', 'for', 'the', 'task', 'of', 'coreference-aware', 'MRC,', 'there', 'are', 'various', 'datasets', 'for', 'the', 'task', 'of', 'coreference', 'resolution.', 'Coreference', 'resolution', 'datasets', 'contain', 'the', 'annotation', 'of', 'expressions', 'that', 'refer', 'to', 'the', 'same', 'entity.', 'In', 'this', 'paper,', 'we', 'hypothesize', 'that', 'we', 'can', 'directly', 'use', 'coreference', 'resolution', 'corpora', 'to', 'improve', 'the', 'coreference', 'reasoning', 'of', 'MRC', 'models.', 'We', 'propose', 'an', 'effective', 'approach', 'to', 'convert', 'coreference', 'annotations', 'into', 'QA', 'pairs', 'so', 'that', 'models', 'learn', 'to', 'perform', 'coreference', 'resolution', 'by', 'answering', 'those', 'questions.', 'In', 'our', 'experiments,', 'we', 'use', 'the', '9', 'We', 'examine', '50', 'randomly', 'selected', 'examples', 'from', 'our', 'challenge', 'set,', 'and', 'they', 'were', 'all', 'answerable', 'by', 'a', 'human.', '<ref type=""group"">CoNLL-2012 dataset (Pradhan et al., 2012b)</ref>', 'that', 'is', 'the', 'largest', 'annotated', 'dataset', 'with', 'coreference', 'information.']",110,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
4aa08dcc-af3f-4463-bfa6-9f5d8cc186bb,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Learning deep disentangled embeddings with the f-statistic loss'],['2018'],['Karl Ridgeway;C Michael;unk Mozer'],single,"['Apart', 'from', 'designing', 'classification', 'tasks', 'for', 'disentanglement', 'evaluation,', 'another', 'method', 'is', 'based', 'on', 'estimating', 'the', 'mutual', 'information', '(MI)', 'between', 'a', 'single', 'dimension', 'of', 'the', 'latent', 'variable', 'and', 'a', 'single', 'generative', 'factor.', '<ref type=""single"">Chen et al. (2018)</ref>', 'propose', 'to', 'use', 'the', 'average', 'of', 'the', 'gap', '(difference)', 'between', 'the', 'largest', 'normalised', 'MI', '(by', 'the', 'information', 'entropy', 'of', 'the', 'generative', 'factor)', 'and', 'the', 'second', 'largest', 'normalised', 'MI', 'over', 'all', 'generative', 'factors', 'as', 'the', 'disentanglement', 'score,', 'whereas', 'the', 'modularity', 'metric', 'of', '<ref type=""single"">Ridgeway and Mozer (2018)</ref>', 'measures', 'whether', 'a', 'single', 'latent', 'variable', 'has', 'the', 'highest', 'MI', 'with', 'only', 'one', 'generative', 'factor', 'and', 'none', 'with', 'others.']",73,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
4aee5d0f-e018-40c6-b19b-0bc664597528,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['Machine translation without a source text'],['1990'],['H Somers;J Tsujii;D Jones'],single,"['The', 'idea', 'to', 'develop', 'this', 'sort', 'of', 'interaction', 'in', 'the', 'direction', 'of', 'a', 'more', 'sophisticated', 'clarification', 'dialogue', 'is', 'now', 'gaining', 'currency', 'with', 'the', 'emergence', 'of', 'DBMT', '<ref type=""group"">[3, 4, 47]</ref>', 'and', 'the', 'notion', 'of', ""'MT"", 'without', 'a', 'source', ""text'"", '<ref type=""single"">[43],</ref>', 'where', 'the', 'dialogue', 'aims', 'not', 'merely', 'at', 'disambiguating', 'a', 'given', 'text,', 'but', 'in', 'helping', 'the', 'user', 'to', 'compose', 'it', 'in', 'the', 'first', 'place.']",36,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
4b2f347e-656a-4a48-9135-ee6c18ba63bc,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['So What Can We Talk About Now'],['1983'],['B Webber ; Webber'],single,"['Besides,', 'concept', 'instance', 'nodes', '(CI)', 'and', 'concept', 'sequence', 'instance', 'structures', '(CSI)', 'are', 'dynamically', 'created', 'during', 'parsing.', 'Each', 'CI', 'or', 'CSI', 'is', 'connected', 'to', 'the', 'associated', 'CC', 'or', 'CSC', 'by', 'INST', 'link.', 'CIs', 'correspond', 'to', 'discourse', 'entities', 'proposed', 'in', '<ref type=""single"">[Webber, 1983).</ref>', 'Three', 'additional', 'links', 'are', 'used', 'to', 'facilitate', 'pragmatic', 'inferences.', 'They', 'are', 'CONTEXT', 'links.', 'CONSTRAINT', 'links', 'and', 'EQROLE', 'links.', 'A', 'CONTEXT', 'link', 'is', 'a', 'path', 'of', 'contextual', 'priming', 'which', 'is', 'crucial', 'in', 'word', 'sense', 'disambiguation.', 'When', 'a', 'word', 'is', 'activated', 'during', 'processing,', 'the', 'activation', 'spreads', 'through', 'CONTEXT', 'links', 'and', 'impose', 'contextual', 'priming', 'to', 'relevant', 'concepts.', 'A', 'CONSTRAINT', 'link', 'denotes', 'an', 'antecedent/consequence', 'relationship', 'between', 'two', 'events', 'or', 'states,', 'which', 'is', 'created', 'between', 'two', 'CSRs.', 'An', 'EQROLE', 'link', 'denotes', 'the', 'necessary', 'argument', 'matching', 'condition', 'for', 'testing', 'an', 'antecedent/consequence', 'relationship,', 'which', 'is', 'created', 'between', 'two', 'CSEs', 'in', 'different', 'CSCs.']",38,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4b320c01-749f-433a-af8a-a42a0c56a628,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['Vietnam passes cyber security law'],['2018'],['Tuan Son'],single,"['We', 'collect', 'the', 'data', 'for', 'two', 'months', 'from', 'August', 'to', 'October', '2020.', 'There', 'are', 'two', 'main', 'sources', 'of', 'the', 'data:', 'SNSs', 'and', 'Vietnamese', 'newspapers.', 'As', 'for', 'the', 'former', 'source,', 'public', 'social', 'media', 'posts', 'are', 'retrieved', 'from', 'news', 'groups', 'and', 'key', 'opinion', 'leaders', '(KOLs).', 'Many', 'fake', 'news,', 'however,', 'has', 'been', 'flagged', 'and', 'removed', 'from', 'the', 'social', 'networking', 'sites', 'since', 'the', 'enforcement', 'of', 'Vietnamese', 'cybersecurity', 'law', 'in', '2019', '<ref type=""single"">(Son, 2018).</ref>', 'Therefore,', 'to', 'include', 'the', 'deleted', 'fake', 'news,', 'we', 'gather', 'newspaper', 'articles', 'reporting', 'these', 'posts', 'and', 'recreate', 'their', 'content.']",66,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
4b75a4b4-5c1d-424e-9b86-bf7360c6b43e,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['WordNet: A lexical database for English'],['1992'],['A George;unk Miller'],single,"['and', 'the', 'WordNet', 'database', '<ref type=""single"">(Miller, 1992)</ref>', 'with', 'a', 'number', 'of', 'different', 'distance', 'functions.']",4,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
4bc88726-244c-47c4-8d41-f4b0781e8efe,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['Enhancing the TED-LIUM corpus with selected data for language modeling and more TED talks'],['2014'],['A Rousseau;P Deléglise;Y Estève'],single,"['This', 'section', 'describes', 'how', 'we', 'prepare', 'the', 'collapsed', 'single', 'sequence', 'composed', 'of', 's', 'i', 'in', 'Eq.', '(8).', 'We', 'explain', 'this', 'data', 'preparation', 'with', 'both', 'English', '(TED-LIUM', 'release', '2', '(TEDLIUM2)', '<ref type=""single"">(Rousseau et al., 2014))</ref>', 'and', 'Japanese', '(corpus', 'of', 'spontaneous', 'Japanese', '(CSJ)', '<ref type=""single"">(Maekawa et al., 2000</ref>', '))', 'data', 'as', 'an', 'example.', 'The', 'sequence', 'type', 'includes', 'the', 'graphemic', 'and', 'phonemic', 'transcripts', '1,', 'as', 'well', 'as', 'the', 'POS', 'tags.']",29,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
4bda6500-9ff1-4879-9a27-8caa19cc1dc0,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Broadcast news lm adaptation using contemporary texts'],['2001'],['M Federico;N Bertoldi'],single,"['The', 'baseline', 'system', 'built', 'for', 'the', 'task', 'is', 'a', 'simple', 'PBSMT', 'system', 'trained', 'only', 'on', 'the', ""'in-domain'"", 'training', 'data', 'released', 'as', 'a', 'part', 'of', 'the', 'evaluation', 'campaign.', 'This', 'training', 'data', 'comprised', 'of', 'both', 'parallel', 'and', 'monolingual', 'data', 'from', 'the', 'TED', '1', 'http://iwslt2011.org', 'Talks:', '2', 'a', 'collection', 'of', 'public', 'speeches', 'on', 'a', 'variety', 'of', 'topics.', 'Out-of-domain', 'data', 'in', 'the', 'form', 'of', 'a', 'parallel', 'Multi-UN', 'corpus', '3', 'was', 'also', 'available', 'to', 'enrich', 'the', 'models', 'trained', 'on', 'in-domain', 'data.', 'For', 'domain-adaptation', 'we', 'enhanced', 'the', 'language', 'models', 'built', 'on', 'the', 'TED', 'corpus', 'data', 'with', 'selected', 'data', 'from', 'the', 'UN', 'corpus.', 'Mixture', 'adaptation', '<ref type=""single"">[4]</ref>', 'techniques', 'were', 'used', 'to', 'combine', 'models', 'from', 'multiple', 'sources', 'weighted', 'according', 'to', 'their', 'fit', 'with', 'respect', 'to', 'the', 'development', 'set.', 'The', 'adapted', 'language', 'models', 'provided', 'an', 'improvement', 'of', 'about', '5.16', 'absolute', '(21.99%', 'relative)', 'BLEU', 'points', 'for', 'Ar-En', 'and', '1.25', 'absolute', '(11.76%', 'relative)', 'BLEU', 'points', 'for', 'Zh-En', 'language', 'pairs', 'over', 'the', 'unadapted', 'baseline.']",98,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4c089e24-7287-4d9b-81fa-61b6d8f30c76,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['unknown', 'Sparse, dense, and attentional representations for text retrieval. CoRR, abs']","['unknown', 'unknown']","['unknown', 'Yi Luan;Jacob Eisenstein;Kristina Toutanova;Michael Collins']",group,"['Table', '2', 'shows', 'the', 'main', 'experimental', 'results.', 'We', 'can', 'see', 'that', 'RocketQA', 'significantly', 'outperforms', 'all', 'the', 'baselines', 'on', 'both', 'MSMARCO', 'and', 'NQ', 'datasets.', 'Another', 'observation', 'is', 'that', 'the', 'dense', 'retrievers', 'are', 'overall', 'better', 'than', 'the', 'sparse', 'retrievers.', 'Such', 'a', 'finding', 'has', 'also', 'been', 'reported', 'in', 'previous', 'studies', '<ref type=""group"">(Karpukhin et al., 2020, Luan et al., 2020, Xiong et al., 2020),</ref>', 'which', 'indicates', 'the', 'effectiveness', 'of', 'the', 'dense', 'retrieval', 'approach.']",47,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
4c760f4a-c274-4ee6-8e9d-05b4bd8c4be5,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Searching for solutions in games and artificial intelligence'],['1994'],['Louis Victor;Allis unk'],single,"['One', 'of', 'the', 'central', 'subjects', 'of', 'artificial', 'intelligence', 'research', 'has', 'long', 'been', 'the', 'development', 'of', 'agents', 'that', 'play', 'various', 'games', 'at', 'the', 'human', 'level', 'or', 'better.', 'Most', 'studies', 'in', 'the', 'field', 'focus', 'on', 'combinatorial', 'games,', 'that', 'can', 'be', 'easily', 'formalized', 'mathematically,', 'such', 'as', 'chess', 'and', 'go', '(see,', 'for', 'example,', '<ref type=""single"">Allis et al., 1994).</ref>', 'The', 'popular', 'board', 'game', 'Codenames', 'is', 'different', 'from', 'these', 'in', 'many', 'aspects', 'and', 'may', 'provide', 'an', 'excellent', 'experimental', 'ground', 'in', 'areas', 'such', 'as', 'predicting', 'human', 'behavior', 'or', 'implementing', 'human-machine', 'cooperation.']",49,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4c791b07-9140-48f4-b5bb-29625a86c801,Can Semantic Role Labeling Improve SMT?,2009,Dekai Wu;Pascale Fung,['METEOR: An automatic metric for MT evaluation with improved correlation with human judgement'],['2005'],['Satanjeev Banerjee;Alon Lavie'],single,"['It', 'has', 'been', 'widely', 'observed', 'that', 'the', 'negative', 'impacts', 'of', 'such', 'errors', 'on', 'the', 'utility', 'of', 'the', 'translation', 'are', 'inadequately', 'reflected', 'by', 'evaluation', 'metrics', 'based', 'on', 'lexical', 'criteria.', 'The', 'accuracy', 'of', 'translation', 'lexical', 'choice', 'has', 'reached', 'increasingly', 'satisfactory', 'levels-at', 'least', 'for', 'largely', 'literal', 'genres', 'such', 'as', 'newswire', '-which', 'helps', 'boost', 'lexically', 'oriented', 'scores', 'such', 'as', 'BLEU', '<ref type=""single"">(Papineni et al., 2002)</ref>', 'or', 'METEOR', '<ref type=""single"">(Banerjee and Lavie, 2005)</ref>', 'despite', 'serious', 'role', 'confusion', 'errors', 'in', 'the', 'translations.']",59,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]"
4c7e0b43-be66-4869-86c6-2061f17405d7,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['Efficient Estimation of Word Representations in Vector Space'],['2013'],['T Mikolov;K Chen;G Corrado;J Dean'],single,"['Another', 'straightforward', 'operation', 'is', 'to', 'sum', 'the', 'embeddings', '(technique', 'used', 'in', '<ref type=""single"">[23])</ref>', 'of', 'the', 'previous', 'lemma', 'with', 'the', 'embedding', 'of', 'the', 'previous', 'factors,', 'as', 'described', 'in', 'equation', '7.']",11,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3]"
4c821844-95b9-45e8-8264-36eb7f0a1459,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Evidence for universality and cultural variation of differential emotion response patterning'],['1994'],['Klaus Scherer;Harald Wallbott'],single,"['Because', 'OPUS', 'open', 'subtitles', 'is', 'a', 'parallel', 'corpus', 'we', 'are', 'able', 'to', 'evaluate', 'our', 'annotated', 'datasets', 'across', 'languages', 'and', 'at', 'identical', 'levels', 'of', 'granularity.', 'Although', 'the', 'subtitles', 'might', 'be', 'translated', 'using', 'different', 'translation', 'philosophies', '(favoring', 'e.g.', 'meaning,', 'mood,', 'or', 'idiomatic', 'language', 'as', 'the', 'prime', 'objective)', '<ref type=""single"">(Carl et al., 2011),</ref>', 'we', 'expect', 'the', 'translations', 'to', 'have', 'aimed', 'at', 'capturing', 'the', 'sentiments', 'and', 'emotions', 'originally', 'expressed', 'in', 'the', 'film', 'based', 'on', 'previous', 'studies', '(e.g.', '<ref type=""single"">Cowen et al. (2019),</ref>', '<ref type=""single"">Scherer and Wallbott (1994),</ref>', '<ref type=""single"">Creutz (2018),</ref>', '<ref type=""single"">Scherrer (2020)</ref>', 'and', 'Kajava', 'et', 'al.', '(2020)).']",70,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
4cd4676a-2cf1-4053-9122-03b1bd4d14c7,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,['SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks'],['2018'],['Ke Wang;Xiaojun Wan'],single,"['Evaluation', 'For', 'this', 'task,', 'we', 'have', 'classified', 'the', 'generated', 'sentences', 'in', 'terms', 'of', 'their', 'sentiment', 'using', 'a', 'Bidirectional-LSTM', 'as', 'classifier.', 'In', 'addition,', 'we', 'have', 'evaluated', 'two', 'quality', 'metrics:', '1)', 'the', 'novelty', 'of', 'each', 'generated', 'sentence', '(Eq.', '5)', 'using', 'the', 'definition', 'from', '<ref type=""single"">[20],</ref>', 'where', 'JS', 'is', 'the', 'Jaccard', 'similarity', 'and', 'C', 'j', 'are', 'the', 'training', 'set', 'sentences.', 'The', 'novelty', 'measures', 'the', 'diversity', 'between', 'the', 'generated', 'data', 'and', 'the', 'training', 'corpus,', 'and', '2)', 'the', 'diversity', 'metric', '(Eq.', '6),', 'a', 'measure', 'of', 'the', ""model's"", 'ability', 'to', 'generate', 'diverse', 'sentences', 'and', 'avoid', 'mode', 'collapse.']",41,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4ce2e6ce-71a4-47e9-9670-57d51dd869bf,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs', 'unknown']","['unknown', 'unknown']","['Gautier Izacard;Edouard Grave', 'unknown']",group,"['Table', '5:', 'The', 'experimental', 'results', 'of', 'passage', 'reading', 'on', 'NQ', 'dataset.', 'In', 'this', 'paper,', 'we', 'focus', 'on', 'extractive', 'reader,', 'while', 'the', 'recent', 'generative', 'readers', '<ref type=""group"">(Lewis et al., 2020, Izacard and Grave, 2020)</ref>', 'can', 'also', 'be', 'applied', 'here', 'and', 'may', 'lead', 'to', 'better', 'results.']",24,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
4d21de9a-b471-4195-8d4f-a5027988598d,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['The effectiveness of stemming for natural language access to Slovene textual data'],['1992'],['M Popovič;P Willett'],single,"['Each', 'language', 'part', 'of', 'the', 'bilingual', 'word', 'list', 'was', 'treated', 'independently', 'using', 'the', 'same', 'method,', 'but', 'obviously', 'different', 'corpus.', 'Each', 'word', 'from', 'bilingual', 'word', 'list', 'was', 'stemmed', 'using', 'a', 'modified', 'version', 'of', '<ref type=""single"">(Popovič, 1992)</ref>', 'algorithm', 'that', 'takes', 'into', 'consideration', 'only', 'extensions', 'that', 'were', 'present', 'in', 'paradigms.', 'This', 'means', 'that', 'each', 'word', 'is', 'shortened', 'of', 'the', 'longest', 'possible', 'extension', 'producing', ""word's"", 'stem.', 'All', 'extensions', 'are', 'attached', 'to', 'the', 'stem', 'producing', 'a', 'multiset', 'of', 'words.', 'This', 'multiset', 'is', 'searched', 'in', 'monolingual', 'referential', 'corpus,', 'in', 'our', 'case', '<ref type=""group"">(Erjavec et al., 1998) and (Serbian, 2007),</ref>', 'all', 'words', 'that', 'are', 'found', 'in', 'corpus', 'present', 'a', 'list', 'of', 'possible', 'extensions,', 'thus', 'reducing', 'the', 'number', 'of', 'all', 'extensions', 'to', 'a', 'moderate', 'number.']",32,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4de55fa4-1491-4963-bd30-6e33dff37202,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['Colbert: Efficient and effective passage search via contextualized late interaction over BERT', 'unknown']","['2020', 'unknown']","['Omar Khattab;Matei Zaharia', 'unknown']",group,"['Passage', 're-ranking', 'for', 'open-domain', 'QA', 'Based', 'on', 'the', 'retrieved', 'passages', 'from', 'a', 'first-stage', 'retriever,', 'BERT-based', 'rerankers', 'have', 'recently', 'been', 'applied', 'to', 'retrieval-based', 'question', 'answering', 'and', 'search-related', 'tasks', '<ref type=""group"">(Wang et al., 2019, Nogueira and Cho, 2019, Nogueira et al., 2019b, Yan et al., 2019),</ref>', 'and', 'yield', 'substantial', 'improvements', 'over', 'the', 'traditional', 'methods.', 'Although', 'effective', 'to', 'some', 'extent,', 'these', 'rankers', 'employ', 'the', 'cross-encoder', 'architecture', '(as', 'shown', 'in', 'Figure', '1b)', 'that', 'is', 'impractical', 'to', 'be', 'applied', 'to', 'all', 'passages', 'in', 'a', 'corpus', 'with', 'respect', 'to', 'a', 'question.', 'The', 're-rankers', '<ref type=""group"">(Khattab and Zaharia, 2020, Gao et al., 2020)</ref>', 'with', 'light', 'weight', 'interaction', 'based', 'on', 'the', 'representations', 'of', 'dense', 'retrievers', 'have', 'been', 'studied.', 'However,', 'these', 'techniques', 'still', 'rely', 'on', 'a', 'separate', 'retriever', 'which', 'provides', 'candidates', 'and', 'representations.', 'As', 'a', 'comparison,', 'we', 'focus', 'on', 'developing', 'dual-encoder', 'based', 'retrievers.']",71,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
4e146b7b-4ec3-46ad-9d51-79e400819de8,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['NLTK: the natural language toolkit'],['2002'],['E Loper;S Bird'],single,"['""', '!""!', '#', '$%', '!""!', '&amp,!', '""', '#""!', '#', '$%', '#""!', '&amp,!', '""', '$""!', '#', '$%', '$""!', '&amp,!', '""', '!""#', '#', '$%', '!""#', '&amp,!', '""', '#""#', '#', '$%', '#""#', ""'"", '%', '$""#', '&amp,!', '""', '$""#', '#', '$%', '%""#', ""'"", '%', '&amp,""#', ""'"", '%', '\'""#', '&amp,', '(!', '#', '$!', '""', '!""!', ""'!"", '""', '!""#', ""'!"", '""', '!""$', '&amp,', '(#', '#', '$!', '""', '#""!', ""'!"", '""', '#""#', ""'!"", '""', '#""$', '&amp,', '($', '#', '$!', '""', '$""!', ""'!"", '""', '$""#', ""'!"", '""', '$""$', '&amp,!', '""', '!""$', '#', '$%', '!""$', '&amp,!', '""', '#""$', '#', '$%', '#""$', '&amp,!', '""', '$""$', '#', '$%', '$""$', '&amp,For', 'the', 'Japanese', 'data,', 'we', 'use', 'the', 'annotation', 'labels', 'provided', 'in', 'the', 'corpus.', 'Note', 'that', 'some', 'of', 'the', 'POS', 'tags', 'are', 'estimated', 'using', 'a', 'morphological', 'analysis', 'model.', 'For', 'the', 'English', 'data,', 'we', 'obtain', 'these', 'sequences', 'from', 'the', 'pronunciation', 'dictionary', 'provided', 'in', 'the', 'corpus', 'and', 'WordNet', '<ref type=""single"">(Miller, 1998),</ref>', 'respectively.', 'Some', 'words', 'in', 'the', 'vocabulary', 'have', 'two', 'or', 'more', 'pronunciations', 'in', 'the', 'pronunciation', 'dictionary.', 'To', 'obtain', 'phoneme', 'sequences,', 'we', 'randomly', 'selected', 'a', 'single', 'pronunciation', 'per', 'word', 'from', 'the', 'candidate', 'pronunciations.', 'Since', 'in', 'WordNet,', '57', '%', 'of', 'the', 'words', 'in', 'the', 'corpus', 'are', 'not', 'annotated', 'with', 'the', 'POS', 'tags,', 'we', 'annotated', 'these', 'labels', 'with', 'the', 'output', 'of', 'the', 'POS', 'tagging', 'system', '<ref type=""single"">(Loper and Bird, 2002).</ref>', 'Next,', 'we', 'replaced', 'these', 'phonemes', 'and', 'POS', 'tags', 'with', 'special', 'symbols', '(Fig.', '2(c))', 'to', 'distinguish', 'them', 'from', 'the', 'grapheme', 'symbols.', 'Third,', 'we', 'split', 'graphemic', 'and', 'linguistic', 'annotation', 'sequences', 'at', 'word', 'boundaries', 'and', 'obtain', 'sub-sequences', '(ȳ', 'i,k', 'in', 'Eq.', '(8))', '(Fig.', '2(d)).', 'Then', 'sub-sequences', 'are', 'aggregated', 'with', 'the', 'segments', '(s', 'i', 'in', 'Eq.', '(8))', 'and', 'collapsed', 'into', 'the', 'target', 'sequence', 'in', 'the', 'manner', 'of', 'Eq.', '(8)', '(Fig.', '2(e)).', 'For', 'the', 'English', 'data,', 'we', 'applied', 'byte-pair', 'encoding', '(BPE)', '<ref type=""single"">(Kudo and Richardson, 2018)</ref>', 'to', 'the', 'collapsed', 'target', 'sequence', '(Fig.', '2(f)).']",205,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4e8b6a77-d4be-4046-a02a-97f40d073544,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['Lexical-Functional Grammar: A Formal System for Grammatical Representation'],['1982'],['R Bresnan ; Kaplan;J Bresnan;J Bresnan;R Kaplan;A Zaenen'],single,"['A', 'CSC', 'captures', 'ordering', 'constraints', 'of', 'natural', 'language,', 'and', 'it', 'roughly', 'corresponds', 'to', 'phrase', 'structure', 'rules.', 'CSCs', 'can', 'be', 'used', 'to', 'represent', 'syntax', 'and', 'semantics', 'of', 'sentences', 'at', 'different', 'levels', 'of', 'abstraction', 'from', 'instances', 'of', 'surface', 'sequence', 'to', 'linguistically', 'motivated', 'grammar', 'such', 'as', 'Lexical-Functional', 'Grammar', '(LFG)', '<ref type=""single"">[Kaplan and Bresnan, 1982].</ref>', 'As', 'shown', 'in', 'figure', '2,', 'a', 'CSC', 'consists', 'of', 'a', 'root', 'node', '(CSR),', 'element', 'nodes', '(CSE),', 'a', 'FIRST', 'link,', 'a', 'LAST', 'link,', 'NEXT', 'link(s)', 'and', 'ROLE', 'links.', 'A', 'CSR', 'is', 'a', 'representative', 'node', 'for', 'the', 'meaning', 'of', 'the', 'entire', 'CSC', 'structure,', 'CSRs', 'are', 'connected', 'to', 'their', 'designated', 'interlingual', 'concepts', 'by', 'ENG', 'or', 'JPN.', 'Each', 'CSC', 'has', 'one', 'or', 'more', 'CSEs', 'linked', 'to', 'a', 'CSR', 'by', 'ROLE', 'links.', 'The', 'ordering', 'constraints', 'between', 'two', 'concept', 'sequence', 'element', 'nodes', 'are', 'represented', 'by', 'NEXT', 'link.', 'FIRST', 'and', 'LAST', 'links', 'in', 'each', 'CSC', 'points', 'to', 'the', 'first', 'and', 'last', 'elements,', 'respectively.', 'Also,', 'each', 'CSE', 'represents', 'the', 'relevant', 'case', 'role,', 'and', 'the', 'case', 'role', 'has', 'a', 'selectional', 'restriction.', 'Since', 'we', 'want', 'to', 'avoid', 'heavy', 'symbolic', 'operations', 'during', 'parsing,', 'ROLE', 'links', 'and', 'associated', 'constraint', 'links', 'are', 'used', 'instead', 'of', 'performing', 'type', 'and', 'value', 'consistency', 'check', 'by', 'unification.', 'Therefore', 'each', 'CSE', 'is', 'used', 'for', 'both', 'enforcing', 'the', 'ordering', 'constraint', 'and', 'capturing', 'semantic', 'information.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4efe12ff-7f24-4f00-b753-ebd288c416e0,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['ORCAS: 20 million clicked query-document pairs for analyzing search'],['2020'],['Nick Craswell;Daniel Campos;Bhaskar Mitra;Emine Yilmaz;Bodo Billerbeck'],single,"['Unlabeled', 'questions', 'We', 'collect', '1.7', 'million', 'unlabeled', 'questions', 'from', 'Yahoo!', 'Answers', '5,', 'ORCAS', '<ref type=""single"">(Craswell et al., 2020)</ref>', 'and', 'MRQA', '<ref type=""single"">(Fisch et al., 2019).</ref>', 'We', 'use', 'the', 'questions', 'from', 'Yahoo!', 'Answers,', 'ORCAS', 'and', 'NQ', 'as', 'new', 'questions', 'in', 'the', 'experiments', 'of', 'MSMARCO.', 'We', 'only', 'use', 'the', 'questions', 'from', 'MRQA', 'as', 'the', 'new', 'questions', 'in', 'the', 'experiments', 'of', 'NQ.', 'Since', 'both', 'NQ', 'and', 'MRQA', 'mainly', 'contain', 'factoid-questions,', 'while', 'other', 'datasets', 'contain', 'both', 'factoid', 'and', 'non-factoid', 'questions.']",13,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4f36509e-1b50-49b4-8d26-e311e3198c69,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,"['The TALP ngram-based SMT system for IWSLT', 'The university of washington machine translation system for the iwslt 2007 competition', 'Arabic preprocessing schemes for statistical machine translation']","['2007', '2007', '2006']","['P Lambert;M Costa-Jussà;J Crego;M Khalilov;J No;R Banchs;J Fonollosa;H Schwenk', 'K Kirchhoff;M Yang', 'N Habash;F Sadat']",group,"['There', 'is', 'a', 'large', 'body', 'of', 'work', 'in', 'the', 'literature', 'showing', 'that', 'a', 'morphological', 'decomposition', 'of', 'the', 'Arabic', 'words', 'can', 'improve', 'the', 'word', 'coverage', 'and', 'by', 'these', 'means', 'the', 'translation', 'quality,', 'see', 'for', 'instance', '<ref type=""group"">[10, 14, 15].</ref>', 'This', 'is', 'in', 'particular', 'true', 'for', 'under-resourced', 'tasks', 'like', 'this', 'evaluation.', 'Most', 'of', 'the', 'published', 'work', 'is', 'based', 'on', 'the', 'freely', 'available', 'tools,', 'like', 'the', 'Buckwalter', 'transliterator', 'and', 'the', 'MADA', 'and', 'TOKAN', 'tools', 'for', 'morphological', 'analysis', 'from', 'Columbia', 'University.']",34,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
4f6067c2-de52-4400-9a44-eb13b17ff731,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['unknown'],['unknown'],['unknown'],single,"['Each', 'annotated', 'document', 'consists', 'of', 'a', 'title', 'and', '3', 'paragraphs', 'of', 'text,', 'and', 'contains', 'a', 'list', 'of', 'non-pronominal', 'base-NPs', '(most', 'identified', 'by', 'SpaCy', '<ref type=""single"">[Honnibal et al., 2020]</ref>', '9', 'but', 'some', 'added', 'manually', 'by', 'the', 'annotators),', 'a', 'list', 'of', 'coreference', 'clusters', 'over', 'the', 'NPs,', 'and', 'a', 'list', 'of', 'NP-relations', 'that', 'hold', 'in', 'the', 'text.', 'Each', 'relation', 'is', 'a', 'triplet', 'consisting', 'of', 'two', 'NPs', 'from', 'the', 'NP', 'list,', 'and', 'a', 'connecting', 'element', 'which', 'is', 'one', 'of', '23', 'prepositions', '(displayed', 'in', 'Table', '1)', '10', 'or', 'a', ""''member(s)"", ""of''"", 'relation', 'designating', 'set-membership.', 'The', 'list', 'of', 'NP', 'relations', 'is', 'exhaustive,', 'and', 'aims', 'to', 'cover', 'all', 'and', 'only', 'valid', 'NP-NP', 'relations', 'in', 'the', 'document.']",23,"[3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4fa279b1-f81e-4b97-a92d-1eec7beaf4b9,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['Natural questions: a benchmark for question answering research'],['2019'],['Tom Kwiatkowski;Jennimaria Palomaki;Olivia Redfield;Michael Collins;Ankur Parikh;Chris Alberti;Danielle Epstein;Illia Polosukhin;Jacob Devlin;Kenton Lee;Kristina Toutanova;Llion Jones;Matthew Kelcey;Ming-Wei Chang;Andrew Dai;Jakob Uszkoreit;Quoc Le;Slav Petrov'],single,"['Third,', 'it', 'is', 'expensive', 'to', 'acquire', 'large-scale', 'training', 'data', 'for', 'open-domain', 'QA.', 'MSMARCO', 'and', 'Natural', 'Questions', '<ref type=""single"">(Kwiatkowski et al., 2019)</ref>', 'are', 'two', 'largest', 'datasets', 'for', 'open-domain', 'QA.', 'They', 'are', 'created', 'from', 'commercial', 'search', 'engines,', 'and', 'have', '516K', 'and', '300K', 'annotated', 'questions,', 'respectively.', 'However,', 'it', 'is', 'still', 'insufficient', 'to', 'cover', 'all', 'the', 'topics', 'of', 'questions', 'issued', 'by', 'users', 'to', 'search', 'engines.']",16,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
4fc9994e-e039-4a13-8414-cdda4281fbd9,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,"['Preliminary Considerations on the Constitution of an ELTA (European Language Technology Agency). Pisa, Document prepared for DG XIII']",['1991'],['A Zampolli'],single,"['The', '1986', 'Grosseto', '(Tuscany)', 'Workshop', '""On', 'automating', 'the', 'lexicon""', '<ref type=""single"">(Walker et al. 1995)</ref>', 'is', 'usually', 'recognised', 'as', 'the', 'event', 'marking', 'an', 'inversion', 'of', 'tendency', 'and', 'the', 'starting', 'point', 'of', 'the', 'process', 'which', 'gradually', 'brought', 'the', 'major', 'actors', 'of', 'the', 'NLP', 'sector', 'to', 'pay', 'more', 'and', 'more', 'attention', 'to', 'reusable', 'language', 'resources.', 'This', 'process,', 'which', 'was', 'fostered', 'by', 'a', 'number', 'of', 'initiatives', 'which', 'followed', 'directly', 'from', 'the', 'Grosseto', 'workshop,', 'achieved', 'a', 'crucial', 'step', 'through', 'the', 'recognition,', 'in', 'the', 'so-', '<ref type=""single"">called Danzin Report (1992),</ref>', 'of', 'the', 'infrastructural', 'role', 'of', 'LR', '(see', 'also', '<ref type=""single"">Zampolli 1991).</ref>', 'This', 'was', 'very', 'influential', 'in', 'the', 'formation', 'of', 'the', 'strategy', 'of', 'the', 'European', 'Commission', '(EC).', 'In', 'fact,', 'the', 'issue', 'of', 'LR', 'is', 'now', 'regularly', 'present', 'in', 'the', 'initiatives', 'of', 'the', 'EC', 'in', 'the', 'field', 'of', 'language', 'processing.']",84,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
502e9260-b205-4917-9dfc-ed0109b60e80,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Making sense of word embeddings'],['2016'],['Maria Pelevina;Nikolay Arefiev;Chris Biemann;Alexander Panchenko'],single,"['Hope', 'and', 'Keller', '(2013),', 'for', 'example,', 'use', 'a', 'graph', 'of', 'co-occurrences', 'for', 'word', 'sense', 'induction.', 'Later', '<ref type=""single"">Pelevina et al. (2016)</ref>', 'use', 'a', 'similar', 'method', 'to', 'disambiguate', 'word', 'embedding', 'models.']",16,"[3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
5041b755-2716-48ea-91d9-f0d9d32880e5,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,"['Assessing composition in sentence vector representations', 'Targeted syntactic evaluation of language models', 'What you can cram into a single $&!#* vector: Probing sentence embeddings for linguistic properties', 'Intrinsic probing through dimension selection', 'Informationtheoretic probing with minimum description length', 'Do sequence-tosequence VAEs learn global features of sentences?', 'Designing and interpreting probes with control tasks', 'Information-theoretic probing for linguistic structure']","['2018', '2018', '2018', '2020', '2020', '2020', '2019', '2020']","['Allyson Ettinger;Ahmed Elgohary;Colin Phillips;Philip Resnik', 'Rebecca Marvin;Tal Linzen', 'Alexis Conneau;German Kruszewski;Guillaume Lample;Loïc Barrault;Marco Baroni', 'Adina Lucas Torroba Hennigen;Ryan Williams;unk Cotterell', 'Elena Voita;Ivan Titov', 'Tom Bosc;Pascal Vincent', 'John Hewitt;Percy Liang', 'Tiago Pimentel;Josef Valvoda;Rowan Hall Maudslay;Ran Zmigrod;Adina Williams;Ryan Cotterell']",group,"['Learning', 'task-agnostic', 'unsupervised', 'representations', 'of', 'data', 'has', 'been', 'the', 'center', 'of', 'attention', 'across', 'various', 'areas', 'of', 'Machine', 'Learning', 'and', 'more', 'specifically', 'NLP.', 'However,', 'little', 'is', 'known', 'about', 'the', 'way', 'these', 'continuous', 'representations', 'organise', 'information', 'about', 'data.', 'In', 'recent', 'years,', 'the', 'NLP', 'community', 'has', 'focused', 'on', 'the', 'question', 'of', 'design', 'and', 'selection', 'of', 'suitable', 'linguistic', 'tasks', 'to', 'probe', 'the', 'presence', 'of', 'syntactic', 'or', 'semantic', 'phenomena', 'in', 'representations', 'as', 'a', 'whole', '<ref type=""group"">(Bosc and Vincent, 2020, Voita and Titov, 2020, Torroba Hennigen et al., 2020, Pimentel et al., 2020, Hewitt and Liang, 2019, Ettinger et al., 2018, Marvin and Linzen, 2018, Conneau et al., 2018).</ref>', 'Nonetheless,', 'a', 'finegrain', 'understanding', 'of', 'information', 'organisation', 'in', 'coordinates', 'of', 'a', 'continuous', 'representation', 'is', 'yet', 'to', 'be', 'achieved.']",69,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
508a12a1-fd09-42b9-8acc-c7f069798e9b,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Gender identity and lexical variation in social media'],['2014'],['David Bamman;Jacob Eisenstein;Tyler Schnoebelen'],single,"['It', 'is', 'because', 'solely', 'relying', 'on', 'network', 'homophily', 'as', 'the', 'inductive', 'bias', 'for', 'generating', 'profiles', 'caused', 'the', 'method', 'of', '<ref type=""single"">Mishra et al. (2018a)</ref>', 'to', 'make', 'some', 'faulty', 'generalizations.', 'Such', 'observations', 'have', 'also', 'been', 'made', 'by', 'other', 'works,', 'a', 'prominent', 'one', 'of', 'which', 'is', 'the', 'work', 'of', '<ref type=""single"">Bamman et al. (2014)</ref>', 'who', 'explored', 'the', 'relationships', 'amongst', 'gender,', 'language,', 'and', 'social', 'network', 'connections.', 'The', 'researchers', 'noted', 'that', 'even', 'though', 'there', 'may', 'exist', 'many', 'linguistic', 'clusters', 'that', 'exhibit', 'strong', 'orientations', 'to', 'one', 'gender,', 'yet', 'the', 'characteristics', 'of', 'any', 'particular', 'cluster', 'do', 'not', 'necessarily', 'align', 'with', 'populationlevel', 'statistics', 'for', 'that', 'gender.', 'Furthermore,', 'they', 'observed', 'that', 'there', 'are', 'individuals', 'whose', 'linguistic', 'practices', 'differ', 'from', 'population-level', 'trends', 'for', 'their', 'gender', 'and', 'that', 'gender', 'homophily', 'does', 'not', 'capture', 'their', 'linguistic', 'practices.']",43,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
50d87801-0834-4de7-ba8e-7ca053ec4521,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['On calibration of modern neural networks'],['2017'],['Chuan Guo;Geoff Pleiss;Yu Sun;Kilian Weinberger'],single,"['Calibration', 'requires', 'that', 'a', ""model's"", 'confidence', 'on', 'its', 'predictions', 'is', 'equal', 'to', 'the', 'accuracy', 'of', 'these', 'predictions', '<ref type=""single"">(Guo et al., 2017).</ref>', 'Previous', 'work', '<ref type=""group"">(Müller et al., 2019, Kumar and Sarawagi, 2019, Wang et al., 2020)</ref>', 'has', 'found', 'that', 'a', 'more', 'calibrated', 'text', 'generation', 'model', 'tends', 'to', 'have', 'better', 'performance,', 'and', 'techniques', 'like', 'label', 'smoothing', 'can', 'improve', 'both', 'the', 'token-level', 'calibration', 'and', 'sequence-level', 'accuracy', '(i.e.', 'the', 'ability', 'of', 'generating', 'better', 'results).', 'One', 'intuitive', 'explanation', 'of', 'this', 'phenomenon', 'is', 'to', 'interpret', 'the', ""model's"", 'estimated', 'probability', 'of', 'a', 'generated', 'summary', 'as', 'the', 'product', 'of', 'the', ""model's"", 'confidences', 'on', 'a', 'series', 'of', 'tokenlevel', 'predictions.', 'Then,', 'since', 'a', 'more', 'calibrated', ""model's"", 'confidence', 'estimates', 'better', 'the', 'accuracy', 'of', 'its', 'predictions,', 'the', ""model's"", 'estimated', 'probability', 'of', 'one', 'sequence', 'should', 'be', 'more', 'indicative', 'of', 'the', 'quality', 'of', 'this', 'sequence,', 'which', 'is', 'essential', 'for', 'the', 'beam', 'search', 'during', 'inference.', 'However,', 'the', 'relation', 'of', 'token-level', 'calibration', 'and', 'sequencelevel', 'performance', 'remains', 'inconclusive', '<ref type=""single"">(Müller et al., 2019).</ref>', '10', 'For', 'example,', 'a', 'generator', 'that', 'always', 'predicts', 'a', 'uniform', 'distribution', 'over', 'all', 'tokens', 'would', 'be', 'perfectly', 'calibrated,', 'however,', 'such', 'a', 'model', 'would', 'not', 'generate', 'high-quality', 'outputs.']",17,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
50db6fee-0fc1-45e1-a03a-56e4f673d3d7,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Evaluating the evaluation of diversity in natural language generation'],['2021'],['Guy Tevet;Jonathan Berant'],single,"['Designing', 'neural', 'diversity', 'metrics.', 'In', 'spite', 'of', 'growing', 'interest', 'in', 'NLG', 'models', 'that', 'produce', 'diverse', 'outputs,', 'there', 'is', 'currently', 'no', 'principled', 'neu-ral', 'method', 'for', 'evaluating', 'the', 'diversity', 'of', 'an', 'NLG', 'system.', 'As', 'described', 'in', '<ref type=""single"">Tevet and Berant (2021),</ref>', 'existing', 'automatic', 'diversity', 'metrics', '(e.g.', 'Self-BLEU)', 'perform', 'worse', 'than', 'humans', 'on', 'the', 'task', 'of', 'estimating', 'content', 'diversity,', 'indicating', 'a', 'low', 'correlation', 'between', 'metrics', 'and', 'human', 'judgments.']",34,"[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
5130579f-6987-43d4-8d91-92e4d163e732,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Linear indexed automata and tabulation of TAG parsing'],['1998'],['M-J Nederhof'],single,"['These', 'items', 'are', 'like', 'those', 'proposed', 'for', 'the', 'tabulation', 'of', 'linear', 'indexed', 'automata', '<ref type=""single"">[10]</ref>', 'LCYK', '=', '{[A,', ',y,i,j', 'I', 'B,', 'p,q]', 'I', 'A,', 'B', 'E', 'VN,', ""'Y"", 'E', 'Vi,', '0', '::,', 'i::,', 'j,', '(p,q)', '::,', '(i,', 'j)}', '11.cYK', '=', '{[a,', 'i', '-1,', 'i]', 'I', 'a', '=', 'ai,', 'lJ', '::,', 'i', '::,', 'n}', 'v', 'scan', '-', '[a,j,', 'j', '+', '1]', 'A[]', '➔', 'a', 'E', 'p', 'CYK', '-[A..', '1', '1', '],', '-,', '1,', '1+', '-,', '-,', '-I', '[B,-,', 'i,', 'k', '1', '-,', '-,', '-],', '1)[00-y](', '](oo]', '_', '[C,', '17', ',k,j', 'I', 'D,']",13,"[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
5143c579-3b3d-49b8-876d-4f9ff5f5c6fe,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['unknown'],['unknown'],['unknown'],single,"['In', 'practice,', 'the', 'separation', 'of', 'question', 'encoding', 'and', 'passage', 'encoding', 'is', 'desirable,', 'so', 'that', 'the', 'dense', 'representations', 'of', 'all', 'passages', 'can', 'be', 'precomputed', 'for', 'efficient', 'retrieval.', 'Here,', 'we', 'adopt', 'two', 'independent', 'neural', 'networks', 'initialized', 'from', 'pre-trained', 'LMs', 'for', 'the', 'two', 'encoders', 'E', 'q', '(•)', 'and', 'E', 'p', '(•)', 'separately,', 'and', 'take', 'the', 'representations', 'at', 'the', 'first', 'token', '(e.g.,', '<ref type=""single"">[CLS]</ref>', 'symbol', 'in', 'BERT)', 'as', 'the', 'output', 'for', 'encoding.']",58,"[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2]"
51ae962b-d5d2-4ebf-a02c-3eb127106cb7,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Distributed representations of words and phrases and their compositionality'],['2013'],['Tomas Mikolov;Ilya Sutskever;Kai Chen;Greg Corrado;Jeff Dean'],single,"['cosine', 'similarity', 'in', 'Skip-gram', '<ref type=""single"">(Mikolov et al., 2013),</ref>']",4,"[1, 1, 1, 1, 1]"
51f99389-855e-4869-b864-83335779ebb3,Comparison of post-editing productivity between professional translators and lay users,2014,Nora Aranberri;Gorka Labaka,['The impact of machine translation quality on human post-editing'],['2014'],['P Koehn;U Germann'],single,"['MT', 'output', 'quality', 'is', 'also', 'essential', 'in', 'post-editing', 'measurements,', 'a', 'factor', 'that', 'is', 'often', 'neglected', 'when', 'reporting', 'productivity', 'gain.', 'An', 'exception', 'is', 'a', 'seminal', 'work', 'by', '<ref type=""single"">Koehn and Germann (2014).</ref>', 'They', 'studied', 'the', 'relation', 'between', 'MT', 'quality', 'and', 'post-editing,', 'and', 'concluded', 'that', 'differences', 'in', 'post-editing', 'skills', 'might', 'be', 'more', 'decisive', 'than', 'MT', 'quality', 'to', 'foresee', 'productivity', 'gain', 'when', 'comparing', 'systems', 'within', 'the', 'same', 'quality', 'range.', 'Our', 'findings', 'show', 'that', 'the', 'text', 'for', 'which', 'a', 'higher', 'increase', 'in', 'productivity', 'was', 'obtained', 'seems', 'to', 'be', 'slightly', 'easier', 'and', 'better', 'suited', 'for', 'our', 'MT', 'system.']",26,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
5271dccb-0e35-481e-963e-999cb0e82b20,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['Named entity recognition using cross-lingual resources: Arabic as an example'],['2013'],['Kareem Darwish'],single,"['We', 'evaluate', 'on', '7', 'sequence', 'labelling', 'benchmarks:', '4', 'of', 'which', 'are', 'NER', 'datasets', 'and', '3', 'of', 'which', 'are', 'POStagging', 'datasets', '1.', 'In', 'brief,', 'each', 'dataset', 'consists', 'of', 'a', 'sequence', 'of', 'sentences,', 'where', 'each', 'sentence', 'has', 'a', 'sequence', 'of', '(word:tag)', 'pairs.', 'For', 'NER', 'we', 'use', 'the', 'BinAjeeba', '<ref type=""single"">(Darwish, 2013),</ref>', 'the', 'ANERCorp', 'developed', 'by', '<ref type=""single"">Benajiba et al. (2007),</ref>', 'and', 'the', 'Wikipedia', 'and', 'Newswire', 'datasets', 'which', 'are', 'mapped', '2', 'versions', 'of', 'the', 'fine-grained', 'WikiFANE', 'and', 'NewsFANE', 'datasets', '<ref type=""single"">(Alotaibi and Lee, 2014)</ref>', 'respectively.', 'For', 'POStagging', 'we', 'are', 'evaluating', 'on', '3', 'standard', 'datasets:', 'WikiNews', '<ref type=""single"">(Abdelali et al., 2019),</ref>', 'Al-Mushaf', '<ref type=""single"">(Zeroual and Abdelhak, 2016),</ref>', 'Prague', 'Arabic', 'Dependency', 'Tree', 'Bank', '(PADT)', '<ref type=""single"">(Hajic et al., 2004).</ref>']",46,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
52811710-c5e0-4a60-b6d3-6b78513ac43b,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,"['Massively Parallel Memory-Based Parsing', 'Parallel Incremental Sentence Produclion for a Model of Simultaneous Interpretation']","['1991', '1989']","['( Kitano;H Higuchi ; Kitano;T Higuchi', 'H Kitano;H Kitano;H Kitano;H Tomabechi;Levin unk']",group,"['called', 'DMSNAP', 'using', 'a', 'parallel', 'marker-passing', 'scheme.', 'DM-SNAP', 'is', 'a', 'SNAP', 'implementation', 'of', 'the', 'ΦDMDIALOG', 'speechto-speech', 'dialogue', 'translation', 'system', '<ref type=""group"">[Kitano, 1990a ] [Kitano, 1991a],</ref>', 'but', 'with', 'some', 'modifications', 'to', 'meet', 'hardware', 'constraints.', 'Despite', 'its', 'high', 'performance,', 'our', 'system', 'carries', 'out', 'sound', 'syntactic', 'and', 'semantic', 'analysis', 'including', 'lexical', 'ambiguity,', 'structural', 'ambiguity,', 'pronoun', 'reference,', 'control,', 'unbounded', 'dependency,', 'and', 'others.']",19,"[0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
5293abbf-b0a5-4258-a596-9192d4225de3,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Classifying arguments by scheme'],['2011'],['Vanessa Wei Feng;Graeme Hirst'],single,"['Some', 'research', 'adopted', 'argumentation', 'schemes', 'as', 'a', 'framework,', 'making', 'comparisons', 'with', 'discourse', 'relations', '<ref type=""single"">(Cabrio et al., 2013)</ref>', 'and', 'collecting', 'and', 'leveraging', 'data', 'at', 'varying', 'degrees', 'of', 'granularity.', 'At', 'a', 'coarse', 'level,', 'prior', 'studies', 'annotated', 'the', 'presence', 'of', 'particular', 'argumentation', 'schemes', 'in', 'text', '<ref type=""group"">(Visser et al., 2020, Lawrence et al., 2019, Lindahl et al., 2019, Reed et al., 2008)</ref>', 'and', 'developed', 'models', 'to', 'classify', 'different', 'schemes', '<ref type=""single"">(Feng and Hirst, 2011).</ref>', 'However,', 'each', 'scheme', 'often', 'accommodates', 'both', 'support', 'and', 'attack', 'relations', 'between', 'statements,', 'so', 'classifying', 'those', 'relations', 'requires', 'semantically', 'richer', 'information', 'within', 'the', 'scheme', 'than', 'just', 'its', 'presence.', 'To', 'that', 'end,', '<ref type=""single"">Reisert et al. (2018)</ref>', 'annotated', 'individual', 'components', 'within', 'schemes,', 'particularly', 'emphasizing', 'argument', 'from', 'consequences.', 'Based', 'on', 'the', 'logic', 'behind', 'this', 'scheme,', '<ref type=""single"">Kobbe et al. (2020)</ref>', 'developed', 'an', 'unsupervised', 'method', 'to', 'classify', 'the', 'support', 'and', 'attack', 'relations', 'using', 'syntactic', 'rules', 'and', 'lexicons.', 'Our', 'work', 'extends', 'these', 'studies', 'by', 'including', 'other', 'normative', 'schemes', '(practical', 'reasoning', 'and', 'property-based', 'reasoning)', 'and', 'annotating', 'richer', 'information.']",47,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
533f8df9-6d1c-453c-8cd3-265fe8d10732,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['unknown'],['unknown'],['unknown'],single,"['Job', 'Selection', 'Collecting', 'and', 'generating', 'job', 'ads', 'for', 'all', 'possible', 'jobs', 'is', 'prohibitively', 'timely', 'and', 'costly.', 'Hence,', 'we', 'restrict', 'our', 'experiments', 'to', 'a', 'sample', 'of', '15', 'jobs', 'selected', 'via', 'three', 'criteria:', '(1)', 'prevalence,', 'jobs', 'with', 'a', 'sufficiently', 'large', 'labour', 'force', 'in', 'the', 'UK', '(N', '≥', '40,000),', '(2)', 'relevance,', 'jobs', 'which', 'have', 'a', 'sufficiently', 'large', 'number', 'of', 'real-world', 'job', 'ads', 'on', 'a', 'popular', 'online', 'forum', '(N', '≥', '1,000)', 'and', '(3)', 'bias,', 'jobs', 'which', 'represent', 'the', 'most', 'male-biased,', 'female-biased', 'and', 'neutral', 'parts', 'of', ""GPT-3's"", 'prior', 'distribution', 'in', 'how', 'frequently', 'certain', 'jobs', 'are', 'associated', 'with', 'a', 'given', 'gender.', 'To', 'apply', 'these', 'criteria,', 'we', 'first', 'filter', 'jobs', 'in', 'the', 'UK', 'economy', 'by', 'prevalence', 'and', 'relevance', '<ref type=""single"">(ONS, 2018).</ref>', 'Then', 'to', 'estimate', ""GPT-3's"", 'priors', 'of', 'occupational', 'bias,', 'we', 'generate', '1,000', 'completions', 'for', 'the', 'prompt', '""What', 'gender', 'is', 'the', '{job}?', 'The', '{job}', 'is', 'a', '[token]"",', 'where', 'a', 'completion', 'could', 'be:', '""What', 'gender', 'is', 'the', 'plumber?']",111,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
535d0f79-ae06-49ad-9631-0759b8d98c7f,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,"['unknown', 'Baidu neural machine translation systems for WMT19', 'unknown']","['2020', '2019', 'unknown']","['Fandong Meng;Jianhao Yan;Yijin Liu;Yuan Gao;Xianfeng Zeng;Qinsong Zeng;Peng Li;Ming Chen;Jie Zhou;Sifan Liu', 'Meng Sun;Bojian Jiang;Hao Xiong;Zhongjun He;Hua Wu;Haifeng Wang', 'unknown']",group,"['As', 'shown', 'in', 'previous', 'work', '<ref type=""group"">(Wang et al., 2019, Sun et al., 2019, Meng et al., 2020),</ref>', 'increasing', 'the', 'depth', 'of', 'the', 'Transformer', 'encoder', 'can', 'substantially', 'improve', 'model', 'performance,', 'therefore', 'we', 'train', 'the', 'Transformer', 'with', 'deep', 'encoder', 'to', 'obtain', 'a', 'better', 'source', 'representation.']",5,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
5391071f-0afc-4232-951a-a73971c384a7,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,"['BRUMS at SemEval-2020 task 12: Transformer based multilingual offensive language identification in social media', 'BRUMS at HASOC 2019: Deep learning models for multilingual hate speech and offensive language identification', 'Offensive language identification in Greek']","['2020', '2019', '2020']","['Tharindu Ranasinghe;Hansi Hettiarachchi', 'Tharindu Ranasinghe;Marcos Zampieri;Hansi Hettiarachchi', 'Zesis Pitenis;Marcos Zampieri;Tharindu Ranasinghe']",group,"['The', 'main', 'motivation', 'behind', 'the', 'TransWiC', 'architecture', 'is', 'the', 'success', 'transformer-based', 'architectures', 'had', 'in', 'various', 'natural', 'language', 'processing', 'tasks', 'like', 'offensive', 'language', 'identification', '<ref type=""group"">(Ranasinghe and Hettiarachchi, 2020, Ranasinghe et al., 2019c, Pitenis et al., 2020),</ref>', 'offensive', 'spans', 'identification', '<ref type=""group"">(Ranasinghe and Zampieri, 2021a, Ranasinghe et al., 2021),</ref>', 'language', 'detection', '<ref type=""single"">(Jauhiainen et al.,</ref>', 'Lang.']",23,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3]"
53f7484f-1cf2-4fc8-a26f-30cd0fbc5f22,drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM,2022,Dylan Phelps,['SemEval-2022 Task 2: Multilingual Idiomaticity Detection and Sentence Embedding'],['2022'],['Edward Harish Tayyar Madabushi;Marcos Gow-Smith;Carolina Garcia;Marco Scarton;Aline Idiart;unk Villavicencio'],single,"['SemEval-2022', 'task', '2b', '<ref type=""single"">(Tayyar Madabushi et al., 2022)</ref>', 'encourages', 'the', 'creation', 'of', 'better', 'representations', 'of', 'idiomatic', 'expressions', 'across', 'multiple', 'languages', 'by', 'presenting', 'a', 'Semantic', 'Text', 'Similarity', '(STS)', 'task', 'in', 'which', 'correct', 'STS', 'scores', 'are', 'required', 'whether', 'or', 'not', 'either', 'sentence', 'contains', 'an', 'idiomatic', 'expression.', 'The', 'sub-task', 'requires', 'the', 'creation', 'of', 'a', 'self-consistent', 'model', 'in', 'which', 'a', 'sentence', 'including', 'an', 'idiomatic', 'expression', 'and', 'one', 'containing', 'its', 'literal', 'meaning', ""('swan"", ""song'"", 'and', ""'final"", ""performance')"", 'are', 'exactly', 'similar', 'to', 'each', 'other', 'and', 'equally', 'similar', 'to', 'any', 'other', 'sentence.']",3,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
5432b066-cfa4-4d54-936f-dbdacff11957,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['Recursive deep models for semantic compositionality over a sentiment treebank'],['2013'],['Richard Socher;Alex Perelygin;Jean Wu;Jason Chuang;D Christopher;Andrew Manning;Christopher Ng;unk Potts'],single,"['We', 'apply', 'the', 'proposed', 'framework', 'and', 'quantify', 'second-order', 'robustness', 'through', 'two', 'second-order', 'attacks', '(§3).', 'We', 'experiment', 'with', 'English', 'sentiment', 'classification', 'on', 'the', 'SST-2', 'dataset', '<ref type=""single"">(Socher et al., 2013)</ref>', 'across', 'various', 'model', 'architectures.', 'Surprisingly,', 'although', 'robustly', 'trained', 'CNN', '<ref type=""single"">(Jia et al., 2019)</ref>', 'and', 'Transformer', '<ref type=""single"">(Xu et al., 2020)</ref>', 'can', 'achieve', 'high', 'robustness', 'under', 'strong', 'attacks', '<ref type=""group"">(Alzantot et al., 2018, Garg and Ramakrishnan, 2020)</ref>', '(23.0%-71.6%', 'success', 'rates),', 'for', 'around', '96.0%', 'of', 'the', 'test', 'examples', 'our', 'attacks', 'can', 'find', 'a', 'vulnerable', 'example', 'by', 'perturbing', '1.3', 'words', 'on', 'average.', 'This', 'finding', 'indicates', 'that', 'these', 'robustly', 'trained', 'models,', 'despite', 'being', 'first-order', 'robust,', 'are', 'not', 'second-order', 'robust.']",24,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5433acd7-1d0a-4387-bf37-243e6407e7df,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Babelnet: Building a very large multilingual semantic network'],['2010'],['Roberto Navigli;Simone Ponzetto'],single,"['and', 'the', 'BabelNet', 'knowledge', 'graph', '<ref type=""single"">(Navigli and Ponzetto, 2010b),</ref>', 'with', 'a', 'framework', 'that', 'associates', 'words', 'according', 'to', 'special', 'rules,', 'developed', 'specifically', 'for', 'this', 'purpose.']",5,"[0, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
5435a7ff-18f8-4c4d-bf48-8ae6337450c5,Themes in the work of Margaret Masterman,1988,Yorick Wilks,['Semantic theory'],['1972'],['Jerrold Katz'],single,"['At', 'bottom,', 'she', 'believed', 'that', 'such', 'interlinguas', 'were', 'in', 'need', 'of', 'some', 'form', 'of', 'empirical', 'justification', 'and', 'could', 'not', 'be', 'treated', 'as', 'unprovable', 'and', 'arbitrary', 'assumptions', 'for', 'a', 'system,', 'in', 'the', 'way', '<ref type=""single"">Katz (1972)</ref>', 'has', 'tried', 'to', 'do', 'by', 'arguing', 'from', 'the', 'role', 'of', 'assumed', 'entities', 'in', 'physics', 'and', 'mathematics.', 'There', 'was', 'one', 'weak', 'form', 'of', 'empirical', 'support', 'available:', 'statistics', 'derived', 'from', 'dictionaries', 'showed', 'that', 'the', 'first', '100', 'commonest', 'defining', 'words', 'in', 'English', 'dictionaries', '(exempting', ""'a'"", 'and', ""'the')"", 'corresponded', 'very', 'closely', 'indeed', 'to', 'the', 'primitives', 'of', 'NUDE.', 'But', 'MMB', 'wanted', 'something', 'more', 'structural', 'and', 'spent', 'some', 'considerable', 'time', 'trying', 'to', 'associate', 'the', 'NUDE', 'elements', 'with', 'the', 'classifying', 'principles', 'of', 'the', 'thesaurus', 'itself,', 'which', 'would', 'then', 'link', 'back', 'to', 'the', 'distributional', 'facts', 'about', 'texts', 'that', 'the', 'thesaurus', 'itself', 'represented.', 'In', 'this,', 'as', 'in', 'other', 'ways,', 'MMB', 'had', 'more', 'intuitive', 'sympathy', 'with', 'earlier', 'distributional', 'or', 'structural', 'linguistics', 'than', 'with', 'the', 'more', 'apparently', 'mathematical', 'and', 'symbolic', 'linguistics', 'of', 'Chomsky', 'and', 'his', 'followers.']",32,"[0, 0, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
546e7abb-9962-4e49-bfbc-2c9106ff7d2c,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Unlearn dataset bias in natural language inference by fitting the residual'],['2019'],['He He;Sheng Zha;Haohan Wang'],single,"['In', 'this', 'work,', 'we', 'introduce', 'a', 'framework', 'to', 'automatically', 'identify', 'spurious', 'correlations', 'exploited', 'by', 'the', 'model,', 'sometimes', 'also', 'denoted', 'as', '""shortcuts""', 'in', 'prior', 'work', '<ref type=""group"">(Geirhos et al., 2020, Minderer et al., 2020)</ref>', '1,', 'at', 'a', 'large', 'scale.', 'Our', 'proposed', 'framework', 'differs', 'from', 'existing', 'literature', 'with', 'a', 'focus', 'more', 'on', 'automatic', 'shortcut', 'identification,', 'instead', 'of', 'pre-defining', 'a', 'limited', 'set', 'of', 'shortcuts', 'or', 'learning', 'from', 'human', 'annotations', '(Table', '1).', 'Our', 'framework', 'works', 'as', 'follows:', 'given', 'a', 'task', 'and', 'a', 'trained', 'model,', 'we', 'first', 'utilize', 'interpretability', 'methods,', 'e.g.,', 'attention', 'scores', '<ref type=""group"">(Clark et al., 2019b, Kovaleva et al., 2019)</ref>', 'and', 'integrated', 'gradient', '<ref type=""single"">(Sundararajan et al., 2017)</ref>', 'which', 'are', 'commonly', 'used', 'for', 'interpreting', ""model's"", 'decisions,', 'to', 'automatically', 'extract', 'tokens', 'that', 'the', 'model', 'deems', 'as', 'important', 'for', 'task', 'label', 'Objective', 'Approach', 'for', 'shortcut', 'identification', '<ref type=""single"">He et al. (2019)</ref>', 'Robustness', 'against', 'known', 'shortcuts', 'Pre-defined', '<ref type=""single"">Clark et al. (2019a)</ref>', 'Robustness', 'against', 'known', 'shortcuts', 'Pre-defined', '<ref type=""single"">Clark et al. (2020)</ref>', 'Robustness', 'against', 'unknown', 'shortcuts', 'A', 'low-capacity', 'model', 'to', 'specifically', 'learn', 'shortcuts', '<ref type=""single"">Wang and Culotta (2020a)</ref>', 'prediction.', 'We', 'then', 'introduce', 'two', 'extra', 'steps', 'to', 'further', 'categorize', 'the', 'extracted', 'tokens', 'to', 'be', '""genuine""', 'or', '""spurious"".', 'We', 'utilize', 'a', 'cross-dataset', 'analysis', 'to', 'identify', 'tokens', 'that', 'are', 'more', 'likely', 'to', 'be', '""shortcut"".']",111,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
54bf8c5b-756c-40b2-be3a-ebe0d8d78122,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,"['Annotating events, temporal expressions and relations in italian: the it-timeml experience for the ita-timebank']",['2011'],['Tommaso Caselli;Valentina Lenzi;Rachele Sprugnoli'],single,"['1.', 'The', 'TempEval-3', 'TimeBank', 'dataset', 'was', 'used', 'for', 'English', '<ref type=""single"">(UzZaman et al., 2012).</ref>', 'The', 'corpus', 'consists', 'of', '61,418', 'tokens', 'for', 'training', 'and', '6,756', 'event', 'mentions.', '3.', 'For', 'Italian,', 'we', 'use', ""Ita-TimeBank's"", 'ILC', 'corpus', '<ref type=""single"">(Caselli et al., 2011a)</ref>', 'the', 'Italian', 'corpus', 'annotated', 'using', 'ISO-TimeML', 'rules', 'for', 'events', 'and', 'temporal', 'information.', 'The', 'corpus', 'consists', 'of', '68,000', 'tokens', 'and', '10,591', 'event', 'mentions.']",30,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
55154692-1773-4be6-a947-641923ff7add,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,"['Mixture content selection for diverse sequence generation', 'Mixture models for diverse machine translation: Tricks of the trade']","['2019', '2019']","['Jaemin Cho;Minjoon Seo;Hannaneh Hajishirzi', ""Tianxiao Shen;Myle Ott;Michael Auli;Marc'aurelio Ranzato""]",group,"['To', 'empower', 'the', 'generation', 'model', 'to', 'produce', 'multiple', 'reasonable', 'outputs,', 'we', 'employ', 'a', 'mixture', 'of', 'expert', '(MoE)', 'module', 'to', 'model', 'uncertainty', 'and', 'generate', 'diverse', 'outputs.', 'While', 'the', 'MoE', 'models', 'have', 'primarily', 'been', 'explored', 'as', 'a', 'means', 'of', 'increasing', 'model', 'capacity,', 'they', 'are', 'also', 'being', 'used', 'to', 'boost', 'diverse', 'generation', 'process', '<ref type=""group"">(Shen et al., 2019, Cho et al., 2019).</ref>', 'Formally,', 'the', 'MoE', 'module', 'introduces', 'a', 'multinomial', 'latent', 'variable', 'z', '∈', '{1,', '•,', 'K},', 'and', 'decomposes', 'the', 'marginal', 'likelihood', 'as', 'follows:p(y|x,', 'G', 'x)', '=', 'K', 'z=1', 'p(z|x,', 'G', 'x', ')p(y|z,', 'x,', 'G', 'x', ').', '(7)Training.', 'We', 'minimize', 'the', 'loss', 'function', '(in', 'Eq.(', '6))', 'using', 'the', 'MoE', 'decomposition,∇', 'log', 'p(y|x,', 'G', 'x)', '(8)', '=', 'K', 'z=1', 'p(z|x,', 'y,', 'G', 'x)', '∇', 'log', 'p(y,', 'z|x,', 'G', 'x', '),and', 'train', 'the', 'model', 'with', 'the', 'EM', 'algorithm', '<ref type=""single"">(Dempster et al., 1977).</ref>', 'Ideally,', 'we', 'would', 'like', 'different', 'experts', 'to', 'specialize', 'in', 'different', 'reasoning', 'abilities', 'so', 'that', 'they', 'can', 'generate', 'diverse', 'outputs.', 'The', 'specialization', 'of', 'experts', 'means', 'that', 'given', 'the', 'input,', 'only', 'one', 'element', 'in', '{p(y,', 'z|x,', 'G', 'x', ')}', 'K', 'z=1', 'should', 'dominate', 'in', 'value', '<ref type=""single"">(Shen et al., 2019).</ref>', 'To', 'encourage', 'this,', 'we', 'employ', 'a', 'hard', 'mixture', 'model', 'to', 'maximize', 'max', 'z', 'p(y,', 'z|x,', 'G', 'x)', 'by', 'assigning', 'full', 'responsibility', 'to', 'the', 'expert', 'with', 'the', 'largest', 'joint', 'probability.', 'Training', 'proceeds', 'via', 'hard-EM', 'can', 'be', 'written', 'as:']",50,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
554d25a1-b33a-468b-a977-010856197aab,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,"['Towards hierarchical importance attribution: Explaining compositional semantics for neural sequence models', 'Anchors: High-precision modelagnostic explanations']","['2020', '2018']","['Xisen Jin;Junyi Du;Zhongyu Wei;Xiangyang Xue;Xiang Ren', 'Sameer Marco Tulio Ribeiro;Carlos Singh;unk Guestrin']",group,"['Based', 'on', 'the', 'learned', 'state', 'tracking', 'model,', 'a', 'straightforward', 'idea', 'of', 'obtaining', 'salient', 'words', 'is', 'to', 'apply', 'importance', 'attribution', 'approaches.', 'Specifically,', 'these', 'approaches', 'measure', 'the', 'importance', 'of', 'each', 'word', 'by', 'observing', 'the', 'prediction', 'difference', 'caused', 'by', 'replacing', 'it', '<ref type=""group"">(Ribeiro et al., 2018, Jin et al., 2020).</ref>', 'As', 'discussed', 'before,', 'this', 'would', 'result', 'in', 'different', 'action', 'representations', 'for', 'utterances', 'with', 'the', 'same', 'action.', 'To', 'address', 'this', 'issue,', 'we', 'consider', 'learning', 'action', 'representations', 'from', 'a', 'broader', 'vocabulary,', 'which', 'releases', 'the', 'constraint', 'of', 'selecting', 'salient', 'words', 'only', 'within', 'utterances.']",38,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
561581b3-5e5d-4d16-ba0f-6bdf3e0e473c,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['An Algorithm for Finding Noun Phrase Correspondences in Bilingual Corpora'],['1993'],['J Kupiec'],single,"['We', 'first', 'review', 'three', 'efforts', 'to', 'translate', 'multiword', 'units', 'by', 'scoring', 'POS-tagged', 'phrases', 'or', 'by', 'fusing', 'individual', 'target', 'language', 'words', 'that', 'appear', 'correlated', 'to', 'a', 'source', 'language', 'phrase.', '<ref type=""single"">Kupiec (1993)</ref>', 'examined', 'translation', 'of', 'noun', 'phrases', 'between', 'English', 'and', 'French', 'and', 'reported', '90%', 'accuracy', 'in', 'an', 'informal', 'evaluation', 'of', 'the', 'one', 'hundred', 'translations', 'that', 'had', 'the', 'highest', 'confidence', 'scores.', 'His', 'method', 'requires', 'POS-tagging', 'each', 'sentence', 'in', 'an', 'aligned', 'parallel', 'text', '(i.e.,', 'both', 'sides', 'are', 'tagged).', 'Then', 'noun', 'phrases', 'are', 'scored', 'using', 'an', 'iterative', 'estimation', 'method.', 'Kupiec', 'notes', 'several', 'sources', 'of', 'error', 'caused', 'by', 'problems', 'using', 'POS', 'information', 'instead', 'of', 'constituent', 'parses,', 'such', 'as', 'an', 'inability', 'to', 'infer', 'prepositional', 'phrase', 'attachment.', 'The', 'method', 'relies', 'on', 'having', 'POS', 'tagging', 'or', 'parsing', 'in', 'both', 'languages.']",28,"[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
562bdaad-ce0b-4e37-89a6-42b1cdf5b3a1,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['English Verb Classes and Alternations'],['1993'],['B Levin'],single,"['Many', 'of', 'the', 'lexical', 'items', 'classified', 'into', ""Levin's"", 'verb', 'classes', 'are', 'listed', 'as', 'members', 'of', 'more', 'than', 'one', 'semantic', 'class', '<ref type=""single"">[8].</ref>', 'There', 'are', 'in', 'fact', '3104', 'verbs,', 'but', '4194', 'verb/class', 'pairings,', 'or', 'verb', 'senses,', 'for', 'an', 'average', 'of', '1.35', 'senses', 'per', 'verb.', 'Levin', 'gives', 'only', 'a', 'few', 'informal', 'indications', 'about', 'how', 'to', 'interpret', 'a', 'multiple', 'listing', 'for', 'a', 'verb.', 'Sometimes', 'the', 'verb', 'is', 'listed', 'in', 'several', 'classes', 'because', 'there', 'is', 'a', 'systematic', 'meaning', 'relationship', 'among', 'them.', 'Other', 'times,', 'the', 'multiple', 'categorization', 'seems', 'to', 'be', 'an', 'idiosyncrasy', 'involving', 'two', 'verbs', 'that', 'happen', 'to', 'have', 'the', 'same', 'spelling,', 'i.e.,', 'homonyms.', 'For', 'example,', 'the', 'verb', 'draw', 'is', 'listed', 'as', 'a', 'remove', 'verb', '(class', '10.1),', 'as', 'a', 'scribble', 'verb', '(class', '25.2)', 'and', 'as', 'a', 'performance', 'verb', '(class', '26.7).', 'While', 'the', 'latter', 'two', 'senses', 'seem', 'systematically', 'related', '(both', 'seem', 'to', 'be', 'involved,', 'for', 'example,', 'in', 'a', 'usage', 'like', 'draw', 'a', 'portrait)', 'the', 'remove', 'sense', '(as', 'in', 'draw', 'water', 'from', 'the', 'well)', 'is', 'clearly', 'distinct.']",20,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
56d650b1-39f0-4190-9e3b-38a00e9d075a,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,['BLEU: a method for automatic evaluation of machine translation'],['2002'],['Kishore Papineni;Salim Roukos;Todd Ward;Wei-Jing Zhu'],single,"['Evaluation', 'As', 'evaluation', 'measures,', 'we', 'have', 'adopted', 'corpus', 'BLEU', '<ref type=""single"">[17]</ref>', 'to', 'assess', 'syntactic', 'quality', 'and', 'the', 'Kullback-Leibler', '(KL)', 'divergence', '<ref type=""single"">[12]</ref>', 'between', 'the', 'topic', 'used', 'for', 'conditioning', 'and', 'the', 'topic', 'extracted', 'from', 'the', 'generated', 'sentence', 'to', 'assess', 'semantic', 'coherence.', 'A', 'low', 'KL', 'value', 'means', 'that', 'the', 'distribution', 'inferred', 'from', 'the', 'output', 'of', 'the', 'model', 'is', 'similar', 'to', 'the', 'one', 'extracted', 'from', 'the', 'conditioning', 'input', 'sentence', 'and', 'used', 'as', 'conditioning', 'vector', 'c.', 'This', 'implies', 'that', 'the', 'semantic', 'conditioning', 'has', 'been', 'carried', 'out', 'successfully.']",9,"[0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
576422ff-bf5e-43d7-8875-1be226be96ed,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['A deep generative framework for paraphrase generation'],['2018'],['Ankush Gupta;Arvind Agarwal;Prawaan Singh;Piyush Rai'],single,"['(3)', 'Piano', 'is', 'a', 'kind', 'of', 'art', 'form.', 'generation', '<ref type=""single"">(Gupta et al., 2018).</ref>', 'In', 'these', 'tasks,', 'output', 'spaces', 'are', 'constrained', 'by', 'input', 'context,', 'i.e.,', 'the', 'contents', 'of', 'multiple', 'outputs', 'should', 'be', 'similar,', 'and', 'globally,', 'under', 'the', 'same', 'topic.', 'However,', 'many', 'NLG', 'tasks,', 'e.g.,', 'generative', 'commonsense', 'reasoning,', 'pose', 'unique', 'challenges', 'for', 'generating', 'multiple', 'reasonable', 'outputs', 'that', 'are', 'semantically', 'different.']",9,"[0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
576e6ebf-244e-4aef-9e88-d36961edf4a6,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['unknown'],['2020'],['unk Nguyen Van Nha'],single,"['To', 'disentangle', 'dataset', 'shift', 'and', 'evidence', 'ambiguity', 'of', 'the', 'data', 'splitting', 'strategy,', 'we', 'apply', 'RDS', 'stochastic', 'choice', 'reward', 'mechanism', '<ref type=""single"">(Nguyen et al., 2020)</ref>', 'to', 'create', 'public', 'training,', 'public-and', 'private', 'testing', 'sets.', 'Figure', '3', 'illustrates', 'the', 'learning', 'dynamic', 'towards', 'the', 'goal.']",19,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
577d5c48-8b6e-4e10-a7d3-0c50daabc604,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['Document expansion by query prediction. CoRR, abs']",['1904'],['Rodrigo Nogueira;Wei Yang;Jimmy Lin;Kyunghyun Cho'],single,"['Passage', 'retrieval', 'for', 'open-domain', 'QA', 'For', 'opendomain', 'QA,', 'a', 'passage', 'retriever', 'is', 'an', 'important', 'component', 'to', 'identify', 'relevant', 'passages', 'for', 'answer', 'extraction.', 'Traditional', 'approaches', '<ref type=""single"">(Chen et al., 2017)</ref>', 'implemented', 'term-based', 'passage', 'retrievers', '(e.g.', 'TF-IDF', 'and', 'BM25),', 'which', 'have', 'limited', 'representation', 'capabilities.', 'Recently,', 'researchers', 'have', 'utilized', 'deep', 'learning', 'to', 'improve', 'traditional', 'passage', 'retrievers,', 'including', 'document', 'expansions', '<ref type=""single"">(Nogueira et al., 2019c),</ref>', 'question', 'expansions', '<ref type=""single"">(Mao et al., 2020)</ref>', 'and', 'term', 'weight', 'estimation', '<ref type=""single"">(Dai and Callan, 2019).</ref>']",52,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0]"
57da5cbf-a615-48d5-bc77-6839e555e174,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,['Flickr30k entities: Collecting region-to-phrase correspondences for richer imageto-sentence models'],['2015'],['A Bryan;Liwei Plummer;Chris Wang;Juan Cervantes;Julia Caicedo;Svetlana Hockenmaier;unk Lazebnik'],single,"['Image-Text', 'Retrieval:', 'The', 'image-text', 'retrieval', 'typically', 'includes', 'two', 'sub-tasks:', 'image-retrieval', '(IR)', 'aims', 'to', 'retrieval', 'an', 'image', 'when', 'given', 'a', 'specific', 'caption', 'and', 'text-retrieval', '(TR)', 'is', 'on', 'the', 'contrary.', 'We', 'perform', 'experiments', 'on', 'both', 'Flickr30k', '<ref type=""single"">(Plummer et al., 2015)</ref>', 'and', 'MSCOCO', 'dataset.', 'As', 'in', 'UNITER,', 'we', 'construct', 'a', 'mini-batch', 'for', 'each', 'GPU', 'of', 'a', 'matched', 'image-text', 'pair,', 't-1', 'negative', 'images,', 'and', 't-1', 'negative', 'texts', 'where', 't', 'is', 'set', 'as', '32.', 'Besides,', 'we', 'take', 'a', 'fully-connected', 'network', 'on', 'top', 'of', 'h', 'cls', 'and', 'adopt', 'the', 'binary', 'cross-entropy', 'loss', 'as', 'supervision', 'signal.', 'The', 'finetuning', 'iterations', 'are', 'up', 'to', '10K', 'by', 'following', 'linear', 'decay', 'scheduling', 'with', 'initial', 'lr', '7e-5', 'for', 'Transformer,', '1e-4', 'for', 'CNNs.', 'Top-K', '(R@K,', 'K', '∈', '{1,', '5,', '10})', 'recall', 'is', 'the', 'evaluation', 'metric.']",34,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
58266100-f96b-40a2-83a2-2a39cc9f720a,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Pointer sentinel mixture models'],['2017'],['Stephen Merity;Caiming Xiong;James Bradbury;Richard Socher'],single,"['We', 'further', 'ascertain', 'the', 'findings', 'of', '§4.1', 'via', 'language', 'modeling', 'on', 'WikiText-103', '<ref type=""single"">(Merity et al., 2017)</ref>', 'using', 'a', '6-layer', 'Transformer', 'decoder', 'with', '156M', 'parameters.', 'Using', 'an', 'input', 'length', 'of', '1024,', 'we', 'trained', 'two', 'models', 'with', 'vanilla', 'and', 'top-64', 'attentions', 'at', 'the', 'self-attention', 'layers,', 'obtaining', 'test', 'perplexity', 'scores', 'of', '30.96', 'and', '30.51', 'respectively,', 'slightly', 'better', 'in', 'case', 'of', 'top-64', '(details', 'in', '§A.3).']",12,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5827aba0-9772-4ef9-9f8b-59afbab29782,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['The hidden assumptions behind counterfactual explanations and principal reasons'],['2020'],['Solon Barocas;Andrew Selbst;Manish Raghavan'],single,"['Users.', 'Besides', 'being', 'a', 'mechanism', 'for', 'designers', 'to', 'interpret', 'their', 'methods,', 'an', 'effective', 'operationalization', 'of', 'explainability', 'should', 'also', 'serve', 'as', 'a', 'means', 'for', 'users', 'to', 'receive', 'explanations', 'for', 'the', 'decisions', 'made', 'by', 'a', 'detection', 'method.', '<ref type=""single"">Jurgens et al. (2019)</ref>', 'argue', 'in', 'their', 'work', 'that', 'an', 'online', 'platform', 'can', 'build', 'legitimacy', 'and', 'transparency', 'by', 'offering', 'justifications', 'to', 'users', 'when', 'their', 'comments', 'are', 'deemed', 'abusive', 'by', 'the', 'detection', 'method', 'of', 'the', 'platform,', 'which', 'can', 'in', 'turn', 'lead', 'to', 'increase', 'in', 'compliance', 'with', 'the', 'norms', 'of', 'the', 'platform.', 'That', 'said,', 'unlike', 'in', 'the', 'case', 'of', 'designers', 'of', 'the', 'method,', 'offering', 'feature', 'attribution', 'based', 'explanations', 'that', 'simply', 'highlight', 'parts', 'of', 'a', ""user's"", 'comment', 'may', 'not', 'be', 'effective', 'at', 'making', 'the', 'user', 'agree', 'with', 'the', 'decision', 'of', 'the', 'detection', 'method', '<ref type=""single"">(Carton et al., 2020).</ref>', 'Alternatively,', 'providing', 'a', 'meaningful', 'counterfactual', 'paraphrase', 'that', 'is', 'non-abusive', 'is', 'not', 'only', 'difficult', '<ref type=""single"">(Laugel et al., 2019),</ref>', 'but', 'can', 'also', 'be', 'seen', 'as', 'paternalism', 'on', 'the', 'part', 'of', 'the', 'platform', '<ref type=""single"">(Barocas et al., 2020),</ref>', 'i.e.,', 'that', 'the', 'platform', 'is', 'trying', 'to', 'tell', 'the', 'user', 'what', 'to', 'say', 'or', 'how', 'to', 'present', 'their', 'opinions.', 'On', 'the', 'other', 'hand,', 'principal-reason', 'explanations', '<ref type=""single"">(Barocas et al., 2020),</ref>', 'whereby', 'the', 'detection', 'method', 'selects', 'the', 'reason(s)', 'for', 'its', 'decision', 'from', 'a', 'curated', 'list,', 'can', 'constitute', 'an', 'effective', 'operationalization.', 'Such', 'a', 'list', 'can', 'be', 'prepared', 'for', 'each', 'of', 'the', 'four', 'properties', 'of', 'explainability,', 'e.g.,', 'by', 'selecting', 'the', 'relevant', 'norms', 'from', 'the', 'terms', 'of', 'service', 'of', 'the', 'platform,', 'hence', 'allowing', 'for', 'a', 'principal', 'reason', 'to', 'be', 'offered', 'per', 'property', 'or', 'a', 'combination', 'thereof.', 'When', 'coupled', 'with', 'feature', 'attribution,', 'this', 'approach', 'to', 'operationalization', 'can', 'clearly', 'indicate', 'to', 'the', 'user', 'the', 'norm(s)', 'that', 'their', 'comment', 'violates', 'and,', 'where', 'possible,', 'highlight', 'parts', 'that', 'contribute', 'to', 'the', 'violation(s).', 'For', 'example,', 'given', 'a', 'comment', 'like', '""You', 'f***,', 'why', 'do', 'you', 'have', 'to', 'support', 'that', 'team??"",', 'the', 'detection', 'method', 'can', 'highlight', 'the', 'first', 'part', 'based', 'on', 'feature', 'attribution', 'and', 'select', 'the', 'norm', 'forbidding', 'the', 'use', 'of', 'expletives', 'directed', 'at', 'others.']",150,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
582cfecc-f32b-4a0c-85ff-4d73fe80ae59,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['Trace', 'Embedding:', 'Each', 'trace', 'input', 'item', 't', 'i', 'is', 'projected', 'into', 'ti', '∈', 'R', 'd.', 'We', 'also', 'generate', 'Sinusoidal', 'Positional', 'Embeddings', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'o', 'i', 'to', 'capture', 'the', 'temporal', 'order', 'of', 'the', 'traces.', 'The', 'final', 'trace', 'embedding', 'T', '=', '{t1', ',...,', 'tM', '},', 'where', 'ti', '=', 'ti', '+', 'o', 'i.']",21,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5861fdec-fd65-4b53-8a8d-9a596cf056c3,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Neural domain adaptation for biomedical question answering'],['2017'],['Georg Wiese;Dirk Weissenborn;Mariana Neves'],single,"['The', 'exploitation', 'of', 'pre-trained', 'models', 'followed', 'by', 'task-specific', 'fine-tuning', 'haved', 'pushed', 'the', 'state-ofthe-art', 'forwards,', 'while', 'requiring', 'much', 'less', 'computational', 'and', 'data', 'resources.', 'The', 'idea', 'behind', 'pre-training', 'is', 'to', 'reuse', 'the', 'weights', 'parameters', 'trained', 'on', 'a', 'set', 'of', 'source', 'tasks', 'and', 'continue', 'to', 'fine-tune', 'them', 'on', 'under-resourced', 'target', 'tasks', 'to', 'achieve', 'knowledge', 'transfer.', 'Dai', 'and', '<ref type=""single"">Le (2015)</ref>', 'were', 'the', 'first', 'to', 'propose', 'to', 'pre-train', 'RNNs', 'using', 'auto-encoders', 'and', 'language', 'models', 'as', 'part', 'of', 'their', 'QA', 'encoding', 'layer.', '<ref type=""single"">Min et al. (2017)</ref>', 'and', '<ref type=""single"">Wiese et al. (2017)</ref>', 'pre-trained', 'QA', 'models', 'before', 'applying', 'the', 'fine-tuning', 'process', 'between', 'the', 'source', 'and', 'the', 'target', 'domains.', 'Other', 'efforts', 'focused', 'on', 'pretraining', 'Transformer-based', 'models', 'multilingually', 'such', 'as', 'the', 'multilingual', 'version', 'of', 'BERT', '(called', 'mBERT)', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'or', 'XLM-R', '<ref type=""single"">(Conneau et al., 2020)</ref>', 'to', 'learn', 'cross-lingual', 'representations', 'which', 'are', 'transferable', 'across', 'languages.']",77,"[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
589f51be-7f4d-40e8-b266-cf7369826158,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['Experiments and Prospects of Example-Based Machine Translation'],['1986'],['C Stanfill;D Waltz;E Sumita;H Iida;H Tomabechi;R Wilensky'],single,"['DMSNAP', 'is', 'capable', 'of', 'resolving', 'this', 'lexical', 'ambiguity', 'through', 'use', 'of', 'contextual', 'priming', 'using', 'the', 'contextual', 'marker', '(C-Marker)', '<ref type=""single"">[Tomabechi, 1987]</ref>', 'and', 'the', 'cost-based', 'disambiguation', '<ref type=""single"">[Kitano et al., 1989].</ref>', 'Sentence', 's3', 'contains', 'a', 'word', 'sense', 'ambiguity', 'in', 'the', 'interpretation', 'of', 'the', 'word', ""'paper''"", 'as', 'either', 'a', 'technical', 'document', 'or', 'a', 'sheet', 'of', 'paper.', 'Upon', 'reading', ""'paper',"", 'C-THESIS', 'and', 'C-PAPER', 'are', 'activated.', 'At', 'this', 'time,', 'C-THESIS', 'has', 'a', 'C-MARKER.', 'The', 'C-MARKER', 'comes', 'from', 'activation', 'of', 'C-IJCAI-91', 'and', 'C-CONFERENCE,', 'in', 'previous', 'sentences,', 'which', 'has', 'contextual', 'links', 'connecting', 'concepts', 'relevant', 'to', 'academic', 'conference', 'such', 'as', 'C-THESIS.', 'The', 'meaning', 'hypothesis', 'containing', 'C-THESIS', 'costs', 'less', 'than', 'the', 'one', 'with', 'C-PAPER', 'so', 'that', 'it', 'is', 'selected', 'as', 'the', 'best', 'hypothesis.']",18,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
58ce26ae-4270-4dad-8d7a-55e96e02daeb,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,['ConvAI at SemEval-2019 task 6: Offensive language identification and categorization with perspective and BERT'],['2019'],['John Pavlopoulos;Nithum Thain;Lucas Dixon;Ion Androutsopoulos'],single,"['Offensive', 'language', 'can', 'include', 'various', 'categories', 'such', 'as', 'threats,', 'vilification,', 'insults,', 'calumniation,', 'discrimination', 'and', 'swearing', '<ref type=""single"">(Pavlopoulos et al., 2019).</ref>', 'Detection', 'of', 'such', 'language', 'is', 'necessary', 'for', 'ease', 'of', 'moderation', 'of', 'content', 'on', 'social', 'media.', 'Despite', 'their', 'popularity,', 'toxicity', 'detection', 'tasks', 'have', 'focused', 'majorly', 'on', 'sequence', 'classification,', 'rather', 'than', 'sequence', 'tagging.', 'Finding', 'which', 'spans', 'make', 'a', 'comment', 'or', 'document', 'toxic', 'in', 'nature', 'is', 'crucial', 'in', 'explaining', 'the', 'reasons', 'behind', 'their', 'toxicity.', 'Additionally,', 'such', 'attributions', 'would', 'allow', 'for', 'more', 'efficient', 'semi-automated', 'quality-based', 'moderation', 'of', 'content,', 'especially', 'for', 'verbose', 'documents,', 'in', 'comparison', 'to', 'quantitative', 'toxicity', 'scores.']",15,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
59071786-a536-4f1d-9a18-505c0389ca20,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['unknown'],['unknown'],['unknown'],single,"['Pairwise', 'diversity', '(⇓).', 'Referred', 'as', '""self-""', '(e.g.,', 'self-BLEU)', '<ref type=""single"">(Zhu et al., 2018),</ref>', 'it', 'measures', 'the', 'within-distribution', 'similarity.', 'This', 'metric', 'computes', 'the', 'average', 'of', 'sentence-level', 'metrics', 'between', 'all', 'pairwise', 'combinations', 'of', 'hypotheses', '{Y', '(1),', '•,', 'Y', '(K)}', 'generated', 'from', 'each', 'source', 'sequence', 'X.', 'Lower', 'pairwise', 'metric', 'indicates', 'high', 'diversity', 'between', 'generated', 'hypotheses.']",8,"[3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
592d349b-96c1-4453-b563-d86e3284b01e,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['Developing a measure of sociocultural competence: The case of apology'],['1981'],['A Cohen;E Olshtain'],single,"['After', 'the', 'selection', 'of', 'documents', 'for', 'analysis,', 'a', 'list', 'of', 'keywords', 'was', 'prepared', 'independently', 'by', 'the', 'authors', 'and', 'then', 'compiled.', 'As', 'traditionally', 'held,', 'an', 'apology', 'consists', 'of', 'five', 'major', 'parts', '<ref type=""single"">(Cohen et al, 1981).</ref>', 'These', 'are', 'the', 'following:']",30,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3]"
597e6134-ad19-48d2-9d76-46626ca4ec89,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['More', 'recently,', 'neural', 'networks-based', 'strategies', 'and', 'transformer-based', 'architectures', 'has', 'been', 'applied', 'to', 'hate', 'speech', 'detection', 'due', 'to', 'the', 'good', 'results', 'achieved', 'in', 'various', 'tasks.', '<ref type=""single"">Banerjee et al. (2020)</ref>', '2021)', 'compared', 'two', 'pre-trained', 'language', 'models,', 'such', 'as', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'and', 'XLM', '(CONNEAU', 'and', 'Lample,', '2019)', 'trained', 'to', 'detect', 'hate', 'speech', 'in', 'the', 'Spanish', 'language.']",34,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5980b50b-078f-4b7c-bd79-3c6e38536579,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Individual comparisons by ranking methods'],['1945'],['F Wilcoxon'],single,"['The', 'mean', 'adequacy', 'score', 'when', 'bilingual', 'participants', 'were', 'presented', 'with', 'alignments', 'was', '8.35.', 'When', 'alignments', 'were', 'omitted', 'from', 'the', 'post-editing', 'tool,', 'the', 'mean', 'adequacy', 'score', 'was', '7.85.', 'A', 'Wilcoxon', 'signed-rank', 'test', '<ref type=""single"">(Wilcoxon, 1945)</ref>', 'showed', 'that', 'when', 'participants', 'were', 'presented', 'with', 'alignments', 'the', 'ratings', 'of', 'their', 'translations', 'were', 'significantly', 'higher', 'than', 'when', 'participants', 'post-edited', 'without', 'access', 'to', 'alignments', '(N', '=', '6,', 'Z', '=', '-2.207,', 'p', '=', '0.027).']",31,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
59cf3d45-bcf2-4326-bd64-878e68f7e380,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,"['Bridging resolution: Task definition, corpus resources and rule-based experiments']",['2018'],['Ina Roesiger;Arndt Riester;Jonas Kuhn'],single,"['First,', 'there', 'is', 'no', 'agreed-upon', 'definition', 'of', 'bridging', '<ref type=""single"">(Roesiger et al., 2018b).</ref>', 'Consequently,', 'manual', 'annotation', 'of', 'bridging', 'relations,', 'and', 'the', 'use', 'of', 'these', 'annotations,', 'requires', 'substantial', 'expertise', 'and', 'effort.', 'In', 'contrast,', 'NP', 'Enrichment', 'is', 'compactly', 'defined,', 'and', 'is', 'amenable', 'to', 'large-scale', 'annotation', 'after', 'only', 'a', 'brief', 'annotator', 'training.']",8,"[3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
59f0a195-d9a8-435e-8097-5b2362c76c0e,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Combining textual entailment and argumentation theory for supporting online debates interactions'],['2012'],['Elena Cabrio;Serena Villata'],single,"['The', 'aforementioned', 'correlations,', 'however,', 'are', 'byproducts', 'rather', 'than', 'core', 'mechanisms', 'of', 'argumentative', 'relations.', 'In', 'order', 'to', 'decide', 'whether', 'a', 'statement', 'supports', 'or', 'attacks', 'another,', 'we', 'cannot', 'ignore', 'the', 'logical', 'relation', 'between', 'them.', 'Textual', 'entailment', 'was', 'found', 'to', 'inform', 'argumentative', 'relations', '<ref type=""single"">(Choi and Lee, 2018)</ref>', 'and', 'used', 'to', 'detect', 'arguments', '<ref type=""single"">(Cabrio and Villata, 2012).</ref>', 'Similarly,', 'there', 'is', 'evidence', 'that', 'the', 'opinions', 'of', 'two', 'statements', 'toward', 'the', 'same', 'concept', 'constitute', 'their', 'argumentative', 'relations', '<ref type=""group"">(Gemechu and Reed, 2019, Kobbe et al., 2020).</ref>', 'Causality', 'between', 'events', 'also', 'received', 'attention,', 'and', 'causality', 'graph', 'construction', 'was', 'proposed', 'for', 'argument', 'analysis', '<ref type=""single"">(Al-Khatib et al., 2020).</ref>', 'Additionally,', 'in', 'argumentation', 'theory,', ""Walton's"", 'argumentation', 'schemes', '<ref type=""single"">(Walton et al., 2008)</ref>', 'specify', 'common', 'reasoning', 'patterns', 'people', 'use', 'to', 'form', 'an', 'argument.', 'This', 'motivates', 'our', 'work', 'to', 'investigate', 'logical', 'mechanisms', 'in', 'four', 'categories:', 'factual', 'consistency,', 'sentiment', 'coherence,', 'causal', 'relation,', 'and', 'normative', 'relation.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5a083832-f59f-4c4d-92a3-f79db6e5cbc7,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Can punctuation help parsing'],['1994'],['B Jones'],single,"['The', 'approach', 'to', 'text', 'grammar', 'taken', 'here', 'is', 'in', 'many', 'ways', 'similar', 'to', 'that', 'of', '<ref type=""single"">Jones (1994).</ref>', 'However,', 'he', 'opts', 'to', 'treat', 'punctuation', 'marks', 'as', 'clitics', 'on', 'words', 'which', 'introduce', 'additional', 'featural', 'information', 'into', 'standard', 'syntactic', 'rules.', 'Thus,', 'his', 'grammar', 'is', 'thoroughly', 'integrated', 'and', 'it', 'would', 'be', 'harder', 'to', 'extract', 'an', 'independent', 'text', 'grammar', 'or', 'build', 'a', 'modular', 'semantics.', 'The', 'coverage', 'of', 'the', 'integrated', 'version', 'of', 'the', 'text', 'grammar', 'is', 'described', 'in', 'more', 'detail', 'in', '<ref type=""single"">Briscoe &amp, Carroll ( 1994).</ref>', '<ref type=""group"">(Elworthy, 1993 (Elworthy, , 1994) )</ref>', 'trained', 'on', 'text', 'tagged', 'with', 'a', 'slightly', 'modified', 'version', 'of', 'CLAWS-II', 'labels', '<ref type=""single"">(Garside et al. , 1987).</ref>', '<ref type=""single"">Carroll (1994)</ref>', 'that', 'in', 'practice', 'NL', 'grammars', 'do', 'not', 'evince', 'worst-case', 'parsing', 'complexity.']",15,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5a737225-0c0b-44ba-b36a-d35ab91a1cd8,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['A2C', 'Training.', 'Each', 'parallel', 'A2C', 'agent', 'samples', 'from', 'the', 'the', 'current', 'pool', 'of', 'available', 'questsi.e.', 'the', 'curriculum-for', 'a', 'fixed', 'number', 'of', 'steps', 'k', 'before', 'switching', 'to', 'the', 'quest', 'pool', 'corresponding', 'to', 'the', 'next', 'higher', 'level', 'difficulty', 'curriculum.', 'The', 'initial', 'pool', 'of', 'quests', 'is', 'the', 'training', 'set', 'of', 'LIGHT-Quests', 'as', 'seen', 'in', '<ref type=""single"">Ammanabrolu et al. (2021)</ref>', 'and', 'all', 'pools', 'after', 'that', 'correspond', 'to', 'decreasing', 'values', 'of', 'n', 'used', 'when', 'generating', 'the', 'curriculums', '(as', 'seen', 'in', 'Figure', '6).']",51,"[3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
5aa08b2f-9742-44f6-a66b-3e6b52e03626,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Learning text representation using recurrent convolutional neural network with highway layers'],['2016'],['Y Wen;unk Luo;unk Wang'],single,"['We', 'then', 'use', 'the', 'highway', 'network', '<ref type=""single"">(Srivastava et al., 2015)</ref>', 'on', 'the', 'combined', 'hidden', 'state', 'vector', 'h.', 'This', 'network', 'adaptively', '""carries""', 'some', 'dimensions', 'of', 'h', 'to', 'the', 'output', 'for', 'predicting', 'the', 'correct', 'label', 'sequence.', 'Therefore,', 'the', 'hidden', 'states', 'undergo', 'the', 'following', 'transformation', '<ref type=""single"">(Wen et al., 2016)</ref>', ':h', 'i', '=', 'ρ(h', 'i)', 'g(W', 'H', 'hi', '+b', 'H', ')+(1−ρ(h))', 'hi', '(9)The', 'function', 'ρ(h', 'w)', '=', 'σ(W', 'ρ', 'h', 'i', '+', 'b', 'ρ', '),', 'which', 'is', 'a', 'simple', 'activation', 'function.', 'g', 'is', 'any', 'non-linear', 'function,', 'such', 'as', 'sigmoid', 'or', 'hyperbolic', 'tangent.', 'Following', 'the', 'highway', ""network's"", 'output,', 'we', 'pass', 'the', 'hidden', 'embeddings', 'to', 'a', 'dropout', 'layer,', 'which', 'effectively', 'reduces', 'the', 'number', 'of', 'hidden', 'units', 'by', 'a', 'fraction', 'd,', 'so', 'h', 'drop', '∈', 'R', 'k/d×l,', 'and', 'a', 'linear', 'layer,', 'which', 'maps', 'the', 'h', 'drop', 'to', 'a', 'smaller', 'embedding', 'space.', 'We', 'label', 'this', 'space', 'h', '∈', 'R', 'k/d×f', '(f', 'being', 'the', 'dimensions', 'of', 'the', 'feature', 'space)', 'for', 'brevity.']",39,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5abf367a-a41a-4fbd-a432-78ec74fbed1a,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['A Framework of a Mechanical Trans lation between Japanese and English by Analogy Principle'],['1968'],"['C Moldovan ; Lin;D Moldovan;"" Snap: Simulator Results ; Moldovan;D Lee;W Lin;C Nagao;M Pollard;C Sag;I Quillian;M Riesbeck;C Martin;C Riesbeck;C Schank;R Sato;S Nagao;M unk']",single,"['Memory-based', 'MT', 'is', 'an', 'idea', 'of', 'viewing', 'MT', 'as', 'a', 'memory', 'activity.', 'For', 'example,', 'parsing', 'is', 'considered', 'as', 'a', 'memory-search', 'process', 'which', 'identifies', 'similar', 'cases', 'in', 'the', 'past', 'from', 'the', 'memory,', 'and', 'to', 'provide', 'interpretation', 'based', 'on', 'the', 'identified', 'case.', 'It', 'can', 'be', 'considered', 'as', 'an', 'application', 'of', 'Memory-Based', 'Reasoning', '(MBR)', '<ref type=""single"">[Stanfill and Waltz, 1986]</ref>', 'and', 'Case-Based', 'Reasoning', '(CBR)', '<ref type=""single"">[Riesbeck and Schank, 1989]</ref>', 'to', 'NLP.', 'This', 'view,', 'however,', 'counters', 'to', 'traditional', 'idea', 'to', 'view', 'NLP', 'as', 'an', 'extensive', 'rule', 'application', 'process', 'to', 'build', 'up', 'meaning', 'representation.', 'Some', 'models', 'has', 'been', 'proposed', 'in', 'this', 'direction,', 'such', 'as', 'Direct', 'Memory', 'Access', 'Parsing', '(DMAP)', '<ref type=""single"">[Riesbeck and Martin, 1985]</ref>', 'and', 'ΦDMDIALOG', '<ref type=""single"">[Kitano, 1990a].</ref>', 'Independently,', 'the', 'idea', 'of', 'using', 'examples', 'for', 'translation', 'has', 'been', 'proposed', 'by', '<ref type=""single"">[Nagao, 1984],</ref>', 'and', 'some', 'experimental', 'results', 'has', 'been', 'reported', 'recently', '<ref type=""group"">[Sato and Nagao, 1990] [Sumita and Iida, 1991]</ref>', 'and', '<ref type=""single"">[Furuse et al., 1990].</ref>', 'Recently,', 'such', 'an', 'approach', 'is', 'gaining', 'increasing', 'attention', 'due', 'to', 'the', 'problems', 'in', 'the', 'traditional', 'machine', 'translation', 'approach:']",56,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5ad3a996-b937-4fc3-822f-ecfedb29b0c5,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['A simple and effective model for answering multi-span questions'],['2020'],['Elad Segal;Avia Efrat;Mor Shoham;Amir Globerson;Jonathan Berant'],single,"['Joint:', 'we', 'concatenate', 'the', 'training', 'examples', 'from', 'Quoref', 'and', 'CoNLL-to-QA', 'converted', '11', 'The', 'only', 'difference', 'of', 'TASE', 'in', 'our', 'experiments', 'and', 'the', 'reported', 'results', 'in', '<ref type=""single"">Segal et al. (2020)</ref>', 'is', 'the', 'number', 'of', 'training', 'epochs.', 'For', 'a', 'fair', 'comparison,', 'we', 'train', 'all', 'models', 'for', 'the', 'same', 'number', 'of', 'iterations.']",25,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5ae1ad2e-846b-46bc-b3c8-922d349d96a6,drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM,2022,Dylan Phelps,['BERTRAM: Improved word embeddings have big impact on contextualized model performance'],['2020'],['Timo Schick;Hinrich Schütze'],single,"['To', 'achieve', 'this', 'goal,', 'we', 'investigate', 'whether', 'due', 'to', 'the', 'similarity', 'between', 'idioms', 'and', 'rare-words', 'Schick', 'and', ""Schütze's"", 'BERT', 'for', 'Attentive', 'Mimicking', '<ref type=""single"">(Schick and Schütze, 2020)</ref>', '(BERTRAM)', 'model,', 'which', 'was', 'designed', 'for', 'use', 'with', 'rare-words,', 'can', 'be', 'used', 'to', 'explicitly', 'learn', 'high-quality', 'embeddings', 'for', 'idiomatic', 'expressions.', 'We', 'also', 'investigate', 'how', 'many', 'examples', 'of', 'each', 'idiom', 'are', 'required', 'to', 'create', 'embeddings', 'that', 'perform', 'well', 'on', 'the', 'task,', 'as', 'well', 'as', 'how', 'the', 'quality', 'of', 'contexts', 'fed', 'to', 'the', 'BERTRAM', 'model', 'effects', 'the', 'representations', 'and', 'performance', 'on', 'the', 'task.']",22,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5b03fcd7-8228-400f-b973-14450efc9a70,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Overview of the iwslt 2011 evaluation campaign'],['2011'],['M Federico;L Bentivogli;M Paul;S Stueker'],single,"['In', 'this', 'paper', 'we', 'describe', 'the', 'machine', 'translation', 'systems', 'built', 'for', 'our', 'participation', 'in', 'IWSLT', '2011', 'evaluation', 'campaign', '<ref type=""single"">[1]</ref>', 'for', 'the', 'Arabic-English', '(Ar-En)', 'and', 'Chinese-English', '(Zh-En)', 'MT', 'track', 'translation', 'tasks.', 'We', 'use', 'different', 'SMT', 'models,', 'ranging', 'from', 'standard', 'phrase-based', 'SMT', 'models', '<ref type=""single"">[2]</ref>', 'to', 'CCG-augmented', 'hierarchical', 'phrasebased', 'models', '<ref type=""single"">[3]</ref>', 'to', 'translate', 'the', 'test', 'data', 'provided.', 'The', 'open-domain', 'nature', 'of', 'the', 'data', 'and', 'the', 'restricted', 'size', 'of', 'the', 'in-domain', 'training', 'corpora', 'necessitated', 'the', 'use', 'of', 'domain', 'adaptation', 'techniques', 'to', 'improve', 'translation', 'quality.']",18,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5b051aca-8dab-4531-91ca-a714c82fe22c,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['SUMBT: Slot-utterance matching for universal and scalable belief tracking'],['2019'],['Hwaran Lee;Jinsik Lee;Tae-Yoon Kim'],single,"['Before', 'presenting', 'the', 'proposed', 'action', 'learning', 'approach,', 'we', 'first', 'briefly', 'introduce', 'dialogue', 'state', 'tracking', 'tasks.', 'For', 'dialogues{(c', 't,', 'x', 't', ')|1', '≤', 't', '≤', 'n', 'd', '},', 'let', '{b', 't', '|1', '≤', 't', '≤', 'n', 'd', '}be', 'the', 'dialogue', 'state', 'for', 'each', 'turn,', 'where', 'b', 't', '∈', '{0,', '1}', 'N', 'b', 'and', 'N', 'b', 'is', 'the', 'number', 'of', 'all', 'slot-value', 'pairs.', 'Dialogue', 'state', 'tracking', 'is', 'usually', 'formulated', 'as', 'a', 'multilabel', 'learning', 'problem', 'where', 'the', 'state', 'at', 'turn', 't', 'predicted', 'by', 'modeling', 'the', 'conditional', 'distribution', 'p(bt', '|c', 't)', '=', 'p(b', 't', '|u', 't,', 'x', 't−1,', 'b', 't−1', '),', 'where', 'b', 't−1', 'is', 'the', 'dialogue', 'state', 'in', 'the', 'previous', 'turn.', 'To', 'model', 'this', 'conditional', 'distribution,', 'a', 'state', 'tracking', 'model', 'p', 'B', '(u', 't,', 'x', 't−1,', 'b', 't−1)', 'mainly', 'employs', 'an', 'utterance', 'en-coder,', 'a', 'context', 'encoder', 'to', 'work', 'with', 'a', 'slot-value', 'predictor', 'that', 'estimates', 'whether', 'a', 'slot-value', 'pair', 'should', 'be', 'included', 'in', 'the', 'dialogue', 'states', '<ref type=""single"">(Lee et al., 2019).</ref>', 'Specifically,', 'the', 'predictor', 'takes', 'as', 'input', 'a', 'slot-value', 'pair', '(s', 'i,', 'e', 'i', '),', 'and', 'the', 'encoded', 'utterances', 'h', 'utt', '∈', 'R', 'D', 'and', 'context', 'h', 'ctx', '∈', 'R', 'D', 'from', 'the', 'utterance', 'encoder', 'f', 'utt', '(u', 't,', 'x', 't−1)', 'and', 'context', 'encoder', 'f', 'ctx', '(b', 't−1)', 'respectively,', 'and', 'D', 'is', 'the', 'hidden', 'dimension.', 'The', 'prediction', 'is', 'then', 'performed', 'by', 'aggregating', 'the', 'results', 'of', 'slot-value', 'predictor', 'f', 'val', '(h', 'utt,', 'h', 'ctx,', '(s', 'i,', 'e', 'i', '))', 'for', 'the', 'complete', 'N', 'b', 'slotvalue', 'pairs.', 'We', 'optimize', 'the', 'state', 'tracking', 'model', 'using', 'the', 'cross-entropy', 'loss:L', '=', 'd', 'i', 't=1:n', 'd', '−', 'log(b', 't', '•p', 'B', '(u', 't,', 'x', 't−1,', 'c', 't−1', '))', '(4)where', 'the', 'parameters', 'of', 'p', 'B,', 'which', 'include', 'f', 'utt,', 'f', 'ctx,', 'and', 'f', 'val,', 'are', 'jointly', 'trained.']",152,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5b956b77-7cd7-4fdd-8e2d-fc6810a27231,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Comprehensive supersense disambiguation of English prepositions and possessives'],['2018'],['Nathan Schneider;Jena Hwang;Vivek Srikumar;Jakob Prange;Austin Blodgett;Sarah Moeller;Aviram Stern;Adi Shalev;Omri Abend'],single,"['To', 'conclude,', 'we', 'argue', 'that', 'despite', 'the', 'ambiguities', 'of', 'prepositions,', 'they', 'allow', 'us', 'to', 'obtain', 'a', 'meaningful', 'set', 'of', 'typed', 'semantic', 'links', 'between', 'NPs,', 'which', 'are', 'well', 'understood', 'by', 'people', 'and', 'can', 'be', 'effectively', 'processed', 'by', 'NLP', 'models.', 'While', 'the', 'annotation', 'can', 'be', 'refined', 'to', 'include', 'a', 'fine-grained', 'sense', 'annotation', 'for', 'each', 'link,', 'for', 'example,', 'via', 'a', 'scheme', 'as', 'that', 'of', '<ref type=""single"">Schneider et al. (2018),</ref>', 'we', 'leave', 'such', 'an', 'extension', 'to', 'future', 'work.']",61,"[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]"
5bba977e-de97-4bec-946d-013bd4883f02,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['Eda: Easy data augmentation techniques for boosting performance on text classification tasks'],['2019'],['Jason Wei;Kai Zou'],single,"['Data', 'augmentation', 'Data', 'augmentation', 'is', 'the', 'technique', 'used', 'to', 'increase', 'the', 'amount', 'of', 'data', 'by', 'adding', 'slightly', 'modified', 'copies', 'of', 'already', 'existing', 'data', 'or', 'newly', 'created', 'synthetic', 'data', 'from', 'existing', 'data.', 'It', 'acts', 'as', 'a', 'regularizer', 'and', 'helps', 'reduce', 'overfitting', 'when', 'training', 'a', 'machine', 'learning', 'model.', 'In', 'this', 'paper,', 'data', 'augmentation', 'consists', 'of', 'two', 'parts.', 'We', 'first', 'add', 'the', 'dataset', 'released', 'by', 'CWI', '2018', 'into', 'the', 'training', 'set.', 'Besides,', 'for', 'subtask', '2,', 'since', 'its', 'training', 'dataset', 'is', 'small', 'which', 'only', 'contains', 'one', 'thousand', 'samples,', 'we', 'add', 'the', 'dataset', 'of', 'subtask', '1', 'to', 'train', 'the', 'model', 'for', 'subtask', '2.', 'Then,', 'for', 'a', 'given', 'sentence', 'in', 'the', 'training', 'set,', 'we', 'perform', 'the', 'operations', 'containing', 'synonym', 'replacement,', 'random', 'insertion,', 'random', 'swap,', 'and', 'random', 'deletion', 'introduced', 'by', '<ref type=""single"">Wei and Zou (2019).</ref>']",123,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
5be90da0-c7e0-4e70-a30d-58b3f31ed065,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Teaching natural language processing through big data text summarization with problem-based learning'],['2020'],['Liuqing Li;Jack Geissinger;William Ingram;Edward Fox'],single,"['Generative', 'language', 'models', 'are', 'getting', 'bigger:', 'from', ""ELMo's"", 'release', 'in', '2018', 'with', '94M', 'parameters', '<ref type=""single"">(Joshi et al., 2018)</ref>', 'to', 'Megatron-Turing', 'NLG', 'in', '2022', 'with', '530Bn', '<ref type=""single"">(Smith et al., 2022),</ref>', 'there', 'has', 'been', 'approximately', 'a', 'tenfold', 'annual', 'increase', 'in', 'parameters.', 'The', 'growing', 'capabilities', 'of', 'these', 'models', 'have', 'supported', 'their', 'adoption', 'in', 'many', 'downstream', 'tasks,', 'from', 'text', 'summarisation', '<ref type=""single"">(Li et al., 2020)</ref>', 'and', 'weather', 'reporting', '<ref type=""single"">(Gatt and Krahmer, 2018)</ref>', 'to', 'writing', 'code', '<ref type=""single"">(Chen et al., 2021).</ref>', 'However,', 'there', 'are', 'various', 'associated', 'risks,', 'such', 'as', 'privacy', 'erosion,', 'copyright', 'infringement,', 'environmental', 'harms', 'and', 'negative', 'stereotyping', 'of', 'social', 'groups', '<ref type=""group"">(Margoni, 2019, Feyisetan et al., 2020, Bender et al., 2021, Bommasani et al., 2021, Weidinger et al., 2021).</ref>', 'We', 'focus', 'on', 'the', 'latter', 'of', 'these', 'risks,', 'specifically', 'the', 'problem', 'of', 'gender', 'bias', 'with', 'respect', 'to', 'occupation.', '*', 'Equal', 'contribution.']",50,"[3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5bf82317-b6ac-44db-b2c7-883ba93b90ec,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Realistic evaluation principles for cross-document coreference resolution'],['2021'],['Arie Cattan;Alon Eirew;Gabriel Stanovsky;Mandar Joshi;Ido Dagan'],single,"['Coreference', 'We', 'follow', '<ref type=""single"">Cattan et al. (2021)</ref>', 'and', 'evaluate', 'the', 'coreference', 'agreement', 'scores', 'after', 'filtering', 'singleton', 'clusters.', 'We', 'report', 'the', 'standard', 'CoNLL-2012', 'score', '<ref type=""single"">(Pradhan et al., 2012)</ref>', 'that', 'combines', 'three', 'coreference', 'metric', 'scores.', 'The', 'in-domain', 'test', 'score', '13', 'is', '82.1,', 'while', 'in', 'the', 'OOD', 'the', 'score', 'is', '77.1.', 'For', 'comparison', 'with', 'the', 'most', 'dominant', 'coreference', 'dataset,', 'OntoNotes', '<ref type=""single"">(Weischedel et al., 2013),</ref>', 'which', 'only', 'reported', 'the', 'MUC', 'agreement', 'score', '<ref type=""single"">(Grishman and Sundheim, 1996),</ref>', 'we', 'also', 'measure', 'the', 'MUC', 'score', 'on', 'our', 'dataset.', 'The', 'MUC', 'score', 'on', 'our', 'dataset', 'is', '83.6,', 'compared', 'to', '78.4-89.4', 'in', 'OntoNotes,', 'depending', 'on', 'the', 'domain', '<ref type=""single"">(Pradhan et al., 2012).</ref>', 'It', 'is', 'worth', 'noting', 'that', 'on', 'the', 'Newswire', 'domain', 'of', 'Onto-Notes', '<ref type=""single"">(Weischedel et al., 2013)</ref>', '(the', 'domain', 'that', 'is', 'most', 'similar', 'to', 'ours)', 'the', 'score', 'is', '80.9,', 'which', 'indicates', 'a', 'high', 'quality', 'of', 'annotation', 'in', 'our', 'corpus.', 'We', 'expect', 'the', 'quality', 'of', 'our', 'final', 'coreference', 'data', 'to', 'be', 'even', 'higher', 'due', 'to', 'the', 'consolidation', 'step', 'that', 'was', 'done', 'by', 'an', 'expert', 'on', 'the', 'test', 'set', 'and', 'OOD', 'splits.']",3,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5c7cba84-7b32-4776-b1dc-093c51d4275f,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,"['ApplicaAI at SemEval-2020 task 11: On RoBERTa-CRF, span CLS and whether self-training helps them', 'Portuguese named entity recognition using BERT-CRF. CoRR, abs']","['2020', '1909']","['Dawid Jurkiewicz;Łukasz Borchmann;Izabela Kosmala;Filip Graliński', 'Fábio Souza;Rodrigo Nogueira;Roberto De;Alencar Lotufo']",group,"['A', 'recently', 'popular', 'approach', 'in', 'Named-Entity', 'Recognition', 'tasks', 'has', 'been', 'to', 'use', 'Conditional', 'Random', 'Fields', '(CRF)', 'with', 'BERT-based', 'models.', 'Inspired', 'by', 'the', 'CRF-based', 'approaches', '<ref type=""group"">(Souza et al., 2019, Jurkiewicz et al., 2020),</ref>', 'we', 'use', 'BERT-based', 'models', 'with', 'a', 'single', 'BiLSTM', 'layer', 'and', 'a', 'CRF', 'layer.', 'During', 'training,', 'the', 'CRF', 'loss', 'is', 'used', 'and', 'during', 'prediction,', 'Viterbi', 'Decoding', 'is', 'performed.', 'Though', 'CRF', 'is', 'generally', 'used', 'for', 'word-level', 'classification,', 'we', 'do', 'not', 'mask', 'inner', 'and', 'end', 'tokens', 'for', 'a', 'word', 'as', 'it', 'degrades', 'dev', 'set', 'performance', 'for', 'our', 'systems.', 'Hence,', 'all', 'the', 'tokens', 'of', 'a', 'word', 'are', 'considered', 'for', 'classification.']",24,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5c96703e-96bd-434e-b7d6-b73130464d24,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,"['Inducing multilingual text analysis tools via robust projection across aligned corpora', 'Multilingual projection for parsing truly low-resource languages', 'Yara parser: A fast and accurate dependency parser', 'unknown']","['2001', '2016', '2015', 'unknown']","['David Yarowsky;Grace Ngai;Richard Wicentowski', 'Željko Agić;Anders Johannsen;Barbara Plank;Natalie Héctor Martínez Alonso;Anders Schluter;unk Søgaard', 'Mohammad Sadegh Rasooli;Joel Tetreault', 'unknown']",group,"['Research', 'shows', 'that', 'affect', 'categories', 'are', 'quite', 'universal', '<ref type=""group"">(Cowen et al., 2019, Scherer and Wallbott, 1994).</ref>', 'Therefore,', 'theoretically', 'they', 'should', 'also', 'to', 'a', 'large', 'degree', 'retain', 'emotion', 'categories', 'when', 'translated.', 'Annotation', 'projection', 'has', 'been', 'shown', 'to', 'offer', 'reliable', 'results', 'in', 'different', 'NLP', 'and', 'NLU', 'tasks', '<ref type=""group"">(Kajava et al., 2020, Yarowsky et al., 2001, Agić et al., 2016, Rasooli and Tetreault, 2015).</ref>', 'Projection', 'is', 'sometimes', 'the', 'only', 'feasible', 'way', 'to', 'produce', 'resources', 'for', 'under-resourced', 'languages.', 'By', 'taking', 'datasets', 'created', 'for', 'high-resource', 'languages', 'and', 'projecting', 'these', 'results', 'on', 'the', 'corresponding', 'items', 'in', 'the', 'underresourced', 'language', 'using', 'parallel', 'corpora,', 'we', 'can', 'create', 'datasets', 'in', 'as', 'many', 'languages', 'as', 'exist', 'in', 'the', 'parallel', 'corpus.', 'A', 'parallel', 'corpus', 'for', 'multiple', 'languages', 'enables', 'the', 'simultaneous', 'creation', 'of', 'resources', 'for', 'multiple', 'languages', 'at', 'a', 'low', 'cost.']",38,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5d07bd0a-8cec-418b-aa1a-bdb87eabd542,Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets,2021,George-Andrei Dima;Dumitru-Clementin Cercel;Mihai Dascalu,['Logistic regression in rare events data'],['2001'],['Gary King;Langche Zeng'],single,"['Class', 'Weights:', 'The', 'class', 'unbalance', 'problem', 'from', 'subtask', '1a', 'is', 'addressed', 'using', 'the', 'weighted', 'version', 'of', 'the', 'cross-entropy', 'loss.', 'The', 'weights', 'of', 'the', 'two', 'classes', 'were', 'computed', 'using', 'the', 'balanced', 'heuristic', '<ref type=""single"">(King and Zeng, 2001)</ref>', 'from', 'the', 'scikitlearn', 'library', '<ref type=""single"">(Pedregosa et al., 2011).</ref>']",31,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3]"
5d2e1885-fe31-4447-ba81-4146feddcd7a,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['Capturing motion verb generalizations with synchronous tags'],['1996'],['Martha Palmer;Joseph Rosenzweig'],single,"['With', 'the', 'recent', 'lexico-structural', 'approach', 'to', 'transfer', 'lexicons,', '<ref type=""group"">[10, 11, 1],</ref>', 'these', 'approaches', 'are', 'no', 'longer', 'as', 'distinct', 'as', 'traditionally', 'viewed,', 'and', 'are', 'not', 'necessarily', 'antithetical,', 'in', 'that', 'they', 'are', 'both', 'concerned', 'with', 'cross-linguistic', 'semantic', 'components.', 'The', 'lexico-structural', 'approach', 'gains', 'efficiency', 'by', 'recognizing', 'that', 'structural', 'correspondences', 'hold', 'for', 'entire', 'classes', 'of', 'lexical', 'items.', 'For', 'example,', 'a', 'classic', 'problem', 'is', 'the', 'translation', 'of', 'motion', 'verbs', 'from', 'English', 'to', 'French.', 'In', 'English', 'the', 'manner', 'of', 'motion', 'can', 'be', 'incorporated', 'into', 'the', 'matrix', 'verb,', 'with', 'the', 'direction', 'of', 'the', 'motion', 'being', 'adjoined', 'on', 'by', 'a', 'prepositional', 'phrase,', 'as', 'in', 'John', 'swam', 'across', 'the', 'lake.', 'In', 'many', 'cases,', 'this', 'is', 'not', 'allowed', 'in', 'French,', 'where', 'the', 'direction', 'becomes', 'incorporated', 'into', 'the', 'matrix', 'verb,', 'and', 'the', 'manner', 'is', 'adjoined', 'on', 'as', 'an', 'adverbial', 'or', 'a', 'prepositional', 'phrase,', 'as', 'in', 'Jean', 'a', 'traversé', 'le', 'lac', 'à', 'la', 'nage,', '(Jean', 'crosses', 'the', 'lake', 'by', 'swimming).', 'This', 'type', 'of', 'structural', 'correspondence', 'has', 'been', 'typically', 'handled', 'best', 'by', 'interlingua', 'approaches,', 'since', 'traditional', 'transfer', 'approaches', 'required', 'that', 'every', 'possible', 'combination', 'of', 'manner', 'of', 'motion', 'verb', 'and', 'path', 'prepositional', 'phrase', 'be', 'listed', 'explicitly,', 'and', 'paired', 'with', 'its', 'target', 'language', 'equivalent.', 'The', 'lexico-structural', 'approach', 'allows', 'the', 'entire', 'class', 'of', 'English', 'manner', 'of', 'motion', 'verbs', 'that', 'have', 'adjoined', 'path', 'prepositional', 'phrases,', 'to', 'be', 'associated', 'in', 'a', 'single', 'transfer', 'lexicon', 'entry', 'with', 'the', 'class', 'of', 'French', 'directed', 'motion', 'verbs', 'with', 'adjoined', 'manners', 'of', 'motion.', 'This', 'is', 'effected', 'by', 'treating', 'manner', 'of', 'motion,', 'path', 'and', 'directed', 'motion', 'as', 'cross-linguistic', 'semantic', 'features', 'that', 'occur', 'in', 'both', 'languages,', 'and', 'serve', 'to', 'anchor', 'the', 'correspondences', '<ref type=""single"">[11].</ref>', 'These', 'are', 'the', 'same', 'basic', 'components', 'that', 'Jackendoff', 'ascribes', 'to', 'change-of-location', 'verbs', 'in', 'his', 'Lexical', 'Conceptual', 'Structures', '(LCS),', 'GO,', 'PATH', 'and', 'MANNER,', '<ref type=""single"">[5].</ref>', 'A', 'similar', 'interlingua', 'treatment,', 'also', 'based', 'on', 'LCS,', 'would', 'decompose', 'the', 'English', 'phrase', 'swim', 'across', 'the', 'lake', 'into', 'the', 'same', 'three', 'separate', 'components', 'which', 'would', 'constitute', 'the', 'predicates', 'of', 'the', 'predicate-argument', 'structure.', 'This', 'predicate', 'argument', 'structure,', 'the', 'LCS,', 'then', 'also', 'serves', 'as', 'the', 'representation', 'for', 'the', 'French', 'translation', '<ref type=""single"">[2].</ref>']",255,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5d3ddd80-fc67-4e17-a2b2-92d479c81d82,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Post-editing time as a measure of cognitive effort'],['2012'],['M Koponen;W Aziz;L Ramos;L Specia'],single,"['We', 'hypothesize', 'that', 'texts', 'with', 'alignment', 'are', 'less', 'cognitively', 'demanding', 'to', 'process,', 'and', 'so', 'less', 'effortful', 'to', 'post-edit', 'than', 'texts', 'without', 'alignment.', 'If', 'this', 'is', 'the', 'case,', 'shorter', 'post-editing', 'times', 'for', 'texts', 'with', 'alignment', 'are', 'consistent', 'with', 'previous', 'findings', 'by', '<ref type=""single"">Koponen et al. (2012),</ref>', 'who', 'found', 'that', 'per', 'word', 'post-editing', 'times', 'were', 'shorter', 'for', 'segments', 'that', 'were', 'less', 'cognitively', 'demanding', 'because', 'of', 'the', 'linguistic', 'structure.', 'Related', 'work', 'on', 'cognitive', 'effort', 'in', 'post-editing', '<ref type=""group"">(Lacruz et al., 2014, Lacruz and Shreve, 2014)</ref>', 'has', 'also', 'shown', 'decreased', 'densities', 'of', 'short', 'pauses', 'when', 'less', 'cognitively', 'demanding', 'segments', 'are', 'post-edited.']",40,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
5d42ab79-56dd-4911-a3f5-044a1ec75f08,Diverse dialogue generation with context dependent dynamic loss function,2020,Ayaka Ueyama;Yoshinobu Kano,['Rouge: A package for automatic evaluation of summaries'],['2004'],['Chin-Yew Lin'],single,"['Table', '1', 'and', 'Table', '2', 'respectively', 'present', 'evaluation', 'results', 'for', 'Japanese', 'and', 'English', 'datasets', 'in', 'perplexity,', 'BLEU', '<ref type=""single"">(Papineni et al., 2002),</ref>', 'DIST-N', '<ref type=""single"">(Li et al., 2016),</ref>', 'ROUGE', '<ref type=""single"">(Lin, 2004),</ref>', 'also', 'showing', 'length,', 'which', 'is', 'an', 'average', 'number', 'of', 'tokens', 'generated', 'in', 'a', 'sentence.', '*', 'in', 'these', 'tables', 'indicate', 'significant', 'differences', 'between', 'baseline', 'models', 'and', 'INF', 'model', 'for', 'each', 'evaluation', 'metric', '(p&lt,0.05).', 'BLEU', 'and', 'ROUGE', 'were', 'used', 'to', 'assess', 'the', 'quality', 'of', 'the', 'generated', 'sentences,', 'whereas', 'DIST-N', 'was', 'used', 'to', 'calculate', 'the', 'proportion', 'of', 'different', 'n-grams', 'among', 'the', 'n-grams', 'included', 'in', 'the', 'generated', 'sentences,', 'and', 'therefore', 'to', 'assess', 'the', 'diversity', 'of', 'the', 'generated', 'sentences.']",21,"[3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5d9a3a01-f8dc-475f-84c0-2281b32dd064,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['UPAR7: A knowledge-based system for headline sentiment tagging'],['2007'],['François-Régis Chaumartin'],single,"['A', 'viable', 'approach', 'to', 'sentiment', 'analysis', 'of', 'newspaper', 'headlines', 'has', 'been', 'developed', 'by', 'using', 'linguistic', 'techniques', 'and', 'a', 'broad-coverage', 'lexicon', '<ref type=""single"">(Chaumartin, 2007).</ref>']",20,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
5daeac9e-9f8c-4380-97e2-397207335861,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,"['Training tips for the transformer model', 'Analyzing multihead self-attention: Specialized heads do the heavy lifting, the rest can be pruned']","['2018', '2019']","['Martin Popel;Ondřej Bojar', 'Elena Voita;David Talbot;Fedor Moiseev;Rico Sennrich;Ivan Titov']",group,"['We', 'use', 'the', 'Transformer-Base', 'model', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'which', 'has', '6', 'layers', 'each', 'in', 'the', 'three', 'components:', 'encoder', 'self-attention', '(ES),', 'encoderdecoder', 'cross-attention', '(ED),', 'and', 'decoder', 'selfattention', '(DS).', 'In', 'each', 'layer', 'of', 'each', 'of', 'the', 'three', 'components,', 'we', 'have', '8', 'attention', 'heads,', 'totalling', 'to', '3', '×', '6', '×', '8', '=', '144', 'attention', 'heads.', 'We', 'train', 'the', 'mod-els', 'with', '2.5', 'million', 'sentence', 'pairs', 'each', 'from', 'the', ""WMT'14"", 'English-Russian', '(EN-RU)', 'and', 'English-German', '(EN-DE)', 'datasets.', 'We', 'report', 'BLEU', 'scores', 'on', ""WMT's"", 'newstest2014.', 'We', 'use', 'Adam', 'optimizer', '(Kingma', 'and', 'Ba,', '2014)', 'with', 'parameters', 'β', '1', '=', '0.9,', 'β', '2', '=', '0.997,', 'and', '=', '10', '−9.', 'We', 'vary', 'the', 'learning', 'rate', 'according', 'to', 'the', 'formula', 'described', 'in', '<ref type=""single"">Vaswani et al. (2017)</ref>', 'with', 'warmup', 'steps', '=', '16k.', 'We', 'use', 'large', 'batch', 'sizes', 'of', '32k', 'and', '25k', 'for', 'EN-RU', 'and', 'EN-DE,', 'respectively,', 'as', 'it', 'has', 'been', 'established', 'that', 'large', 'batch', 'sizes', 'are', 'inherent', 'to', 'the', 'performance', 'of', 'Transformers', '<ref type=""group"">(Popel and Bojar, 2018, Voita et al., 2019b).</ref>', 'We', 'achieve', 'effectively', 'large', 'batch', 'sizes', 'using', 'the', 'technique', 'of', 'gradient', 'accumulation', 'on', 'single', 'NVIDIA', 'V100', 'and', '1080Ti', 'GPUs.']",145,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5dc63b1e-1cfd-4bd1-a12a-266b30fedb78,Themes in the work of Margaret Masterman,1988,Yorick Wilks,"['Semantic grammar: an engineering technique for constructing natural language understanding systems. Bolt, Beranek and Newman']",['1978'],['R Burton'],single,"['A', 'major', 'concern', 'of', ""MMB's"", 'was', 'always', 'how', 'to', 'parse', 'written', 'English', 'into', 'a', 'machine', 'representation', 'for', 'MT', '<ref type=""single"">(Masterman, 1968).</ref>', 'She', 'believed', 'that', 'such', 'a', 'representation', 'should', 'be', 'fundamentally', 'semantic', 'in', 'nature', '(i.e.', 'based', 'on', 'meaning', 'rather', 'than', 'syntax)', 'and', 'that', 'those', 'semantic', 'structures', 'should', 'be', 'used', 'in', 'the', 'parsing', 'process', 'itself.', 'The', 'latter', 'view', 'was', 'highly', 'original,', 'since', 'virtually', 'no', 'one', 'has', 'ever', 'proposed', 'such', 'a', 'thing', '-the', 'doctrine', 'is', 'now', 'known', 'as', 'semantic', 'parsing,', 'and', 'is', 'well', 'known', 'even', 'if', 'not', 'as', 'fashionable', 'as', 'it', 'was', 'ten', 'years', 'ago', '-and', 'espousing', 'it', 'certainly', 'set', 'MMB', 'apart', 'from', 'the', 'prevailing', 'syntactic', 'approaches', 'of', 'her', 'time.', 'Some', 'contemporary', 'clarification', 'will', 'be', 'needed', 'in', 'later', 'commentary', 'on', 'this', 'point,', 'since', 'the', 'meaning', 'of', 'the', 'word', ""'semantics'"", 'as', 'used', 'by', 'MMB', 'in', 'this', 'connection,', 'cannot', 'be', 'equated', 'with', 'either', 'its', 'use', 'in', ""'semantic"", ""grammar'"", '(e.g.', '<ref type=""single"">Burton, 1978)</ref>', 'to', 'mean', 'parsing', 'by', 'the', 'use', 'of', 'particular', 'word-names', 'as', 'they', 'occur', 'in', 'text', '(e.g.', 'as', 'in', 'a', 'program', 'that', 'knew', 'what', 'words', 'would', 'follow', ""'electrical'),"", 'nor', 'with', 'its', 'currently', 'dominant', 'use', 'in', 'formal,', 'logical', 'semantics,', 'to', 'which', 'we', 'shall', 'return', 'in', 'a', 'moment.']",142,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5dd0ea30-ae44-4baa-97cc-d94ef741f62a,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,['RelGAN: Relational Generative Adversarial Networks for Text Generation'],['2019'],['Weili Nie;Nina Narodytska;Ankit Patel'],single,"['In', 'these', 'experiments', 'we', 'have', 'compared', 'the', 'conditioned', 'text', 'generation', 'of', 'CTERM-GAN', 'with', 'that', 'of', 'the', 'state-of-the-art', 'adversarial', 'architectures', '-Se-qGAN', '<ref type=""single"">[24],</ref>', 'RelGAN', '<ref type=""single"">[16],</ref>', 'and', 'TGVAE', '<ref type=""single"">[22]</ref>', '-and', 'a', 'classic', 'auto-regressive', 'LSTM', 'language', 'model', 'with', 'an', 'initial', 'conditioning,', 'in', 'terms', 'of', 'both', 'syntactic', 'and', 'semantic', 'quality.', 'The', 'main', 'goal', 'is', 'to', 'ensure', 'a', 'good', 'quality', 'for', 'the', 'generation', 'by', 'introducing', 'a', 'conditioning', 'on', 'the', 'semantic', 'of', 'the', 'sentence.', 'In', 'this', 'task,', 'the', 'conditioning', 'consists', 'of', 'the', 'word', 'distribution', 'for', 'a', 'topic', 'extracted', 'from', 'a', 'sentence,', 'either', 'provided', 'by', 'the', 'user', 'or,', 'as', 'in', 'our', 'case,', 'sampled', 'from', 'the', 'dataset.', 'Any', 'type', 'of', 'topic', 'model', 'can', 'be', 'adopted:', 'in', 'our', 'case,', 'an', 'LDA', 'model', '<ref type=""single"">[2]</ref>', 'has', 'been', 'trained', 'on', 'a', 'starting', 'dataset', 'in', 'order', 'to', 'have', 'a', 'distribution', 'of', 'the', 'topics', 'covered', 'within', 'the', 'corpus.', 'The', 'LDA', 'model,', 'both', 'in', 'training', 'and', 'in', 'inference,', 'given', 'an', 'input', 'sentence,', 'builds', 'a', 'distribution', 'on', 'the', 'vocabulary.', 'In', 'turn,', 'this', 'distribution', 'influences', 'the', ""model's"", 'sentence', 'generation', 'thanks', 'to', 'its', 'inclusion', 'in', 'the', 'generation', 'process.', 'Most', 'likely,', 'improving', 'the', 'quality', 'of', 'the', 'topic', 'extraction', 'is', 'likely', 'to', 'improve', 'the', 'final', 'results', 'of', 'the', 'model.', 'Eventually,', 'the', 'extracted', 'distribution', 'is', 'used', 'as', 'the', 'condition-', 'ing', 'input,', 'c,', 'for', 'the', 'relational', 'memory', 'during', 'the', 'generation,', 'as', 'described', 'in', 'Section', '3.']",22,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5e0664f8-71b6-487a-a212-3d9ad391ea15,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['Conditional generators of words definitions'],['2018'],['Artyom Gadetsky;Ilya Yakubovskiy;Dmitry Vetrov'],single,"['For', 'the', 'definition', 'generation', 'dataset,', 'we', 'directly', 'use', 'the', 'OD', 'dataset', 'published', 'by', '<ref type=""single"">Gadetsky et al. (2018).</ref>', 'The', 'training', 'set', 'has', '33,128', 'words', 'and', '97,855', 'entries.', 'Each', 'entry', 'consists', 'of', 'a', 'triplet', 'of', '(w', '*,', 'c,', 'd', 'com', ').', 'For', 'testing,', 'we', 'align', 'the', 'words', 'and', 'context', 'in', 'OD', 'with', 'the', 'definitions', 'in', 'OALD', 'through', 'manual', 'annotation.', 'The', 'annotated', 'test', 'set', 'includes', '3,881', 'words', 'and', '5,111', 'entries,', 'which', 'is', 'used', 'for', 'automatic', 'evaluation', 'in', 'experiments.', 'Each', 'entry', 'in', 'the', 'test', 'set', 'has', 'both', 'golden', 'complex', 'and', 'simple', 'definitions', 'from', 'OD', 'and', 'OALD,', 'respectively.', 'Detailed', 'statistics', 'are', 'listed', 'in', 'Table', '1.']",13,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0]"
5e35ec41-7a3a-415a-a917-df8046efb805,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['unknown'],['2018'],['Mingbo Ma;Liang Huang;Hao Xiong;Renjie Zheng;Kaibo Liu;Baigong Zheng;Chuanqiang Zhang;Zhongjun He;Hairong Liu;Xing Li'],single,"['The', 'wait-k', 'policy', '<ref type=""single"">(Ma et al., 2018)</ref>', 'refers', 'to', 'write', 'target', 'word', 'y', 't', 'after', 'reading', 'source-side', 'pre-fix', '(x', '1', '..x', 't+k−1', ').', 'Let', 'g(t)', 'be', 'a', 'monotonic', 'nondecreasing', 'function', 'of', 't', 'that', 'indicates', 'the', 'number', 'of', 'source', 'words', 'read', 'by', 'the', 'encoder', 'when', 'writing', 'the', 'target', 'word', 'y', 't.', 'Unlike', 'full-sentence', 'translation,', 'the', 'wait-k', 'policy', 'uses', 'the', 'source', 'prefix', '(x', '1', ',...,', 'x', 'g(t))', 'rather', 'than', 'the', 'whole', 'sentence', 'x', 'to', 'generate', 'y', 't:', 'p(y', 't', '|x', '≤g(t),', 'y', '&lt,t', ').', 'Thus,', 'the', 'decoding', 'probability', 'is', 'shown', 'in', 'Eq.', '7,', 'and', 'given', 'training', 'data', 'D,', 'the', 'training', 'objective', 'is', 'shown', 'in', 'Eq.', '8.']",3,"[1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5e3d562b-b98c-49ca-8bd4-131812b79e71,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Resources and benchmark corpora for hate speech detection: a systematic review'],['2020'],['Fabio Poletto;Valerio Basile;Manuela Sanguinetti;Cristina Bosco;Viviana Patti'],single,"['Although', 'there', 'are', 'some', 'efforts', 'to', 'detect', 'nonacceptable', 'language', 'in', 'Portuguese,', 'they', 'evaluate', 'the', 'developed', 'approach', 'in', 'their', 'own', 'corpus,', 'making', 'a', 'fair', 'comparison', 'among', 'the', 'models', 'difficult.', 'Moreover,', 'these', 'corpora', 'are', 'much', 'smaller', 'when', 'compared', 'to', 'corpora', 'of', 'other', 'languages', '<ref type=""single"">(Poletto et al., 2020)</ref>', 'and', 'than', 'the', 'ToLD-Br', 'corpus.', 'This', 'fact', 'makes', 'the', 'development', 'of', 'robust', 'strategies', 'to', 'handle', 'toxic', 'comments', 'difficult,', 'as', 'they', 'usually', 'require', 'a', 'large', 'corpus.', 'As', 'one', 'can', 'see', 'in', 'Table', '1,', 'the', 'corpus', 'has', 'a', 'little', 'more', 'non-toxic', 'than', 'toxic', 'tweets.', 'In', 'this', 'paper,', 'we', 'adopted', 'the', 'binary', 'version', 'of', 'the', 'corpus,', 'i.e.,', 'our', 'objective', 'is', 'to', 'identify', 'if', 'a', 'comment', 'is', 'toxic', 'or', 'non-toxic.']",41,"[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5e44b66f-ff23-4e08-98b4-7b31f36c8240,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,"['A study of word association', 'Word association norms: Grade school through college']","['1966', '1964']","['David Mcneill', 'S David;James J Palermo;unk Jenkins']",group,"['This', 'task', 'is', 'highly', 'related', 'to', 'word', 'association', 'modeling,', 'which', 'has', 'been', 'studied', 'extensively', 'in', 'psycholinguistics', 'for', 'a', 'long', 'time', '<ref type=""group"">(Palermo and Jenkins, 1964, McNeill, 1966),</ref>', 'but', 'is', 'by', 'no', 'means', 'equivalent', 'to', 'it.', 'In', 'word', 'association', 'experiments,', 'subjects', 'should', 'name', 'any', 'word', 'associated', 'with', 'a', 'given', 'word', 'as', 'quickly', 'as', 'possible,', 'but', 'in', 'this', 'case,', 'the', ""spymaster's"", 'task', 'is', 'to', 'find', 'a', 'word', 'that', 'is', 'related', 'to', 'as', 'many', 'words', 'from', 'a', 'given', 'set', 'as', 'possible,', 'but', 'not', 'or', 'significantly', 'less', 'closely', 'to', 'a', 'set', 'of', 'other', 'words.', 'The', 'time', 'allotted', 'for', 'the', 'task', 'is', 'also', 'limited', 'at', 'most', 'very', 'loosely', '(by', 'the', 'patience', 'of', 'the', 'other', 'players),', 'and', 'based', 'on', 'personal', 'experiences,', 'spymasters', 'often', 'use', 'several', 'minutes', 'of', 'thinking', 'time', 'to', 'come', 'up', 'with', 'the', 'right', 'clue.', 'For', 'this', 'reason,', 'connected', 'words', 'are', 'often', 'related', 'in', 'a', 'complex', 'way,', 'even', 'indirectly.', 'The', 'task', 'of', 'agents', '-to', 'find', 'words', 'in', 'the', 'table', 'related', 'to', 'the', 'clue', 'word', '-is', 'more', 'like', 'simple', 'associations,', 'but', 'time', 'is', 'not', 'dominant', 'here', 'either,', 'and', 'more', 'complex,', 'indirect', 'relations', 'also', 'matter.', 'In', 'a', 'game', 'between', 'people,', 'the', 'relationship', 'and', 'common', 'knowledge', 'between', 'the', 'players', 'can', 'also', 'count,', 'but', 'this', 'is', 'not', 'an', 'influencing', 'factor', 'in', 'a', 'game', 'with', 'an', 'agent.']",20,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5e47fe44-def1-4660-a210-98be9d59d0f1,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['Specifically,', 'we', 'use', 'a', 'retrieval-based', 'ranker', 'model', 'that', 'checks', 'for', 'similarity', 'of', '<ref type=""single"">StarSpace (Wu et al., 2018)</ref>', 'embeddings.', 'Our', 'choice', 'of', 'model', 'is', 'influenced', 'by', '<ref type=""single"">Fan et al. (2019)</ref>', 'who', 'report', 'stateof-the-art', 'retrieval', 'performance', 'for', 'locations', 'in', 'LIGHT', 'using', 'this', 'model.', 'The', 'overall', 'ranker', 'model', 'first', 'trains', 'a', 'randomly', 'initialized', 'StarSpace', 'embedding', 'model', 'that', 'is', 'designed', 'to', 'correlate', 'characters', 'with', 'the', 'locations', 'they', 'are', 'found', 'in.', 'It', 'learns', 'a', 'single', 'bag-of-words', 'embedding', 'that', 'takes', 'into', 'account', 'all', 'the', 'individual', 'words', 'contained', 'within', 'the', 'input-encoding', 'character', 'and', 'location', 'information', 'as', 'well', 'as', 'the', 'previously', 'mentioned', 'negative', 'Quest', 'Generation.', 'The', 'quest', 'is', 'now', 'generated', 'using', 'the', 'existing', 'character', 'and', 'location', 'information.', 'The', 'generation-based', 'models', 'used', 'in', 'this', 'pipeline', 'are', 'trained', 'to', 'return', 'the', 'most', 'likely', 'output', 'sequence', 'given', 'an', 'input', 'sequence.', 'Given', 'a', 'target', 'sequence', 'Y', '=', '{y', '1,', '...,', 'y', 'M}', 'and', 'some', 'input', 'context', 'vector', 'via', 'the', 'encoders', 'X.', 'These', 'models', 'use', 'autoregressive', 'decoding', 'techniques', 'that', 'factor', 'the', 'distribution', 'over', 'the', 'target', 'sequence', 'into', 'a', 'chain', 'of', 'conditional', 'probabilities', 'with', 'a', 'causal', 'left', 'to', 'right', 'structure', 'as', 'P', '(Y', '|X,', 'θ)', '=', 'M', '+1', 'i=1', 'p(y', 'i', '|y', '0:i−1,', 'X,', 'θ)', 'where', 'θ', 'represents', 'the', 'current', 'network', 'parameters.', 'At', 'test', 'time,', 'a', 'special', 'start-of-sequence', 'token', 'is', 'provided', 'to', 'the', 'model', 'which', 'then', 'proceeds', 'to', 'decode', 'the', 'rest', 'of', 'the', 'output', 'sequence', 'using', 'beam', 'search.']",21,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5e48fe03-24b0-4525-8073-a75eb9aa0c01,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,"['Saurabh Tiwary, and Tong Wang']",['2018'],['Payal Bajaj;Daniel Campos;Nick Craswell;Li Deng;Jianfeng Gao;Xiaodong Liu;Rangan Majumder;Andrew Mcnamara;Bhaskar Mitra;Tri Nguyen;Mir Rosenberg;Xia Song;Alina Stoica'],single,"['(3)', 'the', 'subword', 'field,', 'which', 'breaks', 'tokens', 'into', 'subwords,', 'and', '(4)', 'the', 'd2q', 'field,', 'which', 'includes', 'the', 'stemmed', 'tokens', 'from', 'the', 'concatenated', 'docTTTTTquery', 'predictions', '(for', 'the', 'd2q', 'variants).', 'For', 'each', 'querydocument', 'pair,', 'feature', 'extraction', 'is', 'repeated', 'over', 'all', 'applicable', 'fields.', 'In', 'total,', 'there', 'are', '83', 'different', 'features', '(per', 'field)', 'plus', 'four', 'translation-based', 'features', 'that', 'are', 'only', 'available', 'in', 'the', 'raw', 'and', 'subword', 'fields.', 'We', 'additionally', 'test', 'on', 'the', 'MS', 'MARCO', 'document', 'ranking', 'task', '<ref type=""single"">(Bajaj et al., 2018)</ref>', 'in', 'a', 'zeroshot', 'manner.', 'For', 'this,', 'we', 'segment', 'each', 'document', 'into', 'multiple', 'passages', 'as', 'the', 'neural', 'models', 'cannot', 'process', 'long', 'documents.', 'Specifically,', 'we', 'use', 'the', 'sliding', 'window', 'strategy', 'of', '<ref type=""single"">Pradeep et al. (2021),</ref>', 'where', 'the', 'window', 'length', 'is', 'ten', 'sentences', 'with', 'a', 'stride', 'of', 'five', 'sentences.', 'Retrieval', 'is', 'performed', 'at', 'the', 'passage', 'level,', 'and', 'the', 'document', 'score', 'is', 'computed', 'based', 'on', 'the', 'highest', 'relevance', 'score', 'among', 'its', 'passages.']",73,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5e7b2a0f-2c5b-4085-b416-5a7e218b9f54,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Parsing Schemata -A Fra mework fo r Sp ecification and Analysis of Parsing Algorithms'],['1997'],['K Sikkel'],single,"['We', 'will', 'describe', 'parsing', 'algorithms', 'using', 'Parsing', 'Schemata,', 'a', 'framework', 'for', 'high-level', 'description', 'of', 'parsing', 'algorithms', '<ref type=""single"">(15].</ref>', 'An', 'interesting', 'application', 'of', 'this', 'framework', 'is', 'the', 'analysis', 'of', 'the', 'relations', 'between', 'different', 'parsing', 'algorithms', 'by', 'studying', 'the', 'formal', 'relations', 'between', 'their', 'underlying', 'parsing', 'schemata.']",16,"[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
5f554d4b-295e-4fd0-af6a-106e8ffe9c11,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Variable-free discourse representation structures'],['2021'],['Johan Bos'],single,"['In', 'prediction', 'tasks,', 'it', 'is', 'important', 'that', 'label', 'predictions', 'generalize', 'to', 'unseen', 'data.', 'In', 'contrast', 'to', 'this,', 'the', 'numeric', 'part', 'of', 'referent', 'labels', 'in', 'clauses', 'are', 'not', 'meaningful', 'and', 'depend', 'on', 'the', 'number', 'of', 'referents', 'that', 'were', 'introduced', 'before', 'in', 'the', 'same', 'sentence,', 'so', 'they', 'would', 'generalize', 'poorly.', 'Thus,', 'in', 'row', '(2),', 'we', 'change', 'the', 'referents', 'to', 'be', 'relative,', 'inspired', 'by', '<ref type=""single"">Bos (2021):</ref>', 'referents', 'that', 'have', 'not', 'occurred', 'before', 'get', 'the', 'index', '0', 'and', 'referents', 'that', 'have', 'occurred', 'get', 'a', 'negative', 'index,', 'indicating', 'how', 'long', 'ago', 'the', 'same', 'referent', 'last', 'occurred', '(counting', 'back', 'among', 'all', 'occurrences', 'of', 'referents', 'of', 'the', 'same', 'type).']",61,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
5fa87e7a-2f6b-4a54-a059-8981db5a6555,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['Stanford neural machine translation systems for spoken language domains'],['2015'],['Minh-Thang Luong;Christopher D Manning'],single,"['A', 'simple', 'yet', 'effective', 'method', 'for', 'improving', 'translation', 'quality', 'on', 'the', 'downstream', 'task', 'is', 'fine-tuning', 'with', 'domain', 'data,which', 'is', 'known', 'as', 'domain', 'adaption', '<ref type=""single"">(Luong and Manning, 2015).</ref>', 'We', 'train', 'for', 'another', '2', 'epochs', 'on', 'the', 'BSTC', 'dataset', 'with', 'pretrained', 'model.', 'Furthermore,', 'we', 'obverse', 'that', 'finetuning', 'on', 'limited', 'spoken', 'corpus', 'lead', 'to', 'overfit', 'quickly,', 'as', 'evidenced', 'by', 'the', 'significant', 'improvement', 'on', 'the', 'BSTC', 'development', 'set', 'while', 'degrades', 'rapidly', 'on', 'the', 'CWMT', 'development', 'set.']",23,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
6010f581-a07e-4ccc-9ac2-63a7da590186,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,['ColBERT: Efficient and effective passage search via contextualized late interaction over BERT'],['2020'],['Omar Khattab;Matei Zaharia'],single,"['Pretrained', 'transformers', 'such', 'as', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'have', 'dramatically', 'increased', 'retrieval', 'effectiveness', 'in', 'many', 'tasks', 'across', 'a', 'multitude', 'of', 'domains', '<ref type=""single"">(Lin et al., 2020a).</ref>', 'Nevertheless,', 'in', 'a', 'standard', '""retrieve-then-rerank""', 'setup,', 'the', 'application', 'of', 'pretrained', 'transformer-based', 'rerankers', 'incurs', 'large', 'computational', 'costs', 'and', 'long', 'query', 'latencies,', 'making', 'those', 'rerankers', 'unrealistic', 'for', 'many', 'real-world', 'applications.', 'For', 'example,', 'according', 'to', 'the', 'ColBERT', 'paper', '<ref type=""single"">(Khattab and Zaharia, 2020),</ref>', 'reranking', '1000', 'hits', 'from', 'the', 'MS', 'MARCO', 'passage', 'dataset', 'takes', '32.9', 'seconds', 'per', 'query.', 'Other', 'researchers', 'have', 'noted', 'the', 'computational', 'costs', 'of', 'transformer-based', 'rankers', '(Hofstätter', 'and', 'Hanbury,', '*', 'Equal', 'contribution', '2019),', 'and', 'this', 'realization', 'has', 'compelled', 'the', 'field', 'to', 'explore', 'other', 'approaches,', 'for', 'example,', 'simplified', 'models', '<ref type=""group"">(Hofstätter et al., 2020, Soldaini and Moschitti, 2020, Mitra et al., 2020, MacAvaney et al., 2020, Gao et al., 2020, Jiang et al., 2020)</ref>', 'and', 'learned', 'dense', 'representations', '<ref type=""group"">(Xiong et al., 2020, Lin et al., 2020b).</ref>']",55,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
60874e59-fd7b-47f0-af98-01465bb9f859,Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets,2021,George-Andrei Dima;Dumitru-Clementin Cercel;Mihai Dascalu,['Publicly available clinical bert embeddings'],['2019'],['Emily Alsentzer;John Murphy;William Boag;Wei-Hung Weng;Di Jindi;Tristan Naumann;Matthew Mcdermott'],single,"['Language', 'Models:', 'We', 'experimented', 'with', 'BERTbase', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'and', 'with', 'the', 'domainspecific', 'Transformers,', 'namely', 'BioBERT', 'and', 'Bio-ClinicalBERT', '<ref type=""single"">(Alsentzer et al., 2019).</ref>', 'After', 'a', 'preliminary', 'fine-tuning', 'on', 'the', 'subtask', '1a,', 'the', 'most', 'promising', 'results', 'were', 'obtained', 'by', 'BioBERT.']",16,"[3, 3, 2, 2, 2, 3, 3, 3, 2, 1, 1, 1, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
60b82cb4-eca3-4897-a522-ea8e3f9d0ec5,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['Tree pushdown automata'],['1985'],['K Schimpf;J Gallier'],single,"['A', 'standard', 'buTPDA', 'is', 'not', 'quite', 'the', 'right', 'model.', '<ref type=""single"">Schimpf and Gallier (1985)</ref>', 'prove', 'that', 'TPDAs', 'are', 'necessary', 'for', 'operating', 'on', 'tree', 'sets', 'with', 'context-free', 'path', 'languages.', '7', 'But', 'they', 'also', 'prove', 'that', 'the', 'yield', 'of', 'the', 'class', 'of', 'tree', 'languages', 'accepted', 'by', 'buTPDAs', 'is', 'the', 'indexed', 'languages.', 'For', 'the', 'nature', 'of', 'gNCNs', 'presented', 'in', 'this', 'paper,', 'the', 'string', 'language', 'should', 'be', 'within', 'the', 'mildly', 'context-sensitive', 'languages', '(MCSLs),', 'thus', 'this', 'type', 'of', 'TPDA', 'is', 'too', 'powerful.']",9,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2]"
60f0865a-9431-4524-b181-8145a641fc5f,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['Handling Structural Divergences and Recovering Dropped Arguments in a Korean/English Machine Translation System'],['2000'],['H Grune;C Bal;K Jacobs;unk Langendoen;U Chichester;B Han;M Lavoie;O Palmer;R Rambow;T Kittredge;N Korelsky;M Kim;unk Kim'],single,"['It', 'can', 'of', 'course', 'be', 'argued', 'that', 'an', 'alternative', 'representation', 'would', 'be', 'more', 'appropriate', 'for', 'MT,', 'where', 'who', 'depends', 'from', 'likes', 'in', 'the', 'tree.', 'We', 'have', 'used', 'the', 'system', 'of', '<ref type=""single"">Han et al. (2000)</ref>', 'to', 'illustrate', 'this', 'point', 'because', 'it', 'is', 'a', 'system', 'that', 'has', 'the', 'goal', 'of', 'exploring', 'the', 'feasibility', 'of', 'a', 'plug-and-play', 'architecture:', 'that', 'is,', 'necessary', 'components', 'such', 'as', 'a', 'parser', 'are', 'obtained', 'from', 'elsewhere,', 'with', 'a', 'given', 'output', 'structure', 'that', 'it', 'is', 'necessary', 'to', 'use.', 'Given', 'this,', 'gNCNs', 'are', 'required', 'either', 'directly', 'or', 'indirectly.', 'The', 'case', 'of', 'the', 'direct', 'relation,', 'using', 'these', 'structures', 'as', 'the', 'basis', 'for', 'a', 'transfer', 'component,', 'is', 'illustrated', 'already', 'in', 'the«DXD[the]', '¬COMPs[which]', '«DXD[the]', '¬COMPs[which]', '«DXD[the]', '«NXdxN[floor]', '¬N0nx0Vnx1[covered]', '«NXdxN[dust]', '¬N0nx0Vnx1[collected]', '«NXdxN[jacket]', '¬Vvx[is]', '«nx0Ax1[tweed]', '«DXD[the]', '¬COMPs[which]', '«DXD[the]', '«NXdxN[dust]', '¬N0nx0Vnx1[collected]', '«NXdxN[jacket]', '¬Vvx[is]', '«NXN[it]', '«DXD[the]', '«NXdxN[floor]', '«nx0Vnx1[covered]', '¬sPUs[.]', '«nx0Ax1[tweed]Figure', '5:', 'Derivation', 'tree', 'pair', 'for', 'example', '(4)', 'lefthand', 'pair', 'of', 'Figure', '4,', 'a', 'pairing', 'indirectly', 'involving', 'gNCNs', 'would', 'be', 'required', 'in', 'transforming', 'the', 'syntactic', 'representation', 'into', 'a', 'deeper', 'semantic', 'one', '(the', 'one', 'used', 'in', 'translation),', 'as', 'in', 'the', 'righthand', 'pair', 'of', 'Figure', '4.', 'This', 'latter', 'is', 'the', 'sort', 'of', 'relation', 'that', 'may', 'need', 'to', 'be', 'specified,', 'then,', 'in', 'a', 'formalism', 'with', 'multiple', 'levels,', 'such', 'as', 'MTT.']",30,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
60f3c57c-8b46-4e34-8e31-ec0c952459e9,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Subword regularization: Improving neural network translation models with multiple subword candidates'],['2018'],['Taku Kudo'],single,"['Ortega', 'et', 'al.', '(2020b)', 'used', 'morphological', 'information,', 'such', 'as', 'affixes,', 'to', 'guide', 'the', 'Byte-Pair-Encoding', '(BPE)', 'segmentation', 'algorithm', '<ref type=""single"">(Sennrich et al., 2016b)</ref>', 'for', 'Quechua.', 'However,', 'their', 'improvement', 'is', 'not', 'significant,', 'and', 'according', 'to', '<ref type=""single"">Bostrom and Durrett (2020),</ref>', 'BPE', 'tends', 'to', 'oversplit', 'roots', 'of', 'infrequent', 'words.', 'They', 'showed', 'that', 'a', 'unigram', 'language', 'model', '<ref type=""single"">(Kudo, 2018)</ref>', 'seems', 'like', 'a', 'better', 'alternative', 'to', 'split', 'affixes', 'and', 'preserve', 'roots', '(in', 'English', 'and', 'Japanese).']",45,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]"
6160a8c3-73ab-4eb0-91fb-9d8cdd72e26c,drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM,2022,Dylan Phelps,['SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation'],['2017'],['Daniel Cer;Mona Diab;Eneko Agirre;Iñigo Lopez-Gazpio;Lucia Specia'],single,"['English', 'and', 'Portuguese', 'are', 'the', 'primary', 'languages', 'and', 'general', 'STS', 'data,', 'from', 'STSBenchmark', '<ref type=""single"">(Cer et al., 2017)</ref>', 'and', 'ASSIN2', '<ref type=""single"">(Real et al., 2020)</ref>', 'for', 'English', 'and', 'Portuguese', 'respectively,', 'and', 'idiom', 'STS', 'data', 'for', 'both', 'languages', 'are', 'included', 'in', 'the', 'train,', 'dev,', 'eval', 'and', 'test', 'sets.', 'A', 'very', 'small', 'amount', '(50', 'examples)', 'of', 'Galician', 'data,', 'comprised', 'of', 'idiom', 'STS', 'data,', 'is', 'also', 'included', 'in', 'the', 'test', 'set.']",13,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
620fb93f-2db9-4ded-95e3-6c13f871e499,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Implicit argument prediction as reading comprehension'],['2019'],['Pengxiang Cheng;Katrin Erk'],single,"['Explicit', 'vs.', 'Implicit', 'NP', 'Relations', 'Next,', 'we', 'analyze', 'the', 'composition', 'of', 'the', 'relations', 'in', 'the', 'dataset,', 'as', 'to', 'whether', 'these', 'relations', 'are', 'implicit', 'or', 'explicit.', 'While', 'there', 'is', 'no', 'accepted', 'definition', 'of', 'explicit-implicit', 'distinction', 'in', 'the', 'literature', '<ref type=""group"">(Carston, 2009, Jarrah, 2016),</ref>', 'here', 'we', 'adapt', 'a', 'definition', 'originally', 'used', 'by', '<ref type=""single"">Cheng and Erk (2019)</ref>', 'for', 'another', 'phenomenon,', 'implicit', 'arguments:', '14', 'In', 'an', 'implicit', 'relation', 'the', 'anchor', 'and', 'the', 'complement', 'are', 'not', 'syntactically', 'connected', 'to', 'each', 'other', 'and', 'might', 'not', 'even', 'appear', 'in', 'the', 'same', 'sentence.', 'This', 'implies,', 'for', 'example,', 'that', 'any', 'inter-sentential', 'relations', 'are', 'implicit', '15,', 'while', 'relations', 'within', 'one', 'sentence', 'can', 'be', 'either', 'implicit', 'or', 'explicit.', 'We', 'sample', 'three', 'documents', 'from', 'the', 'test-set,', 'containing', '590', 'links', 'in', 'total,', 'and', 'count', 'the', 'number', 'of', 'relations', 'of', 'each', 'type.', 'Our', 'manual', 'analysis', 'reveals', 'that', '89.8%', 'of', 'the', 'relations', 'are', 'implicit.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
62d012ad-e4c0-46a2-9f76-fcd8985adb8b,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,['Continuous space language models'],['2007'],['H Schwenk'],single,"['where', 't', 'i', 'denotes', 'the', 'desired', 'output,', 'i.e.,', 'the', 'probability', 'should', 'be', '1.0', 'for', 'the', 'next', 'word', 'in', 'the', 'training', 'sentence', 'and', '0.0', 'for', 'all', 'the', 'other', 'ones.', 'The', 'first', 'part', 'of', 'this', 'equation', 'is', 'the', 'cross-entropy', 'between', 'the', 'output', 'and', 'the', 'target', 'probability', 'distributions,', 'and', 'the', 'second', 'part', 'is', 'a', 'regularization', 'term', 'that', 'aims', 'to', 'prevent', 'the', 'neural', 'network', 'from', 'over-fitting', 'the', 'training', 'data', '(weight', 'decay).', 'The', 'parameter', 'β', 'has', 'to', 'be', 'determined', 'experimentally.', 'Training', 'is', 'done', 'using', 'a', 're-sampling', 'algorithm', 'as', 'described', 'in', '<ref type=""single"">[11].</ref>']",85,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1]"
62faf58f-8404-483d-b816-b49e7fa5e9c5,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,['Unification-based Reconstruction of Multi-hop Explanations for Science Questions'],['2021'],['Marco Valentino;Mokanarangan Thayaparan;André Freitas'],single,"['The', 'current', 'state-of-the-art', 'on', 'the', 'explanation', 'regeneration', 'task', 'is', 'represented', 'by', 'a', 'model', 'that', 'employs', 'a', 'combination', 'of', 'language', 'models', 'and', 'Graph', 'Neural', 'Networks', '(GNN)', '<ref type=""single"">(Li et al., 2020),</ref>', 'with', 'the', 'bulk', 'of', 'performance', 'contributed', 'from', 'the', 'language', 'model.', 'Strong', 'performance', 'is', 'also', 'achieved', 'by', 'transformer', 'models', 'adapted', 'to', 'rank', 'inference', 'chains', '<ref type=""single"">(Das et al., 2019)</ref>', 'or', 'operating', 'in', 'an', 'iterative', 'and', 'recursive', 'fashion', '<ref type=""single"">(Cartuyvels et al., 2020).</ref>', 'In', 'contrast', 'with', 'neural-based', 'models,', 'recent', 'works', '<ref type=""single"">(Valentino et al., 2021)</ref>', 'have', 'shown', 'that', 'the', 'explanatory', 'patterns', 'emerging', 'in', 'the', 'WorldTree', 'corpus', 'can', 'be', 'leveraged', 'to', 'improve', 'sparse', 'retrieval', 'models', 'and', 'provide', 'a', 'viable', 'way', 'to', 'alleviate', 'semantic', 'drift.']",66,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
63066805-2b93-4522-82d7-692f8f559fbe,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Abductive commonsense reasoning'],['2020'],['Chandra Bhagavatula;Chaitanya Ronan Le Bras;Keisuke Malaviya;Ari Sakaguchi;Hannah Holtzman;Doug Rashkin;Scott Downey;Yih Wen-Tau;Yejin Choi'],single,"['Commonsense', 'explanation', 'generation.', 'It', 'aims', 'to', 'generate', 'an', 'explanation', 'given', 'a', 'counterfactual', 'statement', 'for', 'sense-making', '<ref type=""single"">(Wang et al., 2019).</ref>', 'We', 'use', 'the', 'benchmark', 'dataset', 'ComVE', 'from', 'SemEval-2020', 'Task', '4', '<ref type=""single"">(Wang et al., 2020).</ref>', 'The', 'dataset', 'contains', '10,000', '/', '997', '/', '1,000', 'examples', 'for', 'training', '/', 'development', '/', 'test', 'sets,', 'respectively.', 'The', 'average', 'input/output', 'length', 'is', '7.7', '/', '9.0', 'words.', 'All', 'examples', 'in', 'the', 'dataset', 'have', '3', 'references.', 'Abductive', 'commonsense', 'reasoning.', 'It', 'is', 'also', 'referred', 'as', 'α-NLG.', 'It', 'is', 'the', 'task', 'of', 'generating', 'a', 'valid', 'hypothesis', 'about', 'the', 'likely', 'explanations', 'to', 'partially', 'observable', 'past', 'and', 'future.', 'We', 'use', 'the', 'ART', 'benchmark', 'dataset', '<ref type=""single"">(Bhagavatula et al., 2020)</ref>', 'that', 'consists', 'of', '50,481', '/', '1,779', '/', '3,560', 'examples', 'for', 'training', '/', 'development', '/', 'test', 'sets.', 'The', 'average', 'input/output', 'length', 'is', '17.4', '/', '10.8', 'words.', 'Each', 'example', 'in', 'the', 'ART', 'dataset', 'has', '1', 'to', '5', 'references.']",95,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
630e675d-2749-48be-9782-9dbd748a0ec7,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,"['MULTEXT-East Version 3: Multilingual Morphosyntactic Specifications, Lexicons and Corpora']",['2004'],['Erjavec Tomaž'],single,"['Objective', 'and', 'subjective', 'evaluation', 'methods', 'were', 'used', 'in', 'final', 'testing', 'as', 'only', 'a', 'correct', 'mixture', 'of', 'methods', 'minimizes', 'evaluation', 'bias.', 'Translation', 'quality', 'evaluation', 'was', 'conducted', 'using', 'subjective', 'evaluation', 'methods,', 'where', 'a', 'group', 'of', 'native', 'and', 'near-native', 'speakers', 'scored', 'translations.', 'Automatic', 'objective', 'measures', '<ref type=""single"">NIST and BLEU (Papineni, 2001)</ref>', 'were', 'used', 'to', 'ensure', 'wider', 'coverage.', 'Bilingual', 'corpus', '<ref type=""single"">(Erjavec, 2004)</ref>', 'was', 'use', 'd', 'in', 'all', 'evaluation', 'processes.']",51,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]"
6392db29-ec56-4bb4-94e3-cdfd5053ec88,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['Comparisons of levin and wordnet. Presentation in working session of Semantic Tagging Workshop'],['1997'],['Doug Jones;Boyan Onyshkevych'],single,"['It', 'is', 'not', 'clear', 'how', 'much', 'WordNet', 'synsets', 'should', 'be', 'expected', 'to', 'overlap', 'with', 'Levin', 'classes,', 'and', 'preliminary', 'indications', 'are', 'that', 'there', 'is', 'a', 'wide', 'discrepancy', '<ref type=""single"">[4],</ref>', '<ref type=""single"">[6],</ref>', '<ref type=""single"">[3].</ref>', 'However,', 'it', 'would', 'be', 'useful', 'for', 'the', 'WordNet', 'synsets', 'to', 'have', 'access', 'to', 'the', 'detailed', 'syntactic', 'information', 'that', 'the', 'Levin', 'classes', 'contain,', 'and', 'it', 'would', 'be', 'equally', 'useful', 'to', 'have', 'more', 'guidance', 'as', 'to', 'when', 'membership', 'in', 'a', 'Levin', 'class', 'does', 'in', 'fact', 'indicate', 'shared', 'semantic', 'components.', 'Identification', 'of', 'these', 'components', 'is', 'critical', 'to', 'the', 'use', 'of', 'classes', 'and', 'their', 'semantic', 'features', 'for', 'translation', 'purposes,', 'whether', 'transfer-based', 'or', 'interlingua', 'based.', 'Although', 'Levin', 'classes', 'group', 'together', 'verbs', 'with', 'similar', 'argument', 'structures,', 'the', 'meanings', 'of', 'the', 'verbs', 'are', 'not', 'necessarily', 'synonymous.', 'Some', 'classes', 'such', 'as', 'break', '(break,', 'chip,', 'crack,', 'crash,', 'crush,', 'fracture,', 'rip,', 'shatter,', 'smash,', 'snap,', 'splinter,', 'tear)', 'and', 'cut', '(chip,', 'clip,', 'cut,', 'hack,', 'hew,', 'saw,', 'scrape,', 'scratch,', 'slash,', 'snip)', 'contain', 'verbs', 'that', 'are', 'quite', 'synonymous,', 'but', 'others,', 'such', 'as', 'braid', '(bob,', 'braid,', 'brush,', 'clip,', 'coldcream,', 'comb,', 'condition,', 'crimp,', 'crop,', 'curl,', 'etc.)', 'do', 'not,', 'which', 'at', 'least', 'partly', 'explains', 'the', 'lack', 'of', 'overlap', 'between', 'Levin', 'and', 'WordNet.']",27,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
63b79a9e-9074-43bb-b665-7f52861e38cc,Corpora and Machine Translation,1993,Yorick Wilks,['Poor estimates of context are worse than none'],['1990'],['W Gale;K Church'],single,"['They', 'are,', 'as', 'it', 'were,', 'wholly', 'pragmatic', 'statisticians:', 'less', 'pure', 'than,', 'say,', 'the', 'Gale', 'group', '(e.g.', '<ref type=""single"">Gale &amp, Church 1990)</ref>', 'at', 'AT&amp,T:', 'this', 'is', 'easily', 'seen', 'by', 'the', 'IBM', 'introduction', 'of', 'notions', 'like', 'the', 'one', 'they', 'call', '""informants""', 'where', 'a', 'noun', 'phrase', 'of', 'some', 'sort', 'is', 'sought', 'before', 'a', 'particular', 'text', 'item', 'of', 'interest.', 'This', 'is', 'an', 'interpolation', 'of', 'a', 'highly', 'theoretically-loaded', 'notion', 'into', 'a', 'routine', 'that,', 'until', 'then,', 'had', 'treated', 'all', 'text', 'items', 'as', 'mere', 'uninterpreted', 'symbols.']",16,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6443bfb8-2d12-4e0c-9612-db75a63bbbb0,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Dict2vec: Learning word embeddings using lexical dictionaries'],['2017'],['Julien Tissier;Christophe Gravier;Amaury Habrard'],single,"['In', 'addition,', 'they', 'introduce', 'another', 'method', 'to', 'score', 'clues', 'not', 'only', 'on', 'the', 'basis', 'of', 'word', 'similarities,', 'but', 'also', 'on', 'the', 'basis', 'of', 'their', 'frequency', 'and', 'the', 'similarity', 'of', 'Dict2vec', 'vectors', '<ref type=""single"">(Tissier et al., 2017)</ref>', '-but', 'this', 'is', 'actually', 'a', 'modification', 'of', 'the', 'original', 'distance', 'matrix.']",31,"[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
645ef370-1fb3-4b24-bbb1-7b549ab531bc,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Identifying civilians killed by police with distantly supervised entity-event extraction'],['2017'],"[""Katherine Keith;Abram Handler;Michael Pinkham;Cara Magliozzi;Joshua Mcduffie;Brendan O' Connor""]",single,"['The', 'type', 'of', 'information', 'recovered', 'by', 'the', 'NP', 'Enrichment', 'task', 'complements', 'well-established', 'core', 'NLP', 'tasks', 'such', 'as', 'entity', 'typing,', 'entity', 'linking,', 'coreference', 'resolution,', 'and', 'semantic-role', 'labeling', '<ref type=""single"">(Jurafsky and Martin, 2009).</ref>', 'We', 'believe', 'it', 'serves', 'as', 'an', 'important', 'and', 'much-needed', 'building', 'block', 'for', 'downstream', 'applications', 'that', 'require', 'text', 'understanding,', 'including', 'information', 'retrieval,', 'relation', 'extraction', 'and', 'event', 'extraction,', 'question', 'answering,', 'and', 'so', 'on.', 'In', 'particular,', 'the', 'NP', 'Enrichment', 'task', 'neatly', 'encapsulates', 'much', 'of', 'the', 'long-range', 'information', 'that', 'is', 'often', 'required', 'by', 'such', 'applications.', 'Take', 'for', 'example', 'a', 'system', 'that', 'attempts', 'to', 'extract', 'reports', 'on', 'police', 'shooting', 'incidents', '<ref type=""single"">(Keith et al., 2017),</ref>', 'with', 'the', 'following', 'challenging,', 'but', 'not', 'uncommon,', 'passage:', '2']",92,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6484c43e-74d9-434d-8dd2-66e5389b31a5,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,"['unknown', 'Mark my word: A sequence-to-sequence approach to definition modeling', 'Learning to describe unknown phrases with local and global contexts']","['unknown', '2019', '2019']","['unknown', 'Timothee Mickus;Denis Paperno;Matthieu unk', 'Shonosuke Ishiwatari;Hiroaki Hayashi;Naoki Yoshinaga;Graham Neubig;Shoetsu Sato;Masashi Toyoda;Masaru Kitsuregawa']",group,"['The', 'definition', 'generation', 'task', 'is', 'first', 'introduced', 'by', '<ref type=""single"">Noraset et al. (2017).</ref>', 'Although', 'this', 'task', 'is', 'proposed', 'as', 'a', 'potentially', 'useful', 'tool', 'for', 'explainable', 'AI,', 'many', 'subsequent', 'works', 'believe', 'that', 'it', 'can', 'assist', 'language', 'learning', 'by', 'giving', 'definitions', 'for', 'words', 'in', 'the', 'text', '<ref type=""group"">(Ishiwatari et al., 2019, Mickus et al., 2019, Yang et al., 2020).</ref>']",40,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
64eab2d0-0ea1-45c7-9d4d-46fb3093063c,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['unknown'],['2016'],['Eric Jang;Shixiang Gu;Ben Poole'],single,"['With', 'a', 'slight', 'abuse', 'of', 'notations,', 'we', 'use', 'p', 'B', '(x', 't−1)', 'to', 'denote', 'p', 'B', '(u', 't,', 'x', 't−1,', 'c', 't−1', ').', 'We', 'formulate', 'the', 'training', 'loss', 'for', 'self-supervised', 'task', 'as:L', 'mem', '=', 'd', 'i', '−', 'log(b', 't', 'p', 'B', '(l(x', 't−1', ')))', '−', 'KL(p', 'B', '(x', 't−1', ')||p', 'B', '(l(x', 't−1', '))', '(9)where', 'KL', 'is', 'Kullback-Leibler', 'divergence,', 'and', 'l(x', 't−1', '))', 'is', 'the', 'natural', 'language', 'action', 'obtained', 'via', 'the', 'memory', 'component.', 'This', 'loss', 'enforces', 'the', 'learned', 'action', 'representations', 'to', 'restore', 'both', 'the', 'ground', 'truth', 'and', 'predicted', 'state', 'transitions.', 'Note', 'that', 'the', 'natural', 'language', 'actions', 'are', 'sampled', 'from', 'categorical', 'distributions,', 'which', 'is', 'nondifferentiable.', 'To', 'get', 'gradients', 'for', 'the', 'memory', 'component', 'during', 'back-propagation,', 'we', 'apply', 'a', 'continuous', 'approximation,', 'i.e.,', 'using', 'gumbelsoftmax', 'trick', 'instead', 'to', 'conduct', 'sampling', '<ref type=""single"">(Jang et al., 2016),</ref>', 'to', 'enable', 'end-to-end', 'differentiability.']",126,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3]"
66048f78-1f7d-4e50-8e9a-bfc7236302e2,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['A broad-coverage challenge corpus for sentence understanding through inference'],['2018'],['Adina Williams;Nikita Nangia;Samuel Bowman'],single,"['Our', 'training', 'data', 'include', 'two', 'public', 'datasets:', 'MNLI', '<ref type=""single"">(Williams et al., 2018)</ref>']",8,"[2, 2, 2, 2, 2, 2, 2, 1, 1]"
660888a1-62b7-4896-93b8-2d3ff4d4e00b,Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets,2021,George-Andrei Dima;Dumitru-Clementin Cercel;Mihai Dascalu,['Adversarial multi-task learning for text classification'],['2017'],['Pengfei Liu;Xipeng Qiu;Xuan-Jing Huang'],single,"['Multi-Task', 'Learning', 'represents', 'a', 'training', 'strategy', 'where', 'a', 'shared', 'model', 'is', 'simultaneously', 'learning', 'multiple', 'tasks.', '<ref type=""single"">Ruder (2017)</ref>', 'analysed', 'the', 'techniques', 'applied', 'in', 'MTL', 'and', 'compared', 'the', 'hard', 'parameter', 'sharing', 'and', 'soft', 'parameter', 'sharing', 'paradigms,', 'concluding', 'that', 'the', 'former', 'is', 'still', 'pervasive', 'in', 'nowadays', 'approaches.', 'MTL', 'proved', 'to', 'fasten', 'the', 'convergence', 'and', 'to', 'improve', 'the', 'model', 'performance', 'in', 'a', 'variety', 'of', 'NLP', 'applications,', 'including', 'named', 'entity', 'recognition', '<ref type=""single"">(Aguilar et al., 2018),</ref>', 'fake', 'news', 'detection', '<ref type=""single"">(Wu et al., 2019),</ref>', 'multilingual', 'offensive', 'language', 'identification', '<ref type=""single"">(Chen et al., 2020b),</ref>', 'sentiment', 'analysis', '<ref type=""single"">(Zaharia et al., 2020),</ref>', 'humor', 'classification', '<ref type=""single"">(Vlad et al., 2020),</ref>', 'recommender', 'systems', '<ref type=""single"">(Tang et al., 2020),</ref>', 'and', 'even', 'question', 'answering', '<ref type=""single"">(Kongyoung et al., 2020).</ref>', 'MTL', 'also', 'increases', 'performance', 'in', 'conjunction', 'with', 'semi-supervised', 'learning', '<ref type=""single"">(Liu et al., 2007),</ref>', 'curriculum', 'learning', '<ref type=""single"">(Dong et al., 2017),</ref>', 'sequence-tosequence', '<ref type=""single"">(Zaremoodi and Haffari, 2018),</ref>', 'reinforcement', 'learning', '<ref type=""single"">(Gupta et al., 2020),</ref>', 'and', 'adversarial', 'learning', '<ref type=""single"">(Liu et al., 2017).</ref>']",110,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1]"
663652af-e322-4541-bc4a-0f1a2af61af6,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['PE2rr corpus: Manual error annotation of automatically preannotated MT post-edits'],['2016'],['Maja Popović;Mihael Arčan'],single,"['Second,', 'we', 'use', 'the', 'PE', '2', 'rr', 'dataset', '<ref type=""single"">(Popović and Arčan, 2016),</ref>', 'which', 'is', 'a', 'manually', 'annotated', 'error', 'analysis', 'of', 'MT', 'output.', 'Each', 'example', 'in', 'the', 'dataset', 'consists', 'of', 'a', 'source', 'sentence,', 'one', 'MT', 'output,', 'and', 'two', 'correct', 'translations,', 'along', 'with', 'two', 'error', 'annotations.', 'These', 'annotations', 'are', 'word-level', 'annotations', 'into', '8', 'broadly', 'non-linguistic', 'classes,', 'such', 'as', 'German', 'Source:', 'Frauen,', 'die', 'in', 'Burkina', 'Faso', 'zu', 'Hexen', 'abgestempelt', 'werden,', 'weisen', 'in', 'der', 'Regel', 'einige', 'gemeinsame', 'gesellschaftliche', 'Merkmale', 'auf.', 'Original', 'Translation', '(Annotated):', 'Women', 'in', 'Burkina', 'Faso', '[miss]', 'are', 'branded', 'as', 'witches,', 'usually', '[miss]', 'some', 'common', 'social', 'features.', 'Post-edit:', 'Women', 'in', 'Burkina', 'Faso', 'who', 'are', 'branded', 'as', 'witches', 'usually', 'have', 'some', 'common', 'social', 'features.', 'Original', 'Reference:', 'Women', 'declared', 'as', 'witches', 'in', 'Burkina', 'Faso', 'usually', 'have', 'several', 'common', 'characteristics.', '""addition"",', '""lexical', 'error"",', 'or', '""untranslated"".', 'See', 'Figure', '2', 'for', 'an', 'example.']",8,"[0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
664e5f37-13bf-479d-9f26-bfe1847af3d6,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,"['unknown', 'Mark my word: A sequence-to-sequence approach to definition modeling', 'Conditional generators of words definitions', 'Definition modeling: Learning to define word embeddings in natural language']","['unknown', '2019', '2018', '2017']","['unknown', 'Timothee Mickus;Denis Paperno;Matthieu unk', 'Artyom Gadetsky;Ilya Yakubovskiy;Dmitry Vetrov', 'Thanapon Noraset;Chen Liang;Larry Birnbaum;Doug Downey']",group,"['Simple', 'definition', 'in', 'OALD', 'a', 'notice', 'or', 'announcement', 'in', 'a', 'public', 'medium', 'promoting', 'a', 'product,', 'service,', 'or', 'event', 'or', 'publicizing', 'a', 'job', 'vacancy.', 'current', 'context', 'because', 'of', 'the', 'cognitively', 'inaccurate', 'nature', 'of', 'discrete', 'sense', 'boundaries', '<ref type=""group"">(Rosch and Mervis, 1975, Kilgarriff, 1997, Tyler and Evans, 2001).</ref>', 'Secondly,', 'the', 'predefined', 'inventories', 'need', 'to', 'be', 'updated', 'manually', 'by', 'lexicographers,', 'which', 'is', 'time-consuming', 'and', 'causes', 'dictionaries', 'to', 'lag', 'behind', 'the', 'ever-changing', 'language', 'usage.', 'Different', 'from', 'previous', 'work', '<ref type=""group"">(Noraset et al., 2017, Gadetsky et al., 2018, Mickus et al., 2019, Kong et al., 2020)</ref>', 'that', 'focused', 'only', 'on', 'how', 'to', 'generate', 'definitions,', 'we', 'further', 'propose', 'a', 'novel', 'task', 'of', 'Simple', 'Definition', 'Generation', '(SDG).', 'Making', 'the', 'definitions', 'easier', 'to', 'read', 'and', 'understand', 'could', 'benefit', 'the', 'language', 'learners,', 'low', 'literacy', 'readers,', 'as', 'well', 'as', 'helping', 'people', 'with', 'aphasia', 'or', 'dyslexia.', 'For', 'example,', 'compared', 'with', 'the', 'Oxford', 'Dictionary', '(OD),', 'the', 'Oxford', 'Advanced', ""Learner's"", 'Dictionary', '(OALD)', 'has', 'simpler', 'definitions,', 'which', 'are', 'specifically', 'designed', 'for', 'language', 'learners.', 'As', 'shown', 'in', 'Figure', '1,', 'the', 'definition', 'of', 'the', 'word', 'advertisement', 'in', 'OALD', 'does', 'not', 'contain', 'difficult', 'words', 'or', 'phrases', 'such', 'as', 'announcement', 'and', 'public', 'medium.']",64,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
66717a40-fad3-45f1-946c-b0f38aec2e71,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Transformers: State-of-the-art natural language processing'],['2020'],['Thomas Wolf;Lysandre Debut;Victor Sanh;Julien Chaumond;Clement Delangue;Anthony Moi;Pierric Cistac;Tim Rault;Rmi Louf;Morgan Funtowicz;Joe Davison;Sam Shleifer;Clara Patrick Von Platen;Yacine Ma;Julien Jernite;Canwen Plu;Teven Xu;Sylvain Scao;Mariama Gugger;Quentin Drame;Alexander Lhoest;unk Rush'],single,"['We', 'use', 'diverse', 'beam', 'search', '<ref type=""single"">(Vijayakumar et al., 2018)</ref>', 'to', 'generate', '16', 'candidates', 'for', 'each', 'data', 'sample.', 'On', 'CNNDM', 'and', 'XSum,', 'we', 'use', 'the', 'pre-trained', 'BART', '12', 'and', 'PEGASUS', '13', 'models', 'from', 'the', 'Transformers', '<ref type=""single"">(Wolf et al., 2020)</ref>', 'library', 'as', 'the', 'base', 'abstractive', 'models', 'for', 'candidate', 'summary', 'generation', 'and', 'model', 'finetuning', 'respectively.', 'On', 'NYT,', 'we', 'first', 'fine-tuned', 'a', 'BART', 'model', '14', 'with', 'MLE', 'training', 'as', 'the', 'base', 'abstractive', 'model,', 'since', 'our', 'data', 'pre-processing', 'is', 'sightly', 'different', 'from', 'the', 'previous', 'work', 'and', 'there', 'are', 'no', 'available', 'pre-trained', 'checkpoints.', 'We', 'where', 'warmup', 'denotes', 'the', 'warmup', 'steps,', 'which', 'is', 'set', 'to', '10000,', 'step', 'is', 'the', 'number', 'of', 'updating', 'steps,', 'lr', 'is', 'the', 'learning', 'rate.', 'We', 'set', 'the', 'length', 'penalty', 'factor', 'α', 'in', 'the', 'scoring', 'function', '(Eq.', '9)', 'to', 'the', 'same', 'value', 'as', 'used', 'in', 'the', 'original', 'beam', 'search.', 'We', 'search', 'the', 'value', 'of', 'the', 'margin', 'λ', 'in', 'the', 'contrastive', 'loss', '(Eq.', '8)', 'within', 'the', 'range', '[1', '×', '10', '−5,', '1],', 'and', 'decide', 'the', 'value', 'based', 'on', 'the', 'model', 'performance', 'on', 'the', 'validation', 'set.', 'We', 'also', 'performed', 'extensive', 'search', 'for', 'the', 'coefficient', 'γ', 'in', 'Eq.', '10.', 'The', 'specific', 'hyper-parameter', 'setting', 'is', 'reported', 'in', 'Tab.', '13.']",31,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
66bdf49d-3fb6-44de-8954-6458490f9a02,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Playing codenames with language graphs and word embeddings'],['2021'],['Divya Koyyalagunta;Anna Sun;Rachel Draelos;Cynthia Rudin'],single,"['Following', '<ref type=""single"">Koyyalagunta et al. (2021),</ref>', 'we', 'use', 'λ', '=', '0.5', 'for', 'Koyyalagunta', 'and', 'KoyyRestrict', 'scoring', 'functions,', 'but', 'also', 'for', 'the', 'Harmonic', 'function.', 'We', 'pair', 'all', 'relatedness', 'measures', 'to', 'all', 'scoring', 'functions,', 'creating', '16', 'agents', 'in', 'total,', 'and', 'generate', 'clues', 'for', 'n', '=', '2', 'and', '3', 'targeted', 'blue', 'words', 'using', 'all', 'of', 'them.', 'Differently', 'from', '<ref type=""single"">Koyyalagunta et al. (2021),</ref>', 'we', 'consider', 'all', 'of', 'our', 'vocabulary', 'words', 'as', 'possible', 'clue', 'words.', 'For', 'each', 'possible', 'clue', 'word,', 'the', 'best', 'target', 'words', 'in', 'the', 'set', 'I', 'n', 'are', 'the', 'n', 'closest', 'words', 'to', 'the', 'clue', 'word,', 'so', 'scoring', 'a', 'possible', 'clue', 'is', 'computationally', 'inexpensive.']",1,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
66d4c5ca-46ac-4336-8c79-6242617388e2,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Mixture models for diverse machine translation: Tricks of the trade'],['2019'],"[""Tianxiao Shen;Myle Ott;Michael Auli;Marc'aurelio Ranzato""]",single,"['Producing', 'K', 'outputs', 'during', 'inference.', 'In', 'order', 'to', 'generate', 'K', 'different', 'outputs', 'on', 'test', 'set,', 'we', 'follow', '<ref type=""single"">Shen et al. (2019)</ref>', 'to', 'enumerate', 'all', 'latent', 'variables', 'z', 'and', 'then', 'greedily', 'decoding', 'each', 'token', 'by', 'ŷt', '=', 'arg', 'max', 'p(y|ŷ', '1:t−1,', 'z,', 'x).', 'In', 'other', 'words,', 'we', 'ask', 'each', 'expert', 'to', 'seek', 'different', 'sets', 'of', 'concepts', 'on', 'the', 'knowledge', 'graph,', 'and', 'use', 'the', 'selected', 'concepts', 'to', 'generate', 'K', 'different', 'outputs.', 'Notably,', 'this', 'decoding', 'procedure', 'is', 'efficient', 'and', 'easily', 'parallelizable.', 'Furthermore,', 'to', 'make', 'fair', 'comparisons', 'with', 'sampling-based', 'methods,', 'we', 'use', 'greedy', 'decoding', 'without', 'any', 'sampling', 'strategy.']",17,"[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
66f52dad-c5ae-4cb9-bbd5-615aee03fc09,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,"['Multilingual Sentiment and Subjectivity Analysis. Multilingual natural language processing', 'unknown']","['2011', '2020']","['Carmen Banea;Rada Mihalcea;Janyce Wiebe', 'Dorottya Demszky;Dana Movshovitz-Attias;Jeongwoo Ko;Alan Cowen;Gaurav Nemade;Sujith Ravi']",group,"['The', 'number', 'of', 'unique', 'label', 'combinations', 'is', '147,', 'including', 'single-label.', 'The', 'most', 'common', 'label', 'combinations', 'beyond', 'single-label', 'are', 'anger', 'with', 'disgust', '(2.4%)', 'and', 'joy', 'with', 'trust', '(2.1%)', 'followed', 'by', 'different', 'combinations', 'of', 'the', 'positive', 'emotions', 'of', 'anticipation,', 'joy,', 'and', 'trust.', 'These', 'findings', 'are', 'in', 'line', 'with', 'previous', 'findings', 'discussing', 'overlapping', 'categories', '<ref type=""group"">(Banea et al., 2011, Demszky et al., 2020).</ref>', 'However,', 'these', 'are', 'followed', 'by', 'anger', 'combined', 'with', 'anticipation', 'and', 'sadness', 'with', 'surprise.', 'The', 'first', 'combination', 'is', 'possibly', 'a', 'reflection', 'of', 'the', 'genre,', 'as', 'a', 'common', 'theme', 'for', 'anger', 'with', 'anticipation', 'is', 'threats.', 'The', 'combination', 'of', 'surprise', 'with', 'negative', 'emotions', '(anger,', 'disgust,', 'fear,', 'sadness)', 'is', 'much', 'more', 'common', 'than', 'a', 'combination', 'with', 'positive', 'emotions.']",51,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6710cdc7-c0f2-4947-a93e-07f4fffb8a77,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['(2020)', 'that', 'focus', 'on', 'creating', 'content', 'especially', 'for', '2D', 'visual', 'games', 'via', 'search', 'or', 'reinforcement', 'learning', 'based', 'methods.', '<ref type=""single"">Ammanabrolu et al. (2020b,a)</ref>', 'use', 'knowledge', 'graphs', 'to', 'ground', 'language', 'and', 'produce', 'worlds', 'and', 'quests', 'separately', 'for', 'text', 'games', 'from', 'existing', 'corpora', 'such', 'as', 'stories.', '<ref type=""single"">Fan et al. (2019)</ref>', 'leverage', 'LIGHT', 'to', 'learn', 'to', 'generate', 'interactive', 'fiction', 'worlds', 'on', 'the', 'basis', 'of', 'locations,', 'characters,', 'and', 'objects-this', 'work', 'is', 'closest', 'in', 'spirit', 'to', 'our', 'own', 'World', 'Generation', 'module', 'later', 'on.', 'They', 'all', 'focus', 'on', 'either', 'generating', 'or', 'playing', 'games.']",40,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
6758893f-9e3c-4740-8ed7-71eefd4502e6,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,"['Kg-bart: Knowledge graph-augmented bart for generative commonsense reasoning', 'Abductive commonsense reasoning', 'A knowledge-enhanced pretraining model for commonsense story generation']","['2021', '2020', '2020']","['Ye Liu;Yao Wan;Lifang He;Hao Peng;Philip S Yu', 'Chandra Bhagavatula;Chaitanya Ronan Le Bras;Keisuke Malaviya;Ari Sakaguchi;Hannah Holtzman;Doug Rashkin;Scott Downey;Yih Wen-Tau;Yejin Choi', 'Jian Guan;Fei Huang;Zhihao Zhao;Xiaoyan Zhu;Minlie Huang']",group,"['Incorporating', 'external', 'knowledge', 'is', 'essential', 'for', 'many', 'NLG', 'tasks', 'to', 'augment', 'the', 'limited', 'textual', 'information', '<ref type=""group"">(Yu et al., 2022c, Dong et al., 2021, Yu et al., 2022b).</ref>', 'Some', 'recent', 'work', 'explored', 'using', 'graph', 'neural', 'networks', '(GNN)', 'to', 'reason', 'over', 'multihop', 'relational', 'knowledge', 'graph', '(KG)', 'paths', '<ref type=""group"">(Zhou et al., 2018, Jiang et al., 2019, Zhang et al., 2020a, Wu et al., 2020, Yu et al., 2022a, Zeng et al., 2021).</ref>', 'For', 'example,', '<ref type=""single"">Zhou et al. (2018)</ref>', 'enriched', 'the', 'context', 'representations', 'of', 'the', 'input', 'sequence', 'with', 'neighbouring', 'concepts', 'on', 'ConceptNet', 'using', 'graph', 'attention.', '<ref type=""single"">Ji et al. (2020)</ref>', 'performed', 'dynamic', 'multi-hop', 'reasoning', 'on', 'multi-relational', 'paths', 'extracted', 'from', 'the', 'external', 'commonsense', 'KG.', 'Recently,', 'some', 'work', 'attempted', 'to', 'integrate', 'external', 'commonsense', 'knowledge', 'into', 'generative', 'pretrained', 'language', 'models', '<ref type=""group"">(Guan et al., 2020, Bhagavatula et al., 2020, Liu et al., 2021).</ref>', 'For', 'example,', '<ref type=""single"">Guan et al. (2020)</ref>', 'conducted', 'post-training', 'on', 'sythetic', 'data', 'constructed', 'from', 'commonsense', 'KG', 'by', 'translating', 'triplets', 'into', 'natural', 'language', 'texts', 'using', 'templates.', '<ref type=""single"">Yu et al. (2022c)</ref>', 'wrote', 'a', 'comprehensive', 'survey', 'for', 'more', 'detailed', 'comparisons', 'of', 'different', 'knowledge', 'graph', 'enhanced', 'NLG', 'methods.']",82,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
67dd4d77-e980-4cb7-a675-507581b64431,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['unknown'],['unknown'],['unknown'],single,"['We', 'design', 'a', 'memory', 'component', 'to', 'identify', 'the', 'salient', 'words', 'of', 'system', 'utterances', 'in', 'terms', 'of', 'modeling', 'state', 'transitions', '(Sec.', '3.2).', 'To', 'further', 'boost', 'the', ""memory's"", 'capability', 'in', 'learning', 'compact', 'natural', 'language', 'actions,', 'we', 'propose', 'a', 'novel', 'auxiliary', 'task', 'to', 'identify', 'salient', 'words', 'of', 'dialogue', 'context', 'in', 'a', 'supervised', 'setting', '<ref type=""single"">(Sec. 3.3).</ref>', 'Furthermore,we', 'propose', 'to', 'take', 'more', 'advantage', 'from', 'the', 'action', 'learning', 'phase', 'by', 'reusing', 'the', 'memory', 'component', 'for', 'conditioned', 'response', 'generation', '(Sec.', '3.4).']",50,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
68f04c7e-9e20-4e7c-9540-71c2ecfbf957,ROI Analysis model for Language Service Providers,2013,Ekaterina Stambolieva,['Business Strategies for Building Strategic Advantage and Revenue from Machine Translation'],['2013'],['Dion Wiggins'],single,"['Wiggins', '(2013)', 'gives', 'yet', 'another', 'perspective', 'of', 'investment', 'and', 'MT', 'implementation', 'in', 'Asia', 'Online', '3', 'business', 'environment.', 'Some', 'of', 'the', 'advantages', 'of', 'providing', 'MT-incorporated', 'solutions', '<ref type=""single"">Wiggins (2013)</ref>', 'list', 'are', 'reduced', 'translation', 'costs,', 'faster', 'delivery', 'time,', 'expansion', 'of', 'existing', 'relationships', 'with', 'clients,', 'broadening', 'offered', 'functionality', 'and', 'opening', 'new', 'market', 'possibilities.']",25,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
69213775-25ed-428d-939e-65cd1289c58d,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Latent cross: Making use of context in recurrent recommender systems'],['2018'],['Alex Beutel;Paul Covington;Sagar Jain;Can Xu;Jia Li;Vince Gatto;Ed Chi'],single,"['In', 'order', 'to', 'see', 'the', 'effectiveness', 'of', 'the', 'representation', 'learning', 'method,', 'the', 'next', 'two', 'baselines', 'incorporate', 'logical', 'mechanisms', 'in', 'different', 'ways.', 'BERT+LX', 'uses', 'latent', 'cross', '<ref type=""single"">(Beutel et al., 2018)</ref>', 'to', 'directly', 'incorporate', 'predicate', 'values', 'in', 'R1-R13', 'as', 'features,', 'we', 'use', 'an', 'MLP', 'to', 'encode', 'the', 'predicate', 'values,', 'exploring', '(i)', 'one', 'hidden', 'layer', 'with', 'D=768', 'and', '(ii)', 'no', 'hidden', 'layers.', 'BERT+LX', 'consistently', 'outperforms', 'a', 'simple', 'MLP', 'without', 'latent', 'cross.', 'BERT+MT', 'uses', 'multitask', 'learning', 'to', 'train', 'the', 'main', 'and', 'logic', 'tasks', 'simultaneously.']",25,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
695be529-8d0b-4f0f-993e-c684f25f15de,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,['EAGLES Recommendations on Semantic Encoding'],['1999'],['A Sanfilippo'],single,"['In', 'the', 'specification', 'phase', 'we', 'have', 'taken', 'into', 'account', 'requirements', 'of', 'NLP', 'applications', 'and', 'tasks', '(parsing,', 'generation,', 'machine', 'translation,', 'word', 'sense', 'disambiguation,', 'cross-language', 'information', 'retrieval,', 'etc.)', '-also', 'as', 'stated', 'in', 'the', 'EAGLES', 'report', 'of', 'the', 'Lexicon/Semantics', 'Working', 'Group', '<ref type=""single"">(Sanfilippo et al. 1999)</ref>', '-for', 'the', 'decisions', 'on', 'the', 'basic', 'semantic', 'notions', 'and', 'the', 'more', 'specific', 'types', 'of', 'semantic', 'information', 'to', 'be', 'encoded.', 'This', 'is', 'of', 'utmost', 'importance', 'given', 'the', 'applicative', 'objectives', 'of', 'the', 'PAROLE/SIMPLE', 'lexicons.', 'A', 'dichotomy', 'at', 'stake', 'here', 'is', 'the', 'one', 'between', 'generality', 'of', 'a', 'LR', 'vs.', 'usefulness', 'for', 'applications.', 'In', 'principle,', 'only', 'when', 'we', 'know', 'the', 'actual', 'specific', 'use', 'we', 'intend', 'to', 'do', 'of', 'a', 'LR', 'can', 'we', 'build', 'the', ""'very"", ""best'"", 'LR', 'for', 'that', 'use,', 'but', 'this', 'has', 'proved', 'to', 'be', 'too', 'expensive', 'and', 'not', 'realistic.', 'In', 'practice,', 'however,', 'there', 'exists', 'a', 'large', 'core', 'of', 'information', 'that', 'can', 'be', 'shared', 'by', 'many', 'applicative', 'uses,', 'and', 'this', 'leads', 'to', 'the', 'concept', 'of', '""generic""', 'LR,', 'which', 'is', 'at', 'the', 'basis', 'of', 'the', 'EAGLES', 'initiative', 'and', 'of', 'the', 'PAROLE/SIMPLE', 'projects.', 'This', 'generic', 'shareable', 'core', 'of', 'information', 'must', 'then', 'be', 'enhanced', 'and', 'tuned', 'with', 'other', 'means', '(see', 'sections', '3', 'and', '4).']",38,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
695ffeab-369c-457d-befe-ec349a3a461d,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Why do people lie online? because everyone lies on the internet'],['2016'],['Michelle Drouin;Daniel Miller;M Shaun;Elisa Wehle;unk Hernandez'],single,"['While', 'researchers', 'have', 'started', 'incorporating', 'user', 'and', 'community', 'information', 'into', 'detection', 'of', 'abusive', 'language,', 'there', 'has', 'been', 'no', 'discussion', 'of', 'the', 'ethical', 'guidelines', 'for', 'doing', 'so.', 'Therefore,', 'taking', 'a', 'stand', 'on', 'the', 'issue,', 'we', 'lay', 'out', 'five', 'ethical', 'considerations', 'in', 'the', 'design', 'and', 'implementation', 'of', 'methods', 'that', 'incorporate', 'user', 'or', 'community', 'information:', 'Personal', 'vs.', 'population-level', 'trends.', 'It', 'is', 'important', 'to', 'perform', 'appropriate', 'generalizations', 'from', 'personal', 'traits', 'to', 'population-level', 'behavioral', 'trends.', 'Methods', 'should', 'avoid', 'relying', 'on', 'simple', 'inductive', 'biases', 'such', 'as', 'personal', 'traits', 'of', 'users,', 'e.g.,', 'gender,', 'race,', 'etc.,', 'as', 'this', 'can', 'easily', 'lead', 'to', 'scenarios', 'of', 'faulty', 'generalizations', 'where', 'comments', 'from', 'a', 'particular', 'gender', 'or', 'race', 'are', 'always', 'labeled', 'abusive/benign.', 'Moreover,', 'relying', 'solely', 'on', 'personal', 'traits', 'of', 'users', 'also', 'comes', 'with', 'the', 'risk', 'that', 'such', 'information', 'may', 'not', 'always', 'be', 'present', 'or', 'may', 'not', 'be', 'accurate', 'even', 'when', 'present', '<ref type=""single"">(Drouin et al., 2016).</ref>', 'On', 'the', 'other', 'hand,', 'more', 'complex', 'inductive', 'biases', 'learned', 'from', 'data,', 'as', 'in', 'the', 'case', 'of', 'social', 'graph', 'based', 'methods,', 'provide', 'a', 'safer', 'and', 'more', 'reliable', 'generalization', 'from', 'personal', 'behaviors', 'of', 'users', 'or', 'communities', 'to', 'population', 'level', 'trends.', 'Bias', 'in', 'datasets.', 'An', 'obvious', 'pitfall', 'in', 'working', 'with', 'methods', 'that', 'incorporate', 'user', 'and', 'community', 'information', 'is', 'having', 'datasets', 'where', 'comments', 'come', 'from', 'users', 'belonging', 'to', 'some', 'limited', 'demographics', 'only.', 'We', 'refer', 'to', 'this', 'as', 'demographic', 'bias.', 'Datasets', 'with', 'demographic', 'bias', 'will', 'cause', 'the', 'methods', 'to', 'overfit', 'to', 'linguistic', 'practices', 'and', 'dialects', 'of', 'users', 'and', 'communities', 'belonging', 'to', 'specific', 'demographics', '<ref type=""single"">(Sap et al., 2020),</ref>', 'hence', 'diminishing', 'the', 'power', 'of', 'the', 'methods', 'to', 'generalize.', 'In', 'fact,', 'this', 'bias', 'is', 'not', 'only', 'a', 'problem', 'for', 'methods', 'we', 'discussed,', 'but', 'for', 'any', 'NLP', 'method', 'in', 'general.', 'When', 'it', 'comes', 'to', 'methods', 'that', 'incorporate', 'user', 'or', 'community', 'information', 'specifically,', 'there', 'are', 'two', 'other', 'biases', 'that', 'must', 'be', 'kept', 'in', 'mind', 'when', 'constructing', 'datasets,', 'we', 'refer', 'to', 'them', 'as', 'comment', 'distribution', 'bias', 'and', 'label', 'distribution', 'bias.', 'Comment', 'distribution', 'bias', 'occurs', 'when', 'the', 'majority', 'of', 'comments', 'in', 'the', 'dataset', 'come', 'from', 'a', 'small', 'number', 'of', 'unique', 'users.', 'Such', 'datasets', 'allow', 'the', 'methods', 'to', 'simply', 'overfit', 'to', 'the', 'linguistic', 'or', 'social', 'behaviors', 'and', 'community', 'roles', 'of', 'specific', 'users', '<ref type=""single"">(Wiegand et al., 2019).</ref>', 'Label', 'distribution', 'bias', 'occurs', 'when', 'only', 'the', 'abusive', 'comments', 'of', 'a', 'user', 'are', 'included', 'in', 'the', 'dataset.', 'Abuse', 'is', 'a', 'relatively', 'infrequent', 'phenomenon,', 'even', 'at', 'an', 'individual', 'level', '<ref type=""group"">(Waseem and Hovy, 2016, Wulczyn et al., 2017).</ref>', 'Only', 'getting', 'abusive', 'comments', 'of', 'a', 'user', 'can', 'make', 'the', 'methods', 'simply', 'associate', 'the', 'identity', 'of', 'the', 'user', 'to', 'abusiveness', 'when', 'including', 'user', 'information.', 'Moreover,', 'datasets', 'with', 'this', 'bias', 'can', 'also', 'make', 'phenomena', 'like', 'homophily', 'appear', 'overly', 'effective', 'in', 'the', 'detection', 'of', 'abuse', 'by', 'sampling', 'only', 'abusive', 'comments', 'from', 'users', 'who', 'are', 'close', 'in', 'the', 'social', 'network.']",139,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6972d175-c33c-4bc3-84c5-ccd79ab9021d,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['We', 'perform', 'evaluations', 'with', 'fine-tuned', 'cased', 'multilingual', 'and', 'language', 'specific', 'BERT', '(Bidirectional', 'Encoder', 'Representations', 'from', 'Transformers)', 'models', '<ref type=""single"">(Devlin et al., 2019),</ref>', 'as', 'well', 'as', 'Suport', 'Vector', 'Machines', '(SVMs).', 'Our', 'evaluations', 'show', 'that', 'the', 'human-annotated', 'datasets', 'behave', 'on', 'par', 'with', 'comparable', 'state-of-the-art', 'datasets', 'such', 'as', 'the', 'GoEmotions', 'dataset', '<ref type=""single"">(Demszky et al., 2020).</ref>', 'Furthermore,', 'the', 'projected', 'datasets', 'have', 'accuracies', 'that', 'closely', 'resemble', 'human-annotated', 'data', 'with', 'macro', 'f1', 'scores', 'of', '0.51', 'for', 'the', 'human', 'annotated', 'Finnish', 'data', 'and', '0.45', 'for', 'the', 'projected', 'Finnish', 'data', 'when', 'evaluating', 'with', 'FinBERT', '<ref type=""single"">(Virtanen et al., 2019).</ref>']",17,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
69c72499-c385-4d1f-8852-b6c859a337c7,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Pointer sentinel mixture models'],['2016'],['Stephen Merity;Caiming Xiong;James Bradbury;Richard Socher'],single,"['Figure', '2:', 'Amount', 'of', 'data', 'in', 'GB', '(log-scale)', 'for', 'the', '88', 'languages', 'that', 'appear', 'in', 'both', 'the', 'Wiki-100', '<ref type=""single"">(Merity et al., 2016)</ref>', 'corpus', 'used', 'for', 'mBERT', 'and', 'XLM-100', '<ref type=""single"">(Conneau et al., 2020).</ref>', 'None', 'of', 'the', 'Indian', 'languages', 'feature', 'among', 'top-25', 'languages', 'with', 'the', 'largest', 'amount', 'of', 'data.']",18,"[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
6a188eff-39ab-46f0-a10a-816fdab4ed62,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,"['So much to read, so little time: How do we read, and can speed reading help?']",['2016'],['Keith Rayner;Elizabeth Schotter;E Michael;Mary Masson;Rebecca Potter;unk Treiman'],single,"['In', 'a', 'Rapid', 'Serial', 'Visual', 'Presentation', '(RSVP)', 'paradigm,', 'sentences', 'were', 'presented', 'one', 'word', 'at', 'a', 'time,', 'on', 'average', 'every', '≈', '240', 'ms,', 'in', 'a', 'white', 'monospace', 'font', 'on', 'a', 'grey', 'background', 'approximately', 'in', 'the', 'centre', 'of', 'the', 'screen,', 'at', 'the', 'optimal', 'viewing', 'position', '<ref type=""single"">(Rayner et al., 2016).</ref>', 'Each', 'word', 'subtended', 'a', 'horizontal', 'angle', '0.76', 'to', 'the', 'left', 'and', '11.81', 'to', 'the', 'right', 'from', 'the', 'centre.', 'Sentences', 'were', 'separated', 'by', '500', 'ms', 'of', 'a', 'white', 'central', 'fixation', 'cross', '(see', 'Figure', '1).', 'On', 'approximately', '20%', 'of', 'the', 'sentences', 'in', 'each', 'session,', 'the', 'participant', 'was', 'prompted', 'to', 'verbalise', 'the', 'previous', 'sentence', 'back', 'to', 'the', 'experimenter.', 'An', 'accuracy', 'score', 'of', '93%', 'across', 'all', 'sessions', 'confirmed', 'that', 'the', 'participant', 'successfully', 'attended', 'the', 'sentences.', 'Stimuli', 'were', 'presented', 'using', 'PsychoPy', '<ref type=""single"">(Peirce et al., 2019)</ref>', 'on', 'an', 'LCD', 'monitor', 'with', 'a', 'resolution', 'of', '1920x1080', 'pixels', 'and', '60', 'Hz', 'refresh', 'rate.', 'The', ""subject's"", 'head', 'was', 'stabilised', 'with', 'a', 'chin-rest.', 'Gilching,', 'Germany).', 'Channel', 'impedances', 'were', 'kept', 'below', '15', 'kΩ.', 'Data', 'were', 'preprocessed', 'using', 'MNE-Python', '<ref type=""single"">(Gramfort et al., 2013).</ref>', 'Individual', 'EEG', 'sessions', 'were', 'band-pass', 'filtered', 'between', '1-40', 'Hz,', 'downsampled', 'to', '250', 'Hz', 'and', 're-referenced', 'to', 'average', 'reference.', 'Noisy', 'channels', 'were', 'determined', 'based', 'on', 'visual', 'inspection', 'and', 'interpolated.', 'Non-neuronal', 'components', '(e.g.', 'ocular,', 'muscular,', 'electrical)', 'were', 'removed', 'via', 'Independent', 'Component', 'Analysis', '(ICA)', 'individually', 'for', 'each', 'recording', 'session', '(an', 'average', 'of', '4', 'components', 'were', 'removed', 'per', 'EEG', 'session).']",43,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6aab6bfa-e5e2-4db5-b17c-bbfba90fc609,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,['Continuous space language models for the IWSLT 2006 task'],['2006'],['H Schwenk;M Costa-Jussà;J Fonollosa'],single,"['The', 'perplexities', 'on', 'the', 'development', 'data', 'are', 'summarized', 'in', 'Table', '2.', 'It', 'is', 'not', 'surprising', 'to', 'see', 'that', 'adding', 'the', 'development', 'data', 'of', 'previous', 'evaluations', 'improves', 'the', 'perplexity', 'since', 'this', 'more', 'than', 'doubles', 'the', 'amount', 'of', 'in-domain', 'data.', 'The', 'small', 'Gale', 'as', 'well', 'as', 'the', 'large', 'Gigaword', 'corpus', 'have', 'also', 'a', 'noticeable', 'effect.', '1', 'The', 'continuous', 'space', 'language', 'model', 'was', 'trained', 'on', 'all', 'the', 'available', 'data,', 'including', 'the', 'large', 'Gigaword', 'corpus,', 'using', 'a', 'resampling', 'algorithm', '<ref type=""single"">[11].</ref>', 'This', 'approach', 'achieved', 'a', 'reduction', 'in', 'perplexity', 'of', 'more', 'than', '15%', 'in', 'comparison', 'to', 'the', 'large', 'back-off', 'language', 'model.', 'This', 'is', 'inline', 'with', 'results', 'obtained', 'in', 'previous', 'IWSLT', 'evaluations', '<ref type=""single"">[9],</ref>', 'but', 'here', 'both', 'language', 'models', 'are', 'trained', 'on', 'substantially', 'more', 'data.']",105,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
6afbd666-b6b3-45fa-82c7-5092ce3f3c74,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Fairwashing: the risk of rationalization'],['2019'],['Ulrich Aïvodji;Hiromi Arai;Olivier Fortineau;Sébastien Gambs;Satoshi Hara;Alain Tapp'],single,"['Interpretability', 'There', 'has', 'been', 'a', 'lot', 'of', 'work', 'on', 'better', 'interpreting', ""models'"", 'decision', 'process,', 'e.g.,', 'understanding', 'BERT', '<ref type=""group"">(Clark et al., 2019b, Kovaleva et al., 2019)</ref>', 'and', 'attention', 'in', 'transformers', '<ref type=""single"">(Hao et al., 2020),</ref>', 'or', 'through', 'text', 'generation', 'models', '<ref type=""single"">(Narang et al., 2020).</ref>', 'In', 'this', 'paper', 'we', 'utilize', 'the', 'attention', 'scores', 'as', 'a', 'generic', 'way', 'to', 'understand', 'what', 'features', 'a', 'model', 'relies', 'on', 'for', 'making', 'its', 'predictions.', 'Other', 'common', 'model', 'interpretation', 'techniques', '<ref type=""group"">(Sundararajan et al., 2017, Ribeiro et al., 2016),</ref>', 'or', 'more', 'recent', 'work', 'on', 'hierarchical', 'attentions', '<ref type=""single"">(Chen et al., 2020)</ref>', 'and', 'contrastive', 'explanations', '<ref type=""single"">(Jacovi et al., 2021),</ref>', 'can', 'be', 'used', 'as', 'well.', 'In', '<ref type=""single"">Pruthi et al. (2020),</ref>', 'the', 'authors', 'found', 'that', 'attention', 'scores', 'can', 'be', 'manipulated', 'to', 'deceive', 'human', 'decision', 'makers.', 'The', 'reliability', 'of', 'existing', 'interpretation', 'methods', 'is', 'a', 'research', 'topic', 'by', 'itself,', 'and', 'extra', 'care', 'needs', 'to', 'be', 'taken', 'when', 'using', 'attention', 'for', 'auditing', 'models', 'on', 'fairness', 'and', 'accountability', '<ref type=""single"">(Aïvodji et al., 2019).</ref>']",121,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
6b9495ec-2822-4736-8dcb-4e5e7af64f8d,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,"['Crisis management by apology: corporate response to allegations of wrongdoing', 'unknown']","['2010', 'unknown']","['Keith Michael;Hearit unk', 'unknown']",group,"['From', 'the', 'point', 'of', 'view', 'of', 'communication', 'study,', 'most', 'of', 'the', 'research', 'on', 'public', 'apologies', 'is', 'focused', 'on', 'apology', 'as', 'a', 'speech', 'act', '(e.g.', '<ref type=""group"">Edmondson, 1981, Fraser, 1981, Holmes 1990, Blum-Kulka et al.1989, Olshtain and Cohen 1983, Owen, 1983, Trosborg, 1987).</ref>', 'The', 'studies', 'are', 'based', 'on', 'two', 'perspectives.', 'The', 'first', 'is', 'from', 'the', 'point', 'of', 'view', 'of', 'the', 'offended', 'party', '<ref type=""single"">(Lee &amp, Chung, 2012)</ref>', 'and', 'the', 'second', 'sees', 'apology', 'from', 'the', 'point', 'of', 'view', 'of', 'the', 'offender', '<ref type=""group"">(Darby &amp, Schlenker, 1989, Goffman, 1971, Hearit, 1994 Hearit, , 1996 Hearit, , 1997 Hearit, , 2010,, Schlenker &amp, Darby, 1981).</ref>']",58,"[0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
6b94f8b7-856a-41ad-87b2-6bf427cf386d,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,['Pooled contextualized embeddings for named entity recognition'],['2019'],['Alan Akbik;Tanja Bergmann;Roland Vollgraf'],single,"['Unsupervised', 'systems', 'Majority', 'of', 'the', 'unsupervised', 'WSD', 'systems', 'use', 'external', 'knowledge', 'bases', 'like', 'WordNet', '<ref type=""single"">(Miller, 1995)</ref>', 'and', 'BabelNet', '<ref type=""single"">(Navigli and Ponzetto, 2012).</ref>', 'For', 'each', 'input', 'word,', 'its', 'correct', 'meaning', 'according', 'to', 'the', 'context', 'can', 'be', 'found', 'using', 'graph-based', 'techniques', 'from', 'those', 'external', 'knowledge', 'bases.', 'However,', 'these', 'approaches', 'are', 'only', 'limited', 'to', 'the', 'languages', 'supported', 'by', 'used', 'knowledge', 'bases.', 'More', 'recent', 'works', 'like', 'Hettiarachchi', 'and', 'Ranasinghe', '(2020a),', '<ref type=""single"">Ranasinghe et al. (2019a)</ref>', 'propose', 'to', 'use', 'stacked', 'word', 'embeddings', '<ref type=""single"">(Akbik et al., 2018)</ref>', 'obtained', 'by', 'general', 'purpose', 'pretrained', 'contextualised', 'word', 'embedding', 'models', 'such', 'as', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'and', 'Flair', '<ref type=""single"">(Akbik et al., 2019)</ref>', 'for', 'unsupervised', 'WSD.', 'Despite', 'their', 'ability', 'to', 'scale', 'over', 'different', 'languages,', 'unsupervised', 'approaches', 'fall', 'behind', 'supervised', 'systems', 'in', 'terms', 'of', 'accuracy.']",85,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6ba94104-a2d4-406c-b74c-256440e5d75d,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Deep-Type: Multilingual Entity Linking by Neural Type System Evolution'],['2018'],['Jonathan Raiman;Olivier Raiman'],single,"['In', 'entity', 'linking', 'specifically,', 'typing', 'has', 'been', 'explored', 'for', 'cross-domain', 'entity', 'linking', '<ref type=""group"">(Gupta et al., 2017, Onoe and Durrett, 2020).</ref>', 'Past', 'work', 'by', '<ref type=""single"">Raiman and Raiman (2018)</ref>', 'has', 'also', 'explored', 'learning', 'a', 'type', 'system', 'for', 'this', 'task.', 'Our', 'approach', 'to', 'learning', 'types', 'starts', 'from', 'a', 'large', 'set', 'and', 'filters', 'it', 'down,', 'which', 'is', 'a', 'simpler', 'problem.', 'A', 'range', 'of', 'approaches', 'have', 'also', 'considered', 'augmenting', 'pretrained', 'models', 'with', 'type', 'information', '<ref type=""single"">(Peters et al., 2019),</ref>', 'however,', 'in', 'these', 'models,', 'the', 'types', 'inform', 'dense', 'embeddings', 'which', 'are', 'still', 'uninterpretable.']",16,"[1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6beaf7b1-aa9b-4ebc-91b9-95d7e6924f03,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,['SciB-ERT: A pretrained language model for scientific text'],['2019'],['Iz Beltagy;Kyle Lo;Arman Cohan'],single,"['ArXiv', 'open-sources', 'the', 'LaTeX', 'version', 'of', 'their', 'articles,', 'when', 'available.', 'In', 'order', 'to', 'make', 'our', 'Symlink', 'dataset', 'open-access', 'to', 'the', 'whole', 'community,', 'we', 'crawled', 'the', 'metadata', 'of', 'these', 'articles', 'and', 'only', 'selected', 'articles', 'under', 'the', 'CC', 'BY', 'license.', 'Once', 'obtained', 'the', 'LaTeX', 'project,', 'we', 'extracted', 'all', 'the', 'paragraphs', 'from', 'the', '.tex', 'files.', 'We', 'filtered', 'out', 'all', 'short', 'paragraphs', 'with', 'less', 'than', '50', 'words', 'and', 'paragraphs', 'without', 'symbols.', 'Since', 'a', 'formula', 'can', 'be', 'composed', 'in', 'multiple', 'ways', 'such', 'as', 'inline', 'formulae', '(between', '$', '$),', 'displayed', 'formulae', '(between', '$$', '$$),', 'or', 'using', 'commands', 'e.g.', 'array,', 'to', 'keep', 'the', 'original', 'TeX', 'format', 'of', 'the', 'formulae,', 'all', 'of', 'these', 'math', 'objects', 'are', 'masked', 'before', 'tokenization.', 'Then,', 'we', 'used', 'the', 'SciBERT', 'tokenizer', '<ref type=""single"">(Beltagy et al., 2019)</ref>', 'to', 'tokenize', 'the', 'text.', 'The', 'original', 'math', 'object', 'is', 'then', 'restored.', 'As', 'we', 'observed', 'that', 'many', 'papers', 'have', 'nested', 'math', 'objects,', 'we', 'deleted', 'all', 'the', 'nested', 'objects,', 'hence,', 'having', 'non-nested', 'LaTeX', 'data.', 'This', 'is', 'helpful', 'as', 'it', 'makes', 'the', 'LaTeX', 'documents', 'more', 'similar', 'to', 'the', 'ones', 'generated', 'by', 'the', 'PDF-to-LaTeX', 'tools,', 'which', 'do', 'not', 'contain', 'nested', 'objects.']",117,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6c48fc67-68e6-4f23-bb85-80010de4050b,Themes in the work of Margaret Masterman,1988,Yorick Wilks,['NETtalk: a parallel network that learns to read aloud'],['1986'],['T Sejnowski;C Rosenberg'],single,"['It', 'is', 'this', 'very', 'issue', 'that', 'the', 'current', 'wave', 'of', 'theories', 'labelled', ""'connectionist'"", '(e.g.', '<ref type=""single"">Sejnowski and Rosenberg, 1986)</ref>', 'seeks', 'to', 'tackle:', 'how', 'underlying', 'classifiers', 'can', 'emerge', 'spontaneously', 'from', 'data', 'by', 'using', 'no', 'more', 'than', 'association', 'and', 'classification', 'algorithms.', 'MMB', 'would', 'have', 'sympathised', 'with', 'its', 'anti-logicism,', 'but', 'would', 'have', 'found', 'its', 'statistical', 'basis', 'only', 'thin', 'mathematics,', 'and', 'would', 'have', 'not', 'been', 'sympathetic', 'to', 'its', 'anti-symbolic', 'disposition.']",14,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6cb87225-e8a1-4675-88d5-9139231c0097,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Creating an Annotated Corpus for Sentiment Analysis of German Product Reviews'],['2013'],['Katarina Boland;Andias Wira-Alam;Reinhard Messerschmidt'],single,"['A', 'majority', 'of', 'recent', 'papers', 'on', 'multilabel', 'emotion', 'classification', 'focus', 'on', 'the', 'SemEval', '2018', 'dataset', 'which', 'is', 'based', 'on', 'tweets.', 'Similarly,', 'many', 'of', 'the', 'non-multilabel', 'classification', 'papers', 'use', 'Twitter', 'data.', 'Twitter', 'is', 'a', 'good', 'base', 'for', 'emotion', 'classification', 'as', 'tweets', 'are', 'limited', 'in', 'length', 'and', 'generally', 'stand-alone,', 'i.e.', 'the', 'reader', 'or', 'annotator', 'does', 'not', 'need', 'to', 'guess', 'the', 'context', 'in', 'the', 'majority', 'of', 'cases.', 'Furthermore,', 'hashtags', 'and', 'emojis', 'are', 'common,', 'which', 'further', 'makes', 'the', 'emotion', 'recognition', 'easier', 'for', 'both', 'human', 'annotators', 'and', 'emotion', 'detection', 'and', 'sentiment', 'analysis', 'models.', 'Reddit', 'data,', 'as', 'used', 'by', '<ref type=""single"">Demszky et al. (2020),</ref>', 'and', 'movie', 'subtitles', 'used', 'by', 'this', 'paper,', 'are', 'slightly', 'more', 'problematic', 'as', 'they', 'are', 'not', '""selfcontained"".', 'Reddit', 'comments', 'are', 'typically', 'longer', 'than', 'one', 'line', 'and', 'therefore', 'provide', 'some', 'context', 'for', 'annotators', 'to', 'go', 'by,', 'but', 'often', 'lacks', 'the', 'hashtags', 'and', 'emojis', 'of', 'twitter', 'and', 'can', 'be', 'quite', 'context-dependent', 'as', 'Reddit', 'comments', 'are', 'by', 'definition', 'reactions', 'to', 'a', 'post', 'or', 'another', 'comment.', 'Movie', 'subtitles', 'annotated', 'out', 'of', 'sequence', 'have', 'virtually', 'no', 'context', 'to', 'aid', 'the', 'annotator', 'and', 'are', 'supposed', 'to', 'be', 'accompanied', 'by', 'visual', 'cues', 'as', 'well.', 'However,', 'annotating', 'with', 'context', 'can', 'reduce', 'the', 'accuracy', 'of', ""one's"", 'model', 'by', 'doubly', 'weighting', 'surrounding', 'units', 'of', 'granularity', '(roughly', ""'sentences'"", 'in', 'our', 'case)', '<ref type=""single"">(Boland et al., 2013).</ref>', 'On', 'the', 'other', 'hand,', 'contextual', 'annotations', 'are', 'less', 'frustrating', 'for', 'the', 'annotator', 'and', 'therefore,', 'would', 'likely', 'provide', 'more', 'annotations', 'in', 'the', 'same', 'amount', 'of', 'time', '<ref type=""single"">( Öhman, 2020).</ref>']",203,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
6cc5e33e-cf09-4b52-8b2b-8ba6d2e8bd49,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Statistical decision-tree models for parsing'],['1995'],['D Magerman'],single,"['Schabes', 'et', 'al.', '<ref type=""single"">(1993)</ref>', 'and', '<ref type=""single"">Magerman (1995)</ref>', 'report', 'results', 'using', 'the', 'GEIG', 'evaluation', 'scheme', 'which', 'are', 'numerically', 'superior', 'to', 'ours.', 'However,', 'their', 'experiments', 'are', 'not', 'strictly', 'compati', 'ble', 'because', 'they', 'both', 'utilise', 'more', 'homogeneous', 'and', 'probably', 'simpler', 'corpora.', 'In', 'addition,', 'Schabes', 'et', 'al.', 'do', 'not', 'recover', 'tree', 'labelling,,', 'whilst', 'Magerman', 'has', 'developed', 'a', 'parser', 'designed', 'to', 'produce', 'identical', 'analyses', 'to', 'those', 'used', 'in', 'the', 'Penn', ""'Ireebank,"", 'removing', 'the', 'problem', 'of', 'spurious', 'errors', 'due', 'to', 'grammatical', 'incompatibility.', 'Both', 'these', 'approaches', 'achieve', 'better', 'cov', 'erage', 'by', 'constructing', 'the', 'grammar', 'fully', 'automatically.', 'No', 'one', 'has', 'yet', 'shown', 'that', 'any', 'robust', 'parser', 'is', 'practical', 'and', 'useful', 'for', 'some', 'NLP', 'task.', 'However,', 'it', 'seems', 'likely', 'that', 'say', 'rule-to-rule', 'semantic', 'interpretation', 'will', 'be', 'easier', 'with', 'hand-constructed', 'grammars', 'with', 'an', 'explicit,', 'de', 'terminate', 'ruleset.', 'A', 'more', 'meaningful', 'comparison', 'will', 'require', 'application', 'of', 'different', 'parsers', 'to', 'an', 'identical', 'and', 'extended', 'test', 'suite', 'and', 'utllisation', 'of', 'a', 'more', 'stringent', 'standard', 'evaluation', 'procedure', 'sensitive', 'to', 'node', 'labellings.']",5,"[3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6ccf0eb0-1c70-4936-8fea-5d13208aca79,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['A survey on hate speech detection using natural language processing'],['2017'],['Anna Schmidt;Michael Wiegand'],single,"['The', 'term', 'toxic', 'comment', 'is', 'commonly', 'found', 'in', 'literature', 'as', 'harmful', 'speech,', 'hate', 'speech,', 'or', 'offensive', 'language.', 'Toxic', 'comment', 'may', 'be', 'viewed', 'as', 'negative', 'online', 'behaviors,', 'i.e.,', 'comments', 'that', 'are', 'rude,', 'disrespectful,', 'may', 'contain', 'hate', 'speech,', 'or', 'otherwise', 'likely', 'to', 'make', 'someone', 'leave', 'a', 'discussion', '1.', '<ref type=""single"">Schmidt and Wiegand (2017)</ref>', 'define', 'hate', 'speech', 'as', 'any', 'communication', 'that', 'disparages', 'a', 'person', 'or', 'a', 'group', 'based', 'on', 'some', 'characteristic', 'such', 'as', 'race,', 'color,', 'ethnicity,', 'gender,', 'sexual', 'orientation,', 'nationality,', 'religion,', 'or', 'other', 'characteristics.', 'Also,', 'it', 'may', 'occur', 'with', 'different', 'linguistic', 'styles,', 'even', 'in', 'subtle', 'forms', 'or', 'when', 'humour', 'is', 'used', '<ref type=""single"">(Fortuna and Nunes, 2018).</ref>', 'It', 'is', 'important', 'to', 'highlight', 'that', 'fighting', 'these', 'types', 'of', 'comments', 'is', 'of', 'utmost', 'importance', 'since', 'they', 'are', 'a', 'crime', 'in', 'several', 'countries.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
6ce8151f-6aee-4e3a-ba96-a468e7972cd6,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Argumentation schemes'],['2008'],['Douglas Walton;Chris Reed;Fabrizio Macagno'],single,"['Reasoning', 'based', 'on', 'causal', 'relation', 'between', 'events', 'is', 'used', 'in', 'two', 'types', 'of', 'argumentation:', 'argument', 'from', 'cause', 'to', 'effect', 'and', 'argument', 'from', 'effect', 'to', 'cause', '<ref type=""single"">(Walton et al., 2008)</ref>', 'Effect-to-cause', '(E2C)', 'reasoning', 'has', 'the', 'reversed', 'direction,', 'S', 'describes', 'an', 'observation', 'and', 'C', 'is', 'a', 'reasonable', 'explanation', 'that', 'may', 'have', 'caused', 'it.', 'If', 'C', 'causes', '(obstructs)', 'S,', 'then', 'S', 'is', 'likely', 'to', 'support', '(attack)', 'C,', 'as', 'in:', 'The', 'probabilities', 'are', 'computed', 'by', 'a', 'causality', 'module', '(§4.3).Claim:', 'St.', 'Andrew']",25,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6d26a458-cd8f-47ee-9745-7607c1849934,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['Concept annotation in the craft corpus'],['2012'],['Michael Bada;Miriam Eckert;Donald Evans;Kristin Garcia;Krista Shipley;Dmitry Sitnikov;A William;unk Baumgartner;Karin Bretonnel Cohen;Judith Verspoor;unk Blake'],single,"['Task', 'Definition', 'There', 'are', 'two', 'subtasks', 'in', 'the', 'LCP', 'task.', 'For', 'subtask', '1,', 'the', 'goal', 'is', 'to', 'predict', 'the', 'complexity', 'score', 'for', 'a', 'single', 'word', 'from', 'the', 'given', 'context.', 'As', 'an', 'example', 'shown', 'in', 'Figure', '1,', 'the', ""'refuge'"", 'is', 'the', 'word', 'that', 'needs', 'to', 'be', 'predicted', 'and', 'since', 'the', 'meaning', 'of', 'it', 'is', 'harder', 'to', 'get', 'in', 'the', 'first', 'context,', 'its', 'complexity', 'score', 'in', 'the', 'first', 'context', 'is', 'much', 'higher.', 'For', 'subtask', '2,', 'the', 'goal', 'is', 'to', 'predict', 'the', 'complexity', 'score', 'for', 'a', 'multi-word', 'expression', 'from', 'the', 'given', 'context.', 'An', 'example', 'is', 'also', 'shown', 'in', 'the', 'right', 'part', 'of', 'Figure', '1.', 'a', '5-point', 'Likert', 'scale:', 'one', 'for', 'very', 'easy,', 'two', 'for', 'easy,', 'three', 'for', 'neutral,', 'four', 'for', 'difficult,', 'and', 'five', 'for', 'very', 'difficult.', 'The', 'numerical', 'labels', 'were', 'transformed', 'to', 'a', '0-1', 'range', 'as', 'shown', 'in', 'Figure', '1.', 'To', 'add', 'further', 'variation', 'to', 'the', 'data,', 'three', 'corpora', 'were', 'selected', 'including', 'Bible,', 'Europarl', '<ref type=""single"">(Koehn, 2005)</ref>', 'and', 'Biomedical', '<ref type=""single"">(Bada et al., 2012).</ref>', 'Each', 'corpus', 'has', 'its', 'own', 'unique', 'language', 'features', 'and', 'styles.', 'In', 'addition', 'to', 'single', 'words,', 'multi-word', 'expressions', 'were', 'also', 'selected', 'for', 'annotating.', 'In', 'the', 'end,', 'there', 'were', '9476', 'annotated', 'contexts', 'with', '5166', 'unique', 'words.']",154,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6dc92787-8a95-41fa-a2fa-d67d724a8266,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['Bleu: a method for automatic evaluation of machine translation'],['2002'],['Kishore Papineni;Salim Roukos;Todd Ward;Wei-Jing Zhu'],single,"['We', 'use', 'BLEU', '<ref type=""single"">(Papineni et al., 2002)</ref>', '10', 'and', 'Average', 'Lagging', '(AL)', '<ref type=""single"">(Ma et al., 2018)</ref>', '11', 'to', 'evaluate', 'translation', 'quality', 'and', 'latency', 'respectively.', 'AL', 'measures', 'the', 'degree', 'the', 'user', 'is', 'out', 'of', 'sync', 'with', 'the', 'speaker.', 'As', 'shown', 'in', 'Eq.9-10,', 't', 'is', 'decoding', 'step,', 'τ', 'is', 'cut-off', 'decoding', 'step', 'where', 'source', 'sentence', 'is', 'finished,', 'g(t)', 'denotes', 'the', 'number', 'of', 'source', 'words', 'read', 'by', 'the', 'encoder', 'at', 'decoding', 'step', 't,', 'and', 'r', '=', '|x|/|y|', 'is', 'the', 'target-to-source', 'length', 'ratio.', 'The', 'smaller', 'the', 'AL', '(roughly', 'equivalent', 'to', 'k)', 'is,', 'the', 'more', 'real-time', 'the', 'simultaneous', 'translation', 'system', 'is.AL', 'g', '(x,', 'y)', '=', '1', 'τ', 'τ', 't=1', 'g(t)', '−', 't', '−', '1', 'r', '(9)where', 'τ', 'g', '(|x|)', '=', 'min{t|g(t)', '=', '|x|}', '(10)']",3,"[2, 2, 1, 1, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6e2ea89f-0670-4502-8223-ec7a8264960b,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,"['unknown', 'DeKo: Derivations-und Kompositionsmorphologie, Zwischenbericht']","['unknown', '2001']","['unknown', 'Ulrich Heid']",group,"['DeKo', '(for', 'Derivation', 'and', 'Komposition,', 'funded', 'by', 'the', 'state', 'of', 'Baden-Württemberg', 'from', 'Jan', '2000', '-June', '2001)', 'is', 'designed', 'as', 'a', 'German', 'word', 'formation', 'component', 'in', 'a', 'larger', 'computational', 'linguistic', 'application.', '13', 'It', 'was', 'done', 'on', 'a', 'much', 'smaller', 'scale', 'than', 'Word', 'Manager', 'and', 'is', 'not', 'used', 'in', 'any', 'commercial', 'products.', 'In', 'this', 'tutorial', 'we', 'focus', 'on', 'some', 'basic', 'design', 'features', '-especially', 'where', 'they', 'differ', 'from', 'Word', ""Manager's"", 'features.', 'More', 'details', 'can', 'be', 'found', 'in', '<ref type=""group"">Heid 2001 , Schmid et al. 2001</ref>', 'and', 'at', 'http://www.ims.uni-stuttgart.de/projekte/DeKo/.', 'Here', 'we', 'want', 'to', 'concentrate', 'on', 'the', 'corpus-based', 'acquisition', 'of', 'data,', 'the', 'item-and-arrangement', 'design,', 'analysis', 'and', 'structure,', 'and', 'the', 'interaction', 'between', 'DeKo', 'and', 'the', 'lexicon.', 'Although', 'the', 'DeKo', 'project', 'proper', 'is', 'finished,', 'work', 'is', 'still', 'being', 'done', 'to', 'improve', 'the', 'program', 'and', 'especially', 'to', 'extend', 'the', 'lexicon.']",74,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6e465382-79c7-443c-bd7e-1ae16ff25a72,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,"['The affective weight of lexicon', 'WordNet Affect: an Affective Extension of WordNet']","['2006', '2004']","['Carlo Strapparava;Allesandro Valitutti;Oliviero Stock', 'Carlo Strapparava;Allesandro Valitutti']",group,"['We', 'analyzed', 'the', 'results', 'related', 'to', 'the', 'keywords', 'in', 'WordNet-Affect', '<ref type=""group"">(Strapparava &amp, Valitutti, 2004, Strapparava et al., 2006)</ref>', '),', 'a', 'linguistic', 'resource', 'for', 'the', 'lexical', 'representation', 'of', 'affective', 'knowledge.', 'In', 'this', 'the', 'affective', 'concepts', 'representing', 'emotional', 'state', 'are', 'individuated', 'by', 'synsets', 'marked', 'with', 'the', 'alabel', 'EMOTION.', 'There', 'are', 'also', 'other', 'a-labels', 'for', 'those', 'concepts', 'representing', 'moods,', 'situations', 'eliciting', 'emotions,', 'or', 'emotional', 'responses.']",10,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
6e472884-dc2e-4468-bae1-9ac167d34db4,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Data-driven approach using semantics for recognizing and classifying timeml events in italian'],['2011'],['Tommaso Caselli;Hector Llorens;Borja Navarro-Colorado;Estela Saquete'],single,"['3.', '<ref type=""single"">Caselli et al. (2011b)</ref>', 'establishes', 'the', 'current', 'state', 'of', 'the', 'art', 'for', 'data', 'driven', 'models', 'in', 'temporal', 'and', 'event', 'extent', 'information', 'in', 'Italian.', 'The', 'system', 'is', 'a', 'modification', 'of', 'the', 'TipSem', 'system.', 'We', 'compares', 'our', 'models', 'to', 'their', 'reported', 'scores.', 'However,', 'the', 'corpus', 'used', 'in', '<ref type=""single"">Caselli et al. (2011b)</ref>', 'is', 'the', 'Ita-TimeBank', 'which', 'has', 'been', 'augmented', 'with', 'further', 'annotations', 'and', 'resources,', 'while', 'our', 'system', 'uses', 'just', 'the', 'Ita-TimeBank', 'for', 'event', 'extraction.']",1,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6e918860-77a4-4a44-926b-9daf930711fd,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['The stages of event extraction'],['2006'],['David Ahn'],single,"['Neural', 'approaches', 'to', 'sequence', 'tagging', 'are', 'common', 'due', 'to', 'extensive', 'developments', 'in', 'named', 'entity', 'recognition.', '<ref type=""single"">Huang et al. (2015)</ref>', 'introduced', 'and', 'cultivated', 'the', 'use', 'of', 'bidirectional', 'LSTMs', 'to', 'incorporate', 'features', 'that', 'could', 'be', 'used', 'for', 'sequence', 'tagging', 'using', 'a', 'CRF.', '<ref type=""single"">Ma and Hovy (2016)</ref>', ""'s"", 'architecture', 'and', 'the', 'NeuroNER', 'program', '<ref type=""single"">(Dernoncourt et al., 2017)</ref>', 'provided', 'a', 'basic', 'architecture', 'and', 'influenced', 'multiple', 'developments', 'to', 'most', 'sequence', 'labeling', 'tasks,', 'including', 'event', '<ref type=""single"">detection and extraction (Araki, 2018).</ref>', 'The', 'task', 'of', 'event', 'extraction', 'in', 'any', 'language', 'involves', 'the', 'identification', 'of', 'the', 'event', 'nugget', '<ref type=""single"">(Ahn, 2006).</ref>', 'Prominent', 'work', 'has', 'been', 'done', 'to', 'analyze', 'the', 'lexical', 'and', 'semantic', 'features', 'of', 'event', 'representation', '<ref type=""single"">(Li et al., 2013),</ref>', 'which', 'served', 'as', 'a', 'basis', 'for', 'neural', 'event', 'nugget', 'detection', '<ref type=""single"">(Liang et al., 2017).</ref>']",76,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
6e966579-f5b0-45ec-bf3e-fab2639496de,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Parsing {with) Punctuation. Rank Xerox Research Centre'],['1994'],['E Briscoe;J Carroll'],single,"['We', 'took', 'all', 'in-coverage', 'sentences', 'from', 'Susanne', 'of', 'length', '8-40', 'words', 'inclusive', 'containing', 'internal', 'punctuation,', 'a', 'total', 'of', '2449', 'sentences.', 'The', 'APB', 'for', 'this', 'set', 'was', '1.273,', 'mean', 'length', '22.5', 'words,', 'giving', 'an', 'expected', 'number', 'of', 'analyses', 'for', 'an', 'average', 'sentence', 'of', '225.', 'We', 'then', 're-moved', 'all', 'sentence-internal', 'punctuation', 'from', 'this', 'set', 'and', 're-parsed', 'it.', 'Around', '8%', 'of', 'sentences', 'now', 'failed', 'to', 'receive', 'an', 'analysis.', 'For', 'those', 'that', 'did', '(mean', 'length', '20.7', 'words),', 'the', 'APB', 'was', 'now', '1', '.320,', 'so', 'an', 'average', 'sentence', 'would', 'be', 'assigned', '310', 'analyses,', '38%', 'more', 'than', 'before.', 'On', 'closer', 'inspection,', 'the', 'increase', 'in', 'ambiguity', 'is', 'due', 'to', 'two', 'factors:', 'a)', 'a', 'significant', 'proportion', 'of', 'sentences', 'that', 'previously', 'received', '1', '...:..', '9', 'analyses', 'now', 'receive', 'more,', 'and', 'b)', 'there', 'is', 'a', 'much', 'more', 'substantial', 'tail', 'in', 'the', 'distribution', 'of', 'sentence', 'length', 'vs.', 'number', 'of', 'parses,', 'due', 'to', 'some', 'longer', 'sentences', 'being', 'assigned', 'many', 'more', 'parses.', 'Manual', 'examination', 'of', '100', 'depunctuated', 'examples', 'revealed', 'that', 'in', 'around', 'a', 'third', 'of', 'cases,', 'although', 'the', 'system', 'returned', 'global', 'analyses,', 'the', 'correct', 'one', 'was', 'not', 'in', 'this', 'set', '<ref type=""single"">(Briscoe &amp, Carroll, 1994).</ref>', 'With', 'a', 'more', 'constrained', '(sub', 'categorised)', 'syntactic', 'grammar,', 'many', 'of', 'these', 'examples', 'would', 'not', 'have', 'received', 'any', 'global', 'syntactic', 'analysis.']",177,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
6ea4b637-192a-4f93-8312-469f65c423ae,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Q-BERT: hessian based ultra low precision quantization of BERT'],['2020'],['Sheng Shen;Zhen Dong;Jiayu Ye;Linjian Ma;Zhewei Yao;Amir Gholami;Michael Mahoney;Kurt Keutzer'],single,"['Many', 'works', 'address', 'the', 'issue', 'of', 'model', 'compression', 'with', 'quantization,', 'pruning,', 'knowledge', 'distillation', 'or', 'a', 'combination', 'of', 'these', 'approaches.', 'The', 'idea', 'of', 'quantization', '<ref type=""single"">(Shen et al., 2020)</ref>', 'is', 'to', 'take', 'advantage', 'of', 'the', 'use', 'of', 'lower', 'precision', 'bit-width', 'floats', 'to', 'reduce', 'memory', 'usage', 'and', 'increase', 'computational', 'density.', 'Following', 'the', 'same', 'objective,', 'pruning', '<ref type=""single"">(Michel et al., 2019)</ref>', 'consists', 'in', 'removing', 'parts', 'of', 'a', 'model', '(weight', 'bindings,', 'attentional', 'heads)', 'with', 'minimal', 'precision', 'losses.', 'Finally,', 'knowledge', 'distillation', '<ref type=""single"">(Sanh et al., 2019)</ref>', 'enables', 'the', 'generation', 'of', 'models', 'that', 'mimic', 'the', 'performance', 'of', 'a', 'large', 'model', '(or', 'set', 'of', 'models)', 'while', 'having', 'fewer', 'parameters.']",23,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6ed2d469-7806-45f4-8db7-f7d51cdb4766,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Faster r-cnn: Towards real-time object detection with region proposal networks'],['2015'],['Kaiming Shaoqing Ren;Ross He;Jian Girshick;unk Sun'],single,"['For', 'the', 'visual', 'feature,', 'we', 'adopt', 'Faster-RCNN', '<ref type=""single"">(Ren et al., 2015)</ref>', 'to', 'extract', '100', 'bounding', 'box', 'proposals.']",7,"[2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2]"
6ef16ef4-3bf6-4dc0-8c78-aca927b12321,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,"['Detect all abuse! toward universal abusive language detection models', 'Machine learning and semantic analysis of in-game chat for cyberbullying', 'Exploring cyberbullying and other toxic behavior in team competition online games']","['2020', '2018', '2015']","['Kunze Wang;Dong Lu;Caren Han;Siqu Long;Josiah Poon', 'Shane Murnion;J William;Adrian Buchanan;Gordon Smales;unk Russell', 'Haewoon Kwak;Jeremy Blackburn;Seungyeop Han']",group,"['In', 'the', 'past', 'few', 'years,', 'Natural', 'Language', 'Processing', '(NLP)', 'researchers', 'have', 'proposed', 'several', 'online', 'game/community', 'toxicity', 'analysis', 'frameworks', 'Figure', '1:', 'An', 'example', 'intent/slot', 'annotation', 'from', 'the', 'CONDA', '(CONtextual', 'Dual-Annotated)', 'dataset.', '<ref type=""group"">(Kwak et al., 2015, Murnion et al., 2018, Wang et al., 2020)</ref>', 'and', 'datasets', '<ref type=""group"">(Märtens et al., 2015, Stoop et al., 2019).</ref>', 'However,', 'existing', 'datasets', '(1)', 'focus', 'only', 'on', 'the', 'single', 'utterance', 'level', 'without', 'deeper', 'understanding', 'of', 'context', 'in', 'the', 'whole', 'conversation/chat,', 'and', '(2)', 'do', 'not', 'explicitly', 'use', 'semantic', 'clues', 'from', 'the', 'words', 'within', 'the', 'utterance.']",30,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
6fbfaf76-3c98-4c23-a15c-fcac6be5dd6a,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,"['unknown', 'Longformer: The long-document transformer', 'Reformer: The efficient transformer', 'Blockwise selfattention for long document understanding', 'Generating long sequences with sparse transformers']","['2020', '2020', '2020', '2020', '2019']","['Ankit Gupta;Jonathan Berant', 'Iz Beltagy;E Matthew;Arman Peters;unk Cohan', 'Nikita Kitaev;Lukasz Kaiser;Anselm Levskaya', 'Jiezhong Qiu;Hao Ma;Omer Levy;Sinong Wen-Tau Yih;Jie Wang;unk Tang', 'Rewon Child;Scott Gray;Alec Radford;Ilya Sutskever']",group,"['The', 'attention', 'function', '(Eq.', '1)', 'requires', 'the', 'computation', 'of', 'QK', 'containing', 'L', 'Q', 'L', 'K', 'entries', 'and', 'can', 'be', 'expensive', 'for', 'long', 'sequences', '(L', 'Q', 'and', 'L', 'K', 'are', 'typically', 'the', 'sequence', 'length).', 'To', 'alleviate', 'this', 'issue,', 'sparse', 'attention', 'variants', '<ref type=""group"">(Child et al., 2019, Qiu et al., 2020, Kitaev et al., 2020, Beltagy et al., 2020, Gupta and Berant, 2020)</ref>', 'relax', 'this', 'requirement', 'and', 'compute', 'only', 'a', 'few', 'entries', 'of', 'QK,', 'masking', 'out', 'the', 'rest.', 'For', 'a', 'binary', 'mask']",40,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0]"
7033a2a3-1451-4cef-8b58-545a532c193b,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,['A Survey on Explainability in Machine Reading Comprehension'],['2020'],['Mokanarangan Thayaparan;Marco Valentino;André Freitas'],single,"['to', 'form', 'reasoning', 'chains', 'that', 'support', 'the', 'correct', 'answer', '(see', 'Figure', '1).', 'As', 'such,', 'multi-hop', 'inference', 'represents', 'a', 'crucial', 'step', 'towards', 'explainability', 'in', 'complex', 'question', 'answering,', 'as', 'the', 'set', 'of', 'supporting', 'facts', 'can', 'be', 'interpreted', 'as', 'an', 'explanation', 'for', 'the', 'underlying', 'inference', 'process', '<ref type=""single"">(Thayaparan et al., 2020).</ref>']",43,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1]"
7042aafd-f496-4ba3-b7a9-a072fd5d0af1,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,['A new decoder for spoken language translation based on confusion networks'],['2005'],['N Bertoldi;M Federico'],single,"['There', 'are', 'several', 'reports', 'in', 'the', 'literature', 'showing', 'that', 'a', 'careful', 'design', 'of', 'the', 'interface', 'between', 'automatic', 'speech', 'recognition', '(ASR)', 'and', 'machine', 'translation', 'can', 'be', 'important', 'to', 'limit', 'the', 'performance', 'degradation', 'observed', 'when', 'translating', 'an', 'automatic', 'transcription', '(as', 'opposed', 'to', 'a', 'manual', 'transcription).', 'These', 'works', 'include', 'the', 'translation', 'of', 'richer', 'data', 'structures', 'than', 'the', '1-best', 'ASR', 'output,', 'see', 'for', 'instance', '<ref type=""single"">[18]</ref>', 'or', 'various', 'aspects', 'of', 'case,', 'punctuation', 'and', 'word', 'normalization', '<ref type=""group"">[19, 20].</ref>']",60,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
70653da2-cfcc-475f-981a-6746923ba9d4,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,"['Automatic bilingual dictionary construction for Tirukural', 'unknown', 'Information extraction framework for Kurunthogai']","['2018', 'unknown', '2019']","['C Subalalitha', 'unknown', 'C Subalalitha']",group,"['India', 'has', 'a', 'population', 'of', '1.4', 'billion', 'people', 'speaking', '447', 'languages', 'and', 'over', '10,000', 'dialects,', 'making', 'it', 'the', 'country', 'with', 'the', 'fourth-highest', 'number', 'of', 'languages', '<ref type=""single"">(Chakravarthi, 2020).</ref>', 'However,', 'Indian', 'lan-guages', 'are', 'highly', 'under-represented', 'on', 'the', 'Internet', 'and', 'Natural', 'Language', 'Processing', '(NLP)', 'systems', 'for', 'Indian', 'languages', 'are', 'in', 'their', 'nascency', '<ref type=""group"">(Bharathi et al., 2022, Priyadharshini et al., 2021)</ref>', '.Tamil', 'is', 'a', 'member', 'of', 'the', 'southern', 'branch', 'of', 'the', 'Dravidian', 'languages,', 'a', 'group', 'of', 'about', '26', 'languages', 'indigenous', 'to', 'the', 'Indian', 'subcontinent.', 'It', 'is', 'also', 'classed', 'as', 'a', 'member', 'of', 'the', 'Tamil', 'language', 'family,', 'which', 'contains', 'the', 'languages', 'of', 'around', '35', 'ethnolinguistic', 'groups,', 'including', 'the', 'Irula', 'and', 'Yerukula', 'languages', '<ref type=""group"">(Sakuntharaj and Mahesan, 2021 , 2017 , 2016, Thavareesan and Mahesan, 2019 , 2020a ,b, 2021).</ref>', 'Malayalam', 'is', ""Tamil's"", 'closest', 'significant', 'cousin,', 'the', 'two', 'began', 'splitting', 'during', 'the', '9th', 'century', 'AD.', 'Although', 'several', 'variations', 'between', 'Tamil', 'and', 'Malayalam', 'indicate', 'a', 'pre-historic', 'break', 'of', 'the', 'western', 'dialect,', 'the', 'process', 'of', 'separating', 'into', 'a', 'different', 'language,', 'Malayalam,', 'did', 'not', 'occur', 'until', 'the', '13th', 'or', '14th', 'century', '<ref type=""group"">(Anita and Subalalitha, 2019b,a, Subalalitha and Poovammal, 2018, Subalalitha, 2019).</ref>', 'Even', 'state-of-the-art', 'multilingual', 'NLP', 'systems', 'perform', 'sub-optimally', 'on', 'Dravidian', 'languages', '<ref type=""single"">(Google, 2021).</ref>', 'This', 'can', 'be', 'explained', 'by', 'the', 'fact', 'that', 'multilingual', 'language', 'models', 'are', 'often', 'jointly', 'trained', 'on', '100+', 'languages', 'and', 'Indian', 'languages', 'constitute', 'only', 'a', 'small', 'fraction', 'of', 'their', 'vocabulary', 'and', 'training', 'data', '(as', 'shown', 'in', 'Figure', '2).', 'Machine', 'learning', 'models', 'and', 'tools', 'have', 'been', 'proposed', 'for', 'many', 'Natural', 'Language', 'Understanding', 'tasks.', 'In', 'this', 'work,', 'we', 'focus', 'on', 'Extractive', 'Question-Answering', '(QA),', 'where', 'the', 'goal', 'is', 'to', 'localize', 'the', 'answer', 'to', 'a', 'question', 'within', 'a', 'large', 'context', '(see', 'Figure', '1).', 'Specifically,', 'we', 'aim', 'to', 'develop', 'a', 'common', 'multilingual', 'question', 'answering', 'model', 'for', 'multiple', 'Indian', 'languages.', 'A', 'multilingual', 'model', 'has', 'several', 'advantages:', '(1)', 'learning', 'of', 'cues', 'across', 'different', 'languages,', '(2)', 'a', 'single', 'model', 'for', 'many', 'languages,', 'and', '(3)', 'avoiding', 'dependency', 'on', 'English', 'translation', 'during', 'inference.', 'In', 'this', 'work,', 'we', 'start', 'with', 'a', 'pre-trained', 'multilingual', 'Bidi-', 'rectional', 'Encoder', 'Representations', 'from', 'Transformers', '(mBERT)', 'model', 'and', 'further', 'pre-train', 'it', 'with', 'SQuAD', '<ref type=""single"">(Rajpurkar et al., 2016),</ref>', 'a', 'large-scale', 'question', 'answering', 'dataset', 'in', 'English.', 'The', 'resulting', 'English-language', 'mBERT-QA', 'model', 'is', 'fine-tuned', 'and', 'evaluated', 'for', 'Indian', 'languages', 'Tamil', 'and', 'Hindi', 'using', 'the', 'ChAII', 'dataset', '<ref type=""single"">(Google, 2021).</ref>']",148,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
70723d7e-0c6d-4990-ba18-c5aad43876a0,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Rethinking attention with performers'],['2021'],['Valerii Krzysztof Marcin Choromanski;David Likhosherstov;Xingyou Dohan;Andreea Song;Tamas Gane;Peter Sarlos;Jared Hawkins;Afroz Davis;Lukasz Mohiuddin;David Kaiser;Lucy Belanger;Adrian Colwell;unk Weller'],single,"['Compared', 'to', 'prior', 'methods,', 'top-k', 'attention', 'has', 'multiple', 'attractive', 'properties:', 'Top-k', 'attention', 'has', 'the', 'same', 'memory', 'footprint', 'as', 'Performer', '<ref type=""single"">(Choromanski et al., 2021),</ref>', 'a', 'stateof-the-art', 'attention', 'variant', 'with', 'linear', 'time', 'and', 'memory', 'complexity,', 'on', 'very', 'long', 'inputs', '(orange', 'curve,', 'Fig.', '1,', 'top-right),', 'while', 'being', 'as', 'fast', 'as', 'vanilla', 'attention,', 'and', 'even', 'faster', 'than', 'linear', 'variants', 'on', 'inputs', 'of', 'length', 'up', 'to', '4K', '(Figure', '1,', 'bottom-left).', 'This', 'allows', 'us,', 'e.g.,', 'to', 'train', 'a', 'typical', '12-layer', 'Transformer', 'decoder', 'over', '32K-long', 'inputs', 'on', 'a', '30GiB', 'GPU', '(Figure', '3a).']",19,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
70928c76-2d99-4f84-b005-c1b2b403ed66,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,['unknown'],['unknown'],['unknown'],single,"['There', 'are', 'two', 'obvious', 'approaches', 'to', 'try', 'and', 'answer', 'this', 'question.', 'The', 'first', 'is', 'to', 'simply', 'consider', 'transformer-based', 'features', '(e.g.,', 'BERT', 'score,', 'ColBERT', 'score,', 'etc.)', 'as', 'yet', 'another', 'feature', 'within', 'a', 'learning-to-rank', 'framework-for', 'example,', 'with', 'gradient', 'boosted', 'decision', 'trees', '<ref type=""single"">(Wang et al., 2020).</ref>', 'This', 'is', 'not', 'the', 'route', 'that', 'we', 'take,', 'because', 'this', 'approach', 'has', 'less', 'bearing', 'on', 'our', 'desire', 'to', 'increase', 'the', 'efficiency', 'of', 'transformer-based', 'models.', 'Instead,', 'we', 'take', 'the', 'alternative', 'approach', 'of', 'using', 'learningto-rank', 'techniques', 'as', 'a', '""filtering""', 'stage', 'in', 'a', 'multistage', 'ranking', 'architecture', 'to', 'reduce', 'the', 'number', 'of', 'candidates', 'under', 'consideration', 'by', 'BERT.', 'More', 'concretely,', 'we', 'find', 'that', 'a', 'design', 'based', 'on', 'this', 'idea', 'achieves', 'the', 'same', 'level', 'of', 'effectiveness', 'as', 'a', 'standard', 'retrieve-and-rerank', 'approach', 'using', 'BERT,', 'but', 'is', 'up', 'to', '18×', 'faster.', 'Other', 'effectiveness-efficiency', 'tradeoffs', 'are', 'possible,', 'giving', 'developers', 'a', 'rich', 'design', 'space', 'to', 'build', 'systems', 'tailored', 'to', 'different', 'application', 'scenarios.']",39,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
70e9b3a6-207f-4574-97fc-4a24ecd50ced,Can Semantic Role Labeling Improve SMT?,2009,Dekai Wu;Pascale Fung,['A smorgasbord of features for automatic mt evaluation'],['2008'],['Jesús Giménez;Lluís Màrquez'],single,"['Giménez', 'and', 'Màrquez', '(2007b)', 'and', '<ref type=""single"">Giménez and Màrquez (2008)</ref>', 'introduced', 'and', 'refined', 'a', 'set', 'of', 'new', 'MT', 'evaluation', 'metrics', 'employing', 'rich', 'assortments', 'of', 'features', 'reflecting', 'various', 'kinds', 'of', 'similarity', 'at', 'lexical,', 'shallow', 'syntactic,', 'deep', 'syntactic,', 'shallow', 'semantic,', 'and', 'deep', 'semantic', 'levels.']",5,"[3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
717d08c1-01ef-42d8-aeb3-160e0bac9ea6,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['ALBERT: A lite BERT for self-supervised learning of language representations'],['2020'],['Zhenzhong Lan;Mingda Chen;Sebastian Goodman;Kevin Gimpel;Piyush Sharma;Radu Soricut'],single,"['To', 'answer', 'these', 'questions,', 'we', 'first', 'establish', 'in', 'section', '2', 'a', 'state-of-the-art', 'that', 'is', 'meant', 'to', 'be', 'broad', 'enough', 'to', 'have', 'a', 'shallow', 'overview', 'depicting', 'the', 'ins', 'and', 'outs', 'and', 'issues', 'around', 'the', 'usability', 'of', 'Transformer-based', 'models', 'whose', 'breadcrumb', 'trail', 'is', 'the', 'issue', 'of', 'resources.', 'Then,', 'we', 'present', 'in', 'the', 'section', '3', 'the', 'recent', 'progress', 'of', 'the', 'questionanswering', 'task,', 'through', 'the', 'use', 'of', 'these', 'latest', 'models.', 'In', 'sections', '4', 'and', '5', 'we', 'introduce', 'our', 'model', 'and', 'present', 'our', 'experiments', 'on', 'the', 'usability', 'of', 'Transformers', 'models', 'in', 'a', 'question-answering', 'task', 'for', '<ref type=""single"">French, on FQuAD (d\'Hoffschmidt et al., 2020)</ref>', 'and', 'PIAF', '<ref type=""single"">(Keraron et al., 2020)</ref>', 'corpora.', 'We', 'propose', 'to', 'address', 'the', 'instability', 'relating', 'to', 'data', 'scarcity', 'by', 'investigating', 'various', 'training', 'strategies', 'with', 'data', 'augmentation,', 'hyperparameters', 'optimization', 'and', 'cross-lingual', 'transfer.', 'Finally,', 'we', 'present', 'a', 'new', 'compact', 'model', 'for', 'French', 'based', 'on', 'ALBERT', '<ref type=""single"">(Lan et al., 2020)</ref>', '1,', 'and', 'compare', 'it', 'to', 'existing', 'monolingual', 'and', 'multilingual', 'models,', 'large', 'and', 'compact,', 'under', 'constrained', 'conditions', '(notably', 'on', 'learning', 'data).']",130,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]"
721760d5-4686-4d4d-a1f4-7affc9441ae2,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Bleurt: Learning robust metrics for text generation'],['2020'],['Thibault Sellam;Dipanjan Das;Ankur Parikh'],single,"['Therefore,', 'neural-based', 'diversity', 'metrics', 'are', 'highly', 'demanded.', 'Intuitively,', 'the', 'metrics', 'should', 'include', 'computational', 'comparisons', 'of', 'multiple', 'references', 'and', 'hypotheses', 'by', 'projecting', 'them', 'into', 'the', 'same', 'semantic', 'space,', 'unlike', 'metrics', 'for', 'evaluating', 'the', 'generation', 'quality,', 'e.g.,', 'BERTScore', '<ref type=""single"">(Zhang et al., 2020b)</ref>', 'and', 'BLEURT', '<ref type=""single"">(Sellam et al., 2020),</ref>', 'which', 'only', 'measures', 'the', 'correlation', 'between', 'a', 'pair', 'of', 'reference', 'and', 'hypothesis.']",39,"[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
72c7a171-ef01-4b7b-bdbc-7334c37111ef,Themes in the work of Margaret Masterman,1988,Yorick Wilks,['English through pictures'],['1952'],['I Richards;C Gibson'],single,"['The', 'connection', 'of', 'all', 'this', 'to', 'ideograms', 'had', 'been', 'noted', 'by', 'Richards,', 'who', 'was', 'much', 'preoccupied', 'by', 'Chinese,', 'and', 'who', 'developed', 'English', 'through', 'pictures', '<ref type=""single"">(Richards and Gibson, 1952),</ref>', 'a', 'highly', 'successful', 'language', 'teaching', 'tool.', 'MMB', 'came', 'to', 'Chinese', 'through', 'Michael', 'Halliday,', 'then', 'a', 'Cambridge', 'University', 'lecturer', 'in', 'Chinese,', 'and', 'began', 'to', 'use', 'stick-pictures', 'as', 'representations', 'of', 'situations', 'but', 'which', 'could', 'also', 'provide', 'a', 'plausible', 'referential', 'underpinning', 'for', 'language:', 'something', 'universal,', 'and', 'outside', 'the', 'world', 'of', 'the', 'language', 'signs', 'themselves,', 'yet', 'which', 'did', 'not', 'fall', 'back', 'on', 'the', 'naive', 'referentialism', 'of', 'those', 'who', 'said', 'that', 'the', 'meanings', 'of', 'words', 'were', 'things', 'or', 'inexpressible', 'concepts.']",24,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
72ecc9df-5409-4c27-88a5-c77767f4723a,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Machine translation and monolingual postediting: The AFRL WMT-14 system'],['2014'],['L Schwartz;T Anderson;J Gwinnup;K Young'],single,"['The', 'Russian', 'language', 'news', 'articles', 'used', 'in', 'this', 'study', 'have', 'corresponding', 'reference', 'translations.', 'It', 'is', 'therefore', 'possible', '(although', 'given', 'current', 'machine', 'translation', 'quality,', 'highly', 'unlikely)', 'that', 'machine', 'translation', 'quality', 'for', 'any', 'given', 'segment', 'could', 'conceivably', 'surpass', 'the', 'quality', 'of', 'the', 'corresponding', 'reference', 'translation', '(if', 'for', 'example,', 'the', 'reference', 'translator', 'makes', 'a', 'mistake).', 'For', 'assessing', 'the', 'quality', 'of', 'the', 'Russian-English', 'machine', 'translations,', 'then,', 'we', 'follow', 'the', '12-point', 'adequacy', 'scale', 'of', '<ref type=""single"">Schwartz et al. (2014).</ref>', 'This', 'adequacy', 'scale', 'is', 'shown', 'in', 'Table', '1a', 'on', 'page', '2,', 'this', 'scale', 'ranges', 'from', 'a', 'low', 'of', '2', '(the', 'English', 'translation', 'makes', 'no', 'sense', 'at', 'all)', 'to', 'a', 'high', 'of', '12', '(the', 'translation', 'is', 'superior', 'to', 'the', 'reference).']",69,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
73299666-4945-4570-9170-6db03f9b96aa,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['A diversity-promoting objective function for neural conversation models'],['2016'],['Jiwei Li;Michel Galley;Chris Brockett;Jianfeng Gao;Bill Dolan'],single,"['Corpus', 'diversity', '(⇑).', 'Distinct-k', '<ref type=""single"">(Li et al., 2016)</ref>', 'measures', 'the', 'total', 'number', 'of', 'unique', 'k-grams', 'normalized', 'by', 'the', 'total', 'number', 'of', 'generated', 'k-gram', 'tokens', 'to', 'avoid', 'favoring', 'long', 'sentences.', 'Entropyk', '<ref type=""single"">(Zhang et al., 2018)</ref>', 'reflects', 'how', 'evenly', 'the', 'empirical', 'k-gram', 'distribution', 'is', 'for', 'a', 'given', 'sentence', 'when', 'word', 'frequency', 'is', 'considered.', 'Human', '6.62', '0.0', '12.43', '0.0', '10.36', '0.0', '6.04', '0.0', '53.57', '0.0', '10.84', '0.0', '100.0', '0.0', '100.0', '0.0', '*', 'Metrics:', 'SB-3/4:', 'Self-BLEU-3/4', '(⇓),', 'D-2:', 'Distinct-2', '(⇑),', 'E-4:', 'Entropy-4', '(⇑),', 'B-4:', 'BLEU-4', '(⇑),', 'R-L:', 'ROUGE-L', '(⇑)#Uni.C(⇑)', 'Jaccard', '(⇓)', 'SB-3', '(⇓)', 'SB-4', '(⇓)', 'D-2(⇑)', 'E-4(⇑)', 'B-4', '(⇑)', 'R-L', '(⇑)', 'CVAE', 'z', '=']",4,"[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
737635af-1e7c-4bc0-8b8f-20a6ede7212d,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,['Syntactic and Semantic Type and Selection'],['1999'],['T Briscoe;A Korhonen;N Calzolari;S Montemagni;V Pirrelli;S Federici;G Carroll;M Light;D Mccarthy;D Prescher;S Riezler;M Rooth'],single,"['The', 'SPARKLE', 'project', 'has', 'shown', '(see', '<ref type=""single"">Briscoe et al. 1999)</ref>', 'how', 'far', 'simple', 'robust', 'phrasal', 'parsing', 'combined', 'with', 'classification', 'techniques', 'utilising', 'limited', 'and', 'manageable', 'linguistic', 'knowledge', 'and', 'statistical', 'data', 'from', 'substantial', 'corpora', 'can', 'ameliorate', 'this', 'problem', 'in', 'the', 'area', 'of', 'predicate', 'subcategorisation,', 'argument', 'structure', 'and', 'semantic', 'preferences,', 'an', 'area', 'in', 'which', 'most', 'extant', 'conventional', 'dictionaries,', 'lexical', 'databases', 'and', 'realistic', 'lexicons', 'are', 'demonstrably', 'weak', 'or', '-when', 'available', '-by', 'necessity', 'never', 'complete.']",6,"[3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
738d20b9-cf59-4c7b-bb22-64cd614e4c1b,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,"['Determining relative argument specificity and stance for complex argumentative structures', 'Classification and clustering of arguments with contextualized word embeddings']","['2019', '2019']","['Esin Durmus;Faisal Ladhak;Claire Cardie', 'Nils Reimers;Benjamin Schiller;Tilman Beck;Johannes Daxenberger;Christian Stab;Iryna Gurevych']",group,"['The', 'first', 'goal', 'of', 'this', 'experiment', 'is', 'to', 'see', 'if', 'the', 'logical', 'mechanisms', 'improve', 'the', 'predictive', 'power', 'of', 'a', 'model', 'trained', 'without', 'concerning', 'them.', 'Thus,', 'our', 'first', 'baseline', 'is', 'BERT', 'fine-tuned', 'on', 'the', 'main', 'task', 'only.', 'This', 'method', 'recently', 'yielded', 'the', '(near)', 'best', 'accuracy', 'in', 'argumentative', 'relation', 'classification', '<ref type=""group"">(Durmus et al., 2019, Reimers et al., 2019).</ref>']",48,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]"
73f684be-f801-4360-ad31-dc9d3c2915cc,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,['RelGAN: Relational Generative Adversarial Networks for Text Generation'],['2019'],['Weili Nie;Nina Narodytska;Ankit Patel'],single,"['Natural', 'language', 'generation', '(NLG)', 'is', 'gaining', 'increasing', 'attention', 'in', 'the', 'NLP', 'community', 'thanks', 'to', 'its', 'intriguing', 'complexity', 'and', 'central', 'role', 'in', 'many', 'tasks', 'and', 'applications.', 'Recently,', 'generative', 'adversarial', 'networks', '(GANs)', '<ref type=""single"">[7]</ref>', 'have', 'started', 'to', 'display', 'promising', 'performance', 'also', 'in', 'NLG.', 'GANs', 'leverage', 'a', 'form', 'of', 'adversarial', 'learning', 'where', 'a', 'generator', 'incrementally', 'learns', 'to', 'generate', 'realistic', 'samples,', 'while', 'a', 'discriminator', 'simultaneously', 'learns', 'to', 'discriminate', 'between', 'real', 'and', 'generated', 'data.', 'They', 'had', 'originally', 'been', 'proposed', 'as', 'a', 'generative', 'approach', 'for', 'continuous', 'data,', 'such', 'as', 'images,', 'but', 'have', 'later', 'found', 'application', 'also', 'for', 'discrete', 'data,', 'despite', 'their', 'well-known', '""non-differentiability', 'issue"".', 'In', 'fact,', 'several', 'GANs', 'have', 'recently', 'been', 'proposed', 'for', 'text', 'generation', '<ref type=""group"">[24, 16, 25]</ref>', 'and', 'have', 'achieved', 'encouraging', 'results', 'in', 'comparison', 'to', 'comparable', 'maximum', 'likelihood', 'approaches,', 'in', 'particular,', 'RelGAN', '<ref type=""single"">[16]</ref>', 'has', 'outperformed', 'state-of-theart', '(SOTA)', 'results.']",124,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]"
747729fa-57f9-408d-ad79-c9207e05872a,Can Semantic Role Labeling Improve SMT?,2009,Dekai Wu;Pascale Fung,['Automatic learning of chinese-english semantic structure mapping'],['2006'],['Pascale Fung;Zhaojun Wu;Yongsheng Yang;Dekai Wu'],single,"['This', 'situation', 'leads', 'us', 'to', 'consider', 'the', 'potential', 'application', 'of', 'shallow', 'semantic', 'parsing', 'and', 'semantic', 'role', 'labeling', 'models', 'to', 'SMT,', 'in', 'ways', 'that', 'might', 'reduce', 'role', 'confusion', 'errors', 'in', 'the', 'translation', 'output.', 'Within', 'the', 'lexical', 'semantics', 'community,', 'increasingly', 'sophisticated', 'models', 'for', 'shallow', 'semantic', 'parsing', 'are', 'being', 'developed.', 'Such', 'semantic', 'parsers,', 'which', 'automatically', 'label', 'the', 'predicates', 'and', 'arguments', '(roles)', 'of', 'the', 'various', 'semantic', 'frames', 'in', 'a', 'sentence,', 'could', 'automatically', 'identify', 'inconsistent', 'semantic', 'frame', 'and', 'role', 'mappings', 'between', 'the', 'input', 'source', 'sentences', 'and', 'their', 'output', 'translations.', 'This', 'approach', 'is', 'supported', 'by', 'the', 'results', 'of', '<ref type=""single"">Fung et al. (2006),</ref>', 'which', 'reported', 'that', '(for', 'the', 'Chinese-English', 'language', 'pair)', 'approximately', '84%', 'of', 'semantic', 'role', 'mappings', 'remained', 'consistent', 'cross-lingually', 'across', 'sentence', 'translations.']",92,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
7500307f-0aa9-4e7d-9bf9-8042bcf93dfd,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['Bert: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Joint', 'BERT', 'directly', 'utilizes', 'the', 'merit', 'of', 'pretrained', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'and', 'nonrecursively', 'conducts', 'the', 'joint', 'prediction', 'over', 'the', '<ref type=""single"">[CLS]</ref>', 'token', 'embedding', 'for', 'intent', 'and', 'the', 'sequence', 'of', 'token', 'embeddings', 'for', 'slots.']",9,"[3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
7538ce02-6beb-41b3-8d93-b80978cc5def,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['Looking beyond the surface: A challenge set for reading comprehension over multiple sentences'],['2018'],['Daniel Khashabi;Snigdha Chaturvedi;Michael Roth;Shyam Upadhyay;Dan Roth'],single,"['MultiRC:', 'Multi-Sentence', 'Reading', 'Comprehension', 'set', '<ref type=""single"">(Khashabi et al., 2018)</ref>', 'is', 'created', 'in', 'a', 'way', 'that', 'answering', 'questions', 'requires', 'a', 'more', 'complex', 'understanding', 'from', 'multiple', 'sentences.', 'Therefore,', 'coreference', 'reasoning', 'can', 'be', 'one', 'of', 'the', 'sources', 'for', 'improving', 'the', 'performance', 'on', 'this', 'dataset.', 'The', 'Contrast', 'set', 'and', 'MultiRC', 'datasets', 'are', 'not', 'designed', 'to', 'explicitly', 'evaluate', 'coreference', 'reasoning.', 'However,', 'we', 'include', 'them', 'among', 'our', 'evaluation', 'sets', 'to', 'have', 'a', 'broader', 'view', 'about', 'the', 'impact', 'of', 'using', 'our', 'coreference', 'data', 'in', 'QA.', '6', 'as', 'we', 'use', 'it', 'for', 'investigating', 'whether', 'the', 'resulting', 'performance', 'changes', 'are', 'due', 'to', 'using', 'more', 'training', 'data', 'or', 'using', 'coreference-aware', 'additional', 'data.']",5,"[0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
75f096d3-0d17-4996-937b-694b701d3784,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Supertagging: An approach to almost parsing'],['1999'],['S Bangalore;A Joshi'],single,"['CCG', 'provides', 'many', 'advantages', 'when', 'using', 'it', 'in', 'SMT', 'in', 'comparison', 'with', 'phrase-structure', 'grammar.', 'Firstly,', 'CCG', 'has', 'more', 'flexible', 'structures', 'in', 'comparison', 'with', 'phrase-structure', 'grammar.', 'This', 'flexibility', 'results', 'from', 'the', 'ability', 'to', 'combine', 'CCG', 'supertags', 'using', 'simple', 'combinatory', 'operators,', 'which', 'makes', 'it', 'possible', 'to', 'assign', 'a', 'CCG', 'category', 'to', 'a', 'phrase', 'that', 'does', 'not', 'represent', 'a', 'traditional', 'constituent', 'in', 'phrasestructure', 'grammar.', 'This', 'is', 'very', 'important', 'for', 'SMT', 'systems', 'as', 'the', 'power', 'of', 'SMT', 'lies', 'in', 'using', 'statistically', 'extracted', 'phrases', 'which', 'do', 'not', 'necessarily', 'correspond', 'to', 'syntactic', 'constituents.', 'Secondly,', 'CCG', 'categories', 'reflect', 'rich', 'information', 'about', 'the', 'syntactic', 'structure', 'to', 'which', 'the', 'word/phrase', 'belongs', 'at', 'the', 'lexical', 'level', 'without', 'the', 'need', 'to', 'build', 'a', 'full', 'parse', 'tree', 'for', 'the', 'sentence.', 'Thirdly,', 'CCG', 'parsing', 'is', 'more', 'efficient', 'in', 'comparison', 'to', 'phrase-structure', 'grammar', 'parsing.', 'Because', 'most', 'of', 'the', 'CCG', 'grammar', 'is', 'contained', 'in', 'the', 'lexicon,', 'the', 'process', 'of', 'supertagging,', 'which', 'is', 'to', 'assign', 'supertags', '(i.e.', 'complex', 'CCG', 'categories)', 'to', 'the', 'words', 'in', 'a', 'sentence,', 'is', 'considered', '""almost', 'parsing""', '<ref type=""single"">[13].</ref>', 'After', 'supertagging,', 'the', 'CCG', 'parser', 'is', 'only', 'required', 'to', 'combine', 'the', 'supertags', 'using', 'CCG', 'simple', 'combinatory', 'operators.', 'For', 'the', 'aforementioned', 'reasons,', 'CCG', 'is', 'considered', 'more', 'suitable', 'to', 'be', 'used', 'in', 'SMT', 'than', 'phrase-structure', 'grammar.']",164,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7645d880-1c50-4bba-9f69-9a606188c28f,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Modeling the paraphrase detection task over a heterogeneous graph network with data augmentation'],['2020'],['Rogério F De Rafael T Anchiêta;unk Sousa;unk Thiago;unk Pardo'],group,"['We', 'modeled', 'that', 'problem', 'as', 'a', 'heterogeneous', 'network.', 'The', 'structure', 'of', 'our', 'graph', 'was', 'inspired', 'by', '<ref type=""group"">de Sousa et al. (2020) and Anchiêta et al. (2020).</ref>', 'These', 'authors', 'modeled', 'the', 'tasks', 'of', 'helpfulness', 'prediction', 'and', 'paraphrase', 'identification', 'as', 'a', 'heterogeneous', 'network,', 'respectively.', 'For', 'that,', 'they', 'defined', 'an', 'undirected', 'unweighted', 'graph', 'with', 'two', 'node', 'types:', 'sentence', 'and', 'token.', 'However,', 'we', 'have', 'created', 'a', 'weighted', 'graph', 'based', 'on', 'pre-trained', 'word', 'embeddings.', 'The', 'weight', 'between', 'sentence', 'and', 'token', 'nodes', 'is', 'the', 'average', 'of', 'the', 'embedding', 'values', 'for', 'that', 'token.', 'Figure', '1', 'depicts', 'an', 'example', 'of', 'a', 'sentence', 'modeled', 'as', 'a', 'graph.', 'From', 'this', 'figure,', 'we', 'may', 'see', 'two', 'node', 'types:', 'token', 'and', 'sentence,', 'and', 'an', 'undirected', 'and', 'weighted', 'edges', 'between', 'the', 'sentence', 'and', 'tokens', 'nodes.', 'To', 'extract', 'features', 'from', 'the', 'graph', 'structure,', 'we', 'used', 'a', 'regularization', 'algorithm', 'that', 'propagates', 'labels', 'from', 'a', 'small', 'set', 'of', 'labeled', 'nodes', 'to', 'the', 'entire', 'graph.E(t)', 'E(t)', 'E(t)', 'E(t)', 'E(t)', 'E(t)We', 'evaluated', 'the', 'approach', 'using', 'the', 'ToLD-Br', 'corpus', '<ref type=""single"">(Leite et al., 2020).</ref>', 'It', 'has', 'twenty-one', 'thousand', 'annotated', 'tweets', 'as', 'either', 'toxic', 'or', 'non-toxic', 'language.', 'Also,', 'we', 'compared', 'our', 'strategy', 'with', 'different', 'graph-based', 'methods', 'and', 'with', 'transformerbased', 'methods.', 'Our', 'method', 'outperformed', 'all', 'graph-based', 'approaches', 'and', 'achieved', 'competitive', 'results', 'compared', 'to', 'transformer-based', 'methods,', 'using', 'only', '10%', 'of', 'labeled', 'nodes.']",16,"[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
768a8d46-0f9b-4364-8651-3864888b9003,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['Detecting online hate speech using context aware models'],['2017'],['Lei Gao;Ruihong Huang'],single,"['In', 'Figure', '4,', 'we', 'compare', 'our', 'dataset', 'with', 'other', 'toxicity', 'detection', 'datasets', 'using', 'the', 'metric', 'of', 'relative', 'frequency', 'of', 'toxic', 'utterances', 'of', 'each', 'length.', 'The', 'datasets', 'we', 'compare', 'with', 'are', '1)', 'Waseem', '<ref type=""single"">(Waseem and Hovy, 2016)</ref>', 'which', 'consists', 'of', '16.2k', 'tweets', 'binary', 'classified', 'as', 'racism/sexism', 'or', 'other,', '2)', 'FoxNews', '<ref type=""single"">(Gao and Huang, 2017)</ref>', 'which', 'is', '1.5k', 'sentences', 'from', 'Fox', 'News', 'discussion', 'threads', 'classified', 'as', 'hateful/non-', 'The', 'distribution', 'in', 'CONDA', 'is', 'different', 'to', 'the', 'other', 'datasets', 'in', 'that', 'the', 'toxic', 'utterances', 'are', 'shorter.', 'This', 'is', 'due', 'to', 'the', 'terseness', 'of', 'in-game', 'chat', 'during', 'playing,', 'with', 'longer', 'utterances', 'occurring', 'in', 'pregame', 'and', 'post-game', 'discussion.', 'Waseem', 'has', 'a', 'particular', 'distribution', 'due', 'to', 'the', 'character', 'limit', 'in', 'Twitter', '(140', 'characters', 'at', 'the', 'time).', 'FoxNews', 'and', 'StormfrontWS', 'are', 'forums', 'which', 'foster', 'the', 'use', 'of', 'longer', 'sentences.']",46,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
769cf682-9464-4f37-8347-0b5be3235e57,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,"['Semantic influences on parsing: Use of thematic role information in syntactic ambiguity resolution', 'Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension']","['1994', '1998']","['C John;unk Trueswell;K Michael;Susan Tanenhaus;unk Garnsey', 'Ken Mcrae;J Michael;Michael Spivey-Knowlton;unk Tanenhaus']",group,"['These', 'co-occurrence', 'probabilities', 'are', 'psycholinguistically', 'relevant', 'because', 'they', 'feed', 'into', 'information-theoretic', 'measures', 'of', ""'thematic"", ""fit'"", 'and', 'selectional', 'restriction', '<ref type=""group"">(Resnik, 1996, Lapata et al., 1999, Padó et al., 2007, Vecchi et al., 2017)</ref>', 'which', 'are', 'relevant', 'in', 'predicting', 'human', 'online', 'processing', 'difficulty', '(e.g.', '<ref type=""group"">McRae et al., 1998, Trueswell et al., 1994),</ref>', 'and', 'play', 'a', 'key', 'role', 'in', 'language', 'acquisition', '<ref type=""single"">(Erickson and Thiessen, 2015).</ref>', 'Most', 'prominently,', 'the', 'widely-used', 'pointwise', 'mutual', 'information', '(PMI)', 'measure', 'of', 'association', 'strength,', 'PMI', '(w,', 'c)', '=', 'log', 'p(w|c)', 'p(w)', '<ref type=""group"">(Fano, 1961, Church and Hanks, 1990),</ref>', 'relies', 'on', 'these', 'condi-tional', 'probabilities', 'as', 'an', 'input.', 'PMI', 'makes', 'appearances', 'in', 'models', 'of', 'grammar', 'induction', 'from', 'text', '(Magerman', 'and', '<ref type=""group"">Marcus, 1990, Yuret, 1998, Clark and Fijalkow, 2020, Hoover et al., 2021),</ref>', 'online', 'sentence', 'comprehension', 'and', 'production', '<ref type=""group"">(Futrell et al., 2020b, Ranjan et al., 2022),</ref>', 'and', 'quantitative', 'theories', 'of', 'word', 'order', 'variation', '<ref type=""group"">(Futrell et al., 2020a, Sharma et al., 2020).</ref>']",29,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
76a52b26-b465-484a-b1c5-87fa66db348f,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,"['Genitives, relational nouns, and the argument-modifier distinction', 'Possessive Descriptions, Dissertations in linguistics. Center for the Study of Language and Information', 'Functional concepts and frames', 'Uniformity vs. versatility: The genitive, a case study', 'The interpretation of relational nouns', 'Constructing a lexicon of relational nouns', 'unknown', 'unknown']","['2000', '1995', '2015', '1983', '1988', '2018', 'unknown', '1985']","['Barbara Partee;V Borschev', 'Christian Barker', 'Sebastian Löbner', 'Barbara Partee', 'Jos De Bruin;Remko Scha', 'Edward Newell;Jackie Cheung', 'unknown', 'Sebastian Loebner']",group,"['Our', 'departure', 'point', 'for', 'this', 'work', 'has', 'been', 'the', 'notion', 'of', 'an', 'implicit', 'argument', 'of', 'a', 'noun,', 'that', 'is,', 'nouns', 'such', 'as', ""''brother''"", 'or', ""''price''"", 'that', 'are', 'incomplete', 'on', 'their', 'own,', 'and', 'require', 'an', 'argument', 'to', 'be', 'complete.', 'In', 'linguistics,', 'these', 'are', 'referred', 'to', 'as', 'relational', 'nouns', '<ref type=""group"">(Partee, 1983 (Partee, /1997,, Loebner, 1985, Barker, 1995, De Bruin and Scha, 1988, Partee et al., 2000, Löbner, 2015, Newell and Cheung, 2018).</ref>', 'In', 'contrast,', 'nouns', 'like', ""''plant'',"", 'or', ""''sofa''"", 'are', 'called', 'sortal', 'and', 'are', 'conceived', 'as', ""''complete'',"", 'their', 'denotation', 'need', 'not', 'rely', 'on', 'the', 'relation', 'to', 'other', 'nouns,', 'and', 'can', 'be', 'fully', 'determined.']",47,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
76e77210-dfaf-4e5d-8feb-b0a89dcbf609,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,"['SQuAD: 100,000+ questions for machine comprehension of text']",['2016'],['Pranav Rajpurkar;Jian Zhang;Konstantin Lopyrev;Percy Liang'],single,"['The', 'performance', 'of', 'QA', 'models', 'are', 'evaluated', 'using', 'the', 'Exact', 'Match', '(EM)', 'and', 'F1', 'scores.', 'The', 'EM', 'score', 'is', 'the', 'percentage', 'of', 'system', 'outputs', 'that', 'match', 'exactly', 'with', 'the', 'ground', 'truth', 'answers.', 'The', 'F1', 'score', 'is', 'a', 'combined', 'measure', 'of', 'precision', 'and', 'recall', 'that', 'is', 'less', 'strict', 'than', 'EM.', 'The', 'evaluation', 'process', '3', 'involves', 'post-processing', 'identical', 'to', 'that', 'presented', 'by', ""d'Hoffschmidt"", 'et', 'al.', '(2020)', 'and', 'inspired', 'by', 'that', 'proposed', 'for', 'English', 'by', '<ref type=""single"">Rajpurkar et al. (2016),</ref>', 'which', 'consists', 'of', 'the', 'removal', 'of', 'punctuation', 'marks', 'and', 'determiners', '4', 'as', 'well', 'as', 'a', 'down-casing', 'of', 'the', 'answers', '(ground', 'truths', 'and', 'predictions).']",72,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
76fcdf32-b5e3-498e-b572-02d380e31df5,Entity Attribute Relation Extraction with Attribute-Aware Embeddings,2020,Dan Iter;Xiao Yu;Fangtao Li,"['The Structure of Language', 'A general framework for distributional similarity']","['1954', '2003']","['S Zellig;unk Harris', 'Julie Weeds;David Weir']",group,"['The', 'key', 'insight', 'of', 'this', 'paper', 'is', 'that', 'entities', 'that', 'share', 'many', 'attributes', 'are', 'often', 'similar.', 'This', 'is', 'an', 'extension', 'of', 'the', 'distributional', 'hypothesis,', '<ref type=""group"">(Harris, 1954, Weeds and Weir, 2003),</ref>', 'which', 'states', 'that', 'words', 'with', 'similar', 'semantic', 'meanings', 'tend', 'to', 'appear', 'in', 'similar', 'contexts,', 'and', 'builds', 'on', 'work', 'that', 'use', 'referential', 'attributes', 'to', 'estimate', 'semantic', 'relatedness', '<ref type=""group"">(Gupta et al., 2015, Freitas et al., 2013).</ref>', 'For', 'the', 'attribute-aware', 'embeddings,', 'we', 'argue', 'that', 'a', 'good', 'representation', 'for', 'an', 'entity', 'can', 'be', 'inferred', 'from', 'its', 'most', 'common', 'attributes,', 'which', 'we', 'may', 'have', 'access', 'to', 'from', 'an', 'external', 'source', 'of', 'knowledge.', 'In', 'Figure', '1,', 'we', 'want', 'to', 'classify', 'two', 'candidate', 'relations', 'given', 'the', 'other', 'known', 'relations.']",24,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
776304f3-d01b-45e9-977c-70eaa7d7ad46,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,['Captum: A unified and generic model interpretability library for pytorch'],['2020'],['Narine Kokhlikyan;Vivek Miglani;Miguel Martin;Edward Wang;Bilal Alsallakh;Jonathan Reynolds;Alexander Melnikov'],single,"['We', 'use', 'Integrated', 'Gradients', '<ref type=""single"">(Sundararajan et al., 2017)</ref>', 'from', 'the', 'Captum', '<ref type=""single"">(Kokhlikyan et al., 2020)</ref>', 'library', 'for', 'qualitative', 'analysis', 'of', 'predictions', 'for', 'the', 'SpanBERT-SP,', 'and', 'the', 'RoBERTa-TC', 'models.', 'We', 'calculate', 'Integrated', 'Gradients', 'of', 'the', 'targets', 'with', 'respect', 'to', 'the', 'embedding', 'layer', 'outputs.', 'The', 'Riemann', 'Right', 'numerical', 'approximation', 'method', 'is', 'used,', 'with', 'n', 'steps=50.', 'Following', '<ref type=""single"">Ramnath et al. (2020),</ref>', 'we', 'calculate', 'token-wise', 'importance', 'distributions', 'and', 'word-wise', 'distributions', 'for', 'a', 'few', 'examples.', 'We', 'refer', 'the', 'paper', 'to', 'the', 'reader', 'for', 'more', 'details.']",8,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
77b7e195-be5d-4bc6-b8fd-5015586c56d4,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Parameter-efficient transfer learning for nlp'],['2019'],['Neil Houlsby;Andrei Giurgiu;Stanislaw Jastrzebski;Bruna Morrone;Quentin De Laroussilhe;Andrea Gesmundo;Mona Attariyan;Sylvain Gelly'],single,"['Another', 'axis', 'of', 'development', 'concerns', 'the', 'use', 'of', 'neural', 'architecture', 'search', '<ref type=""single"">(Elsken et al., 2019)</ref>', 'which', 'allows', 'to', 'optimize', 'a', 'model', 'by', 'progressively', 'modifying', 'the', 'design', 'of', 'the', 'network', 'through', 'trial', 'and', 'error,', 'eliminating', 'insignificant', 'operations.', 'To', 'avoid', 'the', 'unnecessary', 'large', 'number', 'of', 'parameters,', 'adapters', '<ref type=""single"">(Houlsby et al., 2019)</ref>', 'were', 'introduced', 'to', 'allow', 'fine-tuning', 'of', 'the', 'set', 'of', 'parameters', 'specific', 'to', 'the', 'task', 'of', 'interest', 'rather', 'than', 'the', 'entire', 'model.']",42,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
77edba3c-fd0d-4b9e-b680-d7246dc33749,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,"[""Poor man's bert: Smaller and faster transformer models""]",['2020'],['Hassan Sajjad;Fahim Dalvi;Nadir Durrani;Preslav Nakov'],single,"['We', 'evaluate', 'these', 'experiments', 'both', 'on', 'the', 'Transformer', 'and', 'BERT', 'models.', 'Our', 'results', 'show', 'that', 'a', 'large', 'fraction', 'of', 'attention', 'heads', 'can', 'be', 'pruned', 'randomly:', '75%', 'of', 'the', 'attention', 'heads', 'of', 'Transformer', 'can', 'be', 'randomly', 'pruned', 'with', 'a', 'drop', 'of', 'less', 'than', '1', 'BLEU', 'point', 'on', 'NMT', 'tasks.', 'Similarly,', 'half', 'of', 'the', 'attention', 'heads', 'of', 'BERT', 'can', 'be', 'randomly', 'pruned', 'with', 'an', 'average', 'drop', 'in', 'accuracy', 'of', 'less', 'than', '1%', 'across', 'a', 'chosen', 'set', 'of', 'GLUE', 'tasks', '1.', 'Significantly', 'for', 'Transformers,', 'we', 'find', 'no', 'evidence', 'for', 'pruning', 'methods', 'preferring', 'specific', 'attention', 'heads', 'based', 'on', 'their', 'location,', 'even', 'when', 'the', 'locations', 'are', 'chosen', 'to', 'match', 'attention', 'heads', 'identified', 'to', 'be', 'more', 'important', 'in', 'existing', 'studies.', 'Similarly', 'on', 'the', 'BERT', 'model,', 'pruning', 'top', 'and', 'bottom', 'layers', 'do', 'not', 'show', 'significant', 'difference,', 'even', 'though', 'existing', 'studies', 'attribute', 'higher', 'importance', 'to', 'the', 'latter', '<ref type=""single"">(Sajjad et al., 2020).</ref>', 'However,', 'we', 'identify', 'a', 'preference', 'to', 'avoid', 'pruning', 'the', 'middle', 'layers', 'and', 'consecutive', 'layers.', 'Lastly,', 'we', 'check', 'if', 'during', 'fine-tuning', 'certain', 'heads', 'compensate', 'more', 'for', 'the', 'pruned', 'heads.', 'If', 'so,', 'such', 'heads', 'would', 'perhaps', 'be', 'more', 'important.', 'However,', 'we', 'find', 'no', 'such', 'evidence.', 'In', 'particular,', 'during', 'fine-tuning,', 'the', 'un-pruned', 'heads', 'change', 'similarly', 'across', 'most', 'pruning', 'configurations.', 'Overall,', 'our', 'experiments', 'suggest', 'that', 'interpretation', 'of', 'attention', 'heads', 'does', 'not', 'strongly', 'inform', 'pruning.', 'The', 'rest', 'of', 'the', 'paper', 'is', 'organized', 'as', 'follows:', 'Section', '2', 'mentions', 'about', 'the', 'models', 'and', 'the', 'datasets', 'used', 'for', 'this', 'work', 'followed', 'by', 'Section', '3', 'which', 'provides', 'details', 'of', 'the', 'experimental', 'process.', 'This', 'section', 'reports', 'results', 'on', 'both', 'Transformer', 'and', 'BERT', 'models.', 'We', 'summarize', 'our', 'work', 'in', 'Section', '4.']",139,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
78664403-8a6d-4a13-9c4f-7cbc5bb63e6e,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,"['Mixture models for diverse machine translation: Tricks of the trade', 'unknown', 'Mixture content selection for diverse sequence generation']","['2019', 'unknown', '2019']","[""Tianxiao Shen;Myle Ott;Michael Auli;Marc'aurelio Ranzato"", 'unknown', 'Jaemin Cho;Minjoon Seo;Hannaneh Hajishirzi']",group,"['Existing', 'diversity-promoting', 'methods', 'only', 'varied', 'the', 'language', 'styles', 'and', 'failed', 'to', 'perform', 'different', 'knowledge', 'reasoning', 'to', 'generate', 'diverse', 'contents', '<ref type=""group"">(Cho et al., 2019, Shen et al., 2019, Holtzman et al., 2020).</ref>', 'Here,', 'incorporating', 'commonsense', 'KG', 'is', 'essential', 'for', 'the', 'generative', 'reasoning', '(GR)', 'tasks', 'because', 'the', 'KG', 'cannot', 'only', 'augment', 'the', 'limited', 'information', 'in', 'the', 'input', 'text,', 'but', 'also', 'provide', 'a', 'rich', 'searching', 'space', 'for', 'knowledge', 'reasoning.', 'Therefore,', 'we', 'propose', 'to', 'employ', 'commonsense', 'KG', 'to', 'play', 'the', 'central', 'role', 'of', 'performing', 'diverse', 'knowledge', 'reasoning,', 'then', 'use', 'different', 'sets', 'of', 'selected', 'concepts', 'to', 'produce', 'diverse', 'outputs.']",19,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
78698375-e636-4cf9-9226-ea2d2ab57957,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,['Sequence prediction exploiting similarity information'],['2007'],['István Bíró;Zoltán Szamonek;Csaba Szepesvári'],single,"['Distributional', 'similarity', 'information', 'has', 'been', 'used', 'to', 'improve', 'modeling', 'of', 'word', 'co-occurrence', 'probabilities', 'in', 'previous', 'work.', '<ref type=""group"">Dagan et al. (1994 Dagan et al. ( , 1999) )</ref>', 'defined', 'a', 'kernel-based', 'interpolated', 'language', 'model', 'where', 'probability', 'mass', 'is', 'explicitly', 'spread', 'over', 'similar', 'words,', 'with', 'variant', 'models', 'along', 'these', 'lines', 'found', 'in', '<ref type=""single"">Wang et al. (2005)</ref>', 'and', 'Yarlett', '<ref type=""single"">(2008).</ref>', 'These', 'models', 'leverage', 'similarity', 'information', 'about', 'target', 'words', 'but', 'not', 'context', 'words.', 'In', 'contrast,', '<ref type=""single"">Bíró et al. (2007)</ref>', 'proposed', 'a', 'method', 'which', 'uses', 'similarity', 'information', 'about', 'the', 'context', 'word', 'but', 'not', 'the', 'target', 'word.', '<ref type=""single"">Toutanova et al. (2004)</ref>', 'developed', 'a', 'method', 'that', 'can', 'exploit', 'similarity', 'information', 'about', 'both', 'target', 'and', 'context,', 'using', 'a', 'Markov', 'Chain', 'algorithm', 'incorporating', 'distributional', 'and', 'WordNet', 'similarities.', 'None', 'of', 'this', 'previous', 'work', 'derived', 'word', 'similarity', 'information', 'from', 'pretrained', 'embeddings,', 'because', 'such', 'embeddings', 'did', 'not', 'exist', 'at', 'the', 'time.']",58,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
78a1cfaa-566e-4d7f-b70a-e8e30e6fa66d,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,"['Exploring classic and neural lexical translation models for information retrieval: Interpretability, effectiveness, and efficiency benefits', 'unknown']","['2021', '2020']","['Leonid Boytsov;Zico Kolter', 'Leonid Boytsov;Eric Nyberg']",group,"['Translation-based', 'features', 'Capturing', 'semantic', 'relationships', 'between', 'a', 'query', 'and', 'a', 'document', 'is', 'also', 'crucial', 'to', 'improving', 'retrieval', 'accuracy.', 'To', 'incorporate', 'such', 'features,', 'we', 'can', 'use', 'a', 'translation', 'model', '<ref type=""group"">(Boytsov and Nyberg, 2020, Boytsov and Kolter, 2021)</ref>', 'to', 'measure', 'the', 'log', 'translation', 'probability', 'between', 'queries', 'and', 'documents.', 'The', 'conditional', 'probability', 'we', 'need', 'p(q|d', 'n)', 'is', 'generated', 'by', 'the', 'IBM', 'Model', '1', 'translation', 'model,', 'and', 'the', 'final', 'query-document', 'feature', 'is', 'the', 'sum', 'of', 'all', 'individual', 'conditional', 'query', 'probabilities.']",28,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
78bf0a46-4a12-491a-833c-c17715bd0ea5,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,"['Building competitive direct acoustics-to-word models for english conversational speech recognition', 'Endto-end named entity and semantic concept extraction from speech']","['2018', '2018']","['K Audhkhasi;B Kingsbury;B Ramabhadran;G Saon;M Picheny', 'S Ghannay;A Caubrière;Y Estève;N Camelin;E Simonnet;A Laurent;E Morin']",group,"['Another', 'option', 'for', 'using', 'O2O', 'models', 'is', 'to', 'output', 'multiple', 'sequences', 'as', 'a', 'single', 'sequence', 'instead', 'of', 'using', 'conditional', 'chain', 'mapping,', 'as', 'shown', 'in', 'Fig.', '1(c).', 'For', 'example,', 'in', '<ref type=""single"">(Audhkhasi et al., 2018),</ref>', 'the', 'O2O', 'model', 'produces', 'word', 'transcripts', 'by', 'first', 'generating', 'a', ""word's"", 'constituent', 'graphemes', 'followed', 'by', 'the', 'word', 'itself.', 'Another', 'application,', 'explored', 'in', '<ref type=""single"">(Shafey et al., 2019)</ref>', 'used', 'the', 'O2O', 'model', 'to', 'produce', 'graphemes', 'followed', 'by', 'speaker', 'role.', 'This', 'approach', 'is', 'the', 'simplest', 'to', 'implement', 'because', 'we', 'can', 'reuse', 'the', 'neural', 'network', 'architecture', 'used', 'to', 'produce', 'the', 'primary', 'sequence', 'to', 'sequence', 'mapping', 'to', 'produce', 'the', 'secondary', 'label', 'sequence', '(e.g.,', 'connectionist', 'temporal', 'classification', '(CTC)', 'based', 'systems).', 'In', 'contrast', 'to', 'the', 'previous', 'two', 'approaches,', 'the', 'O2O', 'model', 'does', 'not', 'require', 'postprocessing', 'to', 'align', 'the', 'label', 'sequences', 'during', 'inference', 'since', 'the', 'output', 'sequence', 'preserves', 'the', 'alignment', 'between', 'the', 'word', 'and', 'corresponding', 'annotation', 'labels,', 'alignment', 'is', 'only', 'needed', 'for', 'the', 'data', 'preparation', 'stage', 'during', 'training', 'to', 'produce', 'the', 'appropriate', 'target', 'sequences.', 'For', 'this', 'reason,', 'we', 'used', 'the', 'O2O', 'model', 'in', 'this', 'study.', 'This', 'paper', 'proposes', 'to', 'use', 'a', 'state-of-the-art', 'Transformer-based', 'E2E', 'ASR', 'system', '<ref type=""single"">(Karita et al., 2019)</ref>', 'for', 'the', 'O2O', 'model', 'with', 'a', 'single', 'sequence,', 'instead', 'of', 'CTC-based', 'approaches', 'which', 'are', 'frequently', 'supported', '<ref type=""group"">(Audhkhasi et al., 2018, Ghannay et al., 2018).</ref>', 'Compared', 'with', 'the', 'CTC-based', 'systems,', 'this', 'approach', 'can', 'explicitly', 'model', 'the', 'relationship', 'between', 'the', 'output', 'labels', 'thanks', 'to', 'the', 'autoregressive', 'decoder', 'network,', 'similar', 'to', 'the', 'conditional', 'chain', 'rule', 'model', 'in', 'Fig.', '1(b).', 'We', 'also', 'demonstrate', 'improved', 'performance', 'compared', 'to', 'the', 'CTC-based', 'systems.', 'Another', 'contribution', 'is', 'that', 'we', 'conducted', 'an', 'extensive', 'empirical', 'evaluation', 'to', 'analyze', 'and', 'demonstrate', 'the', 'utility', 'of', 'our', 'approach.', 'For', 'example,', 'we', 'applied', 'the', 'method', 'to', 'English', 'and', 'Japanese', 'ASR', 'tasks', 'in', 'which', 'phonemic', 'transcripts', 'and', 'POS', 'tags', 'are', 'simultaneously', 'produced.', 'Our', 'approach', 'predicts', 'linguistic', 'annotations', 'correctly', 'even', 'though', 'corresponding', 'graphemes', 'are', 'wrong,', 'while', 'the', 'pipeline', 'approach,', 'in', 'which', 'NLP-based', 'methods', 'are', 'applied', 'to', 'a', 'hypothesized', 'ASR', 'transcript,', 'fails.', 'This', 'feature', 'is', 'helpful', 'for', 'the', 'downstream', 'NLP', 'system', 'like', 'slot', 'filling', 'or', 'intent', 'detection.', 'Besides,', 'our', 'approach', 'is', 'suitable', 'for', 'on-device', 'applications', 'because', 'the', 'E2E', 'model', 'archives', 'small-footprint', 'prediction', '<ref type=""single"">(Pang et al., 2018).</ref>', 'Note', 'that', 'our', 'primary', 'goal', 'is', 'to', 'provide', 'aligned', 'transcripts', 'and', 'linguistic', 'annotations', 'with', 'minimal', 'degradation', 'in', 'ASR', 'performance.', 'We', 'are', 'not', 'aiming', 'to', 'improve', 'ASR', 'performance.', 'The', 'features', 'of', 'the', 'proposed', 'method', 'are', 'summarized', 'as', 'follows:']",192,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
78e20995-f5d1-4e7c-b46f-a630a4e901e6,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Transformers: State-of-the-art natural language processing'],['2020'],['Thomas Wolf;Lysandre Debut;Victor Sanh;Julien Chaumond;Clement Delangue;Anthony Moi;Pierric Cistac;Tim Rault;Rmi Louf;Morgan Funtowicz;Joe Davison;Sam Shleifer;Clara Patrick Von Platen;Yacine Ma;Julien Jernite;Canwen Plu;Teven Xu;Sylvain Scao;Mariama Gugger;Quentin Drame;Alexander Lhoest;unk Rush'],single,"['All', 'models', 'use', 'the', 'SHIBA', 'implementation', 'of', 'CA-NINE', '<ref type=""single"">(Tanner and Hagiwara, 2021).</ref>', 'SHIBA', 'was', 'designed', 'for', 'use', 'on', 'the', 'Japanese', '[jpn]', 'language,', 'which', 'does', 'not', 'include', 'spaces', 'between', 'its', 'characters', '(similar', 'to', 'our', 'phonetic', 'representations', 'without', 'word', 'boundaries).', 'We', 'used', 'the', 'default', 'hyperparameter', 'settings', 'for', 'SHIBA', 'pre-training', 'and', 'finetuning,', 'because', 'we', 'are', 'primarily', 'concerned', 'with', 'the', 'relative', 'impact', 'of', 'various', 'combinations', 'of', 'pretraining', 'data', 'on', 'the', 'downstream', 'NER', 'tasks.', 'We', 'use', 'the', 'Hugging', 'Face', 'transformers', 'library', '<ref type=""single"">(Wolf et al., 2020)</ref>', 'to', 'train', 'all', 'models.']",73,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2]"
7916c898-1260-4995-ba15-95fe15dc3ad6,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Towards hierarchical importance attribution: Explaining compositional semantics for neural sequence models'],['2020'],['Xisen Jin;Junyi Du;Zhongyu Wei;Xiangyang Xue;Xiang Ren'],single,"['We', 'compare', 'with', 'the', 'following', 'baselines', 'that', 'do', 'not', 'consider', 'conditioned', 'generation:', '(1)', 'Seqto-Seq', '<ref type=""single"">(Budzianowski et al., 2018)</ref>', 'implemented', 'based', 'on', 'transformer', '<ref type=""single"">(Vaswani et al., 2017),</ref>', '(2)', 'TSCP', '<ref type=""single"">(Lei et al., 2018),</ref>', 'and', 'two', 'baselines', 'that', 'adopt', 'latent', 'action', 'learning', 'for', 'conditioned', 'generation:', '(3)', 'LaRL', '<ref type=""single"">(Zhao et al., 2019),</ref>', '(4)', 'MALA', '<ref type=""single"">(Huang et al., 2020a).</ref>', 'Note', 'that', 'for', 'these', 'two', 'approaches,', 'we', 'experiment', 'with', 'both', 'discrete', 'and', 'continuous', 'latent', 'action', 'representations.', 'We', 'also', 'compare', 'the', 'full', 'model', 'MASP', 'with', 'its', 'two', 'variants:', '(1)', 'Post-hoc', 'Saliency', 'obtains', 'action', 'representations', 'via', 'the', 'importance', 'attribution', 'technique', 'as', '<ref type=""single"">Jin et al. (2020),</ref>', '(2)', 'Memory-based', 'Saliency', 'employs', 'the', 'same', 'memory', 'component', 'as', 'MASP', 'but', 'trained', 'without', 'the', 'pseudo', 'parallel', 'corpus.']",79,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
794f8d7f-63d2-4134-8977-927b0e7ef557,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,['Wic: the word-in-context dataset for evaluating context-sensitive meaning representations'],['2019'],['Mohammad Taher Pilehvar;Jose Camacho-Collados'],single,"[""Words'"", 'semantics', 'have', 'a', 'dynamic', 'nature', 'which', 'depends', 'on', 'the', 'surrounding', 'context', '<ref type=""single"">(Pilehvar and Camacho-Collados, 2019).</ref>', 'Therefore,', 'the', 'majority', 'of', 'words', 'tends', 'to', 'be', 'polysemous', '(i.e.', 'have', 'multiple', 'senses).', 'For', 'few', 'examples,', 'words', 'such', 'as', '""cell"",', '""bank""', 'and', '""report""', 'can', 'be', 'mentioned.', 'Due', 'to', 'this', 'nature', 'in', 'natural', 'language,', 'it', 'is', 'important', 'to', 'focus', 'on', 'word-in-context', 'sense', 'while', 'extracting', 'the', 'meaning', 'of', 'a', 'word', 'which', 'appeared', 'in', 'a', 'text', 'segment.', 'Also,', 'this', 'is', 'a', 'critical', 'requirement', 'to', 'many', 'applications', 'such', 'as', 'question', 'answering,', 'document', 'summarisation,', 'information', 'retrieval', 'and', 'information', 'extraction.']",12,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
796e9c48-ebb3-49bb-9cc7-a34a3d257a01,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['Measuring and mitigating unintended bias in text classification'],['2018'],['Lucas Dixon;John Li;Jeffrey Sorensen;Nithum Thain;Lucy Vasserman'],single,"['We', 'experiment', 'with', 'the', 'validation', 'split', 'on', 'a', 'single', 'RTX', '3090,', 'and', 'measure', 'the', 'average', 'running', 'time', 'per', 'example.', 'As', 'shown', 'in', 'Table', '6,', 'SO-Beam', 'runs', 'faster', 'than', 'SO-Enum', 'since', 'it', 'utilizes', 'the', 'probability', 'output.', 'The', 'running', 'time', 'may', 'increase', 'if', 'the', 'model', 'has', 'improved', 'second-order', 'robustness.', 'A.4', 'Additional', 'Results', 'on', 'Protected', 'Tokens', 'Fig.', '7', 'presents', 'the', 'experimental', 'results', 'with', 'additional', 'protected', 'tokens', 'such', 'as', 'nationality,', 'religion,', 'and', 'sexual', 'orientation', '(from', 'Ribeiro', 'et', 'al.', '(2020)).', 'We', 'use', 'the', 'same', 'base', 'LSTM', 'as', 'described', 'in', '§4.2.', 'One', 'interesting', 'observation', 'is', 'when', 'p', '=', '(gay,', 'straight)', 'where', 'the', 'bias', 'is', 'negative,', 'indicating', 'that', 'the', 'sentiment', 'classifier', 'tends', 'to', 'give', 'more', 'negative', 'prediction', 'when', 'substituting', 'gay', '→', 'straight', 'in', 'the', 'input.', 'This', 'phenomenon', 'is', 'opposite', 'to', 'the', 'behavior', 'of', 'toxicity', 'classifiers', '<ref type=""single"">(Dixon et al., 2018),</ref>', 'and', 'we', 'hypothesize', 'that', 'it', 'may', 'be', 'caused', 'by', 'the', 'different', 'distribution', 'of', 'training', 'data.', 'To', 'verify', 'the', 'hypothesis,', 'we', 'count', 'the', 'number', 'of', 'training', 'examples', 'containing', 'each', 'word,', 'and', 'observe', 'that', 'we', 'have', 'far', 'more', 'negative', 'examples', 'than', 'positive', 'examples', 'among', 'those', 'containing', 'straight', '(Table', '7).', 'After', 'looking', 'into', 'the', 'training', 'set,', 'it', 'turns', 'out', 'that', 'straight', 'to', 'video', 'is', 'a', 'common', 'phrase', 'to', 'criticize', 'a', 'film,', 'thus', 'the', 'classifier', 'incorrectly', 'correlates', 'straight', 'with', 'negative', 'sentiment.', 'This', 'also', 'reveals', 'the', 'limitation', 'of', 'our', 'method', 'on', 'polysemous', 'words.', 'In', 'Fig.', '8,', 'we', 'measure', 'the', 'bias', 'on', 'X', 'test', 'and', 'observe', 'positive', 'bias', 'on', 'most', 'tokens', 'for', 'both', 'k', '=', '0', 'and', 'k', '=', '3,', 'which', 'indicates', 'that', 'the', 'model', '""tends""', 'to', 'make', 'more', 'positive', 'predictions', 'for', 'examples', 'containing', 'certain', 'female', 'pronouns', 'than', 'male', 'pro-', 'nouns.', 'Notice', 'that', 'even', 'though', 'gender', 'swap', 'mitigates', 'the', 'bias', 'to', 'some', 'extent,', 'it', 'is', 'still', 'difficult', 'to', 'fully', 'eliminate', 'the', 'bias.', 'This', 'is', 'probably', 'caused', 'by', 'tuples', 'like', '(him,', 'his,', 'her)', 'which', 'cannot', 'be', 'swapped', 'perfectly,', 'and', 'requires', 'additional', 'processing', 'such', 'as', 'part-of-speech', 'resolving', '<ref type=""single"">(Zhao et al., 2018a).</ref>', 'To', 'help', 'evaluate', 'the', 'naturalness', 'of', 'our', 'constructed', 'examples', 'used', 'in', '§4,', 'we', 'provide', 'sample', 'sentences', 'in', 'Table', '9', 'and', 'Table', '10.', 'Bold', 'words', 'are', 'the', 'corresponding', 'patch', 'words', 'p,', 'taken', 'from', 'the', 'predefined', 'list', 'of', 'gendered', 'pronouns.']",128,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7996be5b-46a4-4a39-9ed3-603f91d7b8f9,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['A meta-level grammar: redefining Synchronous TAG for translation and paraphrase'],['1999'],['M Dras'],single,"['Paraphrase', 'Here', 'we', 'use', 'an', 'example,', '(4),', 'from', '<ref type=""single"">Dras (1999),</ref>', 'where', 'paraphrases', 'are', 'represented', 'by', 'pairing', 'TAG', 'derivation', 'trees', '(Figure', '5).', 'This', 'is', 'again', 'similar', 'to', 'the', 'previous', 'MT', 'examples:', 'in', 'order', 'to', 'define', 'a', 'paraphrase', 'where', 'the', 'most', 'embedded', 'clause', 'becomes', 'a', 'separate', 'sentence,', 'it', 'is', 'necessary', 'to', 'form', 'a', 'gNCN', '(those', 'nodes', 'in', 'bold', 'in', 'Figure', '5).']",8,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
79a2f9e8-9b64-4e34-b4a4-7668862dc5c5,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,['A unified MRC framework for named entity recognition'],['2020'],['Xiaoya Li;Jingrong Feng;Yuxian Meng;Qinghong Han;Fei Wu;Jiwei Li'],single,"['Lee', 'and', 'Na', '(2022)', '(JBNU-CCLab)', 'achieved', 'their', 'state-of-the-art', 'performance', 'using', 'SciBERT', '<ref type=""single"">(Beltagy et al., 2019).</ref>', 'Their', 'entity', 'model', 'consists', 'of', 'an', 'MRC-based', 'model', '<ref type=""single"">(Li et al., 2020),</ref>', 'simplifying', 'the', 'tasks', 'as', 'binary', 'classification', 'problems', 'whether', 'span', 'is', 'valid', 'using', 'entity', 'type', 'information', 'as', 'input', 'features.', 'They', 'proposed', 'a', 'simple', 'rule-based', 'Symbol', 'Tokenizer', 'to', 'predict', 'accurately', 'the', 'complex', 'symbols', 'appearing', 'in', 'scientific', 'documents.', 'The', 'relation', 'model', 'exploits', 'entity', 'span', 'information', 'and', 'entity', 'type', 'information', 'as', 'input', 'features', 'using', 'typed', 'entity', 'marker.', 'Additionally,', 'the', 'paper', 'ex-ploited', 'many', 'regularization', 'techniques', 'to', 'improve', 'the', 'model', 'performance', 'such', 'as', 'regularized', 'dropout', '<ref type=""single"">(Wu et al., 2021)</ref>', 'and', 'representational', 'collapse', 'prevention', '<ref type=""single"">(Aghajanyan et al., 2020)</ref>', 'and', 'traditional', 'ensemble', 'techniques.']",20,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
79d3482f-d9d9-47a5-814f-532bd4ab19c5,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['LT@Helsinki at SemEval-2020 Task 12: Multilingual or language-specific BERT?'],['2020'],['Marc Pàmies;Emily Öhman;Kaisla Kajava;Jörg Tiedemann'],single,"['After', 'the', 'annotations', 'were', 'extracted', 'from', 'the', 'database,', 'the', 'data', 'needed', 'to', 'be', 'cleaned', 'up.', 'The', 'different', 'evaluations', 'required', 'different', 'pre-processing', 'steps.', 'Most', 'commonly,', 'this', 'included', 'the', 'removal', 'of', 'superfluous', 'characters', 'containing', 'no', 'information.', 'We', 'tried', 'to', 'keep', 'as', 'much', 'of', 'the', 'original', 'information', 'as', 'possible,', 'including', 'keeping', 'offensive,', 'racist,', 'and', 'sexist', 'language', 'as', 'is.', 'If', 'such', 'information', 'is', 'removed,', 'the', 'usefulness', 'of', 'the', 'data', 'is', 'at', 'risk', 'of', 'being', 'reduced,', 'particularly', 'when', 'used', 'for', 'e.g.', 'offensive', 'language', 'detection', '<ref type=""single"">(Pàmies et al., 2020).</ref>']",79,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]"
79d402b3-1249-4691-a298-1d59bee993c4,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Statistically-Driven Computer Grammars of English: The IBM/ Lancaster Approach'],['1993'],['E Black;R Garside;G Leech'],single,"['Accurate', 'enough', 'parse', 'selection', 'for', 'practical', 'applications', 'will', 'require', 'a', 'more', 'lexic.', 'alised', 'system.', '<ref type=""single"">Magerman\'s ( 1995)</ref>', 'parser', 'is', 'an', 'extension', 'of', 'the', 'history-based', 'parsing', 'approach', 'devel', 'oped', 'at', 'IBM', '(e.g.', '<ref type=""single"">Black, 1993)</ref>', 'in', 'which', 'rules', 'are', 'conditioned', 'on', 'lexical', 'and', 'other', '(essentially', 'arbitrary)', 'information', 'available', 'in', 'the', 'parse', 'history.', 'In', 'future', 'work,', 'we', 'intend', 'to', 'explore', 'a', 'more', 'restricted', 'and', 'semantically-driven', 'version', 'of', 'this', 'approach', 'in', 'which,', 'firstly,', 'probabilities', 'are', 'associated', 'with', 'different', 'subcategorisation', 'possibilities,', 'and', 'secondly,', 'alternative', 'predicate', 'argument', 'structures', 'derived', 'from', 'the', 'grammar', 'are', 'ranked', 'probabilistically.', 'However,', 'the', 'mas', 'sively', 'increased', 'coverage', 'obtained', 'here', 'by', 'relaxing', 'subcategorisation', 'constraints', 'underlines', 'the', 'need', 'to', 'acquire', 'accurate', 'and', 'complet�', 'subcategorisation', 'frames', 'in', 'a', 'corpus-driven', 'fas', 'hion,', 'before', 'such', 'constraints', 'can', 'be', 'exploited', 'robustly', 'and', 'effectively', 'with', 'free', 'text.']",29,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7a50d6ed-fbff-4e1b-b5db-cb53f68fd79f,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['Organisation du lexique-grammaire des verbes français'],['1990'],['Christian Leclerc'],single,"['In', 'this', 'paper', 'we', 'have', 'presented', 'a', 'more', 'fine-grained', 'analysis', 'of', 'the', 'Levin', 'classes', 'which', 'highlights', 'the', 'semantic', 'components', 'entailed', 'by', 'certain', 'syntactic', 'frames,', 'and', 'hence', 'the', 'semantic', 'components', 'of', 'entire', 'classes', 'of', 'verbs.', 'We', 'hypothesize', 'that', 'the', 'semantic', 'components', 'we', 'are', 'identifying', 'will', 'be', 'useful', 'for', 'cross-linguistic', 'generalizations.', 'An', 'important', 'avenue', 'of', 'future', 'research', 'which', 'we', 'intend', 'to', 'explore', 'is', 'the', 'comparison', 'of', 'the', 'translations', 'of', 'these', 'classes', 'to', 'independently-defined', 'classes', 'in', 'other', 'languages,', 'such', 'as', 'French', 'verb', 'classes', '<ref type=""single"">[7]</ref>', 'or', 'European', 'WordNet.', '3', 'These', 'cross-linguistic', 'generalizations', 'will', 'be', 'equally', 'valuable', 'for', 'both', 'transfer-based', 'and', 'interlinguabased', 'approaches', 'to', 'machine', 'translation.', 'Presumably', 'both', 'approaches', 'need', 'to', 'be', 'augmented', 'with', 'pragmatic', 'information', 'about', 'tense', 'and', 'aspect', 'and', 'information', 'structure,', 'in', 'particular', 'coreference,', 'in', 'order', 'to', 'provide', 'an', 'adequate', 'basis', 'for', 'translation', 'in', 'many', 'circumstances.', 'It', 'could', 'be', 'argued', 'that', 'a', 'language-specific', 'predicate-argument', 'structure', 'will', 'lend', 'itself', 'more', 'readily', 'to', 'language-specific', 'pragmatic', 'annotation', 'than', 'a', 'language-independent', 'one,', 'but', 'it', 'would', 'still', 'be', 'necessary', 'to', 'ensure', 'that', 'the', 'pragmatic', 'annotation', 'was', 'meaningful', 'in', 'the', 'target', 'languages', 'as', 'well,', 'i.e.,', 'cross-linguistic.', 'The', 'discovery', 'of', 'cross-linguistic', 'pragmatic', 'features', 'is', 'an', 'equally', 'important', 'area', 'for', 'future', 'research.']",80,"[0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7a57dee6-9911-4351-b4e1-eea1c98188b5,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['To', 'verify', 'that', 'the', 'plug-and-play', 'property', 'of', 'topk', 'attention', 'also', 'holds', 'at', 'self-attention', 'layers,', 'we', 'downloaded', 'a', 'BERT-large-uncased-whole-wordmasking', 'checkpoint', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'already', 'fine-tuned', 'on', 'SQuAD', 'v1', '<ref type=""single"">(Rajpurkar et al., 2016)</ref>', 'and', 'evaluated', 'its', 'performance', 'on', 'the', 'development', 'set', 'before', 'and', 'after', 'replacing', 'its', 'self-attention', 'layers', 'with', 'top-k', 'attention.', 'For', 'k', 'as', 'low', 'as', '16', '(4%', 'of', 'input', 'length),', 'we', 'only', 'saw', 'a', 'minor', 'decrease', 'in', 'the', 'exact', 'match', 'scores', '(86.9', '→', '86.2).', 'Moreover,', 'to', 'empirically', 'verify', 'that', 'dense', 'approximations', 'of', 'vanilla', 'attention', '(Performer,', 'RFA,', 'etc)', 'indeed', 'require', 'corrective', 'pre-training,', 'we', 'repeated', 'the', 'measurement', 'using', 'Performer', 'attention', 'with', '256', 'features,', 'obtaining', 'a', 'score', 'of', '0.38.']",19,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7acdb690-770e-495e-80c1-fd548309f0f9,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['Counter-fitting word vectors to linguistic constraints'],['2016'],['Nikola Mrkšić;Ó Diarmuid;Blaise Séaghdha;Milica Thomson;Lina Gašić;Pei-Hao Rojas-Barahona;David Su;Tsung-Hsien Vandyke;Steve Wen;unk Young'],single,"['Given', 'an', 'input', 'sentence', 'x', '0,', 'we', 'want', 'to', 'find', 'patch', 'words', 'p', 'and', 'a', 'vulnerable', 'example', 'x0', 'such', 'that', 'f', '(x', '0', '⊕', 'p)', '=', 'f', '(x', '0', ').', 'Follow', '<ref type=""single"">Alzantot et al. (2018),</ref>', 'we', 'choose', 'p', 'from', 'a', 'predefined', 'list', 'of', 'counter-fitted', 'synonyms', '<ref type=""single"">(Mrkšić et al., 2016)</ref>', 'that', 'maximizes', '|f', 'soft', '(p', '(2))', '−', 'f', 'soft', '(p', '(1)', ')|.', 'Here', 'f', 'soft', '(x):', 'X', '→', '[0,', '1]', 'denotes', 'probability', 'output', '(e.g.,', 'after', 'the', 'softmax', 'layer', 'but', 'before', 'the', 'final', 'argmax),', 'f', 'soft', '(p', '(1))', 'and', 'f', 'soft', '(p', '(2))', 'denote', 'the', 'predictions', 'for', 'the', 'single', 'word,', 'and', 'we', 'enumerate', 'through', 'all', 'possible', 'p', 'for', 'x', '0.', 'Let', 'k', 'be', 'the', 'neighborhood', 'distance,', 'then', 'the', 'attack', 'is', 'equivalent', 'to', 'solving:x0', '=', 'argmax', 'x∈Neighbor', 'k', '(x', '0)', '|F', '(x,', 'p)|.(3)']",42,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7bc4421b-a0db-4f66-b331-dcdcd20aee8b,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,"['Differences in brain potentials to open and closed class words: class and frequency effects', 'Brain potentials elicited by words: word length and frequency predict the latency of an early negativity']","['2001', '1997']","['unk Thomas F Münte;M Bernardina;Helga Wieringa;Andras Weyerts;Mike Szentkuti;Sönke Matzke;unk Johannes', 'Lee Osterhout;Michael Bersick;Richard Mckinnon']",group,"['For', 'comparison', 'with', 'previous', 'research', '<ref type=""group"">(Osterhout et al., 1997, Münte et al., 2001),</ref>', 'we', 'decoded', 'word', 'length,', 'frequency', 'and', 'class', 'with', 'linear', 'SVMs', 'in', 'a', 'temporally-resolved', 'fashion', 'from', '0', 'to', '700', 'ms', 'poststimulus', 'EEG,', 'recorded', 'during', 'sentence', 'reading.']",5,"[2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
7be4ceed-0718-4acf-8859-a6b7a3ebec38,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['Multivariate pattern analysis for meg: A comparison of dissimilarity measures'],['2018'],['Matthias Guggenmos;Philipp Sterzer;Radoslaw Martin Cichy'],single,"['EEG', 'signals', 'were', 'extracted', 'from', '-100', 'to', '700', 'ms', 'relative', 'to', 'word', 'onset.', 'For', 'baseline', 'correction,', 'we', 'subtracted', 'the', 'channel-wise', 'mean', 'from', '-100', 'ms', 'to', '0', 'ms', 'from', 'the', 'evoked', 'post-stimulus', 'EEG', 'response', '([0', '700]', 'ms', 'separately', 'for', 'each', 'word,', 'see', 'Figure', '1).', 'EEG', 'data', 'were', 'spatially', 'multivariate', 'noise', 'normalised', 'using', 'the', 'noise', 'covariance', 'matrix', 'estimated', 'separately', 'for', 'each', 'target', 'class', '<ref type=""single"">(Guggenmos et al., 2018).</ref>', 'Each', 'EEG', 'trial', 'was', 'annotated', 'with', 'the', 'gold', 'part', 'of', 'speech', 'tags', 'of', 'the', 'current', 'and', 'subsequent', 'words,', 'their', 'word', 'lengths,', 'and', 'Zipf-logarithmic', 'frequency', 'scores', 'from', 'the', 'Python', 'package', 'WordFreq', '<ref type=""single"">(Speer et al., 2018).</ref>']",61,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7c17508d-7eaf-4cfd-9b7f-fcae91e3b7a3,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['GloVe: Global vectors for word representation'],['2014'],['Jeffrey Pennington;Richard Socher;Christopher Manning'],single,"['cosine', 'similarity', 'in', 'GloVe', '<ref type=""single"">(Pennington et al., 2014a),</ref>']",4,"[2, 2, 2, 1, 1]"
7cde2ed7-1480-4906-bd09-ace84e922784,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,"['Disentangling disentanglement in variational autoencoders', 'Benchmarks, algorithms, and metrics for hierarchical disentanglement', 'Disentangling by factorising', 'beta-vae: Learning basic visual concepts with a constrained variational framework', 'unknown', 'Understanding disentangling in β-vae']","['2019', '2021', '2018', '2017', 'unknown', '2018']","['Emile Mathieu;Tom Rainforth;Yee Whye Siddharth;unk Teh', 'Andrew Slavin Ross;Finale Doshi-Velez', 'Hyunjik Kim;Andriy Mnih', 'Irina Higgins;Loïc Matthey;Arka Pal;Christopher Burgess;Xavier Glorot;Matthew Botvinick;Shakir Mohamed;Alexander Lerchner', 'unknown', 'Christopher Burgess;Irina Higgins;Arka Pal;Loïc Matthey;Nick Watters;Guillaume Desjardins;Alexander Lerchner']",group,"['In', 'areas', 'such', 'as', 'image', 'processing,', 'the', 'same', 'question', 'has', 'been', 'receiving', 'a', 'lot', 'of', 'attention', 'and', 'inspired', 'a', 'wave', 'of', 'methods', 'for', 'learning', 'and', 'evaluating', 'unsupervised', 'representation', 'disentanglement', '<ref type=""group"">(Ross and Doshi-Velez, 2021, Mathieu et al., 2019, Kim and Mnih, 2018, Burgess et al., 2018, Higgins et al., 2018 Higgins et al., , 2017) )</ref>', 'and', 'creation', 'of', 'large', 'scale', 'datasets', '<ref type=""single"">(Dittadi et al., 2021).</ref>', 'It', 'has', 'been', 'argued', 'that', 'disentanglement', 'is', 'the', 'means', 'towards', 'representation', 'interpretability', '<ref type=""single"">(Mathieu et al., 2019),</ref>', 'generalization', '<ref type=""single"">(Montero et al., 2021),</ref>', 'and', 'robustness', '<ref type=""group"">(Bengio et al., 2013, Bengio, 2013).</ref>', 'However,', 'these', 'benefits', 'are', 'yet', 'to', 'be', 'realized', 'and', 'evaluated', 'in', 'text', 'domain.']",29,"[3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7d06ec80-091d-4a24-947d-012da3973b9b,Can Semantic Role Labeling Improve SMT?,2009,Dekai Wu;Pascale Fung,['Automatic labeling of semantic roles'],['2002'],['Daniel Gildea;Dan Jurafsky'],single,"['Semantic', 'parsers', 'analyze', 'a', 'sentence', 'with', 'the', 'aim', 'of', 'identifying', 'the', '""who', 'did', 'what', 'to', 'whom,', 'for', 'whom', 'or', 'what,', 'how,', 'where,', 'when,', 'and', 'why.""', 'Shallow', 'semantic', 'parsing', 'extracts', 'the', 'predicateargument', 'structure', 'of', 'verbs', 'in', 'a', 'sentence', 'based', 'on', 'the', 'syntactic', 'tree', 'of', 'that', 'sentence.', 'For', 'example,', 'the', 'predicate', 'argument', 'structure', 'of', 'the', 'verb', 'hold', 'in', 'Figure', '1', 'specifies', 'a', '""holding""', 'relation', 'between', 'both', 'sides', '(who)', 'and', 'meeting', '(what)', 'on', 'Sunday', '(when).', 'For', 'a', 'sentence', 'with', 'multiple', 'verbs,', 'there', 'can', 'be', 'multiple', 'predicate', 'argument', 'structures.', 'Shallow', 'semantic', 'parsing', 'systems', 'are', 'mostly', 'based', 'on', 'classifiers', 'that', 'learn', 'from', 'a', 'manually', 'annotated', 'semantic', 'corpus', '<ref type=""single"">(Gildea and Jurafsky (2002),</ref>', '<ref type=""single"">Pradhan et al. (2005)</ref>', ').', 'Following', 'the', 'publication', 'of', 'the', 'Proposional', 'Bank', '(PropBank)', '<ref type=""single"">(Palmer et al., 2005)</ref>', 'first', 'in', 'English,', 'then', 'in', 'Chinese,', 'it', 'has', 'been', 'possible', 'to', 'train', 'these', 'classifiers', 'to', 'perform', 'semantic', 'analysis', 'on', 'news', 'wire', 'type', 'of', 'texts.']",102,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7d355f51-680c-4191-8865-2cc817a607ec,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Resources and benchmark corpora for hate speech detection: a systematic review'],['2020'],['Fabio Poletto;Valerio Basile;Manuela Sanguinetti;Cristina Bosco;Viviana Patti'],single,"['To', 'deal', 'with', 'toxic', 'comments,', 'most', 'approaches', 'adopt', 'supervised-machine', 'learning', 'techniques', 'and', 'are', 'mainly', 'focused', 'on', 'the', 'English', 'language', '<ref type=""single"">(Poletto et al., 2020).</ref>', 'These', 'approaches', 'range', 'from', 'surface-level', 'features,', 'as', 'Bag-Of-Words', '<ref type=""single"">(Paiva et al., 2019),</ref>', 'linguistics', 'features,', 'as', 'Part-Of-Speech', 'information', '<ref type=""single"">(Chen et al., 2012),</ref>', 'deep', 'neural', 'networks,', 'as', 'Long', 'Short-Term', 'Memory', '(LSTM)', '<ref type=""single"">(Fortuna et al., 2019)</ref>', 'and', 'Convolutional', 'Neural', 'Networks', '(CNN)', '<ref type=""single"">(Badjatiya et al., 2017)</ref>', 'to', 'Transformer', 'architectures', '<ref type=""single"">(Leite et al., 2020).</ref>', 'Despite', 'interesting', 'results', 'achieved', 'by', 'Transformer', 'architectures,', 'there', 'are', 'still', 'several', 'rooms', 'to', 'be', 'explored', 'in', 'this', 'research', 'area.']",19,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7df4a0fa-eb5f-4bd3-b801-da53846df3c7,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,"['unknown', 'Neural learning for question answering in italian']","['unknown', '2018']","['unknown', 'Danilo Croce;Alexandra Zelenanska;Roberto Basili']",group,"['Automatically', 'translating', 'the', 'context,', 'question', 'and', 'answer', 'triples', 'from', 'a', 'high-resource', 'language,', 'such', 'as', 'English', '(called', 'source', 'domain)', 'to', 'lowresource', 'languages', '(called', 'target', 'domains)', 'have', 'enabled', 'the', 'evaluation', 'of', 'models', 'for', 'languages', 'with', 'no', 'training', 'data', 'available', 'but', 'also', 'the', 'creation', 'of', 'large-scale', 'MT-based', 'QA', 'corpora', 'for', 'the', 'Italian', '<ref type=""group"">(Croce et al., 2018 ), Spanish (Carrino et al., 2020),</ref>', 'Arabic', '<ref type=""single"">(Mozannar et al., 2019)</ref>', 'and', 'Korean', '(Youngmin', 'Kim,', '2020)', 'languages.']",49,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 0, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3]"
7e481786-4496-470e-ba5e-03b98966fb70,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Tagged back-translation'],['2019'],['Isaac Caswell;Ciprian Chelba;David Grangier'],single,"['To', 'alleviate', 'the', 'issue,', 'we', 'add', 'a', 'special', 'tag', 'for', 'the', 'BT', 'data', '<ref type=""single"">(Caswell et al., 2019).</ref>', 'With', 'BT[t],', 'we', 'send', 'a', 'signal', 'to', 'the', 'model', 'that', 'it', 'is', 'processing', 'synthetic', 'data,', 'and', 'thus,', 'it', 'may', 'not', 'hurt', 'the', 'learning', 'over', 'the', 'real', 'data.', 'Table', '2', '(rows', '(c,g))', 'shows', 'the', 'results.']",13,"[3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0]"
7e773b92-eeb7-46a9-b044-232ec739f5e6,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,"['Contextual analysis of mathematical expressions for advanced mathematical search', 'Mining coreference relations between formulas and text using Wikipedia']","['2011', '2010']","['Keisuke Yokoi;Minh-Quoc Nghiem', 'Minh Nghiem Quoc;Keisuke Yokoi']",group,"['Previous', 'studies', 'on', 'symbol-description', 'extraction', 'rely', 'on', 'pattern', 'matching', '<ref type=""group"">(Yokoi et al., 2011, Nghiem Quoc et al., 2010)</ref>', 'and', 'rule-based', 'algorithms', '<ref type=""single"">(Alexeeva et al., 2020).</ref>', 'These', 'methods', 'might', 'work', 'for', 'observed', 'patterns', 'with', 'an', 'assumption', 'of', 'close', 'proximity', 'between', 'symbol', 'and', 'description.', 'They', 'may', 'fail', 'to', 'capture', 'distant', 'symboldescription', 'pairs', 'and', 'symbols', 'in', 'very', 'complex', 'structures', 'such', 'as', 'algorithms', 'in', 'computer', 'science', 'literature.']",9,"[3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
7e84dbe8-46f5-4f8c-aeb8-5d412e14e27f,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Length-controllable image captioning'],['2020'],['Chaorui Deng;Ning Ding;Mingkui Tan;Qi Wu'],single,"['Controllability', 'Analysis', 'on', 'Temporal', 'Frequency', 'Then,', 'we', 'analyze', 'the', 'controllability', 'of', 'the', 'temporal', 'frequency', 'τ', 'to', 'present', 'whether', 'the', 'coarse-grained', 'or', 'fine-grained', 'tracepoints', '(sampling', 'rate,', 'in', 'other', 'words)', 'affects', 'the', 'generation', 'performance.', 'As', 'the', 'Table', '4', 'shows,', 'we', 'change', 'the', 'temporal', 'frequency', 'τ', 'from', '0.4', 'to', '1.2.', 'A', 'performance', 'drop', 'is', 'impressive', 'with', 'the', 'τ', 'getting', 'larger.', 'The', 'purpose', 'of', 'this', 'experiment', 'for', 'various', 'τ', 'is', 'to', 'simulate', 'the', 'trace', 'drawing', 'speed', 'of', 'users', 'in', 'a', 'real', 'application', 'scenario,', 'and', 'a', 'larger', 'τ', 'is', 'equivalent', 'to', 'a', 'faster', 'drawing', 'speed.', 'As', '<ref type=""single"">Deng et al. (2020)</ref>', 'has', 'demonstrated,', 'the', 'length', 'is', 'one', 'of', 'the', 'critical', 'facts', 'that', 'impact', 'quantitative', 'performance.', 'This', 'result', 'implies', 'we', 'can', 'further', 'decide', 'to', 'generate', 'either', 'a', 'coarse-grained', 'or', 'fine-grained', 'caption', 'by', 'controlling', 'the', 'time-frequency', 'τ.']",91,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
7ee9a6db-d1db-4e9e-a93e-0b5c75a43d0f,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,"['MadDog: A web-based system for acronym identification and disambiguation', 'unknown']","['2021', 'unknown']","['Ben Amir Pouran;Franck Veyseh;Walter Dernoncourt;Thien Huu Chang;unk Nguyen', 'unknown']",group,"['Definition', 'extraction', 'from', 'scientific', 'document', 'is', 'close', 'to', 'the', 'task', 'presented', 'in', 'SemEval', 'Task', '12.', 'The', 'Scientific', 'Document', 'Understanding', 'workshop', 'has', 'hosted', 'the', 'Acronym', 'Extraction', 'and', 'Acronym', 'Disambiguation', 'Shared', 'Tasks,', 'namely', 'Acronym', 'Extraction', 'and', 'Acronym', 'Disambiguation', 'Shared', 'Tasks', '<ref type=""group"">(Veyseh et al., 2021a (Veyseh et al., , 2022)).</ref>', 'The', 'prior', 'studies', 'in', 'this', 'research', 'direction', 'considers', 'extracting', 'definitions', 'from', 'the', 'text', '<ref type=""group"">(Spala et al., 2019 (Spala et al., , 2020,, Veyseh et al., 2020),</ref>', 'or', 'together', 'with', 'acronyms,', 'and', 'acronyms', 'sense', 'disambiguation', '(Pouran', 'Ben', '<ref type=""group"">Veyseh et al., 2020 Veyseh et al., , 2021)).</ref>']",63,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
7f25e854-fda7-4e46-a3ec-40ed86395a23,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Comparing models of associative meaning: An empirical investigation of reference in simple language games'],['2018'],['Matthias Judy Hanwen Shen;Bjarke Hofer;Roger Felbo;unk Levy'],single,"['To', 'the', 'best', 'of', 'our', 'knowledge,', 'the', 'first', 'algorithms', 'similar', 'to', 'Codenames', 'agents', 'have', 'been', 'created', 'by', '<ref type=""single"">Shen et al. (2018)</ref>', 'specifically', 'to', 'model', 'human', 'associations.', 'In', 'their', 'simplified', 'game,', 'the', 'board', 'always', 'consists', 'of', 'three', 'nouns,', 'and', 'the', 'agent', 'gives', 'a', 'clue', 'that', 'must', 'be', 'one', 'of', 'three', 'adjectives,', 'and', 'refers', 'to', 'exactly', 'two', 'of', 'the', 'board', 'words.', 'Their', 'clues', 'were', 'generated', 'based', 'on', 'the', 'following', 'five', 'similarity', 'functions:']",17,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7f31bd04-720a-4471-9417-7b9557fa817d,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Evidence That Gendered Wording in Job Advertisements Exists and Sustains Gender Inequality'],['2011'],['Danielle Gaucher;Justin Friesen;Aaron Kay'],single,"['Gender-Coded', 'Word', 'Prevalence', 'This', 'method', '<ref type=""single"">(Gaucher et al., 2011)</ref>', 'is', 'operationalised', 'through', 'a', 'set', 'of', 'masculine-and', 'feminine-themed', 'words', 'in', 'the', 'context', 'of', 'job', 'ads.', '""Adventurous""', 'and', '""stubborn""', 'are', 'coded', 'as', 'masculine', 'words', 'while', '""affectionate""', 'and', '""kind""', 'are', 'coded', 'as', 'feminine', 'words.', 'This', 'research', 'provides', 'us', 'with', '42', 'masculine', 'and', '40', 'feminine', 'words,', 'with', 'a', 'wider', 'set', 'of', 'potential', 'words', 'permeating', 'from', 'these', '(i.e.', '""Compet*""', 'which', 'may', 'manifest', 'itself', 'as', 'competitive,', 'competition', 'and', 'so', 'on).', 'Our', 'measure', 'counts', 'the', 'prevalence', 'of', 'these', 'words', 'in', 'a', 'given', 'text.', 'The', 'calculation', 'is:']",5,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3]"
7f3c0c31-46b1-47f4-9a6b-1cf1567392d9,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['Graph reasoning with context-aware linearization for interpretable fact extraction and verification'],['2021'],['Neema Kotonya;Thomas Spooner;Daniele Magazzeni;Francesca Toni'],single,"['Considering', 'the', 'inevitable', 'expense', 'in', 'format', 'conversion,', 'we', 'believe', 'that', 'each', 'evidence', 'in', 'its', 'original', 'format', 'can', 'contribute', 'necessary', 'information', 'to', 'final', 'verification,', 'thus', 'should', 'be', 'better', 'encoded', 'in', 'its', 'original', 'format.', 'This', 'further', 'indicates', 'that', 'we', 'should', 'design', 'both', 'sentence-to-table', 'and', 'table(cell)-to-sentence', 'conversion', 'methods', 'to', 'obtain', 'all', 'evidence', 'in', 'both', 'formats,', 'and', 'maintain', 'two', 'parallel', 'encoders', 'to', 'absorb', 'the', 'two', 'formats,', 'respectively.', 'An', 'advantage', 'of', 'doing', 'so', 'is', 'to', 'maximally', 'encourage', 'early', 'interaction,', 'which', 'proves', 'more', 'effective', 'than', 'pair-wise', 'encoding', '<ref type=""group"">(Tymoshenko and Moschitti, 2021, Jiang et al., 2021)</ref>', 'When', 'converting', 'table', 'evidence', 'into', 'sentences,', 'previous', 'works', 'either', 'convert', 'table', 'cells', 'to', 'a', 'concatenation', 'of', 'key-value', 'pairs', '<ref type=""group"">(Aly et al., 2021, Malon, 2021),</ref>', 'or', 'construct', 'sentences', 'in', 'a', 'coordinate-description', 'style', '<ref type=""single"">(Kotonya et al., 2021a).</ref>', 'They', 'pay', 'less', 'attention', 'to', 'the', 'conventional', 'organization', 'of', 'tables', 'structures.', 'We', 'observe', 'that,', 'in', 'a', 'table,', 'the', 'column', 'headers', 'usually', 'represent', 'the', 'types/properties', 'and', 'the', 'row', 'headers', 'often', 'denote', 'entities', 'or', 'scopes.', 'We', 'argue', 'that', 'one', 'should', 'consider', 'these', 'conventions', 'to', 'convert', 'a', 'table', 'cell', 'evidence', 'into', 'more', 'natural', 'sentences,', 'and', 'later', 'pretrained', 'language', 'models', 'will', 'be', 'able', 'to', 'better', 'capture', 'the', 'contextualized', 'semantics', 'of', 'the', 'table', 'cells', 'from', 'generated', 'sentences.', 'On', 'the', 'other', 'hand,', 'existing', 'pre-trained', 'table', 'models', 'are', 'trained', 'to', 'analyze', 'one', 'table', 'at', 'one', 'time,', 'while', 'previous', 'evidence', 'conversion', 'methods', 'produce', 'several', 'small', 'tables', 'for', 'one', 'instance.', 'It', 'would', 'be', 'necessary', 'to', 'properly', 'organize', 'all', 'evidence', 'in', 'one', 'table', 'so', 'that', 'pre-trained', 'table', 'models', 'can', 'allow', 'the', 'most', 'interactions', 'among', 'all', 'evidence', 'pieces.']",108,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7fa53f42-a945-4a17-8ed4-79cf99b4845c,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,['Visualcomet: Reasoning about the dynamic context of a still image'],['2020'],['Jae Park;Chandra Bhagavatula;Roozbeh Mottaghi;Ali Farhadi;Yejin Choi'],single,"['Given', 'a', 'question', 'for', 'an', 'image,', 'VCR', 'needs', 'to', '1.)', 'correctly', 'answer', '(Q→A),', '2.)', 'provide', 'a', 'rationale', 'justifying', 'its', 'answer', '(QA→R),', '3.)', 'reason', 'both', 'of', 'them', '(Q→AR),', 'which', 'requires', 'higher-order', 'cognition', 'and', 'commonsense', 'reasoning', 'about', 'the', 'world.', 'Following', 'UNITER,', 'we', 'introduce', 'a', 'second-stage', 'pretraining', 'over', 'the', 'VCR', 'dataset', 'due', 'to', 'severe', 'difference', 'in', 'dataset', 'distribution', 'compared', 'to', 'indomain', 'image-text', 'corpus.', 'In', 'addition,', 'we', 'also', 'utilize', 'a', 'similar', 'person', 'grounding', '<ref type=""single"">(Park et al., 2020)</ref>', 'pretext', 'task', 'to', 'tightly', 'align', 'the', 'person', 'tags', 'in', 'text', 'and', 'their', 'visual', 'locations.', 'During', 'finetuning', 'stage,', 'we', 'concatenate', 'each', 'question', 'along', 'with', 'each', 'possible', 'answer', 'to', 'form', 'four', 'kinds', 'of', 'text', 'inputs,', 'and', 'feed', 'each', 'of', 'them', 'into', 'Transformer', 'network', 'with', 'corresponding', 'image', 'embeddings.', 'Finally,', 'a', 'binary', 'cross-entropy', 'loss', 'is', 'adopted', 'to', 'supervise', 'each', 'pair.', 'Since', 'VCR', 'questions', 'explicitly', 'reference', 'objects', 'at', 'specific', 'locations,', 'we', 'implement', 'coreferencing', 'between', 'text', 'and', 'image', 'by', 'replacing', 'referenced', 'entities', 'in', 'the', 'questions', 'with', 'their', 'corresponding', 'box', 'locations.', 'In', 'the', 'second', 'stage', 'pretraining', 'for', 'VCR,', 'we', 'reduce', 'the', 'learning', 'rate', 'to', 'a', 'constant', '5e-05', 'and', 'trained', 'for', 'an', 'additional', '9K', 'steps.', 'Due', 'to', 'longer', 'sequence', 'lengths', 'in', 'the', 'VCR', 'dataset,', 'a', 'training', 'batch-size', 'of', '224', 'is', 'used.', 'We', 'also', 'use', 'a', 'step', 'size', 'of', '2', 'for', 'gradient', 'accumulation.', 'After', 'pretraining,', 'we', 'finetuned', 'on', 'the', 'VCR', 'task', 'for', '10K', 'steps', 'with', 'a', 'learning', 'rate', 'of', '1e-04', 'for', 'both', 'the', 'Transformer', 'and', 'the', 'CNNs.', 'Linear', 'warmup', 'of', 'the', 'learning', 'rate', 'is', 'applied', 'for', '1000', 'steps,', 'followed', 'by', 'a', 'linear', 'decay', 'ending', 'at', 'a', 'total', 'of', '10K', 'steps.']",69,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
7fedcf32-580d-4ef1-b9df-aeaa398f3c3e,Themes in the work of Margaret Masterman,1988,Yorick Wilks,"['For English translation see Anscombe', 'unknown']","['1922', 'unknown']","['L Wittgenstein;unk Untersuchungen', 'unknown']",group,"['MMB', 'would', 'also', 'welcome', 'anecdotal', 'evidence,', 'of', 'the', 'sort', 'to', 'be', 'found', 'in', 'the', 'work', 'of', 'Cassirer,', 'that', 'metaphorical', 'uses', 'of', 'language', 'were', 'in', 'some', 'historical', 'sense', 'original,', 'and', 'not', 'a', 'later', 'luxury.', 'She', 'rejected', 'the', 'view', 'that', 'language', 'originally', 'consisted', 'of', 'simple,', 'unambiguous,', 'Augustinian', 'names', 'of', 'objects', '-the', 'view', 'parodied', 'by', '<ref type=""group"">Wittgenstein (1928 Wittgenstein ( , 1972) )</ref>', 'in', 'the', 'opening', 'of', 'Philosophical', 'investigations', '-but', 'preferred', 'the', 'idea', 'of', 'original', 'primitive', 'atoms', 'of', 'wide,', 'vague,', 'unspecific', 'meaning,', 'which', 'were', 'then', 'both', 'refined', 'to', 'specific', 'referents', 'in', 'use', 'and', 'constantly', 'extended', 'by', 'metaphor.', 'Here,', 'for', 'MMB,', 'was', 'the', 'root', 'not', 'only', 'of', 'the', 'metaphor,', 'but', 'also', 'of', 'metaphysics', 'itself,', 'which', 'consisted', 'for', 'her,', 'as', 'for', 'Wittgenstein,', 'of', 'words', 'used', 'outside', 'their', 'hitherto', 'normal', 'realm', 'of', 'application.', 'But,', 'whereas', 'he', 'thought', 'that', 'words', 'were', ""'on"", ""holiday'"", 'when', 'so', 'used,', 'for', 'her', 'it', 'was', 'part', 'of', 'their', 'everyday', 'work.']",52,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
802e9017-6e2f-4264-95f3-18cc1180bd47,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,"[""What does bert look at? an analysis of bert's attention""]",['2019'],['Kevin Clark;Urvashi Khandelwal;Omer Levy;Christopher D Manning'],single,"['The', 'middle', 'layers', 'in', 'BERT', 'have', 'been', 'shown', 'to', 'have', 'specific', 'characteristics', 'of', 'higher', 'attention', 'entropy', 'and', 'greater', 'attention', 'to', 'specific', 'tokens', '<ref type=""single"">(Clark et al., 2019).</ref>', 'We', 'thus', 'considered', 'configurations', 'where', 'we', 'compare', 'pruning', 'top', 'and', 'bottom', 'layers', 'against', 'pruning', 'middle', 'layers', '(last', 'eight', 'rows', 'of', 'Table', '5).', 'The', 'results', 'indicate', 'a', 'clear', 'preference:', 'In', '14', 'out', 'of', '16', 'cases,', 'pruning', 'the', 'middle', 'layers', 'performs', 'worse', 'that', 'pruning', 'equal', 'number', 'of', 'layers', 'distributed', 'among', 'top/bottom', 'layers.', 'Indeed,', 'we', 'incur', 'an', 'additional', 'over', '2%', 'average', 'drop', 'in', 'accuracy', 'for', 'QNLI', 'and', 'SST-2', 'tasks,', 'indicating', 'a', 'task-specific', 'sensitivity', 'to', 'pruning', 'middle', 'layers.']",22,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
802f8c01-d121-459e-97b1-92b4bda9de27,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,"['Characterbased neural machine translation', 'Character-based neural machine translation', 'A character-level decoder without explicit segmentation for neural machine translation']","['2016', '2015', '2016']","['M Costa-Jussà;J Fonollosa', 'W Ling;I Trancoso;C Dyer;A Black', 'J Chung;K Cho;Y Bengio']",group,"['Recently,', 'some', 'works', 'have', 'used', 'subword', 'units', 'level', 'instead', 'of', 'word-level', 'for', 'translation.', 'In', '<ref type=""single"">[7],</ref>', 'the', 'rare', 'and', 'unknown', 'words', 'are', 'encoded', 'as', 'subword', 'units', 'with', 'the', 'Byte', 'Pair', 'Encoding', '(BPE)', 'algorithm.', 'The', 'authors', 'show', 'that', 'this', 'method', 'can', 'generate', 'words', 'which', 'are', 'unseen', 'at', 'training', 'time.', 'Another', 'lower', 'level', 'for', 'translation', 'is', 'the', 'character-level', 'NMT,', 'which', 'has', 'been', 'presented', 'in', 'several', 'works', '<ref type=""group"">[8, 9, 10]</ref>', 'and', 'showed', 'promising', 'results.']",63,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2]"
806e5e10-4f30-415d-bd85-8f8e29945c5d,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['A deep generative framework for paraphrase generation'],['2018'],['Ankush Gupta;Arvind Agarwal;Prawaan Singh;Piyush Rai'],single,"['In', 'order', 'to', 'create', 'diversity,', 'existing', 'methods', 'attempted', 'to', 'produce', 'uncertainty', 'by', 'introducing', 'random', 'noise', 'into', 'a', 'latent', 'variable', '<ref type=""single"">(Gupta et al., 2018)</ref>', 'or', 'sampling', 'next', 'token', 'widely', 'from', 'the', 'vo-', 'cabulary', '<ref type=""single"">(Holtzman et al., 2020).</ref>', 'However,', 'these', 'methods', 'were', 'not', 'able', 'to', 'explicitly', 'control', 'varying', 'semantics', 'units', 'and', 'produce', 'outputs', 'of', 'diverse', 'content.', 'Meanwhile,', 'the', 'input', 'text', 'alone', 'contains', 'too', 'limited', 'knowledge', 'to', 'support', 'diverse', 'reasoning', 'and', 'produce', 'multiple', 'reasonable', 'outputs', '<ref type=""single"">(Yu et al., 2022c).</ref>', 'As', 'an', 'example,', 'Table', '1', 'shows', 'the', 'human', 'evaluation', 'results', 'on', 'two', 'GCR', 'tasks.', 'While', 'human', 'annotators', 'were', 'able', 'to', 'produce', '2.60', 'different', 'yet', 'reasonable', 'explanations', 'on', 'the', 'ComVE', 'dataset,', 'one', 'SoTA', 'diversity-promoting', 'method', '(i.e.,', 'nucleus', 'sampling', '<ref type=""single"">(Holtzman et al., 2020))</ref>', 'could', 'produce', 'only', '2.15', 'reasonable', 'explanations.']",19,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
80943c72-cc5b-4e2d-ba48-d568db9cdf24,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Bert: Pre-training of deep bidirectional transformers for language understanding'],['2018'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Our', 'baseline', 'is', 'the', 'mBERT', 'model', '<ref type=""single"">(Devlin et al., 2018),</ref>', 'which', 'is', 'pre-trained', 'using', 'pretext', 'tasks', 'like', 'Masked', 'Language', 'Modelling', 'and', 'Next', 'Sentence', 'Prediction', 'on', 'a', 'multilingual', 'text', 'corpus', 'that', 'includes', 'our', 'target', 'languages,', 'Hindi', 'and', 'Tamil.', 'The', 'default', 'output', 'head', 'of', 'mBERT', 'is', 'replaced', 'with', 'the', 'head', 'for', 'the', 'question-answering', 'task.', 'This', 'is', 'done', 'by', 'adding', 'separate', 'output', 'heads', 'for', 'classifying', 'the', 'start', 'and', 'end', 'positions', 'as', 'shown', 'in', '<ref type=""single"">Devlin et al. (2018).</ref>']",6,"[2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
80d909f1-e559-40b6-92c0-e91853524195,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,"['MADAMIRA: A fast, comprehensive tool for morphological analysis and disambiguation of Arabic']",['2014'],['Arfath Pasha;Mohamed Al-Badrashiny;Mona Diab;Ahmed Kholy;Ramy Eskander;Nizar Habash;Manoj Pooleery;Owen Rambow;Ryan Roth'],single,"['Shakkala', 'was', 'built', 'by', '<ref type=""single"">Barqawi (2017)</ref>', 'for', 'Arabic', 'text', 'diacritization', 'using', 'Bi-LSTM', 'networks', 'combined', 'with', 'character', 'embeddings.', '<ref type=""single"">Fadel et al. (2019)</ref>', 'demonstrated', 'the', 'superiority', 'of', 'the', 'neural', 'approach', 'of', 'Shakkala', 'compared', 'to', 'other', 'different', 'automatic', 'diacritization', 'systems', 'available', 'online', 'e.g.,', '<ref type=""single"">Ali-Soft, Farasa, Harakat, and MADAMIRA.</ref>', 'Some', 'recent', 'work', 'in', 'Arabic', 'NLP', 'has', 'started', 'to', 'make', 'use', 'of', 'such', 'systems.', 'For', 'example,', 'Al-Sallab', 'et', 'al.', '(2017)', 'proposed', 'AROMA,', 'a', 'recursive', 'deep', 'learning', 'model', 'for', 'opinion', 'mining', 'in', 'Arabic.', 'Preprocessing', 'in', 'AROMA', 'included', 'morphological', 'tokenization', 'and', 'automatic', 'diacritization', 'carried', 'out', 'by', 'MADAMIRA', '<ref type=""single"">(Pasha et al., 2014).</ref>', 'This', 'resulted', 'in', 'improved', 'performance', 'in', 'classifying', 'opinion', 'as', 'positive', 'or', 'negative', 'on', 'a', 'range', 'of', 'different', 'Arabic', 'corpora.', 'Similarly,', '<ref type=""single"">Baly et al. (2017)</ref>', 'used', 'a', 'Recursive', 'Neural', 'Tensor', 'Network', '(RNTN)', 'for', 'sentiment', 'analysis', 'and', 'reported', 'that', 'adding', 'orthographic', 'features', 'such', 'as', 'diacritics', 'improved', 'the', 'performance.', 'They', 'incorporated', 'orthographic', 'features', 'such', 'as', 'diacritics', 'by', 'enlarging', 'the', 'vocabulary', 'to', 'have', 'distinct', 'word', 'forms', 'for', 'different', 'versions', 'of', 'the', 'word', '(diacritized/undiacritized)', 'and', 'then', 'deriving', 'embeddings', 'by', 'training', 'a', 'Continuous', 'Bag', 'of', 'Words', '(CBOW)', 'model', '<ref type=""single"">(Mikolov et al., 2013).</ref>', 'Similarly,', '<ref type=""single"">Alqahtani et al. (2019)</ref>', 'introduced', 'automatic', 'selective', 'diacritization', 'as', 'a', 'viable', 'step', 'in', 'lexical', 'disambiguation.', 'They', 'evaluated', 'the', 'system', 'in', 'downstream', 'tasks', 'including', 'POS', 'which', 'improved', 'from', '97.99%', 'by', 'baseline', 'to', '98.70%.', 'They', 'trained', 'word', 'embeddings', 'on', 'selectively-diacritized', 'dataset', 'to', 'enrich', 'the', 'vocabulary.']",82,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
827a8fb5-65cd-42a9-a242-fada7d1bdad5,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['Neural machine translation of rare words with subword units'],['2015'],['R Sennrich;B Haddow;A Birch'],single,"['For', 'sake', 'of', 'comparison,', 'we', 'have', 'computed', 'BLEU', 'at', 'word', 'level', 'using', 'BPE', 'method', '<ref type=""single"">[7].</ref>', 'We', 'computed', 'the', 'subwords', 'units', 'in', 'the', 'output', 'side', 'of', 'the', 'neural', 'network', 'as', 'done', 'with', 'Factored', 'approach.', 'We', 'set', 'the', 'number', 'of', 'merge', 'operations', 'for', 'the', 'BPE', 'algorithm,', 'as', 'explained', 'in', 'the', 'paper', '<ref type=""single"">[7],</ref>', 'following', 'equation', '12.']",49,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3]"
82939666-4a87-473d-afa9-44d85ad14a6f,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,"['Pretrained transformers improve out-of-distribution robustness', 'unknown']","['2020', 'unknown']","['Dan Hendrycks;Xiaoyuan Liu;Eric Wallace;Adam Dziedzic;Rishabh Krishnan;Dawn Song', 'unknown']",group,"['Despite', 'great', 'progress', 'has', 'been', 'made', 'over', 'improved', 'accuracy,', 'deep', 'learning', 'models', 'are', 'known', 'to', 'be', 'brittle', 'to', 'out-of-domain', 'data', '<ref type=""group"">(Hendrycks et al., 2020, Wang et al., 2019),</ref>', 'adversarial', 'attacks', '<ref type=""group"">(Mc-Coy et al., 2019, Jia and Liang, 2017, Jin et al., 2020),</ref>', 'partly', 'due', 'to', 'sometimes', 'the', 'models', 'have', 'exploited', 'spurious', 'correlations', 'in', 'the', 'existing', 'training', 'data', '<ref type=""group"">(Tu et al., 2020, Sagawa et al., 2020).</ref>', 'In', 'Figure', '1,', 'we', 'show', 'an', 'example', 'of', 'a', 'sentiment', 'classification', 'model', 'making', 'spurious', 'correlations', 'over', 'the', 'phrases', '""Spielberg""', 'and', '""New', 'York', 'Subway""', 'due', 'to', 'their', 'high', 'co-occurrences', 'with', 'positive', 'and', 'negative', 'labels', 'respectively', 'in', 'the', 'training', 'data.']",20,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
82e6844b-7b94-4cc3-81e6-4fc0c7469cff,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Layers of interpretation: On grammar and compositionality'],['2015'],['Emily Bender;Dan Flickinger;Stephan Oepen;Woodley Packard;Ann Copestake'],single,"['Why', 'care', 'about', 'compositionality', 'in', 'semantic', 'parsing?', 'If', 'the', 'goal', 'of', 'semantic', 'parsing', 'is', 'not', 'merely', 'to', 'automatically', 'obtain', 'a', 'representation', 'of', 'the', 'meaning', 'of', 'an', 'utterance', 'but', 'also', 'to', 'understand', 'why', 'the', 'parser', 'produced', 'that', 'answer,', 'i.e.,', 'an', 'explainable', 'and', 'transparent', 'system,', 'compositionality', 'can', 'help.', 'In', 'particular,', 'in', 'the', 'output', 'of', 'our', 'parser,', 'every', 'token', 'is', 'mapped', 'to', 'one', 'of', 'a', 'finite', 'number', 'of', 'meaning', 'fragments', '(unlike', 'a', 'sequence-to-sequence', 'system', 'where', 'a', 'single', 'token', 'can', 'in', 'principle', 'give', 'rise', 'to', 'an', 'unbounded', 'number', 'of', 'output', 'symbols),', 'every', 'clause', 'belongs', 'to', 'one', 'of', 'these', 'fragments', '(unlike', 'a', 'sequence-to-sequence', 'system', 'where', 'the', 'output', 'is', 'not', 'usually', 'anchored),', 'and', 'there', 'is', 'a', 'straightforward', 'rule', 'that', 'combines', 'fragments', 'into', 'utterance', 'meanings', '(unlike', 'sequence-to-sequence', 'systems', 'where', 'the', 'interactions', 'between', 'tokens', 'are', 'opaque).', 'This', 'type', 'of', 'transparency', 'is', 'especially', 'important', 'in', 'human-in-the-loop', 'annotation,', 'where', 'parsers', 'produce', 'an', 'initial', 'annotation', 'and', 'annotators', 'correct', 'them.', 'To', 'do', 'this', 'efficiently', 'and', 'consistenly,', 'annotators', 'need', 'to', 'pinpoint', 'where', 'an', 'error', 'arises,', 'and', 'word-meaning', 'pairings', 'with', 'a', 'finite', 'number', 'of', 'meanings', 'seem', 'a', 'good', 'handle', 'on', 'that.', '<ref type=""single"">Bender et al. (2015)</ref>', 'make', 'a', 'similar', 'argument', 'about', 'grammar-based', 'sembanking,', 'pointing', 'out', 'the', 'consistency,', 'comprehensiveness,', 'and', 'scalability', 'that', 'compositionality', 'afford.', 'sequence-to-sequence', 'ones', 'is', 'a', 'big', 'step', 'ahead', 'towards', 'transparent', 'DRS', 'parsing.', 'It', 'is', 'also', 'worth', 'noting', 'that', 'our', 'sequence', 'encoding', 'scheme', 'is', 'equally', 'applicable', 'to', 'incremental', 'parsers,', 'which', 'potentailly', 'afford', 'a', 'greater', 'degree', 'of', 'psycholinguistic', 'plausibility.', 'In', 'addition,', 'the', 'multi-task', 'architecture', 'of', 'our', 'approach', 'is', 'modular', 'and', 'allows', 'for', 'arbitrary', 'additional', 'sequence', 'labeling', 'tasks', 'and', 'factorizations.']",177,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
83b3f0e4-645e-4121-b918-e5f09f42be58,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,"['WorldTree V2: A Corpus of Science-Domain Structured Explanations and Inference Patterns supporting Multi-Hop Inference', 'WorldTree: A Corpus of Explanation Graphs for Elementary Science Questions supporting Multi-hop Inference']","['2020', '2018']","['Zhengnan Xie;Sebastian Thiem;Jaycie Martin;Elizabeth Wainwright;Steven Marmorstein;Peter Jansen', 'Peter Jansen;Elizabeth Wainwright;Steven Marmorstein;Clayton Morrison']",group,"['There', 'is', 'a', 'recent', 'explosion', 'of', 'explanation-centred', 'datasets', 'for', 'multi-hop', 'question', 'answering', '<ref type=""group"">(Jhamtani and Clark, 2020, Xie et al., 2020, Jansen et al., 2018, Khot et al., 2020, Yang et al., 2018, Thayaparan et al., 2020, Wiegreffe and Marasović, 2021).</ref>', 'However,', 'most', 'of', 'these', 'datasets', 'require', 'the', 'aggregation', 'of', 'only', 'two', 'sentences', 'or', 'paragraphs,', 'making', 'it', 'hard', 'to', 'evaluate', 'the', 'robustness', 'of', 'the', 'models', 'in', 'terms', 'of', 'semantic', 'drift.', 'On', 'the', 'other', 'hand,', 'the', 'WorldTree', 'corpus', '<ref type=""group"">(Xie et al., 2020, Jansen et al., 2018)</ref>', 'used', 'in', 'this', 'shared', 'task', 'is', 'explicitly', 'designed', 'to', 'test', 'multi-hop', 'inference', 'models', 'on', 'the', 'reconstruction', 'of', 'long', 'inference', 'chains', 'requiring', 'the', 'aggregation', 'of', 'an', 'average', 'of', '6', 'facts,', 'and', 'as', 'many', 'as', '16', 'facts.']",49,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
83e7df43-9479-4485-8fb1-5897a23f020a,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['Lexical-Functional Grammar: A Formal System for Grammatical Representation'],['1982'],['R Bresnan ; Kaplan;J Bresnan;J Bresnan;R Kaplan;A Zaenen'],single,"['There', 'are', 'two', 'ways', 'to', 'handle', 'sentences', 'with', 'unbounded', 'dependency.', 'The', 'first', 'approach', 'is', 'straightforward', 'memorybased', 'approach', 'which', 'simply', 'store', 'a', 'set', 'of', 'CSCs', 'involves', 'unbounded', 'dependency.', 'A', 'large', 'set', 'of', 'CSCs', 'would', 'have', 'to', 'be', 'prepared', 'for', 'this,', 'but', 'its', 'simplicity', 'minimized', 'computational', 'requirements.', 'Alternatively,', 'we', 'can', 'employ', 'somewhat', 'linguistic', 'treatment', 'of', 'this', 'phenomena', 'within', 'our', 'framework.', 'The', 'syntactic', 'constraint', 'network', 'has', 'a', 'node', 'representing', 'TOPIC', 'and', 'FOCUS', 'which', 'usually', 'bound', 'to', 'the', 'displaced', 'phrase.', 'An', 'address', 'of', 'CI', 'for', 'the', 'displaced', 'phrase', '(such', 'as', ""'the"", ""bug'"", 'in', 'the', 'example', 's9)', 'is', 'propagated', 'to', 'the', 'TOPIC', 'or', 'FOCUS', 'nodes', 'in', 'the', 'syntactic', 'constraint', 'network.', 'Further', 'propagation', 'of', 'the', 'address', 'of', 'the', 'CI', 'is', 'controlled', 'by', 'acti-vation', 'of', 'nodes', 'along', 'the', 'syntactic', 'constraint', 'network.', 'The', 'network', 'virtually', 'encodes', 'a', 'finite-state', 'transition', 'equivalent', 'to', '{COMP|XCOMP}*GF-COMP', '<ref type=""single"">[Kaplan and Zaenen, 1989]</ref>', 'where', 'GF-COMP', 'denotes', 'grammatical', 'functions', 'other', 'than', 'COMP.', 'The', 'address', 'of', 'the', 'CI', 'bound', 'to', 'TOPIC', 'or', 'FOCUS', 'can', 'propagate', 'through', 'the', 'path', 'based', 'on', 'the', 'activation', 'patterns', 'of', 'the', 'syntactic', 'constraint', 'network,', 'and', 'the', 'activation', 'patterns', 'are', 'essentially', 'controlled', 'by', 'markers', 'flow', 'from', 'the', 'memory', 'network.', 'When', 'the', 'CSC', 'is', 'accepted', 'and', 'there', 'is', 'a', 'case-role', 'not', 'bound', 'to', 'any', 'CI', '(OBJECT', 'in', 'the', 'example),', 'the', 'CSE', 'for', 'the', 'case-role', 'bound', 'with', 'the', 'CI', 'propagated', 'from', 'the', 'syntactic', 'constraint', 'network.']",134,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
840aa8e9-a04b-4d76-82d8-5ee970ac250f,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['A Framework of a Mechanical Trans lation between Japanese and English by Analogy Principle'],['1968'],"['C Moldovan ; Lin;D Moldovan;"" Snap: Simulator Results ; Moldovan;D Lee;W Lin;C Nagao;M Pollard;C Sag;I Quillian;M Riesbeck;C Martin;C Riesbeck;C Schank;R Sato;S Nagao;M unk']",single,"['DMSNAP', 'complete', 'parsing', 'in', 'the', 'order', 'of', 'milliseconds.', 'While', 'actual', 'SNAP', 'hardware', 'is', 'now', 'being', 'assembled', 'and', 'to', 'be', 'fully', 'operational', 'by', 'May', '1991,', 'this', 'section', 'provides', 'performance', 'estimation', 'with', 'precise', 'simulation', 'of', 'the', 'SNAP', 'machine.', 'Simulations', 'of', 'the', 'DMSNAP', 'algorithm', 'have', 'been', 'performed', 'on', 'a', 'SUN', '3/280', 'using', 'the', 'SNAP', 'simulator', 'which', 'has', 'been', 'developed', 'at', 'USC', '<ref type=""single"">[Lin and Moldovan, 1990</ref>', '].', 'The', 'simulator', 'is', 'implemented', 'in', 'both', 'SUN', 'Common', 'LISP', 'and', 'C,', 'and', 'simulates', 'the', 'SNAP', 'machine', 'at', 'the', 'processor', 'level.', 'The', 'LISP', 'version', 'of', 'the', 'simulators', 'also', 'provides', 'information', 'about', 'the', 'number', 'of', 'SNAP', 'clock', 'cycles', 'required', 'to', 'perform', 'the', 'simulation.']",58,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
840b0d15-05a6-4fc3-92b3-cf6c365dc92e,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['Mass: Masked sequence to sequence pretraining for language generation'],['2019'],['Kaitao Song;Xu Tan;Tao Qin;Jianfeng Lu;Tie-Yan Liu'],single,"['Our', 'proposed', 'SimpDefiner', 'also', 'takes', 'the', 'given', 'word', 'and', 'context', 'as', 'input.', 'Differently,', 'our', 'main', 'focus', 'is', 'to', 'generate', 'definitions', 'with', 'appropriate', 'complexity', 'to', 'better', 'help', 'language', 'learners.', 'Besides,', 'our', 'model', 'is', 'based', 'on', 'MASS', '<ref type=""single"">(Song et al., 2019),</ref>', 'which', 'is', 'a', 'pre-trained', 'encoder-decoder', 'model', 'and', 'is', 'suitable', 'for', 'generation', 'tasks.']",35,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
8441ce14-9ea3-4898-942c-aad2c60fb607,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['ROUGE: A package for automatic evaluation of summaries'],['2004'],['Chin-Yew Lin'],single,"['The', 'candidate', 'quality', 'measure', 'M', 'can', 'be', 'defined', 'in', 'many', 'ways.', 'In', 'this', 'work', 'we', 'define', 'it', 'as', 'the', 'ROUGE', '<ref type=""single"">(Lin, 2004)</ref>', 'score', 'of', 'a', 'candidate', 'summary', 'S', 'i', 'given', 'the', 'reference', 'summary', 'S', '*.', 'To', 'coordinate', 'a', 'pre-trained', 'abstractive', 'model,', 'we', '1)', 'use', 'it', 'to', 'generate', 'different', 'candidate', 'summaries', 'with', 'various', 'levels', 'of', 'quality,', '2', 'then', '2)', 'encourage', 'the', 'model', 'to', 'assign', 'higher', 'estimated', 'probabilities', 'to', 'better', 'candidates', 'by', 'fine-tuning', 'the', 'model', 'with', 'a', 'contrastive', 'loss,', 'following', 'the', 'previous', 'work', '<ref type=""group"">(Hopkins and May, 2011, Zhong et al., 2020):</ref>']",20,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8444eaf8-9b06-470d-bb95-f19cef0149f9,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['DATR: A Language for Lexical Knowledge Representation'],['1996'],['Roger Evans;Gerald Gazdar'],single,"['The', 'combination', 'of', 'lexical', 'knowledge', 'and', 'rule', 'knowledge', 'enables', 'WM', 'to', 'function', 'as', 'a', 'full', 'morphological', 'component.', 'As', 'shown', 'by', 'ten', 'Hacken', '(1998),', 'the', 'effects', 'of', 'this', 'coverage', 'are', 'particularly', 'striking', 'in', 'the', 'domain', 'of', 'word', 'formation,', 'for', 'which', 'a', 'system', 'taking', 'a', 'lexicon', 'as', 'modelled', 'in', 'Fig.', '2B', 'as', 'a', 'basis', 'lacks', 'the', 'procedural', 'component.', 'Thus', 'a', 'formalism', 'such', 'as', 'DATR,', 'as', 'described', 'by', '<ref type=""single"">Evans &amp, Gazdar (1996),</ref>', 'though', 'able', 'to', 'represent', 'word', 'formation', 'relationships,', 'cannot', 'deal', 'with', 'unseen', 'words', 'without', 'a', 'separate', 'recognition', 'module.', 'In', 'WM,', 'word', 'formation', 'rules', 'are', 'at', 'the', 'same', 'time', 'available', 'declaratively,', 'as', 'the', 'structural', 'backbone', 'of', 'the', 'database,', 'and', 'procedurally', 'for', 'the', 'recognition', 'of', 'new', 'words.']",65,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
845719bc-f932-425a-ae11-3f8e8c6c005d,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Gender Language Style and Group Composition in Internet Discussion Groups'],['1996'],['Victor Savicki;Dawn Lingenfelter;Merle Kelley'],single,"['Previous', 'research', 'has', 'demonstrated', 'that', 'some', 'demographic', 'settings', 'are', 'inherently', 'more', 'abusive', 'than', 'others.', 'For', 'example,', 'a', 'study', 'by', '<ref type=""single"">Stephens et al. (2013)</ref>', 'mapped', 'the', 'locations', 'of', 'hateful', 'tweets', 'across', 'the', 'United', 'States', 'to', 'uncover', 'the', 'regions', 'where', 'people', 'use', 'hate', 'speech', 'the', 'most.', 'They', 'observed', 'that', 'areas', 'with', 'low', 'diversity', 'use', 'more', 'derogatory', 'slurs', 'against', 'racial', 'and', 'sexual', 'minorities.', 'A', 'separate', 'line', 'of', 'work', 'by', '<ref type=""single"">Savicki et al. (1996)</ref>', 'concluded', 'that', 'male-only', 'discussion', 'groups', 'on', 'the', 'Internet', 'use', 'more', 'coarse', 'and', 'abusive', 'language', 'than', 'female-only', 'groups.', 'These', 'works', 'indicate', 'that', 'demographic', 'settings', 'can', 'be', 'predictive', 'of', 'the', '(abusive)', 'nature', 'of', 'comments', 'orig-inating', 'from', 'within', 'them.', 'User', 'and', 'community', 'information', 'constitutes', 'a', 'direct', 'and', 'simple', 'way', 'of', 'capturing', 'the', 'demographic', 'setting', 'of', 'a', 'comment.']",63,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
846b40c6-48a6-4de1-b18d-d51e2deb6f71,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Argument relation classification using a joint inference model'],['2017'],['Yufang Hou;Charles Jochim'],single,"['The', 'second', 'dataset', 'is', 'Debatepedia', 'arguments', '<ref type=""single"">(Hou and Jochim, 2017).</ref>', 'A', 'total', 'of', '508', 'topics', 'are', 'paired', 'with', '15K', 'pro', 'and', 'con', 'responses,', 'and', 'we', 'treat', 'each', 'pair', 'as', 'an', 'argument', 'and', 'each', 'topic', 'and', 'response', 'as', 'claim', 'and', 'statement,', 'respectively.']",6,"[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
846eb893-8678-4dae-b80e-91e9c320d286,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Scheduled sampling for sequence prediction with recurrent neural networks'],['2015'],['Samy Bengio;Oriol Vinyals;Navdeep Jaitly;Noam Shazeer'],single,"['Comparing', 'Eq.', '6', 'with', 'Eq.', '3,', 'the', 'major', 'difference', 'is', 'that', 'during', 'inference', 'the', 'model', 'makes', 'new', 'predictions', 'based', 'on', 'its', 'own', 'previous', 'predictions', 'S', '&lt,t', 'instead', 'of', 'the', 'reference', 'S', '*', '&lt,t.', 'As', 'a', 'result,', 'even', 'if', 'the', 'generation', 'model', 'g', 'achieves', 'very', 'high', 'accuracy', 'w.r.t.', 'Eq.', '3,', 'once', 'S', '&lt,t', 'starts', 'to', 'deviate', 'from', 'S', '*,', 'there', 'is', 'the', 'risk', 'that', 'the', 'performance', 'of', 'g', 'will', 'significantly', 'degrade.', 'This', 'problem', 'has', 'been', 'identified', 'as', 'the', 'exposure', 'bias', '<ref type=""single"">(Bengio et al., 2015).</ref>']",79,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
84a357bb-cfec-4d30-8538-2c4cda622669,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Advances in optimizing recurrent networks'],['2013'],['Yoshua Bengio;Nicolas Boulanger-Lewandowski;Razvan Pascanu'],single,"['Equations', '7', 'and', '8', 'attempt', 'to', 'account', 'for', 'this', 'by', 'using', 'a', 'shared', 'weight', 'concatenation', 'and', 'a', 'weighted', 'concatenation', 'respectively.', 'In', 'equation', '7,', 'W', '∈', 'R', 'k×k', 'is', 'a', 'weight', 'matrix,', 'where', 'the', 'values', 'are', 'scaled', 'down', 'to', '1,', 'in', 'order', 'to', 'capture', 'the', 'relative', 'importance', 'of', 'each', 'h', 'c', 'i', 'and', 'h', 'w', 'i', '∀h', 'c', 'i', '∈', 'h', 'c,', 'h', 'w', 'i', '∈', 'h', 'w.', 'This', 'shared', 'weighting', 'is', 'a', 'modification', 'of', 'the', 'concept', 'of', 'leaky', 'integration', '<ref type=""single"">(Bengio et al., 2013).</ref>', 'On', 'the', 'other', 'hand,', 'equation', '8', 'uses', 'two', 'independent', 'weight', 'matrices,', 'W', 'c,', 'W', 'w', '∈', 'R', 'k×k,', 'which', 'does', 'not', 'constrain', 'the', 'network', 'to', 'use', 'on', 'other', 'the', 'other', 'hidden', 'representation.', 'However,', 'the', 'gradients', 'are', 'still', 'clipped', 'at', 'a', 'low', 'value', '(≈', '1)', 'to', 'avoid', 'explosion.']",79,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
84ef5b77-05f3-404d-96cb-bcd15cbd0799,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['X-bar Syntax'],['1977'],['R Jackendoff'],single,"['We', 'utilised', 'the', 'ANLT', 'metagrammatical', 'formalism', 'to', 'develop', 'a', 'feature-based,', 'declara', 'tive', 'description', 'of', 'PoS', 'label', 'sequences', 'for', 'English.', 'This', 'grammar', 'compiles', 'into', 'a', 'DCG-like', 'grammar', 'of', 'approximately', '400', 'rules.', 'It', 'has', 'been', 'designed', 'to', 'enumerate', 'possible', 'valencies', 'for', 'predicates', '(verbs,', 'adj', 'ectives', 'and', 'nouns)', 'by', 'including', 'separate', 'rules', 'for', 'each', 'pattern', 'of', 'possible', 'complementation', 'in', 'English.', 'The', 'distinction', 'between', 'arguments', 'and', 'adj', 'uncts', 'is', 'expressed,', 'following', 'X-bar', 'theory', '(e.g.', '<ref type=""single"">Jackendoff, 1977),</ref>', 'by', 'Chomsky-adjunction', 'of', 'adjuncts', 'to', 'maximal', 'projections', '{XP', '�', 'XP', 'Adjunct)', 'as', 'opposed', 'to', 'government', 'of', 'arguments', '(i.e.', 'arguments', 'are', 'sisters', 'within', 'Xl', 'projections,', 'XI', '�', 'XO', 'Argl.', '..', 'ArgN).', 'Although', 'the', 'grammar', 'enumerates', 'complementation', 'possibilities', 'and', 'checks', 'for', 'global', 'sentential', 'well-formedness,', 'it', 'is', 'best', 'de', 'scribed', 'as', ""'intermediate'"", 'as', 'it', 'does', 'not', 'attempt', 'to', 'associate', ""'displaced'"", 'constituents', 'with', 'their', 'canonical', 'position', '/', 'grammatical', 'role.']",70,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
84f15eab-3de8-4406-a3d0-02d6abed02ee,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,['Improving the representation and conversion of mathematical formulae by considering their textual context'],['2018'],['Moritz Schubotz;André Greiner-Petter;Philipp Scharpf;Norman Meuschke;S Howard;Bela Cohl;unk Gipp'],single,"['The', 'exponential', 'growth', 'of', 'published', 'articles', 'may', 'exceeds', 'many', ""readers'"", 'ability', 'to', 'keep', 'track', 'of', 'the', 'development', 'of', 'their', 'field', 'of', 'interest.', 'Hence,', 'automatic', 'reading', 'comprehension', 'of', 'scientific', 'documents', 'has', 'attracted', 'the', 'attention', 'of', 'researchers', 'across', 'various', 'domains', 'such', 'as', 'Drug', 'Discovery,', 'Knowledge', 'Base', 'Construction,', 'and', 'Natural', 'Language', 'Processing.', 'A', 'crucial', 'aspect', 'of', 'understanding', 'scientific', 'literature', 'is', 'understanding', 'terminologies', 'and', 'formulae', 'because', 'they', 'offer', 'an', 'explicit', 'and', 'precise', 'interface', 'to', 'present', 'the', 'relation', 'between', 'scientific', 'concepts', '<ref type=""single"">(Schubotz et al., 2018).</ref>', 'As', 'such,', 'a', 'reading', 'comprehension', 'machine', 'needs', 'to', '(i)', 'identify', 'their', 'descriptions', 'and', 'formulae,', '(ii)', 'segment', 'them', 'into', 'primitive', 'terms', 'and', 'symbols,', 'and', '(iii)', 'link', 'the', 'associated', 'terms', 'and', 'corresponding', 'symbols.']",76,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
84fcbcbf-0a04-4d16-b9da-b2422fb62e7d,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['On the systematicity of probing contextualized word representations: The case of hypernymy in BERT'],['2020'],['Abhilasha Ravichander;Eduard Hovy;Kaheer Suleman;Adam Trischler;Jackie Chi Kit Cheung'],single,"['For', 'semantics,', 'the', 'situation', 'is', 'even', 'more', 'complicated.', 'While', ""BERT's"", 'performance', 'on', 'natural', 'language', 'understanding', 'tasks', 'set', 'a', 'new', 'state', 'of', 'the', 'art,', 'more', 'targeted', 'tests', 'of', 'its', 'semantic', 'abilities', 'have', 'yielded', 'less', 'positive', 'results.', 'BERT', 'has', 'limited', 'knowledge', 'of', 'lexical', 'semantic', 'relations', 'such', 'as', 'hypernymy', '<ref type=""single"">(Ravichander et al., 2020)</ref>', 'and', 'antonymy', '<ref type=""single"">(Staliunaite and Iacobacci, 2020).</ref>', 'Moreover,', 'it', 'has', 'fragile', 'representations', 'of', 'named', 'entities', '<ref type=""single"">(Balasubramanian et al., 2020),</ref>', 'and', 'imprecise', 'representations', 'of', 'numbers', '<ref type=""single"">(Wallace et al., 2019).</ref>', 'These', 'flaws', 'comprise', 'specific', 'linguistic', 'phenomena', 'that', 'BERTScore,', 'due', 'to', 'its', 'use', 'of', 'BERT,', 'might', 'be', 'unable', 'to', 'handle,', 'and', 'thus', 'merit', 'investigation.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
8509321c-37db-46cf-b730-4c655cee849c,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['unknown'],['2020'],['unk Nguyen Van Nha'],single,"['Trained', 'on', 'Vietnamese', 'texts', 'of', 'the', 'CommonCrawl', 'corpus', 'ETNLP', '<ref type=""single"">(Vu et al., 2019)</ref>', 'x', 'Trained', 'on', '1GB', 'texts', 'of', 'Vietnamese', 'Wikipedia', 'PhoBERT', '<ref type=""single"">(Nguyen and Nguyen, 2020)</ref>', 'x']",19,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
8516d3fb-4292-49d8-b452-05a925a6665e,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,"['unknown', 'BERT: Pre-training of deep bidirectional transformers for language understanding']","['unknown', '2019']","['unknown', 'Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova']",group,"['We', 'have', 'established', 'that', 'the', 'performance', 'of', 'top-k', 'attention', 'is', 'comparable', 'to', 'vanilla', 'attention', 'when', 'training', 'the', 'model', 'from', 'scratch.', 'In', 'this', 'set-up,', 'several', 'recently-proposed', 'approaches', 'have', 'also', 'reported', 'competitive', 'performances', '<ref type=""single"">(Tay et al., 2021).</ref>', 'Now,', 'we', 'consider', 'a', 'different', 'and', 'more', 'practical', 'setup,', 'where', 'the', 'starting', 'point', 'is', 'using', 'an', 'already', 'pre-trained', 'language', 'model', '<ref type=""group"">(Devlin et al., 2019, Raffel et al., 2020).</ref>', 'As', 'such', 'models', 'were', 'trained', 'using', 'vanilla', 'attention,', 'replacing', 'it', 'with', 'a', 'new', 'attention', 'variant', 'typically', 'requires', 'a', 'corrective', 'pretraining', 'stage', 'to', 'allow', 'the', 'model', 'weights', 'to', 'adjust', 'to', 'the', 'new', 'variant,', 'which', 'can', 'be', 'expensive', 'for', 'large', 'models.', 'For', 'example,', '<ref type=""group"">(Gupta and Berant, 2021, Peng et al., 2021)</ref>', 'have', 'shown', 'that', 'using', 'random', 'features', 'without', 'corrective', 'pre-training', 'leads', 'to', 'high', 'error', 'rates', 'in', 'a', 'language', 'modeling', 'task.', 'Moreover,', 'as', 'explained', 'in', '§2.1,', 'most', 'past', 'methods', 'are', 'incompatible', 'with', 'feed-forward', 'layers.', 'In', 'the', 'subsequent', 'experiments', 'we', 'show', 'that', 'it', 'is', 'possible', 'to', 'replace', 'vanilla', 'with', 'top-k', 'attention,', 'at', 'multi-head', 'attention', 'and', 'feed-forward', 'layers,', 'and', 'perform', 'inference', 'and', 'fine-tuning', 'without', 'any', 'need', 'for', 'such', 'correction.']",52,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8534d42b-3d3b-42e7-8f33-c76924e4be01,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Learning word vectors for 157 languages'],['2018'],['Edouard Grave;Piotr Bojanowski;Prakhar Gupta;Armand Joulin;Tomas Mikolov'],single,"['For', 'our', 'contextual', 'word', 'embeddings,', 'we', 'use', 'fastText', 'embeddings', 'for', 'English', '<ref type=""single"">(Bojanowski et al., 2017)</ref>', 'which', 'are', 'pretrained', 'on', 'common-Crawl', 'and', 'the', 'Wikipedia', 'corpus.', 'FastText', 'embeddings', 'are', 'also', 'used', 'for', 'Hindi,', 'French,', 'Spanish', 'and', 'Italian', 'word', 'representations', '<ref type=""single"">(Grave et al., 2018).</ref>', 'The', 'bi-LSTM', 'trains', 'on', 'a', 'fixed', '300', 'hidden', 'dimensions', 'for', 'all', 'the', 'bi-LSTMs', 'in', 'the', 'architecture.']",34,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
85415672-de9f-4a49-9f43-7ffd18868fce,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Applicability of indexed grammars to natural languages'],['1987'],['G Gazdar'],single,"['A', 'linear', 'indexed', 'grammar', 'is', 'a', 'tuple', '(Vr,', 'V', 'N,', 'Vi,', 'P,', 'S),', 'where', 'Vr', 'is', 'a', 'finite', 'set', 'of', 'terminals,', 'V', 'N', 'a', 'finite', 'set', 'of', 'non-terminals,', 'Vi', 'is', 'a', 'finite', 'set', 'of', 'indices,', 'SE', 'V', 'N', 'is', 'the', 'start', 'symbol', 'and', 'Pisa', 'finite', 'set', 'of', 'productions.', 'Following', '<ref type=""single"">[7]</ref>', 'we', 'consider', 'productions', 'in', 'which', 'at', 'most', 'one', 'element', 'can', 'be', 'pushed', 'on', 'or', 'popped', 'from', 'a', 'stack', 'of', 'indices', ':Ao', '[oo', '1]', '➔', 'Ai', '[]', '...', 'Ai', '-i', 'l]', ""Ai[oo,']"", 'Ai-i', 'l]', '...', 'Am', '[]', 'Ao', '[]', '➔', 'awhere', 'm', 'is', 'the', 'length', 'of', 'the', 'production,', 'A', 'i', 'E', 'VN', 'for', 'each', 'O', '-�', 'j', '�', 'm,', 'Ai', 'is', 'the', 'dependent', 'child,', 'oo', 'is', 'the', 'part', 'of', 'the', 'indices', 'stack', 'transmitted', 'from', 'the', 'father', 'to', 'the', 'dependent', 'child,,,', "",'"", 'E', 'Vi', 'U', '{€}', 'and', 'for', 'each', 'production', 'either,', 'or', "",'"", 'or', 'both', 'must', 'be', '€', 'and', 'a', 'E', 'VT', 'U', '{€}.']",49,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
85826bd2-b3de-4f91-941b-66b05c3e06fb,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['unknown'],['2019'],['Gemma Bel-Enguix;Helena Gómez-Adorno;Jorge Reyes-Magaña;Gerardo Sierra'],single,"['Word', 'associations', 'have', 'been', 'a', 'subject', 'of', 'active', 'research', 'for', 'a', 'long', 'time', 'in', 'cognitive', 'science', 'and', 'psycholinguistics', 'for', 'various', 'reasons.', 'They', 'were', 'used', 'to', 'study', 'mental', 'functioning,', 'memory,', 'and', 'certain', 'diseases.', 'Word', 'associations', 'were', 'also', 'applied', 'for', 'modeling', 'the', 'cognitive', 'lexicon', 'and', 'some', 'linguistic', 'processes', '(summarized', 'by', '<ref type=""single"">Bel-Enguix et al., 2019).</ref>']",48,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1]"
85e3953b-2945-40c6-8183-d05f6ea0c034,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['unknown'],['unknown'],['unknown'],single,"['When', 'the', 'parsing', 'is', 'done,', 'a', 'V-MARKER', 'is', 'passed', 'to', 'the', 'target', 'language', '(Japanese)', 'expression', 'WANT-CIRCUM-J', 'from', 'WANT-CIRCUM,', 'and,', 'then,', 'to', 'the', 'first', 'CSE', 'of', 'WANT-CIRCUM-J.', 'Since', 'the', 'first', 'CSE', 'has', 'a', 'G-MARKER', 'pointing', 'to', 'JON,', ""'jon'"", 'becomes', 'the', 'first', 'word', 'in', 'the', 'translated', 'Japanese', 'sentence', 'and', 'then', 'the', 'V-MARKER', 'is', 'passed', 'to', 'the', 'next', 'CSE.', 'See', '<ref type=""single"">[Kitano, 1990b]</ref>', 'for', 'the', 'details', 'of', 'generation', 'process.', 'This', 'operation', 'is', 'repealed', 'for', 'all', 'CSEs', 'in', 'the', 'CSC.', 'Finally,', 'the', 'Japanese', 'sentence', 'tl', 'is', 'constructed', 'for', 'the', 'English', 'sentence', 's1.']",57,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
86cf52b1-9c15-4c84-af4e-438b290ad8b6,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,"['Robustness to spurious correlations in text classification via automatically generated counterfactuals', 'Robustness to spurious correlations via human annotations']","['2020', '2020']","['Zhao Wang;Aron Culotta', 'Megha Srivastava;Tatsunori Hashimoto;Percy Liang']",group,"['Genuine', 'tokens', 'are', 'tokens', 'that', 'causally', 'affect', 'a', ""task's"", 'label', '<ref type=""group"">(Srivastava et al., 2020, Wang and Culotta, 2020b),</ref>', 'and', 'thus', 'the', 'correlations', 'between', 'those', 'tokens', 'and', 'the', 'labels', 'are', 'what', 'we', 'expect', 'the', 'model', 'to', 'capture', 'and', 'to', 'more', 'heavily', 'rely', 'on.', 'On', 'the', 'other', 'hand,', 'spurious', 'tokens,', 'or', 'shortcuts', 'as', 'commonly', 'denoted', 'in', 'prior', 'work', '<ref type=""group"">(Geirhos et al., 2020, Minderer et al., 2020),</ref>', 'are', 'features', 'that', 'correlate', 'with', 'task', 'labels', 'but', 'are', 'not', 'genuine,', 'and', 'thus', 'might', 'fail', 'to', 'transfer', 'to', 'challenging', 'test', 'conditions', '<ref type=""single"">(Geirhos et al., 2020)</ref>', 'or', 'out-of-distribution', 'data,', 'spurious', 'tokens', 'do', 'not', 'causally', 'affect', 'task', 'labels', '<ref type=""group"">(Srivastava et al., 2020, Wang and Culotta, 2020b).</ref>']",83,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1]"
86e61aca-53e0-4d62-9435-b27d9e4ce3da,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Recursive deep models for semantic compositionality over a sentiment treebank'],['2013'],['Richard Socher;Alex Perelygin;Jean Wu;Jason Chuang;D Christopher;Andrew Manning;Christopher Ng;unk Potts'],single,"['Task', '1:', 'Sentiment', 'classification.', 'For', 'the', 'task', 'of', 'sentiment', 'classification,', 'we', 'use', 'several', 'datasets', 'in', 'our', 'experiments.', 'To', 'find', 'shortcuts', 'in', 'Stanford', 'Sentiment', 'Treebank', '(SST-2)', '<ref type=""single"">(Socher et al., 2013)</ref>', 'dataset,', 'we', 'first', 'train', 'a', 'model', 'on', 'SST-2', 'training', 'set', 'which', 'consists', 'of', '67,', '349', 'sentences.', 'We', 'then', 'evaluate', 'the', 'model', 'on', 'SST-2', 'training', 'set', '5', 'and', 'Yelp', '(As-ghar,', '2016)', 'test', 'set', 'and', 'obtain', 'attention', 'scores.', 'For', 'cross-dataset', 'analysis,', 'we', 'compare', 'the', 'important', 'tokens', 'extracted', 'from', 'SST-2', 'and', 'Yelp.', 'Similarly,', 'we', 'train', 'another', 'model', 'on', '80,', '000', 'amazon', 'kitchen', 'reviews', '<ref type=""single"">(He and McAuley, 2016),</ref>', 'and', 'apply', 'it', 'on', 'the', 'kitchen', 'review', 'dev', 'set', 'and', 'the', 'amazon', 'electronics', 'dev', 'set,', 'both', 'having', '10,', '000', 'reviews.']",25,"[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
878b7a5b-2938-408b-86b7-4a6f5d81bc2b,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,"['Parsing argumentation structures in persuasive essays', 'Show me your evidencean automatic method for context dependent evidence detection', 'End-to-end argumentation mining in student essays', 'Argumentation mining in user-generated web discourse']","['2017', '2015', '2016', '2017']","['Christian Stab;Iryna Gurevych', 'Ruty Rinott;Lena Dankin;Carlos Perez;Mitesh Khapra;Ehud Aharoni;Noam Slonim', 'Isaac Persing;Vincent Ng', 'Ivan Habernal;Iryna Gurevych']",group,"['Logical', 'mechanisms', 'have', 'not', 'been', 'actively', 'studied', 'in', 'argumentative', 'relation', 'classification.', 'Models', 'based', 'on', 'hand-crafted', 'features', 'have', 'used', 'relatively', 'simple', 'lexical', 'features,', 'such', 'as', 'n-grams,', 'discourse', 'markers,', 'and', 'sentiment', 'agreement', 'and', 'word', 'overlap', 'between', 'two', 'statements', '<ref type=""group"">(Stab and Gurevych, 2017, Habernal and Gurevych, 2017, Persing and Ng, 2016, Rinott et al., 2015).</ref>', 'Recently,', 'neural', 'models', 'have', 'become', 'dominant', 'approaches', '<ref type=""group"">(Chakrabarty et al., 2019, Durmus et al., 2019, Eger et al., 2017).</ref>', 'Despite', 'their', 'high', 'accuracy', 'and', 'finding', 'of', 'some', 'word-level', 'interactions', 'between', 'statements', '<ref type=""group"">(Xu et al., 2019, Chen et al., 2018),</ref>', 'they', 'provide', 'quite', 'limited', 'insight', 'into', 'governing', 'mechanisms', 'in', 'argumentative', 'relations.', 'Indeed,', 'more', 'and', 'more', 'evidence', 'suggests', 'that', 'supervised', 'models', 'learn', 'to', 'overly', 'rely', 'on', 'superficial', 'cues,', 'such', 'as', 'discourse', 'markers', '<ref type=""single"">(Optiz and Frank, 2019),</ref>', 'negating', 'words', '<ref type=""single"">(Niven and Kao, 2019),</ref>', 'and', 'sentiment', '<ref type=""single"">(Allaway and McKeown, 2020)</ref>', 'behind', 'the', 'scenes.', 'We', 'instead', 'use', 'an', 'interpretable', 'method', 'based', 'on', 'PSL', 'to', 'examine', 'logical', 'mechanisms', '(§7)', 'and', 'then', 'show', 'evidence', 'that', 'these', 'mechanisms', 'can', 'inform', 'supervised', 'models', 'in', 'intuitive', 'ways', '(§8).']",36,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
88276289-1839-48a8-92ed-c207b13be5b6,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Playing codenames with language graphs and word embeddings'],['2021'],['Divya Koyyalagunta;Anna Sun;Rachel Draelos;Cynthia Rudin'],single,"['Among', 'the', 'configurations,', 'FastText', 'similarity', 'combined', 'with', 'the', 'Koyyalagunta', 'scoring', 'function', 'was', 'evaluated', 'previously', 'by', '<ref type=""single"">Koyyalagunta et al. (2021),</ref>', 'where', 'it', 'was', 'the', 'best', 'agent', 'without', 'any', 'language-specific', 'resource,', 'i.e.', 'using', 'raw', 'corpora', 'only.', 'The', 'results', 'show', 'that', 'this', 'is', 'outperformed', 'by', 'many', 'of', 'our', 'new', 'configurations.']",15,"[2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
8868c686-94e6-4193-94de-7747f5f1a254,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,['TransQuest: Translation quality estimation with cross-lingual transformers'],['2020'],['Tharindu Ranasinghe;Constantin Orasan;Ruslan Mitkov'],single,"['Crosslingual', 'Since', 'there', 'were', 'no', 'training', 'data', 'available', 'for', 'cross-lingual', 'datasets,', 'we', 'followed', 'a', 'zero-shot', 'approach', 'for', 'them.', 'Multilingual', 'and', 'cross-lingual', 'transformer', 'models', 'like', 'multilingual', 'BERT', 'and', 'XLM-R', 'show', 'strong', 'cross-lingual', 'transfer', 'learning', 'performance.', 'They', 'can', 'be', 'trained', 'on', 'one', 'language,', 'typically', 'a', 'resource-rich', 'language', 'and', 'can', 'be', 'used', 'to', 'perform', 'inference', 'on', 'another', 'language.', 'The', 'cross-lingual', 'nature', 'of', 'the', 'transformer', 'models', 'has', 'provided', 'the', 'ability', 'to', 'do', 'this', '<ref type=""single"">(Ranasinghe et al., 2020c).</ref>', 'Therefore,', 'we', 'used', 'the', 'models', 'trained', 'on', 'the', 'English-English', 'dataset', 'to', 'get', 'predictions', 'for', 'cross-lingual', 'datasets.']",69,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
8885d58d-52a3-4c9b-ad62-dbb46017bf4b,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Discourse representation parsing for sentences and documents'],['2019'],['Jiangming Liu;Shay Cohen;Mirella Lapata'],single,"['Apart', 'from', 'the', 'small', 'gold', 'set', 'whose', 'quality', 'is', 'guaranteed', 'by', 'human', 'annotators,', 'PMB', '3.0.0', 'also', 'contains', 'silver', 'and', 'bronze', 'data', 'with', 'partial', 'or', 'no', 'manual', 'checking', 'of', 'the', 'annotations.', 'Their', 'lower', 'quality', 'is', 'compensated', 'for', 'by', 'quantity.', '<ref type=""single"">Liu et al. (2019)</ref>', 'report', 'a', 'large', 'improvement', 'for', 'their', 'DRS', 'parser', 'when', 'first', 'training', 'on', 'the', 'bronze', 'and', 'silver', 'data,', 'then', '""fine-tuning""', 'on', 'gold', 'data.', 'Since', 'we', 'are', 'using', 'a', 'Transformer', 'model', 'like', 'them,', 'we', 'expected', 'this', 'technique', 'could', 'also', 'boost', 'our', ""parser's"", 'performance.', 'Thus,', 'we', 'tested', 'our', 'model', 'with', '5', 'epochs', 'training', 'on', 'silver', 'and', 'bronze', 'followed', 'by', '5', 'epochs', 'on', 'gold.', 'The', 'results', 'are', 'shown', 'in', 'Table', '5.', 'They', 'confirm', 'that', 'more', 'data', 'means', 'better', 'results', 'even', 'when', 'the', 'data', 'is', 'not', 'perfect.', 'Although', 'the', 'bigger', 'training', 'set', 'also', 'increases', 'the', 'number', 'of', 'classes', 'for', 'all', 'three', 'labels', 'more', 'than', '10-fold,', 'the', 'model', 'seems', 'to', 'handle', 'it', 'just', 'fine.', 'The', 'only', 'downside', 'is', 'the', 'longer', 'training', 'time:', 'as', 'the', 'silver', 'and', 'bronze', 'sets', 'for', 'English', 'are,', 'respectively,', '21', 'and', '25', 'times', 'larger', 'than', 'the', 'gold', 'one,', 'the', 'time', 'consumption', 'jumps', 'from', 'a', 'few', 'minutes', 'to', 'more', 'than', '10', 'hours.', '2019)', 'with', 'the', 'addition', 'of', 'BERT', 'embeddings,', 'and', 'their', '""best""', 'model', 'encodes', 'the', 'character', 'embedding', 'and', 'the', 'BERT', 'embedding', 'separately', 'before', 'feeding', 'their', 'concatenated', 'vector', 'into', 'the', 'decoder,', 'which', 'achieved', 'state-of-the-art', 'results.', 'Worth', 'noting', 'is', 'their', 'claim', 'that', ""it's"", 'best', 'to', 'keep', 'BERT', 'parameters', '""frozen"",', 'which', 'we', 'did', 'not', 'find', 'to', 'be', 'the', 'case', 'for', 'our', 'model:', 'in', 'preliminary', 'experimentation,', 'finetuning', 'BERT', 'parameters', 'with', 'our', 'model', 'outperformed', 'a', 'corresponding', 'frozen', 'model', 'by', '20%', 'in', 'Counter', 'f-score.']",38,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
89153e94-6fe3-4973-84a9-a0f2e639e0ea,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['unknown'],['unknown'],['unknown'],single,"['The', 'transliteration', 'of', 'text', 'and', 'audio', 'data', 'into', 'phonetic', 'representations', 'presents', 'several', 'other', 'challenges', 'related', 'to', 'potential', 'loss', 'of', 'information', 'or', 'injection', 'of', 'noise:', '1.', 'Loss', 'of', 'suprasegmental', 'information:', 'In', 'some', 'languages,', 'meaning', 'may', 'be', 'encoded', 'through', 'tones,', 'or', 'pitch', 'changes', 'across', 'sounds', '(aka', 'across', 'segments,', 'or', '""suprasegmental"").', 'Particularly', 'for', 'tonal', 'languages', 'such', 'as', 'Mandarin', 'Chinese', '[cmn],', 'this', 'loss', 'can', 'represent', 'a', 'significant', 'informational', 'loss', 'particularly', 'for', 'homophones', 'with', 'different', 'tones,', 'as', 'seen', 'in', '(Amrhein', 'and', 'Sennrich,', '2020).', 'While', 'IPA', 'symbols', 'can', 'represent', 'these', 'intricacies,', 'it', 'adds', 'complexity', '2.', 'Phone/phoneme', 'differences:', 'As', 'noted', 'in', '<ref type=""single"">(Li et al., 2020),</ref>', 'speech', 'sounds', 'which', 'are', 'physically', 'different', '(different', 'phones),', 'may', 'be', 'perceived', 'as', 'the', 'same', '(one', 'phoneme)', 'by', 'speakers', 'of', 'one', 'language,', 'but', 'these', 'same', 'sounds', 'could', 'perhaps', 'be', 'distinguished', 'by', 'speakers', 'of', 'another', 'language.', 'For', 'example,', 'the', 'French', 'words', 'words', 'bouche,', 'and', 'bûche', 'contain', 'phones', '(/u/', 'vs.', '/y/)', 'which', 'may', 'sound', '""the', 'same""', 'to', 'English', 'speakers,', 'but', 'are', 'semantically', 'different', 'to', 'French', 'speakers.', 'In', 'other', 'words,', 'in', 'English,', 'both', 'phones', 'map', 'to', 'the', 'same', 'phoneme', 'perceptually.', 'As', 'the', 'Allosaurus', 'phone', 'recognizer', 'recognizes', 'the', 'actual', 'phones/sounds,', 'not', 'their', 'perceived', 'phonemes,', 'it', 'would', 'transcribe', 'these', 'two', 'phones', 'to', 'different', 'representations', 'even', 'for', 'English', 'speech.', 'This', 'can', 'be', 'mitigated', 'to', 'an', 'extent', 'by', 'customizing', 'the', 'output', 'of', 'Allosaurus', 'on', 'a', 'per-language', 'basis,', 'see', 'Sec.', '4.3.']",94,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
89198528-f577-4afd-baca-63f44b27c280,Comparison of post-editing productivity between professional translators and lay users,2014,Nora Aranberri;Gorka Labaka,"['unknown', ""Productivity or quality? Let's do both"", 'The efficacy of human post-editing for language translation', 'A productivity test of statistical machine translation post-editing in a typical localisation context', 'Productivity and quality in MT post-editing', 'Tapta: A user-driven translation system for patent documents based on domain-aware statistical machine translation']","['unknown', '2013', '2013', '2010', '2009', '2011']","['unknown', 'J Van Den Bogaert;unk De;N Sutter', 'S Green;J Heer;C Manning', 'M Plitt;F Masselot', 'A Guerberof', 'B Pouliquen;C Mazenc;A Iorio']",group,"['Thanks', 'to', 'the', 'significant', 'improvement', 'of', 'machine', 'translation', '(MT)', 'over', 'the', 'past', 'two', 'decades,', 'the', 'translation', 'industry', 'has', 'already', 'started', 'to', 'exploit', 'it,', 'mainly', 'by', 'combining', 'it', 'with', 'post-editing.', 'A', 'good', 'number', 'of', 'recent', 'works', 'report', 'a', 'productivity', 'increase', 'thanks', 'to', 'postediting', 'of', 'MT', 'output', 'as', 'compared', 'to', 'the', 'traditional', 'human', 'translation', '(e.g.,', '<ref type=""group"">Guerberof, 2009, Plitt and Masselot, 2010, Garcia, 2011, Pouliquen et al., 2011, Skadiņš et al., 2011, den Bogaert and Sutter, 2013, Green et al., 2013, Läubli et al., 2013).</ref>']",53,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1]"
8970ced6-b992-4e58-a3a8-a1dc27965bb3,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,"['Graph Constrained Reinforcement Learning for Natural Language Action Spaces', 'unknown']","['2020', 'unknown']","['Prithviraj Ammanabrolu;Matthew Hausknecht', 'unknown']",group,"['Text-based', 'Game', 'Playing', 'and', 'Generation.', 'Recent', 'text', 'game', 'playing', 'works', 'have', 'focused', 'on', 'tackling', 'three', 'primary', 'challenges:', '(1)', 'how', 'to', 'represent', 'agent', 'knowledge', 'to', 'effectively', 'operate', 'in', 'partially', 'observable', 'environments', '<ref type=""group"">(Adhikari et al., 2020, Sautier et al., 2020),</ref>', '(2)', 'scaling', 'RL', 'algorithms', 'to', 'handle', 'combinatorial', 'natural', 'language', 'state-action', 'spaces', '<ref type=""group"">(Zahavy et al., 2018, Ammanabrolu and Hausknecht, 2020, Jang et al., 2021),</ref>', 'and', '(3)', 'giving', 'agents', 'commonsense', 'priors', 'to', 'better', 'reason', 'about', 'the', 'world', '<ref type=""group"">(Murugesan et al., 2020 (Murugesan et al., , 2021) )</ref>', 'On', 'the', 'flip', 'side,', 'we', 'have', 'procedural', 'generation', 'of', 'games', 'with', 'works', 'such', 'as', 'Short', 'and', 'Adams', '(2017),', 'Risi', 'and', 'Togelius', '(2019),', 'Khalifa', 'et', 'al.']",42,"[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
8a6098c6-62c2-417d-a4f6-b9619982fddd,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Isolating sources of disentanglement in variational autoencoders'],['2018'],['T Ricky;Xuechen Chen;unk Li;B Roger;David Grosse;unk Duvenaud'],single,"['where', 'X', '∈', '{A,', 'B,', 'C,', 'D}).', 'We', 'consider', 'two', 'settings', 'where', 'each', 'generative', 'factor', 'is', 'embedded', 'in', 'a', 'single', 'dimension', '(denoted', 'by', 'Ex.1),', 'or', 'two', 'dimensions', '(denoted', 'by', 'Ex.2).', 'In', 'each', 'setting', 'we', 'uniformly', 'sample', '20', 'values', 'from', '-1', 'to', '1', 'to', 'represent', '20', 'assignments', 'per', 'factor', 'and', 'use', 'them', 'to', 'allocate', 'the', 'assignments', 'into', 'distinctive', 'bins', 'per', 'each', 'corresponding', 'dimension.', 'By', 'concatenating', 'dimensions', 'for', 'each', 'generative', 'factor,', 'we', 'construct', 'two', 'ideal', 'disentangled', 'representations', 'for', 'data', 'points', 'in', 'this', 'toy', 'dataset,', 'amounting', 'to', '4', 'and', '8', 'dimensional', 'representations,', 'respectively.', 'Using', 'these', 'representations', '(skipping', 'the', 'encoding', 'step),', 'we', 'measured', 'the', 'above', 'metrics.', 'Table', '1', '(Ex.1', 'and', 'Ex.2', 'columns)', 'summarises', 'the', 'results,', 'illustrating', 'that', 'out', 'of', 'the', '6', 'metrics,', '<ref type=""single"">Higgins et al. (2017),</ref>', 'Ridgeway', 'and', 'Mozer', '(2018),', '<ref type=""single"">Kim and Mnih (2018)</ref>', 'are', 'the', 'only', 'ones', 'that', 'reach', 'the', 'potential', 'maximum', '(i.e.,', '100),', 'while', '<ref type=""single"">Chen et al. (2018)</ref>', 'exhibits', 'its', 'sensitivity', 'towards', 'completeness', 'when', 'we', 'allocate', 'two', 'dimensions', 'per', 'factors.']",136,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]"
8a7cbc11-0280-4372-8b0d-3a0186874df3,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,"['Feverous: Fact extraction and verification over unstructured and structured information', 'FEVER: a large-scale dataset for fact extraction and VERification']","['2021', '2018']","['Rami Aly;Zhijiang Guo;M Schlichtkrull;James Thorne', 'James Thorne;Andreas Vlachos;Christos Christodoulopoulos;Arpit Mittal']",group,"['Following', 'the', 'widely', 'adopted', 'fact', 'verification', 'pipeline', '<ref type=""group"">(Thorne et al., 2018, Aly et al., 2021),</ref>', 'we', 'take', 'three', 'steps', 'to', 'solve', 'the', 'FEVEROUS', 'task', '(i)', 'retrieving', 'pages', 'from', 'the', 'Wikipedia', 'dump,', '(ii)', 'extracting', 'evidence', 'from', 'the', 'retrieved', 'pages,', 'and', '(iii)', 'verifying', 'the', 'claim', 'according', 'to', 'extracted', 'evidence.']",7,"[2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
8aa01f75-555a-4236-987b-0719b4b890b5,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Author profiling for abuse detection'],['2018'],['Pushkar Mishra;Marco Tredici;Helen Yannakoudakis;Ekaterina Shutova'],single,"['Twitter', 'has', 'been', 'the', 'most', 'common', 'online', 'platform', 'from', 'which', 'researchers', 'have', 'sourced', 'datasets', 'with', 'user', 'and', 'community', 'information.', 'Galán-García', 'et', 'al.', '(2016)', 'constructed', 'a', 'dataset', 'of', '1,', '900', 'tweets', 'from', '19', 'different', 'twitter', 'accounts', 'with', 'time', 'of', 'publication,', 'language,', 'and', 'geo-position', 'for', 'each', 'tweet', 'taken', 'from', 'the', 'profile', 'of', 'the', 'user', 'who', 'created', 'it.', '<ref type=""single"">Waseem and Hovy (2016)</ref>', 'released', 'a', 'list', 'of', '16,', '907', 'tweet', 'IDs', 'along', 'with', 'their', 'corresponding', 'annotations,', 'labeling', 'each', 'tweet', 'as', 'racist,', 'sexist', 'or', 'neither.', 'For', 'each', 'tweet,', 'the', 'dataset', 'contains', 'the', 'gender', 'of', 'the', 'user', 'who', 'created', 'it', 'along', 'with', 'their', 'geo-location.', 'Since', 'Twitter', 'APIs', 'allow', 'researchers', 'to', 'access', 'information', 'about', 'a', 'user', 'given', 'a', 'tweet', 'ID,', 'the', 'dataset', 'of', '<ref type=""single"">Waseem and Hovy (2016)</ref>', 'was', 'expanded', 'by', '<ref type=""single"">Mishra et al. (2018a)</ref>', 'to', 'include', 'the', 'follower-following', 'information', 'amongst', 'users', 'who', 'created', 'the', 'tweets', 'contained', 'in', 'the', 'dataset.', '<ref type=""single"">Ribeiro et al. (2018)</ref>', '2016)', 'which', 'respective', 'contain', '5,', '668', 'Portuguese', 'tweets', 'and', '13,', '766', 'German', 'tweets', 'by', 'using', 'Twitter', 'APIs', 'to', 'get', 'user', 'information', 'such', 'as', 'gender,', 'number', 'of', 'followers,', 'number', 'of', 'status', 'updates,', 'etc.', 'Deviating', 'from', 'Twitter,', '<ref type=""single"">Pavlopoulos et al. (2017b)</ref>', 'released', 'a', 'dataset', 'of', '1.45M', 'abusive', 'and', 'benign', 'comments', 'in', 'Greek', 'sourced', 'from', 'the', 'news', 'portal', 'Gazzetta.', 'For', 'each', 'comment,', 'the', 'dataset', 'also', 'contains', 'the', 'ID', 'of', 'the', 'user', 'who', 'created', 'the', 'comment.']",117,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8ac851c4-743d-44ca-b84a-fd8f86c00f6c,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['unknown'],['unknown'],['unknown'],single,"['The', 'study', 'uses', 'a', 'self-built', 'corpus.', 'Since', 'the', 'phenomenon', 'of', 'public', 'apologies', 'is', 'relatively', 'recent', 'in', 'India,', 'we', 'could', 'only', 'access', 'a', 'corpus', 'of', '18', 'apologies', 'available', 'in', 'the', 'digital', 'public', 'domain,', 'offered', 'during', '2007-2017.', 'The', 'corpus', 'is', 'in', 'the', 'English', 'language', 'as', 'it', 'is', 'the', 'second', 'official', 'language', 'in', 'India.', 'It', 'is', 'the', 'lingua', 'franca', 'spoken', 'amongst', 'a', 'wide', 'proportion', 'of', 'the', 'population', 'and', 'has', 'about', '125', 'million', 'speakers,', 'which', 'is,', 'country-wise,', 'the', 'second', 'highest', 'in', 'the', 'world,', 'only', 'below', 'United', 'States', 'of', 'America', '4.', 'We', 'employ', 'a', 'close', 'reading', 'approach', '<ref type=""single"">(Amernic et al., 2007)</ref>', 'for', 'the', 'analysis.', 'All', 'of', 'the', 'selected', 'apologies', 'were', 'delivered', 'in', 'India,', 'by', 'Indians', 'so', 'as', 'to', 'understand', 'any', 'cultural', 'implication', 'of', 'the', 'communication.', 'All', 'of', 'these', 'were', 'offered', 'by', 'senior', 'executives', 'of', 'the', 'company', 'or', 'prominent', 'public', 'personalities', 'in', 'India.', 'Of', 'these', 'two', 'were', 'electronic', 'mails,', 'seven', 'were', 'letters,', 'four', 'were', 'blog', 'posts,', 'four', 'were', 'tweets', 'out', 'of', 'which', 'two', 'are', 'related', 'to', 'the', 'same', 'event,', 'and', 'one', 'was', 'a', 'media', 'statement.', 'Out', 'of', 'the', '18', 'apologies,', '11', 'were', 'given', 'by', 'individual(s)', 'in', 'a', 'role,', '3', 'were', 'given', 'by', 'organizations', 'and', '4', 'were', 'given', 'by', 'individuals.', 'The', 'gender-wise', 'distribution', 'of', 'the', 'apology', 'givers', 'is', '14', 'males', 'and', '4', 'females.', 'The', 'apologies', 'selected', 'have', 'been', 'assigned', 'a', 'code', 'number', 'for', 'easy', 'reference.']",92,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8b00fba7-4317-471f-98ff-f91a916027f5,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Rethinking attention with performers'],['2021'],['Valerii Krzysztof Marcin Choromanski;David Likhosherstov;Xingyou Dohan;Andreea Song;Tamas Gane;Peter Sarlos;Jared Hawkins;Afroz Davis;Lukasz Mohiuddin;David Kaiser;Lucy Belanger;Adrian Colwell;unk Weller'],single,"['In', 'this', 'section,', 'we', 'benchmark', 'top-k', 'attention', 'in', 'terms', 'of', 'time', 'and', 'memory,', 'and', 'compare', 'it', 'to', 'vanilla', 'attention,', 'query-chunking', 'without', 'the', 'top-k', 'operation,', 'and', 'to', 'Performer', '<ref type=""single"">(Choromanski et al., 2021),</ref>', 'as', 'a', 'representative', 'of', 'state-of-the-art', 'linear', 'attention', 'variants.', 'We', 'separately', 'benchmark', '(a)', 'a', 'single', 'self-attention', 'layer', 'over', 'long', 'sequences,', '(b)', 'a', 'single', 'feed-forward', 'layer', 'with', 'a', 'large', 'feedforward', 'dimension,', 'and', '(c)', 'a', '12-layer', 'Transformer', 'decoder', 'with', 'same', 'architecture', 'as', 'BERT-base', '<ref type=""single"">(Devlin et al., 2019).</ref>']",27,"[0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8bc60d2e-6458-4108-9fca-aec671910615,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Hierarchical neural story generation'],['2018'],['Angela Fan;Mike Lewis;Yann Dauphin'],single,"['To', 'the', 'best', 'of', 'our', 'knowledge,', 'we', 'are', 'the', 'first', 'work', 'to', 'explore', 'diverse', 'knowledge', 'reasoning', 'on', 'commonsense', 'KG', 'to', 'generate', 'multiple', 'diverse', 'output', 'sequences.', 'Therefore,', 'we', 'only', 'compared', 'our', 'MoKGE', 'with', 'existing', 'diversity-promoting', 'baselines', 'without', 'using', 'knowledge', 'graph.', 'VAE-based', 'method.', 'The', 'variational', 'auto-encoder', '(VAE)', '(Kingma', 'and', 'Welling,', '2014)', 'is', 'a', 'deep', 'generative', 'latent', 'variable', 'model.', 'VAE-based', 'methods', 'produce', 'diverse', 'outputs', 'by', 'sampling', 'different', 'latent', 'variables', 'from', 'an', 'approximate', 'posterior', 'distribution.', 'CVAE-SVG', '(SVG', 'is', 'short', 'for', 'sentence', 'variant', 'generation)', '<ref type=""single"">(Gupta et al., 2018)</ref>', 'is', 'a', 'conditional', 'VAE', 'model', 'that', 'can', 'produce', 'multiple', 'outputs', 'based', 'an', 'original', 'sentence', 'as', 'input.', 'MoE-based', 'method.', 'Mixture', 'models', 'provide', 'an', 'alternative', 'approach', 'to', 'generate', 'diverse', 'outputs', 'by', 'sampling', 'different', 'mixture', 'components.', 'We', 'compare', 'against', 'two', 'mixture', 'of', 'experts', '(MoE)', 'implementations', 'by', '<ref type=""single"">Shen et al. (2019)</ref>', 'and', '<ref type=""single"">Cho et al. (2019).</ref>', 'We', 'refer', 'them', 'as', 'MoE-prompt', '<ref type=""single"">(Shen et al., 2019)</ref>', 'and', 'MoE-embed', '<ref type=""single"">(Cho et al., 2019).</ref>', 'Sampling-based', 'method.', 'Sampling', 'methods', 'create', 'diverse', 'outputs', 'by', 'sampling', 'next', 'token', 'widely', 'from', 'the', 'vocabulary.', 'We', 'compare', 'against', 'two', 'sampling', 'algorithms', 'for', 'decoding,', 'including', 'truncated', 'sampling', '<ref type=""single"">(Fan et al., 2018)</ref>', 'and', 'nucleus', 'sampling', '<ref type=""single"">(Holtzman et al., 2020).</ref>', 'Truncated', 'sampling', '<ref type=""single"">(Fan et al., 2018)</ref>', 'randomly', 'samples', 'words', 'from', 'top-k', 'probability', 'candidates', 'of', 'the', 'predicted', 'distribution', 'at', 'each', 'decoding', 'step.', 'Nucleus', 'sampling', '<ref type=""single"">(Holtzman et al., 2020)</ref>', 'avoids', 'text', 'degeneration', 'by', 'truncating', 'the', 'unreliable', 'tails', 'and', 'sampling', 'from', 'the', 'dynamic', 'nucleus', 'of', 'tokens', 'containing', 'the', 'vast', 'majority', 'of', 'the', 'probability', 'mass.']",161,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8c251b9f-ad18-4b1e-8565-968f09bef670,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['We', 'create', 'entity', 'representations', 'of', 'a', 'mention', 'span', 'm', 'and', 'a', 'context', 's', 'using', 'ELMo', '<ref type=""single"">(Peters et al., 2018)</ref>', 'and', 'BERT', '<ref type=""single"">(Devlin et al., 2019).</ref>', 'We', 'largely', 'follow', 'the', 'embedding', 'procedure', 'of', '<ref type=""single"">Chen et al. (2019).</ref>', 'Their', 'downstream', 'models', 'use', 'trainable', 'weights', 'to', 'combine', 'the', 'vectors', 'from', 'the', 'pre-trained', 'model', 'layers,', 'we', 'use', 'this', 'in', 'the', 'baselines', 'as', 'well', 'except', 'for', 'the', 'results', 'in', 'Table', '4', 'and', 'for', 'ELMo.', 'Note', 'that', 'we', 'do', 'not', 'fine', 'tune', 'the', 'ELMo', 'and', 'BERT', 'parameters', 'of', 'the', 'baselines,', 'since', 'our', 'focus', 'is', 'on', 'general', 'entity', 'representations', 'that', 'can', 'work', 'off-the-shelf', 'rather', 'than', 'task', 'specific', 'entity', 'representations.', 'Our', 'approach', 'does', 'not', 'use', 'task', 'specific', 'fine', 'tuning', 'either.', 'ELMO', 'We', 'run', 'ELMo', 'on', 'the', 'entire', 'sentence', 's', 'and', 'combine', 'the', 'three', 'layer', 'outputs', 'using', 'uniform', 'weights.', 'Then,', 'we', 'average', 'contextualized', 'vectors', 'of', 'the', 'mention', 'span', 'm', 'to', 'obtain', 'the', 'entity', 'representation.']",18,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8c291514-72c3-47ec-885c-c28956296a8b,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Scikit-learn: Machine learning in Python'],['2011'],['F Pedregosa;G Varoquaux;A Gramfort;V Michel;B Thirion;O Grisel;M Blondel;P Prettenhofer;R Weiss;V Dubourg;J Vanderplas;A Passos;D Cournapeau;M Brucher;M Perrot;E Duchesnay'],single,"['With', 'the', 'regularization', 'values,', 'we', 'fed', 'several', 'machine', 'learning', 'algorithms', 'to', 'identify', 'and', 'predict', 'toxic', 'comments.', 'We', 'experimented', 'Multi', 'Layer', 'Perceptron,', 'Naïve', 'Bayes,', 'Decision', 'Tree,', 'Support', 'Vector', 'Machine,', 'and', 'Gradient', 'Boosting', 'from', 'the', 'Scikit-Learn', 'library', '<ref type=""single"">(Pedregosa et al., 2011).</ref>']",35,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]"
8c96e170-7a8c-40c1-af7d-0f98bc149678,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['What do you learn from context? Probing for sentence structure in contextualized word representations'],['2018'],['Ian Tenney;Patrick Xia;Berlin Chen;Alex Wang;Adam Poliak;Thomas Mccoy;Najoung Kim;Benjamin Van Durme;Samuel Bowman;Dipanjan Das;Ellie Pavlick'],single,"['we', 'have', 'a', 'single', 'multiclass', 'head', 'that', 'outputs', 'the', 'connecting', 'preposition', 'or', 'NONE,', 'in', 'case', 'the', 'NPs', 'are', 'not', 'connected.', 'We', 'also', 'experiment', 'with', 'a', 'frozen', '(or', ""''probing'')"", 'variant', 'of', 'both', 'models,', 'in', 'which', 'we', 'keep', 'the', 'MLM', 'frozen,', 'and', 'update', 'only', 'the', 'NP', 'encoding', 'and', 'prediction', 'heads.', 'The', 'frozen', 'architecture', 'is', 'intended', 'to', 'quantify', 'the', 'degree', 'to', 'which', 'the', 'pretrained', 'MLM', 'encodes', 'the', 'relevant', 'information,', 'and', 'it', 'is', 'very', 'similar', 'to', 'the', 'edge-probing', 'architecture', 'of', '<ref type=""single"">Tenney et al. (2018).</ref>', 'Finally,', 'the', 'static', 'variant', 'aims', 'to', 'measure', 'how', 'well', 'a', 'model', 'can', 'perform', 'with', 'NPs', 'alone,', 'without', 'considering', 'their', 'context.', 'This', 'model', 'sums', 'all', 'the', 'static', 'embeddings', 'of', 'each', 'span', 'and', 'uses', 'the', 'same', 'modeling', 'as', 'the', 'coupled', 'prediction.', 'This', 'baseline', 'uses', 'the', '300-dim', 'word2vec', 'non-contextualized', 'embeddings', '<ref type=""single"">(Mikolov et al., 2013).</ref>', 'We', 'experiment', 'with', 'two', 'versions:', 'decoupled', 'and', 'coupled.']",76,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8cc235c3-772d-408a-a3cc-faa89c54e974,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Domain adaptation in statistical machine translation of user-forum data using componentlevel mixture modelling'],['2011'],['P Banerjee;S Naskar;J Roturier;A Way;J Van Genabith'],single,"['Mixture', 'Modelling', '<ref type=""single"">[8],</ref>', 'a', 'well-established', 'technique', 'for', 'combining', 'multiple', 'models,', 'has', 'been', 'extensively', 'used', 'for', 'language', 'model', 'adaptation', 'in', 'SMT', '<ref type=""single"">[4].</ref>', 'This', 'technique', 'has', 'also', 'been', 'used', 'for', 'adapting', 'the', 'translation', 'model', 'in', 'SMT', 'with', 'limited', 'success', '<ref type=""single"">[9].</ref>', 'For', 'the', 'given', 'task,', 'since', 'the', 'size', 'of', 'the', ""'in-domain'"", 'data', 'was', 'not', 'significantly', 'large,', 'we', 'used', ""'suitable'"", 'subsets', 'of', 'data', 'from', 'the', 'other', 'available', ""'out-ofdomain'"", 'corpora', 'to', 'enrich', 'the', 'models.', 'For', 'a', 'mixture', 'adapted', 'language', 'model,', 'the', 'probability', 'of', 'an', 'n-gram', 'hw', 'is', 'given', 'as', 'in', '(2):P', 'r', 'mix', '(w|h)', '=', 'f', '*', 'mix', '(w|h)', '+', 'λ', 'mix', '(h)P', 'r', 'mix', '(w|', 'h)', '(2)where', 'w', 'is', 'the', 'current', 'word,', 'h', 'is', 'the', 'corresponding', 'history,', 'f', '*', 'mix', 'is', 'the', 'mixture', 'model', 'discounted', 'relative', 'fre-quency,', 'λ', 'mix', 'indicates', 'the', 'mixture', 'model', 'zero-frequency', 'estimate', 'and', 'hw', 'is', 'the', 'lower', 'order', 'n', '−', '1', 'gram.', 'The', 'discounted', 'frequency', 'and', 'zero-frequency', 'estimates', 'are', 'defined', 'as', 'follows:']",37,"[3, 3, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8e121d63-4fc5-4513-a494-4adc9cd3a10d,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,"['unknown', 'Exploring the limits of transfer learning with a unified text-totext transformer']","['unknown', '2020']","['unknown', 'Colin Raffel;Noam Shazeer;Adam Roberts;Katherine Lee;Sharan Narang;Michael Matena;Yanqi Zhou;Wei Li;Peter Liu']",group,"['The', 'training', 'paradigm', 'proposed', 'in', 'this', 'paper', 'may', 'be', 'extended', 'to', 'any', 'Seq2Seq', 'model.', 'However,', 'it', 'can', 'be', 'a', 'non-trivial', 'overhead', 'to', 'generate', 'the', 'candidate', 'summaries', 'using', 'large', 'neural', 'models', 'on', 'the', 'entire', 'training', 'set.', 'On', 'the', 'other', 'hand,', 'recent', 'work', '<ref type=""group"">(Raffel et al., 2020, Zhang et al., 2020, Schick and Schütze, System Summary</ref>', 'Reference', 'chelsea', 'forward', 'tammy', 'abraham', 'nets', 'first-half', 'double', 'for', 'chelsea.', 'dominic', 'solanke', 'adds', 'a', 'third', 'late', 'on', 'as', 'chelsea', 'look', 'set', 'to', 'win', 'trophy.', 'manchester', 'city', 'struggle', 'without', 'injured', 'star', 'thierry', 'ambrose.', 'read:', 'mourinho', 'warns', 'his', 'young', 'chelsea', 'players', 'he', 'can', 'not', 'play', 'them', 'all.', 'click', 'here', 'to', 'read', 'our', 'match', 'report', 'from', 'man', 'city', ""'s"", 'academy', 'stadium.']",41,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8e19c4ef-6fa8-43cd-98ec-d6a6b29e25d0,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['unknown'],['unknown'],['unknown'],single,"['Construction', 'with', 'masked', 'language', 'model.', 'We', 'construct', 'neighborhood', 'sentences', 'from', 'x', '0', 'by', 'substituting', 'at', 'most', 'k', 'tokens.', 'As', 'shown', 'in', 'Algorithm', '1,', 'the', 'construction', 'employs', 'a', 'recursive', 'approach', 'and', 'replaces', 'one', 'token', 'at', 'a', 'time.', 'For', 'each', 'recursion,', 'the', 'algorithm', 'first', 'masks', 'each', 'token', 'of', 'the', 'input', 'sentence', '(may', 'be', 'the', 'original', 'x', '0', 'or', 'the', 'x', 'from', 'last', 'recursion)', 'separately', 'and', 'predicts', 'likely', 'replacements', 'with', 'a', 'masked', 'language', 'model', '(e.g.,', '<ref type=""single"">DistilBERT, Sanh et al. 2019).</ref>', 'To', 'ensure', 'the', 'naturalness,', 'we', 'keep', 'the', 'top', '20', 'tokens', 'for', 'each', 'mask', 'with', 'the', 'largest', 'logit', '(subject', 'to', 'a', 'threshold,', 'Line', '9).', 'Then,', 'the', 'algorithm', 'constructs', 'neighborhood', 'sentences', 'by', 'replacing', 'the', 'mask', 'with', 'found', 'tokens.', 'We', 'use', 'the', 'notation', 'x', 'in', 'the', 'following', 'sections', 'to', 'denote', 'the', 'constructed', 'sentences', 'within', 'the', 'neighborhood.', 'L', '←', 'SortDecreasing(L),', '9', 'lmin', '←', 'max{L', '(κ),', 'L', '(0)', '−', 'δ},']",72,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8e41a066-a5c1-4ca7-b26c-f8b9ee46857d,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,"[""Why 'I'm sorry' doesn't always translate""]",['2012'],['William Maddux;Peter Kim;Tetsushi Okumara;Jeanne Brett'],single,"['Culturally,', 'saying', 'sorry', 'does', 'not', 'come', 'easy', 'to', 'Indians', 'and', 'more', 'so', 'to', 'Indian', 'business', 'and', 'political', 'leaders.', 'This', 'hesitation', 'can', 'perhaps', 'be', 'linked', 'to', 'the', 'fact', 'that', 'in', 'India', 'a', 'public', 'apologyis', 'seen', 'as', 'an', 'admission', 'of', 'guilt', '<ref type=""single"">(Maddux et al, 2012).</ref>', 'On', 'the', 'other', 'hand', 'it', 'is', 'a', 'common', 'occurrence', 'in', 'countries', 'like', 'Japan', 'and', 'Hong', 'Kong,', 'where', 'the', 'corporate', 'apology', 'is', 'an', 'expression', 'of', 'eagerness', 'to', 'repair', 'damage', 'and', 'relationships', 'and', 'does', 'not', 'imply', 'guilt', '(ibid).', 'In', 'the', 'past,', 'the', 'speech', 'act', 'of', 'apology', 'was', 'almost', 'absent', 'from', 'the', 'repertoire', 'of', 'Indian', 'corporates', 'and', 'public', 'figures', '<ref type=""single"">(Kaul et al,2015).</ref>', 'Even', 'written', 'apologies', 'were', 'very', 'few', 'and', 'were', 'offered', 'only', 'when', 'there', 'was', 'a', 'strong', 'demand', 'from', 'different', 'sections', 'of', 'society.', 'However,', 'the', 'new', 'generation', 'e-commerce', 'companies', 'seem', 'to', 'be', 'heralding', 'an', 'attitudinal', 'change', 'in', 'this', 'corporate', 'practice.', 'This', 'could', 'be', 'due', 'to', 'the', 'increasing', 'digital', 'customer', 'base', 'for', 'India', 'Inc.', ""India's"", 'internet', 'user', 'base', 'has', 'grown', 'to', '324.95', 'million', 'in', 'September', '2015,', 'a', '27.73%', 'YOY', 'growth', '(TRAI,', '2016).', 'On', 'social', 'media', 'platforms', 'situations', 'can', 'escalate', 'rapidly,', 'breaking', 'down', 'the', 'traditional', 'barriers', 'of', 'time,', 'location,', 'and', 'gatekeepers', 'of', 'information', '<ref type=""single"">(Kaul et al, 2015).</ref>', 'Thus,', 'in', 'stark', 'contrast', 'to', 'the', 'past,', 'we', 'see', 'a', 'spate', 'of', 'apology', 'e-mails,', 'tweets', 'and', 'blog', 'posts', 'being', 'offered', 'by', 'e-commerce', 'players', '(ibid).', 'Figure', '1', 'shows', 'the', 'rising', 'trend', 'of', 'apologies', 'being', 'given', 'publicly', 'in', 'the', 'written', 'digital', 'media,', 'with', 'a', 'sharp', 'increase', 'from', 'the', 'year', '2016', 'to', '2017.', 'Since', 'the', 'practice', 'of', 'offering', 'a', 'public', 'apology', 'is', 'relatively', 'new', 'for', 'Indian', 'businesses,', 'it', 'is', 'to', 'be', 'understood', 'that', 'an', 'apology', 'not', 'delivered', 'effectively', 'rather', 'than', 'mitigating', 'the', 'damage,', 'can', 'escalate', 'the', 'damage', 'done.', 'In', 'this', 'context,', 'it', 'is', 'important', 'to', 'analyze', 'the', 'lexical', 'choice', 'made', 'in', 'these', 'apologies', 'and', 'the', 'implications', 'thereof.']",39,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8e8a93fe-50f6-4b0c-b432-a51eb572b7ad,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments'],['2005'],['S Banerjee;A Lavie'],single,"['Subjective', 'evaluation', 'was', 'performed', 'after', 'first', 'poor', 'BLEU', 'results', 'triggered', 'some', 'distrust.', 'Many', 'authors', 'agree', 'that', 'BLEU', 'metric', 'systematically', 'penalizes', 'RBMT', 'systems', '<ref type=""single"">(Callison-Burch et al., 2006)</ref>', 'and', 'it', 'is', 'not', 'suited', 'for', 'highly', 'inflexible', 'languages.', 'Authors', 'of', 'METEOR', '<ref type=""single"">(Banerjee et al., 2005),</ref>', '<ref type=""single"">(Lavie, 2007)</ref>', 'state', 'that', 'their', 'system', 'fixes', 'most', 'of', 'the', 'problems', 'encountered', 'using', 'BLEU', 'metric,', 'they', 'state', 'that', 'METEOR', 'correlates', 'highly', 'with', 'human', 'judgement.', 'Unfortunately', 'METEOR', 'does', 'not', 'support', 'our', 'language', 'pair,', 'we', 'hope', 'to', 'change', 'this', 'in', 'the', 'near', 'future,', 'see', 'further', 'work', 'Separate', 'scales', 'for', 'fluency', 'and', 'adequacy', 'were', 'developed', 'under', 'the', 'assumption', 'that', 'a', 'translation', 'might', 'be', 'disfluent', 'but', 'contain', 'all', 'the', 'information', 'from', 'the', 'source.']",35,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
8eae5aa3-977e-4b76-9a0c-c70cc5aadb3a,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['OpusTools and Parallel Corpus Diagnostics'],['2020'],['Mikko Aulamo;Umut Sulubacak;Sami Virpioja;Jörg Tiedemann'],single,"['To', 'test', 'how', 'well', 'our', 'data', 'is', 'suited', 'for', 'emotion', 'projection,', 'we', 'projected', 'the', 'English', 'annotations', 'onto', 'our', 'Finnish', 'unannotated', 'data', 'using', 'OPUS', 'tools', '<ref type=""single"">(Aulamo et al., 2020).</ref>', 'We', 'chose', 'Finnish', 'as', 'our', 'main', 'test', 'language', 'as', 'we', 'also', 'have', 'some', 'annotated', 'data', 'for', 'it', 'to', 'use', 'as', 'a', 'test', 'set.', 'The', 'manually', 'annotated', 'Finnish', 'data', 'consists', 'of', 'nearly', '20k', 'individual', 'annotations', 'and', 'almost', '15k', 'unique', 'annotated', 'sentences', 'plus', 'an', 'additional', '7,536', 'sentences', 'annotated', 'as', 'neutral', '6.', 'The', 'criteria', 'for', 'the', 'inclusion', 'of', 'an', 'annotation', 'was', 'the', 'same', 'as', 'for', 'English.', 'The', 'distribution', 'of', 'the', 'number', 'of', 'labels', 'and', 'the', 'labels', 'themselves', 'are', 'quite', 'similar', 'to', 'that', 'of', 'the', 'English', 'data.', 'Relatively', 'speaking', 'there', 'is', 'a', 'little', 'less', 'anticipation', 'in', 'the', 'Finnish', 'data,', 'but', 'anger', 'is', 'the', 'biggest', 'category', 'in', 'both', 'languages.', 'We', 'used', 'the', '11,128', 'Finnish', 'sentences', 'for', 'which', 'directly', 'parallel', 'sentences', 'existed', 'and', 'projected', 'the', 'English', 'annotations', 'on', 'them', 'using', 'the', 'unique', 'alignment', 'IDs', 'for', 'both', 'languages', 'as', 'guide.', 'Some', 'of', 'those', 'parallel', 'sentences', 'were', 'part', 'of', 'our', 'already', 'annotated', 'data', 'and', 'were', 'discarded', 'as', 'training', 'data.', 'This', 'served', 'as', 'a', 'useful', 'point', 'of', 'comparison.', 'The', 'average', 'annotation', 'correlation', 'using', ""Cohen's"", 'kappa', 'is', '0.44', '(although', 'accuracy', 'by', 'percentage', 'is', 'over', '90%),', 'and', 'highest', 'for', 'joy', 'at', '0.65,', 'showing', 'that', 'annotation', 'projection', 'differs', 'from', 'human', 'annotation', 'to', 'a', 'similar', 'degree', 'as', 'human', 'annotations', 'differ', 'from', 'each', 'other.']",24,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8eb9eece-4177-403b-99c2-f7d2e46ba907,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Meteor: an automatic metric for mt evaluation with high levels of correlation with human judgments'],['2007'],['A Lavie;A Agarwal'],single,"['For', 'our', 'PBSMT-based', 'translation', 'experiments', 'we', 'used', 'OpenMaTrEx', '<ref type=""single"">[15],</ref>', 'an', 'open', 'source', 'SMT', 'system', 'which', 'provides', 'a', 'wrapper', 'around', 'the', 'standard', 'log-linear', 'phrase-based', 'SMT', 'system', 'Moses', '<ref type=""single"">[6].</ref>', 'Word', 'alignment', 'was', 'performed', 'using', 'Giza++', '<ref type=""single"">[16].</ref>', 'The', 'phrase', 'and', 'the', 'reordering', 'tables', 'were', 'built', 'on', 'the', 'word', 'alignments', 'using', 'the', 'Moses', 'training', 'script.', 'The', 'feature', 'weights', 'for', 'the', 'log-linear', 'combination', 'of', 'the', 'feature', 'functions', 'were', 'tuned', 'using', 'Minimum', 'Error', 'Rate', 'Training', '(MERT)', '<ref type=""single"">[7]</ref>', 'on', 'the', 'devset', 'with', 'respect', 'to', 'BLEU', '<ref type=""single"">[17].</ref>', 'We', 'used', '5-gram', 'language', 'models', 'in', 'all', 'our', 'experiments', 'created', 'using', 'the', 'IRSTLM', 'language', 'modelling', 'toolkit', '<ref type=""single"">[18]</ref>', 'using', 'Modified', 'Kneser-Ney', 'smoothing', '<ref type=""single"">[19].</ref>', 'Mixture', 'adaptation', 'of', 'language', 'models', 'mentioned', 'in', 'Section', '2.2', 'was', 'also', 'performed', 'using', 'the', 'features', 'of', 'the', 'IRSTLM', 'toolkit.', 'Results', 'of', 'translations', 'in', 'every', 'phase', 'of', 'our', 'experiments', 'were', 'evaluated', 'using', 'BLEU,', 'METEOR', '<ref type=""single"">[20]</ref>', 'and', 'TER', '<ref type=""single"">[21]</ref>', 'metrics.', 'The', 'datasets', 'used', 'for', 'the', 'experiments', 'included', 'the', 'specific', 'datasets', 'released', 'by', 'the', 'IWSLT', '2011', 'evaluation', 'campaign.', 'The', 'primary', 'bi-lingual', 'training', 'data', 'comprised', 'of', 'a', 'collection', 'of', 'public', 'speech', 'transcriptions', 'on', 'a', 'variety', 'of', 'topics', 'from', 'TED', 'Talks.', 'The', 'development', 'data', 'released', 'for', 'the', 'task,', 'comprised', 'of', 'both', 'the', 'IWSLT-2010', '4', 'development', 'and', 'test', 'sets.', 'However,', 'for', 'experiments', 'reported', 'in', 'this', 'paper,', 'the', 'IWSLT-2010', 'development', 'set', 'and', 'test', 'sets', 'were', 'used', 'for', 'tuning', 'and', 'testing', 'respectively.', 'As', 'an', 'auxiliary', 'out-of-domain', 'source', 'of', 'bi-lingual', 'training', 'data,', 'the', 'Multi-UN', 'corpus', 'was', 'also', 'released.', 'The', 'monolingual', 'data', 'required', 'to', 'train', 'lan-guage', 'models', 'also', 'comprised', 'of', 'data', 'from', 'both', 'Multi-UN', 'and', 'TED', 'Talks.', 'Table', '1', 'shows', 'the', 'exact', 'sentence', 'counts', 'of', 'the', 'different', 'datasets', 'used', 'in', 'the', 'experiments.']",134,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8f0f30f4-6921-4847-a820-1ffeae7c273a,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['LIGHT-Original.', 'The', 'task', 'itself', 'dervied', 'from', 'the', 'original', 'LIGHT', 'dataset', '<ref type=""single"">(Urbanek et al., 2019)</ref>', 'and', 'involves', 'predicting', 'the', 'next', 'action', 'or', 'utterance', 'given', 'the', 'prior', 'dialogue', 'history', 'as', 'well', 'as', 'the', 'current', 'setting', 'and', 'persona', 'for', 'a', 'character.', 'They', 'are', 'collected', 'in', 'a', 'chit-chat', 'fashion,', 'with', 'no', 'notion', 'of', 'objectives,', 'and', 'so', 'provide', 'priors', 'on', 'how', 'to', 'generally', 'act', 'consistently', 'and', 'speak', 'in', 'a', 'fantasy', 'world,', 'but', 'not', 'directly', 'how', 'to', 'complete', 'quests.']",10,"[3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8f359163-3ecc-4e7c-ac6d-6d529e3585ab,Diverse dialogue generation with context dependent dynamic loss function,2020,Ayaka Ueyama;Yoshinobu Kano,['A diversity-promoting objective function for neural conversation models'],['2016'],['Jiwei Li;Michel Galley;Chris Brockett;Jianfeng Gao;Bill Dolan'],single,"['However,', 'sentence', 'diversity', 'is', 'based', 'not', 'only', 'on', 'individual', 'tokens,', 'but', 'also', 'on', 'the', 'token', 'sequence.', 'We', 'are', 'able', 'to', 'compute', 'weights', 'for', 'loss', 'functions', 'dynamically,', 'depending', 'on', 'the', 'context,', 'while', 'retaining', 'the', 'fluency', 'of', 'generated', 'sentences.', 'We', 'propose', 'such', 'a', 'loss', 'function,', 'Inverse', 'N-gram', 'Frequency', '(INF)', 'loss,', 'which', 'uses', 'the', 'inverse', 'of', 'the', 'frequency', 'of', 'the', 'n-gram', 'of', 'the', 'tokens,', 'rather', 'than', 'the', 'token', 'frequency.', 'We', 'built', 'a', 'neural', 'dialogue', 'system', 'trained', 'by', 'INF', 'loss', 'using', 'huge', 'amounts', 'of', 'dialogue', 'data', 'extracted', 'from', 'Twitter.', 'After', 'comparing', 'models', 'using', 'the', 'SCE', 'loss,', 'the', 'ITF', 'loss,', 'and', 'the', 'INF', 'loss,', 'we', 'evaluated', 'their', 'diversity', 'and', 'fluency.', 'Results', 'show', 'that', 'our', 'proposed', 'INF', 'loss', 'model', 'outperformed', 'the', 'SCE', 'loss', 'and', 'ITF', 'loss', 'models', 'for', 'most', 'automatic', 'assessment', 'measures', 'such', 'as', 'DIST-N', '<ref type=""single"">(Li et al., 2016)</ref>', 'and', 'ROUGE', '<ref type=""single"">(Lin, 2004).</ref>', 'Our', 'INF', 'loss', 'model', 'also', 'achieved', 'higher', 'scores', 'on', 'our', 'human', 'evaluations', 'of', 'coherence', 'and', 'richness.']",129,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8f883bbf-1439-4b2d-9310-e0950c5f0985,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Fine-Grained Entity Typing for Domain Independent Entity Linking'],['2020'],['Yasumasa Onoe;Greg Durrett'],single,"['We', 'collect', 'a', 'set', 'of', 'occurrences', 'of', 'typed', 'entity', 'mentions', 'using', 'hyperlinks', 'in', 'Wikipedia.', 'Given', 'a', 'sentence', 'with', 'a', 'hyperlink,', 'we', 'use', 'the', 'hyperlink', 'as', 'an', 'entity', 'mention', 'm,', 'the', 'sentence', 'as', 'a', 'context', 'sentence', 's,', 'and', 'the', 'Wiki', 'categories', 'of', 'the', 'destination', 'page', 'as', 'the', 'gold', 'entity', 'types', 't', '*.', 'We', 'use', 'the', 'preprocessing', 'of', '<ref type=""single"">Onoe and Durrett (2020)</ref>', 'to', 'modify', 'the', 'type', 'set:', 'they', 'introduce', 'more', 'general', 'categories', 'into', 'the', 'Wikipedia', 'category', 'set', 'by', 'splitting', 'existing', 'complex', 'categories.', 'Following', 'their', 'work,', 'we', 'filter', 'the', 'resulting', 'set', 'to', 'keep', 'the', '60,000', 'most', 'frequent', 'types.', 'Scraping', 'Wikipedia', 'yields', '6M', 'training', 'examples', 'that', 'cover', 'a', 'wide', 'range', 'of', 'entities', 'and', 'entity', 'types.']",56,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8f8c298c-9584-4ccb-966a-4a411183e116,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,"['On the transfer of disentangled representations in realistic settings', 'beta-vae: Learning basic visual concepts with a constrained variational framework', 'Disentangling by factorising']","['2021', '2017', '2018']","['Andrea Dittadi;Frederik Träuble;Francesco Locatello;Manuel Wuthrich;Vaibhav Agrawal;Ole Winther;Stefan Bauer;Bernhard Schölkopf', 'Irina Higgins;Loïc Matthey;Arka Pal;Christopher Burgess;Xavier Glorot;Matthew Botvinick;Shakir Mohamed;Alexander Lerchner', 'Hyunjik Kim;Andriy Mnih']",group,"['The', 'use', 'of', 'synthetic', 'datasets', 'is', 'the', 'common', 'practice', 'for', 'evaluating', 'disentanglement', 'in', 'image', 'domain', '<ref type=""group"">(Dittadi et al., 2021, Higgins et al., 2017, Kim and Mnih, 2018).</ref>', 'Generative', 'simplistic', 'datasets', 'in', 'image', 'domain', 'define', 'independent', 'generative', 'factors', '(e.g.', 'shape,', 'color)', 'behind', 'the', 'data', 'generation.', 'However,', 'a', 'comparable', 'resource', 'is', 'missing', 'in', 'text', 'domain.', 'We', 'develop', 'two', 'synthetic', 'generative', 'datasets', 'with', 'varying', 'degrees', 'of', 'difficulty', 'to', 'analyse', 'and', 'measure', 'disentanglement:', 'The', 'YNOC', 'dataset', '(§3.1)', 'which', 'has', 'only', 'three', 'structures', 'and', 'generative', 'factors', 'appearing', 'in', 'every', 'sentence,', 'and', 'the', 'POS', 'dataset', '(§3.2)', 'which', 'has', 'more', 'structures', 'while', 'some', 'generative', 'factors', 'are', 'not', 'guaranteed', 'to', 'appear', 'in', 'every', 'sentence.', 'The', 'YNOC', 'dataset', 'offers', 'a', 'simpler', 'setting', 'for', 'disentanglement.', 'The', 'templates', 'were', 'then', 'converted', 'into', 'real', 'sentences', 'using', '10', 'years,', '40', 'names,', '20', 'occupations,', 'and', '30', 'cities.', 'This', 'amounted', 'to', 'a', 'total', 'of', '720K', 'sentences,', 'split', 'as', '(60%,20%,20%)', 'into', 'training,', 'validation,', 'and', 'test', 'sets.']",15,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8fd8c1a0-5f91-43bd-8ea5-09c2e85dd4f7,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Translating embeddings for modeling multirelational data'],['2013'],['Antoine Bordes;Nicolas Usunier;Alberto Garcia-Duran;Jason Weston;Oksana Yakhnenko'],single,"['where', 'h', 'v', 'and', 'h', 'r', 'are', 'node', 'embedding', 'and', 'relation', 'embedding.', 'We', 'define', 'the', 'compositional', 'operation', 'as', 'ϕ(h', 'u,', 'h', 'r)', '=', 'h', 'u', '−h', 'r', 'inspired', 'by', 'the', 'TransE', '<ref type=""single"">(Bordes et al., 2013).</ref>', 'The', 'relation', 'embedding', 'is', 'also', 'updated', 'via', 'another', 'linear', 'transformation:']",31,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
8ff309b3-e036-48bb-9f33-81f950527a7c,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,['Aifbwebscience at semeval-2022 task 12: Relation extraction firstusing relation extraction to identify entities'],['2022'],['Nicholas Popovic;Walter Laurito'],single,"['Among', 'four', 'submitted', 'systems,', 'MaChAmp', '(der', 'Goot,', '2022)', 'and', 'AN(L)P', '<ref type=""single"">(Ping and Chi, 2022)</ref>', 'teams', 'used', 'the', 'default', 'tokenizer', 'from', 'either', 'BERT', 'or', 'mBERT,', 'which', 'are', 'not', 'designed', 'for', 'scientific', 'documents.', 'Consequently,', 'they', 'are', 'unable', 'to', 'correctly', 'segment', 'the', 'mathematic', 'source,', 'hence,', 'they', '<ref type=""single"">(Popovic and Laurito, 2022)</ref>', 'and', 'JBNU-CCLab', '(Lee', 'and', 'Na,', '2022)', 'achieved', 'much', 'higher', 'performances', 'thanks', 'to', 'SciBERT', 'tokenizer', 'because', 'it', 'is', 'trained', 'on', 'scientific', 'literature.', 'However,', 'the', 'SciBERT', 'tokenizer', 'is', 'far', 'from', 'perfect', 'such', 'that', 'JBNU-CCLab', 'further', 'proposed', 'to', 'tokenize', 'the', 'mathematical', 'formulae', 'using', 'a', 'customized', 'rule-based', 'tokenizer', 'based', 'on', 'capital', 'letters,', 'numbers,', 'and', 'special', 'characters(e.g.', '%,', '$,', '{,', '}).', 'Hence,', 'they', 'achieved', 'state-of-the-art', 'performance', 'on', 'both', 'NER', 'and', 'RE', 'subtasks.']",40,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
902c98f4-4372-4b65-bb0f-8494f0a40f9e,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,"['Diversified query generation guided by knowledge graph', 'Mixture models for diverse machine translation: Tricks of the trade', 'unknown', 'Mixture content selection for diverse sequence generation']","['2022', '2019', 'unknown', '2019']","['Xinyao Shen;Jiangjie Chen;Jiaze Chen;Chun Zeng;Yanghua Xiao', ""Tianxiao Shen;Myle Ott;Michael Auli;Marc'aurelio Ranzato"", 'unknown', 'Jaemin Cho;Minjoon Seo;Hannaneh Hajishirzi']",group,"['An', 'important', 'desideratum', 'of', 'natural', 'language', 'generation', '(NLG)', 'is', 'to', 'produce', 'outputs', 'that', 'are', 'not', 'only', 'correct', 'but', 'also', 'diverse', '<ref type=""single"">(Tevet and Berant, 2021).</ref>', 'The', 'term', '""diversity""', 'in', 'NLG', 'is', 'defined', 'as', 'the', 'ability', 'of', 'a', 'generative', 'model', 'to', 'create', 'a', 'set', 'of', 'possible', 'outputs', 'that', 'are', 'each', 'valid', 'given', 'the', 'input', 'and', 'vary', 'as', 'widely', 'as', 'possible', 'in', 'terms', 'of', 'content,', 'language', 'style,', 'and', 'word', 'variability', '<ref type=""single"">(Gupta et al., 2018).</ref>', 'This', 'research', 'problem', 'is', 'also', 'referred', 'as', 'one-to-many', 'generation', '<ref type=""group"">(Shen et al., 2019, Cho et al., 2019, Yu et al., 2021, Shen et al., 2022).</ref>']",74,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]"
90f4ac70-239c-48e4-ba75-d03c4b4d92fd,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['Exploratory undersampling for class-imbalance learning'],['2009'],['X Liu;J Wu;Z Zhou'],single,"['EasyEnsemble', '<ref type=""single"">(Liu et al., 2009)</ref>', 'is', 'used', 'to', 'represent', 'a', 'tradition', 'approach', 'in', 'dealing', 'with', 'im-balanced', 'dataset.', 'For', 'the', 'vectorization,', 'we', 'trained', 'a', 'Sent2Vec', '<ref type=""single"">(Pagliardini et al., 2018)</ref>', 'using', 'the', 'combined', '1GB', 'texts', 'of', 'Vietnamese', 'Wikipedia', 'data', '<ref type=""single"">(Vu et al., 2019)</ref>', 'and', '19', 'GB', 'texts', 'of', 'Vuong', '(2018).']",1,"[1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
90f84ca1-0448-4af7-870a-737329286161,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['Training verified learners with learned verifiers'],['2018'],"[""Krishnamurthy Dvijotham;Sven Gowal;Robert Stanforth;Relja Arandjelovic;O' Brendan;Jonathan Donoghue;Pushmeet Uesato;unk Kohli""]",single,"['Robust', 'models', '(first-order).', 'With', 'the', 'same', 'setup', 'as', 'base', 'models,', 'we', 'apply', 'robust', 'training', 'methods', 'to', 'improve', 'the', 'resistance', 'to', 'word', 'substitution', 'attacks.', '<ref type=""single"">Jia et al. (2019)</ref>', 'provide', 'a', 'provably', 'robust', 'training', 'method', 'through', 'Interval', 'Bound', 'Propagation', '(IBP,', '<ref type=""single"">Dvijotham et al. 2018)</ref>', 'for', 'all', 'word', 'substitutions', 'on', 'BoW,', 'CNN', 'and', 'LSTM.', '<ref type=""single"">Xu et al. (2020)</ref>', 'provide', 'a', 'provably', 'robust', 'training', 'method', 'on', 'general', 'computational', 'graphs', 'through', 'a', 'combination', 'of', 'forward', 'and', 'backward', 'linear', 'bound', 'propagation,', 'and', 'the', 'resulting', '3-layer', 'Transformer', 'is', 'robust', 'to', 'up', 'to', '6', 'word', 'substitutions.', 'For', 'both', 'works', 'we', 'use', 'the', 'same', 'set', 'of', 'counter-fitted', 'synonyms', 'provided', 'in', '<ref type=""single"">Jia et al. (2019).</ref>', 'We', 'skip', 'BERT-base', 'due', 'to', 'the', 'lack', 'of', 'an', 'effective', 'robust', 'training', 'method.']",35,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
918e89aa-081d-495c-87d5-f16e00d39556,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,"['A Unified Framework for Phrase-Based, Hierarchical, and Syntax-Based Statistical Machine Translation']",['2009'],['H Hoang;P Koehn;A Lopez'],single,"['We', 'built', 'our', 'HPB', 'baseline', 'using', 'the', 'Moses', 'Chart', 'Decoder', '<ref type=""single"">[24].</ref>', 'Continuous', 'phrases', 'are', 'extracted', 'according', 'to', 'the', 'phrase', 'based', 'system', 'settings', 'explained', 'in', 'Section', '3.1.', 'Maximum', 'phrase', 'length', 'and', 'maximum', 'rule', 'span', 'are', 'both', 'set', 'to', '12', 'words.', 'The', 'maximum', 'span', 'for', 'the', 'chart', 'during', 'decoding', 'is', 'set', 'to', '20', 'words,', 'above', 'which', 'only', 'monotone', 'concatenation', 'of', 'phrases', 'is', 'used.', 'Rules', 'extracted', 'contain', 'up', 'to', '2', 'non-terminals.', 'Adjacent', 'non-terminals', 'on', 'the', 'source', 'side', 'are', 'not', 'allowed.']",10,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
918f76f6-851f-47d1-8c82-bb33a68b5a38,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['Large vocabulary SOUL neural network language models'],['2011'],['H.-S Le;I Oparin;A Messaoudi;A Allauzen;J.-L Gauvain;F Yvon'],single,"['In', 'the', 'same', 'direction', 'but', 'with', 'the', 'other', 'output', 'information,', 'we', 'used', 'only', 'the', 'factors', 'embedding', 'as', 'feedback', '(see', 'equation', '6).', 'fb(y', 't−1)', '=', 'y', 'F', 't−1', '<ref type=""single"">(6)</ref>', 'where', 'y', 'F', 't−1', 'is', 'the', 'embedding', 'of', 'the', 'factors', 'generated', 'at', 'the', 'previous', 'timestep.']",27,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
91cde43a-b6eb-4a07-a90a-a4f58448a65b,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['Reading Wikipedia to answer opendomain questions'],['2017'],['Danqi Chen;Adam Fisch;Jason Weston;Antoine Bordes'],single,"['We', 'use', 'DRQA', '<ref type=""single"">(Chen et al., 2017)</ref>', 'to', 'extract', 'k', 'sentences', 'S', '=', '{s', 'i}', 'k', 'i=1', 'and', 'n', 'tables', 'T', '=', '{t', 'i}', 'n', 'i=1', 'from', 'the', 'retrieved', 'pages,', 'respectively.', 'Then', 'we', 'select', 'cells', 'from', 'the', 'extracted', 'tables.', 'Many', 'instances', 'in', 'the', 'FEVEROUS', 'dataset', 'require', 'evidence', 'cells', 'from', 'more', 'than', 'one', 'table,', 'and', 'each', 'retrieved', 'table', 'has', 'different', 'relevance', 'score', 'to', 'the', 'claim.', 'However,', 'the', 'widely-used', 'cell', 'extractor', '<ref type=""single"">(Aly et al., 2021)</ref>', 'reserves', 'cells', 'from', 'only', 'one', 'table', 'in', 'their', 'implementation.']",3,"[2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
91ff3108-525b-466c-8e0d-acfae9946731,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,"['Portuguese named entity recognition using BERT-CRF. CoRR, abs']",['1909'],['Fábio Souza;Rodrigo Nogueira;Roberto De;Alencar Lotufo'],single,"['In', 'SemEval', '2020-Task', '11', '<ref type=""single"">(Da San Martino et al., 2020),</ref>', 'the', 'first', 'sub-task', '-Span', 'Identification', '-aims', 'at', 'detecting', 'the', 'beginning', 'and', 'the', 'end', 'offset', 'for', 'the', 'propaganda', 'spans', 'in', 'news', 'articles.', 'This', 'sub-task', 'is', 'similar', 'to', 'SemEval', '2021-Task', '5.', 'The', 'proposed', 'approaches', 'for', 'the', 'sub-task', 'can', 'be', 'broadly', 'classified', 'into', 'Span', 'Prediction', 'or', 'Token', 'Classification.', 'Most', 'teams', 'use', 'multi-granular', 'transformer-based', 'systems', 'for', 'token', 'classification/sequence', 'tagging', '<ref type=""group"">(Khosla et al., 2020, Morio et al., 2020, Patil et al., 2020).</ref>', 'Inspired', 'by', '<ref type=""single"">Souza et al. (2019),</ref>', '<ref type=""single"">Jurkiewicz et al. (2020)</ref>', 'use', 'RoBERTa-CRF', 'based', 'systems.', '<ref type=""single"">Li and Xiao (2020)</ref>', 'use', 'a', 'variant', 'of', 'SpanBERT', 'span', 'prediction', 'system.']",63,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9286449f-6ac5-4899-adb7-643f6f7754de,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['Example-based machine translation using connectionist matching'],['1992'],['I Mclean'],single,"['The', 'system', 'will', 'use', 'a', 'wide', 'variety', 'of', 'techniques,', 'many', 'of', 'which', 'are', 'at', 'the', 'forefront', 'of', 'research.', 'For', 'the', 'task', 'of', 'matching', 'of', ""user's"", 'input', 'with', 'the', 'stored', 'examples,', 'parsing', 'of', 'a', 'traditional', 'nature', 'may', 'be', 'employed,', 'but', 'the', 'primary', 'technique', 'will', 'involve', 'stochastic', 'or', 'other', 'pattern', 'matching', 'techniques.', 'Because', 'the', 'aim', 'is', 'to', 'match', 'inputs', 'with', 'similar,', 'but', 'usually', 'not', 'identical', 'examples', 'in', 'the', 'database,', 'the', 'matching', 'techniques', 'must', 'be', 'flexible', 'enough', 'to', 'locate', 'a', 'range', 'of', 'candidate', 'matches', 'against', 'a', 'given', 'input.', 'For', 'this', 'reason,', 'pattern', 'matching', 'incorporating', 'a', 'similarity', 'measure', 'is', 'indicated,', 'such', 'as', 'the', 'techniques', 'proposed', 'in', '<ref type=""group"">[8, 22, 23, 40],</ref>', 'though', 'we', 'are', 'also', 'experimenting', 'with', 'a', 'connectionist', 'approach', 'to', 'this', 'problem', '<ref type=""single"">([28]</ref>', ').']",115,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1]"
9302e68b-36c3-4386-880d-de6016d3afbf,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['One term or two'],['1995'],['K Church'],single,"['In', 'Yamamoto', 'and', ""Church's"", 'work,', 'they', 'demonstrate', 'how', 'interesting', 'multiword', 'phrases', 'can', 'be', 'discovered,', 'by', 'interesting', 'they', 'mean', 'phrases', 'that', 'may', 'be', 'beneficial', 'for', 'information', 'retrieval', 'or', 'computational', 'lexicography', 'as', 'determined', 'by', 'Mutual', 'Information', '(MI)', 'or', 'Residual', 'Inverse', 'Document', 'Frequency', '(RIDF)', '<ref type=""single"">(Church, 1995)</ref>', 'scores.']",41,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]"
9345a9e3-df15-4903-8f07-eb1ceb169ff2,Corpora and Machine Translation,1993,Yorick Wilks,['A performance evaluation of text analysis technologies'],['1991'],['W Lehnert;B Sundheim'],single,"['The', 'basic', 'AI', 'argument', 'for', 'knowledge-based', 'processing', 'does', 'not', 'admit', 'defeat', 'and', 'retreat,', 'it', 'just', 'regroups.', 'It', 'has', 'to', 'accept', 'Bar', ""Hillel's"", 'old', 'anti-MT', 'argument', '(Bar', 'Hillel', '1960)', 'on', 'its', 'own', 'side-i.e.', 'that', 'as', 'he', 'said,', 'good', 'MT', 'must', 'in', 'the', 'end', 'need', 'knowledge', 'representations.', 'One', 'version', 'of', 'this', 'argument', 'is', 'the', 'primitive', 'psychological', 'one:', 'humans', 'do', 'not', 'do', 'translation', 'by', 'exposure', 'to', 'such', 'vast', 'texts,', 'because', 'they', 'simply', 'have', 'not', 'had', 'such', 'exposure,', 'and', 'in', 'the', 'end', 'how', 'people', 'do', 'things', 'will', 'prove', 'important.', 'Note', 'that', 'this', 'argument', 'makes', 'an', 'empirical', 'claim', 'about', 'human', 'exposure', 'to', 'text', 'that', 'might', 'be', 'hard', 'to', 'substantiate.', 'This', 'argument', 'will', 'cut', 'little', 'ice', 'with', 'our', 'opponents,', 'but', 'there', 'may', 'still', 'be', 'a', 'good', 'argument', 'that', 'we', 'do', 'need', 'representations', 'for', 'tasks', 'in', 'NLP', 'related', 'to', 'MT:', 'e.g.', 'we', 'cannot', 'really', 'imagine', 'doing', 'summarization', 'or', 'question', 'answering', 'by', 'purely', 'statistical', 'methods,', 'can', 'we?', 'There', 'is', 'related', 'practical', 'evidence', 'from', 'message', 'extraction:', 'in', 'the', 'MUC', 'competitions', '<ref type=""single"">(Lehnert &amp, Sundheim 1991),</ref>', 'the', 'systems', 'that', 'have', 'done', 'best', 'have', 'been', 'hybrids', 'of', 'preference', 'and', 'statistics,', 'such', 'as', 'of', 'Grishman', 'and', 'Lehnert,', 'and', 'not', 'pure', 'systems', 'of', 'either', 'type.']",161,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
938527d2-d18d-48a8-9c41-6360021f1251,Comparison of post-editing productivity between professional translators and lay users,2014,Nora Aranberri;Gorka Labaka,['A productivity test of statistical machine translation post-editing in a typical localisation context'],['2010'],['M Plitt;F Masselot'],single,"['The', 'attitude', 'towards', 'post-editing', 'or,', 'more', 'generally,', 'MT', 'might', 'also', 'set', 'the', 'tone', 'for', 'the', 'job', 'and', 'highlight', 'the', 'importance', 'of', 'more', 'objective', 'measurements', 'rather', 'than', 'basing', 'the', 'integration', 'of', 'MT', 'on', 'translator', 'perception', 'only.', 'The', 'mismatch', 'between', 'the', ""translators'"", 'perception', 'of', 'productivity', 'and', 'their', 'actual', 'productivity', 'has', 'been', 'previously', 'reported', 'by', 'Autodesk,', 'specifically', 'on', 'the', ""company's"", 'follow', 'up', 'work', 'on', '<ref type=""single"">Plitt and Masselot (2010).</ref>', '8', 'To', 'check', 'for', 'this', 'effect,', 'we', 'asked', 'participants', 'to', 'fill', 'in', 'a', 'short', 'questionnaire', 'after', 'completing', 'the', 'tasks.', 'One', 'of', 'the', 'questions', 'asked', 'was', 'whether', 'they', 'thought', 'having', 'the', 'MT', 'output', 'helped', 'them', 'complete', 'the', 'translation.', 'They', 'were', 'asked', 'to', 'mark', 'this', 'on', 'a', 'scale', 'from', '-5', 'to', '5', 'where', '-5', 'meant', 'that', 'the', 'MT', 'output', 'had', 'greatly', 'hindered', 'their', 'work', 'and', '5', 'meant', 'that', 'the', 'MT', 'output', 'had', 'greatly', 'helped', 'their', 'work', '(see', 'Table', '5).', 'Overall,', 'users', 'were', 'more', 'positive', 'about', 'having', 'the', 'MT', 'output', 'displayed', 'when', 'translating,', 'with', 'only', 'one', 'out', 'of', 'six', 'claiming', 'that', 'it', 'hindered', 'the', 'process.', 'In', 'the', 'case', 'of', 'translators,', 'however,', 'three', 'out', 'of', 'six', 'heavily', 'penalized', 'its', 'use,', 'one', 'reported', 'that', 'it', 'was', 'better', 'than', 'not', 'having', 'it,', 'and', 'two', 'reported', 'some', 'benefit.', 'T1', 'commented', 'that', 'translation', 'and', 'post-editing', 'required', 'different', 'skills', 'and', 'that', 'should', 'the', 'same', 'time', 'be', 'spent', 'in', 'post-editing', 'and', 'translating,', 'the', 'translation', 'would', 'most', 'probably', 'be', 'of', 'better', 'quality.', 'T6', 'was', 'the', 'most', 'positive', 'of', 'all', 'with', 'regards', 'to', 'MT', 'and', 'admitted', 'that', 'the', 'output', 'helped', 'in', 'acquiring', 'the', 'terminology', 'but', 'was', 'hopeless', 'with', 'syntax,', 'which', 'needed', 'a', 'complete', 'rework.', 'T2,', 'T3', 'and', 'T4', 'indicated', 'that', 'the', 'MT', 'output', 'had', 'clearly', 'interfered', 'in', 'their', 'job.', 'T2', 'reported', 'that', 'MT', 'output', 'slowed', 'down', 'the', 'process', 'considerably', 'because', 'reading,', 'understanding', 'and', 'considering', 'what', 'to', 'reuse', 'from', 'it', 'was', 'very', 'time-consuming.', 'T3', 'commented', 'that', 'translating', 'from', 'scratch', 'was', 'easier', 'and', 'faster,', 'and', 'that', 'even', 'checking', 'the', 'MT', 'output', 'for', 'terminology', 'would', 'most', 'often', 'not', 'help.', 'T4', 'claimed', 'that', 'the', 'MT', 'system', 'did', 'not', 'translate', 'the', 'order', 'of', 'the', 'phrases', 'properly,', 'which', 'rendered', 'the', 'translation', 'incomprehensible.', 'Interestingly,', 'T3', 'and', 'T4', 'did', 'benefit', 'from', 'postediting.']",61,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
93aa21a9-2790-4c6c-9887-35f0d9706472,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,"['Social media behavior, toxic masculinity, and depression']",['2019'],['Mike Parent;Teresa Gobble;Aaron Rochlen'],single,"['Coordinated', 'behavior', 'or', 'brigading,', 'i.e.,', 'when', 'users', 'with', 'similar', 'beliefs', 'act', 'in', 'a', 'coordinated', 'manner', 'in', 'a', 'social', 'space', 'towards', 'some', 'common', 'objective', '<ref type=""single"">(Parent et al., 2019).</ref>']",23,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
93b75140-0b57-458d-aa01-a5c76f98d4f5,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,"['Feature extraction for large-scale text collections', 'unknown']","['2020', '2013']","['Luke Gallagher;Antonio Mallia;J Culpepper;Torsten Suel;B Barla Cambazoglu', 'Tao Qin;Tie-Yan Liu']",group,"['Our', 'LTR', 'features', 'fall', 'into', 'four', 'categories:', 'term-based,', 'score-based,', 'proximity-based,', 'and', 'translation-based.', 'These', 'features', 'are', 'inspired', 'by', 'previous', 'studies', 'on', 'LTR', '<ref type=""group"">(Qin and Liu, 2013, Gallagher et al., 2020)</ref>', 'and', 'summarized', 'in', 'Table', '1.', 'An', 'enumeration', 'of', 'all', 'features', 'is', 'presented', 'in', 'Appendix', 'A.']",21,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
94a38cf8-b798-4401-aed0-b8ca9b481d28,A User-Based Usability Assessment of Raw Machine Translated Technical Instructions,2012,Stephen Doherty;Sharon O'brien,['Measuring human readability of machine generated text: three case studies in speech recognition and machine translation'],['2005'],['D Jones;E Gibson;W Shen;N Granoien;M Herzog;D Reynolds;C Weinstein'],single,"['There', 'are', 'relatively', 'few', 'studies', 'of', 'the', 'usability', 'of', 'raw', 'machine', 'translated', 'documentation', 'by', 'real', 'end-users.', 'For', 'example,', ""Tomita's"", 'work', '<ref type=""group"">(Tomita, 1992, Tomita et al., 1993)</ref>', 'focused', 'on', 'the', 'concept', 'of', 'content', 'comprehension.', '<ref type=""single"">Fuji (1999)</ref>', 'evaluated', 'the', 'informativeness,', 'comprehension,', 'and', 'fluency', 'of', 'MT', 'output,', 'where', 'participants', 'had', 'no', 'reference', 'to', 'the', 'source', 'text,', 'while', '<ref type=""single"">Fuji et al. (2001)</ref>', 'measured', 'the', 'concept', 'of', 'usefulness.', '<ref type=""single"">Jones et al. (2005)</ref>', 'measure', 'the', 'readability', 'of', 'MT', 'output.', 'While', 'comprehensibility', 'and', 'readability', 'are', 'frequently', 'considered', 'to', 'be', 'components', 'of', 'usability,', 'these', 'studies', 'address', 'only', 'specific', 'aspects', 'of', 'the', 'concept', 'of', 'usability.', '<ref type=""single"">Gaspari\'s study (2004)</ref>', 'in', 'which', 'real', 'end', ""users'"", 'needs', 'are', 'evaluated', 'in', 'the', 'context', 'of', 'web', 'usability', 'comes', 'closest', 'to', 'the', 'study', 'presented', 'here.', 'However,', ""Gaspari's"", 'focus', 'is', 'on', 'the', 'usability', 'of', 'online', 'MT', 'systems,', 'as', 'opposed', 'to', 'the', 'text', 'they', 'generate.']",54,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
94ba9ec2-0eef-4dae-aec2-5dd91826516c,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['Using suffix arrays to compute term frequency and document frequency for all substrings in a corpus'],['2001'],['M Yamamoto;K Church'],single,"['Irrespective', 'of', 'how', 'the', 'suffix', 'array', 'is', 'created,', '<ref type=""single"">Yamamoto and Church (2001)</ref>', 'demonstrated', 'how', 'given', 'a', 'suffix', 'array,', 'frequencies', 'of', 'occurrence', 'for', 'all', 'substrings', 'can', 'be', 'ascertained', 'in', 'linear', 'time.', 'More', 'precisely,', 'by', 'doing', 'O(N)', 'preprocessing,', 'frequency', 'information', 'about', 'any', 'substring', 'can', 'be', 'obtained', 'in', 'O(log', 'N)', 'time.', 'Enumerating', 'over', 'all', 'substrings', 'naturally', 'requires', 'quadratic', 'time.', 'However,', 'their', 'technique', 'works', 'by', 'partitioning', 'substrings', 'into', 'at', 'most', '2N', 'classes', 'which', 'have', 'unique', 'collection', 'frequency,', 'the', 'number', 'of', 'times', 'the', 'string', 'occurs', 'in', 'the', 'text,', 'and', 'document', 'frequency,', 'the', 'number', 'of', 'separate', 'documents', 'the', 'string', 'occurs', 'in.', '(The', 'text', 'may', 'contain', 'special', 'end-of-document', 'markers.)']",8,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3]"
94dc3777-3438-4244-9ff0-dc0f320e53d2,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Connecting vision and language with localized narratives'],['2020'],['Jordi Pont-Tuset;Jasper Uijlings;Beer Changpinyo;Radu Soricut;Vittorio Ferrari'],single,"['In', 'the', 'Localized', 'Narratives', 'dataset', '<ref type=""single"">(Pont-Tuset et al., 2020),</ref>', 'the', 'annotators', 'describe', 'the', 'image', 'while', 'drawing', 'the', 'traces', 'of', 'their', 'attention', 'movement,', 'which', 'presents', 'a', 'spatial', 'alignment', 'between', 'visual', 'objects', 'and', 'caption', 'tokens', 'as', 'well', 'as', 'a', 'temporal', 'alignment', 'between', 'user', 'intention(by', 'trace)', 'and', 'caption', 'sentences.', 'From', 'Figure', '1,', 'we', 'see', 'that', 'the', 'caption', 'tokens,', 'e.g.', '""person"",', '""horse"",', '""trees""', 'can', 'be', 'grounded', 'to', 'the', 'visual', 'objects', 'spatially,', 'and', 'the', 'order', 'of', 'caption', 'sentences', 'can', 'be', 'arranged', 'to', 'align', 'to', 'the', 'order', 'of', 'traces', 'temporally.', 'Although', 'it', 'is', 'easy', 'for', 'humans', 'to', 'recognize', 'which', 'visual', 'object', 'is', 'indicated', 'by', 'the', 'traces,', 'it', 'is', 'a', 'challenge', 'for', 'the', 'agent', 'to', 'recognize,', 'emphasize', 'and', 'arrange', 'visual', 'semantics', 'solely', 'based', 'on', 'several', ""tracepoints'"", 'coordinates.', 'Thereby,', 'we', 'mainly', 'devote', 'our', 'effort', 'to', 'the', 'spatial', 'grounding', 'and', 'temporal', 'controllability', 'of', 'image', 'captioning.']",5,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
95277296-d145-4d04-ba84-8d81355eeb10,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Incorporating non-local information into information extraction systems by gibbs sampling'],['2005'],['Jenny Finkel;Trond Grenager;Christopher Manning'],single,"['For', 'the', 'English', 'data', 'we', 'used', 'Stanford', 'NER', '(named', 'entity', 'recognition)', '<ref type=""single"">(Finkel et al., 2005)</ref>', 'to', 'replace', 'names', 'and', 'locations', 'with', 'the', 'tags:', '[PERSON]', 'and', '[LOCATION]', 'respectively.', 'We', 'kept', 'organization', 'names', 'as', 'is', 'because', 'we', 'felt', 'that', 'the', 'emotions', 'and', 'sentiments', 'towards', 'some', 'large', 'well-known', 'organizations', 'differ', 'too', 'much', '(cf.', 'IRS,', 'FBI,', 'WHO,', 'EU,', 'and', 'MIT).', 'For', 'the', 'Finnish', 'data,', 'we', 'replaced', 'names', 'and', 'locations', 'using', 'the', 'Turku', 'NER', 'corpus', '<ref type=""single"">(Luoma et al., 2020).</ref>']",11,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
954f6fdb-7ef5-44c8-bd48-75c96e007330,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,"['Document expansion by query prediction', 'From doc2query to docTTTTTquery']","['2019', '2019']","['Rodrigo Nogueira;Wei Yang;Jimmy Lin;Kyunghyun Cho', 'Rodrigo Nogueira;Jimmy Lin']",group,"['In', 'addition,', 'we', 'also', 'examine', 'the', 'docTTTTTquery', 'document', 'expansion', 'technique', '<ref type=""group"">(Nogueira et al., 2019b, Nogueira and Lin, 2019)</ref>', 'based', 'on', 'predicting', 'queries', 'for', 'which', 'a', 'text', 'would', 'be', 'relevant', '(henceforth,', 'just', 'd2q', 'for', 'short).', 'The', 'predicted', 'queries', 'are', 'concatenated', 'to', 'the', 'end', 'of', 'the', 'original', 'text,', 'this', 'greatly', 'improves', 'BoW', 'retrieval.', 'We', 'call', 'this', 'variant', 'BoW', 'd2q', 'and', 'denote', 'the', 'corresponding', 'pipeline', 'BoW', 'd2q', '(1000)', '+', 'BERT.']",10,"[0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
959b202c-1f4b-46be-b82a-51ca8575bf97,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Matching the Blanks: Distributional Similarity for Relation Learning'],['2019'],['unk Livio Baldini;Nicholas Soares;Jeffrey Fitzgerald;Tom Ling;unk Kwiatkowski'],single,"['ture.', 'Dense', 'representations', 'of', 'entities', 'have', 'similarly', 'been', 'applied', 'to', 'entity', 'linking', '<ref type=""group"">(Yamada et al., 2016, Eshel et al., 2017),</ref>', 'as', 'well', 'as', 'relation', 'extraction', '<ref type=""single"">(Baldini Soares et al., 2019),</ref>', 'entity', 'typing', '<ref type=""single"">(Ling et al., 2020),</ref>', 'and', 'question', 'answering', '<ref type=""single"">(Févry et al., 2020).</ref>', 'Those', 'approaches', 'use', 'millions', 'of', 'predefined', 'entities,', 'while', 'our', 'approach', 'uses', 'a', 'much', 'smaller', 'number', 'of', 'types', '(10k', 'or', '60k).', 'This', 'makes', 'it', 'simultaneously', 'more', 'compact', 'and', 'also', 'more', 'flexible', 'when', 'generalizing', 'to', 'unknown', 'entities.']",18,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
968411c1-302d-490c-b922-392bbe018be3,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,"['Pixel-bert: Aligning image pixels with text by deep multi-modal transformers', 'unknown']","['2020', 'unknown']","['Zhicheng Huang;Zhaoyang Zeng;Bei Liu;Dongmei Fu;Jianlong Fu', 'unknown']",group,"['End-to-End', '(E2E)', 'Pretraining', 'directly', 'feed', 'dense', 'features', 'on', 'image', 'grids', 'from', 'a', 'visual', 'backbone', 'network', 'into', 'a', 'Transformer', 'network', 'along', 'with', 'text', 'tokens.', 'As', 'such,', 'both', 'the', 'visual', 'and', 'Transformer', 'networks', 'are', 'optimized', 'jointly', 'in', 'an', 'end-to-end', 'manner', 'in', 'the', 'pretraining', '&amp,', 'finetuning', 'stage.', 'Pixel-Bert', 'and', 'SOHO', '<ref type=""group"">(Huang et al., 2021 (Huang et al., , 2020) )</ref>', 'pioneer', 'the', 'use', 'of', 'the', 'E2E', 'pretraining', 'architecture', 'and', 'propose', 'a', 'novel', 'visual-dictionary', 'masked', 'vision', 'modeling', 'task.', 'E2E-VLP', '<ref type=""single"">(Xu et al., 2021)</ref>', 'presents', 'a', 'pretraining', 'framework', 'supervised', 'with', 'additional', 'object', 'detection', 'and', 'image', 'captioning', 'tasks', 'to', 'enhance', 'visual', 'semantics', 'learning.', 'It', 'is', 'worth', 'noting', 'that', 'their', 'object', 'detection', 'pretext', 'task', 'requires', 'millions', 'of', 'bounding', 'boxes', 'annotation,', 'unable', 'to', 'generalize', 'to', 'large-scale', 'image-text', 'corpus.', 'ViLT', '<ref type=""single"">(Kim et al., 2021)</ref>', 'is', 'the', 'first', 'to', 'unify', 'vision', 'and', 'language', 'with', 'a', 'pure', 'Transformer', 'network,', 'which', 'has', 'a', 'simpler', 'structure', 'and', 'enjoys', 'faster', 'inference.', 'However,', 'compared', 'to', 'the', 'twostep', 'methods,', 'they', 'are', 'typically', 'less', 'expressive', 'in', 'terms', 'of', 'object-level', 'concepts', 'and', 'thus', 'suffer', 'from', 'weaker', 'performances', 'on', 'challenging', 'visual', 'reasoning', 'tasks.', 'Our', 'method', 'is', 'in', 'line', 'with', 'the', 'E2E', 'pretraining', 'framework.', 'The', 'key', 'difference', 'is', 'that', 'we', 'propose', 'to', 'facilitate', 'learning', 'object-aware', 'multi-modal', 'representations', 'by', 'performing', 'object', 'semantic', 'knowledge', 'distillation.']",47,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
96b897c7-35a8-4dd4-8817-eeee43d42f43,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,"['The impact of listener gaze on predicting reference resolution', 'Using listener gaze to refer in installments benefits understanding', 'Learning cognitive features from gaze data for sentiment and sarcasm classification using convolutional neural network', 'At a glance: The impact of gaze aggregation views on syntactic tagging']","['2015', '2018', '2017', '2019']","['Nikolina Koleva;Martín Villalba;Maria Staudte;Alexander Koller', 'Nikolina Mitev;Patrick Renner;Thies Pfeiffer;Maria Staudte', 'Abhijit Mishra;Kuntal Dey;Pushpak Bhattacharyya', 'Sigrid Klerke;Barbara Plank']",group,"['Integrating', 'eye-movements', 'of', 'the', 'speaker.', 'Many', 'eye-tracking', 'technologies', 'in', 'the', 'market', 'employ', 'a', 'sufficient', 'sampling', 'frequency', 'to', 'enable', 'gazecontingent', 'applications.', 'With', 'advancements', 'in', 'the', 'eye-tracking', 'technology,', 'incorporating', 'eye', 'movements', 'of', 'a', 'speaker', 'or', 'a', 'listener', 'enables', 'us', 'to', 'predict', '/', 'resolve', 'which', 'entity', 'is', 'being', 'referred', 'to', 'in', 'a', 'complex', 'visual', 'environment', '<ref type=""group"">(Klerke and Plank, 2019, Mitev et al., 2018, Mishra et al., 2017, Koleva et al., 2015).</ref>', 'However,', 'these', 'studies', 'are', 'limited', 'to', 'relatively', 'simple', 'scenes.', 'Situated', 'language', 'understanding', 'in', 'a', 'referentially', 'complex', 'environment', 'or', 'under', 'noisy', 'situations', 'imposes', 'a', 'different', 'level', 'of', 'challenge', 'that', 'we', 'aim', 'to', 'address.', 'The', 'number', 'of', 'studies', 'that', 'utilize', 'gaze', 'features', '<ref type=""group"">(Sood et al., 2020, Park et al., 2019, Karessli et al., 2017)</ref>', 'is', 'very', 'limited.', 'In', 'this', 'study,', 'we', 'propose', 'to', 'incorporate', 'the', 'eye-movements', 'of', 'the', 'speaker', 'to', 'improve', 'the', 'crossmodal', 'mapping', 'performance.', 'This', 'additional', 'deictic', 'modality', 'may', 'improve', 'the', 'recovery', 'of', 'the', 'intended', 'meaning', 'especially', 'when', 'the', 'communication', 'is', 'noisy', '(acoustically', 'or', 'visually).', 'The', 'gaze', 'embeddings', 'will', 'be', 'created', 'by', 'using', 'existing', 'eyemovement', 'datasets.', 'However,', 'there', 'are', 'only', 'few', 'big-size', 'eye-movement', 'datasets', 'available', '<ref type=""group"">(Alac ¸am et al., 2020b, Wilming et al., 2017, Ehinger et al., 2009).</ref>', 'Thus,', 'to', 'enlarge', 'available', 'data,', 'we', 'will', 'conduct', 'a', 'set', 'of', 'experimental', 'studies', 'with', 'increasing', 'referential', 'complexity.', 'There,', 'we', 'will', 'record', ""participants'"", 'instructions', 'on', 'a', 'task-oriented', 'scenario', 'and', 'their', 'eye-movements', 'regarding', 'target', 'objects.']",52,"[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
96ea6ea6-667e-4984-ab4b-d54f84ebf12d,Entity Attribute Relation Extraction with Attribute-Aware Embeddings,2020,Dan Iter;Xiao Yu;Fangtao Li,['Improving hypernymy detection with an integrated path-based and distributional method'],['2016'],['Vered Shwartz;Yoav Goldberg;Ido Dagan'],single,"['As', 'proposed', 'by', '<ref type=""single"">Shwartz et al. (2016),</ref>', 'adding', 'the', 'word', 'embedding', 'or', 'distributive', 'representation', 'for', 'the', 'candidate', 'strings', 'can', 'improve', 'the', 'performance', 'of', 'the', 'model.', 'The', 'embeddings', 'of', 'the', 'two', 'candidate', 'terms', 'in', 'the', 'entity-attribute', 'pair', 'are', 'concatenated', 'to', 'each', 'side', 'of', 'the', 'aggregated', 'sentences', 'vector', 'described', 'in', 'the', 'previous', 'section.', 'The', 'embeddings', 'for', 'e', 'and', 'a', 'are', 'simply', '−', '→', 'v', 'e', 'and', '−', '→', 'v', 'a.', 'Thus', 'the', 'full', 'representation', 'of', 'a', 'entity-attribute', 'pair', 'is:−', '→', 'v', '(e,a)', '=', '[−', '→', 'v', 'e,', '−', '→', 'v', 'sents(e,a),', '−', '→', 'v', 'a]']",3,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
97157cc9-3253-4c40-950e-990ec7452baf,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Probing neural network comprehension of natural language arguments'],['2019'],['Timothy Niven;Hung-Yu Kao'],single,"['There', 'have', 'been', 'great', 'advances', 'in', 'argument', 'mining-classifying', 'the', 'argumentative', 'relation', 'between', 'statements', 'as', 'support,', 'attack,', 'or', 'neutral.', 'Recent', 'research', 'has', 'focused', 'on', 'training', 'complex', 'neural', 'networks', 'on', 'large', 'labeled', 'data.', 'However,', 'the', 'behavior', 'of', 'such', 'models', 'remains', 'obscure,', 'and', 'recent', 'studies', 'found', 'evidence', 'that', 'those', 'models', 'may', 'rely', 'on', 'spurious', 'statistics', 'of', 'training', 'data', '<ref type=""single"">(Niven and Kao, 2019)</ref>', 'and', 'superficial', 'cues', 'irrelevant', 'to', 'the', 'meaning', 'of', 'statements,', 'such', 'as', 'discourse', 'markers', '<ref type=""single"">(Opitz and Frank, 2019).</ref>', 'Hence,', 'in', 'this', 'work,', 'we', 'turn', 'to', 'an', 'interpretable', 'method', 'to', 'investigate', 'logical', 'relations', 'between', 'statements,', 'such', 'as', 'causal', 'relations', 'and', 'factual', 'contradiction.', 'Such', 'relations', 'have', 'been', 'underemphasized', 'in', 'earlier', 'studies', '<ref type=""group"">(Feng and Hirst, 2011, Lawrence and Reed, 2016),</ref>', 'possibly', 'because', 'their', 'operationalization', 'was', 'unreliable', 'then.', 'Now', 'that', 'computational', 'semantics', 'is', 'fast', 'developing,', 'our', 'work', 'takes', 'a', 'first', 'step', 'to', 'computationally', 'investigate', 'how', 'logical', 'mechanisms', 'contribute', 'to', 'building', 'argumentative', 'relations', 'between', 'statements', 'and', 'to', 'classification', 'accuracy', 'with', 'and', 'without', 'training', 'on', 'labeled', 'data.']",55,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
974445d7-0965-4b5c-9876-f1650eec4b9c,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Europarl: A parallel corpus for statistical machine translation'],['2005'],['Philipp Koehn'],single,"['English-Spanish', 'datasets', 'We', 'consider', 'the', 'Eu-roParl', '(1.7M', 'sentences)', '<ref type=""single"">(Koehn, 2005)</ref>', 'and', 'the', 'NewsCommentary-v8', '(174k', 'sentences)', 'corpora', 'for', 'pre-training.']",8,"[2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2]"
97944eb4-9327-4ddb-bccf-91f679a1f487,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['The time-course of processing of grammatical class and semantic attributes of words: Dissociation by means of erp. Syntax-related ERP-effects in Dutch'],['2003'],['P Hagoort;M Wassenaar;C Brown'],single,"['The', 'confound-controlled', 'analysis', 'dissociated', 'word', 'length,', 'frequency', 'and', 'class', 'effects', 'in', 'EEG.', 'This', 'replication', 'of', 'earlier', 'ERP', '<ref type=""group"">(Osterhout et al., 1997, Münte et al., 1998)</ref>', 'and', 'MEG', 'decoding', 'work', '<ref type=""single"">(King et al., 2020)</ref>', 'validates', 'a', 'new', 'EEG', 'data', 'set', 'for', 'an', 'extensive', 'morphosyntactically', 'gold', 'annotated', 'corpus,', 'c.f.', '<ref type=""single"">Bhattasali et al. (2020).</ref>', 'Transformers', 'successfully', 'decoded', '6', 'PoS', 'tags', 'from', 'single', 'trial', 'EEG', 'with', 'data', 'augmentation', 'and', '3-1', 'pretraining', '(≈', '40%', 'accuracy),', 'raising', 'the', 'possibility', 'to', 'boost', 'PoS', 'induction', 'with', 'EEG-decoded', 'PoS', 'tags.', 'While', 'we', 'acknowledge', 'that', 'our', 'results', 'are', 'limited', 'to', 'EEG', 'data', 'from', 'a', 'single', 'subject,', 'given', 'the', 'spatial', 'smoothness', 'of', 'EEG', 'scalp', 'topographies,', 'we', 'envision', 'pretraining', 'on', 'EEG', 'obtained', 'from', 'different', 'participants.', 'Further,', 'because', 'human', 'brains', 'generate', 'similar', 'neural', 'signatures', 'for', 'word', 'classes', 'across', 'different', 'languages', '(c.f.', 'Yudes', '(2016),', '<ref type=""single"">Münte et al. (2001),</ref>', '<ref type=""single"">Hagoort et al. (2003)</ref>', '),', 'pretraining', 'PoS-EEG', 'decoders', 'on', 'large', 'morphosyntactically', 'annotated', 'EEG', 'datasets', 'for', 'English', 'followed', 'by', 'fine-tuning', 'on', 'a', 'smaller', 'annotated', 'EEG', 'data', 'set', 'for', 'a', 'low-resource', 'language', 'may', 'enable', 'successful', 'generalisation', 'to', 'EEG', 'obtained', 'from', 'reading', 'non-annotated', 'texts', 'in', 'this', 'low-resource', 'language.', 'PoS-induction', 'jointly', 'based', 'on', 'annotated', 'texts', 'and', 'EEG', 'signals', 'could', 'thus', 'be', 'transformative', 'for', 'corpus', 'generation', 'of', 'low-resource', 'languages.']",118,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9838624d-0274-433e-94fa-d03811d74cdb,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['COMET: A neural framework for MT evaluation'],['2020'],['Ricardo Rei;Craig Stewart;Ana Farinha;Alon Lavie'],single,"['With', 'the', 'advent', 'of', 'deep', 'learning,', 'new', 'automatic', 'metrics', 'have', 'arisen,', 'both', 'in', 'response', 'to', 'and', 'making', 'use', 'of', 'the', 'technical', 'advances', 'brought', 'by', 'deep', 'learning.', 'In', 'particular,', 'metrics', 'like', 'COMET', '<ref type=""single"">(Rei et al., 2020)</ref>', 'and', 'BERTScore', 'use', 'large', 'pre-trained', 'language', 'models', '(LLMs)', 'to', 'generate', 'scores', 'for', 'candidate', 'sentences.', 'The', 'use', 'of', 'these', 'LLMs', 'allows', 'for', 'metrics', 'that', 'take', 'advantage', 'of', 'the', 'linguistic', 'capabilities', 'of', 'these', 'LLMs,', 'and', 'no', 'longer', 'rely', 'solely', 'on', 'surface-level', 'features', 'such', 'as', 'n-grams.']",31,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
9851e2b5-c4ec-4f8d-9f12-2de68853ef31,ROI Analysis model for Language Service Providers,2013,Ekaterina Stambolieva,"['MT & ROI -Scoping, Defining, Measuring and Selecting Suitalbe Projects']",['2012'],['Dion Wiggins;Kirti Vashee'],single,"['There', 'is', 'a', 'current', 'need', 'for', 'accurate', 'ROI', 'analysis', 'schemes', 'for', 'LSPs.', 'As', '<ref type=""single"">Wiggins and Vashee (2012)</ref>', 'discuss,', 'LSPs', 'that', 'have', 'not', 'incorporated', 'MT', 'in', 'their', 'internal', 'workflow', 'by', '2015', 'will', 'be', 'facing', 'the', 'risk', 'of', 'bankruptcy.', 'Moreover,', 'both', 'researchers', 'and', 'professionals', 'agree', 'it', 'is', 'out', 'of', 'the', 'question', 'whether', 'LSPs', 'should', 'implement', 'the', 'usage', 'of', 'MT', 'in', 'their', 'respective', 'businesses', 'or', 'not.', 'The', 'question', 'has', 'shifted', 'to', 'how', 'LSPs', 'can', 'profit', 'from', 'the', 'usage', 'of', 'MT', 'internally', 'and', 'harvest', 'the', 'proven', 'benefits.']",13,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
98c8c7d6-c859-41a6-975b-8a1be12a55b2,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,"[""Exploring top management language for signals of possible deception: The words of Satyam's chair Ramalinga Raju""]",['2013'],['Russel Craig;Tony Mortensen;Shefali Iyer'],single,"['Linguistic', 'analysis', 'of', 'social', 'discourse,', 'using', 'digital', 'lexical', 'resources', 'and', 'related', 'software,', 'has', 'been', 'an', 'upward', 'trend', 'in', 'the', 'recent', 'past.', 'WordNet', 'has', 'been', 'used', 'for', 'marking', 'the', 'event', 'profile', 'of', 'news', 'articles', 'as', 'a', 'function', 'of', 'verb', 'type', '<ref type=""single"">(Klavans, 1998</ref>', ').', 'An', 'Adversary-Intent-Target', '(AIT)', 'model', 'has', 'been', 'developed', 'which', 'is', 'based', 'on', 'an', 'Ontology', 'for', 'the', 'Analysis', 'of', 'Terrorist', 'Attacks', '<ref type=""single"">(Turner et al, 2011).</ref>', 'DICTION', '5.0', 'text', 'analysis', 'master', 'variable,', 'CERTAINTY', 'has', 'been', 'used', 'to', 'analyze', 'top', 'management', 'language', 'for', 'signals', 'of', 'possible', 'deception', '<ref type=""single"">(Craig et al, 2013).</ref>']",81,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
98ff4304-f526-4a4c-9fb3-c7704bd6ed69,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Semeval-2020 task 4: Commonsense validation and explanation'],['2020'],['Cunxiang Wang;Shuailong Liang;Yili Jin;Yilong Wang;Xiaodan Zhu;Yue Zhang'],single,"['Figure', '1', 'shows', 'an', 'example', 'in', 'the', 'commonsense', 'explanation', 'generation', '(ComVE)', 'task.', 'The', 'dataset', 'has', 'collected', 'explanations', 'to', 'counterfactual', 'statements', 'for', 'sense-making', 'from', 'three', 'annotators', '<ref type=""single"">(Wang et al., 2020).</ref>', 'From', 'the', 'annotations,', 'we', 'observed', 'that', 'different', 'annotators', 'gave', 'explanations', 'to', 'the', 'unreasonable', 'statement', 'from', 'different', 'perspectives', 'to', 'make', 'them', 'diverse', 'in', 'terms', 'of', 'content,', 'e.g.,', 'wrong', 'effect', 'and', 'inappropriate', 'usage.']",25,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3]"
9971c51a-5035-473c-a170-7a3cc88ab087,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['Transformers: State-of-the-art natural language processing'],['2020'],['Thomas Wolf;Lysandre Debut;Victor Sanh;Julien Chaumond;Clement Delangue;Anthony Moi;Pierric Cistac;Tim Rault;Rmi Louf;Morgan Funtowicz;Joe Davison;Sam Shleifer;Clara Patrick Von Platen;Yacine Ma;Julien Jernite;Canwen Plu;Teven Xu;Sylvain Scao;Mariama Gugger;Quentin Drame;Alexander Lhoest;unk Rush'],single,"['We', 'use', 'two', 'recent', 'models', 'from', 'the', 'Quoref', 'leaderboard:', 'RoBERTa', '<ref type=""single"">(Liu et al., 2019)</ref>', 'and', 'TASE', '(Segal', 'et', 'al.,', '2020),', 'from', 'which', 'TASE', 'has', 'the', 'state-ofthe-art', 'results.', 'We', 'use', 'RoBERTa-large', 'from', 'Hug-gingFace', '<ref type=""single"">(Wolf et al., 2020).</ref>', 'TASE', 'casts', 'MRC', 'as', 'a', 'sequence', 'tagging', 'problem', 'to', 'handle', 'questions', 'with', 'multi-span', 'answers.', 'It', 'assigns', 'a', 'tag', 'to', 'every', 'token', 'of', 'the', 'context', 'indicating', 'whether', 'the', 'token', 'is', 'a', 'part', 'of', 'the', 'answer.', 'We', 'use', 'the', 'TASE', 'IO', '+SSE', 'setup', 'that', 'is', 'a', 'combination', 'of', 'their', 'multi-span', 'architecture', 'and', 'single-span', 'extraction', 'with', 'IO', 'tagging.We', 'use', 'the', 'same', 'configuration', 'and', 'hyper-parameters', 'for', 'TASE', 'IO', '+SSE', 'as', 'described', 'in', '<ref type=""single"">Segal et al. (2020).</ref>', 'We', 'train', 'all', 'models', 'for', 'two', 'epochs', 'in', 'all', 'experiments.', '11', 'We', 'use', 'the', 'F1', 'score', 'that', 'calculates', 'the', 'number', 'of', 'shared', 'words', 'between', 'predictions', 'and', 'gold', 'answers', 'for', 'evaluation.']",29,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
99c12b83-aa6c-4070-9d3d-c29952e86ef7,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Datasets: A community library for natural language processing'],['2021'],['Quentin Lhoest;Albert Villanova Del Moral;Yacine Jernite;Abhishek Thakur;Suraj Patrick Von Platen;Julien Patil;Mariama Chaumond;Julien Drame;Lewis Plu;Joe Tunstall;Mario Davison;Gunjan Šaško;Bhavitvya Chhablani;Simon Malik;Teven Brandeis;Victor Scao;Canwen Sanh;Nicolas Xu;Angelina Patry;Philipp Mcmillan-Major;Sylvain Schmid;unk Gugger'],single,"['We', 'used', 'GNU', 'Parallel', 'for', 'much', 'of', 'the', 'dataset', 'processing', '<ref type=""single"">(Tange, 2011).</ref>', 'In', 'combination', 'with', '<ref type=""single"">Lhoest et al. (2021)</ref>', 'from', 'Hugging', 'Face,', 'GNU', 'Parallel', 'significantly', 'accelerated', 'pre-processing', 'and', 'phone', 'transcription.']",14,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
9a0c76db-70ff-47e0-8545-cdcb78375e85,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['unknown'],['unknown'],['unknown'],single,"['Cross-batch', 'negatives', '3', 'The', 'cross-batch', 'negative', 'sampling', 'is', 'implemented', 'with', 'differentiable', 'all-gather', 'operation', 'provided', 'in', 'FleetX', '<ref type=""single"">(Dong, 2020),</ref>', 'that', 'is', 'a', 'highly', 'scalable', 'distributed', 'training', 'engine', 'of', 'PaddlePaddle.', 'The', 'all-gather', 'operator', 'makes', 'representation', 'of', 'passages', 'across', 'all', 'GPUs', 'visible', 'on', 'each', 'GPU', 'and', 'thus', 'the', 'cross-batch', 'negative', 'sampling', 'approach', 'can', 'be', 'applied', 'globally.']",16,"[0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9a423e82-1c4f-4716-9123-6d15eedfdc28,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['Efficient estimation of word representations in vector space'],['2013'],['Tomas Mikolov;Kai Chen;Greg Corrado;Jeffrey Dean'],single,"['For', 'natural', 'language', 'processing', 'tasks', 'in', 'Vietnamese,', 'there', 'have', 'been', 'many', 'pre-trained', 'language', 'models', 'are', 'available.', 'In', '2016,', '<ref type=""single"">Vu (2016)</ref>', 'introduced', 'the', 'first', 'monolingual', 'pre-trained', 'models', 'for', 'Vietnamese', 'based', 'on', 'Word2Vec', '<ref type=""single"">(Mikolov et al., 2013).</ref>', 'The', 'use', 'of', 'pre-trained', 'Word2VecVN', 'models', 'was', 'proved', 'to', 'be', 'useful', 'in', 'various', 'tasks,', 'such', 'as', 'the', 'name', 'entity', 'recognition', 'task', '<ref type=""single"">(Vu et al., 2018).</ref>']",30,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
9a7bae68-8e52-4c96-b671-2dbfda610cde,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Learning word vectors for sentiment analysis'],['2011'],['Andrew Maas;Raymond Daly;Peter Pham;Dan Huang;Andrew Ng;Christopher Potts'],single,"['Long', 'Range', 'Arena', '<ref type=""single"">(Tay et al., 2021)</ref>', 'is', 'a', 'recently', 'established', 'benchmark', 'for', 'evaluating', 'the', 'ability', 'of', 'Transformer', 'variants', 'to', 'handle', 'long', 'sequences.', 'It', 'comprises', 'of', 'multiple', 'text', 'classification', 'tasks', 'with', 'inputs', 'containing', 'thousands', 'of', 'tokens', '(Table', '1).', 'In', 'ListOps', '<ref type=""single"">(Nangia and Bowman, 2018),</ref>', 'given', 'a', 'sequence', 'of', 'operations', 'on', 'single-digit', 'integers,', 'the', 'model', 'predicts', 'a', 'single-digit', 'solution', 'modeled', 'as', '10-way', 'classification.', 'IMDb', 'movie', 'reviews', '<ref type=""single"">(Maas et al., 2011)</ref>', 'is', 'a', 'character-level', 'binary', 'sentiment', 'classification', 'task.', 'Lastly,', 'in', 'the', 'ACL', 'Anthology', 'Network', '(AAN)', '<ref type=""single"">(Radev et al., 2013)</ref>', 'task,', 'a', 'character-level', 'model', 'classifies', 'if', 'there', 'is', 'a', 'citation', 'between', 'a', 'pair', 'of', 'papers.']",59,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9af78c81-12f6-4ae0-860c-fddb23f7d14f,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,['Albert: A lite bert for self-supervised learning of language representations'],['2019'],['Zhenzhong Lan;Mingda Chen;Sebastian Goodman;Kevin Gimpel;Piyush Sharma;Radu Soricut'],single,"['Recent', 'work', 'has', 'identified', 'that', 'consecutive', 'lay-', 'ers', 'of', 'BERT', 'have', 'similar', 'functionality', '<ref type=""single"">(Lan et al., 2019).</ref>', 'To', 'study', 'this,', 'we', 'considered', 'configurations', 'where', 'six', 'even', 'and', 'odd', 'alternate', 'layers', 'are', 'pruned', 'and', 'compare', 'it', 'with', 'other', 'strategies', 'of', 'pruning', '50%', 'layers', 'of', 'BERT', '(Table', '6).', 'We', 'observe', 'that', 'the', 'odd', 'configuration', 'performs', 'better', 'than', 'the', 'Top', '6', 'and', 'Bottom', '6', 'configurations,', 'indicating', 'a', 'preference', 'to', 'avoid', 'pruning', 'of', 'consecutive', 'layers.', 'Effect', 'of', 'Fine-Tuning.', 'Recent', 'studies', '<ref type=""group"">(Kovaleva et al., 2019, Houlsby et al., 2019)</ref>', 'have', 'reported', 'that', 'when', 'fine-tuning', 'BERT', 'for', 'specific', 'tasks,', 'the', 'top', 'layers', 'change', 'much', 'more', 'than', 'the', 'lower', 'layers.', 'We', 'now', 'evaluate', 'this', 'for', 'fine-tuning', 'after', 'pruning.']",13,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9b61f41b-a475-4135-a1e6-d71fc92a3054,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['IXM2: A Parallel Associative Processor for Knowledge Processing'],['1990'],['T Gibson ; Gibson;unk Higuchi'],single,"['We', 'are', 'currently', 'investigating', 'whether', 'our', 'model', 'is', 'consistent', 'with', 'human', 'language', 'processing', 'which', 'has', 'limited', 'memory', 'capacity', '<ref type=""single"">[Gibson, 1990].</ref>']",18,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]"
9c035139-62d1-4230-a4e8-91e4d0fb4174,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties'],['2021'],['Kathleen Siminyu;Xinjian Li;Antonios Anastasopoulos;David Mortensen;Michael Marlo;Graham Neubig'],single,"['Nevertheless,', 'it', 'has', 'been', 'shown', 'by', '<ref type=""single"">Siminyu et al. (2021)</ref>', 'that', 'it', 'is', 'possible', 'to', 'improve', 'phone', 'recognition', 'with', 'even', 'small', 'amounts', '(approximately', '100', 'sentences)', 'of', 'annotation.', 'It', 'may', 'be', 'possible', 'to', 'improve', 'phonetic', 'language', 'modeling', 'results', 'by', 'performing', 'this', 'fine-tuning', 'in', 'the', 'target', 'language.']",6,"[0, 2, 2, 2, 2, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
9c2ce5fc-8ff2-4abf-94b1-c64c1ba96ad0,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,"['Sentence boundary detection for transcribed tunisian arabic', 'A morphological-syntactical analysis approach for arabic textual tagging']","['2016', '2008']","['Inès Zribi;Inès Kammoun;Mariem Ellouze;Philippe Belguith;unk Blache', 'Shihadeh Alqrainy']",group,"['Turning', 'our', 'attention', 'now', 'to', 'Arabic', 'POS', 'tagging,', 'many', 'approaches', 'have', 'also', 'been', 'adopted', 'over', 'the', 'years', 'including', 'rule-based', 'methods', '<ref type=""group"">(Alqrainy, 2008, Zribi et al., 2016),</ref>', 'statistical', 'models', '<ref type=""group"">(Al Shamsi and Guessoum, 2006, Kadim and Lazrek, 2018),</ref>', 'hybrid', 'models', '<ref type=""group"">(Vashishtha and Susan, 2019, Forsati and Shamsfard, 2014)</ref>', 'and', 'neural', 'networks', '<ref type=""group"">(Yousif and Sembok, 2006, Yousif and Sembok, 2005).</ref>', 'Performance', 'is', 'usually', 'much', 'higher', 'for', 'POS', 'tagging', 'than', 'NER.', '<ref type=""single"">Khoja (2001)</ref>', 'introduced', 'a', 'hybrid', 'POS', 'tagger', '(with', '33', 'tags)', 'which', 'combined', 'HMM', 'with', 'a', 'rule-based', 'tagger.', 'They', 'used', 'the', 'Holy', 'Quran', 'Corpus', 'and', 'achieved', 'an', 'accuracy', 'rate', 'of', '97.6%', 'and', '96.8%', 'respectively.', 'Yousif', 'and', 'Sembok', '(2008)', 'used', 'the', 'SVM', 'approach', 'and', 'a', 'corpus', 'of', '177', 'tagged', 'words.', '<ref type=""single"">Zeroual and Abdelhak (2016)</ref>', 'presented', 'a', 'probabilistic', 'POS', 'tagger', 'for', 'Arabic', 'text', 'based', 'on', 'HMM', 'called', 'Tree', 'Tagger.', 'The', 'proposed', 'tagger', 'obtained', 'accuracy', 'rates', 'of', '99.4%', 'using', ""Al-Mus'haf"", 'corpus.']",20,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9c6095ee-1e81-4594-b3d4-1ad4befddcda,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Unsupervised machine translation using monolingual corpora only'],['2018'],"[""Guillaume Lample;Ludovic Denoyer;Marc'aurelio Ranzato""]",single,"['The', 'memory', 'component', 'and', 'action', 'gate', 'are', 'endto-end', 'trained', 'in', 'a', 'self-supervised', 'way,', 'where', 'the', 'feedback', 'is', 'whether', 'an', 'utterance', 'and', 'its', 'action', 'representation', 'lead', 'to', 'similar', 'state', 'transitions,', 'We', 'can', 'measure', 'such', 'similarity', 'using', 'a', 'dialogue', 'state', 'tracking', '(DST)', 'model.', 'However,', 'a', 'direct', 'application', 'of', 'the', 'DST', 'model', 'trained', 'by', 'Eqn.', '4', 'might', 'be', 'prone', 'to', 'attribute', 'changes', 'between', 'original', 'utterances', 'and', 'compact', 'natural', 'language', 'actions,', 'which', 'results', 'in', 'insufficient', 'feedback.', 'To', 'address', 'this', 'issue,', 'we', 'adopt', 'a', 'denoising', 'training', 'strategy', 'inspired', 'by', 'unsupervised', 'machine', 'translation', '<ref type=""group"">(Lample et al., 2018 (Lample et al., , 2019)),</ref>', 'and', 'obtain', 'a', 'DST', 'model', 'that', 'is', 'more', 'robust', 'to', 'the', 'attribute', 'transformation.', 'Specifically,', 'we', 'apply', 'a', 'noise', 'function', 'g(x)', 'to', 'the', 'utterances,', 'and', 'modify', 'the', 'DST', 'model', 'training', 'loss', 'as:L', 'dst', '=', 'd', 'i', '−', 'log(b', 't', 'p', 'B', '(g(u', 't', '),', 'g(x', 't−1', '),', 'c', 't−1', '))', '(8)where', 'the', 'noise', 'function', 'corrupts', 'the', 'input', 'utterance', 'by', 'performing', 'word', 'drops', 'and', 'word', 'order', 'shuffling', 'as', 'specified', 'in', '<ref type=""single"">Lample et al. (2018).</ref>']",156,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
9c95e97c-cfef-470d-9e82-e0f1bf3a7c2b,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Named Entity Disambiguation for Noisy Text'],['2017'],['Yotam Eshel;Noam Cohen;Kira Radinsky;Shaul Markovitch;Ikuya Yamada;Omer Levy'],single,"['Named', 'Entity', 'Disambiguation', '(NED)', 'We', 'use', 'the', 'standard', 'English', 'CoNLL-YAGO', 'benchmark', '<ref type=""single"">(Hoffart et al., 2011)</ref>', 'preprocessed', 'by', '<ref type=""single"">Chen et al. (2019).</ref>', 'For', 'each', 'entity', 'mention,', 'at', 'most', '30', 'candidate', 'entities', 'are', 'selected', 'using', 'the', 'CrossWikis', 'dictionary', '(Spitkovsky', 'and', 'Chang,', '2012).', 'This', 'dataset', 'contains', '18.5k', 'training,', '4.8k', 'dev,', 'and', '4.5k', 'test', 'examples', 'from', 'newswire', 'text,', 'so', 'the', 'variety', 'of', 'entities', 'and', 'the', 'writing', 'styles', 'are', 'limited.', 'For', 'this', 'reason,', 'we', 'create', 'another', 'NED', 'dataset', 'from', 'WikilinksNED', '<ref type=""single"">(Eshel et al., 2017),</ref>', 'which', 'includes', 'a', 'wide', 'range', 'of', 'entities', 'and', 'diverse', 'writing', 'styles', 'from', 'scraped', 'English', 'web', 'text', 'linking', 'to', 'Wikipedia.', 'We', 'limit', 'the', 'number', 'of', 'candidate', 'entities', 'to', '3', 'for', 'each', 'instance,', 'which', 'still', 'makes', 'a', 'challenging', 'benchmark.', 'We', 'create', '5k', 'training,', '1k', 'dev,', 'and', '1k', 'test', 'examples', 'and', 'call', 'this', 'dataset', 'WLNED.', 'In', 'both', 'CoNLL-YAGO', 'and', 'WLNED,', 'we', 'form', 'descriptions', 'of', 'candidate', 'entities', 'using', 'the', 'Wiki-Context', 'data,', 'but', 'do', 'not', 'use', 'any', 'structural', 'information', 'from', 'Wikipedia', '(hyperlinks,', 'etc.).', 'Our', 'method', 'simply', 'computes', 'cosine', 'similarity', 'and', 'uses', 'it', 'as', 'a', 'score', 'for', 'each', 'task,', 'not', 'introducing', 'any', 'new', 'parameters.', 'Our', 'baselines', 'use', 'a', 'trainable', 'logistic', 'regression', 'layer', 'over', 'pre-trained', 'embeddings', 'to', 'make', 'classification', 'decisions.']",69,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9ca487ed-1497-4446-ad69-5b1fab9fe625,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['unknown'],['unknown'],['unknown'],single,"['Adjectives', 'are', 'primarily', 'used', 'for', 'modification', 'of', 'nouns.', 'They', 'have', 'lexical', 'organization', 'and', 'semantic', 'properties', 'that', 'are', 'not', 'shared', 'by', 'other', 'modifiers', 'and', 'are', 'unique', 'to', 'them', '<ref type=""single"">(Miller et al, 1993).</ref>', 'The', 'selected', 'sense', 'of', 'the', 'adjective', 'sorry', 'in', 'WordNet', 'has', 'the', 'gloss', 'as', 'feeling', 'or', 'expressing', 'regret', 'or', 'sorrow', 'or', 'a', 'sense', 'of', 'loss', 'over', 'something', 'done', 'or', 'undone.', 'The', 'see', 'also', 'relation', 'for', 'this', 'is', 'the', 'adjective', 'penitent,', 'repentant,', 'which', 'means', 'feeling', 'or', 'expressing', 'remorse', 'for', 'misdeeds.', 'Thus,', 'the', 'underlying', 'semantic', 'connotation', 'of', 'the', 'word', 'is', 'a', 'feeling', 'or', 'an', 'emotional', 'state.', 'An', 'example', 'of', 'this', 'is', 'the', 'sentence', 'in', 'the', 'apology', 'number', '3', 'which', 'states-We', 'are', 'truly', 'sorry', 'for', 'this', 'and', 'will', 'ensure', 'that', 'this', 'never', 'happens', 'again.', 'Here', 'the', 'use', 'of', 'sorry', 'refers', 'to', 'the', 'feelings', 'expressed', 'by', 'the', 'offender.', 'In', 'our', 'dataset,', 'out', 'of', 'the', '18', 'communications,', '7', 'have', 'the', 'use', 'of', 'sorry.', 'In', 'these', '7', 'letters', 'it', 'is', 'used', '12', 'times.']",27,"[3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9d010954-b3c7-41d2-8e5a-ec5c0db53c8b,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['The Mental Representation of Grammatical Relations'],['1982'],['J Bresnan ; Bresnan'],single,"['Control', 'is', 'handled', 'using', 'the', 'syntactic', 'constraint', 'network.', 'Sentence', 's7', 'is', 'an', 'example', 'of', 'sentence', 'involving', 'functional', 'control', '<ref type=""single"">[Bresnan, 1982].</ref>', 'In', 's7,', 'both', 'subject', 'control', 'and', 'object', 'control', 'exist', '-the', 'subject', 'of', ""'persuade'"", 'should', 'be', 'the', 'subject', 'of', ""'tried'"", '(subject', 'control),', 'and', 'the', 'subject', 'of', ""'help'"", 'should', 'be', 'the', 'object', 'of', ""'persuade'"", '(object', 'control).', 'In', 'this', 'case,', 'CSCS', 'for', 'infinitival', 'complement', 'has', 'CSE', 'without', 'NEXT', 'link.', 'Such', 'an', 'CSE', 'represents', 'missing', 'subject.', 'There', 'are', 'SUBJ,', 'OBJ,', 'and', 'OBJ2', 'nodes', '(these', 'are', 'functional', 'controller)', 'in', 'the', 'syntactic', 'constraints', 'network', 'each', 'of', 'which', 'store', 'pointer', 'to', 'the', 'CI', 'node', 'for', 'possible', 'controllee.', 'Syntactic', 'constraint', 'links', 'from', 'each', 'lexical', 'items', 'of', 'the', 'verb', 'determine', 'which', 'functional', 'controller', 'is', 'active.', 'Activated', 'functional', 'controller', 'propagate', 'a', 'pointer', 'to', 'the', 'CI', 'node', 'to', 'unbound', 'subject', 'nodes', 'of', 'CSCs', 'for', 'infinitival', 'complements.', 'Basically,', 'one', 'set', 'of', 'nodes', 'for', 'functional', 'controller', 'handles', 'deeply', 'nested', 'cases', 'due', 'to', 'functional', 'locality.']",18,"[3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
9d2ed5ff-c948-4807-a155-0da8c4a5f40f,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,['Huric: a human robot interaction corpus'],['2014'],['Emanuele Bastianelli;Giuseppe Castellucci;Danilo Croce;Luca Iocchi;Roberto Basili;Daniele Nardi'],single,"['HuRIC', '2.0', '<ref type=""single"">(Bastianelli et al., 2014):</ref>', 'audio', 'files', '(656', 'sentences)', 'paired', 'with', 'their', 'transcriptions', 'referring', 'to', 'commands', 'for', 'a', 'robot', 'LAVA', '<ref type=""single"">(Berzak et al., 2016):</ref>', '237', 'sentences,', 'with', '2', 'to', '3', 'interpretations', 'per', 'sentence,', 'and', 'a', 'total', 'of', '1679', 'videos', 'that', 'depict', 'visual', 'variations', 'of', 'each', 'interpretation', 'CLEVR-Ref+', '<ref type=""single"">(Liu et al., 2019):</ref>', '100', 'K', 'synthetic', 'images', 'with', 'several', 'referring', 'expressions', 'Eye4Ref', '(Alac', '¸am', 'et', 'al.,', '2020b):', '86', 'systematically', 'controlled', 'sentence--image', 'pairs', 'and', '2024', 'eye-movement', 'recordings', 'from', 'various', 'referentially', 'complex', 'situations', 'Multimodal', 'embeddings', 'will', 'be', 'created', 'from', 'this', 'pool', 'of', 'datasets.', 'Creating', 'embeddings', 'from', 'various', 'data', 'sources', 'will', 'allow', 'us', 'to', 'cover', 'concepts', 'from', 'various', 'aspects', 'such', 'as', 'linguistic,', 'auditory', 'and', 'visual', 'representations.', 'The', 'variety', 'on', 'the', 'visual', 'modality', 'will', 'also', 'help', 'us', 'to', 'capture', 'different', 'visual', 'depictions', 'in', 'a', 'range', 'from', 'synthetic', 'images', 'to', 'photographs.', 'This', 'will', 'increase', 'the', 'representativeness', 'of', 'the', 'concepts', 'in', 'the', 'training', 'dataset', 'that', 'will', 'in', 'return', 'improve', 'the', 'prediction', 'when', 'it', 'comes', 'to', 'unseen', 'environments', 'either', 'in', 'virtual', 'reality', 'or', 'in', 'a', 'real-world', 'setting.', '70', '%', 'of', 'this', 'collection', 'will', 'be', 'used', 'to', 'create', 'multimodal', 'concept', 'embeddings.', 'The', 'remaining', '30', '%', 'of', 'the', 'datasets', 'will', 'be', 'included', 'in', 'the', 'test', 'and', 'development', 'sets', 'after', 'semi-automatic', 'and', 'manual', 'annotation', 'of', 'contextual', 'representations,', 'target', 'words,', 'missing', 'words,', 'etc.', 'However,', 'Eye4REF', 'will', 'be', 'used', 'as', 'main', 'testset', 'since', 'it', 'was', 'systematically', 'created', 'to', 'involve', 'referentially', 'complex', 'situations.']",2,"[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9d67122c-0961-4a63-bf2e-27ed5f287826,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Decontextualization: Making sentences stand-alone'],['2021'],['Eunsol Choi;Jennimaria Palomaki;Matthew Lamm;Tom Kwiatkowski;Dipanjan Das;Michael Collins'],single,"['A', 'Note', 'on', 'Decontextualization', 'Recently,', '<ref type=""single"">Choi et al. (2021)</ref>', 'introduced', 'the', 'text-decontextualization', 'task,', 'in', 'which', 'the', 'input', 'is', 'a', 'text', 'and', 'an', 'enclosing', 'textual', 'context,', 'and', 'the', 'goal', 'is', 'to', 'produce', 'a', 'standalone', 'text', 'that', 'can', 'be', 'fully', 'interpreted', 'outside', 'of', 'the', 'enclosing', 'context.', 'The', 'decontextualization', 'task', 'involves', 'handling', 'multiple', 'linguistic', 'phenomena,', 'and,', 'in', 'order', 'to', 'perform', 'it', 'well,', 'one', 'must', 'essentially', 'perform', 'a', 'version', 'of', 'the', 'NP', 'Enrichment', 'task.', 'For', 'example,', 'decontextualizing', ""''Prices"", 'are', 'expected', 'to', ""rise''"", 'based', 'on', ""''Temporary"", 'copper', 'shortage.', 'Prices', 'are', 'expected', 'to', ""rise'',"", 'involves', 'establishing', 'the', 'relation', ""''Prices"", '[of', 'copper]', 'are', 'expected', 'to', ""rise'').""]",5,"[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
9e6a4570-4356-41fa-9d97-fbe46979c36e,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['Restricting the Weak-Generative Capacity of Synchronous Tree Adjoining Grammars'],['1994'],['S Shieber'],single,"['In', 'pairing', 'two', 'TAGs', 'for', 'MT,', 'syntax-semantics', 'mapping', 'or', 'paraphrase,', 'under', 'the', 'redefinition', 'of', 'Synchronous', 'TAG', 'in', '<ref type=""single"">Shieber (1994)</ref>', 'there', 'must', 'be', 'an', 'isomorphism', 'between', 'the', 'derivations', 'of', 'two', 'strings', 'to', 'be', 'paired.', 'In', 'TAG,', 'for', 'each', 'DERIVED', 'TREE', 'derived', 'from', 'smaller', 'elementary', 'trees,', 'there', 'is', 'a', 'corresponding', 'DERIVATION', 'TREE', 'which', 'describes', 'the', 'history', 'of', 'the', 'derivation.', 'This', 'derivation', 'tree', 'has', 'a', 'number', 'of', 'similarities', 'to', 'dependency', 'trees,', 'but', 'is', 'not', 'exactly', 'the', 'same', '<ref type=""single"">(Rambow and Joshi, 1997).</ref>', 'In', 'general', 'there', 'will', 'not', 'be', 'an', 'isomorphism', 'between', 'two', 'such', 'trees', 'for', 'any', 'of', 'the', 'above', 'applications,', 'hence', ""Shieber's"", 'proposed', 'extension', 'to', 'allow', '""bounded', 'subderivation""', '(which', 'correspond', 'to', 'gCNs', 'in', 'the', 'context', 'of', 'derivation', 'trees).', 'However,', 'he', 'also', 'notes', 'the', 'possibility,', 'further', 'explored', 'in', '<ref type=""single"">Dras and Bleam (2000),</ref>', 'that', 'the', 'pairing', 'of', 'gNCNs', 'will', 'be', 'necessary.', 'An', 'example', 'taken', 'from', 'the', 'latter', 'is', 'in', '(2).', 'teeth.', 'The', 'doctor', 'wants', 'to', 'be', 'able...', 'to', 'examine', 'his', 'teeth.']",17,"[2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
9f3b2363-257c-43e6-8bcf-613ef0a20d9f,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['Open-source Portuguese-Spanish machine translation'],['2006'],['Miriam Martínez;unk Scalco'],single,"['Apertium,', 'the', 'open-source', 'MT', 'platform', 'that', 'was', 'used', 'as', 'basis', 'in', 'the', 'case', 'study,', 'is', 'described', 'in', 'the', 'first', 'section', 'following', 'the', 'introduction.', 'Materials', 'and', 'methods', 'describe', 'already', 'available', 'language', 'processing', 'tools', 'and', 'materials,', 'mainly', 'corpora.', 'The', 'newly', 'developed', 'methods', 'are', 'described', 'in', 'the', 'same', 'section.', 'Following', 'section', 'describes', 'results', 'and', 'evaluation', 'methods.', 'The', 'last', 'section', 'describes', 'discussion', 'and', 'further', 'work.', 'The', 'modules', 'are', 'shown', 'on', 'Figure', '1,', 'where', 'the', 'specially', 'addressed', 'modules', 'are', 'marked', 'with', 'a', 'new', 'colour', 'and', 'the', 'two', 'newly', 'added', 'modules', 'are', 'inserted.', 'Each', ""group's"", 'data', 'creation', 'was', 'addressed', 'by', 'a', 'particular', 'method,', 'monolingual', 'dictionaries', 'were', 'constructed', 'using', 'bilingual', 'dictionary', 'data', 'and', 'applying', 'automatic', 'paradigm', 'tagging', 'techniques,', 'bilingual', 'dictionary', 'was', 'constructed', 'using', 'available', 'bilingual', 'word-list', 'but', 'a', 'few', 'methods', 'for', 'automatic', 'bilingual', 'dictionary', 'construction', 'were', 'investigated,', 'a', 'method', 'for', 'automatic', 'structural', 'shallow-transfer', 'rule', 'construction', '(Sánchez-', '<ref type=""single"">Martínez et al., 2006)</ref>', 'will', 'be', 'used', 'to', 'construct', 'a', 'set', 'of', 'structural', 'transfer', 'rules.']",139,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
9fa81d15-40bb-4745-aa43-3bccc67ee79a,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,"['Continuous space language models for the IWSLT 2006 task', 'The TALP ngram-based SMT system for IWSLT']","['2006', '2007']","['H Schwenk;M Costa-Jussà;J Fonollosa', 'P Lambert;M Costa-Jussà;J Crego;M Khalilov;J No;R Banchs;J Fonollosa;H Schwenk']",group,"['In', 'this', 'paper,', 'we', 'propose', 'to', 'use', 'the', 'so-called', 'continuous', 'space', 'language', 'model.', 'The', 'basic', 'idea', 'of', 'this', 'approach', 'is', 'to', 'project', 'the', 'word', 'indices', 'onto', 'a', 'continuous', 'space', 'and', 'to', 'use', 'a', 'probability', 'estimator', 'operating', 'on', 'this', 'space', '<ref type=""single"">[8].</ref>', 'Since', 'the', 'resulting', 'probability', 'functions', 'are', 'smooth', 'functions', 'of', 'the', 'word', 'representation,', 'better', 'generalization', 'to', 'unknown', 'n-grams', 'can', 'be', 'expected.', 'A', 'neural', 'network', 'can', 'be', 'used', 'to', 'simultaneously', 'learn', 'the', 'projection', 'of', 'the', 'words', 'onto', 'the', 'continuous', 'space', 'and', 'to', 'estimate', 'the', 'n-gram', 'probabilities.', 'This', 'is', 'still', 'a', 'n-gram', 'approach,', 'but', 'the', 'language', 'model', 'posterior', 'probabilities', 'are', '""interpolated""', 'for', 'any', 'possible', 'context', 'of', 'length', 'n', '−', '1', 'instead', 'of', 'backing-off', 'to', 'shorter', 'contexts.', 'This', 'approach', 'was', 'already', 'successfully', 'applied', 'in', 'statistical', 'machine', 'translation', 'systems,', 'ranging', 'from', 'small', 'IWSLT', 'systems', '<ref type=""group"">[9, 10]</ref>', 'to', 'large', 'NIST', 'systems', '<ref type=""single"">[1].</ref>']",129,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 3, 3, 3, 3]"
9fcafbcd-e993-4819-af98-c38406811d32,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Graph regularized transductive classification on heterogeneous information networks'],['2010'],['Ming Ji;Yizhou Sun;Marina Danilevsky;Jiawei Han;Jing Gao'],single,"['To', 'extract', 'the', 'features', 'regarding', 'the', 'network', 'object', 'classes,', 'we', 'applied', 'a', 'regularization', 'method', 'to', 'the', 'graph.', 'Regularization', 'is', 'a', 'kind', 'of', 'semi-supervised', '(or', 'transductive)', 'classification', 'method', 'that', 'aims', 'to', 'find', 'a', 'set', 'of', 'labels,', 'minimizing', 'a', 'cost', 'function', 'and', 'satisfying', 'two', 'conditions:', '(i)', 'the', 'method', 'needs', 'to', 'be', 'consistent', 'with', 'the', 'set', 'of', 'labels', 'manually', 'annotated', 'and', '(ii)', 'the', 'method', 'needs', 'to', 'be', 'consistent', 'with', 'the', 'network', 'topology,', 'considering', 'that', 'nearest', 'neighbors', 'tend', 'to', 'have', 'the', 'same', 'labels', '<ref type=""single"">(Ji et al., 2010).</ref>']",79,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
a03f8ae9-ca55-4fd6-9630-401caf2b3c73,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['SentiWordNet: a high-coverage lexical resource for opinion mining'],['2007'],['Andrea Esuli;Fabrizio Sebastiani'],single,"['The', 'study', 'of', 'the', 'sentiment', 'associated', 'with', 'the', 'keywords', 'is', 'done', 'using', 'SentiWordNet', '(3.0),', 'a', 'lexical', 'resource', 'which', 'assigns', 'to', 'each', 'synset', 'of', 'WordNet', 'three', 'sentiment', 'scores:', 'positivity,', 'negativity,', 'objectivity', '<ref type=""single"">(Stefano et al, 2010).</ref>', 'The', 'task', 'of', 'finding', 'the', 'sentiments', 'of', 'the', 'words', 'in', 'an', 'apology', 'as', 'expressed', 'in', 'online', 'forums', 'can', 'be', 'put', 'to', 'a', 'rich', 'set', 'of', 'applications', '<ref type=""single"">(Esuli and Sebastiani, 2007).</ref>', 'As', 'for', 'public', 'apologies', 'these', 'tasks', 'can', 'range', 'from', 'tracking', ""readers'"", 'opinions', 'about', 'the', 'sincerity', 'of', 'the', 'communication', 'to', 'customer', 'relationship', 'management.', 'The', 'selected', 'synsets', 'of', 'the', 'keywords', 'were', 'searched', 'for', 'in', 'SentiWordNet.', 'The', 'sentiment', 'scores', 'of', 'each', 'of', 'them', 'were', 'recorded', 'and', 'the', 'results', 'were', 'analyzed.', 'Table', '1', 'shows', 'the', 'sentiment', 'scores', 'for', 'positivity,', 'negativity', 'and', 'objectivity', 'for', 'each', 'of', 'the', 'keywords.', 'In', 'the', 'analysis', 'of', 'the', 'sentiments', 'associated', 'with', 'keywords,', 'of', 'particular', 'interest', 'are', 'the', 'objective', 'scores.', 'The', 'verb', 'apologize', 'has', 'the', 'highest', 'objective', 'score', '(1.0).', 'Its', 'negative', 'and', 'positive', 'scores', 'are', 'zero.', 'The', 'high', 'ObjScore', '(Objective', 'Score)', 'of', 'one', '(1.0)', 'implies', 'that', 'this', 'verb', 'does', 'not', 'convey', 'any', 'sentiment.', 'In', 'a', 'public', 'apology', 'act,', 'this', 'could', 'entail', 'that', 'when', 'an', 'organization', 'or', 'person', 'renders', 'an', 'apology', 'it', 'distances', 'itself', 'from', 'the', 'event', 'or', 'issue', 'and', 'takes', 'an', 'objective', 'position.', 'Similarly', 'the', 'next', 'highest', 'ObjScore', 'is', 'for', 'regret', 'as', 'a', 'verb', '(0.75).', 'Thus,', 'both', 'verbs', '-apologize', 'and', 'regretdo', 'not', 'connect', 'with', 'the', 'negative', 'sentiments', 'associated', 'with', 'the', 'act', 'of', 'an', 'apology.Keywords', 'PosScore', '[0,1]', 'NegScore', '[0,1]', 'ObjScore', '[0,The', 'highest', 'NegScore', '(Negative', 'Score)', 'is', 'for', 'the', 'adjective', 'sorry', '(0.75),', 'followed', 'by', 'the', 'noun', 'regret', 'which', 'has', 'a', 'NegScore', 'of', '0.625.', 'The', 'strong', 'negative', 'connotation', 'of', 'the', 'adjective', 'sorry', 'could', 'help', 'the', 'writer', 'to', 'convey', 'his', 'genuine', 'feeling', 'of', 'remorse', 'and', 'hence', 'should', 'be', 'preferred', 'by', 'the', 'writer', 'to', 'connect', 'with', 'the', 'reader', 'at', 'an', 'emotional', 'level.', 'Since', 'adjectives', 'are', 'the', 'words', 'that', 'carry', 'the', 'most', 'notions', 'of', 'sentiment,', 'their', 'use', 'in', 'the', 'apology', 'can', 'carry', 'the', 'sentiment', 'most', 'effectively.', 'This', 'implies', 'that', 'the', 'adjective', 'sorry', 'carries', 'the', 'highest', 'sentimental', 'load', 'to', 'convey', 'the', 'feeling', 'associated', 'with', 'act', 'of', 'apology.']",57,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a073a3be-44a4-445c-bd27-736495ea1a9f,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Long Range Arena : A benchmark for efficient transformers'],['2021'],['Yi Tay;Mostafa Dehghani;Samira Abnar;Yikang Shen;Dara Bahri;Philip Pham;Jinfeng Rao;Liu Yang;Sebastian Ruder;Donald Metzler'],single,"['For', 'each', 'task,', 'we', 'downloaded', 'and', 'directly', 'used', 'the', 'vanilla', 'Transformer', 'code', 'offered', 'by', 'the', 'authors', '<ref type=""single"">(Tay et al., 2021)</ref>', 'and', 'compared', 'the', 'performance', 'before', 'and', 'after', 'replacing', 'the', 'multi-head', 'attention', 'layers', 'with', 'top-128', 'attention,', 'using', 'identical', 'hyperparameters', 'for', 'both', 'cases', '(details', 'in', '§A.1).', '2', 'Test', 'accuracy', 'measured', 'at', 'the', 'training', 'checkpoint', 'with', 'the', 'highest', 'accuracy', 'on', 'the', 'development', 'set', 'is', 'reported', 'in', 'Table', '1', 'and', 'the', 'learning', 'curves', 'on', 'the', 'development', 'and', 'test', 'sets', 'are', 'shown', 'in', 'Fig.', '5.', 'On', 'IMDb', 'and', 'AAN,', 'the', 'performance', 'of', 'top-128', 'is', 'comparable', 'or', 'better', 'than', 'vanilla', 'attention.', 'For', 'ListOps,', 'there', 'is', 'a', 'minor', 'drop', 'in', 'performance', '(1.5', 'points),', 'but', 'learning', 'curves', '(Figure', '5a)', 'exhibit', 'similar', 'behaviour.']",16,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a086fad3-b4a1-4730-98e7-01661875ab42,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['Sublanguage and multilingual corpus analysis for example-based machine translation'],['1992'],['Alexa unk;M unk;E Barcena'],single,"['The', 'data', 'forming', 'the', 'multilingual', 'corpus', 'of', 'examples', 'are', 'derived', 'empirically', 'from', 'real-life', 'examples', 'of', 'job', 'adverts.', 'For', 'practical', 'reasons,', 'we', 'cannot', 'expect', 'to', 'have', 'available', 'a', 'truly', 'parallel', 'corpus', 'of', 'texts', 'in', 'this', 'domain.', 'The', 'contrastive', 'linguistic', 'knowledge', 'of', 'the', 'system', 'cannot', 'therefore', 'be', 'captured', 'by', 'paired', 'examples', 'of', 'translational', 'equivalents', 'as', 'in', 'the', 'IBM', 'statistical', 'approach', 'for', 'example', '<ref type=""group"">([5, 6]</ref>', '),', 'so', 'the', 'more', 'abstract', 'intentional', 'model', 'is', 'relied', 'on', 'as', 'a', 'kind', 'of', 'mediator,', 'where', 'it', 'is', 'the', 'functional', 'rather', 'than', 'formal', 'property', 'of', 'the', 'text', 'fragment', 'that', 'gives', 'its', 'target', 'language', 'counterpart.', 'The', 'analysis', 'of', 'the', 'multilingual', 'corpora', '<ref type=""single"">([2])</ref>', 'provides', 'us', 'with', 'data', 'influencing', 'the', 'design', 'of', 'the', 'linguistic', 'representations', 'to', 'be', 'used', 'in', 'the', 'example', 'database,', 'as', 'well', 'as', 'determining', 'the', 'content', 'and', 'form', 'of', 'both', 'the', 'intentional', 'model', '-where', 'the', 'functional', 'and', 'pragmatic', 'aspects', 'of', 'the', 'job', 'adverts', 'are', 'defined', '-and', 'providing', 'information', 'to', 'enable', 'the', 'domain', 'knowledge', 'of', 'the', 'system', 'to', 'be', 'defined.', 'This', 'last', 'is', 'based', 'on', 'the', 'prepositional', 'content', 'of', 'the', 'corpus,', 'which', 'determines', 'not', 'only', 'what', 'are', 'the', 'commonalities', 'of', 'the', 'language', 'of', 'the', 'domain,', 'but', 'also', 'enabling', 'illegal', 'phrases', 'to', 'be', 'identified,', 'as', 'well', 'as', 'revealing', 'problems', 'of', 'non-equivalences,', 'especially', 'of', 'job', 'titles', 'and', 'qualifications,', 'etc.', 'An', 'additional', 'point', 'of', 'interest', 'arising', 'especially', 'from', 'the', 'text-type', 'and', 'domain', 'chosen', 'is', 'the', 'likelihood', 'of', 'cultural', 'differences', 'being', 'reflected', 'in', 'differences', 'in', 'the', 'examples', 'and', 'hence', 'in', 'the', 'intentional', 'models.', 'These', 'may', 'be', 'superficial,', 'such', 'as', 'the', 'typical', 'order', 'of', 'presenting', 'the', 'information,', 'or', 'may', 'pose', 'more', 'serious', 'problems', '(see', 'below).']",101,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a0a393bc-cfd1-4e4c-b48b-dacd687b5ea5,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['Assessment of fluency and adequacy in translations'],['2005'],['unk Ldc'],single,"['A', 'bilingual', 'parallel', 'corpus', '<ref type=""single"">(Erjavec, 2004)</ref>', 'was', 'used', 'for', 'automatic', 'evaluation', 'using', 'BLEU', 'metric', '<ref type=""single"">(Papineni et al., 2001).</ref>', 'The', 'results', 'are', 'presented', 'in', 'Table', '2.', 'The', 'values', 'are', 'quite', 'low,', 'partly', 'due', 'to', 'reasons', 'explained', 'in', '(Callison-Burch', 'et', 'al.,', 'partly', 'due', 'to', 'unknown', 'words', 'in', 'test', 'corpus.', 'Figure', '6', 'shows', 'results', 'of', 'evaluation', 'of', 'translation', 'quality', 'using', 'subjective', 'measures', 'using', 'methodology', '<ref type=""single"">(LDC, 2005).</ref>', 'The', 'methodology', 'is', 'explained', 'in', 'chapter', '4.1.', 'Four', 'independent', 'evaluators', '(two', 'native', 'speakers)', 'evaluated', 'sets', 'of', '100', 'sentences', 'using', 'this', 'methodology.']",57,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
a103e852-0a6b-459b-8289-ba84fde2aec0,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,"['Generating natural language adversarial examples', 'Certified robustness to adversarial word substitutions']","['2018', '2019']","['Moustafa Alzantot;Yash Sharma;Ahmed Elgohary;Bo-Jhang Ho;Mani Srivastava;Kai-Wei Chang', 'Robin Jia;Aditi Raghunathan;Kerem Göksel;Percy Liang']",group,"['Attack', 'success', 'rate', '(first-order).', 'We', 'quantify', 'first-order', 'robustness', 'through', 'attack', 'success', 'rate,', 'which', 'measures', 'the', 'ratio', 'of', 'test', 'examples', 'that', 'an', 'adversarial', 'example', 'can', 'be', 'found.', 'We', 'use', 'firstorder', 'attacks', 'as', 'a', 'reference', 'due', 'to', 'the', 'lack', 'of', 'a', 'direct', 'baseline.', 'We', 'experiment', 'with', 'two', 'black-box', 'attacks:', '(1)', 'The', 'Genetic', 'attack', '<ref type=""group"">(Alzantot et al., 2018, Jia et al., 2019)</ref>', 'uses', 'a', 'population-based', 'op-timization', 'algorithm', 'that', 'generates', 'both', 'syntactically', 'and', 'semantically', 'similar', 'adversarial', 'examples,', 'by', 'replacing', 'words', 'within', 'the', 'list', 'of', 'counterfitted', 'synonyms.']",51,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
a2284fff-09b6-47a8-a548-635e266591f1,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['CCG contextual labels in hierarchical phrase-based SMT'],['2011'],['H Almaghout;J Jiang;A Way'],single,"['Despite', 'of', 'the', 'advantages', 'of', 'using', 'CCG', 'categories', 'to', 'label', 'non-terminals', 'in', 'the', 'HPB', 'system', 'compared', 'with', 'SAMT', 'labels,', 'richness', 'of', 'CCG', 'categories', 'still', 'leads', 'to', 'a', 'large', 'number', 'of', 'different', 'non-terminal', 'labels.', 'This', 'causes', 'fragmentation', 'of', 'rule', 'probabilities', 'and', 'consequently', 'affects', 'translation', 'quality', 'negatively.', 'A', 'CCG', 'category', 'C', 'takes', 'the', 'form', 'of', 'C=(T\\L)/R', 'where', 'L', 'represents', 'the', 'left', 'argument', 'category,', 'R', 'the', 'right', 'argument', 'category,', 'and', 'T', 'the', 'resulting', 'category.', 'Each', 'of', 'these', 'constituent', 'categories', 'might', 'be', 'atomic', 'or', 'complex.', 'Furthermore,', 'some', 'atomic', 'CCG', 'categories', 'have', 'features', 'expressed', 'between', 'brackets', 'which', 'describe', 'certain', 'syntactic', 'information.', 'For', 'example,', 'the', 'atomic', 'category', 'S', 'might', 'have', 'a', 'feature', 'attached', 'to', 'it', 'which', 'distinguishes', 'types', 'of', 'sentences', 'such', 'as', 'declarative', 'S[dcl]', 'or', 'wh-question', 'S[wq].', 'All', 'the', 'additional', 'information', 'represented', 'in', 'a', 'single', 'CCG', 'category', 'increases', 'the', 'number', 'of', 'different', 'CCG', 'categories', 'and', 'leads', 'to', 'label', 'sparsity', 'problem.', 'In', 'order', 'to', 'address', 'this', 'problem,', 'we', 'simplify', 'CCG', 'non-terminal', 'labels', 'by', 'reducing', 'the', 'amount', 'of', 'the', 'information', 'represented', 'in', 'them', 'using', 'the', 'following', 'approaches', '<ref type=""single"">[14]:</ref>']",169,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
a237c8f2-31c8-44aa-a13e-7ba28d19e037,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['How to do things with words'],['1975'],['L John;unk Austin'],single,"['The', 'main', 'aspect', 'of', 'an', 'apology', 'lies', 'in', 'the', 'verb', 'that', 'the', 'tenderer', 'chooses', 'to', 'use.', 'We', 'do', 'an', 'analysis', 'of', 'the', 'two', 'verbs,', 'apologize', 'and', 'regret,', 'using', 'WordNet,', 'the', 'former', 'being', 'an', 'explicit', 'performative', 'verb', '<ref type=""single"">(Austin, 1975),</ref>', 'The', 'selected', 'sense', 'of', 'the', 'verb', 'apologize', 'is', 'defined', 'as', '-to', 'acknowledge', 'faults', 'or', 'shortcomings', 'or', 'failing.', 'Its', 'semantic', 'relation', 'of', 'entailment', 'is', 'admit,', 'acknowledge,', 'which', 'means', 'to', 'declare', 'to', 'be', 'true', 'or', 'admit', 'the', 'existence', 'or', 'reality', 'or', 'truth', 'of.', 'One', 'of', 'its', 'troponym', 'is', 'to', 'concede,', 'profess,', 'confess', 'which', 'is', 'defined', 'as', 'to', 'admit', '(to', 'a', 'wrongdoing).', 'The', 'superordinate', 'concept', 'of', 'this', 'chain', 'is', 'the', 'verb', 'think,', 'cogitate,', 'cerebrate', 'which', 'is', 'defined', 'as-to', 'use', 'or', 'exercise', 'the', 'mind', 'or', ""one's"", 'power', 'of', 'reason', 'in', 'order', 'to', 'make', 'inferences,', 'decisions,', 'or', 'arrive', 'at', 'a', 'solution', 'or', 'judgments.', 'Thus,', 'it', 'is', 'clear', 'from', 'the', 'semantic', 'hierarchy', 'that', 'to', 'apologize', 'is', 'to', 'undergo', 'a', 'logical', 'thought', 'process,', 'the', 'natural', 'entailment', 'of', 'which', 'is', 'to', 'admit', 'to', 'a', 'wrong.', 'Once', 'the', 'wrongdoing', 'is', 'admitted', 'the', 'natural', 'consequence', 'should', 'be', 'to', 'take', 'responsibility', 'and', 'offer', 'amends.', 'For', 'instance,', 'apology', 'number', '2', 'says-I', 'sincerely', 'apologize', 'to', 'all', 'Satyamites', 'and', 'stakeholders.', 'This', 'is', 'a', 'clear', 'admission', 'of', 'wrongdoing.', 'The', 'selected', 'concept', 'of', 'the', 'verb', 'regret', 'is', 'defined', 'as', 'to', 'feel', 'remorse', 'for,', 'feel', 'sorry', 'for', 'or', 'be', 'contrite', 'about.', 'Its', 'inherited', 'hypernymy', 'is', 'to', 'feel,', 'experience,', 'which', 'is', 'defined', 'as', 'to', 'undergo', 'an', 'emotional', 'sensation', 'or', 'be', 'in', 'a', 'particular', 'state', 'of', 'mind.', 'Thus,', 'to', 'regret', 'is', 'to', 'undergo', 'a', 'feeling', 'by', 'the', 'offender', 'about', 'the', 'wrongdoing.', 'In', 'the', 'corpus', 'apology', 'number', '10,', 'the', 'Amazon', 'India', 'letter', 'states,', 'To', 'the', 'extent', 'that', 'these', 'items', 'offered', 'by', 'a', 'third-party', 'seller', 'in', 'Canada', 'offended', 'Indian', 'sensibilities,', 'Amazon', 'regrets', 'the', 'same.']",36,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a27b0d1a-2db8-417a-8054-72e84cc8b355,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['Do apologies in e-mails follow spoken or written norms? Some examples from British English'],['2005'],['Ciler Hatipoğlu'],single,"['Nonetheless,', 'the', 'established', 'convention', 'incorporates', 'a', 'distancing', 'from', 'the', 'offence.', 'Also,', 'writers', 'use', 'apologies', 'when', 'they', 'are', 'apologising', 'in', 'a', 'role', '(e.g.', 'as', 'the', 'representative', 'of', 'an', 'organisation).', 'When', 'speaking', 'personally,', 'they', 'use', 'other', 'forms,', 'typically', 'sorry', '<ref type=""single"">(Hatipoğlu, 2005).</ref>', 'Another', 'possibility', 'is', 'that', 'use', 'of', 'the', 'noun', 'form', 'enables', 'the', 'writer', 'to', 'avoid', 'the', 'personal', 'pronoun,', 'creating', 'a', 'distance', 'between', 'the', 'writer', 'and', 'the', 'responsibility', 'for', 'the', 'offence', '(ibid).', 'In', 'our', 'data,', 'individuals', 'have', 'not', 'used', 'this', 'form', 'at', 'all', 'and', 'of', 'the', 'seven', 'occurrences', 'of', 'the', 'noun', 'form,', 'six', 'are', 'by', 'individuals', 'as', 'representative', 'of', 'an', 'organisation.', 'This', 'co-relates', 'to', ""Harrison's"", 'finding', 'that', 'the', 'word', 'apology/', 'apologies', 'help', 'the', 'writers', 'to', 'distance', 'themselves', 'from', 'the', 'instance', 'or', 'event.']",37,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a2d9c9c1-318d-4d04-815b-880bbabcf658,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Kg-bart: Knowledge graph-augmented bart for generative commonsense reasoning'],['2021'],['Ye Liu;Yao Wan;Lifang He;Hao Peng;Philip S Yu'],single,"['We', 'note', 'that', 'as', 'we', 'targeted', 'at', 'the', 'one-to-many', 'generation', 'problem,', 'we', 'excluded', 'those', 'baseline', 'methods', 'mentioned', 'in', 'the', 'related', 'work', 'that', 'cannot', 'produce', 'multiple', 'outputs,', 'e.g.,', '<ref type=""single"">Zhang et al. (2020a),</ref>', '<ref type=""single"">Ji et al. (2020),</ref>', '<ref type=""single"">Liu et al. (2021).</ref>', 'Different', 'from', 'aforementioned', 'methods,', 'our', 'MoKGE', 'can', 'seek', 'diverse', 'reasoning', 'on', 'KG', 'to', 'encourage', 'various', 'generation', 'outputs', 'without', 'any', 'additional', 'conditions.']",29,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
a2eea626-2daa-4f77-a858-4a3821f38abf,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['WordNet: an electronic lexical database'],['1998'],['Christiane Fellbaum'],single,"['A', 'semantic', 'analysis', 'of', 'the', 'selected', 'keywords', 'was', 'done', 'using', 'WordNet', '(3.1).', 'We', 'used', 'semantic', 'relations', 'such', 'as', 'hypernymy,', 'troponymy', 'and', 'entailment', '<ref type=""single"">(Fellbaum, 1998)</ref>', 'to', 'find', 'the', 'implications', 'that', 'the', 'keywords', 'may', 'have,', 'as', 'far', 'as', 'their', 'communicative', 'goals', 'are', 'concerned.']",22,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
a32cd508-6bda-4091-b597-4adfd02fe806,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Opensubtitles2016: Extracting large parallel corpora from movie and tv subtitles'],['2016'],['Pierre Lison;Jörg Tiedemann ; Khalid;Thierry Choukri;Sara Declerck;Marko Goggi;Bente Grobelnik;Joseph Maegaard;unk Mariani'],single,"['We', 'use', 'pretrained', 'BERT', '2', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'for', 'the', 'mention', 'and', 'context', 'encoder.', 'This', 'BERT-based', 'encoder', 'accepts', 'as', 'input', 'a', 'token', 'sequence', 'formatted', 'asx', '=', '[CLS]', 'm', '[SEP]', 's', '[SEP],where', 'the', 'mention', 'm', 'and', 'context', 's', 'are', 'chunked', 'into', 'WordPiece', 'tokens', '<ref type=""single"">(Wu et al., 2016).</ref>', 'We', 'encode', 'the', 'whole', 'sequence', 'using', 'BERT', 'and', 'use', 'the', 'hidden', 'vector', 'at', 'the', '[CLS]', 'token', 'as', 'the', 'mention', 'and', 'context', 'representation:h', '[CLS]', '=', 'BERTENCODER(x).Type', 'Embeddings', 'This', 'output', 'layer', 'is', 'a', 'single', 'linear', 'layer', 'whose', 'parameter', 'matrix', 'can', 'be', 'viewed', 'as', 'a', 'matrix', 'of', 'type', 'embeddings', 'E', '∈', 'R', '|T', '|×d,', 'where', 'd', 'is', 'the', 'dimension', 'of', 'the', 'mention', 'and', 'context', 'representation', 'h', '<ref type=""single"">[CLS].</ref>', 'We', 'obtain', 'the', 'output', 'probabilities', 't', 'by', 'multiplying', 'E', 'by', 'h', '[CLS],', 'followed', 'by', 'an', 'element-wise', 'sigmoid', 'function:t', '=', 'σ', '(E', 'h', '[CLS]).', '3', 'Similar', 'to', 'previous', 'work', '<ref type=""group"">(Choi et al., 2018, Onoe and Durrett, 2019),</ref>', 'we', 'assume', 'independence', 'between', 'all', 'entity', 'type', 'in', 'T.']",40,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a384298e-b13a-442a-99b9-72f539f757b5,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Hate speech and covert discrimination on social media: Monitoring the facebook pages of extreme-right political parties in spain'],['2016'],['Anat Ben;-David unk;Ariadna Matamoros Fernández'],single,"['Throughout', 'the', 'paper,', 'user', 'refers', 'to', 'the', 'user', 'of', 'an', 'online', 'platform', 'who', 'may', 'have', 'posted', 'a', 'comment', 'that', 'is', 'to', 'be', 'classified', 'as', 'abusive', 'or', 'not.', 'The', 'community', 'of', 'this', 'user', 'comprises', 'other', 'users', 'and', 'contents', 'that', 'they', 'interact', 'with', 'on', 'the', 'online', 'plat-form.', 'In', 'other', 'words,', 'community', 'refers', 'to', 'the', 'neighborhood', 'of', 'the', 'user', 'in', 'the', 'social', 'graph', 'of', 'the', 'platform.', 'Conversations', 'online', 'are', 'inherently', 'contextual.', 'Consequently,', 'abuse', 'on', 'online', 'platforms', 'can', 'only', 'be', 'effectively', 'interpreted', 'within', 'a', 'larger', 'context', '<ref type=""single"">(Gao and Huang, 2017)</ref>', 'rather', 'than', 'in', 'isolation.', 'This', 'is', 'especially', 'true', 'for', 'implicit', 'or', 'generalized', 'abuse,', 'which', 'are', 'harder', 'to', 'interpret', 'than', 'explicit', 'abuse', 'for', 'humans', 'and', 'machines', 'alike.', 'Information', 'of', 'the', 'user', 'who', 'posted', 'the', 'comment,', 'or', 'of', 'the', 'surrounding', 'community', 'including', 'the', 'targets', 'of', 'the', 'comment,', 'offers', 'insights', 'into', 'several', 'aspects', 'of', 'the', 'context', 'that', 'are', 'otherwise', 'not', 'accessible', 'through', 'the', 'linguistic', 'content', 'of', 'the', 'comment', 'alone.', 'Here,', 'information', 'may', 'refer', 'to', 'demographic', 'traits', 'like', 'age', 'or', 'gender,', 'knowledge', 'about', 'linguistic', 'behavior,', 'location', 'details,', 'etc.', 'Below', 'we', 'categorize', 'and', 'discuss', 'the', 'aspects', 'of', 'the', 'context', 'relevant', 'to', 'abusive', 'language', 'detection.', 'Sociolinguistic', 'norms.', 'Sociolinguistics', 'studies', 'the', 'effects', 'of', 'society', 'on', 'language', 'and', 'its', 'usage.', 'Researchers', 'in', 'the', 'past', 'have', 'explored', 'the', 'links', 'between', 'the', 'structures', 'and', 'norms', 'of', 'real-world', 'communities', 'and', 'the', 'linguistic', 'practices', 'of', 'people', ""(D'Arcy"", 'and', '<ref type=""single"">Young, 2012).</ref>', 'As', 'in', 'the', 'physical', 'world,', 'individuals', 'and', 'communities', 'on', 'online', 'platforms', 'also', 'abide', 'by', 'certain', 'norms,', 'which', 'may', 'be', 'guided', 'by', 'their', 'cultural', 'backgrounds', 'and/or', 'are', 'based', 'on', 'the', 'standards', 'laid', 'down', 'by', 'the', 'platforms', 'themselves.', 'These', 'norms', 'and', 'standards', 'reflect', 'expectations', 'of', 'respectful', 'behavior,', 'local', 'customs', 'and', 'language', 'patterns', 'within', 'a', 'region,', 'etc.', '<ref type=""single"">(Ben-David and Fernández, 2016).</ref>', 'Consequently,', 'the', 'decision', 'of', 'what', 'is', 'considered', 'abusive', 'must', 'be', 'made', 'taking', 'into', 'account', 'the', 'sociolinguistic', 'norms.', 'User', 'and', 'community', 'information,', 'when', 'leveraged', 'alongside', 'linguistic', 'features,', 'helps', 'capture', 'the', 'relevant', 'sociolinguistic', 'norms', 'in', 'a', 'myriad', 'of', 'ways.', 'For', 'example,', 'a', 'comment', 'may', 'contain', 'the', 'n-word,', 'but', 'interpretation', 'of', 'its', 'use', 'and', 'or', 'the', 'intent', 'is', 'greatly', 'facilitated', 'by', 'the', 'knowledge', 'of', 'the', 'ethnicity', 'of', 'the', 'user', 'who', 'wrote', 'the', 'comment', 'and/or', 'the', 'ethnicity', 'of', 'the', 'target', 'user', 'or', 'community.']",274,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a3eeebc6-1689-461e-bc32-d5a56cfb7ab4,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,"['Language models are unsupervised multitask learners', 'unknown']","['2019', 'unknown']","['Alec Radford;Jeffrey Wu;Rewon Child;David Luan;Dario Amodei;Ilya Sutskever', 'unknown']",group,"['Word', 'co-occurrence', 'probabilities', 'are', 'hard', 'to', 'estimate', 'accurately', 'from', 'text', 'data', 'because', 'empirical', 'counts', 'of', 'a', 'particular', 'pair', 'of', 'words', 'in', 'a', 'particular', 'relation', 'are', 'often', 'sparse.', 'This', 'limitation', 'makes', 'it', 'hard', 'to', 'evaluate', 'cognitive', 'theories', 'that', 'operate', 'on', 'co-occurrence', 'probabilities.', 'Although', 'high-performance', 'pretrained', 'language', 'models', 'now', 'exist', '<ref type=""group"">(Radford et al., 2019, Devlin et al., 2019, etc.),</ref>', 'the', 'probabilities', 'of', 'interest', 'often', 'cannot', 'be', 'read', 'off', 'of', 'these', 'models', 'directly,', 'because', 'w', 'and', 'c', 'might', 'be', 'defined', 'by', 'relations', 'that', 'cannot', 'be', 'straightforwardly', 'detected', 'in', 'terms', 'of', 'linear', 'word', 'order', 'or', 'templates.', 'For', 'example,', 'suppose', 'we', 'are', 'interested', 'in', 'the', 'distribution', 'of', 'adjectives', 'attributively', 'modifying', 'a', 'noun', 'in', 'English.', 'It', 'would', 'not', 'do', 'to', 'ask', 'a', 'language', 'model', 'for', 'the', 'distribution', 'of', 'words', 'immediately', 'preceding', 'a', 'noun,', 'because', 'some', 'of', 'these', 'words', 'will', 'not', 'be', 'attributive', 'adjectives.']",48,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a3f66cf2-ec24-4eb9-8d1a-2d63b9b944b4,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['A stochastic parts program and noun phrase parser for unrestricted text'],['1988'],['K Church'],single,"['Several', 'robust', 'parsing', 'systems', 'exploit', 'the', 'comparative', 'success', 'of', 'part-of-speech', '(PoS)', 'taggers,', 'such', 'as', 'Fidditch', '<ref type=""single"">(Hindle, 1989)</ref>', 'or', '<ref type=""single"">MITFP (de • Marcken, 1990),</ref>', 'by', 'reducing', 'the', 'input', 'to', 'a', 'determinate', 'sequence', 'of', 'extended', 'PoS', 'labels', 'of', 'the', 'type', 'which', 'can', 'be', 'practically', 'disambiguated', 'in', 'context', 'using', 'a', '(H)MM', 'PoS', 'tagger', '(e.g.', '<ref type=""single"">Church, 1988).</ref>', 'Such', 'approaches,', 'by', 'definition,', 'cannot', 'exploit', 'subcategorisation,', 'and', 'probably', 'achieve', 'some', 'of', 'their', 'robustness', 'as', 'a', 'result.', 'However,', 'such', 'parsers', 'typically', 'also', 'employ', 'heuristic', 'rules,', 'such', 'as', ""'low'"", 'attachment', 'of', 'PPs', 'to', 'produce', 'unique', ""'canonical'"", 'analyses.', 'This', 'latter', 'step', 'complicates', 'the', 'recovery', 'of', 'predicate', 'argument', 'structure', 'and', 'does', 'not', 'integrate', 'with', 'a', 'probabilistic', 'approach', 'to', 'parsing.']",46,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
a427ae8f-78c4-4b37-a4b0-9942f4c0b228,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['A hierarchical phrase-based model for statistical machine translation'],['2005'],['D Chiang'],single,"['The', 'following', 'are', 'examples', 'of', 'the', 'hierarchical', 'CFG', 'rules', 'extracted', 'from', 'the', 'Chinese-English', 'sentence', 'pair', '(Aozhou', 'shi', 'yu', 'Beihan', 'you', 'bangjiao', 'de', 'shaoshu', 'guojia', 'zhiyi,', 'Australia', 'is', 'one', 'of', 'the', 'few', 'countries', 'that', 'have', 'diplomatic', 'relations', 'with', 'North', 'Korea)', '<ref type=""single"">[3]:</ref>']",39,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
a4c231de-60c5-4e77-bd52-5059e67452e4,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['SemEval-2019 task 6: Identifying and categorizing offensive language in social media (OffensEval)'],['2019'],['Marcos Zampieri;Shervin Malmasi;Preslav Nakov;Sara Rosenthal;Noura Farra;Ritesh Kumar'],single,"['Toxic', 'comments,', 'posts,', 'and', 'other', 'types', 'of', 'content', 'became', 'more', 'common', 'in', 'social', 'media', 'nowadays.', 'They', 'contain', 'forms', 'of', 'non-acceptable', 'language', '(profanity),', 'which', 'may', 'be', 'concealed', 'or', 'explicit,', 'including', 'insults', 'and', 'threats', 'directed', 'to', 'a', 'group', 'or', 'individual', '<ref type=""single"">(Zampieri et al., 2019).</ref>', 'These', 'comments', 'spread', 'rapidly', 'on', 'the', 'internet,', 'especially', 'on', 'social', 'networks', 'where', 'they', 'find', 'acceptance,', 'and', 'may', 'culminate', 'in', 'several', 'threats', 'to', 'individuals,', 'becoming', 'a', 'serious', 'concern', 'for', 'government', 'organizations,', 'online', 'communities,', 'and', 'social', 'media', 'platforms.']",38,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
a6309530-f8c3-4577-befa-8ea56b8c9530,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['A method for realizing Transfer-Driven Machine Translation'],['1979'],['S Fahlman ; Fahlman;unk Ford'],single,"['Upon', 'processing', 'the', 'first', 'word', ""'John'"", 'in', 'the', 'sentence', 's1,', 'C-JOHN', 'is', 'activated', 'so', 'that', 'C-JOHN', 'gets', 'an', 'A-MARKER', 'and', 'a', 'CI', 'JOHN#l', 'is', 'created', 'under', 'C-JOHN.', 'At', 'this', 'point,', 'the', 'corresponding', 'Japanese', 'lexical', 'item', 'is', 'searched', 'for,', 'and', 'JON', 'is', 'found.', 'A', 'G-MARKER', 'is', 'created', 'on', 'JON.', 'The', 'A-MARKER', 'and', 'G-MARKER', 'propagate', 'up', 'through', 'ISA', 'links', '(activating', 'C-MALE-PERSON', 'and', 'C-PERSON', 'in', 'sequence)', 'and,', 'then,', 'ROLE', 'links.', 'When', 'an', 'A-MARKER', 'collides', 'with', 'a', 'P-MARKER', 'at', 'a', 'CSE,', 'the', 'associated', 'case', 'role', 'is', 'bound', 'with', 'the', 'source', 'of', 'the', 'A-MARKER', 'and', 'the', 'prediction', 'is', 'updated', 'by', 'passing', 'P-MARKER', 'to', 'the', 'next', 'CSE.', 'This', 'P-MARKER', 'is', 'passed', 'down', 'ISA', 'links.', 'In', 'this', 'memory', 'network,', 'the', 'ACTOR', 'roles', 'of', 'concept', 'sequences', 'WANT-CIRCUM-E', 'is', 'bound', 'to', 'JOHN#', '1', 'pointed', 'by', 'the', 'A-MARKER.', 'This', 'is', 'made', 'possible', 'in', 'the', 'SNAP', 'architecture', 'which', 'allows', 'markers', 'to', 'carry', 'address', 'as', 'well', 'as', 'bit-vectors', 'and', 'values,', 'where', 'many', 'other', 'marker-passing', 'machines', 'such', 'as', 'NETL', '<ref type=""single"">[Fahlman, 1979]</ref>', 'and', 'IXM2', '<ref type=""single"">[Higuchi et al., 1991]</ref>', 'only', 'allow', 'bit-vectors', 'to', 'be', 'passed', 'around,', 'Also,', 'G-MARKERs', 'are', 'placed', 'on', 'the', 'ACTOR', 'role', 'CSE', 'of', 'WANT-CIRCUM-J.', 'The', 'G-MARKER', 'points', 'to', 'the', 'Japanese', 'lexical', 'item', ""'jon'.""]",156,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a63668fe-aa33-4170-8252-975c9764dab2,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['Word-based partial annotation for efficient corpus construction'],['2010'],['N Graham;S Mori'],single,"['As', 'we', 'discussed', 'in', 'Section', '4.1.2,', 'we', 'computed', 'the', 'annotation', 'structure', 'accuracy', '(ASA),', 'and', 'it', 'turns', 'out', 'that', 'its', 'range', 'was', 'from', '98.9', '%', 'to', '100.0', '%.', 'This', 'means', 'that', 'the', 'proposed', 'joint', 'model', 'can', 'consistently', 'predict', 'transcriptions', 'and', 'the', 'linguistic', 'annotations', 'in', 'the', 'correct', 'order', 'almost', 'perfectly.', 'We', 'found', 'that', 'almost', 'all', 'errors', 'of', 'the', 'transition', 'occurred', 'in', 'the', 'last', 'word,', 'which', 'might', 'be', 'caused', 'by', 'beam', 'search', 'errors.', 'Pipeline', 'is', 'ASR', 'predicting', 'transcriptions', 'followed', 'by', 'the', 'NLP-based', 'linguistic', 'annotation', 'system', '<ref type=""single"">(Graham and Mori, 2010).</ref>', 'Proposed', 'predicts', 'graphemes', 'and', 'phonemes', 'followed', 'by', 'POS', 'tags', 'from', 'speech.', 'Note', 'that', 'we', 'used', 'only', 'the', 'sentences', 'whose', 'hypothesized', 'ASR', 'transcript', 'is', 'predicted', 'correctly', 'for', 'evaluation.']",82,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a636ce40-a2b3-4eb3-8045-1abe6d25572f,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['unknown'],['unknown'],['unknown'],single,"['This', 'parsing', 'algorithm', 'is', 'similar', 'to', 'the', 'shift-reduce', 'parser', 'except', 'that', 'our', 'algorithms', 'handles', 'ambiguities,', 'parallel', 'processing', 'of', 'each', 'hypothesis,', 'and', 'top-down', 'predictions', 'of', 'possible', 'next', 'input', 'symbol.', 'The', 'generation', 'algorithm', 'implemented', 'on', 'SNAP', 'is', 'a', 'version', 'of', 'the', 'lexically', 'guided', 'bottom-up', 'algorithm', 'which', 'is', 'described', 'in', '<ref type=""single"">[Kitano, 1990b].</ref>']",47,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]"
a669146d-8b27-41c5-970f-f6f050b39655,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Zero-shot stance detection: A dataset and model using generalized topic representations'],['2020'],['Emily Allaway;Kathleen Mckeown'],single,"['Lastly,', 'we', 'test', 'two', 'recent', 'models', 'from', 'stance', 'detection', 'and', 'dis/agreement', 'classification.', 'TGA', 'Net', '<ref type=""single"">(Allaway and McKeown, 2020)</ref>', 'takes', 'a', 'statement-topic', 'pair', 'and', 'predicts', 'the', ""statement's"", 'stance.', 'It', 'encodes', 'the', 'input', 'using', 'BERT', 'and', 'weighs', 'topic', 'tokens', 'based', 'on', 'similarity', 'to', 'other', 'topics.', 'In', 'our', 'task,', 'claims', 'serve', 'as', ""''topics''."", 'We', 'use', 'the', 'published', 'implementation,', 'exploring', '{50,', '100,', '150,', '200}', 'for', 'the', 'number', 'of', 'clusters', 'and', 'increasing', 'the', 'max', 'input', 'size', 'to', 'the', 'BERT', 'input', 'size.', 'Hybrid', 'Net', '<ref type=""single"">(Chen et al., 2018)</ref>', 'takes', 'a', 'quote-response', 'pair', 'and', 'predicts', 'whether', 'the', 'response', 'agrees', 'or', 'disagrees', 'with', 'the', 'quote.', 'It', 'encodes', 'the', 'input', 'using', 'BiLSTM', 'and', 'uses', 'selfand', 'cross-attention', 'between', 'tokens.', 'In', 'our', 'task,', 'claims', 'and', 'statements', 'serve', 'as', ""''quotes''"", 'and', ""''responses'',"", 'respectively.']",14,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a67fff38-9064-4524-b890-47a119dd7b84,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Polynomial parsing of extensions of context-free gram mars'],['1991'],['K Vijay-Shanker;D Weir'],single,"['We', 'have', 'chosen', 'the', 'CYK-like', 'algorithm', 'for', 'LIG', 'described', 'in', '<ref type=""single"">(16]</ref>', 'as', 'our', 'starting', 'point.', 'Due', 'to', 'the', 'intrinsic', 'limitations', 'of', 'this', 'pure', 'bottom-up', 'algorithm,', 'the', 'grammars', 'it', 'can', 'deal', 'with', 'are', 'restricted', 'to', 'those', 'having', 'two', 'elements,', 'or', 'one', 'element', 'which', 'must', 'be', 'a', 'terminal,', 'in', 'the', 'right-hand', 'side', 'of', 'each', 'production.', 'This', 'restriction', 'could', 'be', 'considered', 'as', 'the', 'transposition', 'of', 'the', 'Chomsky', 'normal', 'form', 'to', 'linear', 'indexed', 'grammars.']",10,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a6ce77b5-960f-4dcb-a3d9-1990df5b0f1f,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,"['SemEval-2018 task 1: Affect in tweets', 'Annotation, modelling and analysis of fine-grained emotions on a stance and sentiment detection corpus', 'Emonet: Fine-grained emotion detection with gated recurrent neural networks']","['2018', '2017', '2017']","['Saif Mohammad;Felipe Bravo-Marquez;Mohammad Salameh;Svetlana Kiritchenko', 'Hendrik Schuff;Jeremy Barnes;Julian Mohme;Sebastian Padó;Roman Klinger', 'Muhammad Abdul;-Mageed unk;Lyle Ungar']",group,"['Datasets', 'created', 'for', 'sentiment', 'analysis', 'have', 'been', 'available', 'for', 'researchers', 'since', 'at', 'least', 'the', 'early', '2000s', '<ref type=""single"">(Mäntylä et al., 2018).</ref>', 'Such', 'datasets', 'generally', 'use', 'a', 'binary', 'or', 'ternary', 'annotation', 'scheme', '(positive,', 'negative', '+', 'neutral)', '(e.g.', '<ref type=""single"">Blitzer et al. (2007))</ref>', 'and', 'have', 'traditionally', 'been', 'based', 'on', 'review', 'data', 'such', 'as,', 'e.g.', 'Amazon', 'product', 'reviews,', 'or', 'movie', 'reviews', '<ref type=""group"">(Blitzer et al., 2007, Maas et al., 2011, Turney, 2002).</ref>', 'Many,', 'if', 'not', 'most,', 'emotion', 'datasets', 'on', 'the', 'other', 'hand', 'use', 'Twitter', 'as', 'a', 'source', 'and', 'individual', 'tweets', 'as', 'level', 'of', 'granularity', '<ref type=""group"">(Schuff et al., 2017, Abdul-Mageed and Ungar, 2017, Mohammad et al., 2018).</ref>', 'In', 'the', 'case', 'of', 'emotion', 'datasets,', 'the', 'emotion', 'taxonomies', 'used', 'are', 'often', 'based', 'on', '<ref type=""single"">Ekman (1971)</ref>', 'and', '<ref type=""single"">Plutchik (1980)</ref>', '(which', 'is', 'partially', 'based', 'on', 'Ekman).']",73,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a702ccbd-ab14-4496-97f5-0b7c6baec6eb,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,"['MULTEXT-East Version 3: Multilingual Morphosyntactic Specifications, Lexicons and Corpora']",['2004'],['Erjavec Tomaž'],single,"['An', 'already', 'trained', 'and', 'tested', 'POS', 'tagger', '<ref type=""single"">(Erjavec, 2006)</ref>', 'was', 'available', 'for', 'Slovenian', 'language.', 'Words', 'were', 'tagged', 'using', 'full', 'MSD', 'descriptions', '<ref type=""single"">(Erjavec, 2004)</ref>', 'and', 'grouped', 'into', 'classes', 'with', 'same', 'descriptions', '(words', 'that', 'had', 'the', 'same', 'POS', 'tag', 'were', 'grouped', 'together).', 'This', 'process', 'produced', '312', 'classes', 'in', 'Slovene', 'and', '274', 'classes', 'in', 'Serbian', 'language,', 'see', 'Table', '1', 'for', 'details.', 'A', 'linguist', 'manually', 'tagged', 'the', 'classes', 'to', 'paradigms.']",20,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a74f1ba2-9366-4973-a777-735b858c361b,Themes in the work of Margaret Masterman,1988,Yorick Wilks,['unknown'],['unknown'],['unknown'],single,"['The', 'oddest', 'feature', 'of', ""MMB's"", 'breath-group', 'work,', 'stretching', 'as', 'it', 'did', 'over', 'many', 'years', 'was', 'that', 'it', 'referred', 'constantly', 'to', 'breathing,', 'but', 'nothing', 'ever', 'rested', 'on', 'that:', 'partitions', 'were', 'always', 'inserted', 'into', 'text', 'intuitively', 'in', 'a', 'way', 'that,', 'to', 'me', 'at', 'least,', 'corresponded', 'more', 'naturally', 'to', 'the', 'criteria', 'just', 'listed', '<ref type=""single"">(keywords, punctuation, etc.).</ref>', 'Finally,', 'of', 'course,', 'it', 'would', 'be', 'overbold', 'to', 'assert', 'that', 'there', 'will', 'never', 'be', 'applications', 'of', 'Greek', 'rhetorical', 'figures', 'to', 'the', 'computer', 'understanding', 'of', 'natural', 'language,', 'but', 'none', 'have', 'as', 'yet', 'emerged,', 'except', 'their', 'explicit', 'and', 'obvious', 'use', 'as', 'forms', 'of', 'expression.']",50,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a7cd3d83-4f78-4aaf-ac60-18cc1754f418,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['COMET: A neural framework for MT evaluation'],['2020'],['Ricardo Rei;Craig Stewart;Ana Farinha;Alon Lavie'],single,"['More', 'recently,', '<ref type=""single"">Kocmi et al. (2021)</ref>', 'run', 'a', 'large-scale', 'comparison', 'of', 'MT', 'metrics,', 'including', 'BERTScore', 'using', 'a', 'large', 'dataset', 'of', 'translations', 'with', 'human', 'judgments,', 'they', 'find', 'that', ""BERTScore's"", 'performance', 'is', 'middle-of-the-road,', 'though', 'better', 'than', 'BLEU,', 'and', 'recommend', 'COMET', '<ref type=""single"">(Rei et al., 2020)</ref>', 'for', 'general', 'use.']",35,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 1, 1, 2, 2, 2]"
a7dc450a-d664-4fef-aa45-2e59aa458243,Themes in the work of Margaret Masterman,1988,Yorick Wilks,['Aspects of the theory of syntax'],['1965'],['N Chomsky'],single,"['Although', 'not', 'a', 'formalist', 'herself,', 'and', 'considered', 'an', 'anti-formalist', 'by', 'many,', 'MMB', 'nevertheless', 'believed', 'passionately', 'in', 'the', 'applicability', 'of', 'mathematical', 'techniques', 'to', 'natural', 'language,', 'without', 'them,', 'she', 'believed,', 'there', 'would', 'be', 'nothing', 'worthy', 'of', 'the', 'name', 'of', 'theory.', 'Her', 'opposition', 'was', 'to', 'the', 'assumption', 'that', 'formal', 'logic,', 'in', 'particular,', 'applied', 'directly', 'to', 'natural', 'language,', 'and', 'she', 'would', 'not', 'concede', 'much', 'distinction', 'between', 'that', 'and', 'the', 'methods', 'of', '<ref type=""single"">Chomsky (1965),</ref>', 'a', 'position', 'that', 'has', 'some', 'historical', 'justification.']",67,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2]"
a8bc4df2-cc95-4b30-9042-ff2348d32736,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['End-to-End Named Entity Recognition from English Speech'],['2020'],['H Yadav;S Ghosh;Y Yu;R Shah'],single,"['To', 'obtain', 's', 'i,', 'we', 'use', 'existing', 'annotation', 'tools', 'or', 'manual', 'annotations', 'to', 'jointly', 'align', 'the', 'training', 'sets', 'of', 'the', 'K', 'output', 'sequence', 'types.', 'These', 'segments', 'are', 'used', 'as', 'training', 'targets', 'in', 'an', 'auto-regressive', 'prediction', 'task.', 'In', 'this', 'way,', 'our', 'model', 'implicitly', 'learns', 'to', 'simultaneously', 'predict', 'and', 'align', 'K', 'output', 'sequences', 'from', 'an', 'input', 'X.', 'We', 'discuss', 'further', 'details', 'of', 'the', 'data', 'preparation', 'in', 'Section', '3.2.', 'Letting', 'y', '*', 'i', 'denote', 'elements', 'of', 'the', 'collapsed', 'single-sequence', 'representation', 's', '1', ',...,', 's', 'S,', 'the', 'joint', 'log-likelihood', '(Eq.', '(3))', 'can', 'be', 'written', 'asL', '=', 'log', 'p(y', '1', ',...,', 'y', 'K', '|X)', '=', 'M', '*', 'm=1', 'log', 'p(y', '*', 'm', '|y', '*', '1', ',...,', 'y', '*', 'm−1,', 'X).', '(9)Note', 'that', 'this', 'form', 'is', 'almost', 'equivalent', 'to', 'the', 'single', 'sequence', 'objective', 'function', 'in', 'Eq.', '(1)', 'except', 'for', 'the', 'variable', 'y', '*', 'm', 'takes', 'values', 'from', 'the', 'union', 'of', 'the', 'K', 'symbol', 'sets', 'that', 'represent', 'the', 'K', 'output', 'sequences', 'and', 'the', 'length', 'of', 'this', 'sequenceM', '*', '=', 'K', 'k=1', 'M', 'k,', 'is', 'the', 'sum', 'of', 'the', 'lengths', 'of', 'the', 'K', 'output', 'sequences.This', 'framework', 'has', 'various', 'benefits', 'compared', 'with', 'the', 'existing', 'frameworks', 'described', 'in', 'Section', '2.', 'Similar', 'to', 'the', 'O2O', 'model', 'trained', 'with', 'the', 'conditional', 'chain', 'mapping', 'in', 'Section', '2.2.2,', 'this', 'framework', 'does', 'not', 'assume', 'the', 'conditional', 'independence', 'between', 'output', 'labels', 'and', 'has', 'the', 'flexibility', 'to', 'model', 'the', 'dependency', 'between', 'words/morphemes', 'and', 'linguistic', 'annotations.', 'Related', 'works', 'are', 'using', 'the', 'O2O', 'model,', 'e.g.,', '<ref type=""single"">(Yadav et al., 2020),</ref>', 'but', 'they', 'are', 'based', 'on', 'CTC', 'and', 'do', 'not', 'consider', 'such', 'an', 'explicit', 'output', 'dependency.', 'Also,', 'the', 'proposed', 'method', 'using', 'Transformer', 'can', 'preserve', 'a', 'relationship', 'between', 'the', 'word/morpheme', 'and', 'the', 'corresponding', 'linguistic', 'annotations', 'across', 'the', 'sequence', 'based', 'on', 'the', 'aligned', 'representation', 's', 'i', 'in', 'Eq.', '(8).', 'Finally,', 'this', 'framework', 'is', 'equivalent', 'to', 'the', 'original', 'single-sequence', 'objective', 'function,', 'and', 'we', 'can', 'use', 'an', 'existing', 'strong', 'sequence-to-sequence', 'model', '(transformer', 'in', 'this', 'paper)', 'without', 'any', 'modifications', 'of', 'the', 'algorithm.', 'The', 'only', 'process', 'is', 'to', 'prepare', 'the', 'collapsed', 'single', 'sequence', 'composed', 'of', 's', 'i,', 'which', 'is', 'discussed', 'in', 'the', 'next', 'section.']",236,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
a936b3d4-87d1-4b88-ab33-f79babf669d9,SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering,2020,Aishwarya Ashok;Ganapathy Natarajan;Ramez Elmasri;Laurel Smith-Stvan,['Improving the sentiment analysis process of spanish tweets with bm25'],['2016'],['Juan Sixto;Aitor Almeida;Diego López-De Ipiña'],single,"['At', 'the', 'sentence', 'level,', 'we', 'pick', 'the', 'top', '1', 'sentence,', 'using', 'Okapi', 'BM25,', 'as', 'the', 'gold', 'standard.', 'To', 'retrieve', 'the', 'top', '1', 'sentence', 'using', 'Okapi', 'BM25,', 'we', 'used', 'the', 'question', 'as', 'the', 'query', 'and', 'the', 'product', 'reviews', 'as', 'the', 'documents.', 'Okapi', 'BM25', 'is', 'still', 'widely', 'used', 'as', 'a', 'benchmark', 'in', 'similar', 'tasks', '<ref type=""single"">(Fan et al., 2019</ref>', ').', 'An', 'advantage', 'of', 'using', 'the', 'Okapi', 'BM25', 'is', 'that', 'it', 'provides', 'us', 'with', 'a', 'tf-idf', 'based', 'benchmark', '<ref type=""single"">(Sixto et al., 2016).</ref>', 'Word', 'vectors', 'aim', 'to', 'reduce', 'problem', 'complexity', 'by', 'moving', 'away', 'from', 'tf-idf', 'methods', 'which', 'requires', 'us', 'to', 'one-hot-encode', 'the', 'entire', 'vocabulary.']",71,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
a9a9aaed-25ee-4de8-8f8b-2b5080efcb81,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['A general psychoevolutionary theory of emotion'],['1980'],['Robert Plutchik'],single,"['Some', 'emotions', 'are', 'also', 'more', 'closely', 'correlated.', 'In', ""Plutchik's"", 'wheel', '<ref type=""single"">(Plutchik, 1980)</ref>', 'related', 'emotions', 'are', 'placed', 'on', 'the', 'same', 'dyad', 'so', 'that', 'for', 'example', 'for', 'anger', 'as', 'a', 'core', 'emotion,', 'there', 'is', 'also', 'rage', 'that', 'is', 'more', 'intense,', 'but', 'highly', 'correlated', 'with', 'anger,', 'and', 'annoyance', 'which', 'is', 'less', 'intense,', 'but', 'equally', 'correlated.', 'In', 'this', 'way', 'it', 'is', 'also', 'possible', 'to', 'map', 'more', 'distinct', 'categories', 'of', 'emotions', 'onto', 'larger', 'wholes,', 'in', 'this', 'case', 'rage', 'and', 'annoyance', 'could', 'be', 'mapped', 'to', 'anger,', 'or', 'even', 'more', 'coarsely', 'to', 'negative.', 'This', 'approach', 'has', 'been', 'employed', 'by', 'for', 'example', '<ref type=""single"">Abdul-Mageed and Ungar (2017).</ref>']",10,"[3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
aa121060-ee85-46db-8ebb-700b2b3caee0,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['2', 'As', 'pointed', 'out', 'by', 'a', 'reviewer,', 'an', 'even', 'better', 'factorization', 'of', 'fragments', 'could', 'potentially', 'be', 'achieved', 'by', 'indexing', 'not', 'with', 'respect', 'to', 'linear', 'position', 'but', 'with', 'respect', 'to', 'the', 'syntactic', 'head', 'word.', 'This', 'would', 'require', 'introducing', 'a', 'dependency', 'parsing', 'component.', 'We', 'leave', 'this', 'for', 'future', 'work.', 'Sequence', 'Labeling', 'Transformer', 'Model', 'Our', 'model', 'is', 'schematically', 'depicted', 'in', 'Figure', '4.', 'It', 'takes', 'an', 'input', 'sequence', 'of', 'tokens', 'X', '=', 'w', '1...', 'w', 'n', 'and', 'produces', 'aligned', 'output', 'sequences', 'Y', 's,', 'Y', 'f,', 'Y', 'i,', 'which', 'are', 'word', 'senses,', 'fragments,', 'and', 'integration', 'labels.', 'Our', 'model', 'simply', 'consists', 'of', 'a', 'pre-trained', 'BERT', 'model', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'and', 'three', 'linear', 'classifiers.', 'Each', 'classifier', 'can', 'be', 'seen', 'as', 'a', 'sub-system', 'of', 'the', 'semantic', 'parser', 'that', 'produces', 'one', 'of', 'the', 'three', 'labels', '(word', 'sense,', 'fragment,', 'and', 'integration', 'label).']",100,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
aa4c1a86-446e-4a89-8a2a-20673c116cb2,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Semeval-2007 task 14: Affective text'],['2007'],['Carlo Strapparava;Rada Mihalcea'],single,"['Bostan', 'and', '<ref type=""single"">Klinger (2018)</ref>', 'analyze', '14', 'existing', 'emotion', 'datasets', 'of', 'which', 'only', 'two', 'are', 'multilabel.', 'These', 'are', 'AffectiveText', '<ref type=""single"">(Strapparava and Mihalcea, 2007)</ref>', 'and', 'SSEC', '<ref type=""single"">(Schuff et al., 2017).</ref>', 'Nearly', 'all', 'of', 'these', 'datasets', 'use', 'an', 'annotation', 'scheme', 'based', 'on', 'Ekman', '<ref type=""group"">(Ekman, 1971, Ekman, 1992)</ref>', 'with', 'many', 'adding', 'a', 'few', 'labels', 'often', 'following', ""Plutchik's"", 'theory', 'of', 'emotions', '<ref type=""single"">(Plutchik, 1980).</ref>', 'A', 'typical', 'emotion', 'dataset', 'consists', 'of', '6-8', 'categories.', 'The', 'exception', 'Bostan', 'and', '<ref type=""single"">Klinger (2018)</ref>', 'mention', 'is', 'CrowdFlower', '2', 'with', '14', 'categories,', 'and', 'those', 'not', 'mentioned', 'in', 'Bostan', 'et', 'al.', 'are', 'e.g.', 'the', 'SemEval', '2018', 'task', '1', 'subtask', 'c', 'dataset', '<ref type=""single"">(Mohammad et al., 2018)</ref>', 'with', '11', 'categories,', 'EmoNet', 'with', '24', '<ref type=""single"">(Abdul-Mageed and Ungar, 2017),</ref>', 'and', 'the', 'GoEmotions', 'dataset', '<ref type=""single"">(Demszky et al., 2020)</ref>', 'with', '27', 'categories.']",17,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
aa6c5b3b-6120-40ed-b1ad-6057a294745a,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,"['CorefQA: Coreference resolution as query-based span prediction', 'A Simple Transfer Learning Baseline for Ellipsis Resolution']","['2020', '2019']","['Wei Wu;Fei Wang;Arianna Yuan;Fei Wu;Jiwei Li', 'Rahul Aralikatte;Matthew Lamm;Daniel Hardt;Anders Søgaard']",group,"['The', 'existing', 'approach', 'to', 'convert', 'coreference', 'annotations', 'into', '(question,', 'context,', 'answer)', 'tuples,', 'which', 'is', 'used', 'to', 'improve', 'coreference', 'resolution', 'performance', '<ref type=""group"">(Wu et al., 2020b, Aralikatte et al., 2019),</ref>', 'is', 'to', 'use', 'the', 'sentence', 'of', 'the', 'anaphor', 'as', 'a', 'declarative', 'query,', 'and', 'its', 'closest', 'antecedent', 'as', 'the', 'answer.', 'The', 'format', 'of', 'these', 'queries', 'is', 'not', 'compatible', 'with', 'questions', 'in', 'MRC', 'datasets,', 'and', 'therefore,', 'the', 'impact', 'of', 'this', 'data', 'on', 'MRC', 'models', 'may', 'be', 'limited.', 'In', 'this', 'work,', 'we', 'instead', 'generate', 'questions', 'from', 'those', 'declarative', 'queries', 'using', 'an', 'automatic', 'question', 'generation', 'model.', 'We', 'use', 'the', 'BART', 'model', '<ref type=""single"">(Lewis et al., 2020)</ref>', 'that', 'is', 'one', 'of', 'the', 'state-of-the-art', 'text', 'generation', 'models.', 'Below', 'we', 'explain', 'the', 'details', 'of', 'each', 'of', 'these', 'two', 'approaches', 'for', 'creating', 'QA', 'data', 'from', 'CoNLL-2012.', 'Table', '4', 'shows', 'examples', 'from', 'both', 'approaches.', '2019)', 'choose', 'a', 'sentence', 'that', 'contains', 'an', 'anaphor', 'as', 'a', 'declarative', 'query,', 'the', 'closest', 'nonpronominal', 'antecedent', 'of', 'that', 'anaphor', 'as', 'the', 'answer,', 'and', 'the', 'corresponding', 'document', 'of', 'the', 'expressions', 'as', 'the', 'context.', '10', 'We', 'remove', 'the', 'tuples', 'in', 'which', 'the', 'anaphor', 'and', 'its', 'antecedent', 'are', 'identical.', 'The', 'reason', 'is', 'that', '(1)', 'Quoref', 'already', 'contains', 'many', 'examples', 'in', 'which', 'the', 'coreference', 'relation', 'is', 'between', 'two', 'mentions', 'with', 'the', 'same', 'string,', 'and', '(2)', 'even', 'after', 'removing', 'such', 'examples,', 'CoNLL', 'dec', 'contains', 'around', 'four', 'times', 'more', 'QA', 'pairs', 'than', 'the', 'Quoref', 'training', 'data.']",20,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
aab2a284-5fd6-40c4-83b3-f9356062c06e,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['To', 'solve', 'this', 'dilemma', 'and', 'bridge', 'the', 'gap', 'between', 'practical', 'needs', 'for', 'simple', 'definitions', 'and', 'current', 'trivial', 'definition', 'generation', 'systems,', 'we', 'present', 'a', 'novel', 'method', 'for', 'the', 'SDG', 'task.', 'As', 'illustrated', 'in', 'Figure', '2,', 'our', 'method', 'leverages', 'a', 'multitasking', 'framework', 'SimpDefiner', 'to', 'generate', 'simple', 'definitions', 'by', 'performing', 'three', 'sub-tasks', 'at', 'the', 'same', 'time,', 'which', 'are', 'definition', 'generation,', 'text', 'reconstruction,', 'and', 'language', 'modeling', 'tasks.', 'The', 'framework', 'consists', 'of', 'a', 'fully', 'shared', 'encoder', 'and', 'two', 'partially', 'shared', 'decoders.', 'We', 'disentangle', 'the', 'complexity', 'factors', 'from', 'the', 'text', 'by', 'designing', 'a', 'parameter', 'sharing', 'scheme.', 'Particularly,', 'we', 'share', 'parameters', 'in', 'Complexity-Dependent', 'Layer', 'Normalization', 'and', 'Complexity-Dependent', 'Query', 'Projection', 'of', 'the', 'transformer', 'architecture', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'to', 'control', 'the', 'complexity', '(Section', '3.3).', 'Through', 'joint', 'learning', 'and', 'sharing', 'parameters', 'between', 'the', 'decoders,', 'the', 'SimpDefiner', 'is', 'able', 'to', 'generate', 'complex', 'and', 'simple', 'definitions', 'simultaneously.']",106,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
aad2da78-b66b-4c02-aff6-f7c2b056bd58,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,"[""Huggingface's transformers: State-of-the-art natural language processing""]",['2019'],['Thomas Wolf;Lysandre Debut;Victor Sanh;Julien Chaumond;Clement Delangue;Anthony Moi;Pierric Cistac;Tim Rault;Rémi Louf;Morgan Funtowicz'],single,"['With', 'the', 'same', 'parameters', 'as', 'for', 'English,', 'we', 'used', 'language-specific', 'BERT', 'models', 'from', 'Huggingface', 'transformers', '<ref type=""single"">(Wolf et al., 2019)</ref>', 'for', 'the', 'Arabic,', 'Chinese,', 'Dutch,', 'Finnish,', 'German', 'and', 'Turkish', 'datasets', 'with', '5-fold', 'cross-validation.', 'The', 'annotated', 'Finnish', 'dataset', 'achieves', 'an', 'f1', 'score', 'of', '0.51.', 'The', 'projected', 'annotations', 'achieve', 'slightly', 'worse', 'f1', 'scores', 'than', 'the', 'annotated', 'dataset', 'at', '0.45', 'for', 'Finnish', '(see', 'table', '9).', 'The', 'other', 'datasets', 'achieve', 'similar', 'f1', 'scores,', 'with', 'the', 'Germanic', 'languages', 'of', 'German', 'and', 'Dutch', 'achieving', 'almost', 'as', 'high', 'scores', 'as', 'the', 'original', 'English', 'dataset.', 'This', 'is', 'likely', 'a', 'reflection', 'of', 'typological,', 'cultural,', 'and', 'linguistic', 'similarities', 'between', 'the', 'languages', 'making', 'the', 'translation', 'to', 'begin', 'with', 'more', 'similar', 'to', 'the', 'original', 'and', 'therefore', 'minimizing', 'information', 'loss.']",15,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ab29fb5d-f5f3-4af8-8067-747b95c45081,Themes in the work of Margaret Masterman,1988,Yorick Wilks,['unknown'],['unknown'],['unknown'],single,"['However,', ""MMB's"", 'attitude', 'to', 'these', 'primitives', 'was', 'very', 'unlike', 'that', 'of', 'other', 'peddlers', 'of', 'conceptual', 'primitives', 'or', 'languages', 'of', 'thought:', 'at', 'no', 'point', 'did', 'she', 'suggest,', 'in', 'the', 'way', 'that', 'became', 'fashionable', 'later', 'in', 'cognitive', 'science,', 'that', 'the', 'primitive', 'names', 'constituted', 'some', 'sort', 'of', 'language', 'in', 'the', 'mind', 'or', 'brain', '<ref type=""single"">(Fodor\'s view, 1975)</ref>', 'or', 'that,', 'although', 'they', 'appeared', 'to', 'be', 'English,', 'the', 'primitives', 'like', ""'Move'"", 'and', ""'Do'"", 'were', 'really', 'the', 'names', 'of', 'underlying', 'entities', 'that', 'were', 'not', 'in', 'any', 'particular', 'language', 'at', 'all.', 'This', 'kind', 'of', 'naive', 'imperialism', 'of', 'English', 'has', 'been', 'the', 'bane', 'of', 'linguistics', 'for', 'many', 'years,', 'and', 'shows,', 'by', 'contrast,', 'the', 'far', 'greater', 'sophistication', 'of', 'the', 'structuralism', 'that', 'preceded', 'it.']",50,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ab429d5c-3f3a-47af-ad2d-a6fbb4748ae4,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['Neural re-rankers for evidence retrieval in the feverous task'],['2021'],['Mohammed Saeed;Giulio Alfarano;Khai Nguyen;Duc-Hong Pham;Raphael Troncy;Paolo Papotti'],single,"['An', 'efficient', 'and', 'effective', 'document', 'retriever', 'is', 'required', 'since', 'the', 'Wikipedia', 'dump', 'containing', 'millions', 'of', 'pages.', 'We', 'first', 'narrow', 'the', 'search', 'space', 'to', 'several', 'hundred', 'pages', '(m', '0)', 'with', 'an', 'efficient', 'information', 'retrieval', 'method', 'based', 'on', 'TF-IDF,', 'namely,', 'DRQA', '<ref type=""single"">(Chen et al., 2017).</ref>', 'A', 'RoBERTa-based', 're-ranker', '<ref type=""single"">(Saeed et al., 2021)</ref>', 'and', 'a', 'BM25-based', 're-ranker', 'are', 'then', 'applied', 'in', 'parallel', 'to', 're-rank', 'the', 'm', '0', 'document', 'candidates.', 'We', 'combine', 'the', 'results', 'of', 'two', 're-rankers', 'and', 'keep', 'top', 'm', 'documents', 'since', 'BM25', 'focuses', 'more', 'on', 'entity', 'matching', 'and', 'RoBERTa-based', 're-ranker', 'pays', 'more', 'attention', 'to', 'the', 'overall', 'sentence', 'structure.', 'The', 'document', 'scores', 'are', 'calculated', 'as', 'the', 'sum', 'of', 'their', 'rankings', 'in', 'the', 'two', 're-rankers.', 'Documents', 'with', 'lower', 'scores', 'have', 'higher', 'priority.']",43,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ab9b4581-bbae-4024-8b64-41677f0be38a,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['Learning Non-Isomorphic Tree Mappings for Machine Translation'],['2003'],['J Eisner'],single,"['Thus', 'there', 'are', 'a', 'number', 'of', 'situations', 'in', 'which', 'gCNs', 'are', 'not', 'sufficient.', 'Given', 'that', 'gCNs', 'can', 'be', 'represented', 'by', 'Tree', 'Substitution', 'Grammars,', 'as', 'in', '<ref type=""single"">Eisner (2003),</ref>', 'which', 'are', 'in', 'fact', 'TAGs', 'that', 'do', 'not', 'allow', 'precisely', 'the', 'kind', 'of', 'unbounded', 'phenomena', 'described', 'by', 'TAGs,', 'this', 'would', 'suggest', 'that', 'using', 'a', 'TAG', 'grammar', 'to', 'describe', 'the', 'gNCNs', 'in', 'order', 'to', 'decompose', 'the', 'trees', 'would', 'be', 'feasible,', 'and', 'this', 'is', 'further', 'an', 'interesting', 'question', 'for', 'theoretical', 'reasons', 'described', 'below.']",25,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
abbb97d9-f4b3-46c7-9b36-6858c50b4e2e,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['unknown', 'Learning dense representations for entity retrieval']","['unknown', '2019']","['unknown', 'Daniel Gillick;Sayali Kulkarni;Larry Lansing;Alessandro Presta;Jason Baldridge;Eugene Ie;Diego García-Olano']",group,"['In', 'this', 'part,', 'we', 'conduct', 'the', 'extensive', 'experiments', 'on', 'MSMARCO', 'dataset', 'to', 'examine', 'the', 'effectiveness', 'of', 'the', 'three', 'strategies', 'in', 'RocketQA.', 'Results', 'on', 'NQ', 'dataset', 'has', 'shown', 'the', 'similar', 'findings', '(see', 'in', 'Section', 'A.2', 'in', 'Appendix).', 'First,', 'we', 'compare', 'cross-batch', 'negatives', 'with', 'inbatch', 'negatives', 'by', 'using', 'the', 'same', 'experimental', 'setting', '(i.e.', 'the', 'number', 'of', 'epochs', 'is', '40', 'and', 'the', 'batch', 'size', 'is', '512', 'on', 'each', 'single', 'GPU).', 'From', 'the', 'first', 'two', 'rows', 'in', 'Table', '3,', 'we', 'can', 'see', 'that', 'the', 'performance', 'of', 'the', 'dense', 'retriever', 'can', 'be', 'improved', 'with', 'more', 'negatives', 'by', 'cross-batch', 'negatives.', 'It', 'is', 'expected', 'that', 'when', 'increasing', 'the', 'number', 'of', 'random', 'negatives,', 'it', 'will', 'reduce', 'the', 'discrepancy', 'between', 'training', 'and', 'inference.', 'Furthermore,', 'we', 'investigate', 'the', 'effect', 'of', 'the', 'number', 'of', 'random', 'negatives.', 'Specifically,', 'we', 'examine', 'the', 'performance', 'of', 'dual-encoders', 'trained', 'by', 'using', 'different', 'numbers', 'of', 'random', 'negatives', 'with', 'a', 'fixed', 'number', 'of', 'steps.', 'From', 'Figure', '4,', 'we', 'can', 'see', 'that', 'the', 'model', 'performance', 'increases,', 'when', 'the', 'number', 'of', 'random', 'negatives', 'becomes', 'larger.', 'After', 'a', 'certain', 'point,', 'the', 'model', 'performance', 'starts', 'to', 'drop,', 'since', 'a', 'large', 'batch', 'size', 'may', 'bring', 'difficulty', 'for', 'optimization', 'on', 'training', 'data', 'with', 'limited', 'size.', 'We', 'say', 'that', 'there', 'should', 'be', 'a', 'balance', 'between', 'the', 'batch', 'size', 'and', 'the', 'number', 'of', 'negatives.', 'When', 'increasing', 'the', 'batch', 'size,', 'we', 'will', 'have', 'more', 'negatives', 'for', 'each', 'question.', 'However,', 'when', 'the', 'size', 'of', 'training', 'data', 'is', 'limited,', 'a', 'large', 'batch', 'size', 'will', 'bring', 'difficulty', 'for', 'optimization.', 'Second,', 'we', 'examine', 'the', 'effect', 'of', 'denoised', 'hard', 'negatives', 'from', 'the', 'top-k', 'passages', 'retrieved', 'by', 'the', 'dense', 'retriever.', 'As', 'shown', 'in', 'the', 'third', 'row', 'in', 'Table', '3,', 'the', 'performance', 'of', 'the', 'retriever', 'significantly', 'decreases', 'by', 'introducing', 'hard', 'negatives', 'without', 'denoising.', 'We', 'speculate', 'that', 'it', 'is', 'caused', 'by', 'the', 'fact', 'that', 'there', 'are', 'a', 'large', 'number', 'of', 'unlabeled', 'positives.', 'Specifically,', 'we', 'manually', 'examine', 'the', 'topretrieved', 'passages', 'of', '100', 'questions,', 'that', 'were', 'not', 'labeled', 'as', 'true', 'positives.', 'We', 'find', 'that', 'about', '70%', 'of', 'them', 'are', 'actually', 'positives', 'or', 'highly', 'relevant.', 'Hence,', 'it', 'is', 'likely', 'to', 'bring', 'noise', 'if', 'we', 'simply', 'sample', 'hard', 'negatives', 'from', 'the', 'top-retrieved', 'passages', 'by', 'the', 'dense', 'retriever,', 'which', 'is', 'a', 'widely', 'adopted', 'strategy', 'to', 'sample', 'hard', 'negatives', 'in', 'previous', 'studies', '<ref type=""group"">(Gillick et al., 2019, Wu et al., 2020, Xiong et al., 2020).</ref>', 'As', 'a', 'comparison,', 'we', 'propose', 'denoised', 'hard', 'negatives', 'by', 'a', 'powerful', 'cross-encoder.', 'From', 'the', 'fourth', 'row', 'in', 'Table', '3,', 'we', 'can', 'see', 'that', 'denoised', 'negatives', 'improve', 'the', 'performance', 'of', 'the', 'dense', 'retriever.', 'To', 'obtain', 'more', 'insights', 'about', 'denoised', 'hard', 'negatives,', 'Table', '4', 'gives', 'the', 'sampled', 'hard', 'negatives', 'for', 'two', 'questions', 'before', 'and', 'after', 'denoising.', 'Figure', '5', 'further', 'illustrates', 'the', 'ratio', 'of', 'filtered', 'passages', 'at', 'different', 'ranks.', 'We', 'can', 'see', 'that', 'there', 'are', 'more', 'passages', 'filtered', '(i.e.', 'denoised)', 'at', 'lower', 'ranks,', 'since', 'it', 'is', 'likely', 'to', 'have', 'more', 'false', 'negatives', 'at', 'lower', 'ranks.']",361,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ac2e4321-9781-4537-a807-e08111d1a7d4,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['A hierarchically-labeled Portuguese hate speech dataset'],['2019'],['Paula Fortuna;João Rocha Da;Juan Silva;Leo Soler-Company;Sérgio Wanner;unk Nunes'],single,"['For', 'the', 'Portuguese', 'language,', 'most', 'of', 'the', 'works', 'follow', 'the', 'trend', 'of', 'supervised', 'approaches.', 'de', 'Pelle', 'and', 'Moreira', '(2017)', 'created', 'a', 'dataset', 'consist', 'of', '1,', '250', 'offensive', 'comments', 'and', 'developed', 'a', 'baseline', 'method', 'based', 'on', 'n-gram', 'features', 'to', 'classify', 'offensive', 'comments', 'in', 'their', 'dataset.', '<ref type=""single"">Fortuna et al. (2019)</ref>', 'created', 'a', 'hate', 'speech', 'dataset', 'composed', 'of', '5,', '668', 'tweets', 'and', 'developed', 'a', 'baseline', 'classification', 'using', 'pre-trained', 'word', 'embeddings', 'and', 'LSTM', 'in', 'their', 'dataset.', 'Coutinho', 'and', 'Malheiros', '(2020)', 'trained', 'a', 'logistic', 'regression', 'using', 'superficial', 'features', 'for', 'sentiment', 'analysis.', 'Then,', 'they', 'evaluated', 'that', 'model', 'into', 'a', 'homophobia', 'corpus', 'to', 'detect', 'homophobic', 'posts.']",44,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
aca5e2ad-8826-4668-b271-e1d1346d9ed9,Diverse dialogue generation with context dependent dynamic loss function,2020,Ayaka Ueyama;Yoshinobu Kano,['Another diversity promoting objective function for neural dialogue generation'],['2018'],['Ryo Nakamura;Katsuhito Sudoh;Koichiro Yoshino;Satoshi Nakamura'],single,"['Recently,', 'many', 'reports', 'have', 'described', 'studies', 'using', 'deep', 'learning', 'for', 'dialogue', 'systems', 'that', 'have', 'achieved', 'good', 'performance.', 'They', 'can', 'generate', 'fluent', 'sentences', 'based', 'on', 'a', ""user's"", 'utterances', '<ref type=""group"">(Vinyals and Le, 2015, Shang et al., 2015, Serban et al., 2016).</ref>', 'Nevertheless,', 'such', 'neural', 'dialogue', 'systems', 'tend', 'to', 'generate', 'phrases', 'such', 'as', '""Yes""', 'and', '""I', 'do', 'not', 'know""', 'frequently', 'in', 'non-task-oriented', 'dialog', 'systems,', 'referred', 'to', 'as', 'the', 'low', 'diversity', 'issue', 'and', 'the', 'generic', 'response', 'issue.', 'After', 'training', 'by', 'a', 'loss', 'function', 'of', 'similarity', 'with', 'gold', 'standard', 'reference', 'sentences,', 'frequent', 'phrases', 'are', 'more', 'likely', 'to', 'be', 'assigned', 'a', 'large', 'occurrence', 'probability', 'than', 'rare', 'phrases', 'are.', '<ref type=""single"">Nakamura et al. (2018)</ref>', 'proposed', 'an', 'Inverse', 'Token', 'Frequency', '(ITF)', 'loss,', 'which', 'multiplies', 'the', 'Softmax', 'Cross-Entropy', '(SCE)', 'loss', 'by', 'weights', 'based', 'on', 'the', 'inverse', 'of', 'the', 'frequency', 'of', 'tokens.', 'This', 'ITF', 'loss', 'incorporates', 'the', 'frequency', 'distribution', 'of', 'token', 'classes', 'so', 'that', 'rare', 'tokens', 'become', 'more', 'likely', 'to', 'appear.']",91,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
acb98889-e9a5-46ce-b42c-416498fcd0a1,Harmonised large-scale syntactic/semantic lexicons: a European multilingual infrastructure,1999,Nicoletta Calzolari;Antonio Zampolli,"['unknown', 'Introduction']","['unknown', '1996']","['unknown', 'A Zampolli']",group,"['As', 'other', 'current', 'actions', 'in', 'the', 'field', 'of', 'LR', '(e.g.', 'EAGLES,', 'which', 'is', 'a', 'direct', 'descendant', 'of', 'the', '""Pisa', 'Group"",', 'set-up', 'at', 'the', 'Grosseto', 'Workshop', 'by', 'the', 'Istituto', 'di', 'Linguistica', 'Computazionale', '(ILC)', 'of', 'Pisa', 'and', 'sponsored', 'by', 'the', 'Association', 'for', 'Computational', 'Linguistics', '<ref type=""single"">Sept. 1999</ref>', '(ACL)', 'to', 'explore', 'the', 'feasibility', 'of', '""polytheoretical', 'lexicons""', '<ref type=""single"">(Walker et al. 1987</ref>', ')),', 'the', 'PAROLE', 'and', 'SIMPLE', 'projects,', 'building', 'large', 'corpora', 'and', 'lexicons', 'for', 'many', 'European', 'languages,', 'are', 'the', 'follow-up', 'of', 'some', 'initiatives', 'promoted', 'at', 'the', 'Grosseto', 'Workshop.', 'The', 'Council', 'of', 'Europe,', 'which', 'had', 'co-sponsored', 'the', 'workshop,', 'formed', 'a', 'group', 'of', 'experts,', 'representing', 'European', 'institutes', 'with', 'a', 'well', 'established', 'tradition', 'in', 'the', 'field', 'of', 'lexical', 'and', 'corpus', 'studies,', 'to', 'explore', 'the', 'feasibility', 'of', 'harmonising', 'their', 'activities,', 'in', 'order', 'to', 'establish', 'a', 'Network', 'of', 'European', 'Reference', 'Corpora', '(NERC,', 'for', 'which', 'see', '<ref type=""group"">Calzolari, Baker, Kruyt 1996, Zampolli 1996).</ref>', 'This', 'group,', 'gradually', 'enlarged', 'to', 'include', 'members', 'of', 'all', 'the', 'European', 'Union', '(EU)', 'languages,', 'constituted', 'the', 'PAROLE', 'Consortium', 'which', 'has', 'executed', 'the', 'LE', '(Language', 'Engineering)', 'PAROLE', 'project', 'now', 'followed', 'by', 'the', 'LE', 'SIMPLE', 'project', 'carried', 'on', 'by', 'a', 'similar', 'Consortium', '1.']",130,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
ad05d75b-ede6-4122-992b-6e401cf1ab8c,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['Toxicity detection in multiplayer online games'],['2015'],['Marcus Märtens;Siqi Shen;Alexandru Iosup;Fernando Kuipers'],single,"['Token-level', 'Slot', 'Annotation', 'With', 'the', 'processed', 'token-level', 'data,', 'an', 'automated', 'slot', 'labelling', 'is', 'performed.', 'Initially,', 'we', 'create', 'six', 'distinct', 'slot', 'labels:', 'T', '(Toxicity),', 'C', '(Character),', 'D', '(Dotaspecific),', 'S', '(game', 'Slang),', 'P', '(Pronoun)', 'and', 'O', '(Other).', 'To', 'construct', 'the', 'T', 'lexicon,', 'we', 'combine', 'several', 'toxicity', 'lexicons', '(see', 'Section', '8', 'Ethics)', 'and', 'remove', 'overlaps.', 'We', 'also', 'use', 'the', 'supplemental', 'data', 'sourced', 'by', '<ref type=""single"">Märtens et al. (2015)</ref>', 'for', 'the', 'gamerelated', 'lexicons', '(C,', 'D', 'and', 'S)', 'and', 'carefully', 'modify', 'it.', 'The', 'P', 'lexicon', '(e.g.', ""'u',"", ""'ur')"", 'is', 'constructed', 'by', 'this', 'research', 'because', 'in-game', 'chat', 'is', 'extremely', 'abbreviated.', 'Then,', 'we', 'perform', 'lexicon-based', 'automation', 'by', 'exact', 'matching', 'each', 'lower-cased', 'token', 'against', 'the', 'lexicons.', 'Anything', 'not', 'matching', 'a', 'lexicon', 'is', 'labelled', 'O.', 'We', 'contrast', 'this', 'with', 'typical', 'NLU', 'slot', 'labelling', 'where', 'a', 'semantic', 'concept', 'can', 'stretch', 'over', 'a', 'span', 'of', 'words.', 'In', 'comparison', 'to', 'other', 'toxicity', 'datasets,', 'our', 'lexicon-based', 'slot', 'labelling', 'enables', 'deeper', 'understanding', 'of', 'game', 'context.']",60,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
add4a02a-4b34-4406-8f14-79257408a1d4,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,"['The automatic content extraction (ace) program-tasks, data, and evaluation']",['2004'],['Alexis George R Doddington;unk Mitchell;A Mark;unk Przybocki;A Lance;Stephanie Ramshaw;Ralph Strassel;unk Weischedel'],single,"['However,', 'event', 'detection', 'as', 'a', 'problem', 'shifts', 'when', 'we', 'move', 'away', 'from', 'the', 'annotation', 'paradigm', 'of', 'datasets', 'such', 'as', 'ACE', '<ref type=""single"">(Doddington et al., 2004)</ref>', 'and', 'TAC', 'KBP', '<ref type=""single"">(Mitamura et al., 2015)</ref>', 'to', 'TimeML', 'datasets', 'such', 'as', 'TimeBank', '<ref type=""single"">(Pustejovsky et al., 2006),</ref>', 'which', 'are', 'used', 'in', 'this', 'paper.', 'There', 'has', 'been', 'limited', 'use', 'of', 'deep', 'learning', 'methods', 'on', 'TimeBanks', 'due', 'to', 'fewer', 'event', 'mentions', 'and', 'a', 'need', 'for', 'data', 'augmentation', 'and', 'bootstrapping.', 'However,', 'in', 'this', 'paper,', 'we', 'show', 'that', 'using', 'subword', 'level', 'information,', 'a', 'language', 'invariant', 'deep', 'learning', 'model', 'can', 'provide', 'similar', 'event', 'detection', 'accuracies', 'as', 'heavily', 'feature', 'engineered', 'language', 'specific', 'statistical', 'methods', 'without', 'using', 'any', 'augmented', 'data.']",20,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ae1957ef-036a-4924-be18-a3bc093a52a0,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models'],['2021'],['Hannah Kirk;Yennie Jun;Haider Iqbal;Elias Benussi;Filippo Volpin;Frederic Dreyer;Aleksandar Shtedritski;Yuki Asano'],single,"['Generating', 'Job', 'Ads', 'We', 'use', 'the', 'OpenAI', 'Davinci', 'GPT-3', 'model', 'which', 'has', 'been', 'adapted', 'for', 'natural', 'language', 'requests.', 'We', 'use', 'default', 'parameters', 'values', 'and', '500', 'maximum', 'tokens', 'per', 'completion', '(see', 'Appendix', 'B', 'for', 'hyperparameter', 'details).', 'Keeping', 'default', 'parameters', 'better', 'reflects', 'when', 'non-technical', 'users', 'apply', 'large-scale', 'generative', 'models', '""out-of-the-box""', '<ref type=""single"">(Kirk et al., 2021).</ref>']",48,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
ae3d44a5-f262-49a9-8dbd-19c4c729f60f,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Combining textual entailment and argumentation theory for supporting online debates interactions'],['2012'],['Elena Cabrio;Serena Villata'],single,"['We', 'consider', 'three', 'baselines.', 'Random', 'assigns', 'a', 'relation', 'to', 'each', 'argument', 'randomly.', 'Sentiment', 'assigns', 'a', 'relation', 'based', 'on', 'the', 'claim', 'and', ""statement's"", 'agreement', 'on', 'sentiment:', 'support', 'if', 'both', 'are', 'positive', 'or', 'negative,', 'attack', 'if', 'they', 'have', 'opposite', 'sentiments,', 'and', 'neutral', 'otherwise.', 'We', 'compute', 'a', 'sentiment', 'distribution', 'by', 'averaging', 'all', 'target-specific', 'sentiments', 'from', 'our', 'sentiment', 'classifier', '(§4.2).', 'Textual', 'entailment', 'assigns', 'support', '(attack)', 'if', 'the', 'statement', 'entails', '(contradicts)', 'the', 'claim,', 'and', 'neutral', 'otherwise', '<ref type=""single"">(Cabrio and Villata 2012).</ref>', 'We', 'use', 'our', 'textual', 'entailment', 'module', '(§4.1).', 'For', 'Debatepedia,', 'we', 'choose', 'between', 'support', 'and', 'attack', 'whichever', 'has', 'a', 'higher', 'probability.']",71,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ae5ddf50-4bad-45fd-b151-ae9890871b6d,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['Asynchronous methods for deep reinforcement learning'],['2016'],['Volodymyr Mnih;Adria Badia;Mehdi Mirza;Alex Graves;Timothy Lillicrap;Tim Harley;David Silver;Koray Kavukcuoglu'],single,"['Overall', 'training', 'is', 'done', 'via', 'A2C', '<ref type=""single"">(Mnih et al., 2016)</ref>', 'a', 'policy', 'gradient', 'algorithm', 'that', 'maximizes', 'long-term', 'expected', 'reward', 'by', 'comparing', 'the', 'advantage', 'A(s', 't,', 'a', '*', 't)', 'of', 'taking', 'an', 'action', 'a', 't', 'in', 'a', 'state', 's', 't', 'to', 'the', 'average', 'value', 'of', 'taking', 'any', 'valid', 'action', 'as', 'predicted', 'by', 'the', 'critic', 'V', '(s', 't', ').', 'The', 'setup', 'and', 'network', 'architectures', 'used', 'are', 'similar', 'to', '<ref type=""single"">Ammanabrolu et al. (2021)</ref>', 'and', 'are', 'summarized', 'in', 'Figure', '5.', 'At', 'every', 'step,', 'the', 'LIGHT', 'agent', 'receives', 'as', 'input', 'the', 'text', 'describing', 'the', 'setting,', 'the', ""character's"", 'persona', '&amp,', 'motivation,', 'and', 'the', 'full', 'dialogue', 'history.', 'This', 'is', 'then', 'encoded', 'using', 'a', 'transformer', 'based', 'encoder', 'and', 'sent', 'to', 'the', 'action', 'and', 'dialogue', 'policy', 'networks', 'which', 'output', 'an', 'action/dialogue', 'utterance.', 'These', 'are', 'then', 'passed', 'into', 'the', 'LIGHT', 'environment', 'which', 'process', 'them', 'and', 'returns', 'rewards', 'to', 'be', 'used', 'by', 'the', 'agent.']",6,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ae68ab23-857f-4911-9fea-04afa056d087,Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets,2021,George-Andrei Dima;Dumitru-Clementin Cercel;Mihai Dascalu,['Beyond accuracy: Behavioral testing of nlp models with checklist'],['2020'],['Tongshuang Marco Tulio Ribeiro;Carlos Wu;Sameer Guestrin;unk Singh'],single,"['Augmented', 'Training', 'Dataset:', 'Another', 'explored', 'solution', 'for', 'the', 'unbalance', 'in', 'subtask', '1a', 'consists', 'in', 'augmenting', 'the', 'poorly', 'represented', 'class', '(the', 'positive', 'class).', 'We', 'leverage', 'the', 'predefined', 'augmentation', 'approaches', 'integrated', 'into', 'the', 'Tex-tAttack', 'library', '<ref type=""single"">(Morris et al., 2020).</ref>', 'New', 'positive', 'examples', 'are', 'generated', 'by', 'char', 'swapping,', 'by', 'replacing', 'words', 'with', 'synonyms', 'from', 'the', 'Word-Net', 'thesaurus', '<ref type=""single"">(Miller, 1995),</ref>', 'and', 'by', 'using', 'methods', 'from', 'the', 'CheckList', 'testing', '-i.e.,', 'transformations', 'like', 'location', 'replacement', 'or', 'number', 'alteration', '<ref type=""single"">(Ribeiro et al., 2020).</ref>', 'Five', 'positive', 'examples', 'are', 'automatically', 'added', 'for', 'each', 'initial', 'positive', 'sample,', 'thus', 'increasing', 'the', 'proportion', 'of', 'the', 'poorly', 'represented', 'class', 'from', '7%', 'to', 'almost', '45%.']",68,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
aeef5942-2940-408d-90f9-5e10f71859b7,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Lextools. A toolkit for finite-state linguistic analysis'],['2000'],['Richard Sproat'],single,"['DeKo', 'is', 'implemented', 'as', 'a', 'series', 'of', 'finite-state', 'transducers,', 'using', 'the', 'FST-suite', 'provided', 'by', 'AT&amp,T', '<ref type=""single"">(Sproat 2000b).</ref>', 'A', 'more', 'detailed', 'description', 'of', 'the', 'architecture', 'is', 'given', 'in', '<ref type=""single"">Schmid et al. (2001)</ref>', 'and', 'examples', 'for', 'the', 'rule', 'format', 'are', 'provided', 'in', '<ref type=""single"">Säuberlich (2001).</ref>', 'We', 'need', 'to', 'model', 'three', 'types', 'of', 'rules:']",15,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
aef1ab18-d50f-436a-bb4e-265238d20bf1,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,"['Understanding Dataset Design Choices for Multi-hop Reasoning', 'Compositional Questions Do Not Necessitate Multi-hop Reasoning', 'Is Multihop QA in DIRE Condition? Measuring and Reducing Disconnected Reasoning']","['2019', '2019', '2020']","['Jifan Chen;Greg Durrett', 'Sewon Min;Eric Wallace;Sameer Singh;Matt Gardner;Hannaneh Hajishirzi;Luke Zettlemoyer', 'Harsh Trivedi;Niranjan Balasubramanian;Tushar Khot;Ashish Sabharwal']",group,"['One', 'of', 'the', 'crucial', 'issues', 'regarding', 'the', 'evaluation', 'of', 'multi-hop', 'inference', 'models', 'is', 'the', 'possibility', 'to', 'achieve', 'strong', 'overall', 'performance', 'without', 'using', 'real', 'compositional', 'methods', '<ref type=""group"">(Min et al., 2019, Chen and Durrett, 2019, Trivedi et al., 2020).</ref>', 'Therefore,', 'in', 'order', 'to', 'evaluate', 'multi-hop', 'inference', 'more', 'explicitly,', 'we', 'break', 'down', 'the', 'performance', 'of', 'each', 'model', 'with', 'respect', 'to', 'the', 'difficulty', 'of', 'accessing', 'specific', 'facts', 'in', 'an', 'explanation', 'via', 'direct', 'lexical', 'overlap.', 'This', 'comes', 'from', 'the', 'assumption', 'that', 'facts', 'sharing', 'many', 'terms', 'with', 'question', 'or', 'answer', 'are', 'relatively', 'easier', 'to', 'find', 'and', 'rank', 'highly.']",25,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
af1c5ea0-56fe-4c8c-bff3-4d20b2755244,Amrita_CEN_NLP@SDP2021 Task A and B,2021,Isha Indhu;Kavya Kumar;Lakshaya Karthikeyan,['Classification and regression by randomforest'],['2002'],['Andy Liaw;Matthew Wiener'],single,"['This', 'paper', 'reports', 'the', 'submissions', 'of', 'the', 'Am-rita_CEN_NLP', 'team', 'for', 'the', '3C', 'Citation', 'Context', 'Classification', 'shared', 'task', '<ref type=""single"">Kunnath et al. (2021).</ref>', 'We', 'used', 'deep', 'learning', 'and', 'machine', 'learning', 'models', 'developed', 'using', 'Bi-LSTM', 'and', 'Random', 'Forest', 'algorithms', '<ref type=""single"">Liaw et al. (2002),</ref>', '<ref type=""single"">Premjith et al. (2019a),</ref>', '<ref type=""single"">Premjith et al. (2019b)</ref>', 'to', 'complete', 'the', 'subtasks.', 'They', 'will', 'be', 'elaborated', 'upon', 'in', 'Section', '4.']",33,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0]"
af73f135-942b-405d-9166-b484e4928cbb,SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering,2020,Aishwarya Ashok;Ganapathy Natarajan;Ramez Elmasri;Laurel Smith-Stvan,['Efficient estimation of word representations in vector space'],['2013'],['Tomas Mikolov;Kai Chen;Greg Corrado;Jeffrey Dean'],single,"['For', 'the', 'cosine', 'similarity', 'calculation,we', 'use', 'word2vec', 'to', 'calculate', 'the', 'sentence', 'vector', 'as', 'sum', 'of', 'the', 'word', 'vectors', 'of', 'the', 'words', 'in', 'the', 'sentence.', 'The', 'calculation', 'of', 'sentence', 'vector', 'was', 'to', 'take', 'advantage', 'of', 'the', 'compositionality', 'property', 'using', 'word2vec', '<ref type=""single"">(Mikolov et al., 2013).</ref>', 'We', 'used', 'word', 'vectors', 'of', 'dimension', '100', 'trained', 'on', 'the', '2015', 'wikidump.']",39,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
af7aef92-2892-49d3-ad18-541ea61a7131,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Lexical co-occurrence and association strength'],['1990'],['P Donald;Kimberly Spence;unk Owens'],single,"['Instead,', 'we', 'can', 'use', 'methods', 'that', 'require', 'only', 'raw', 'corpora.', 'For', 'this,', 'the', 'results', 'of', '<ref type=""single"">Spence and Owens (1990)</ref>', 'are', 'the', 'most', 'important', 'studies', 'of', 'associations.', 'They', 'have', 'shown', 'that', 'the', 'amount', 'of', 'co-occurrences', 'of', 'words', 'in', 'a', 'corpus', 'is', 'a', 'good', 'indicator', 'of', 'the', 'semantic', 'relationship', 'between', 'them', 'and', 'is', 'also', 'suitable', 'for', 'measuring', 'the', 'strength', 'of', 'associations.', 'Bel', '<ref type=""single"">Enguix et al. (2014)</ref>', 'also', 'predict', 'associations', 'from', 'co-occurrences,', 'using', 'a', 'network', 'of', 'bigram', 'counts.', 'Similar', 'to', 'their', 'methods,', 'we', 'use', 'weighted', 'co-occurrences', 'explicitly', 'to', 'model', 'the', 'connection', 'of', 'words', '(for', 'details,', 'see', '4.1.).']",15,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
af9db006-876a-4b9d-bd37-e2df00d79be8,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,"['Computer-aided translation: a business viewpoint', ""Pre-editing and the use of simplified writing for MT: an engineer's experience of operating an MT system""]","['1979', '1990']","['J Elliston', 'P Pym']",group,"['It', 'is', 'again', 'relatively', 'recent', 'that', 'the', 'notion', 'of', 'MT', 'with', 'restricted', 'input', 'has', 'come', 'to', 'be', 'associated', 'with', ""'sublanguage'"", '<ref type=""group"">([16, 24, 25, 26]</ref>', '),', 'as', 'opposed', 'to', 'the', 'case', 'previously,', 'when', 'it', 'was', 'typically', 'the', 'MT', 'system', 'which', 'dictated', 'the', 'restrictions', 'rather', 'than', 'vice', 'versa', '(e.g.', '<ref type=""group"">[11, 31]</ref>', ').', 'In', 'the', 'system', 'described', 'here,', 'the', 'sublanguage', 'approach', 'gives', 'us', 'not', 'only', 'vocabulary', 'and', 'syntax,', 'but', 'also', 'the', 'contextual', 'and', 'domain', 'knowledge', 'employed', 'by', 'the', 'system.', 'And,', 'in', 'keeping', 'with', 'the', 'strong', 'corpus-based', 'approach,', 'these', 'knowledge', 'sources', 'are', 'derived', 'directly', 'from', 'an', 'analysis', 'of', 'corpora', '<ref type=""single"">([2]</ref>', '),', 'not', 'from', 'some', ""linguist's"", 'introspection,', 'as', 'is', 'the', 'case', 'in', 'conventional', 'rule-based', 'MT', 'systems.', 'An', 'additional', 'point', 'of', 'interest', 'in', 'this', 'research', 'is', 'the', 'contrastive', 'aspect,', 'since', 'our', 'approach', 'requires', 'us', 'to', 'make', 'an', 'explicitly', 'comparative', 'analysis', 'of', 'three', 'corpora', 'which,', 'it', 'should', 'be', 'stressed,', 'are', 'not', 'in', 'fact', 'parallel', 'corpora,', 'but', 'simply', 'collections', 'of', 'pragmatically', 'similar', 'material.']",44,"[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b018449b-a1e7-4f24-a9f1-ee94d1a579af,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['TQ-AutoTest -an automated test suite for (machine) translation quality'],['2018'],['Vivien Macketanz;Renlong Ai;Aljoscha Burchardt;Hans Uszkoreit'],single,"['First,', 'we', 'apply', 'our', 'framework', 'to', 'the', 'TQ-AutoTest', 'dataset', '<ref type=""single"">(Macketanz et al., 2018).</ref>', 'Originally', 'used', 'for', 'targeted', 'evaluation', 'of', 'MT', 'systems,', 'it', 'includes', 'German', 'source', 'sentences', 'that', 'each', 'exhibit', 'one', 'of', '14', 'different', 'linguistic', 'phenomena,', 'such', 'as', 'ambiguity,', 'composition,', 'and', 'subordination.']",9,"[0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
b035355d-b503-4763-ab65-87b23be80f6b,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['Here,', 'we', 'summarize', 'the', 'pre-training', 'tasks', 'for', 'the', 'encoders', 'mentioned', 'in', 'Section', '4.2.', 'These', 'tasks', 'are', 'unchanged', 'from', 'those', 'described', 'in', '<ref type=""single"">Ammanabrolu et al. (2021).</ref>']",21,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1]"
b07a0bb8-2fe4-45ac-be85-45d8184e3b15,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,"['CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in Onto-Notes', 'A model-theoretic coreference scoring scheme']","['2012', '1995']","['Alessandro Sameer Pradhan;Nianwen Moschitti;Olga Xue;Yuchen Uryupina;unk Zhang', 'Marc Vilain;John Burger;John Aberdeen;Dennis Connolly;Lynette Hirschman']",group,"['Much', 'work', 'in', 'NLP', 'addresses', 'the', 'recovery', 'of', 'such', 'verb-mediated', 'relations', '(SRL)', '<ref type=""group"">(Gildea and Jurafsky, 2002, Palmer et al., 2010),</ref>', 'either', 'using', 'pre-specified', 'role', 'ontologies', 'such', 'as', 'PropBank', 'or', 'FrameNet', '<ref type=""group"">(Palmer et al., 2005, Ruppenhofer et al., 2016),</ref>', 'or,', 'more', 'recently,', 'using', 'natural-languagebased', 'representations', '(QA-SRL)', '<ref type=""group"">(He et al., 2015, FitzGerald et al., 2018).</ref>', 'Another', 'well-studied', 'kind', 'of', 'semantic', 'relations', 'between', 'NPs', 'is', 'that', 'of', 'coreference', '<ref type=""group"">(Vilain et al., 1995, Pradhan et al., 2012),</ref>', 'where', 'two', '(or', 'more)', 'NPs', 'refer', 'to', 'the', 'same', 'entity.']",44,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
b0c87bf3-5014-4c55-81db-1f11a6e28435,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,['unknown'],['2019'],['Rodrigo Nogueira;Kyunghyun Cho'],single,"['BoW', '+', 'BERT', 'As', 'a', 'baseline,', 'we', 'consider', 'the', 'retrieve-and-rerank', 'approach', 'originally', 'proposed', 'by', '<ref type=""single"">Nogueira and Cho (2019),</ref>', 'which', 'has', 'emerged', 'as', 'the', 'standard', 'architecture', 'for', 'applying', 'pretrained', 'transformers', 'to', 'ranking.', 'We', 'notate', 'a', 'specific', 'configuration', 'of', 'this', 'design', 'as', 'BoW(k', '0)', '+', 'BERT,', 'where', 'k', '0', 'denotes', 'the', 'number', 'of', 'candidates', 'from', 'bag-of-words', 'retrieval', 'that', 'are', 'then', 'reranked', 'by', 'BERT.', 'A', 'commonly', 'used', 'default', 'is', 'BoW(1000)', '+', 'BERT', '<ref type=""single"">(Nogueira and Cho, 2019).</ref>']",14,"[0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b0d1f62f-c2ce-4f1a-b8b5-6f075f6b49c4,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['Parametrizing', 'Curriculum', 'Difficulty.', 'Given', 'the', 'relative', 'imbalance', 'of', 'this', 'multinomial', 'distribution,', 'as', 'seen', 'in', 'Figure', '3,', 'we', 'hypothesize', 'that', 'a', 'LIGHT', 'agent', 'only', 'learns', 'to', 'do', 'well', 'on', 'certain', 'types', 'of', 'objectives', 'and', 'not', 'others-memorizing', 'trajectories', 'for', 'less', 'seen', 'quest', 'types,', 'i.e.', 'those', 'found', 'in', 'the', 'tail', 'of', 'the', 'distribution.', 'Preliminary', 'evidence', 'for', 'this', 'hypothesis', 'is', 'also', 'seen', 'in', '<ref type=""single"">Prabhumoye et al. (2020),</ref>', 'where', 'they', 'show', 'a', 'positive', 'correlation', 'between', 'the', 'number', 'of', 'instances', 'of', 'a', 'particular', 'type', 'of', 'quest', 'during', 'training', 'and', 'the', 'final', 'test', 'goal-achievement', 'performance.', 'Based', 'on', 'these', 'observations', 'and', 'our', 'initial', 'hypothesis,', 'we', 'use', 'this', 'particular', 'dimension', 'to', 'parametrize', 'curriculum', 'difficulty', 'for', 'training', 'LIGHT', 'agents-quest', 'types', 'that', 'are', 'rarer', 'in', 'the', 'initial', 'training', 'data', 'will', 'be', 'harder', 'for', 'the', 'agent', 'to', 'generalize', 'to', 'in', 'a', 'zero-shot', 'setting.']",59,"[0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b0d2c639-bda5-4912-865b-0b256b8889dc,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,['Early exiting BERT for efficient document ranking'],['2020'],['Ji Xin;Rodrigo Nogueira;Yaoliang Yu;Jimmy Lin'],single,"['At', 'a', 'high', 'level,', 'the', 'entire', 'premise', 'of', 'our', 'work', 'is', 'the', 'point', 'of', 'multi-stage', 'ranking,', 'in', 'that', 'the', 'architecture', 'evolved', 'to', 'achieve', 'a', 'good', 'balance', 'between', 'effectiveness', 'and', 'efficiency', 'in', 'end-to-end', 'retrieval.', 'Motivated', 'by', 'the', 'observation,', 'dating', 'back', 'more', 'than', 'a', 'decade,', 'that', 'effective', 'techniques', 'are', 'often', 'computationally', 'expensive,', 'multi-stage', 'retrieval', 'architectures', 'control', 'latency', 'by', 'applying', 'expensive', 'techniques', 'over', 'only', 'the', 'most', 'promising', 'candidates', '<ref type=""single"">(Wang et al., 2011).</ref>', 'This', 'is', 'often', 'operationalized', 'as', 'optimizing', 'for', 'recall', 'in', 'the', 'earlier', 'stages', 'of', 'the', 'pipeline.', 'Specifically', 'in', 'the', 'context', 'of', 'transformers,', 'multi-stage', 'neural', 'pipelines', 'have', 'been', 'explored', 'in', 'the', 'past', 'by', 'many', 'researchers', '<ref type=""group"">(Nogueira et al., 2019a, Soldaini and Moschitti, 2020, Matsubara et al., 2020, Pradeep et al., 2021).</ref>', 'The', 'key', 'difference', 'in', 'our', 'work', 'is', 'the', '(re-)introduction', 'of', '""traditional""', 'feature-based', 'learning-to-rank', 'approaches', 'alongside', 'neural', 'models.', 'This', 'aligns', 'with', 'our', 'broader', 'goal', 'of', 'investigating', 'how', 'learning', 'to', 'rank', 'might', 'contribute', 'to', 'modern', 'retrieval', 'approaches', 'dominated', 'by', 'neural', 'models.', 'The', 'computational', 'costs', 'associated', 'with', 'ranking', 'using', 'pretrained', 'transformers', 'can', 'be', 'reduced', 'in', 'various', 'ways.', 'We', 'can', 'accelerate', 'inference', 'using', 'smaller', 'or', 'simpler', 'models.', '<ref type=""single"">Gao et al. (2020)</ref>', 'use', 'distillation', 'to', 'transfer', 'knowledge', 'captured', 'in', 'a', 'larger', 'model', 'into', 'a', 'smaller', 'model,', 'achieving', 'substantial', 'speedups', 'with', 'minimal', 'effectiveness', 'loss.', '<ref type=""single"">Hofstätter et al. (2020)</ref>', 'propose', 'a', 'simpler', 'transformer', 'model', 'to', 'capture', 'contextual', 'information', 'that', 'trades', 'effectiveness', 'for', 'much', 'faster', 'inference.', 'Additional', 'examples', 'of', 'this', 'approach', 'include', '<ref type=""group"">Mitra et al. (2020) and MacAvaney et al. (2020).</ref>', 'An', 'alternative', 'is', 'to', 'introduce', 'early-exit', 'optimizations,', 'as', 'in', '<ref type=""single"">Soldaini and Moschitti (2020)</ref>', 'and', '<ref type=""single"">Xin et al. (2020).</ref>', 'Further', 'speedups', 'can', 'be', 'gained', 'by', 'making', 'modifications', 'to', 'the', 'backbone', 'transformer', 'model,', 'as', 'in', '<ref type=""single"">Sanh et al. (2020).</ref>', 'The', 'key', 'point', 'is', 'that', 'our', 'proposed', 'LTR', 'filtering', 'module', 'achieves', 'speedups', 'in', 'a', 'manner', 'that', 'is', 'orthogonal', 'to', 'the', 'methods', 'discussed', 'here,', 'which', 'focus', 'on', 'directly', 'accelerating', 'transformer', 'inference.', 'Thus,', 'these', 'approaches', 'can', 'be', 'combined', 'with', 'our', 'method', 'for', 'even', 'greater', 'efficiency', 'gains.']",220,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b13a34ae-b9af-4cca-a89c-eae005576f40,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Measuring morphological productivity: Is automatic preprocessing sufficient?'],['2001'],['Stefan Evert;Anke Lüdeling'],single,"['There', 'are', 'two', 'approaches', 'to', 'assessing', 'the', 'productivity', 'of', 'a', 'word', 'formation', 'rule:', 'the', 'qualitative', 'and', 'the', 'quantitative', 'approach.', 'For', 'a', 'full', 'understanding,', 'a', 'combination', 'of', 'both', 'perspectives', 'is', 'necessary.', 'In', 'the', 'qualitative', 'approach,', 'all', 'the', 'restrictions', 'and', 'linguistic', 'properties', 'of', 'the', 'rule', 'are', 'described', '(see', 'the', 'next', 'paragraph', 'for', 'some', 'examples).', 'The', 'qualitative', 'description', 'does', 'not', 'exhaust', 'our', 'intuition', 'of', 'productivity,', 'there', 'is', 'also', 'a', 'quantitative', 'element', 'involved:', 'intuitively', 'one', 'could', 'say', 'that', 'some', 'word', 'formation', 'rules', 'seem', 'to', 'produce', 'new', 'words', 'more', 'readily', 'than', 'others', '-an', 'intuition', 'which', 'cannot', 'be', 'formalized.', 'In', 'quantitative', 'studies', 'this', 'intuition', 'is', 'approximated', 'by', 'the', 'question:', 'how', 'probable', 'is', 'it', 'that', 'we', 'will', 'see', 'a', 'new', 'type', '(lexeme)', 'produced', 'by', 'word', 'formation', 'process', 'X', 'after', 'we', 'have', 'sampled', 'a', 'certain', 'amount', 'of', 'text?', 'Quantitative', 'studies', 'of', 'the', 'productivity', 'of', 'word', 'formation', 'processes', 'are', 'important', 'for', 'the', 'design', 'of', 'word', 'formation', 'systems', 'if', 'the', 'resources', 'are', 'limited', 'and', 'one', 'has', 'to', 'concentrate', 'on', 'the', 'most', 'productive', 'word', 'formation', 'processes', '(on', 'the', 'quantitative', 'aspects', 'of', 'productivity', 'see', 'for', 'example', '<ref type=""group"">Baayen 1992 Baayen , 2000,, Baayen &amp, Lieber 1991, Plag 1999,</ref>', 'for', 'a', 'discussion', 'of', 'some', 'corpus', 'related', 'problems', 'in', 'calculating', 'productivity', 'indices', 'see', '<ref type=""single"">Evert &amp, Lüdeling 2001).</ref>']",188,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
b16a4fd4-1212-4adf-ade8-932d21f17d6f,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,"['MRP 2020: The second shared task on crossframework and cross-lingual meaning representation parsing', 'Fast semantic parsing with welltypedness guarantees', 'Character-level representations improve DRS-based semantic parsing even in the age of BERT']","['2020', '2020', '2020']","[""Stephan Oepen;Omri Abend;Lasha Abzianidze;Johan Bos;Jan Hajic;Daniel Hershcovich;Bin Li;O' Tim;Nianwen Gorman;Daniel Xue;unk Zeman"", 'Matthias Lindemann;Jonas Groschwitz;Alexander Koller', 'Rik Van Noord;Antonio Toral;Johan Bos']",group,"['In', 'recent', 'years,', 'most', 'work', 'on', 'annotating', 'naturallanguage', 'text', 'with', 'comprehensive,', 'broad-coverage', 'meaning', 'representations', 'has', 'been', 'performed', 'in', 'three', 'frameworks:', 'Abstract', 'Meaning', 'Representations', '<ref type=""single"">(Banarescu et al., 2013),</ref>', 'Universal', 'Cognitive', 'Conceptual', 'Annotation', '<ref type=""single"">(Abend and Rappoport, 2013),</ref>', 'and', 'Discourse', 'Representation', 'Structures', '<ref type=""single"">(Abzianidze et al., 2017).</ref>', 'Accurate', 'parsers', 'exist', 'for', 'all', 'three', '(e.g.,', '<ref type=""group"">Lindemann et al., 2020, Oepen et al., 2020, van Noord et al., 2020).</ref>', 'Each', 'formalism', 'has', 'its', 'specific', 'strength:', 'AMRs', 'go', 'very', 'far', 'in', 'abstracting', 'away', 'from', 'surface', 'variation', 'in', 'how', 'a', 'certain', 'meaning', 'is', 'expressed,', 'UCCA', 'has', 'a', 'clear', 'mapping', 'between', 'form', 'and', 'meaning', 'and', 'a', 'modular', 'architecture,', 'and', 'DRSs', 'ground', 'natural', 'language', 'meaning', 'in', 'first-order', 'logic,', 'by', 'explicitly', 'representing', 'the', 'scopes', 'of', 'negation,', 'quantification,', 'disjunction,', 'etc.', 'In', 'this', 'paper,', 'we', 'focus', 'on', 'parsing', 'to', 'DRSs.']",41,"[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b1735d05-c237-41f8-9eb3-508f52139625,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['Better external memory suffix array construction'],['2005'],['R Dementiev;J Kärkkäinen;J Mehnert;P Sanders'],single,"['The', 'size', 'of', 'aligned', 'corpora', 'that', 'we', 'were', 'able', 'to', 'use', 'was', 'limited', 'by', 'available', 'memory.', 'The', 'memory', 'footprint', 'chiefly', 'consists', 'of', 'the', 'text', 'and', '8', 'bytes/word', 'to', 'hold', 'a', 'word', 'position', 'array,', 'and', 'the', 'suffix', 'array.', 'It', 'is', 'possible', 'that', 'algorithms', 'for', 'external', 'suffix', 'array', 'construction', 'could', 'be', 'employed,', 'such', 'as', 'the', 'DC3', 'algorithm', 'by', '<ref type=""single"">Dementiev et al. (2005)</ref>', 'so', 'that', 'even', 'larger', 'corpora', 'could', 'be', 'used.']",56,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3]"
b1b2f3bc-c051-4479-ac08-e71afb2a51f5,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['French timebank: an isotimeml annotated reference corpus'],['2011'],['André Bittar;Pascal Amsili;Pascal Denis;Laurence Danlos'],single,"['4.', 'For', 'French,', 'we', 'use', 'the', 'French', 'TimeBank', 'as', 'it', 'is', 'the', 'ISO-TimeML', 'annotated', 'reference', 'corpus', 'for', 'event', 'annotation', 'tasks', '<ref type=""single"">(Bittar et al., 2011).</ref>', 'The', 'corpus', 'consists', 'of', '16,208', 'tokens', 'and', '2,100', 'event', 'mentions.']",20,"[0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
b1b3220f-8356-4cc4-bb5f-f4afa49642e6,Entity Attribute Relation Extraction with Attribute-Aware Embeddings,2020,Dan Iter;Xiao Yu;Fangtao Li,['Biperpedia: An ontology for search applications'],['2014'],['Rahul Gupta;Alon Halevy;Xuezhi Wang;Steven Whang;Fei Wu'],single,"['(1)', 'we', 'compare', 'extracted', 'entity-attribute', 'pairs', 'to', 'those', 'extracted', 'by', 'the', 'previous', 'state-ofthe-art', 'Biperpedia', '<ref type=""single"">(Gupta et al., 2014)</ref>', 'and', '(2)', 'we', 'report', 'precision', 'over', 'a', 'small', 'set', 'of', 'longtail', 'entityattribute', 'pairs', 'that', 'did', 'not', 'appear', 'in', 'our', 'distant', 'supervision.']",14,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
b220a762-92a1-4f29-a552-27700c0d909d,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,"['Enriching word vectors with subword information', 'Loss in translation: Learning bilingual word mapping with a retrieval criterion']","['2017', '2018']","['Piotr Bojanowski;Edouard Grave;Armand Joulin;Tomas Mikolov', 'Armand Joulin;Piotr Bojanowski;Tomas Mikolov;Hervé Jégou;Edouard Grave']",group,"['For', 'each', 'language,', 'I', 'use', 'the', 'fastText', 'aligned', 'word', 'vectors', '<ref type=""group"">(Bojanowski et al., 2017, Joulin et al., 2018),</ref>', '3', 'limiting', 'the', 'vocabulary', 'set', 'V', 'to', 'the', 'top', '200,000', 'vectors', 'by', 'frequency.', 'For', 'the', 'target', 'word', 'vocabulary', 'W,', 'I', 'take', 'the', '10,000', 'most', 'frequent', 'wordforms', 'among', 'all', 'attributive', 'adjectives', 'extracted', 'from', 'the', 'entire', 'CoNLL', 'Wikipedia', 'dataset.']",10,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
b2dfd029-eca8-4132-8c33-cea4cc085b8d,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Efficient transformers: A survey'],['2009'],['Yi Tay;M Dehghani;Dara Bahri;Donald Metzler'],single,"['To', 'alleviate', 'this,', 'past', 'work', 'proposed', 'approximation', 'methods', 'for', 'the', 'computation', 'of', 'softmax(QK', ').', 'One', 'major', 'line', 'of', 'research', 'focused', 'on', 'sparse', 'attention', 'variants,', 'where', 'only', 'a', 'few', 'similarity', 'scores', 'are', 'computed', 'per', 'query,', 'and', 'the', 'rest', 'are', 'ignored.', 'Methods', 'differ', 'by', 'which', 'query-key', 'pairs', 'are', 'selected', '<ref type=""group"">(Child et al., 2019, Ye et al., 2019, Qiu et al., 2020, Roy et al., 2021, Kitaev et al., 2020, Beltagy et al., 2020, Gupta and Berant, 2020, Vyas et al., 2020).</ref>', 'A', 'second', 'line', 'of', 'research', 'explored', 'dense', 'variants', '<ref type=""group"">(Katharopoulos et al., 2020, Wang et al., 2020, Bello, 2021, Tay et al., 2020a)</ref>', '(cf.', '<ref type=""single"">(Tay et al., 2020b)</ref>', 'for', 'a', 'survey).', 'For', 'example,', 'instead', 'of', 'computing', 'the', 'attention', 'scores', 'exactly', 'for', 'only', 'a', 'small', 'number', 'of', 'querykey', 'pairs,', '<ref type=""single"">(Choromanski et al., 2021)</ref>', 'compute', 'an', 'approximation', 'of', 'scores', 'for', 'all', 'pairs.']",58,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
b2e8e9c6-9d9e-4a07-900c-7b5207f086aa,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['Wordnet-based lexical simplification of a document'],['2012'],['Rebecca Thomas;Sven Anderson'],single,"['A', 'related', 'area', 'of', 'LCP', 'is', 'CWI.', 'Early', 'studies', 'on', 'CWI', 'either', 'attempt', 'to', 'simplify', 'all', 'words', '<ref type=""single"">(Thomas and Anderson, 2012)</ref>', 'or', 'set', 'a', 'frequency-based', 'threshold', '<ref type=""single"">(Biran et al., 2011).</ref>', '<ref type=""single"">Shardlow (2013)</ref>', 'indicates', 'that', 'a', 'classification-based', 'method', 'to', 'CWI', 'is', 'the', 'most', 'promising', 'one.', 'Most', 'of', 'the', 'teams', 'participating', 'in', 'two', 'CWI', 'shared', 'tasks', 'also', 'use', 'classification', 'approaches', 'with', 'extensive', 'feature', 'engineering.']",17,"[0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b30d1dc5-0f24-48be-aa2a-01b0939f0915,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Sequence to sequence learning with neural networks'],['2014'],['Ilya Sutskever;Oriol Vinyals;Quoc V Le'],single,"['Neural', 'methods', 'for', 'abstractive', 'summarization', '<ref type=""group"">(Rush et al., 2015, Nallapati et al., 2016, Chopra et al., 2016, Lewis et al., 2020, Zhang et al., 2020)</ref>', 'formulate', 'summarization', 'as', 'a', 'sequenceto-sequence', '(Seq2Seq)', 'problem', '<ref type=""single"">(Sutskever et al., 2014),</ref>', 'learning', 'to', 'generate', 'the', 'summary', 'in', 'an', 'autoregressive', 'manner.', 'Such', 'models', 'are', 'commonly', 'trained', 'with', 'maximum', 'likelihood', 'estimation', '(MLE),', 'maximizing', 'predictive', 'probability', 'of', 'the', 'reference', 'output', 'given', 'the', 'gold', 'sub-sequence', 'before', 'it.', 'However,', 'during', 'inference', 'the', 'model', 'must', 'also', 'generate', 'the', 'output', 'based', 'on', 'possibly', 'erroneous', 'previous', 'steps.', 'This', 'can', 'hurt', 'model', 'performance,', 'a', 'phenomenon', 'often', 'called', 'exposure', 'bias', '<ref type=""group"">(Bengio et al., 2015, Ranzato et al., 2016).</ref>', 'To', 'maintain', 'reasonable', 'performance', 'even', 'in', 'the', 'case', 'of', 'a', 'sub-sequence', 'with', 'errors,', 'we', 'argue', 'that', 'the', 'model', 'must', 'accurately', 'estimate', 'relative', 'quality', 'of', 'different', 'generated', 'outputs,', 'since', 'effective', 'inference', 'requires', 'comparison', 'among', 'these', 'candidates.']",13,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b348bb17-8fe0-4f10-bcc1-20e2fedb48a9,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['Word-based partial annotation for efficient corpus construction'],['2010'],['N Graham;S Mori'],single,"['To', 'compare', 'the', 'linguistic', 'annotation', 'performance,', 'we', 'prepared', 'a', 'pipeline', 'system,', 'i.e.,', 'ASR', 'followed', 'by', 'an', 'NLP-based', 'linguistic', 'annotation.', 'In', 'the', 'pipeline', 'system,', 'the', 'separated', 'model', 'of', 'CTC+Transformer', 'first', 'predicts', 'graphemic', 'sequences.', 'Then,', 'the', 'linear', 'SVM', 'with', 'L2', 'normalization,', 'trained', 'using', 'KyTea', '<ref type=""single"">(Graham and Mori, 2010),</ref>', 'predicts', 'word', 'boundaries', 'and', 'linguistic', 'annotation', 'from', 'the', 'predicted', 'sequences.', 'To', 'train', 'KyTea,', 'we', 'only', 'used', 'the', 'transcriptions', 'in', 'the', 'ASR', 'training', 'set', 'to', 'perform', 'a', 'fair', 'comparison', 'to', 'the', 'proposed', 'method.']",42,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
b353dc34-50ed-47f7-b567-1ab0993d2690,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,"['Situated language learning via interactive narratives', 'Grounded cognition. Annual Review of Psychology', 'Experience grounds language']","['2021', '2008', '2020']","['Prithviraj Ammanabrolu;unk Mark O Riedl', 'Lawrence Barsalou', 'Yonatan Bisk;Ari Holtzman;Jesse Thomason;Jacob Andreas;Yoshua Bengio;Joyce Chai;Mirella Lapata;Angeliki Lazaridou;Jonathan May;Aleksandr Nisnevich;Nicolas Pinto;Joseph Turian']",group,"['A', 'key', 'hypothesis', 'in', 'the', 'pursuit', 'towards', 'creating', 'goal-driven', 'natural', 'language-based', 'agents', 'posits', 'that', 'interactivity', 'and', 'environment', 'grounding', 'is', 'critical', 'for', 'effective', 'language', 'learning', '<ref type=""group"">(Barsalou, 2008, Bisk et al., 2020, Ammanabrolu and Riedl, 2021).</ref>', 'Text', 'games', 'provide', 'a', 'platform', 'on', 'which', 'to', 'interactively', 'train', 'agents', 'that', 'can', 'both', 'act', 'and', 'speak', 'in', 'a', 'situated', 'manner-producing', 'language', 'that', 'is', 'both', 'goal-driven', 'and', 'contextually', 'relevant.']",24,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
b372ef82-423a-4982-8816-d96d16e33be5,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['PLMs', 'such', 'as', 'BERT', '(Bidirectional', 'Encoder', 'Representations', 'from', 'Transformers)', 'use', 'the', 'encoder', 'structure', 'of', 'the', 'Transformer', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'for', 'deep', 'self-supervised', 'learning,', 'which', 'requires', 'task-specific', 'fine-tuning.', 'In', 'this', 'paper,', 'the', 'downstream', 'task', 'to', 'predict', 'the', 'complexity', 'scores,', 'a', 'real-value', 'in', 'the', 'range', 'of', '[0,1],', 'of', 'given', 'words.']",16,"[2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b3777c20-bb10-45b1-aeac-3c6673d578ff,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Machine translation and monolingual postediting: The AFRL WMT-14 system'],['2014'],['L Schwartz;T Anderson;J Gwinnup;K Young'],single,"['We', 'hypothesize', 'that', 'any', 'effects', 'of', 'word', 'alignment', 'visualization', 'on', 'post-editing', 'may', 'be', 'dependent', 'on', 'the', 'quality', 'of', 'the', 'underlying', 'machine', 'translations', 'displayed', 'to', 'the', 'post-editors.', 'Because', 'we', 'care', 'about', 'the', 'adequacy', 'of', 'post-edited', 'translations,', 'we', 'consider', 'actual', 'human', 'judgements', 'to', 'be', 'preferable', 'to', 'automated', 'metrics', 'such', 'as', 'BLEU', '<ref type=""single"">(Papineni et al., 2002),</ref>', 'which', 'at', 'best', 'serve', 'as', 'a', 'flawed', 'proxy', 'for', 'human', 'judgements.', 'Instead,', 'following', '<ref type=""single"">Albrecht et al. (2009)</ref>', 'and', '<ref type=""single"">Schwartz et al. (2014),</ref>', 'we', 'therefore', 'obtained', 'human', 'judgements', 'of', 'translation', 'adequacy', 'for', 'the', 'Russian-English', 'and', 'Spanish-English', 'machine', 'translations', 'used', 'in', 'this', 'study.']",65,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
b3d7f686-942b-466f-b815-d6b745522af0,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Machine translation and monolingual postediting: The AFRL WMT-14 system'],['2014'],['L Schwartz;T Anderson;J Gwinnup;K Young'],single,"['Our', 'post-editing', 'interface', 'can', 'be', 'seen', 'in', 'Figure', '1', 'above.', 'Each', 'text', 'was', 'presented', 'to', 'posteditors', 'in', 'one', 'of', 'two', 'variant', 'modalities', '-word-level', 'alignment', 'links', 'could', 'either', 'be', 'visualized', 'or', 'left', 'absent.', 'In', 'both', 'variants,', 'each', 'source', 'language', 'segment', 'was', 'presented', 'along', 'with', 'the', 'corresponding', 'machine', 'translated', 'English', 'segment,', 'a', 'text', 'field', '(initially', 'populated', 'with', 'the', 'machine', 'translated', 'segment)', 'where', 'the', 'post-editor', 'could', 'make', 'changes', 'was', 'also', 'presented.', 'In', 'the', 'first', 'variant,', 'the', 'word-level', 'alignment', 'links', 'produced', 'by', 'the', 'machine', 'translation', 'decoder', '(Moses', 'for', 'Russian-English,', 'Bing', 'Translator', 'for', 'Spanish-English)', 'were', 'graphically', 'displayed,', 'linking', 'source', 'words', 'to', 'their', 'corresponding', 'machine', 'translated', 'target', 'words.', 'In', 'the', 'second', 'variant,', 'the', 'word-level', 'alignment', 'links', 'were', 'omitted', 'from', 'the', 'visualization', 'interface.', 'Figure', '2:', 'Percentage', 'of', 'segments', 'judged', 'to', 'be', 'in', 'each', 'adequacy', 'category.', 'For', 'each', 'language', 'pair,', 'we', 'report', 'percentages', 'for', 'raw', '(unedited)', 'machine', 'translation', 'output,', 'as', 'well', 'as', 'output', 'postedited', 'by', 'a', 'bilingual', 'post-editor', 'with', 'access', 'to', 'alignments', 'and', 'without', 'access', 'to', 'alignments.', 'For', 'Russian-English,', 'we', 'additionally', 'report', 'percentages', 'for', 'output', 'post-edited', 'by', 'a', 'monolingual', 'post-editor', '<ref type=""single"">(Schwartz et al., 2014)</ref>', 'with', 'access', 'to', 'alignments.']",172,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1]"
b3e36325-b8e2-4391-b4dd-9373ff72e989,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,"['Multilingual tokenisation, tagging, and lemmatisation with totale']",['2006'],['Erjavec Tomaž'],single,"['A', 'research', 'of', 'already', 'available', 'and', 'accessible', 'language', 'processing', 'tools', 'and', 'materials,', 'mostly', 'corpora,', 'revealed', 'that', 'there', 'is', 'a', 'reasonably', 'big', 'amount', 'of', 'work', 'already', 'done', 'for', 'Slovenian', 'language,', 'less', 'for', 'Serbian.', 'The', 'tools', 'for', 'Slovenian', 'language', 'are', '(reasonable', 'or', 'even', 'good', 'quality):', 'part', 'of', 'speech', 'tagger', '<ref type=""single"">(Erjavec, 2006)</ref>', 'and', '<ref type=""single"">(Brants, 2000),</ref>', 'lemmatizer', '<ref type=""single"">(Erjavec, 2006)</ref>', 'and', '<ref type=""single"">(Erjavec et al., 2004),</ref>', 'stemmer', '<ref type=""single"">(Popovič et al., 1992)</ref>', 'and', '<ref type=""single"">(Vilar et al., 2000),</ref>', 'none', 'of', 'these', 'tools', 'exists', 'for', 'Serbian', 'language.', 'Both', 'languages', 'have', 'solid', 'monolingual', 'reference', 'corpora', '(going', 'into', 'hundreds', 'of', 'millions)', 'and', 'a', 'small', 'bilingual', 'corpus', '<ref type=""single"">(Erjavec, 2004)</ref>', 'that', 'was', 'used', 'mostly', 'for', 'evaluation', 'purposes.']",47,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b425d550-0f15-4c6f-9f23-912efd02edef,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['unknown'],['unknown'],['unknown'],single,"['As', '<ref type=""single"">Kumar et al. (2021)</ref>', 'showed,', 'they', 'might', 'associate', 'words', 'that', 'are', 'not', 'in', 'a', 'strong', 'direct', 'connection,', 'but', 'are', 'only', 'indirectly', 'related', '(e.g.', 'religion', 'is', 'not', 'related', 'to', 'tree,', 'but', 'both', 'are', 'related', 'to', 'Christmas,', 'therefore', 'religion', 'could', 'be', 'a', 'clue', 'for', 'tree).']",1,"[2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
b4bc1895-8c4a-4fe3-9524-4db80703127e,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Normalized (pointwise) mutual information in collocation extraction'],['2009'],['Gerlof Bouma'],single,"['A', 'standard', 'and', 'probably', 'the', 'most', 'common', 'method', 'to', 'calculate', 'word', 'relatedness', 'from', 'co-occurrences', 'is', 'computing', 'the', 'pointwise', 'mutual', 'information', '(PMI)', 'of', 'two', 'words.', 'However,', 'PMI', 'has', 'wellknown', 'shortcomings,', 'such', 'as', 'overvaluing', 'the', 'relatedness', 'of', 'rare', 'words,', 'and', 'lacking', 'a', 'fixed', 'upper', 'and', 'lower', 'bound.', '<ref type=""single"">Bouma (2009)</ref>', 'introduced', 'normalized', 'PMI', 'as', 'PMI', 'norm', '(x,', 'y)', '=', 'ln', 'p(x,', 'y)', 'p(x)p(y)', '−', 'ln', 'p(x,', 'y),']",45,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
b4f389d3-a040-4f44-a144-b0a6fe8eca0b,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,['unknown'],['2014'],['J Ian;Jean Goodfellow;Mehdi Pouget-Abadie;Bing Mirza;David Xu;Sherjil Warde-Farley;Aaron Ozair;Yoshua Courville;unk Bengio'],single,"['As', 'training', 'loss,', 'we', 'have', 'used', 'a', 'non-saturating', 'GAN', 'loss', 'function', '<ref type=""single"">[7],</ref>', 'that,', 'considering', 'the', 'doublediscriminator', 'model,', 'is', 'extended', 'as:lD', '=', '1', 'm', 'm', 'X', 'i=1', '\uf8ff✓', 'log(D', 'S', '(xr))', '+', 'log(1', 'D', 'S', '(G(xz)))', '◆', '+', '✓', 'log(D', 'T', '(xr))', '+', 'log(1', 'D', 'T', '(G(xz)))◆', '1', 'All', 'the', 'training', 'information', 'and', 'hyperparameters', 'are', 'described', 'in', 'Appendix', 'D.', 'We', 'will', 'release', 'all', 'our', 'code', 'publicly', 'after', 'the', 'anonymity', 'period.', '1:', 'CTERM-GAN', 'architecture', 'lG', '=', '1', 'm', 'm', 'X', 'i=1', '\uf8ff', 'log(D', 'S', '(G(xz)))', 'log(D', 'T', '(G(xz)))where', 'is', 'a', 'hyperparameter', 'that', 'assigns', 'a', 'relative', 'weight', 'to', 'the', 'topic', 'discriminator', 'with', 'respect', 'to', 'the', 'syntax', 'one.', 'plays', 'an', 'important', 'role', 'during', 'training', 'since,', 'if', 'it', 'is', 'too', 'low,', 'the', 'model', 'ignores', 'the', 'conditioning', 'due', 'to', 'the', 'limited', 'penalty.', 'Conversely,', 'a', 'too', 'high', 'a', 'value', 'would', 'give', 'too', 'much', 'importance', 'to', 'the', 'conditioning,', 'affecting', 'the', 'quality', 'of', 'the', 'generated', 'sentence.']",11,"[0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b50958fb-9a20-46df-be27-be559c09d624,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['unknown'],['unknown'],['unknown'],single,"['(a)', 'the', 'back', 'vowels', 'a,', 'u,', 'o', 'and', 'the', 'diphthong', 'au,', 'can', 'be', 'fronted', '<ref type=""single"">(umlauted)</ref>']",14,"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
b5111a90-2ebd-40b5-9ecb-ae25ba19ae1e,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['langid. py: An off-the-shelf language identification tool'],['2012'],['Marco Lui;Timothy Baldwin'],single,"['Langage', 'identification', '(langid)', '<ref type=""single"">(Lui and Baldwin, 2012</ref>', '):', 'We', 'use', 'fastText', '5', 'for', 'language', 'identification', 'filtering,', 'which', 'removes', 'sentence', 'pairs', 'that', 'are', 'not', 'predicted', 'as', 'the', 'correct', 'language', 'on', 'either', 'side.']",3,"[0, 0, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
b5b01830-7534-4f4c-8dcb-5abfa3f4ce0e,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['Figure', '7', 'shows', 'the', 'overall', 'architecture', 'and', 'training', 'pipeline-our', 'reinforcement', 'learning', 'pipeline', 'is', 'unchanged', 'from', 'that', 'shown', 'in', '<ref type=""single"">Ammanabrolu et al. (2021)</ref>', 'with', 'the', 'exception', 'of', 'the', 'curriculum', 'of', 'quests', 'performed', 'by', 'the', 'agent', 'and', 'the', 'way', 'the', 'speech', 'rewards', 'are', 'designed.', 'An', 'encoder', 'first', 'takes', 'in', 'information', 'about', 'setting,', 'persona,', 'motivation', 'for', 'a', 'single', 'character', 'then', 'passes', 'it', 'onto', 'a', 'switch', 'module.', 'This', 'switch', 'module', 'is', 'a', 'meta', 'policy', 'that', 'decides', 'if', 'an', 'agent', 'should', 'act', 'or', 'talk', 'and', 'is', 'trained', 'to', 'mimic', 'how', 'often', 'human', 'experts', 'act', 'or', 'talk', 'while', 'performing', 'quests', 'via', 'demonstrations.', 'Two', 'separate', 'policy', 'networks', 'make', 'a', 'decision', 'on', 'which', 'action', 'to', 'perform', 'or', 'dialogue', 'to', 'say', 'given', 'the', 'current', 'context', 'and', 'a', 'single', 'shared', 'critic', 'attempts', 'to', 'measure', 'the', 'value', 'of', 'taking', 'an', 'action', 'in', 'a', 'particular', 'state.']",18,"[3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b5cc6dca-1880-42c1-8c46-5a843dcf6e50,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Attention is All you Need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Lukasz Kaiser;Illia Polosukhin'],single,"['Our', 'model', 'f', 'θ', 'to', 'produce', 'these', 'embeddings', 'is', 'shown', 'in', 'Figure', '2:', 'it', 'takes', 'as', 'input', 'the', 'mention', 'm', 'and', 'its', 'context', 's', 'and', 'predicts', 'probabilities', 'for', 'predefined', 'entity', 'types', 'T.', 'This', 'is', 'a', 'Transformer-based', 'typing', 'model', 'following', 'the', 'BERT', 'model', 'presented', 'in', '<ref type=""single"">Onoe and Durrett (2019).</ref>', 'First,', 'a', 'Transformerbased', 'encoder', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'maps', 'the', 'input', 'variables,', 'm', 'and', 's,', 'to', 'an', 'intermediate', 'vector', 'repre-sentation.', 'A', 'type', 'embedding', 'layer', 'then', 'projects', 'the', 'intermediate', 'representation', 'to', 'a', 'vector', 'whose', 'dimensions', 'correspond', 'to', 'the', 'entity', 'types', 'T.', 'Finally,', 'we', 'apply', 'a', 'sigmoid', 'function', 'on', 'each', 'real-valued', 'score', 'in', 'the', 'vector', 'to', 'obtain', 'the', 'posterior', 'probabilities', 'that', 'form', 'our', 'entity', 'representation', 't', '(top', 'of', 'the', 'figure).']",49,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b60da26a-b940-43df-87a4-20271e6e9eb4,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties'],['2021'],['Kathleen Siminyu;Xinjian Li;Antonios Anastasopoulos;David Mortensen;Michael Marlo;Graham Neubig'],single,"['Regarding', 'the', 'conversion', 'process', 'of', 'text', 'and', 'audio', 'data,', 'we', 'leverage', 'recent', 'advances', 'to', 'transliterate', 'this', 'data', 'into', 'corresponding', 'sounds', 'represented', 'by', 'IPA', 'phonetic', 'symbols.', 'This', 'transliteration', 'is', 'possible', 'for', 'speech/audio', 'data', 'using', 'tools', 'such', 'as', 'the', 'Allosaurus', 'universal', 'phone', 'recognizer,', 'which', 'can', 'be', 'applied', 'without', 'additional', 'training', 'to', 'any', 'language', '<ref type=""single"">(Li et al., 2020),</ref>', 'though', 'it', 'can', 'benefit', 'from', 'fine-tuning', '<ref type=""single"">(Siminyu et al., 2021).</ref>', 'To', 'convert', 'text', 'data', 'to', 'phonemes', 'we', 'can', 'use', 'tools', 'such', 'as', 'the', 'Epitran', 'grapheme-to-phoneme', 'converter', '<ref type=""single"">(Mortensen et al., 2018),</ref>', 'which', 'is', 'specifically', 'designed', 'to', 'provide', 'precise', 'phonetic', 'transliterations', 'in', 'low-resource', 'scenarios.']",58,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b6545c9b-d530-49cf-8599-1b0dfb8abba8,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,['Detecting hate speech on the world wide web'],['2012'],['William Warner;Julia Hirschberg'],single,"['Before', 'the', 'advent', 'in', 'research', 'pertaining', 'to', 'toxic', 'texts,', '<ref type=""single"">Warner and Hirschberg (2012)</ref>', 'modeled', 'hate', 'speech', 'as', 'a', 'word', 'sense', 'disambiguation', 'problem', 'where', 'SVM', 'was', 'used', 'for', 'classification', 'of', 'data.', '<ref type=""single"">Mehdad and Tetreault (2016)</ref>', 'used', 'RNN', 'Language', 'Model', 'with', 'character', 'and', 'token', 'based', 'methods', 'to', 'classify', 'the', 'text.', 'Recently,', 'however,', 'toxic', 'text', 'detection', 'has', 'garnered', 'a', 'lot', 'of', 'attention', '<ref type=""group"">(Nobata et al., 2016, Park and Fung, 2017, Pavlopoulos et al., 2017, Wulczyn et al., 2017).</ref>', 'The', 'increase', 'in', 'offensive', 'language', 'research', 'can', 'partly', 'be', 'credited', 'to', 'various', 'workshops', 'such', 'as', 'Abusive', 'Language', 'Online', '1', '<ref type=""single"">(Waseem et al., 2017),</ref>', 'as', 'well', 'as', 'other', 'fora,', 'such', 'as', 'GermEval', 'for', 'German', 'texts,', '2', 'or', 'TRAC', '<ref type=""single"">(Kumar et al., 2018)</ref>', 'and', 'Kaggle', 'challenges', '3.']",9,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b65c467e-f045-48ec-abb9-7655f2d95d28,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,['unknown'],['2021'],['Ruiqing Zhang;Xiyang Wang;Chuanqiang Zhang;Zhongjun He;Hua Wu;Zhi Li;Haifeng Wang;Ying Chen;Qinfei Li'],single,"['We', 'participate', 'in', 'the', 'Chinese-English', 'streaming', 'transcription', 'track,', 'where', 'each', 'sentence', 'is', 'broken', 'into', 'lines', 'whose', 'length', 'is', 'incremented', 'by', 'one', 'word', 'until', 'the', 'sentence', 'is', 'completed.', 'An', 'example', 'is', 'shown', 'in', 'Table', '1.', 'For', 'pre-training,', 'we', 'use', 'the', 'CWMT21', 'parallel', 'corpus', '(9.1M)', '2,', 'and', 'we', 'fine-tune', 'the', 'pretrained', 'model', 'using', 'transcription', 'and', 'translation', 'of', 'the', 'BSTC', '(Baidu', 'Speech', 'Translation', 'Corpus,37K)', '<ref type=""single"">(Zhang et al., 2021),</ref>', 'shown', 'in', 'Table', '2.', 'We', 'also', 'use', ""CWMT's"", '10M', 'Chinese', 'monolingual', 'data', 'for', 'synthetic', 'data', 'generation.']",61,"[3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b6a61170-ede6-47ae-aab9-c5fc9cd9b1c5,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,['BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['DeepBlueAI.', 'The', 'model', 'presented', 'by', '<ref type=""single"">Pan et al. (2021)</ref>', 'represents', 'the', 'top-performing', 'system', 'in', 'this', 'edition', 'of', 'the', 'shared', 'task', 'with', 'a', 'NDCG', 'score', 'of', '0.820', '-representing', 'a', 'substantial', '32%', 'improvement', 'when', 'compared', 'to', 'the', 'tf.idf', 'baseline.', 'The', 'model', 'employs', 'a', 'two', 'step', 'retrieval', 'strategy.', 'In', 'the', 'first', 'step,', 'a', 'pre-trained', 'language', 'model', 'is', 'finetuned', 'to', 'retrieve', 'the', 'top-K', '(K', '&gt,', '100)', 'relevant', 'facts', 'for', 'each', 'question', 'and', 'answer', 'pair.', 'Subsequently,', 'the', 'same', 'architecture', 'is', 'adopted', 'to', 'build', 'a', 're-ranking', 'model', 'to', 'refine', 'the', 'list', 'of', 'the', 'top-K', 'candidate', 'facts.', 'The', 'authors', 'propose', 'the', 'use', 'of', 'a', 'triplet', 'loss', 'for', 'the', 'fine-tuning', 'of', 'the', 'model.', 'Specifically,', 'the', 'triplet', 'loss', 'minimizes', 'the', 'distance', 'between', 'an', 'anchor', 'and', 'a', 'positive', 'example,', 'while', 'maximizing', 'the', 'distance', 'between', 'the', 'same', 'anchor', 'and', 'a', 'negative', 'example.', 'The', 'team', 'treats', 'question', 'and', 'correct', 'answer', 'as', 'the', 'anchor,', 'while', 'the', 'facts', 'annotated', 'with', 'high', 'ratings', 'are', 'adopted', 'as', 'positive', 'examples.', 'Different', 'experiments', 'are', 'conducted', 'with', 'three', 'negative', 'sampling', 'strategies', 'for', 'retrieval', 'and', 're-ranking.', 'The', 'best', 'results', 'are', 'obtained', 'when', 'sampling', 'negative', 'examples', 'from', 'the', 'same', 'tables', 'of', 'highly', 'relevant', 'facts.', 'The', 'authors', 'find', 'that', 'the', 'best', 'performance', 'is', 'obtained', 'when', 'averaging', 'the', 'results', 'from', 'RoBERTa', '<ref type=""single"">(Liu et al., 2019)</ref>', 'facts', 'to', 'the', 'question', 'using', 'BM25', 'vectors', 'and', 'then', 'update', 'the', 'query', 'vector', 'via', 'a', 'max', 'operation.', 'The', 'iterative', 'retrieval', 'step', 'is', 'performed', 'until', 'a', 'list', 'of', 'K', '=', '200', 'facts', 'is', 'selected', 'from', 'the', 'knowledge', 'base.', 'Subsequently,', 'the', 'top', 'K', 'explanation', 'facts', 'are', 're-ranked', 'using', 'language', 'models.', 'The', 'best', 'model', 'consists', 'of', 'an', 'ensemble', 'of', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'and', 'SciBERT', '<ref type=""single"">(Beltagy et al., 2019).</ref>', 'These', 'models', 'are', 'fine-tuned', 'to', 'predict', 'the', 'target', 'explanatory', 'relevance', 'ratings', 'using', 'the', 'following', 'input:', 'Question', '+', 'Answer', '[SEP]', 'Explanation.', 'Specifically,', 'the', 'authors', 'frame', 'the', 'problem', 'as', 'a', 'regression', 'via', 'mean', 'squared', 'error', 'loss.', 'The', 'ensemble', 'is', 'achieved', 'by', 'linearly', 'combining', 'the', 'scores', 'of', 'the', 'models.', 'The', 'authors', 'reported', 'two', 'negative', 'results', 'obtained', 'using', 'a', 'two-stage', 'approach', 'and', 'different', 'negative', 'sampling', 'techniques.', 'In', 'the', 'two-stage', 'approach,', 'the', 'facts', 'were', 'firstly', 'categorized', 'using', 'binary', 'scores', 'to', 'discriminate', 'between', 'relevant', 'and', 'irrelevant', 'sentences,', 'and', 'then', 're-ranked', 'predicting', 'the', 'target', 'explanatory', 'relevance', 'rating.', 'Regarding', 'the', 'negative', 'sampling', 'strategy,', 'the', 'authors', 'noticed', 'that', 'highest', 'percentage', 'of', 'errors', 'occurring', 'at', 'inference', 'time', 'was', 'due', 'to', 'irrelevant', 'facts', 'that', 'are', 'lexically', 'close', 'to', 'highly', 'relevant', 'explanation', 'sentences.', 'They', 'attempted', 'to', 'alleviate', 'this', 'problem', 'by', 'randomly', 'sampling', 'facts', 'from', 'the', 'knowledge', 'base', 'and', 'retrieving', 'close', 'negative', 'examples', 'during', 'training.', 'Neither', 'of', 'these', 'two', 'methods', 'resulted', 'in', 'significant', 'improvements.']",253,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b6c316e4-db7e-437e-af12-a6d506555b79,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['BERT rediscovers the classical NLP pipeline'],['2019'],['Ian Tenney;Dipanjan Das;Ellie Pavlick'],single,"['If', 'we', 'fine-tune', 'a', 'RoBERTa-large', 'model', 'on', 'Quoref,', 'it', 'achieves', '78', 'F1', 'score', 'while', 'the', 'estimated', 'human', 'performance', 'is', 'around', '93', 'F1', 'score', '<ref type=""single"">(Dasigi et al., 2019).</ref>', 'This', 'high', 'performance,', 'given', 'that', 'RoBERTa', 'can', 'only', 'predict', 'continuous', 'span', 'answers', 'while', 'Quoref', 'also', 'contains', 'discontinuous', 'answers,', 'indicates', 'that', 'either', '(1)', 'Quoref', 'presents', 'coreference-aware', 'QA', 'very', 'well', 'so', 'that', 'the', 'model', 'can', 'properly', 'learn', 'coreference', 'reasoning', 'from', 'the', 'training', 'data,', '(2)', 'pretrained', 'transformer-based', 'models', 'have', 'already', 'learned', 'coreference', 'reasoning', 'during', 'their', 'pre-training,', 'e.g.,', 'as', 'suggested', 'by', '<ref type=""single"">Tenney et al. (2019)</ref>', 'and', '<ref type=""single"">Clark et al. (2019b),</ref>', 'or', '(3)', 'coreference', 'reasoning', 'is', 'not', 'necessarily', 'required', 'for', 'solving', 'most', 'examples.']",81,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
b721d2d7-6e0b-4a57-b09a-02dc444bd6ba,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,"['Unlearn dataset bias in natural language inference by fitting the residual', ""Don't take the easy way out: Ensemble based methods for avoiding known dataset biases""]","['2019', '2019']","['He He;Sheng Zha;Haohan Wang', 'Christopher Clark;Mark Yatskar;Luke Zettlemoyer']",group,"['In', 'the', 'second', 'approach,', 'they', 'first', 'recognize', 'examples', 'that', 'contain', 'artifacts,', 'and', 'use', 'this', 'knowledge', 'in', 'the', 'training', 'objective', 'to', 'either', 'skip', 'or', 'downweight', 'biased', 'examples', '<ref type=""group"">(He et al., 2019, Clark et al., 2019a),</ref>', 'or', 'to', 'regularize', 'the', 'confidence', 'of', 'the', 'model', 'on', 'those', 'examples', '<ref type=""single"">(Utama et al., 2020a).</ref>', 'The', 'use', 'of', 'this', 'information', 'in', 'the', 'training', 'objective', 'improves', 'the', 'robustness', 'of', 'the', 'model', 'on', 'adversarial', 'datasets', '<ref type=""group"">(He et al., 2019, Clark et al., 2019a, Utama et al., 2020a),</ref>', 'i.e.,', 'datasets', 'that', 'contain', 'counterexamples', 'in', 'which', 'relying', 'on', 'the', 'bias', 'results', 'in', 'an', 'incorrect', 'prediction.', 'In', 'addition,', 'it', 'can', 'also', 'improve', 'in-domain', 'performances', 'as', 'well', 'as', 'generalization', 'across', 'various', 'datasets', 'that', 'represent', 'the', 'same', 'task', '<ref type=""group"">(Wu et al., 2020a, Utama et al., 2020b).</ref>']",26,"[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b77e55d0-fd13-44f7-b6e5-d6cf34131cfa,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,"['Chinese wordnet : design, implementation, and application of an infrastructure for cross-lingual knowledge processing']",['2010'],['Chu-Ren Huang;S Hsieh;Jia-Fei Hong;Yun-Zhu Chen;I Su;Yong-Xiang Chen;Sheng-Wei Huang'],single,"['For', 'the', 'definition', 'generation', 'dataset,', 'we', 'use', 'the', 'Chinese', 'WordNet', '(CWN)', '<ref type=""single"">(Huang et al., 2010),</ref>', 'which', 'is', 'a', 'semantic', 'lexicon', 'aiming', 'to', 'provide', 'a', 'knowledge', 'base', 'of', 'sense', 'distinction.', '2', 'We', 'use', 'the', 'corresponding', 'words,', 'contexts,', 'and', 'definitions', 'in', 'CWN', 'for', 'the', 'definition', 'generation', 'task.', 'We', 'split', 'the', 'entire', 'dataset', 'into', 'training,', 'validation,', 'and', 'test', 'sets', 'roughly', 'according', 'to', 'the', 'ratio', 'of', '8:1:1.', 'For', 'the', 'simple', 'text', 'corpus,', 'we', 'extract', '58,867', 'sentences', 'from', 'a', 'number', 'of', 'primary', 'level', 'Chinese', 'as', 'Second', 'Language', 'textbooks,', 'with', 'an', 'average', 'sentence', 'length', 'of', '14.62.']",11,"[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b78925ff-d230-4202-b0c7-af12ed88c44a,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,"['Improving neural machine translation models with monolingual data', 'Understanding back-translation at scale']","['2015', '2018']","['Rico Sennrich;Barry Haddow;Alexandra Birch', 'Sergey Edunov;Myle Ott;Michael Auli;David Grangier']",group,"['Reversely,', 'back-translation', '<ref type=""group"">(Sennrich et al., 2015, Edunov et al., 2018)</ref>', 'first', 'trains', 'a', 'target-tosource', 'model,', 'which', 'then', 'utilizes', 'target-side', 'monolingual', 'data', 'to', 'synthesis', 'a', 'pseudo-parallel', 'corpus.', 'We', 'randomly', 'select', '2M', 'English', 'sentences', 'from', 'the', 'CWMT', 'parallel', 'corpus', 'for', 'back-translation.']",2,"[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
b7ae5b3a-1aba-4acd-a36b-aa2e34afb1e7,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['An Efficient Phrase-to-Phrase Alignment Model for Arbitrarily Long Phrases and Large Corpora'],['2005'],['Y Zhang;S Vogel'],single,"['A', 'few', 'researchers', 'have', 'started', 'to', 'exploit', 'suffix', 'arrays', 'in', 'phrase-based', 'SMT', 'systems.', '<ref type=""single"">Callison-Burch et al. (2005)</ref>', 'have', 'shown', 'how', 'parallel', 'suffix', 'arrays', 'can', 'be', 'used', 'to', 'efficiently', 'compute', 'phrase', 'translations', 'and', 'significantly', 'reduce', 'the', 'large', 'memory', 'footprints', 'that', 'phrased-based', 'SMT', 'systems', 'suffer', 'from', 'when', 'attempting', 'to', 'use', 'longer', '(i.e.,', 'n&gt,3)', 'phrases.', '<ref type=""single"">Zhang and Vogel (2005)</ref>', 'describe', 'a', 'dynamic', 'programming', 'algorithm', 'that', 'more', 'efficiently', 'retrieves', 'alignments', 'for', 'a', 'set', 'of', 'phrases', '(such', 'as', 'all', 'substrings', 'from', 'a', 'sentence', 'that', 'is', 'to', 'be', 'translated),', 'which', 'outperforms', 'direct', 'comparison', 'binary', 'search', 'by', 'a', 'couple', 'of', 'orders', 'of', 'magnitude.', 'Their', 'improvement', 'allows', 'them', 'to', 'compute', 'phrase', 'alignments', 'online.']",49,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
b7caed4e-eb9f-4df7-9a08-1c88f319a14b,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Towards interpreting and mitigating shortcut learning behavior of NLU models'],['2021'],['Mengnan Du;Varun Manjunatha;Rajiv Jain;Ruchi Deshpande;Franck Dernoncourt;Jiuxiang Gu;Tong Sun;Xia Hu'],single,"['Mitigation', 'Multiple', 'approaches', 'have', 'been', 'proposed', 'to', 'mitigate', 'shortcut', 'learning', 'and', 'data', 'biases', '<ref type=""group"">(Clark et al., 2020, Bras et al., 2020, Zhou and Bansal, 2020, Minderer et al., 2020),</ref>', 'through', 'data', 'augmentation', '<ref type=""group"">(Jin et al., 2020, Alzantot et al., 2018),</ref>', 'domain', 'adaptation', '<ref type=""group"">(Blitzer et al., 2006 (Blitzer et al., , 2007)),</ref>', 'and', 'multi-task', 'learning', '<ref type=""single"">(Tu et al., 2020).</ref>', '<ref type=""single"">Du et al. (2021)</ref>', 'proposes', 'to', 'mitigate', 'shortcuts', 'by', 'suppressing', ""model's"", 'prediction', 'on', 'examples', 'with', 'a', 'large', 'shortcut', 'degree.', 'Recent', 'study', 'has', 'also', 'shown', 'removing', 'spurious', 'correlations', 'can', 'sometimes', 'hurt', ""model's"", 'accuracy', '<ref type=""single"">(Khani and Liang, 2021).</ref>', 'Orthogonal', 'to', 'existing', 'works,', 'we', 'propose', 'to', 'first', 'identify', 'unrobust', 'correlations', 'in', 'an', 'NLP', 'model', 'and', 'then', 'propose', 'a', 'targeted', 'mitigation', 'to', 'encourage', 'the', 'model', 'to', 'rely', 'less', 'on', 'those', 'unrobust', 'correlations.']",25,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b7d8309f-dfa6-48ad-8f0a-778d96f366d1,SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering,2020,Aishwarya Ashok;Ganapathy Natarajan;Ramez Elmasri;Laurel Smith-Stvan,['Amazonqa: A review-based question answering task'],['2019'],['Mansi Gupta;Nitish Kulkarni;Raghuveer Chanda;Anirudha Rayasam;Zachary Lipton'],single,"['At', 'the', 'answer', 'level', 'the', 'top', 'candidate', 'sentences', '(up', 'to', '10)', 'returned', 'by', 'our', 'system', 'were', 'compared', 'against', 'the', 'review', 'snippets', 'as', 'the', 'gold', 'standard.', 'The', 'review', 'snippets', 'were', 'top', 'review', 'sentences', 'returned', 'by', 'the', 'system', 'used', 'by', '<ref type=""single"">Gupta et al. (2019)</ref>', '<ref type=""single"">(Gupta et al., 2019)</ref>', 'Average', 'ROUGE', 'scores', 'are', 'reported', 'in', 'Table', '2.', 'Both', 'systems', 'aim', 'at', 'providing', 'the', 'best', 'candidate', 'sentences.', 'Looking', 'at', 'the', 'precision', 'scores,', 'it', 'is', 'clear', 'that', 'our', 'system', 'performance', 'is', 'good', 'in', 'terms', 'of', 'returning', 'relevant', 'sentences,', 'similar', 'in', 'content', 'to', 'the', 'gold', 'standard.', 'The', 'sim', 'method', 'still', 'is', 'the', 'best', 'performing', 'method.', 'We', 'say', 'this', 'because,', 'ROUGE-L', 'looks', 'for', 'the', 'longest', 'common', 'sub', 'se-', 'Looking', 'at', 'the', 'similarity', 'scores,', 'it', 'is', 'clear', 'that', 'the', 'candidate', 'sentences', 'returned', 'by', 'our', 'system', 'is', 'almost', 'exactly', 'similar', 'to', 'the', 'sentences', 'returned', 'by', '<ref type=""single"">Gupta et al. (2019).</ref>', 'Once', 'again', 'our', 'system', 'is', 'able', 'to', 'perform', 'on', 'par', 'with', 'a', 'more', 'complicated', 'system.']",38,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b7eb080b-d509-4326-ace7-987f8781d2d2,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['Optimizing statistical machine translation for text simplification'],['2016'],['Wei Xu;Courtney Napoles;Ellie Pavlick;Quanze Chen;Chris Callison-Burch'],single,"['SARI', 'SARI', '<ref type=""single"">(Xu et al., 2016)</ref>', 'is', 'a', 'lexical', 'simplicity', 'metric', 'that', 'measures', 'how', 'good', 'are', 'the', 'words', 'added,', 'deleted', 'and', 'kept', 'by', 'a', 'simplification', 'model.', 'This', 'metric', 'compares', 'the', 'model', 'output', 'to', 'simplification', 'references', 'and', 'the', 'original', 'sentence.', 'We', 'use', 'the', 'SARI', 'implementation', 'in', 'the', 'EASSE', 'toolkit', '4.']",2,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
b7f0ab56-bd49-42fe-8d31-641ff7927a2c,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['unknown'],['unknown'],['unknown'],single,"['We', 'now', 'describe', 'this', 'step', 'using', 'sentiment', 'classification', 'task', 'as', 'an', 'example', '(more', 'details', 'can', 'be', 'found', 'in', 'Algorithm', '1).', 'Let', 'f', 'be', 'a', 'well', 'trained', 'sentiment', 'classification', 'model.', 'Given', 'a', 'corpus', 'D,', 'for', 'each', 'input', 'sentence', 's', 'i,', 'i', '=', '1,...,', 'n', 'for', 'a', 'total', 'of', 'n', 'sentences', 'in', 'the', 'corpus,', 'we', 'apply', 'f', 'on', 'it', 'to', 'obtain', 'the', 'output', 'probability', 'p', 'pos', 'i', 'and', 'p', 'neg', 'i', 'for', 'positive', 'and', 'negative', 'label', 'respectively.', 'We', 'then', 'extract', 'attention', 'scores', '{a', '1', 'i,', 'a', '2', 'i', ',...,', 'a', 'm', 'i}', 'for', 'tokens', '{t', '1', 'i,', 't', '2', 'i', ',...,', 't', 'm', 'i}', 'in', 'sentence', 's', 'i,', 'where', 'm', 'is', 'the', 'length', 'of', 'the', 'sentence.', 'In', 'BERT-based', 'classification', 'models,', 'the', 'embedding', 'of', '<ref type=""single"">[CLS]</ref>', 'token', 'in', 'the', 'final', 'layer', 'is', 'fed', 'to', 'a', 'classification', 'layer.', 'We', 'thus', 'extract', 'the', 'attention', 'scores', 'of', 'each', 'token', 't', 'used', 'for', 'computing', 'the', 'embedding', 'of', 'the', '[CLS]', 'token', 'and', 'average', 'them', 'across', 'different', 'heads.', 'If', 'p', 'pos', 'i', '&gt,', 'p', 'neg', 'i,', 'we', 'obtain', 'the', 'updated', 'attention', 'score', 'ãj', 'i', '=', 'a', 'j', 'i', '*', 'p', 'pos', 'i,', 'otherwiseãj', 'i', '=', '−a', 'j', 'i', '*', 'p', 'neg', 'i', '.For', 'each', 'token', 't', 'in', 'the', 'vocabulary', 'V,', 'we', 'compute', 'the', 'average', 'attention', 'score:āt', '=', '1', 'mn', 'Σ', 'n', 'i=1', 'Σ', 'm', 'j=1', '[ã', 'j', 'i', '1(t', 'j', 'i', '=', 't)],where', 'we', 'aggregate', 'the', 'attention', 'scores', 'ãj', 'i', 'for', 'token', 't,', 'across', 'all', 'n', 'sentences', 'in', 'the', 'corpus.', 'We', 'then', 'normalize', 'the', 'attention', 'scores', 'across', 'the', 'vocabulary', 'to', 'obtain', 'the', 'importance', 'score', 'for', 'each', 'token', 't:', 'I', 't', '=', 'āt', '/Σ', 't∈V', 'āt.', 'This', 'can', 'lead', 'to', 'very', 'small', 'I', 't', 'for', 'certain', 'tokens,', 'thus', 'we', 'take', 'the', 'log', 'of', 'all', 'importance', 'scores', 'to', 'avoid', 'underflow,', 'I', '′', 't', '=', 'log(I', 't', ').', 'So', 'far,', 'we', 'have', 'computed', 'the', 'importance', 'score', 'for', 'each', 'token.', 'However,', 'we', 'observe', 'that', 'some', 'tokens', 'appearing', 'only', 'very', 'a', 'few', 'times', 'could', 'accidentally', 'have', 'very', 'high', 'importance', 'scores.', 'Thus,', 'we', 'propose', 'to', 'penalize', 'the', 'tokens', 'with', 'low', 'frequencies:Ît', '=', 'I', '′', 't', '−', 'λ/', 'log(1', '+', 'c', 't', '),', 'where', 'c', 't', 'is', 'the', 'frequency', 'of', 'token', 't', 'and', 'λ', 'is', 'a', 'temperature', 'parameter', 'to', 'adjust', 'the', 'degree', 'that', 'we', 'want', 'to', 'penalize', 'over', 'the', 'frequency.']",121,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b8080bdf-6269-4be7-8d8a-2837dbee97fc,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['Factored language models and generalized parallel backoff'],['2003'],['J Bilmes;K Kirchhoff'],single,"['Factored', 'Neural', 'Machine', 'Translation', '(FNMT)', 'approach', 'handles', 'the', 'output', 'vocabulary', 'size', 'problem', 'using', 'factors', 'as', 'a', 'translation', 'unit.', 'The', 'main', 'motivation', 'behind', 'this', 'factored', 'representation', 'is', 'related', 'to', 'the', 'human', 'way', 'to', 'learn', 'how', 'to', 'construct', 'correct', 'sentences.', 'In', 'this', 'work,', 'the', 'factors', 'are', 'referring', 'to', 'the', 'linguistic', 'annotation', 'at', 'word', 'level', 'like', 'the', 'Part', 'of', 'Speech', '(POS)', 'tags.', 'Some', 'works', 'have', 'used', 'factors', 'as', 'additional', 'information', 'for', 'language', 'modeling', '<ref type=""single"">[11]</ref>', 'and', 'also', 'applied', 'for', 'neural', 'networks', 'language', 'models', '<ref type=""group"">[12, 13, 14].</ref>', 'Recently,', 'factors', 'have', 'been', 'used', 'as', 'additional', 'linguistic', 'input', 'features', 'to', 'improve', 'a', 'word-level', 'NMT', 'system', '<ref type=""single"">[15]</ref>', 'as', 'well.']",70,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b8446e19-63f5-483e-ae5b-c23ec842953d,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['Introduction to arabic natural language processing'],['2010'],['Y Nizar;unk Habash'],single,"['Returning', 'to', 'the', 'different', 'approaches', 'of', 'handling', 'Arabic', 'text.', 'As', 'discussed', 'in', 'the', 'previous', 'sections', 'letter', 'normalization', 'and', 'transliteration', 'are', 'examples', 'of', 'the', 'simplification', 'approach.', 'For', 'example,', 'letter', 'normalization', 'is', 'commonly', 'applied', 'to', 'reduce', 'the', 'noise', 'and', 'sparsity', 'in', 'the', 'data', '<ref type=""single"">(Habash, 2010).</ref>', 'For', 'transliteration,', 'Ameur', 'et', 'al.', '(2017)', 'applied', 'a', 'bidirectional', 'attention-based', 'encoder-decoder', 'model', 'for', 'the', 'task', 'of', 'machine', 'transliteration', 'between', 'Arabic', 'and', 'English.']",41,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b8d1921d-e515-43e7-a738-1cbea861e80d,On the weak link between importance and prunability of attention heads,2020,Aakriti Budhraja;Madhura Pande;Preksha Nema;Pratyush Kumar;Mitesh Khapra,"['Q-bert: Hessian based ultra low precision quantization of bert', 'unknown']","['2019', '2019']","['Sheng Shen;Zhen Dong;Jiayu Ye;Linjian Ma;Zhewei Yao;Amir Gholami;W Michael;Kurt Mahoney;unk Keutzer', 'Ofir Zafrir;Guy Boudoukh;Peter Izsak;Moshe Wasserblat']",group,"['In', 'the', 'other', 'major', 'direction,', 'these', 'large', 'Transformer-based', 'models', 'have', 'been', 'down-sized', 'to', 'be', 'more', 'time', 'and', 'space', 'efficient.', 'Different', 'methods', 'for', 'down-sizing', 'have', 'been', 'studied', 'such', 'as', 'pruning', '<ref type=""group"">(McCarley, 2019, Gordon et al., 2020, Sajjad et al., 2020),</ref>', 'distillation', '<ref type=""group"">(Sanh et al., 2019, Liu et al., 2019, Jiao et al., 2019),</ref>', 'weight', 'quantization', '<ref type=""group"">(Zafrir et al., 2019, Shen et al., 2019),</ref>', 'and', 'weight', 'factorization', 'and', 'parameter', 'sharing', '<ref type=""single"">(Lan et al., 2019).</ref>', 'Pruning', 'techniques', 'have', 'been', 'particularly', 'successful', 'in', 'reinforcing', 'the', 'folk-lore', 'that', 'these', 'models', 'are', 'highly', 'over-parameterized.', 'These', 'pruning', 'methods', 'prune', 'parameters', 'based', 'on', 'magnitude', '<ref type=""single"">(Gordon et al., 2020),</ref>', 'importance', '<ref type=""single"">(McCarley, 2019)</ref>', 'or', 'layer-wise', '<ref type=""single"">(Sajjad et al., 2020).</ref>']",34,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b941fbea-b149-4563-83cc-b1add9a5db1f,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Our', 'experiments', 'are', 'also', 'based', 'on', 'the', 'large', 'monolingual', 'French', 'model', 'CamemBERT', '<ref type=""single"">(Martin et al., 2020)</ref>', 'as', 'well', 'as', 'on', 'the', 'two', 'large', 'multilingual', 'models:', 'XLM-R', '<ref type=""single"">(Conneau et al., 2020)</ref>', 'and', 'mBERT', '<ref type=""single"">(Devlin et al., 2019),</ref>', 'both', 'pre-trained', 'from', 'massive', 'corpora', 'dataset', 'in', 'more', 'than', '100', 'languages', 'such', 'as', 'the', 'Common', 'Crawl', '(CC-100)', 'or', 'Wikipedia', '(Wiki-100).', 'We', 'also', 'exploit', 'two', 'compact', 'multilingual', 'models', 'with', 'a', 'distilled', 'version', 'of', 'mBERT:', 'distil-mBERT', '<ref type=""single"">(Sanh et al., 2019)</ref>', 'and', 'small-mBERT', '<ref type=""single"">(Abdaoui et al., 2020),</ref>', 'a', 'mBERT', 'model', 'whose', 'the', 'original', 'vocabulary', 'has', 'been', 'reduced', 'to', 'two', 'languages', '(English', 'and', 'French).', 'Table', '1', 'gives', 'a', 'comparison', 'of', 'the', 'models.']",26,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
b947fa7e-ec49-405f-96e7-ee8b0c6fba68,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['Generation-augmented retrieval for open-domain question answering'],['2009'],['Yuning Mao;Pengcheng He;Xiaodong Liu;Yelong Shen;Jianfeng Gao;Jiawei Han;Weizhu Chen'],single,"['We', 'first', 'compare', 'RocketQA', 'with', 'the', 'previous', 'state-of-the-art', 'approaches', 'on', 'passage', 'retrieval.', 'We', 'consider', 'both', 'sparse', 'and', 'dense', 'passage', 'retriever', 'baselines.', 'The', 'sparse', 'retrievers', 'include', 'the', 'traditional', 'retriever', 'BM25', '<ref type=""single"">(Yang et al., 2017),</ref>', 'and', 'four', 'traditional', 'retrievers', 'enhanced', 'by', 'neural', 'networks,', 'including', 'doc2query', '<ref type=""single"">(Nogueira et al., 2019c),</ref>', 'DeepCT', '<ref type=""single"">(Dai and Callan, 2019),</ref>', 'docTTTT-Tquery', '<ref type=""single"">(Nogueira et al., 2019a)</ref>', 'and', 'GAR', '<ref type=""single"">(Mao et al., 2020).</ref>', 'Both', 'doc2query', 'and', 'docTTTTTquery', 'employ', 'neural', 'question', 'generation', 'to', 'expand', 'documents.', 'In', 'contrast,', 'GAR', 'employs', 'neural', 'generation', 'models', 'to', 'expand', 'questions.', 'Different', 'from', 'them,', 'DeepCT', 'utilizes', 'BERT', 'to', 'learn', 'the', 'term', 'weight.', 'The', 'dense', 'passage', 'retrievers', 'include', 'DPR', '<ref type=""single"">(Karpukhin et al., 2020),</ref>', 'ME-BERT', '<ref type=""single"">(Luan et al., 2020)</ref>', 'and', 'ANCE', '<ref type=""single"">(Xiong et al., 2020).</ref>', 'Both', 'DRP', 'and', 'ME-BERT', 'use', 'in-batch', 'random', 'sampling', 'and', 'hard', 'negative', 'sampling', 'from', 'the', 'results', 'retrieved', 'by', 'BM25,', 'while', 'ANCE', 'enhances', 'the', 'hard', 'negative', 'sampling', 'by', 'using', 'the', 'dense', 'retriever.']",47,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
b9879f67-1a75-490e-8ab1-f0f3b9e480a7,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['where', 'Y', '*', 'denotes', 'a', 'set', 'of', 'all', 'possible', 'hypotheses.', 'The', 'Transformer', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'is', 'a', 'stateof-the-art', 'NN', 'architecture', 'that', 'can', 'be', 'used', 'to', 'maximize', 'Eq.', '(1).', 'The', 'Transformer', 'consists', 'of', 'two', 'NNs:', 'The', 'Encoder', 'network', 'and', 'the', 'Decoder', 'network.', 'Let', 'I', 'emb', 'and', 'D', 'emb', 'be', 'the', 'sequence', 'length', 'and', 'dimension', 'of', 'the', 'acoustic', 'embedding.', 'The', 'Encoder', 'network', 'generates', 'a', 'sequence', 'of', 'embeddings', 'of', 'the', 'acoustic', 'information', 'E', '=', '{e', 'i', '∈', 'D', 'emb}', 'I', 'emb', 'i=1', 'from', 'input', 'feature', 'sequences,', 'i.e.', 'E', '=', 'Encoder(X).', 'The', 'Decoder', 'network', 'predicts', 'the', 'output', 'of', 'the', 'M', '-th', 'step', 'y', 'M', 'given', 'a', 'sub-sequence,', 'including', 'the', 'current', 'output', 'ȳ', '=', '{y', '1,', '•,', 'y', 'M', '−1}', 'and', 'E,', 'i.e.', 'y', 'M', '=', 'Decoder(ȳ,', 'E).', 'This', 'conditional', 'autoregressive', 'modeling', 'function', 'is', 'particularly', 'important', 'in', 'this', 'paper', 'since', 'it', 'can', 'explicitly', 'model', 'the', 'relationship', 'between', 'output', 'labels,', 'unlike', 'CTC.']",12,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
b995c9bc-6d9a-4c02-a61d-5562e7b01d99,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['Factored markov decision processes. Markov Decision Processes in Artificial Intelligence'],['2013'],['Thomas Degris;Olivier Sigaud'],single,"['As', 'noted', 'by', '<ref type=""single"">Urbanek et al. (2019)</ref>', 'and', '<ref type=""single"">Ammanabrolu et al. (2021),</ref>', 'the', 'ability', 'to', 'speak', 'and', 'act', 'in', 'these', 'textual', 'fantasy', 'worlds', 'has', 'implications', 'for', 'domains', 'beyond', 'text-games.', 'Text', 'games', 'are', 'a', 'platform', 'where', 'agents', 'can', 'interact', 'in', 'a', 'relatively', 'isolated', 'environment', 'and', 'learn', 'to', 'interactively', 'communicate', 'effectively', 'through', 'natural', 'language', 'in', 'a', 'situated', 'manner.', 'Our', 'methods', 'use', 'both', 'large', 'language', 'models', 'and', 'deep', 'reinforcement', 'learning', 'and', 'are', 'prone', 'to', 'the', 'pitfalls', 'that', 'other', 'contemporary', 'methods', 'using', 'these', 'techniques', 'face,', 'especially', 'in', 'the', 'areas', 'of', 'dialogue', 'and', 'text', 'game', 'systems.', 'We', 'mitigate', 'this', 'first', 'pitfall', 'by', 'restricting', 'our', 'current', 'system', 'to', 'a', 'retrieval', 'based', 'dialogue,', 'ensuring', 'that', 'we', 'can', 'filter', 'out', 'non-normative', 'dialogue', 'usages', 'beforehand,', 'though', 'we', 'will', 'note', 'that', 'the', 'system', 'can', 'be', 'extended', 'to', 'generative', 'systems', 'as', 'described', 'in', '<ref type=""single"">Prabhumoye et al. (2020).</ref>', 'Further,', 'the', 'LIGHT', 'dataset', 'is', 'crowdsourced', 'and', 'contains', 'data', 'biases', 'that', 'can', 'be', 'attributed', 'to', 'the', 'crowdworkers', 'tasked', 'with', 'creating', 'the', 'data.', 'Dinan', 'et', 'al.', '(2020)', 'provides', 'an', 'in', 'depth', 'discussion', 'regarding', 'the', 'inherent', 'dataset', 'biases,', 'such', 'as', 'gender', 'bias', 'in', 'the', 'distribution', 'of', 'characters,', 'in', 'LIGHT', 'and', 'techniques', 'to', 'mitigate', 'them-we', 'follow', 'these', 'methods', 'to', 'reduce', 'their', 'effects', 'on', 'both', 'the', 'environment', 'generation', 'and', 'agent', 'training', 'procedures.', 'The', 'LIGHT', 'environment', 'further', 'allows', 'us', 'to', 'factorize', 'the', 'overall', 'action', 'space', 'A', 'into', 'A', 'as', 'the', 'set', 'of', 'possible', 'textual', 'actions', 'or', 'commands', '(e.g.', 'get', 'sword,', 'steal', 'coins', 'from', 'merchant),', 'and', 'U', 'as', 'the', 'set', 'of', 'possible', 'dialogues', 'that', 'can', 'be', 'uttered', 'by', 'an', 'agent,', 'thus', 'making', 'it', 'a', 'factored', 'POMDP', '<ref type=""single"">(Degris and Sigaud, 2013).</ref>', 'This', 'in', 'turn', 'means', 'that,', 'for', 'a', 'given', 'quest', 'q,', 'each', 'expert', 'human', 'demonstration', 'D(q)', '=', 'α', '*', '0,', 'α', '*', '1', '...α', '*', 'n', 'can', 'be', 'factorized', 'into', 'two', 'sub-sequences', 'of', 'expert', 'demonstrations', 'of', 'actions', 'and', 'dialogue', 'D', 'A', '(q)', '=', 'a', '*', '0,', 'a', '*', '1,', '...a', '*', 'n', 'and', 'D', 'U', '(q)', '=', 'u', '*', '0,', 'u', '*', '1,', '...u', '*', 'm', 'respectively.', 'The', 'factorized', 'action', 'spaces', 'A', 'and', 'U', 'are', 'constructed', 'by', 'enumerating', 'all', 'possible', 'actions/dialogue', 'utterances', 'in', 'the', 'all', 'human', 'demonstrations', 'in', 'LIGHT-quests.']",247,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
badb4cc2-692a-41ef-b85c-7931b5489a60,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,"['WordNet: A lexical database for English', 'Representing general relational knowledge in ConceptNet 5', 'Ba-belNet: Building a very large multilingual semantic network']","['1992', '2012', '2010']","['A George;unk Miller', 'Robyn Speer;Catherine Havasi', 'Roberto Navigli;Simone Ponzetto']",group,"['Although', 'the', 'canonical', 'way', 'to', 'represent', 'words', 'is', 'to', 'assign', 'them', 'to', 'vectors,', 'if', 'the', 'goal', 'is', 'to', 'model', 'connections', 'between', 'words,', 'a', 'graph', 'structure', 'is', 'at', 'least', 'as', 'suitable.', 'When', 'each', 'word', 'is', 'represented', 'by', 'a', 'vector,', 'the', 'similarity', 'between', 'them', 'is', 'most', 'often', 'calculated', 'as', 'the', 'cosine', 'of', 'the', 'angle', 'of', 'the', 'two', 'vectors.', 'In', 'the', 'case', 'of', 'graph', 'representations,', 'all', 'words', 'in', 'the', 'dictionary', 'correspond', 'to', 'the', 'vertices', 'of', 'a', 'large', 'graph,', 'and', 'the', 'distance', 'between', 'them', 'can', 'be', 'defined', 'in', 'many', 'ways', 'depending', 'on', 'the', 'graph.', 'One', 'option', 'is', 'the', 'length', 'or', 'weight', 'of', 'the', 'shortest', 'path', 'between', 'the', 'two', 'vertices.', 'Knowledge', 'graphs', '<ref type=""group"">(Miller, 1992, Speer and Havasi, 2012, Navigli and Ponzetto, 2010a)</ref>', 'were', 'already', 'used', 'to', 'model', 'word', 'connections', 'in', 'previous', 'Codenames', 'agents,', 'but', 'other', 'types', 'of', 'language', 'graphs', 'also', 'exist,', 'which', 'could', 'be', 'utilized', 'for', 'this', 'task', 'as', 'well.']",107,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
bb03bd62-2af2-4de6-b8cf-a2e192da8b1f,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Language-style similarity and social networks'],['2020'],['Balazs Kovacs;Adam Kleinbaum'],single,"['In', 'fact,', 'homophily', 'is', 'so', 'prominent,', '<ref type=""single"">Mishra et al. (2019)</ref>', 'noted', 'in', 'their', 'work', 'that', 'the', 'profiles', 'they', 'generated', 'from', 'the', 'social', 'graph', 'of', 'users', 'and', 'tweets', 'could', 'encode', 'patters', 'of', 'similar', 'linguistic', 'practices', 'amongst', 'connected', 'users', 'in', 'the', 'Waseem', 'and', 'Hovy', '(2016)', 'dataset,', 'hence', 'allowing', 'for', 'comments', 'with', 'implicit', 'and', 'generalized', 'sexism', 'or', 'racism', 'to', 'be', 'better', 'detected.', 'Moreover,', 'homophily', 'has', 'direct', 'associations', 'with', 'all', 'the', 'four', 'aspects', 'of', 'context', 'that', 'we', 'described', 'in', 'section', '2,', 'i.e.,', 'similar', 'sociolinguistic', 'norms', 'and', 'shared', 'language', 'markers', 'facilitate', 'homophilic', 'ties', 'in', 'social', 'networks', '<ref type=""single"">(Kovacs and Kleinbaum, 2020),</ref>', 'as', 'do', 'shared', 'beliefs,', 'stereotypes,', 'and', 'demographic', 'traits', '<ref type=""single"">(Mishra et al., 2018a).</ref>', 'Therefore,', 'capturing', 'homophily', 'allows', 'for', 'all', 'the', 'four', 'aspects', 'to', 'be', 'directly', 'captured', 'together.', 'We', 'note', 'that', 'just', 'exploiting', 'simplistic', 'and', 'limited', 'inductive', 'biases', 'that', 'are', 'easy', 'to', 'extract,', 'like', 'gender', 'of', 'the', 'user,', 'can', 'render', 'methods', 'prone', 'to', 'making', 'faulty', 'generalizations', 'because', 'of', 'overfitting', 'to', 'patterns', 'in', 'the', 'training', 'data.', 'This', 'is', 'also', 'evident', 'from', 'the', 'observations', 'that', '<ref type=""single"">Mishra et al. (2019)</ref>', 'made', 'in', 'their', 'work.', 'They', 'noted', 'that', 'the', 'profiles', 'they', 'generated', 'from', 'the', 'social', 'graph', 'consisting', 'of', 'user', 'and', 'tweet', 'nodes', 'improved', 'F', '1', 'scores', 'over', 'the', 'profiles', '<ref type=""single"">Mishra et al. (2018a)</ref>', 'generated', 'from', 'the', 'social', 'graph', 'just', 'consisting', 'of', 'users,', 'with', 'the', 'gains', 'mainly', 'coming', 'from', 'increase', 'in', 'precision.']",88,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bb22e956-bac3-4ce9-80c4-6a006e3d9006,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,"['unknown', 'Collaborative intent prediction with real-time contextual data', 'Contextual intent tracking for personal assistants']","['2018', '2017', '2016']","['Jianfeng Gao;Michel Galley;Lihong Li', 'Yu Sun;Nicholas Yuan;Xing Xie', 'Yu Sun;Nicholas Yuan;Yingzi Wang;Xing Xie;Kieran Mcdonald;Rui Zhang']",group,"['Task-oriented', 'dialogue', 'systems', 'complete', 'tasks', 'for', 'users,', 'such', 'as', 'making', 'a', 'hotel', 'reservation', 'or', 'finding', 'train', 'routes,', 'in', 'a', 'multi-turn', 'conversation', '<ref type=""group"">(Gao et al., 2018, Sun et al., 2016 Sun et al., , 2017)).</ref>', 'The', 'generated', 'system', 'utterances', 'should', 'not', 'only', 'be', 'naturally', 'sound,', 'but', 'more', 'importantly', 'be', 'informative,', 'i.e.,', 'to', 'proceed', 'the', 'dialogue', 'towards', 'task', 'completion.', 'To', 'fulfill', 'this', 'requirement,', 'conditioned', 'response', 'generation', 'is', 'widely', 'adopted', 'based', 'on', 'system', 'actions', '*', 'Rui', 'Zhang', 'is', 'the', 'corresponding', 'author.', '<ref type=""group"">(Wen et al., 2017, Chen et al., 2019).</ref>', 'The', 'response', 'generation', 'process', 'is', 'decoupled', 'into', 'two', 'consecutive', 'steps,', 'where', 'an', 'action', 'is', 'first', 'selected', 'and', 'then', 'an', 'utterance', 'is', 'generated', 'conditioned', 'on', 'this', 'action.', 'One', 'can', 'optimize', 'each', 'step', 'towards', 'its', 'goal,', 'i.e.,', 'informative', 'and', 'naturally', 'sound,', 'without', 'impinging', 'the', 'other', '<ref type=""single"">(Yarats and Lewis, 2018).</ref>', 'However,', 'such', 'approaches', 'rely', 'on', 'action', 'annotations', '(as', 'in', 'Table', '1),', 'which', 'require', 'domain', 'knowledge', 'and', 'extensive', 'efforts', 'to', 'obtain.']",21,"[2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bb299960-c458-40fa-87aa-7dd6f4ceab76,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['In', 'SemEval-2021', 'Task-5,', '<ref type=""single"">Pavlopoulos et al. (2021)</ref>', 'provide', 'a', 'dataset', 'of', '10k', 'English', 'texts', 'filtered', 'from', 'Civil', 'Comments', '<ref type=""single"">(Borkan et al., 2019)</ref>', 'dataset.', 'Each', 'text', 'is', 'crowd-annotated', 'with', 'character', 'offsets', 'that', 'make', 'the', 'text', 'toxic.', 'The', 'task', 'is', 'to', 'predict', 'these', 'character', 'offsets', 'given', 'the', 'text.', 'The', 'work', 'presented', 'in', 'this', 'paper', 'aims', 'to', 'provide', 'a', 'comprehensive', 'analysis', 'of', 'simple', 'Token', 'Classification', '(TC)', 'and', 'Span', 'Prediction', '(SP)', 'methods', 'across', 'multiple', 'BERT-based', 'models', '-BERT', '<ref type=""single"">(Devlin et al., 2019),</ref>', 'RoBERTa', '<ref type=""single"">(Liu et al., 2019)</ref>', 'and', 'SpanBERT', '<ref type=""single"">(Joshi et al., 2020).</ref>', 'Additionally,', 'we', 'experiment', 'with', 'a', 'few', 'hybrid', 'approaches', '-Multi-Span', '(MSP),', 'where', 'the', 'model', 'is', 'trained', 'on', 'multiple', 'spans', 'simultaneously,', 'Span+Token', '(SP-TC),', 'where', 'the', 'model', 'is', 'trained', 'on', 'both', 'kinds', 'of', 'tasks', 'simultaneously,', 'LSTM-CRF', '(LC),', 'which', 'uses', 'a', 'LSTM', 'and', 'CRF', 'layer', 'on', 'top', 'of', 'BERT-based', 'models,', 'and', 'a', 'combination', 'of', 'predicted', 'offsets', 'for', 'above', 'techniques', 'using', 'union/intersection.', 'In', 'Section', '2,', 'we', 'perform', 'a', 'compendious', 'literature', 'survey.', 'Section', '3', 'elucidates', 'our', 'approach,', 'including', 'the', 'modelling', 'aspect,', 'the', 'various', 'variants', 'of', 'the', 'base', 'model,', 'and', 'the', 'different', 'Hybrid', 'Systems.', 'In', 'Section', '4,', 'we', 'describe', 'our', 'experimental', 'setup', 'and', 'hyperparameters', 'used', 'for', 'our', 'methods.', 'Lastly,', 'in', 'Section', '5', 'we', 'analyze', 'our', 'results', 'and', 'perform', 'ablative', 'analysis', 'on', 'our', 'systems.']",67,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bb567dec-2847-4922-895d-aff2b8c116d2,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['unknown'],['unknown'],['unknown'],group,"['When', 'processing', 'human', 'language', 'it', 'is', 'difficult', 'to', 'operate', 'only', 'at', 'the', 'level', 'of', 'individual', 'words.', 'While', 'for', 'some', 'tasks,', 'perhaps', 'monolingual', 'information', 'retrieval', 'in', 'particular,', 'this', 'might', 'seem', 'reasonable,', 'for', 'others', 'such', 'as', 'machine', 'translation,', 'cross-language', 'question', 'answering,', 'and', 'translin-gual', 'information', 'retrieval,', 'restriction', 'to', 'processing', 'single', 'words', 'is', 'a', 'significant', 'impediment.', 'There', 'has', 'been', 'much', 'recent', 'interest', 'in', 'computational', 'approaches', 'to', 'dealing', 'with', 'multiword', 'expressions', '(MWEs)', 'as', 'workshops', 'at', '<ref type=""group"">ACL-2006 , SIGIR-2005 , ACL-2004</ref>', 'and', 'other', 'conferences', 'attest.']",70,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3]"
bb83fc28-3660-41e5-b4dc-9d2a3a7ce20c,ROI Analysis model for Language Service Providers,2013,Ekaterina Stambolieva,['Involving Language Professionals in the Evaluation of Machine Translation'],['2012'],['Eleftherios Avramidis;Aljoscha Burchardt;Christian Federmann;Maja Popovic;Cindy Tscherwinka;David Vilar Torres'],single,"['The', 'other', '50%', 'consider', 'it', 'as', 'bad.', 'Moreover,', 'the', 'in-house', 'translators', 'classify', 'the', 'post-editing', 'effort', '<ref type=""single"">(Avramidis et al., 2012)</ref>', 'as', 'intermediate,', 'but', 'this', 'information', 'might', 'be', 'unreliable', 'due', 'to', 'insufficient', 'numbers', 'of', 'answers', 'on', 'the', 'MT', 'output', 'understandability', 'question.']",15,"[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
bb90f344-4046-4fa0-92e6-7021a64ada2f,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['unknown'],['unknown'],['unknown'],single,"['The', 'SDG', 'task', 'is', 'challenging', 'because', 'it', 'requires', 'a', 'model', 'to', 'learn', 'from', 'a', 'standard', 'dictionary', 'containing', 'complex', 'definitions', 'and', 'then', 'generate', 'simple', 'ones,', 'and', 'hence', 'fully', 'unsupervised.', 'A', 'seemingly', 'feasible', 'solution', 'is', 'to', 'generate', 'definitions', 'first', 'and', 'then', 'simplify', 'them,', 'i.e.,', 'the', 'generationsimplification', 'pipeline.', 'However,', 'the', 'simplification', 'task', 'requires', 'dataset', 'with', 'complex-simple', 'sentence', 'pairs,', 'and', 'such', 'data', 'is', 'also', 'difficult', 'to', 'find', 'in', 'languages', 'other', 'than', 'English', '<ref type=""single"">(Martin et al., 2020).</ref>', 'Besides,', 'the', 'pipeline', 'methods', 'do', 'not', 'perform', 'well', 'due', 'to', 'accumulated', 'errors', '(Section', '6.1).']",68,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
bba94bb9-5c82-4b57-a77a-27b2d71346cb,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['SemEval-2017 Task 4: Sentiment analysis in twitter'],['2017'],['Sara Rosenthal;Noura Farra;Preslav Nakov'],single,"['Our', 'training', 'data', 'include', 'five', 'datasets', 'for', 'target-based', 'sentiment', 'classification:', 'SemEval17', '<ref type=""single"">(Rosenthal et al., 2017),</ref>', 'entities', '<ref type=""single"">(Dong et al., 2014),</ref>', 'open', 'domain', '<ref type=""single"">(Mitchell et al., 2013),</ref>', 'Irish', 'politics', '<ref type=""single"">(Bakliwal et al., 2013),</ref>', 'and', 'our', 'annotations', 'of', 'positive/negative', 'norms', 'toward', 'norm', 'targets', '(§5.1).', 'These', 'annotations', 'highly', 'improve', 'classification', 'of', 'sentiments', 'expressed', 'through', 'advocacy', 'and', 'opposition', 'in', 'normative', 'statements.', 'Pretraining', 'on', 'general', 'sentiment', 'resourcessubjectivity', 'lexicon', '<ref type=""single"">(Wilson et al., 2005)</ref>', 'and', 'sen-timent140', '<ref type=""single"">(Go et al., 2009)</ref>', '-also', 'helps', '(Table', '3:', 'Mapping', 'between', 'corpus-specific', 'labels', 'and', 'our', 'labels', 'for', 'the', 'causality', 'module.', '†', 'The', 'order', 'of', 'two', 'input', 'texts', 'are', 'reversed.', '‡', 'The', 'second', 'input', 'text', 'is', 'replaced', 'with', 'a', 'random', 'text', 'in', 'the', 'corpus.']",11,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bbcd3403-1245-4ce3-af46-6938106b88c1,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['HotFlip: White-box adversarial examples for text classification'],['2018'],['Javid Ebrahimi;Anyi Rao;Daniel Lowd;Dejing Dou'],single,"['A', 'line', 'of', 'work', 'has', 'been', 'proposed', 'to', 'study', 'the', 'vulnerability', 'of', 'natural', 'language', 'models,', 'through', 'transformations', 'such', 'as', 'character-level', 'perturbations', '<ref type=""single"">(Ebrahimi et al., 2018),</ref>', 'word-level', 'perturbations', '<ref type=""group"">(Jin et al., 2019, Ren et al., 2019, Yang et al., 2020, Hsieh et al., 2019, Cheng et al., 2020, Li et al., 2020),</ref>', 'prepending', 'or', 'appending', 'a', 'sequence', '<ref type=""group"">(Jia and Liang, 2017, Wallace et al., 2019a),</ref>', 'and', 'generative', 'models', '<ref type=""single"">(Zhao et al., 2018b).</ref>', 'They', 'focus', 'on', 'constructing', 'adversarial', 'examples', 'from', 'the', 'test', 'set', 'that', 'alter', 'the', 'prediction,', 'whereas', 'our', 'methods', 'focus', 'on', 'finding', 'vulnerable', 'examples', 'beyond', 'the', 'test', 'set', 'whose', 'prediction', 'can', 'be', 'altered.', 'Robustness', 'beyond', 'the', 'test', 'set.', 'Several', 'works', 'have', 'studied', 'model', 'robustness', 'beyond', 'test', 'sets', 'but', 'mostly', 'focused', 'on', 'computer', 'vision', 'tasks.', '<ref type=""single"">Zhang et al. (2019)</ref>', 'demonstrate', 'that', 'a', 'robustly', 'trained', 'model', 'could', 'still', 'be', 'vulnerable', 'to', 'small', 'perturbations', 'if', 'the', 'input', 'comes', 'from', 'a', 'distribution', 'only', 'slightly', 'different', 'than', 'a', 'normal', 'test', 'set', '(e.g.,', 'images', 'with', 'slightly', 'different', 'contrasts).', '<ref type=""single"">Hendrycks and Dietterich (2019)</ref>', 'study', 'more', 'sources', 'of', 'common', 'corruptions', 'such', 'as', 'brightness,', 'motion', 'blur', 'and', 'fog.', 'Unlike', 'in', 'computer', 'vision', 'where', 'simple', 'image', 'transformations', 'can', 'be', 'used,', 'in', 'our', 'natural', 'language', 'setting,', 'generating', 'a', 'valid', 'example', 'beyond', 'test', 'set', 'is', 'more', 'challenging', 'because', 'language', 'semantics', 'and', 'grammar', 'must', 'be', 'maintained.', 'Counterfactual', 'fairness.', '<ref type=""single"">Kusner et al. (2017)</ref>', 'propose', 'counterfactual', 'fairness', 'and', 'consider', 'a', 'model', 'fair', 'if', 'changing', 'the', 'protected', 'attributes', 'does', 'not', 'affect', 'the', 'distribution', 'of', 'prediction.', 'We', 'follow', 'the', 'definition', 'and', 'focus', 'on', 'evaluating', 'the', 'counterfactual', 'bias', 'between', 'pairs', 'of', 'protected', 'tokens.', 'Existing', 'literature', 'quantifies', 'fairness', 'on', 'a', 'test', 'dataset', 'or', 'through', 'templates', '<ref type=""group"">(Feldman et al., 2015, Kiritchenko and Mohammad, 2018, May et al., 2019, Huang et al., 2020).</ref>', 'For', 'instance,', '<ref type=""single"">Garg et al. (2019)</ref>', 'quantify', 'the', 'absolute', 'counterfactual', 'token', 'fairness', 'gap', 'on', 'the', 'test', 'set,', 'Prabhakaran', 'et', 'al.', '(2019)', 'study', 'perturbation', 'sensitivity', 'for', 'named', 'entities', 'on', 'a', 'given', 'set', 'of', 'corpus.', '<ref type=""single"">Wallace et al. (2019b),</ref>', '<ref type=""group"">Sheng et al. (2019 Sheng et al. ( , 2020) )</ref>', 'study', 'how', 'language', 'generation', 'models', 'respond', 'differently', 'to', 'prompt', 'sentences', 'containing', 'mentions', 'of', 'different', 'demographic', 'groups.', 'In', 'contrast,', 'our', 'method', 'quantifies', 'the', 'bias', 'on', 'the', 'constructed', 'neighborhood.']",21,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bbd4bef9-76e9-48c4-9b65-f7bbee66a2ac,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['Sparse, dense, and attentional representations for text retrieval. CoRR, abs']",['unknown'],['Yi Luan;Jacob Eisenstein;Kristina Toutanova;Michael Collins'],single,"['chitecture', '<ref type=""single"">(Luan et al., 2020).</ref>', 'The', 'cross-encoder', 'is', 'more', 'effective', 'and', 'robust,', 'while', 'it', 'is', 'inefficient', 'over', 'a', 'large', 'number', 'of', 'candidates', 'in', 'inference.', 'Hence,', 'we', 'first', 'train', 'a', 'cross-encoder', '(following', 'the', 'architecture', 'shown', 'in', 'Figure', '1b).', 'Then,', 'when', 'sampling', 'hard', 'negatives', 'from', 'the', 'top-ranked', 'passages', 'retrieved', 'by', 'a', 'dense', 'retriever,', 'we', 'select', 'only', 'the', 'passages', 'that', 'are', 'predicted', 'as', 'negatives', 'by', 'the', 'cross-encoder', 'with', 'high', 'confidence', 'scores.', 'The', 'selected', 'top-retrieved', 'passages', 'can', 'be', 'considered', 'as', 'denosied', 'samples', 'that', 'are', 'more', 'reliable', 'to', 'be', 'used', 'as', 'hard', 'negatives.']",1,"[0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bbe41768-bd84-4fc2-9b86-4c5bce7f84ef,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['Bleu: a method for automatic evaluation of machine translation'],['2002'],['Kishore Papineni;Salim Roukos;Todd Ward;Wei-Jing Zhu'],single,"['BLEU', 'Previous', 'definition', 'generation', 'studies', '<ref type=""group"">(Noraset et al., 2017, Yang et al., 2020, Kong et al., 2020)</ref>', 'used', 'the', 'BLEU', '<ref type=""single"">(Papineni et al., 2002)</ref>', 'score', 'to', 'measure', 'the', 'closeness', 'of', 'generated', 'results', 'to', 'the', 'standard', 'answers,', 'and', 'to', 'evaluate', 'the', 'accuracy', 'of', 'results.', 'Since', 'the', 'English', 'test', 'set', 'is', 'manually', 'annotated,', 'we', 'calculate', 'the', 'BLEU', 'score', 'of', 'both', 'complex', 'and', 'simple', 'definitions,', 'respectively.']",9,"[0, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
bc08eaf9-312d-4fa2-be86-b7d5e4652b8d,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Transformers: State-of-theart natural language processing'],['2020'],['Thomas Wolf'],single,"['For', 'model', 'training,', 'we', 'used', 'Adam', 'with', 'batch', 'size', 'of', '60,', 'learning', 'rate', 'of', '3e-5,', 'L2', 'weight', 'decay', 'of', '0.01,', 'learning', 'rate', 'warm', 'up', 'over', 'the', 'first', '10,000', 'steps,', 'and', 'linear', 'decay', 'of', 'learning', 'rate.', 'Our', 'models', 'were', 'trained', 'by', 'one', 'Tesla', 'V100', 'GPU', 'card', 'with', '32GB', 'memory,', 'and', 'implemented', 'on', 'PyTorch', 'with', 'the', ""Huggingface's"", 'Transformer', '<ref type=""single"">(Wolf et al., 2020).</ref>', 'All', 'Transformer-based', 'methods', 'were', 'trained', 'with', '30', 'epochs,', 'taken', 'about', '4-5', 'hours', 'on', 'the', 'ComVE', 'dataset', 'and', '7-9', 'hours', 'on', 'the', 'α-NLG', 'dataset.']",56,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
bc40d290-c329-4923-bc33-42edfeb9a20a,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,['SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC)'],['2021'],['Federico Martelli;Najla Kalach;Gabriele Tola;Roberto Navigli'],single,"['This', 'paper', 'describes', 'our', 'submission', 'to', 'SemEval-2021', 'Task', '2', '<ref type=""single"">(Martelli et al., 2021).</ref>', 'Our', 'approach', 'is', 'mainly', 'focused', 'on', 'transformer-based', 'models', 'with', 'different', 'text', 'pair', 'classification', 'architectures.', 'We', 'remodel', 'the', 'default', 'text', 'pair', 'classification', 'architecture', 'and', 'introduce', 'several', 'strategies', 'that', 'outperform', 'the', 'default', 'text', 'pair', 'classification', 'architecture', 'for', 'this', 'task.', 'For', 'effortless', 'generalisation', 'across', 'the', 'languages,', 'we', 'do', 'not', 'use', 'any', 'language-specific', 'processing', 'and', 'resources.', 'In', 'the', 'subtasks', 'where', 'only', 'a', 'few', 'training', 'instances', 'were', 'available,', 'we', 'use', 'few-shot', 'learning', 'and', 'in', 'the', 'subtasks', 'where', 'there', 'were', 'no', 'training', 'instances', 'were', 'available,', 'we', 'use', 'zero-shot', 'learning', 'taking', 'advantage', 'of', 'the', 'cross-lingual', 'nature', 'of', 'the', 'multilingual', 'transformer', 'models.']",9,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bcb216af-e9a3-4130-9fc7-7e07aada89bf,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['Handling Structural Divergences and Recovering Dropped Arguments in a Korean/English Machine Translation System'],['2000'],['H Grune;C Bal;K Jacobs;unk Langendoen;U Chichester;B Han;M Lavoie;O Palmer;R Rambow;T Kittredge;N Korelsky;M Kim;unk Kim'],single,"['As', 'a', 'first', 'step,', 'we', 'consider', 'only', 'cases', 'where', 'at', 'any', 'node', 'during', 'the', 'tree', 'traversal', 'in', 'the', 'BURS,', 'there', 'is', 'only', 'potentially', 'one', 'gNCN', 'at', 'a', 'time:', 'that', 'is,', 'it', 'is', 'not', 'possible', 'to', 'embed', 'or', 'overlap', 'these', 'gNCNs.', 'In', 'order', 'to', 'explain', 'this,', 'consider', 'first', 'the', 'example', 'below.', 'The', 'input', 'AST', '(ignoring', 'the', 'annotations', 'on', 'the', 'nodes)', 'is', 'in', 'Figure', '7,', 'pattern', 'trees,', 'in', 'the', 'form', 'of', 'a', 'TAG', 'grammar', '(with', 'associated', 'costs', 'still', 'indicated', 'by', '),', 'are', 'also', 'in', 'Figure', '7.', 'The', 'algorithm', 'we', 'use', 'for', 'bottom-up', 'pattern', 'matching,', 'adapted', 'from', 'that', 'of', '<ref type=""single"">Grune et al. (2000),</ref>', 'is', 'in', 'Figure', '8.']",96,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2]"
bd31bd3c-34ba-4184-862d-8894318efa07,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Mixture content selection for diverse sequence generation'],['2019'],['Jaemin Cho;Minjoon Seo;Hannaneh Hajishirzi'],single,"['Expert', 'parameterization.', 'Independently', 'parameterizing', 'each', 'expert', 'may', 'exacerbate', 'overfitting', 'since', 'the', 'number', 'of', 'parameters', 'increases', 'linearly', 'with', 'the', 'number', 'of', 'experts', '<ref type=""single"">(Shen et al., 2019).</ref>', 'We', 'follow', 'the', 'parameter', 'sharing', 'schema', 'in', '<ref type=""single"">Cho et al. (2019),</ref>', '<ref type=""single"">Shen et al. (2019)</ref>', 'to', 'avoid', 'this', 'issue.', 'This', 'only', 'requires', 'a', 'negligible', 'increase', 'in', 'parameters', 'over', 'the', 'baseline', 'model', 'that', 'does', 'not', 'uses', 'MoE.', 'In', 'our', 'experiments,', 'we', 'compared', 'adding', 'a', 'unique', 'expert', 'embedding', 'to', 'each', 'input', 'token', 'with', 'adding', 'an', 'expert', 'prefix', 'token', 'before', 'the', 'input', 'text', 'sequence,', 'where', 'they', 'achieved', 'very', 'similar', 'performance.']",29,"[0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bdd3156d-a5eb-4207-8302-3f73c1e2bb8e,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,"['SQuAD: 100,000+ questions for machine comprehension of text']",['2016'],['Pranav Rajpurkar;Jian Zhang;Konstantin Lopyrev;Percy Liang'],single,"['Table', '5', 'presents', 'the', 'results', 'of', 'evaluating', 'the', 'impact', 'of', 'using', 'coreference', 'annotations', 'to', 'improve', 'coreference', 'reasoning', 'in', 'MRC.', 'We', 'report', 'the', 're-sults', 'for', 'both', 'of', 'the', 'examined', 'state-of-the-art', 'models,', 'i.', '<ref type=""single"">(Rajpurkar et al., 2016)</ref>', 'and', 'is', 'then', 'finetuned', 'on', 'Quoref.']",31,"[0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2]"
be13aedc-6fd8-4f39-a529-07290150d14e,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['Beyond accuracy: Behavioral testing of nlp models with checklist'],['2020'],['Tongshuang Marco Tulio Ribeiro;Carlos Wu;Sameer Guestrin;unk Singh'],single,"['In', 'most', 'studies,', 'model', 'robustness', 'is', 'evaluated', 'based', 'on', 'a', 'given', 'test', 'dataset', 'or', 'synthetic', 'sentences', 'constructed', 'from', 'templates', '<ref type=""single"">(Ribeiro et al., 2020).</ref>', 'Specifically,', 'the', 'robustness', 'of', 'a', 'model', 'is', 'often', 'evaluated', 'by', 'the', 'ratio', 'of', 'test', 'examples', 'where', 'the', 'model', 'prediction', 'cannot', 'be', 'altered', 'by', 'semantic-invariant', 'perturbation.', 'We', 'refer', 'to', 'this', 'type', 'of', 'evaluations', 'as', 'the', 'first-order', 'robustness', 'evaluation.', 'However,', 'even', 'if', 'a', 'model', 'is', 'first-order', 'robust', 'on', 'an', 'input', 'sentence', 'x', '0,', 'it', 'is', 'possible', 'that', 'the', 'model', 'is', 'not', 'robust', 'on', 'a', 'natural', 'sentence', 'x0', 'that', 'is', 'slightly', 'modified', 'from', 'x', '0.', 'In', 'that', 'case,', 'adversarial', 'examples', 'still', 'exist', 'even', 'if', 'first-order', 'attacks', 'cannot', 'find', 'any', 'of', 'them', 'from', 'the', 'given', 'test', 'dataset.', 'Throughout', 'this', 'paper,', 'we', 'call', 'x0', 'a', 'vulnerable', 'example.', 'The', 'existence', 'of', 'such', 'examples', 'exposes', 'weaknesses', 'in', ""models'"", 'understanding', 'and', 'presents', 'challenges', 'for', 'model', 'deployment.', 'Fig.', '1', 'illustrates', 'an', 'example.']",19,"[0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
be27df6c-aff2-457c-86b5-2a03cd2ff745,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['Multiwoz-a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling'],['2018'],['Paweł Budzianowski;Tsung-Hsien Wen;Bo-Hsiang Tseng;Iñigo Casanueva;Stefan Ultes;Milica Osman Ramadan;unk Gasic'],single,"['By', 'conducting', 'a', 'joint', 'model', 'for', 'the', 'two', 'tasks,', 'a', 'synergistic', 'effect', 'can', 'be', 'achieved', '<ref type=""single"">(Zhang et</ref>', '2019b).', 'To', 'build', 'multi-turn', 'dialogue', 'datasets,', 'most', 'studies', 'have', 'recruited', 'workers', 'via', 'crowd-sourcing', 'to', 'collect', 'task-oriented', 'dialogues', 'across', 'different', 'domains', '(e.g.', 'in-car', 'assistant', '<ref type=""single"">(Eric et al., 2017),</ref>', 'navigation', 'and', 'events', '<ref type=""single"">(Gupta et al., 2018),</ref>', 'multidomains', '<ref type=""single"">(Budzianowski et al., 2018),</ref>', 'personal', 'notifications', '<ref type=""single"">(Schuster et al., 2019)</ref>', ').', 'Recently,', 'deep', 'learning', 'models', 'have', 'also', 'been', 'extensively', 'studied', 'in', 'order', 'to', 'capture', 'the', 'contextual', 'signals', 'from', 'multiple', 'sequential', 'inputs.', '(e.g.', 'BiLSTM', 'with', 'attention', '<ref type=""single"">(Wang et al., 2019),</ref>', 'GRU', 'with', 'self-attention', 'and', 'context-fusion', '<ref type=""single"">(Gupta et al., 2019).</ref>', 'The', 'models', 'listed', 'all', 'show', 'an', 'increase', 'in', 'semantic', 'detection', 'performance', 'when', 'the', 'context', 'is', 'included', 'in', 'the', 'analysis.']",45,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
be2d317c-a293-4dfc-a29a-230586962e1a,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,['SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks'],['2018'],['Ke Wang;Xiaojun Wan'],single,"['In', 'these', 'experiments', 'we', 'have', 'compared', 'the', 'sentiment-conditioned', 'text', 'generation', 'of', 'CTERM-GAN', 'with', 'that', 'of', 'SeqGAN', '<ref type=""single"">[24],</ref>', 'SentiGAN', '<ref type=""single"">[20]</ref>', 'and', 'an', 'RNNLM', 'baseline', '<ref type=""single"">[14].</ref>', 'Following', 'the', 'experiments', 'carried', 'out', 'in', '<ref type=""single"">[20],</ref>', 'the', 'conditioning', 'has', 'been', 'performed', 'based', 'on', 'only', 'two', 'sentiments,', 'positive', 'or', 'negative.', 'In', 'this', 'case,', 'the', 'conditioning', 'vector,', 'c,', 'taken', 'as', 'input', 'by', 'CTERM-GAN', 'is', 'a', 'one-hot', 'binary', 'variable', 'representing', 'the', 'desired', 'sentiment.', 'The', 'RNNLM', 'and', 'SeqGAN', 'models', 'have', 'been', 'trained', 'separately', 'on', 'the', 'two', 'sentiments', 'by', 'treating', 'positive', 'and', 'negative', 'sentences', 'as', 'two', 'separate', 'datasets,', 'while', 'SentiGAN', 'and', 'the', 'proposed', 'model', 'have', 'been', 'trained', 'jointly.', 'This', 'procedure', 'makes', 'the', 'results', 'comparable', 'although', 'it', 'is', 'clear', 'how', 'the', 'flexibility', 'of', 'SentiGAN', 'and', 'CTERM-GAN', 'makes', 'these', 'models', 'more', 'general.', 'Dataset', 'We', 'have', 'used', 'two', 'datasets,', 'Movie', 'Reviews', '(MR)', '<ref type=""single"">[19]</ref>', 'and', 'Customer', 'Reviews', '(CR)', '<ref type=""single"">[10],</ref>', 'where', 'individual', 'sentences', 'are', 'annotated', 'as', 'either', 'positive', 'or', 'negative.', 'The', 'Movie', 'Reviews', 'dataset', 'consists', 'of', 'user', 'reviews', 'of', 'movies,', 'with', '2,', '133', 'positive', 'and', '2,', '370', 'negative', 'sentences.', 'The', 'Customer', 'Reviews', 'dataset', 'consists', 'of', '1,', '500', 'reviews', 'of', 'products', 'sold', 'online,', 'with', 'positive/negative', 'annotation', 'at', 'sentence', 'level.', 'For', 'this', 'task,', 'only', 'sentences', 'of', 'length', 'shorter', 'than', '15', 'words', 'have', 'been', 'retained,', 'to', 'be', 'able', 'to', 'use', 'the', 'same', 'preprocessing', 'as', '<ref type=""single"">[20].</ref>']",30,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
be64e9e5-3c17-4d6c-9599-5b5bc6a6dfa7,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,"[""Mapping racist tweets in response to president obama's re-election""]",['2012'],['Matthew Zook'],single,"['More', 'recently,', 'researchers', 'have', 'noted', 'that', 'the', 'linguistic', 'features', 'of', 'a', 'comment', 'alone', 'may', 'not', 'be', 'sufficient', 'to', 'classify', 'it', 'as', 'abusive', 'or', 'not.', 'Information', 'of', 'the', 'user', 'who', 'posted', 'the', 'comment,', 'and', 'of', 'the', 'surrounding', 'social', 'community', 'of', 'that', 'user,', 'further', 'provides', 'valuable', 'insights', 'into', 'the', 'abusiveness', 'of', 'the', 'comment.', 'An', 'example', 'of', 'this', 'is', 'the', 'study', 'by', '<ref type=""single"">Zook (2012),</ref>', 'which', 'mapped', 'the', 'locations', 'of', 'racist', 'tweets', 'in', 'response', 'to', 'President', ""Obama's"", 're-election', 'to', 'show', 'that', 'such', 'tweets', 'were', 'not', 'uniformly', 'distributed', 'across', 'the', 'United', 'States', 'but', 'instead', 'came', 'from', 'specific', 'geographical', 'communities', 'of', 'users.', 'Other', 'works', 'have', 'also', 'shown', 'how', 'users', 'on', 'online', 'platforms', 'organize', 'into', 'communities', 'based', 'on', 'factors', 'such', 'as', 'shared', 'beliefs,', 'stereotypes,', 'linguistic', 'norms,', 'or', 'geographical', 'propinquity', '<ref type=""group"">(Jurgens, 2013, Nguyen and Rosé, 2011).</ref>']",59,"[0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
be72350d-bc60-4a94-b1b6-f0138819c399,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,['Hinge-Loss Markov random fields and probabilistic soft logic'],['2017'],['H Stephen;Matthias Bach;Bert Broecheler;Lise Huang;unk Getoor'],single,"['To', 'investigate', 'what', 'logical', 'mechanisms', 'govern', 'argumentative', 'relations,', 'we', 'hypothesize', 'that', 'governing', 'mechanisms', 'should', 'be', 'able', 'to', 'classify', 'the', 'relations', 'without', 'directly', 'training', 'on', 'relationlabeled', 'data.', 'Thus,', 'we', 'first', 'compile', 'a', 'set', 'of', 'rules', 'specifying', 'logical', 'and', 'theory-informed', 'mechanisms', 'that', 'signal', 'the', 'support', 'and', 'attack', 'relations', '(§3).', 'The', 'rules', 'are', 'grouped', 'into', 'four', 'mechanisms:', 'factual', 'consistency,', 'sentiment', 'coherence,', 'causal', 'relation,', 'and', 'normative', 'relation.', 'These', 'rules', 'are', 'combined', 'via', 'probabilistic', 'soft', 'logic', '(PSL)', '<ref type=""single"">(Bach et al., 2017)</ref>', 'to', 'estimate', 'the', 'optimal', 'argumentative', 'relations', 'between', 'statements.', 'We', 'operationalize', 'each', 'mechanism', 'by', 'training', 'semantic', 'modules', 'on', 'public', 'datasets', 'so', 'that', 'the', 'modules', 'reflect', 'real-world', 'knowledge', 'necessary', 'for', 'reasoning', '(§4).', 'For', 'normative', 'relation,', 'we', 'build', 'a', 'necessary', 'dataset', 'via', 'rich', 'annotation', 'of', 'the', 'normative', 'argumentation', 'schemes', 'argument', 'from', 'consequences', 'and', 'practical', 'reasoning', '<ref type=""single"">(Walton et al., 2008),</ref>', 'by', 'developing', 'a', 'novel', 'and', 'reliable', 'annotation', 'protocol', '(§5).']",72,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
be7b59b6-8ed0-465f-80c7-dad86afca06e,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Bert: Pre-training of deep bidirectional transformers for language understanding'],['2018'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['the', 'BERT', 'model', '<ref type=""single"">(Devlin et al., 2018),</ref>']",3,"[1, 1, 1, 1]"
bed8a3bb-bb24-4215-9a11-c798ca8e63ee,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['Glove: Global vectors for word representation'],['2014'],['Jeffrey Pennington;Richard Socher;Christopher D Manning'],single,"['Base', 'models.', 'For', 'BoW,', 'CNN,', 'and', 'LSTM,', 'all', 'models', 'use', 'pre-trained', 'GloVe', 'embeddings', '<ref type=""single"">(Pennington et al., 2014),</ref>', 'and', 'have', 'one', 'hidden', 'layer', 'of', 'the', 'corresponding', 'type', 'with', '100', 'hidden', 'size.', 'Similar', 'to', 'the', 'baseline', 'performance', 'reported', 'in', 'GLUE', '<ref type=""single"">(Wang et al., 2019),</ref>', 'our', 'trained', 'models', 'have', 'an', 'evaluation', 'accuracy', 'of', '81.4%,', '82.5%,', 'and', '81.7%,', 'respectively.', 'For', 'attention-based', 'models,', 'we', 'train', 'a', '3-layer', 'Transformer', '(the', 'largest', 'size', 'in', '<ref type=""single"">Shi et al. 2020)</ref>', 'and', 'fine-tune', 'a', 'pre-trained', 'bertbase-uncased', 'from', 'HuggingFace', '<ref type=""single"">(Wolf et al., 2020).</ref>', 'The', 'Transformer', 'uses', '4', 'attention', 'heads', 'and', '64', 'hidden', 'size,', 'and', 'obtains', '82.1%', 'accuracy.']",13,"[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
bf26fa04-98f7-4f28-9227-3f3809d59d5e,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,['Mixture models for diverse machine translation: Tricks of the trade'],['2019'],"[""Tianxiao Shen;Myle Ott;Michael Auli;Marc'aurelio Ranzato""]",single,"['Improving', 'content', 'diversity', 'in', 'NLG.', 'Most', 'of', 'the', 'existing', 'diversity-promoting', 'work', 'has', 'focused', 'on', 'improving', 'syntactic', 'and', 'lexical', 'diversity,', 'such', 'as', 'different', 'language', 'style', 'in', 'machine', 'translation', '<ref type=""single"">(Shen et al., 2019)</ref>', 'and', 'word', 'variability', 'in', 'paraphrase', 'generation', '<ref type=""single"">(Gupta et al., 2018).</ref>', 'Nevertheless,', 'methods', 'for', 'improving', 'content', 'diversity', 'in', 'NLG', 'systems', 'have', 'been', 'rarely', 'studied', 'in', 'the', 'existing', 'literature.', 'We', 'believe', 'that', 'generating', 'diverse', 'content', 'is', 'one', 'of', 'the', 'most', 'promising', 'aspects', 'of', 'machine', 'intelligence,', 'which', 'can', 'be', 'applied', 'to', 'a', 'wide', 'range', 'of', 'real-world', 'applications,', 'not', 'only', 'limited', 'to', 'commonsense', 'reasoning.']",27,"[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c01f0833-0a99-4bd6-bb28-06144c2f043d,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Evidence That Gendered Wording in Job Advertisements Exists and Sustains Gender Inequality'],['2011'],['Danielle Gaucher;Justin Friesen;Aaron Kay'],single,"['Impact', 'on', 'Job', 'Applications', 'While', 'our', 'goal', 'was', 'to', 'generate', 'gender-neutral', 'job', 'ads,', 'it', 'remains', 'possible', 'that', 'neutrality', 'may', 'still', 'dissuade', 'a', 'particular', 'group', 'from', 'applying', '<ref type=""single"">(Gaucher et al., 2011).</ref>', 'Our', 'work', 'cannot', 'comment', 'experimentally', 'on', 'whether', 'less-biased', 'ads', 'at', 'the', 'text-level', 'result', 'in', 'a', 'greater', 'diversity', 'of', 'applicants.', 'Further', 'social', 'science', 'and', 'experimental', 'research', 'is', 'thus', 'necessary', 'to', 'understand', 'the', 'effects', 'that', 'language', 'in', 'job', 'ads', 'has', 'on', 'applications', 'from', 'various', 'protected', 'groups.']",26,"[0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
c06a4614-803d-4d81-8ffa-3806ffa6debb,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['The processing of natural language by analogy with specific reference to Machine Translation'],['1991'],['D Jones'],single,"['Concerning', 'the', 'use', 'of', 'examples', 'for', 'generation', 'by', ""'recombination',"", 'since', 'the', 'system', 'is', 'example-based,', 'the', 'issue', 'here', 'is', 'not', 'so', 'much', 'generation', 'from', 'representations', '-which', 'are', 'largely', 'given', 'a', 'priori', 'by', 'the', 'corpus', 'of', 'examples', '-but', 'the', 'capability', 'of', 'such', 'a', 'mechanism', 'to', 'generate', 'texts', 'which', 'are', 'not', 'directly', 'represented', 'in', 'the', 'database', 'of', 'examples.', 'The', 'general', 'advantages', 'of', 'example-based', 'natural', 'language', 'processing', 'have', 'already', 'been', 'discussed.', 'However,', 'it', 'is', 'very', 'much', 'appreciated', 'that', 'in', 'order', 'for', 'example-based', 'systems', 'to', 'have', 'any', 'real', 'degree', 'of', 'flexibility', 'they', 'must', 'be', 'afforded', 'some', 'degree', 'of', 'generative', 'capacity', 'above', 'and', 'beyond', 'that', 'supported', 'by', ""'static'"", 'individual', 'examples.', 'This', 'increased', 'flexibility', 'is', 'gained', 'by', 'matching', 'against', 'subcomponents', 'of', 'more', 'than', 'one', 'example', 'across', 'the', 'example', 'database.', 'This', 'may', 'occur', 'when', 'an', 'input', 'text', 'does', 'not', 'match', 'against', 'one', 'complete', 'example', 'but', 'several', 'examples', 'match', 'against', 'parts', 'of', 'the', 'input.', 'Obviously', 'it', 'is', 'important', 'not', 'to', 'reject', 'the', 'input', 'text', 'outright', 'as', ""'ill-formed'"", 'in', 'some', 'way,', 'but', 'attempt', 'to', 'generate', 'a', 'corresponding', ""'clone'"", '<ref type=""single"">([18])</ref>', 'of', 'the', 'input', 'based', 'on', 'the', 'highest', 'scoring', 'matches', 'returned', 'by', 'the', 'matching', 'process.', 'There', 'is', 'a', 'need', 'for', 'information', 'to', 'guide', 'this', 'process,', 'and', 'this', 'information', 'comes', 'from', 'the', 'intentional', 'model', 'and', 'domain', 'knowledge.']",168,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
c0d5756b-1f6f-40cc-bdbb-89c5fcf6182e,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Glove: Global vectors for word representation'],['2014'],['Jeffrey Pennington;Richard Socher;Christopher D Manning'],single,"['Another', 'advantage', 'is', 'that', 'it', 'provides', 'precomputed', 'contextual', 'word', 'representations.', 'QA', 'models', 'based', 'on', 'LSTMs', 'are', 'built', 'on', 'top', 'of', 'static', 'word', 'embeddings', 'models', 'such', 'as', 'GloVe', '<ref type=""single"">(Pennington et al., 2014).</ref>', 'Even', 'these', 'models', 'have', 'up', 'to', '40', 'times', 'fewer', 'parameters', 'than', 'a', 'BERT-based', 'model,', 'they', 'rely', 'on', 'LSTM-based', 'encoders', 'to', 'produce', 'contextual', 'embeddings', 'which', 'considerably', 'lengthens', 'the', 'time', 'required', 'for', 'training', 'and', 'makes', 'the', 'dependence', 'on', 'supervised', 'data', 'more', 'important.']",27,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
c1893101-42ce-40bf-8ff7-d55b190d9ff7,Diverse dialogue generation with context dependent dynamic loss function,2020,Ayaka Ueyama;Yoshinobu Kano,['SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing'],['2018'],['Taku Kudo;John Richardson'],single,"['Japanese', 'and', 'English', 'Twitter', 'conversations', 'were', 'extracted', 'from', 'Twitter', 'replies,', 'adjacent', 'tweets', 'as', 'pairs', 'of', '<ref type=""single"">[utterance, response]</ref>', 'to', 'construct', 'a', 'single-turn', 'dialogue', 'dataset', 'of', 'one', 'million', 'dialogue', 'pairs', 'for', 'each', 'language.', 'SentencePiece', '<ref type=""single"">(Kudo and Richardson, 2018)</ref>', 'was', 'trained', 'using', 'a', 'dataset', 'with', 'a', 'vocabulary', 'of', '32,000', 'for', 'both', 'Japanese', 'and', 'English', 'data.', 'We', 'then', 'used', 'these', 'SentencePiece', 'models', 'to', 'tokenize', 'the', 'training', 'set', 'into', 'subwords.', 'Each', 'of', 'the', 'verification', 'set', 'and', 'the', 'test', 'set', 'consists', 'of', '1024', 'pairs.']",31,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
c1ce5d38-b055-4ab5-8a8d-5b13fafa33c8,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,"['Norms of word association', 'Word association norms: Grade school through college']","['2014', '1964']","['Leo Postman;Geoffrey Keppel', 'S David;James J Palermo;unk Jenkins']",group,"['The', 'above', 'conditions', 'are,', 'of', 'course,', 'far', 'from', 'reality,', 'since', 'such', 'a', 'distance', 'function,', 'which', 'perfectly', 'corresponds', 'to', 'the', 'mental', 'representations', 'of', 'all', 'people,', 'certainly', 'does', 'not', 'exist.', 'This', 'is', 'clear', 'from', 'the', 'fact', 'that', 'in', 'classical', 'association', 'tests,', 'where', 'the', 'actual', 'task', 'is', 'to', 'find', 'nearest', 'neighbors,', 'the', 'subjects', 'never', 'give', 'the', 'same', 'answer', '<ref type=""group"">(Palermo and Jenkins, 1964, Postman and Keppel, 2014</ref>', ').', 'However,', 'it', 'is', 'a', 'meaningful', 'task', 'to', 'create', 'a', 'similarity', 'function', 'and', 'construct', 'a', 'similarity', 'matrix', 'S', '∈', 'R', 'V', '×V,', 'in', 'which', 'S', 'ij', '=', 's(w', 'i,', 'w', 'j)', 'approximates', 'the', 'average', 'similarity', 'perceived', 'by', 'people.']",55,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c1eabee9-d646-4781-9792-01e791a0403e,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,"['unknown', 'REALM: retrievalaugmented language model pre-training']","['unknown', '2002']","['unknown', 'Kelvin Guu;Kenton Lee;Zora Tung;Panupong Pasupat;Ming-Wei Chang']",group,"['Different', 'from', 'the', 'above', 'term-based', 'approaches,', 'dense', 'passage', 'retrieval', 'has', 'been', 'proposed', 'to', 'represent', 'both', 'questions', 'and', 'documents', 'as', 'dense', 'vectors', '(i.e.,', 'embeddings),', 'typically', 'in', 'a', 'dual-encoder', 'architecture', '(as', 'shown', 'in', 'Figure', '1a).', 'Existing', 'approaches', 'can', 'be', 'divided', 'into', 'two', 'categories:', '(1)', 'self-supervised', 'pre-training', 'for', 'retrieval', '<ref type=""group"">(Lee et al., 2019, Guu et al., 2020, Chang et al., 2020)</ref>', 'and', '(2)', 'fine-tuning', 'pre-trained', 'language', 'models', 'on', 'labeled', 'data.', 'Our', 'work', 'follows', 'the', 'second', 'class', 'of', 'approaches,', 'which', 'show', 'better', 'performance', 'with', 'less', 'cost.', 'Although', 'the', 'dual-encoder', 'architecture', 'enables', 'the', 'appealing', 'paradigm', 'of', 'dense', 'retrieval,', 'it', 'is', 'difficult', 'to', 'effectively', 'train', 'a', 'retriever', 'with', 'such', 'an', 'architecture.', 'As', 'discussed', 'in', 'Section', '1,', 'it', 'suffers', 'from', 'a', 'number', 'of', 'challenges,', 'including', 'the', 'training', 'and', 'inference', 'discrepancy,', 'a', 'large', 'number', 'of', 'unlabeled', 'positives', 'and', 'limited', 'training', 'data.', 'Several', 'recent', 'studies', '<ref type=""group"">(Karpukhin et al., 2020, Luan et al., 2020, Chang et al., 2020, Henderson et al., 2017)</ref>', 'tried', 'to', 'address', 'the', 'first', 'challenge', 'by', 'designing', 'complicated', 'sampling', 'mechanism', 'to', 'generate', 'hard', 'negatives.', 'However,', 'it', 'still', 'suffers', 'from', 'the', 'issue', 'of', 'false', 'negatives.', 'The', 'later', 'two', 'challenges', 'have', 'seldom', 'been', 'considered', 'for', 'open-domain', 'QA.']",46,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c1fa5f2f-dad1-4ed5-8a8b-7ddb86c29fa9,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['The mathematics of statistical machine translation'],['1993'],['P Brown;S Della Pietra;V Della Pietra;R Mercer'],single,"['Recently', 'researchers', 'in', 'statistical', 'machine', 'translation', 'have', 'developed', 'methods', 'to', 'move', 'beyond', 'single', 'word', 'alignments', 'and', 'create', 'richer', 'translation', 'models', 'that', 'contain', 'phrasal', 'alignments', '<ref type=""single"">(Och and Ney, 2004).</ref>', 'The', 'general', 'method', 'is', 'to', 'induce', 'single', 'word', 'alignments', 'using', 'maximum', 'likelihood', 'estimates', 'obtained', 'from', 'parallel', 'data', 'such', 'as', 'by', 'IBM', 'Model', '1', '<ref type=""single"">(Brown et al., 1993)</ref>', 'and', 'to', 'use', 'these', 'alignments', 'to', 'suggest', 'adjacent', 'words', 'that', 'may', 'compose', 'a', 'meaningful', 'phrase.', 'By', 'examining', 'bidirectional', 'alignments', 'for', 'the', 'same', 'parallel', 'data', 'a', ""'symmetrized"", 'alignment', ""matrix'"", 'can', 'be', 'obtained,', 'and', 'from', 'this', 'information', 'potential', 'translations', 'of', 'word', 'sequences', 'can', 'be', 'obtained.', 'As', 'long', 'as', 'contiguous', 'sequences', 'are', 'examined', 'it', 'does', 'not', 'matter', 'if', 'the', 'two', 'languages', 'have', 'different', 'word', 'order.', 'The', 'approach', 'can', 'be', 'further', 'generalized', 'by', 'working', 'with', 'word', 'classes', 'so', 'that', 'hypotheses', 'for', 'unseen', 'phrases', 'can', 'be', 'generated.']",48,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c2434e48-43c7-45ee-b934-29e84b1d73c8,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Learning transferable visual models from natural language supervision'],['2021'],['Alec Radford;Jong Kim;Chris Hallacy;Aditya Ramesh;Gabriel Goh;Sandhini Agarwal;Girish Sastry;Amanda Askell;Pamela Mishkin;Jack Clark'],single,"['During', 'fine-tuning,', 'for', 'each', 'data', 'point', 'in', 'the', 'original', 'batch', '(B', 'o)', 'of', 'size', 'n,', 'we', 'pick', 'one', 'of', 'its', 'corresponding', 'translations', 'uniformly', 'at', 'random', 'and', 'form', 'a', 'translated', 'batch', '(B', 'p)', 'of', 'the', 'same', 'size', 'n.', 'It', 'is', 'important', 'to', 'note', 'that', 'B', 'o', 'itself', 'is', 'taken', 'from', 'the', 'combined', 'dataset', 'of', 'source', 'instances', 'and', 'translated', 'instances.', 'The', 'two', 'batches', 'that', 'form', 'a', 'pair', 'are', 'denoted', 'as', 'original', 'batch', 'and', 'pair', 'batch,', 'respectively,', 'in', 'Figure', '4.', 'We', 'use', 'the', 'same', 'mBERT', 'network', 'up', 'to', 'a', 'specific', 'layer', 'as', 'our', 'encoder', '(enc)', 'to', 'transform', 'B', 'o', 'and', 'B', 'p', 'to', 'get', 'the', 'embeddings,', 'E', 'o,', 'E', 'p', '∈', 'R', 'n', '*', 't', '*', 'd,', 'respectively.', 'Then,', 'we', 'apply', 'a', 'global', 'average', 'pooling', '(gap)', 'operation', 'to', 'aggregate', 'the', 'vector', 'representations', 'of', 't', 'tokens', 'into', 'a', 'single', 'vector', 'representation', 'of', 'dimension', 'd', 'for', 'each', 'instance', 'in', 'each', 'batch.', 'This', 'will', 'result', 'in', 'the', 'aggregated', 'embeddings', 'O,', 'P', '∈', 'R', 'n', '*', 'd', 'for', 'B', 'o', 'and', 'B', 'p,', 'respectively.', 'With', 'these', 'n', 'feature', 'vectors', 'in', 'the', 'original', 'and', 'the', 'translated', 'batch,', 'we', 'follow', 'the', 'CLIP', '<ref type=""single"">(Radford et al., 2021)</ref>', 'approach', 'and', 'compute', 'the', 'contrastive', 'loss', 'using', 'the', 'cross-entropy', 'loss', '(L', 'ce', ').', 'Specifically,', 'we', 'multiply', 'the', 'matrices', 'O', 'and', 'P', 'T', 'to', 'get', 'the', 'logits', 'matrix', 'Q', '∈', 'R', 'n', '*', 'n.', 'Then,', 'we', 'apply', 'the', 'cross-entropy', 'loss', 'L', 'ce', 'row-wise', 'and', 'column-wise', 'to', 'the', 'logits', 'matrix', 'Q,', 'with', 'its', 'diagonal', 'locations', 'as', 'original', 'classes', 'for', 'each', 'row', 'and', 'column,', 'respectively.O', '=', 'gap(enc(B', 'o', ')),(2)']",183,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
c2870237-481d-4ad7-8033-2f7e3b173c1e,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['The', 'LIGHT', 'Questing', 'Environment.', 'The', 'LIGHT', 'game', 'environment', '<ref type=""single"">(Urbanek et al., 2019)</ref>', '1', 'is', 'a', 'multi-user', 'fantasy', 'text-adventure', 'game', 'consisting', 'of', 'a', 'rich,', 'diverse', 'set', 'of', '1775', 'characters,', '663', 'locations,', 'and', '3462', 'objects.', 'Characters', 'are', 'able', 'to', 'perform', 'templated', 'actions', 'to', 'interact', 'with', 'both', 'objects', 'and', 'characters,', 'and', 'can', 'speak', 'to', 'other', 'characters', 'through', 'free', 'form', 'text', 'dialogues.', 'Actions', 'in', 'text', 'games', 'generally', 'consist', 'of', 'verb', 'phrases', '(VP)', 'followed', 'optionally', 'by', 'prepositional', 'phrases', '(VP', 'PP).', 'For', 'example,', 'get', 'OBJ,', 'put', 'OBJ,', 'give', 'OBJ', 'to', 'CHAR,', 'etc..', 'These', 'actions', 'change', 'the', 'state', 'of', 'the', 'world', 'which', 'is', 'expressed', 'through', 'text', 'descriptions.']",8,"[3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c2b7e0ae-6f8b-40a4-9b4c-35279921651b,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['Slovenska slovnica'],['2000'],['J Toporišič'],single,"['Monolingual', 'and', 'bilingual', 'dictionaries', 'were', 'constructed', 'using', 'a', 'large', 'bilingual', 'word', 'list', 'of', 'unchecked', 'quality.', 'Paradigms', 'were', 'hand-written', 'according', 'to', '<ref type=""single"">(Toporišič, 2000).</ref>']",20,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1]"
c33bdda7-a739-471b-87e3-7516f6d2e7b7,Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets,2021,George-Andrei Dima;Dumitru-Clementin Cercel;Mihai Dascalu,['Approaching smm4h 2020 with ensembles of bert flavours'],['2020'],['George-Andrei Dima;Andrei-Marius Avram;Dumitru-Clementin Cercel'],single,"['Given', 'that', 'Task', '1', 'was', 'present', 'in', 'previous', 'editions', 'of', 'the', 'SMM4h', 'shared', 'task', '<ref type=""group"">(Weissenbacher et al., 2018 (Weissenbacher et al., , 2019,, Klein et al., 2020),</ref>', 'several', 'approaches', 'were', 'employed', 'to', 'address', 'its', 'challenges.', 'For', 'example,', 'the', 'winning', 'team', 'from', '2019', '<ref type=""single"">(Miftahutdinov et al., 2019)</ref>', 'used', 'an', 'ensemble', 'of', 'BioBERT-CRF', 'models', 'for', 'the', 'ADE', 'extraction', 'task,', 'while', 'addressing', 'the', 'resolution', 'task', 'as', 'a', 'classification.', 'The', 'system', 'proposed', 'by', '<ref type=""single"">Miftahutdinov et al. (2020)</ref>', 'ranked', 'first', 'at', 'the', 'end-to-end', '2020', 'competition', 'using', 'the', 'pretrained', 'EnDR-BERT', '<ref type=""single"">(Tutubalina et al., 2020)</ref>', 'and', 'the', 'CSIRO', 'Adverse', 'Drug', 'Event', 'Corpus', '(CADEC)', '<ref type=""single"">(Karimi et al., 2015)</ref>', 'for', 'further', 'training', 'the', 'model.', 'In', 'addition,', '<ref type=""single"">Dima et al. (2020)</ref>', 'showed', 'that', 'bidirectional', 'Transformers', 'trained', 'using', 'class', 'weighting,', 'together', 'with', 'ensembles', 'that', 'combine', 'various', 'configurations,', 'achieve', 'an', 'F1-score', 'of', '.705', 'on', 'the', 'dataset', 'made', 'available', 'for', 'that', 'edition', 'of', 'the', 'competition.']",83,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
c39660ac-2608-4255-b784-aed65067488c,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,"['On the cost of extracting proximity features for term-dependency models', 'Feature extraction for large-scale text collections']","['2015', '2020']","['Xiaolu Lu;Alistair Moffat;J Culpepper', 'Luke Gallagher;Antonio Mallia;J Culpepper;Torsten Suel;B Barla Cambazoglu']",group,"['Proximity-based', 'features', 'Traditional', 'retrieval', 'models', 'assume', 'terms', 'are', 'independent', 'and', 'ignore', 'their', 'relationships,', 'but', 'the', 'proximity', 'among', 'query', 'terms', 'often', 'serves', 'as', 'an', 'important', 'relevance', 'signal.', 'Thus,', 'we', 'include', 'features', 'that', 'directly', 'capture', 'the', 'proximity', 'of', 'query', 'terms,', 'such', 'as', 'the', 'counts', 'of', 'ordered', 'and', 'unordered', 'co-occurrence', 'of', 'bigrams', 'within', 'different', 'window', 'sizes.', 'We', 'compute', 'the', 'scores', 'of', 'proximity-based', 'retrieval', 'functions,', 'such', 'as', 'SDM', '<ref type=""group"">(Metzler and Croft, 2005, Gallagher et al., 2020)</ref>', 'and', 'BM25-TP', '<ref type=""group"">(Lu et al., 2015, Gallagher et al., 2020),</ref>', 'as', 'our', 'features.']",67,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2]"
c3e81620-6b45-44d5-959e-00e3e5f04b38,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,['Looking beyond the surface: A challenge set for reading comprehension over multiple sentences'],['2018'],['Daniel Khashabi;Snigdha Chaturvedi;Michael Roth;Shyam Upadhyay;Dan Roth'],single,"['improves', 'the', 'performance', 'on', 'some', 'coreferencerelated', 'datasets', '<ref type=""group"">(Wu et al., 2020b, Aralikatte et al., 2019).</ref>', 'There', 'are', 'also', 'various', 'datasets', 'for', 'the', 'task', 'of', 'reading', 'comprehension', 'on', 'which', 'the', 'model', 'requires', 'to', 'perform', 'coreference', 'reasoning', 'to', 'answer', 'some', 'of', 'the', 'questions,', 'e.g.,', 'DROP', '<ref type=""single"">(Dua et al., 2019),</ref>', 'DuoRC', '<ref type=""single"">(Saha et al., 2018),</ref>', 'MultiRC', '<ref type=""single"">(Khashabi et al., 2018),</ref>', 'etc.']",40,"[3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1, 0]"
c3ffb89d-9303-40e8-b997-5f507d45e8d9,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,"['Creating an Annotated Corpus for Sentiment Analysis of German Product Reviews', 'Multilingual twitter sentiment classification: The role of human annotators']","['2013', '2016']","['Katarina Boland;Andias Wira-Alam;Reinhard Messerschmidt', 'Igor Mozetič;Miha Grčar;Jasmina Smailović']",group,"['Previous', 'annotation', 'tasks', 'have', 'shown', 'that', 'even', 'with', 'binary', 'or', 'ternary', 'classification', 'schemes,', 'human', 'annotators', 'agree', 'only', 'about', '70-80%', 'of', 'the', 'time', 'and', 'the', 'more', 'categories', 'there', 'are,', 'the', 'harder', 'it', 'becomes', 'for', 'annotators', 'to', 'agree', '<ref type=""group"">(Boland et al., 2013, Mozetič et al., 2016).</ref>', 'For', 'example,', 'when', 'creating', 'the', 'DENS', 'dataset', '<ref type=""single"">(Liu et al., 2019),</ref>', 'only', '21%', 'of', 'their', 'annotations', 'had', 'consensus', 'between', 'all', 'annotators', 'with', '73.5%', 'having', 'to', 'resort', 'to', 'majority', 'agreement,', 'and', 'a', 'further', '5.5%', 'could', 'not', 'be', 'agreed', 'upon', 'and', 'were', 'left', 'to', 'expert', 'annotators', 'to', 'be', 'resolved.']",36,"[3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c45aa521-f82c-446c-a9db-f13595450d2c,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['We ir. 1993. Parsing some constrained grammar formalisms. Co m putational Linguistics'],['unknown'],['K Vijay-Shanker;D unk'],single,"['To', 'parse', 'this', 'type', 'of', 'grammars,', 'tabulation', 'techniques', 'with', 'polynomial', 'complexity', 'can', 'be', 'designed', 'based', 'on', 'a', 'property', 'defined', 'in', '<ref type=""single"">[17],</ref>', 'that', 'we', 'call', 'context-freeness', 'property', 'of', 'LIG,', 'establishing', 'that', 'ifA[,]', '⇒', 'uB[', ']w', 'where', 'u,', 'w', 'E', 'v,,', 'A,', 'B', 'E', 'VN,,', 'E', 'Vi', 'U', '{€}', 'and', 'B[]', 'is', 'a', 'dependent', 'descendant', 'of', 'A[,],', 'then', 'for', 'each', 'Yi,', 'Y2', 'E_', '(VN[Vt]', 'U', 'VT', ')*and', '/3', 'E', 'V/', 'we', 'have', 'Y1', 'A[/3,]Y2', '⇒', 'Y1uB[,B]wY2.', 'Also,', 'if', 'B[,]', 'is', 'a', 'dependent', 'descendant', 'of', 'A[]', 'and', 'A[]', '⇒', 'uB[,]w', 'then', 'Y', '1', 'A[/3]Y', '2', '⇒', 'Y', '1', 'uB', '[/3,]wY', '2.']",20,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c45ea55b-d55f-4611-bafa-d55298cc8345,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['Feverous: Fact extraction and verification over unstructured and structured information'],['2021'],['Rami Aly;Zhijiang Guo;M Schlichtkrull;James Thorne'],single,"['Fact', 'Verification', 'over', 'Structured', 'and', 'Unstructured', 'Evidence', 'FEVEROUS', '<ref type=""single"">(Aly et al., 2021)</ref>', 'is', 'the', 'first', 'dataset', 'of', 'fact', 'verification', 'on', 'structured', 'and', 'unstructured', 'evidence.', 'Many', 'previous', 'works', 'follow', 'the', 'baseline', 'settings', 'and', 'convert', 'all', 'evidence', 'to', 'text', 'format', 'to', 'perform', 'evidence', 'interaction.', 'They', 'transform', 'each', 'cell', 'to', 'header-value', 'pairs', '<ref type=""group"">(Aly et al., 2021, Malon, 2021)</ref>', 'or', 'in', 'a', 'cell', 'location', 'indication', 'type', '<ref type=""single"">(Kotonya et al., 2021a).</ref>', 'They', 'pay', 'less', 'attention', 'to', 'making', 'the', 'converted', 'text', 'more', 'consistent', 'with', 'natural', 'language', 'expressions', 'or', 'identifying', 'what', 'the', 'context', 'cells', 'represent.', '<ref type=""single"">Bouziane et al. (2021)</ref>', 'propose', 'to', 'convert', 'all', 'evidence', 'to', 'tables.', 'They', 'simply', 'convert', 'each', 'sentence', 'to', 'a', '2-cell', 'table', 'with', 'the', 'Wikipedia', 'title', 'and', 'itself', 'instead', 'of', 'packing', 'closely-tied', 'evidence', 'and', 'building', 'a', 'global', 'evidence', 'table.', 'There', 'are', 'also', 'works', 'focusing', 'on', 'the', 'first', 'two', 'steps', 'two', 'improve', 'the', 'final', 'results.', '<ref type=""single"">Saeed et al. (2021)</ref>', 'propose', 'to', 'add', 'a', 'document', 're-ranker', 'to', 'strengthen', 'the', 'document', 'retrieval.', 'Multi-hop', 'Dense', 'Retriever', '<ref type=""single"">(Bouziane et al., 2021)</ref>', 'and', 'T5', 'generator', '<ref type=""single"">(Malon, 2021)</ref>', 'are', 'introduced', 'to', 'better', 'extract', 'multi-hop', 'evidence.']",8,"[0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c4982e58-c244-41ba-a6c1-7883e8d1fe83,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,['ALBERT: A lite BERT for self-supervised learning of language representations'],['2019'],['Zhenzhong Lan;Mingda Chen;Sebastian Goodman;Kevin Gimpel;Piyush Sharma;Radu Soricut'],single,"['In', 'this', 'paper,', 'we', 'introduce', 'our', 'system', 'for', 'the', 'lexical', 'complexity', 'prediction', 'task', 'of', 'the', 'SemEval-2021', '<ref type=""single"">(Matthew et al., 2021).</ref>', 'We', 'fulfill', 'this', 'task', 'by', 'leveraging', 'multiple', 'pre-trained', 'language', 'models', '(PLM)', 'with', 'different', 'training', 'strategies.', 'There', 'are', 'two', 'main', 'steps', 'for', 'our', 'system:', '(i)', 'fine-tuning', 'numbers', 'of', 'heterogeneous', 'PLMs,', 'including', 'BERT', '<ref type=""single"">(Devlin et al., 2019),</ref>', 'ALBERT', '<ref type=""single"">(Lan et al., 2019),</ref>', 'RoBERTa', '<ref type=""single"">(Liu et al., 2019)</ref>', 'and', 'ERNIE', '<ref type=""single"">(Zhang et al., 2019),</ref>', 'with', 'various', 'hyperparameters', 'and', 'training', 'strategies,', 'obtaining', 'diverse', 'models,', '(ii)', 'applying', 'an', 'effective', 'stacking', 'mechanism', 'on', 'top', 'of', 'these', 'PLMs', 'to', 'predict', 'the', 'final', 'complexity', 'scores.']",50,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
c4d30f90-45e1-4460-b739-fab1505a3944,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,"['WorldTree V2: A Corpus of Science-Domain Structured Explanations and Inference Patterns supporting Multi-Hop Inference', 'WorldTree: A Corpus of Explanation Graphs for Elementary Science Questions supporting Multi-hop Inference']","['2020', '2018']","['Zhengnan Xie;Sebastian Thiem;Jaycie Martin;Elizabeth Wainwright;Steven Marmorstein;Peter Jansen', 'Peter Jansen;Elizabeth Wainwright;Steven Marmorstein;Clayton Morrison']",group,"['Constructing', 'long', 'inference', 'chains', 'can', 'be', 'extremely', 'challenging', 'for', 'existing', 'models,', 'which', 'generally', 'exhibit', 'a', 'large', 'drop', 'in', 'performance', 'when', 'composing', 'explanations', 'and', 'inference', 'chains', 'requiring', 'more', 'than', '2', 'inference', 'steps', '<ref type=""group"">(Fried et al., 2015, Jansen et al., 2017 Jansen et al., , 2018,, Khashabi et al., 2019, Yadav et al., 2020).</ref>', 'To', 'this', 'end,', 'this', 'Shared', 'Task', 'on', 'Multi-hop', 'Inference', 'for', 'Explanation', 'Regeneration', '<ref type=""group"">(Jansen and Ustalov, 2019, 2020)</ref>', 'has', 'focused', 'on', 'expanding', 'the', 'capacity', 'of', 'models', 'to', 'compose', 'long', 'inference', 'chains,', 'where', 'participants', 'are', 'asked', 'to', 'develop', 'systems', 'capable', 'of', 'reconstructing', 'detailed', 'explanations', 'for', 'science', 'exam', 'questions', 'drawn', 'from', 'the', 'WorldTree', 'explanation', 'corpus', '<ref type=""group"">(Xie et al., 2020, Jansen et al., 2018),</ref>', 'which', 'range', 'in', 'compositional', 'complexity', 'from', '1', 'to', '16', 'facts', '(with', 'the', 'average', 'explanation', 'including', '6', 'facts).']",80,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3]"
c4e8d6e3-8fdb-4fdb-8b24-dfdf26c3e310,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,['A large annotated corpus for learning natural language inference'],['2015'],['Gabor Samuel R Bowman;Christopher Angeli;Christopher D Potts;unk Manning'],single,"['Visual', 'Entailment', '(VE):', 'VE', 'task', 'aims', 'to', 'predict', 'whether', 'an', 'image', 'semantically', 'entails', 'the', 'text', 'and', 'requires', 'fine-grained', 'reasoning', 'ability', 'in', 'a', 'model.', 'VE', 'dataset', 'is', 'built', 'upon', 'SNLI', '<ref type=""single"">(Bowman et al., 2015)</ref>', 'and', 'Flickr30k.', 'Each', 'image-text', 'pair', 'is', 'assigned', 'with', 'one', 'of', 'three', 'classes:', 'entailment,', 'neutral,', 'contradiction.', 'As', 'in', 'UNITER,', 'we', 'formulate', 'it', 'as', '3-way', 'classification', 'problem', 'based', 'on', 'h', 'cls.', 'The', 'batch', 'size', 'is', '32', 'per', 'GPU', 'while', 'other', 'finetuning', 'strategies', 'are', 'the', 'same.']",29,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c4f927ee-8350-45e8-86e6-47de9f29c88e,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation'],['2018'],['Mikel Artetxe;Gorka Labaka;Iñigo Lopez-Gazpio;Eneko Agirre'],single,"['To', 'model', 'such', 'indirect', 'connections,', 'we', 'multiply', 'the', 'relatedness', 'matrix', 'by', 'itself,', 'and', 'use', 'the', 'values', 'of', 'the', 'squared', 'matrix', 'S', '′', 'as', 'the', 'relatedness', 'measure', 'between', 'two', 'words.', 'By', 'the', 'definition', 'of', 'matrix', 'multiplication,S', '′', 'ij', '=', 'n', 'k=1', 's', 'i,k', 's', 'k,j', ',that', 'is,', 'if', 'we', 'define', 'G', '0', 'as', 'a', 'graph', 'whose', 'neighborhood', 'matrix', 'is', 'the', 'NPMI', 'matrix', 'then', 'S', '′', 'ij', 'is', 'the', 'sum', 'of', 'the', 'product', 'of', 'the', 'weights', 'on', 'all', 'two-length', 'paths', 'v', 'i', '−', 'v', 'k', '−', 'v', 'j', 'in', 'G', '0.', 'Since', 'all', 'edge', 'weights', 'are', 'between', '0', 'and', '1,', 'considering', 'the', 'weight', 'of', 'a', 'path', 'as', 'the', 'product', 'of', 'its', 'edge', 'weights', 'gives', 'a', 'valid', 'relatedness', 'measure:', 'longer', 'paths', 'and', 'paths', 'that', 'contain', 'smaller', 'weights', 'will', 'yield', 'to', 'smaller', 'relatedness', 'values.', '<ref type=""single"">Artetxe et al. (2018)</ref>', 'also', 'showed', 'on', 'word', 'embeddings,', 'that', 'different', 'powers', 'of', 'embedding', 'matrices', 'are', 'beneficial', 'for', 'word', 'similarity', 'and', 'word', 'relatedness', 'tasks,', 'and', 'that', 'the', 'optimal', 'power', 'is', 'higher', 'for', 'relatedness', 'than', 'for', 'similarity.']",130,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
c5cf19ad-0bff-4b2a-9222-92ec756ac0e8,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Decoupled weight decay regularization'],['2019'],['Ilya Loshchilov;Frank Hutter'],single,"['For', 'trace', 'feature,', 'we', 'use', 'τ', '=', '0.4s', 'to', 'extract', 'trace', 'segment', 'for', 'feature', 'extraction.', 'The', 'embedding', 'size', 'd,', 'number', 'of', 'transformer', 'layers,', 'hidden', 'size', 'of', 'the', 'transformer', 'feed-forward', 'layer', 'are', '768,', '2,', 'and', '768,', 'respectively.', 'The', 'number', 'of', 'attention', 'heads', 'is', '8,', 'and', 'the', 'dropout', 'rate', 'is', '0.1.', 'We', 'adopt', 'the', 'Adam-W', 'optimizer', '<ref type=""single"">(Loshchilov and Hutter, 2019)</ref>', 'with', 'learning', 'rate', 'of', '7e-4(which', 'is', 'the', 'best', 'performance', 'setting', 'of', 'baseline,', 'and', 'adopted', 'widely', 'for', 'other', 'trials),', 'and', 'set', 'two', 'momentum', 'parameters', 'β', '1', '=', '0.9', 'and', 'β', '2', '=', '0.99.', 'We', 'set', 'the', 'batch', 'size', 'to', '256.', 'All', 'models', 'are', 'trained', 'on', '4', 'Tesla', 'V100', 'GPUs', 'with', '32GB', 'memory', 'for', '10', 'to', '12', 'hours.']",54,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
c6821ffc-c5ac-493b-9a7f-fb86cad58859,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['ChAII -Hindi and Tamil question answering'],['2021'],['unk Google'],single,"['We', 'propose', 'a', 'three-stage', 'pipeline', 'called', 'Multilingual', 'Constrative', 'Training', '(MuCoT)', 'to', 'effectively', 'train', 'the', 'mBERT', 'model', 'for', 'question-answering', 'in', 'low-resource', 'languages.', 'An', 'illustration', 'of', 'this', 'pipeline', 'for', 'two', 'low-resource', 'languages,', 'namely', 'Tamil', 'and', 'Hindi,', 'is', 'shown', 'in', 'Figure', '3.', 'The', 'first', 'stage', 'is', 'pre-training', 'the', 'baseline', 'multilingual', 'model', '(mBERT).', 'The', 'second', 'stage', 'involves', 'pre-training', 'the', 'QA', 'head', 'using', 'the', 'large-scale', 'dataset(s)', 'in', 'high', 'resource', 'language(s).', 'In', 'Figure', '3,', 'English', 'is', 'considered', 'the', 'high-resource', 'language', 'and', 'SQuAD', '<ref type=""single"">(Rajpurkar et al., 2016)</ref>', 'dataset', 'is', 'used', 'to', 'pre-train', 'the', 'QA', 'head', 'and', 'obtain', 'the', 'mBERT-QA', 'model.', 'The', 'final', 'stage', 'involves', 'fine-tuning', 'the', 'mBERT-QA', 'model', 'using', 'both', 'original', 'and', 'augmented', 'samples', 'from', 'the', 'target', 'low-resource', 'languages.', 'In', 'this', 'work,', 'ChAII', '<ref type=""single"">(Google, 2021)</ref>', 'dataset', 'is', 'used', 'for', 'obtaining', 'training', 'samples', 'in', 'Tamil', 'and', 'Hindi.']",113,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
c6c13533-48e8-456a-a244-4f2f05252078,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Glove: Global vectors for word representation'],['2014'],['Jeffrey Pennington;Richard Socher;Christopher D Manning'],single,"['Another', 'graph,', 'created', 'as', 'an', 'alternative', 'for', 'word', 'embeddings,', 'is', 'GraphGlove', '<ref type=""single"">(Ryabinin et al., 2020),</ref>', 'where', 'the', 'edges', 'of', 'the', 'graph', 'are', 'optimized', 'by', 'the', 'cost', 'function', 'of', 'GloVe', '<ref type=""single"">(Pennington et al., 2014b),</ref>', 'so', 'that', 'the', 'shortest', 'path', 'between', 'two', 'vertices', 'gives', 'the', 'distance', 'of', 'the', 'corresponding', 'words.']",26,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
c782ec57-4a75-47d8-91f4-8f65bf69ea65,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,"['Word-level textual adversarial attacking as combinatorial optimization', 'Generating natural language adversarial examples']","['2020', '2018']","['Yuan Zang;Fanchao Qi;Chenghao Yang;Zhiyuan Liu;Meng Zhang;Qun Liu;Maosong Sun', 'Moustafa Alzantot;Yash Sharma;Ahmed Elgohary;Bo-Jhang Ho;Mani Srivastava;Kai-Wei Chang']",group,"['Recent', 'studies', 'show', 'that', 'NLP', 'models', 'are', 'vulnerable', 'to', 'adversarial', 'perturbations.', 'A', 'seemingly', '""invariance', 'transformation""', '(a.k.a.', 'adversarial', 'perturbation)', 'such', 'as', 'synonym', 'substitutions', '<ref type=""group"">(Alzantot et al., 2018, Zang et al., 2020)</ref>', 'or', 'syntax-guided', 'paraphrasing', '<ref type=""group"">(Iyyer et al., 2018, Huang and Chang, 2021)</ref>', 'can', 'alter', 'the', 'prediction.', 'To', 'mitigate', 'the', 'model', 'vulnerability,', 'robust', 'training', 'methods', 'have', 'been', 'proposed', 'and', 'shown', 'effective', '<ref type=""group"">(Miyato et al., 2017, Jia et al., 2019, Huang et al., 2019, Zhou et al., 2020).</ref>']",22,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c8dfb5ed-c3d5-4af5-ae7e-8ec57034cb57,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['Bleu: a method for automatic evaluation of machine translation'],['2002'],['Kishore Papineni;Salim Roukos;Todd Ward;Wei-Jing Zhu'],single,"['While', 'manual,', 'human', 'evaluation', 'of', 'machine', 'translation', '(MT)', 'systems', 'is', 'still', 'the', 'gold', 'standard,', 'automatic', 'evaluation', 'metrics', 'have', 'long', 'been', 'used', 'for', 'their', 'relative', 'speed', 'and', 'inexpensiveness.', 'Early', 'automatic', 'metrics', 'were', 'easy', 'to', 'implement', 'and', 'somewhat', 'correlated', 'with', 'human', 'judgements,', 'but', 'have', 'clear', 'limitations:', 'BLEU', '<ref type=""single"">(Papineni et al., 2002)</ref>', 'relies', 'on', 'n-gram', 'overlap,', 'and', 'is', 'thus', 'not', 'robust', 'to', 'differing', 'word', 'order', 'or', 'choice.', 'In', 'contrast,', 'ME-TEOR', '<ref type=""single"">(Lavie and Agarwal, 2007)</ref>', 'requires', 'training,', 'but', 'depends', 'on', 'token', 'alignment,', 'which', 'is', 'also', 'a', 'fraught', 'task.']",45,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
c8e1a2b9-62ed-4aff-bcbd-079acade107c,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['CCG augmented hierarchical phrase-based machine translation'],['2010'],['H Almaghout;J Jiang;A Way'],single,"['Using', 'CCG', 'categories', 'to', 'label', 'non-terminals', 'in', 'HPB', 'rules', 'can', 'produce', 'better', 'translation', 'quality', 'and', 'smaller', 'trans-lation', 'models', 'in', 'comparison', 'with', 'SAMT', '<ref type=""single"">[12].</ref>', 'CCG', 'nonterminal', 'labels', 'are', 'less', 'sparse', 'and', 'represent', 'richer', 'and', 'more', 'accurate', 'syntactic', 'constraints', 'compared', 'to', 'SAMT', 'nonterminal', 'labels', '<ref type=""single"">[12].</ref>']",22,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
c8f9e443-f9ed-44c7-8743-e433bc231276,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,"['Comparing models of associative meaning: An empirical investigation of reference in simple language games', 'Lexical co-occurrence and association strength']","['2018', '1990']","['Matthias Judy Hanwen Shen;Bjarke Hofer;Roger Felbo;unk Levy', 'P Donald;Kimberly Spence;unk Owens']",group,"['Considering', 'the', 'previous', 'results', 'on', 'the', 'relationship', 'between', 'associations', 'and', 'co-occurrences', '(Spence', 'and', '<ref type=""group"">Owens, 1990, Shen et al., 2018),</ref>', 'we', 'create', 'our', 'distance', 'matrices', 'not', 'from', 'the', 'latest', 'neural', 'methods', 'of', 'NLP,', 'but', 'from', 'co-occurrences', 'counted', '1', 'The', 'game:', 'http://spymasters.herokuapp.com/', 'Source', 'code', 'and', 'data:', 'https://github.com/xerevity/', 'CodeNamesAgent', 'in', 'raw', 'text.', 'As', 'English', 'corpora', 'we', 'use', 'the', 'concatenation', 'of', 'the', 'English', 'Wikipedia', 'and', 'the', 'English', 'OpenSubtitles', 'corpus,', 'consisting', 'of', '5.692', 'billion', 'tokens', 'in', 'total.', 'For', 'Hungarian,', 'we', 'use', 'the', 'lemmatized', 'version', 'of', 'the', 'Hungarian', 'Webcorpus', '(Nemeskey,', '2020),', 'also', 'including', 'the', 'Hungarian', 'Wikipedia', '(1.414', 'billion', 'tokens).', 'We', 'work', 'with', 'vocabulary', 'sizes', '15K', 'in', 'English', 'and', '10K', 'in', 'Hungarian,', 'and', 'remove', 'stopwords.']",13,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
c8feb0eb-e4da-47df-9bd2-f72f75072d86,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Bleu: a method for automatic evaluation of machine translation'],['2002'],['Kishore Papineni;Salim Roukos;Todd Ward;Wei-Jing Zhu'],single,"['The', 'train', 'data', 'have', 'been', 'extracted', 'from', 'different', 'domains', 'and', 'sources,', 'which', 'are', 'not', 'necessarily', 'the', 'same', 'as', 'the', 'evaluation', 'sets', 'provided', 'for', 'the', 'Shared', 'Task.', 'Therefore,', 'the', 'official', 'development', 'set', '(995', 'sentences', 'per', 'language)', 'is', 'split', 'into', 'three', 'parts:', '25%-25%-50%.', 'The', 'first', 'two', 'parts', 'are', 'our', 'custom', 'dev', 'and', 'devtest', 'sets', '3.', 'We', 'add', 'the', '50%', 'section', 'to', 'the', 'training', 'set', 'with', 'a', 'sampling', 'distribution', 'of', '20%,', 'to', 'reduce', 'the', 'domain', 'gap', 'in', 'the', 'training', 'data.', 'Likewise,', 'we', 'extract', 'a', 'sample', 'of', 'the', 'training', 'and', 'double', 'the', 'size', 'of', 'the', 'development', 'set.', 'The', 'mixed', 'data', 'in', 'the', 'validation', 'set', 'is', 'relevant,', 'as', 'it', 'allows', 'to', 'evaluate', 'how', 'the', 'model', 'fits', 'with', 'all', 'the', 'domains.', 'We', 'used', 'the', 'same', 'multi-text', 'sentences', 'for', 'evaluation,', 'and', 'avoid', 'any', 'overlapping', 'of', 'the', 'Spanish', 'side', 'with', 'the', 'training', 'set,', 'this', 'is', 'also', 'important', 'as', 'we', 'are', 'going', 'to', 'evaluate', 'multilingual', 'models.', 'Evaluation', 'for', 'all', 'the', 'models', 'used', 'BLEU', '<ref type=""single"">(Papineni et al., 2002)</ref>', 'and', 'chrF', '<ref type=""single"">(Popović, 2015)</ref>', 'metrics.']",154,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 3, 3]"
c92274f4-90eb-4d64-96a6-35fbac37acac,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['XenC: An open-source tool for data selection in natural language processing'],['2013'],['A Rousseau'],single,"['We', 'evaluate', 'our', 'experiments', 'on', 'the', 'English', 'to', 'French', 'Spoken', 'Language', 'Translation', 'task', 'from', 'IWSLT', '2015', 'evaluation', 'campaign', '3.', 'A', 'data', 'selection', 'method', '<ref type=""single"">[18]</ref>', 'consisting', 'on', 'scoring', 'the', 'sentences', 'according', 'to', 'a', 'in-domain', 'language', 'model', 'has', 'been', 'applied.', 'We', 'have', 'used', 'as', 'available', 'parallel', 'corpora', '(news-commentary,', 'united-nations,', 'europarl,', 'wikipedia,', 'and', 'two', 'crawled', 'corpora)', 'and', 'Technology', 'Entertainment', 'Design', '(TED', '4)', 'corpus', 'as', 'in-domain', 'corpus.', 'The', 'data', 'selection', 'allows', 'us', 'to', 'train', 'the', 'models', 'in', 'a', 'faster', 'way', 'taking', 'into', 'account', 'the', 'sentences', 'which', 'contain', 'relevant', 'information', 'of', 'the', 'domain', 'and', 'avoids', 'noisy', 'data.', 'We', 'also', 'did', 'a', 'preprocessing', 'to', 'convert', 'html', 'entities', 'and', 'filter', 'out', 'the', 'sentences', 'with', 'more', 'than', '50', 'words', 'for', 'both', 'source', 'and', 'target', 'languages.', 'We', 'finally', 'end', 'up', 'with', 'a', 'selected', 'corpus', 'of', '2M', 'sentences', '(50.5', 'millions', 'of', 'words),', 'leading', 'to', '147K', 'unique', 'tokens', 'for', 'English', 'side', 'and', '266K', 'unique', 'tokens', 'for', 'French', 'side.']",23,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
ca45ebfe-fa15-4881-85ae-cadd9bba63ac,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['Five papers on wordnet'],['1990'],['G Miller;R Beckwith;C Fellbaum;D Gross;K Miller'],single,"['Two', 'current', 'approaches', 'to', 'English', 'verb', 'classifications', 'are', 'WordNet', 'synonym', 'sets', '<ref type=""single"">[9]</ref>', 'and', 'Levin', 'classes', '<ref type=""single"">[8].</ref>', 'WordNet', 'is', 'an', 'on-line', 'lexical', 'database', 'of', 'English', 'that', 'currently', 'contains', 'about', '120,000', 'sets', 'of', 'noun,', 'verb', 'adjective,', 'and', 'adverb', 'synonyms,', 'each', 'representing', 'a', 'lexicalized', 'concept.', 'A', 'synset', '(synonym', 'set)', 'contains', 'besides', 'all', 'the', 'word', 'forms', 'that', 'can', 'refer', 'to', 'a', 'given', 'concept,', 'a', 'definitional', 'gloss', 'and', '-in', 'most', 'cases', '-an', 'example', 'sentence.', 'Words', 'and', 'synsets', 'are', 'interrelated', 'by', 'means', 'of', 'lexical', 'and', 'semantic-conceptual', 'links,', 'respectively.', 'Antonymy', 'or', 'semantic', 'opposition', 'links', 'individual', 'words,', 'while', 'the', 'super-/subordinate', 'relation', 'links', 'entire', 'synsets.', 'WordNet', 'was', 'designed', 'principally', 'as', 'a', 'semantic', 'network,', 'and', 'contains', 'little', 'syntactic', 'information.']",11,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
caad037e-0200-4b18-8588-4625e5521b5a,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Two Models of Grammatical Description'],['1954'],['Charles Hockett'],single,"['(2)', 'a.', 'sing', 'song', 'b.', 'fleur', 'floral', '<ref type=""single"">Hockett (1954)</ref>', 'outlines', 'two', 'models', 'of', 'describing', 'what', 'we', 'can', 'observe', 'in', 'these', 'examples.', 'In', 'the', 'Item', 'and', 'Arrangement', '(IA)', 'model,', '(1a)', 'is', 'the', 'combination', 'of', 'a', 'stem', 'clear', 'and', 'a', 'prefix', 'un.', 'This', 'combination', 'results', 'in', 'the', 'concatenation', 'of', 'the', 'two', 'forms', 'and', 'the', 'compositional', 'combination', 'of', 'syntactic', 'and', 'semantic', 'properties.', 'In', '(1a)', 'the', 'result', 'is', 'a', 'form', 'unclear', 'with', 'the', 'syntactic', 'category', 'Adjective', 'and', 'the', 'meaning', 'of', 'an', 'antonym', 'of', 'clear.', 'The', 'examples', 'in', '(2)', 'require', 'additional', 'rules', 'to', 'modify', 'the', 'stem.', 'In', '(2a),', 'stem', 'vowel', 'change', 'is', 'the', 'only', 'thing', 'marking', 'the', 'difference', 'between', 'the', 'two', 'words.', 'The', 'alternative', 'model', 'is', 'called', 'Item', '&amp,', 'Process', '(IP).', 'In', 'this', 'model,', 'word', 'formation', 'rules', 'are', 'processes', 'applying', 'to', 'a', 'base.', 'In', '(1a),', 'the', 'process', 'adds', 'un', 'to', 'the', 'left', 'of', 'the', 'stem', 'clear.', 'In', '(2a),', 'the', 'process', 'changes', 'the', 'stem', 'vowel', 'of', 'sing.', 'In', 'IP', 'there', 'are', 'no', 'morphemes', 'but', 'only', 'lexemes', 'and', 'processes.', 'In', 'modern', 'morphological', 'theories', 'both', 'are', 'represented,', 'e.g.', '<ref type=""single"">Lieber (1992)</ref>', 'for', 'IA', 'and', '<ref type=""single"">Anderson (1992)</ref>', 'for', 'IP.', 'An', 'important', 'difference', 'for', 'our', 'purposes', 'is', 'that', 'in', 'IA', 'we', 'have', 'a', 'tree', 'structure', 'whereas', 'in', 'IP', 'we', 'have', 'a', 'derivation', 'history.', 'A', 'tree', 'structure', 'represents', 'the', 'relationship', 'between', 'morphemes,', 'e.g.', '(3).', 'A', 'derivation', 'history', 'lists', 'the', 'different', 'stages', 'rules', 'applying,', 'e.g.', '(4).', 'It', 'should', 'be', 'noted', 'that', 'there', 'are', 'many', 'variants', 'of', 'IA', 'and', 'IP.', 'The', 'reason', 'we', 'are', 'interested', 'in', 'word', 'formation', 'rules', 'is', 'their', 'productivity.', 'Productivity', 'is', 'a', 'difficult', 'and', 'controversial', 'concept,', 'cf.', '<ref type=""single"">Bauer (2001).</ref>', 'Basically,', 'a', 'productive', 'word', 'formation', 'rule', 'can', 'be', 'used', 'to', 'produce', 'new', 'lexical', 'items.', 'When', 'a', 'speaker', 'has', 'a', 'productive', 'word', 'formation', 'rule', 'at', 'her', 'disposal,', 'she', 'can', 'use', 'a', 'word', 'not', 'in', 'her', 'mental', 'lexicon', 'and', 'be', 'understood', 'as', 'far', 'as', 'other', 'speakers', 'have', 'the', 'same', 'word', 'formation', 'rule', 'available.', 'The', 'productivity', 'of', 'word', 'formation', 'makes', 'it', 'impossible', 'to', 'cover', 'the', 'entire', 'lexicon', 'in', 'a', 'finite', 'list.']",7,"[0, 3, 3, 3, 3, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cae64c10-3d1e-4811-bc88-a6a5f25250de,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,"['Neural sequence learning models for word sense disambiguation', 'Quasi bidirectional encoder representations from transformers for word sense disambiguation']","['2017', '2019']","['Alessandro Raganato;Claudio Bovi;Roberto Navigli', 'Michele Bevilacqua;Roberto Navigli']",group,"['Supervised', 'systems', 'Supervised', 'systems', 'rely', 'on', 'semantically-annotated', 'corpora', 'for', 'training', '<ref type=""group"">(Raganato et al., 2017, Bevilacqua and Navigli, 2019).</ref>', 'Early', 'approaches', 'were', 'based', 'on', 'traditional', 'machine', 'learning', 'algorithms', 'like', 'support', 'vector', 'machines', '<ref type=""single"">(Iacobacci et al., 2016).</ref>', 'With', 'the', 'word', 'embedding-based', 'approaches', 'getting', 'popular', 'in', 'natural', 'language', 'processing', 'tasks,', 'more', 'recent', 'approaches', 'on', 'WSD', 'were', 'based', 'on', 'neural', 'network', 'architectures', '<ref type=""group"">(Melamud et al., 2016, Raganato et al., 2017).</ref>', 'However,', 'they', 'rely', 'on', 'large', 'manuallycurated', 'training', 'data', 'to', 'train', 'the', 'machine', 'learning', 'models', 'which', 'in', 'turn', 'hinders', 'the', 'ability', 'of', 'these', 'approaches', 'to', 'scale', 'over', 'unseen', 'words', 'and', 'new', 'languages.', 'More', 'recently,', 'contextual', 'representations', 'of', 'words', 'have', 'been', 'used', 'in', 'WSD', 'where', 'the', 'contextual', 'representations', 'have', 'been', 'employed', 'for', 'the', 'creation', 'of', 'sense', 'embeddings', '<ref type=""single"">(Peters et al., 2018).</ref>', 'However,', 'they', 'also', 'rely', 'on', 'sense-annotated', 'corpora', 'to', 'gather', 'contextual', 'information', 'for', 'each', 'sense,', 'and', 'hence', 'are', 'limited', 'to', 'languages', 'for', 'which', 'gold', 'annotations', 'are', 'available.', 'A', 'very', 'recent', 'approach', 'SensEmBERT', '<ref type=""single"">(Scarlini et al., 2020)</ref>', 'provide', 'WSD', 'by', 'leveraging', 'the', 'mapping', 'between', 'senses', 'and', 'Wikipedia', 'pages,', 'the', 'relations', 'among', 'BabelNet', 'synsets', 'and', 'the', 'expressiveness', 'of', 'contextualised', 'embeddings,', 'getting', 'rid', 'of', 'manual', 'annotations.', 'However,', 'SensEmBERT', '<ref type=""single"">(Scarlini et al., 2020)</ref>', 'only', 'supports', 'five', 'languages', 'making', 'it', 'difficult', 'to', 'use', 'with', 'other', 'languages.']",10,"[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cb1ddfeb-57cc-43b7-9e85-7b4e76edf8f9,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['The syntactic process'],['2000'],['M Steedman'],single,"['CCG', '<ref type=""single"">[5]</ref>', 'is', 'a', 'grammar', 'formalism', 'which', 'consists', 'of', 'a', 'lexicon', 'that', 'pairs', 'words', 'with', 'lexical', 'categories', '(supertags)', 'and', 'a', 'set', 'of', 'combinatory', 'rules', 'which', 'specify', 'how', 'the', 'categories', 'are', 'combined.', 'A', 'supertag', 'is', 'a', 'rich', 'syntactic', 'description', 'that', 'specifies', 'the', 'local', 'syntactic', 'context', 'of', 'the', 'word', 'in', 'the', 'form', 'of', 'a', 'set', 'of', 'arguments.', 'Most', 'of', 'the', 'CCG', 'grammar', 'is', 'contained', 'in', 'the', 'lexicon,', 'that', 'is', 'why', 'CCG', 'has', 'simpler', 'combinatory', 'rules', 'in', 'comparison', 'to', 'CFG', 'production', 'rules.', 'CCG', 'categories', 'are', 'divided', 'into', 'atomic', 'and', 'complex', 'categories.', 'Examples', 'of', 'atomic', 'categories', 'are:', 'S', '(sentence),', 'N', '(noun),', 'NP', '(noun', 'phrase),', 'etc.', 'Complex', 'categories', 'such', 'as', 'S\\NP', 'and', '(S\\NP)/NP', 'are', 'functions', 'which', 'specify', 'the', 'type', 'and', 'directionality', 'of', 'their', 'arguments', 'and', 'results.', 'Complex', 'categories', 'have', 'the', 'following', 'formats:']",1,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cb202cb8-bcfa-4195-9380-6732823a6956,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,"['unknown', 'Curriculum learning']","['unknown', '2009']","['unknown', 'Yoshua Bengio;Jérôme Louradour;Ronan Collobert;Jason Weston']",group,"['Curriculum', 'Learning.', 'Curriculums', 'in', 'reinforcement', 'learning', 'have', 'traditionally', 'been', 'used', 'to', 'set', 'goals', 'of', 'steadily', 'increasing', 'difficulty', 'for', 'an', 'agent', '<ref type=""group"">(Bengio et al., 2009, Schmidhuber, 2013).</ref>', 'The', 'difficulty', 'of', 'these', 'curriculums', 'are', 'generally', 'measured', 'difficulty', 'via', 'proxy', 'of', 'agent', 'performance', '(Narvekar', 'et', 'al.,', '2020)-methods', 'either', 'choose', 'to', 'adversarially', 'set', 'goals', 'of', 'steadily', 'increasing', 'difficulty', '<ref type=""group"">(Sukhbaatar et al., 2018, Racaniere et al., 2019, Dennis et al., 2020, Campero et al., 2021)</ref>', 'or', 'to', 'maximize', 'learning', 'performance', 'based', 'on', 'environment', 'instances', 'an', 'agent', 'finds', 'difficult', 'historically', '<ref type=""group"">(Graves et al., 2017, Portelas et al., 2020).</ref>', 'While', 'we', 'were', 'inspired', 'by', 'these', 'works,', 'they', 'all', 'focus', 'on', 'searching', 'for', 'goals', 'for', 'agents', 'which', 'can', 'be', 'difficult', 'to', 'scale', 'to', 'complex', 'tasks', 'such', 'our', 'own', 'natural', 'language', 'motivation-based', 'goals.', ""We'd"", 'also', 'like', 'to', 'note', 'that', 'most', 'works', 'using', 'procedural', 'generation', 'to', 'benchmark', 'RL', 'agents', 'such', 'as', '<ref type=""single"">Cobbe et al. (2020),</ref>', '<ref type=""single"">Küttler et al. (2020),</ref>', '<ref type=""single"">Samvelyan et al. (2021)</ref>', 'rely', 'on', 'the', 'underlying', 'richness', 'of', 'the', 'game', 'engines', 'to', 'generate', 'novel', 'environments', 'as', 'opposed', 'to', 'learning', 'to', 'generate.']",20,"[0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cb4053ee-1893-4665-beda-745978a15d4c,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Pauses and cognitive effort in post-editing'],['2014'],"[""I Lacruz;G Shreve;S O'brien;L Balling;M Carl;M Simard;L Specia""]",single,"['The', 'keystroke', 'logging', 'data', 'gathered', 'for', 'Spanish-English', 'post-editors', 'allowed', 'the', 'computation', 'of', 'Pause', 'to', 'Word', 'Ratio', '(PWR).', 'For', 'each', 'segment,', 'PWR', 'is', 'the', 'ratio', 'of', 'the', 'number', 'of', 'pauses', 'exceeding', '300ms', 'to', 'the', 'number', 'of', 'words', 'in', 'the', 'MT', 'segment,', 'it', 'is', 'a', 'measure', 'of', 'cognitive', 'effort', 'in', 'post-editing', '<ref type=""single"">(Lacruz and Shreve, 2014).</ref>', 'Higher', 'PWR', 'corresponds', 'to', 'higher', 'cognitive', 'effort.', 'Contrary', 'to', 'expectation,', 'the', 'mean', 'PWR', 'for', 'Spanish-English', 'post-editors', 'was', 'slightly', 'higher', 'for', 'the', 'segments', 'with', 'alignment', '(0.70)', 'than', 'for', 'those', 'without', 'alignment', '(0.63).', 'However,', 'the', 'numerical', 'difference', 'was', 'not', 'significant.']",49,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0]"
cbbc42db-ac7f-4ca0-a97e-689b52a97604,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['Current research in machine translation'],['1990'],['H Somers'],single,"['The', 'design', 'of', 'the', 'system', 'is', 'in', 'response', 'to', 'perceived', 'weaknesses', 'in', 'the', 'classical', 'approach', 'to', 'MT,', 'as', 'still', 'found', 'in', 'so-called', 'state-of-the-art', 'developments', '(cf.', '<ref type=""single"">[42]</ref>', '):', 'notably', 'these', 'include', 'reliance', 'on', 'structure-preserving', 'translation', 'as', 'a', 'first', 'choice,', 'a', 'stratificational', 'approach', 'to', 'both', 'linguistic', 'and', 'computing', 'aspects,', 'leading', 'to', 'a', 'predominantly', 'bottom-up', 'compositional', 'system', 'design,', 'and', 'the', 'reliance', 'on', 'the', 'intuitions', 'and', 'introspection', 'of', 'linguists', 'rather', 'than', ""'real'"", 'data.', 'The', 'system', 'design', 'is', 'influenced', 'by', 'a', 'number', 'of', 'recent', 'research', 'directions', 'including', 'Dialogue-Based', 'MT', 'with', 'a', 'monolingual', 'user,', 'Example-Based', 'MT,', 'corpus-based', 'MT,', 'and', 'the', 'use', 'of', 'sublanguage.']",25,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cbd9cf72-3895-4f74-8013-b0c84e18c37c,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Scikit-learn: Machine learning in python'],['2011'],['Fabian Pedregosa;Gaël Varoquaux;Alexandre Gramfort;Vincent Michel;Bertrand Thirion;Olivier Grisel;Mathieu Blondel;Peter Prettenhofer;Ron Weiss;Vincent Dubourg'],single,"['We', 'also', 'use', 'an', 'SVM', 'classifier', 'with', 'linear', 'kernel', 'and', 'regularization', 'parameter', 'of', '1.', 'Word', 'unigrams,', 'bigrams', 'and', 'trigrams', 'were', 'used', 'as', 'features', 'in', 'this', 'case.', 'Implementation', 'was', 'done', 'using', 'the', 'LinearSVC', 'class', 'from', 'the', 'scikit-learn', 'library', '<ref type=""single"">(Pedregosa et al., 2011).</ref>']",37,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1]"
cc0f481d-26e3-4aff-83f8-48fac0712ce5,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Two Perspectives on the Reusability of Lexical Resources'],['1999'],['Pius Ten Hacken'],single,"['Ten', '<ref type=""single"">Hacken (1999)</ref>', 'describes', 'the', 'opposition', 'between', 'the', 'coverage', 'of', 'the', 'lexical', 'component', 'in', 'the', 'standard', 'approach', 'and', 'in', 'WM', 'in', 'terms', 'of', 'two', 'orthogonal', 'dichotomies:']",1,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
cc436d75-8ab5-41dd-8f72-64a703602bbd,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['Pre-training.', 'We', 'test', 'two', 'model', 'types,', 'drawing', 'from', '<ref type=""single"">Ammanabrolu et al. (2021),</ref>', 'to', 'determine', 'if', 'pre-training', 'effects', 'curriculums', 'learning.']",8,"[0, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
cc8302e8-4679-4359-a017-03b61e7f5d9d,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['Deal or no deal? end-to-end learning for negotiation dialogues'],['2017'],['Mike Lewis;Denis Yarats;N Yann;Devi Dauphin;Dhruv Parikh;unk Batra'],group,"['Goal', 'oriented', 'Dialogue.', 'Sub-tasks', 'within', 'the', 'overall', 'task', 'of', 'goal', 'oriented', 'dialogue,', 'such', 'as', 'dialogue', 'state', 'management', '<ref type=""group"">(Singh et al., 2000, Pietquin et al., 2011, Fatemi et al., 2016)</ref>', 'and', 'response', 'generation', '<ref type=""single"">(Li et al., 2016)</ref>', 'have', 'used', 'RL', 'to', 'boost', 'performance.', 'As', 'noted', 'by', '<ref type=""single"">Ammanabrolu et al. (2021),</ref>', 'the', 'negotiation', 'tasks', 'of', '(Yarats', 'and', '<ref type=""group"">Lewis, 2017, Lewis et al., 2017),</ref>', 'where', 'two', 'agents', 'are', 'trying', 'to', 'convince', 'each', 'other', 'to', 'perform', 'certain', 'actions,', 'are', 'related', 'to', 'the', 'tasks', 'in', 'LIGHT-Quests.', 'These', 'works', 'all', 'lack', 'environment', 'grounding.']",38,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
ccd5d634-0649-4b94-ae48-143a423418d9,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,"['MULTEXT-East Version 3: Multilingual Morphosyntactic Specifications, Lexicons and Corpora']",['2004'],['Erjavec Tomaž'],single,"['Bilingual', 'parallel', 'corpus', '<ref type=""single"">(Erjavec, 2004)</ref>', 'was', 'used', 'in', 'automatic', '(BLEU)', 'evaluation', 'of', 'translations.', 'This', 'corpus', 'consists', 'of', '8600', 'sentences', 'that', 'were', 'not', 'used', 'in', 'translation', 'system', 'construction.']",3,"[1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]"
ccf1092b-a446-414c-bbd0-aebded69372a,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['A learned representation for artistic style'],['2017'],['Jonathon Vincent Dumoulin;Manjunath Shlens;unk Kudlur'],single,"['Style', 'transfer', 'aims', 'to', 'change', 'the', 'style', 'attributes', 'while', 'preserving', 'the', 'content.', 'Our', 'work', 'is', 'related', 'to', 'unsupervised', 'style', 'transfer', 'by', 'regarding', 'the', 'text', 'complexity', 'as', 'one', 'of', 'the', 'style', 'attributes', '<ref type=""single"">(Kawashima and Takagi, 2019).</ref>', '<ref type=""single"">Dumoulin et al. (2017)</ref>', 'demonstrated', 'that', 'the', 'neural', 'networks', 'can', 'capture', 'the', 'artistic', 'style', 'of', 'a', 'diversity', 'of', 'paintings.', 'The', 'authors', 'discovered', 'that', 'adjusting', 'parameters', 'in', 'the', 'layer', 'normalization', 'mechanism', 'leads', 'to', 'different', 'artistic', 'styles.', 'This', 'method', 'permits', 'users', 'to', 'transform', 'images', 'to', 'arbitrary', 'styles', 'learned', 'from', 'individual', 'paintings.', '<ref type=""single"">Jin et al. (2020)</ref>', 'successfully', 'applied', 'this', 'method', 'to', 'the', 'task', 'of', 'headline', 'generation,', 'allowing', 'the', 'model', 'to', 'generate', 'headlines', 'of', 'a', 'specific', 'style,', 'such', 'as', 'humorous,', 'romantic', 'or', 'click-baity,', 'in', 'an', 'unsupervised', 'manner.']",32,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cdde4f9a-c38a-4952-b44d-fee5644c5136,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Incorporating label dependency for answer quality tagging in community question answering via cnn-lstm-crf'],['2016'],['Yang Xiang;Xiaoqiang Zhou;Qingcai Chen;Zhihui Zheng;Buzhou Tang;Xiaolong Wang;Yang Qin'],single,"['We', 'use', 'max-pooling', 'over', 'the', 'output', 'embedding', '(instead', 'of', 'mean-pooling', 'as', 'it', 'better', 'incorporates', 'the', 'nature', 'of', 'natural', 'language', 'sequences', '<ref type=""single"">(Xiang et al., 2016</ref>', '))', 'as:w', 'c', 'i', '=', 'max', 'i', 'e', 'w', 'i', 'i', '(2)For', 'a', 'total', 'of', 'h', 'filters,', 'each', 'of', 'varying', 'widths,', 'we', 'get', 'different', 'representations', 'of', 'w', 'i.', 'Thereforew', 'c', 'i', '=', '[w', 'c', '1,', 'w', 'c', '2', ',...,', 'w', 'c', 'h', ']is', 'the', 'representation', 'of', 'the', 'ith', 'word.']",20,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ce47ae72-2785-47fa-a72a-212284f06af3,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,"['A structural probe for finding syntax in word representations', 'Deep contextualized word representations', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'unknown', 'Language models as knowledge bases?']","['2019', '2018', '2019', 'unknown', '2019']","['John Hewitt;Christopher Manning', 'Matthew Peters;Mark Neumann;Mohit Iyyer;Matt Gardner;Christopher Clark;Kenton Lee;Luke Zettlemoyer', 'Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova', 'unknown', 'Fabio Petroni;Tim Rocktäschel;Sebastian Riedel;Patrick Lewis;Anton Bakhtin;Yuxiang Wu;Alexander Miller']",group,"['The', 'Transformer', 'architecture', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'has', 'been', 'successful', 'in', 'a', 'wide', 'range', 'of', 'natural', 'language', 'processing', 'tasks,', 'including', 'machine', 'translation', '<ref type=""single"">(Edunov et al., 2018),</ref>', 'language', 'modeling', '<ref type=""single"">(Roy et al., 2021),</ref>', 'question-answering', '<ref type=""single"">(Karpukhin et al., 2020),</ref>', 'and', 'many', 'more.', 'Transformers', 'pre-trained', 'on', 'large', 'amounts', 'of', 'text', 'with', 'a', 'language', 'modeling', '(LM)', 'objective,', 'have', 'become', 'the', 'standard', 'in', 'NLP,', 'exhibiting', 'surprising', 'amounts', 'of', 'linguistic', 'and', 'world', 'knowledge', '<ref type=""group"">(Peters et al., 2018, Devlin et al., 2019, Petroni et al., 2019, Hewitt and Manning, 2019, Roberts et al., 2020).</ref>']",55,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
ce48aae5-9388-416a-816c-734202436494,NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based Token Classification and Span Prediction Techniques,2021,Gunjan Chhablani;Abheesht Sharma;Harshit Pandey;Yash Bhartia;Shan Suthaharan,['unknown'],['unknown'],['unknown'],single,"['For', 'all', 'BERT-based', 'models,', 'we', 'use', ""Hugging-Face's"", 'transformers', '<ref type=""single"">(Wolf et al., 2020)</ref>', 'in', 'PyTorch.', 'For', 'CRF,', 'we', 'use', 'the', 'pytorch-crf', '<ref type=""single"">(Kurniawan, 2018)</ref>', 'library.', 'We', 'use', 'a', 'batch', 'size', 'of', '4,', 'train', 'for', '3', 'epochs,', '5', 'Our', 'code', 'can', 'be', 'found', 'at:', 'https://github.com/', 'gchhablani/toxic-spans-detection.', '6', 'We', 'also', 'use', 'Integrated', 'Gradients', 'to', 'understand', 'what', 'the', 'models', 'focus', 'on.', 'For', 'discussion,', 'see', 'Appendix', 'B.', 'use', 'a', 'linear', 'learning', 'rate', 'decay,', 'and', 'an', 'AdamW', 'optimizer', 'with', 'a', 'weight', 'decay', 'of', '0.01.', 'The', 'initial', 'learning', 'rate', 'is', '2e−5.', 'During', 'tokenization,', 'the', 'maximum', 'length', 'allowed', 'is', '384,', 'with', 'the', 'exception', 'of', 'RoBERTa', 'Span+Token', 'where', 'it', 'is', '512.', 'We', 'use', 'LARGE', 'models', 'for', 'all', '-BERT,', 'RoBERTa', 'and', 'SpanBERT,', 'unless', 'otherwise', 'specified.']",8,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cea6ed8d-724f-4d7f-88bd-1323edbb717b,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['An introduction to Tree Adjoining Grammars'],['1987'],['A Joshi'],single,"['TAG', 'is', 'a', 'grammar', 'formalism', 'based', 'on', 'trees', 'rather', 'than', 'context', 'free', 'rules', '<ref type=""single"">(Joshi, 1987).</ref>', 'Elementary', 'trees', 'are', 'of', 'two', 'types,', 'initial', 'trees', 'and', 'auxiliary', 'trees.', 'Auxiliary', 'trees', 'have', 'a', 'designated', 'foot', 'node,', 'marked', 'with', 'a', '*,', 'whose', 'label', 'is', 'the', 'same', 'as', 'that', 'of', 'the', 'root.', 'In', 'Figure', '6,', '«', '½', 'and', '«', '¾', 'are', 'initial', 'trees,', '¬', '½', 'is', 'an', 'auxiliary', 'tree.', 'The', 'trees', 'are', 'combined', 'together', 'by', 'two', 'operations,', 'substitution', 'and', 'adjunction.', 'Under', 'substitution,', 'a', 'node', 'marked', 'for', 'substitution', '5', 'in', 'a', 'tree', 'is', 'replaced', 'by', 'an', 'initial', 'tree', 'with', 'the', 'same', 'label', 'at', 'the', 'root,', 'under', 'adjunction,', 'an', 'internal', 'node', 'in', 'a', 'tree', 'is', ""'split"", ""apart',"", 'replaced', 'by', 'an', 'auxiliary', 'tree', 'with', 'the', 'same', 'label', 'at', 'the', 'root', 'and', 'foot.', 'In', 'the', 'DERIVED', 'TREE', 'for', 'the', 'string,', 'in', 'Figure', '6,', 'copies', 'of', '¬', '½', 'have', 'been', 'adjoined', 'either', 'at', 'the', 'root', 'node', 'labelled', 'of', 'other', 'nodes', '¬', '½', 'or', 'ultimately', 'at', 'the', 'node', 'of', '«', '½,', 'an', '«', '¾', 'tree', 'has', 'been', 'substituted', 'into', 'each', '¬', '½', 'tree', 'at', 'the', 'node', 'labelled.', 'The', 'derivation', 'history', 'is', 'recorded', 'in', 'the', 'DERIVATION', 'TREE', '(Figure', '6).', 'It', 'can', 'be', 'seen', 'that', 'the', 'TAG', 'property', 'of', 'an', ""'extended"", 'domain', 'of', ""locality'"", 'can', 'allow', 'the', 'two', 's', 'in', 'the', 'generated', 'string', 'to', 'be', 'separated', 'by', 'an', 'abitrary', 'amount', 'of', 'intervening', 'material,', 'this', 'characteristic', 'is', 'used', 'for', 'representation', 'of,', 'for', 'example,', 'WH-phenomena', 'when', 'TAG', 'derived', 'trees', 'are', 'used', 'for', 'a', 'linguistic', 'representation.', 'Of', 'more', 'interest', 'for', 'us', 'than', 'the', 'derived', 'string', 'is', 'the', 'nature', 'of', 'the', 'derived', 'tree:', 'the', 'branches', 'containing', 'the', 'nodes', 'in', 'the', 'derived', 'tree', 'are', 'also', 'separated', 'by', 'an', 'arbitary', 'distance.']",13,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cec66e16-86e7-4fb6-9cf7-55b68c51b7f6,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,"['Improving disentangled text representation learning with information-theoretic guidance', 'Designing and interpreting probes with control tasks']","['2020', '2019']","['Pengyu Cheng;Dinghan Martin Renqiang Min;Christopher Shen;Yizhe Malon;Yitong Zhang;Lawrence Li;unk Carin', 'John Hewitt;Percy Liang']",group,"['Even', 'in', 'the', 'presence', 'of', 'such', 'an', 'agreement,', 'learning', 'to', 'disentangle', 'the', 'surface', 'realization', 'of', 'the', 'underlying', 'factors', 'of', 'data', '(e.g.,', 'semantics,', 'syntactic,', 'lexical)', 'in', 'the', 'representation', 'space', 'is', 'a', 'nontrivial', 'task.', 'Additionally,', 'there', 'is', 'no', 'established', 'study', 'for', 'evaluating', 'such', 'models', 'in', 'NLP.', 'A', 'handful', 'of', 'recent', 'works', 'have', 'looked', 'into', 'disentanglement', 'for', 'text', 'by', 'splitting', 'the', 'representation', 'space', 'into', 'predefined', 'disentangled', 'subspaces', 'such', 'as', 'style', 'and', 'content', '<ref type=""group"">(Cheng et al., 2020, John et al., 2019),</ref>', 'or', 'syntax', 'and', 'semantics', '<ref type=""group"">(Balasubramanian et al., 2021, Bao et al., 2019, Chen et al., 2019),</ref>', 'and', 'rely', 'on', 'supervision', 'during', 'training.', 'However,', 'a', 'generalizable', 'and', 'realistic', 'approach', 'needs', 'to', 'be', 'unsupervised', 'and', 'capable', 'of', 'identifying', 'the', 'underlying', 'factors', 'solely', 'via', 'the', 'regularities', 'presented', 'in', 'data.']",69,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ced94dcf-5f64-47e0-a249-9ebebf072a01,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['SpanBERT: Improving pre-training by representing and predicting spans'],['2020'],['Mandar Joshi;Danqi Chen;Yinhan Liu;Daniel Weld;Luke Zettlemoyer;Omer Levy'],single,"['Next,', 'we', 'experiment', 'with', 'three', 'neural', 'models', 'based', 'on', 'a', 'pre-trained', 'masked', 'language', 'model', '(MLM),', 'specifically,', 'SpanBERT', '<ref type=""single"">(Joshi et al., 2020).</ref>', 'We', 'also', 'experiment', 'with', 'an', 'additional', 'baseline', 'with', 'uncontextualized', 'word', 'embeddings.']",17,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cedaa71a-6d1d-417c-a724-4a7d8e529a10,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['Human Behavior and the Principle of Least-Effort'],['1949'],['G Zipf'],single,"['Performance', 'is', 'plotted', 'on', 'the', 'vertical', 'axis', 'and', 'measured', 'for', 'different', 'frequency', 'bins.', 'The', 'Zipfian', 'distribution', 'of', 'terms', 'suggests', 'assessing', 'performance', 'by', 'frequency', 'ranges', 'growing', 'by', 'a', 'constant', 'factor', '<ref type=""single"">(Zipf, 1949),</ref>', 'accordingly', 'we', 'used', 'a', 'logarithmic', 'scale', 'with', 'base=3.', 'The', 'number', 'of', 'terms', 'per', 'bin', 'is', 'given', 'in', 'parentheses.', 'Some', 'of', 'the', 'previous', 'work', 'cited', 'in', 'Section', '2', 'described', 'performance', 'for', 'selected', 'subsets', 'of', 'terms,', 'typically', 'high', 'frequency', 'terms', 'that', 'are', 'easier', 'to', 'translate.', 'We', 'believe', 'presenting', 'translation', 'accuracy', 'as', 'a', 'function', 'of', 'source', 'term', 'frequency', 'is', 'more', 'informative.']",29,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ceed5f31-cf33-4166-85e7-b1cb097b6b6d,A Parameter-Based Message-Passing Parser for MT of Korean and English,1994,Bonnie Dorr;Jye-Hoon Lee;Sungki Suh,['Principle-based parsing without overgeneration'],['1993'],['D Lin'],single,"['We', 'combine', 'the', 'benefits', 'of', 'the', 'message-passing', 'paradigm', 'with', 'the', 'benefits', 'of', 'the', 'parameterized', 'approach', 'to', 'build', 'a', 'more', 'efficient,', 'but', 'easily', 'extensible', 'system,', 'called', 'PRINCITRAN.', '1', 'Our', 'work', 'extends', 'that', 'of', '<ref type=""single"">Lin and Goebel (1993)</ref>', 'and', '<ref type=""single"">Lin (1993)</ref>', 'in', 'that', 'it', 'provides', 'a', 'parameterization', 'mechanism', 'along', 'the', 'lines', 'of', 'Dorr', '(1993b)', 'that', 'allows', 'the', 'system', 'to', 'be', 'ported', 'to', 'languages', 'other', 'than', 'English.', 'We', 'focus', 'particularly', 'on', 'the', 'problem', 'of', 'processing', 'head-final', 'languages', 'such', 'as', 'Korean.', 'The', 'algorithm', 'has', 'been', 'implemented', 'in', 'C++', 'and', 'successfully', 'tested', 'on', 'well-known,', 'translationally', 'divergent', 'sentences.']",34,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cfcd19c0-a232-4e1e-b8ee-711d1b15f694,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Phonologically aware neural model for named entity recognition in low resource transfer settings'],['2016'],['Akash Bharadwaj;David Mortensen;Chris Dyer;Jaime Carbonell'],single,"['We', 'anticipate', 'exploring', 'various', 'extensions', 'to', 'and', 'validations', 'of', 'this', 'method', 'in', 'the', 'future.', 'Specifically,', 'we', 'would', 'like', 'to', 'explore', 'methods', 'that', 'might', 'mitigate', 'performance', 'degradation', 'due', 'to', 'a', 'lack', 'of', 'word', 'boundaries', 'in', 'our', 'method.', 'Subword', 'tokenization', 'techniques,', 'such', 'as', 'Byte-Pair', 'Encodings', '(BPE)', '<ref type=""group"">(Sennrich et al., 2016, Gage, 1994),</ref>', 'or', 'character-based', 'word', 'segmentation', 'techniques', 'might', 'help', 'in', 'detecting', 'and', 'exploiting', 'repeating', 'patterns', 'within', 'the', 'phonetic', 'representation.', 'Furthermore,', 'the', 'word', 'embedding', 'techniques', 'used', 'by', '<ref type=""single"">(Chaudhary et al., 2018)</ref>', 'or', '<ref type=""single"">(Bharadwaj et al., 2016)</ref>', 'have', 'been', 'shown', 'to', 'work', 'well,', 'and', 'would', 'be', 'worth', 'investigating', 'how', 'the', 'removal', 'of', 'spacedelimited', 'word', 'boundaries', 'would', 'affect', 'this.']",71,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
cfd8380b-bc52-4a28-bc4b-c07d925267d2,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['vi', 'Entity', 'Pool', 'Strategy', '-To', 'effectively', 'deal', 'with', 'rare', 'words,', 'transformer', 'models', 'use', 'sub-word', 'units', 'or', 'WordPiece', 'tokens', 'as', 'the', 'input', 'to', 'build', 'the', 'models', '<ref type=""single"">(Devlin et al., 2019).</ref>', 'Therefore,', 'there', 'is', 'a', 'possibility', 'that', 'one', 'target', 'word', 'can', 'be', 'separated', 'into', 'several', 'sub-words.', 'In', 'this', 'strategy,', 'we', 'generate', 'separate', 'fixed-length', 'embeddings', 'for', 'each', 'target', 'word', 'by', 'passing', 'its', 'sub-word', 'outputs', 'through', 'a', 'pooling', 'layer.', 'The', 'pooled', 'outputs', 'are', 'concatenated', 'and', 'fed', 'into', 'a', 'softmax', 'layer', 'to', 'predict', 'the', 'labels', '(Figure', '2e).']",25,"[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
cfeb3360-0679-48ec-abea-5ebcf4342ab2,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['unknown'],['unknown'],['unknown'],single,"['ATOMIC-LIGHT.', 'ATOMIC-LIGHT', 'is', 'a', '(domain-adapted)', 'fantasy', 'commonsense', 'knowledge', 'graph,', 'and', 'as', 'such', 'provides', 'priors', 'for', 'an', 'agent', 'on', 'how', 'to', 'act', 'consistently', 'in', 'the', 'world.', 'For', 'example,', 'given', 'a', 'clause', 'such', 'as', '""The', 'knight', 'wishes', 'to', 'slay', 'the', 'dragon,', 'as', 'a', 'result', 'the', 'knight', 'needs', 'to', 'acquire', 'a', 'sword,""', 'the', 'task', 'would', 'be', 'to', 'predict', 'the', 'underlined', 'text-a', 'form', 'of', 'knowledge', 'graph', 'completion', '<ref type=""single"">(Wang et al., 2017).</ref>']",63,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1]"
d047939f-bc58-4e0a-b094-90dc79aac010,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Evaluating syntax performance of parser/ grammars of English'],['1991'],['P Harrison;S Abney;E Black;D Flickenger;C Gdaniec;R Grishman;D Hindle;B Lngria;M Marcus;B Santorini;T Strzalkowski'],single,"['The', 'probabilistic', 'parser', 'was', 'tested', 'on', 'the', '250', 'sentences', 'held', 'out', 'from', 'the', 'manually-created', 'treebank', '(with', 'mean', 'length', '18.2', 'tokens,', 'mean', 'number', 'of', 'parses', 'per', 'sentence', '977,', 'and', 'APB', '1.', '25', '2),', 'in', 'this', 'test', '85', 'sentences', '(34', '%', ').', 'had', 'the', 'correct', 'analysis', 'ranked', 'in', 'the', 'top', 'three', '3', 'This', 'figure', 'rose', 'to', '51', '%', 'for', 'sentences', 'of', 'less', 'than', '20', 'words.', 'Considering', 'just', 'the', 'highest', 'ranked', 'anal', 'ysis', 'for', 'each', 'sentence,', 'in', '<ref type=""single"">Sampson, Haigh &amp, Atwell\'s (1989)</ref>', 'measure', 'of', 'correct', 'rule', 'application', 'the', 'parser', 'scored', 'a', 'mean', 'of', '83.5%', 'correct', 'over', 'all', '250', 'sentences.', 'Table', '2', 'shows', 'the', 'results', 'of', 'this', 'test-with', 'respect', 'to', 'the', 'original', 'Susanne', 'bracketings-using', 'the', 'Grammar', '�valuation', 'Interest', 'Group', 'scheme', '(GEIG,', 'see', 'e.g.', '<ref type=""single"">Harrison et al., 1991).</ref>', 'This', 'compares', 'unlabelled', 'brack', 'etings', 'derived', 'from', 'corpus', 'treebanks', 'with', 'those', 'derived', 'from', 'parses', 'for', 'the', 'same', 'sentences', 'by', 'computing', 'recall,', 'the', 'ratio', 'of', 'matched', 'brackets', 'over', 'all', 'brackets', 'in', 'the', 'treebank,', 'precision,', 'the', 'ratio', 'of', 'matched', 'brackets', 'over', 'all', 'brackets', 'found', 'by', 'the', 'parser,', ""'crossing"", ""'"", 'brackets,', 'the', 'number', 'of', 'times', 'a', 'bracketed', 'sequence', 'output', 'by', 'the', 'parser', 'overlaps', 'with', 'one', 'from', 'the', 'treebank', 'but', 'neither', 'is', 'properly', 'contained', 'in', 'the', 'other,', 'and', 'minC,', 'the', 'number', 'of', 'sentences', 'for', 'which', 'all', 'of', 'the', 'analyses', 'had', 'one', 'or', 'more', 'crossings.', 'The', 'table', 'also', 'gives', 'an', 'indication', 'of', 'the', 'best', 'and', 'worst', 'possible', 'performance', 'of', 'the', 'disambiguation', 'component', 'of', 'the', 'system,', 'showing', 'the', 'results', 'obtained', 'when', 'parse', 'selection', 'is', 'replaced', 'by', 'a', 'simple', 'random', 'choice,', 'and', 'the', 'results', 'of', 'eval', 'uating', 'the', 'manually-created', 'treebank', 'against', 'the', 'corresponding', 'Susanne', 'bracketings.', 'In', 'this', 'latter', 'figure,', 'the', 'mean', 'number', 'of', 'crossings', 'is', 'greater', 'than', 'zero', 'mainly', 'because', 'of', 'compound', 'noun', 'bracketing', 'ambiguity', 'which', 'our', 'grammar', 'does', 'not', 'attempt', 'to', 'resolve,', 'always', 'returning', 'minC', 'Crossings', 'Recall', '(%)', 'Precision', '(%)', 'Probabilistic', 'parser', 'analyses', '<ref type=""single"">Top-ranked</ref>', '<ref type=""single"">Black (1993:7)</ref>', 'uses', 'the', 'crossing', 'brackets', 'measure', 'to', 'define', 'a', 'notion', 'of', 'structural', 'consistency,', 'where', 'the', 'structural', 'consistency', 'rate', 'for', 'the', 'grammar', 'is', 'defined', 'as', 'the', 'proportion', 'of', 'sentences', 'for', 'which', 'at', 'least', 'one', 'analysis', 'contains', 'no', 'crossing', 'brackets,', 'and', 'reports', 'a', 'rate', 'of', 'around', '95%', 'for', 'the', 'IBM', 'grammar', 'tested', 'on', 'the', 'computer', 'manual', 'corpus.', 'The', 'problem', 'with', 'the', 'GEIG', 'scheme', 'and', 'with', 'structural', 'consistency', 'is', 'that', 'both', 'are', 'still', 'weak', 'measures', '(designed', 'to', 'avoid', 'problems', 'of', 'parser/treebank', 'representational', 'compatibility)', 'which', 'lead', 'to', 'unintuitive', 'numbers', 'whose', 'significance', 'still', 'depends', 'heavily', 'on', 'details', 'of', 'the', 'relationship', 'between', 'the', 'representations', 'compared', '(c.f.', 'the', 'compound', 'noun', 'issue', 'mentioned', 'above).']",115,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d08a2bd1-53d8-4118-bdb4-b0c27e814377,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Emotions from text: Machine learning for textbased emotion prediction'],['2005'],['Cecilia Ovesdotter Alm;Dan Roth;Richard Sproat'],single,"['Some', 'emotions', 'are', 'also', 'harder', 'to', 'detect,', 'even', 'for', 'humans.', '<ref type=""single"">Demszky et al. (2020)</ref>', 'show', 'that', 'the', 'emotions', 'of', 'admiration,', 'approval,', 'annoyance,', 'gratitude', 'had', 'the', 'highest', 'interrater', 'correlations', 'at', 'around', '0.6,', 'and', 'grief,', 'relief,', 'pride,', 'nervousness,', 'embarrassment', 'had', 'the', 'lowest', 'interrater', 'correlations', 'between', '0-0.2,', 'with', 'a', 'vast', 'majority', 'of', 'emotions', 'falling', 'in', 'the', 'range', 'of', '0.3-0.5', 'for', 'interrater', 'correlation.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '<ref type=""single"">(Alm et al., 2005).</ref>']",73,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d0c522fd-fe86-44ef-aa5b-68f4ca714632,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,['Data selection and smoothing in an open-source system for the 2008 NIST machine translation evaluation'],['2008'],['H Schwenk;Y Estève'],single,"['As', 'a', 'baseline', 'experiment', 'we', 'applied', 'our', 'NIST', 'Arabic/English', 'system', '<ref type=""single"">[1]</ref>', 'to', 'the', 'BTEC', 'task', 'of', 'this', 'evaluation.', 'It', 'can', 'be', 'seen', 'in', 'Table', '4,', 'first', 'line,', 'that', 'a', 'system', 'optimized', 'on', 'a', 'news', 'task', 'does', 'not', 'perform', 'very', 'well', 'on', 'tourism', 'related', 'short', 'sentences', 'of', 'the', 'BTEC', 'task.', 'Note', 'that', 'both', 'systems', 'use', 'exactly', 'the', 'same', 'tokenization.', 'Using', 'a', 'language', 'model', 'optimized', 'on', 'the', 'BTEC', 'task', 'does', 'improve', 'the', 'BLEU', 'score', 'by', '3.8', 'points', 'on', 'Dev6,', 'but', 'only', 'marginally', 'on', 'Dev5.', 'Also,', 'the', 'BLEU', 'score', 'obtained', 'by', 'this', 'generic', 'system', 'is', 'comparable', 'to', 'the', 'one', 'obtained', 'when', 'using', 'the', 'in-domain', 'BTEC', 'corpus', 'to', 'train', 'the', 'translation', 'model.', 'On', 'the', 'other', 'hand,', 'there', 'is', 'a', '4:', 'BLEU', 'scores', 'of', 'a', 'generic', 'Arabic/English', 'translation', 'system', '(NIST', 'task).']",10,"[2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d1098b72-70de-4bb6-9a74-51392a01de43,SimsterQ: A Similarity based Clustering Approach to Opinion Question Answering,2020,Aishwarya Ashok;Ganapathy Natarajan;Ramez Elmasri;Laurel Smith-Stvan,['Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences'],['2003'],['Hong Yu;Vasileios Hatzivassiloglou'],single,"['Early', 'work', 'in', 'opinion', 'question', 'answering', 'addressed', 'separating', 'facts', 'from', 'opinions', '<ref type=""single"">(Yu and Hatzivassiloglou, 2003),</ref>', 'and', 'the', 'authors', 'used', 'a', 'Naïve', 'Bayes', 'classifier', 'to', 'identify', 'polarity', 'of', 'the', 'opinions.', '<ref type=""single"">Kim and Hovy (2005)</ref>', 'aimed', 'at', 'identifying', 'the', 'opinion', 'holder', 'of', 'the', 'opinions.', '<ref type=""single"">Stoyanov et al. (2005)</ref>', 'explained', 'the', 'differences', 'between', 'fact', 'based', 'and', 'opinionated', 'answers', 'and', 'how', 'traditional', 'QA', 'systems', 'will', 'not', 'be', 'able', 'to', 'handle', 'multiple', 'perspectives', 'for', 'answers.', 'Some', 'works', 'aimed', 'at', 'using', 'community', 'based', 'question-answers', 'to', 'provide', 'unique', 'answers', 'to', 'questions', '<ref type=""group"">(Liu et al., 2007, Somasundaran et al., 2007).</ref>', '<ref type=""single"">Moghaddam and Ester (2011)</ref>', 'made', 'use', 'of', 'online', 'reviews', 'to', 'answer', 'questions', 'on', 'aspects', 'of', 'a', 'product.', '<ref type=""single"">Li et al. (2009)</ref>', 'and', '<ref type=""single"">Yu et al. (2012)</ref>', 'used', 'graphs', 'and', 'trees', 'to', 'answer', 'opinion', 'questions.', '<ref type=""single"">Wan and McAuley (2016)</ref>', 'modeled', 'ambiguity', 'and', 'subjectivity', 'in', 'opinion', 'QA', 'using', 'statistical', 'models.', '<ref type=""single"">Gupta et al. (2019)</ref>', 'give', 'baselines', 'for', 'answer', 'generation', 'systems', 'given', 'the', 'question', 'and', 'reviews.', 'We', 'use', 'their', 'results', 'as', 'the', 'baseline', 'for', 'our', 'evaluation.', 'We', 'also', 'discuss', 'the', 'dataset', 'from', 'this', 'paper', 'in', '4.2.', 'While', 'most', 'systems', 'used', 'in', 'the', 'works', 'described', 'above', 'are', 'supervised', 'learning', 'models,', 'our', 'system', 'used', 'unsupervised', 'learning', 'to', 'answer', 'binary', '(yes/no)', 'questions.']",11,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d19f0fe9-b005-42e9-81e0-e21945b86ac1,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['unknown'],['2014'],['Greg Durrett;Dan Klein'],single,"['Entity', 'typing', 'information', 'has', 'been', 'used', 'across', 'a', 'range', 'of', 'NLP', 'tasks,', 'including', 'models', 'for', 'entity', 'linking', 'and', 'coreference', '<ref type=""single"">(Durrett and Klein, 2014).</ref>']",19,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d1d86793-5500-481d-afb5-afd31a14792c,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['Some thoughts on interface structure(s)'],['1987'],['H Somers'],single,"['The', 'advantages', 'of', 'EBMT', 'are', 'that', 'translation', 'quality', 'is', 'assured,', 'because', 'the', 'example', 'translations', 'are', 'real.', 'The', 'system', 'knows', 'its', 'limitations:', 'if', 'a', 'suitable', 'example', 'cannot', 'be', 'found,', 'the', 'system', 'will', 'not', 'translate', 'on', 'a', 'word-for-word', 'basis', 'as', 'in', 'rule-based', 'MT.', 'This', 'approach', 'does', 'not', 'depend', 'on', 'structure', 'preservation', 'as', 'a', 'first', 'choice', '(cf.', '<ref type=""single"">[41],</ref>', 'p.84),', 'and', 'perhaps', 'most', 'interesting', 'of', 'all,', 'it', 'is', 'easy', 'to', 'extend', 'an', 'EBMT', 'system:', 'we', 'simply', 'add', 'more', 'examples', 'to', 'the', 'database.', 'Unlike', 'in', 'rule-based', 'MT,', 'there', 'is', 'not', 'the', 'overhead', 'of', ""'entropy'"", 'of', 'performance,', 'where', 'the', 'addition', 'of', 'a', 'new', 'rule', 'has', 'unforeseen', 'repercussions', 'on', 'the', 'rest', 'of', 'the', 'system,', 'which', 'sometimes', 'do', 'not', 'surface', 'until', 'many', 'months', 'after', 'the', 'change', 'was', 'made,', 'and', 'therefore', 'are', 'extremely', 'difficult', 'to', 'trace.']",54,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d1eaff2d-73c4-4f55-a655-09b4632056c5,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,"['Biweighting domain adaptation for cross-language text classification', 'Cross-lingual adaptation using structural correspondence learning', 'A survey of cross-lingual word embedding models']","['2011', '2011', '2019']","['Chang Wan;Rong Pan;Jiefei Li', 'Peter Prettenhofer;Benno Stein', 'Sebastian Ruder;Ivan Vulić;Anders Søgaard']",group,"['Deep', 'models', 'such', 'as', 'Transformers', 'rely', 'heavily', 'on', 'the', 'availability', 'of', 'a', 'large', 'amount', 'of', 'annotated', 'data,', 'which', 'is', 'available', 'only', 'for', 'prominent', 'languages', 'like', 'English,', 'Russian,', 'German', 'or', 'Spanish', '<ref type=""group"">(Ponti et al., 2019, Joshi et al., 2020).</ref>', 'For', 'a', 'majority', 'of', 'other', 'languages', 'with', 'a', 'minimal', 'number', 'of', 'annotations,', 'cross-lingual', 'transfer', 'learning', '<ref type=""group"">(Prettenhofer and Stein, 2011, Wan et al., 2011, Ruder et al., 2019)</ref>', 'has', 'been', 'proposed', 'as', 'a', 'possible', 'solution.', 'This', 'approach', 'can', 'transfer', 'knowledge', 'from', 'the', 'annotation-rich', 'source', 'language', 'to', 'low-resource', 'or', 'zero-resource', 'target', 'languages.', 'Furthermore,', 'multilingual', 'models', '<ref type=""group"">(Lewis et al., 2019, Clark et al., 2020)</ref>', 'can', 'be', 'used', 'to', 'mitigate', 'the', 'data', 'scarcity', 'problem.', 'For', 'example,', 'LASER', '<ref type=""single"">(Artetxe and Schwenk, 2019)</ref>', 'used', 'a', 'bidirectional', 'LSTM', '<ref type=""single"">(Hochreiter and Schmidhuber, 1997)</ref>', 'encoder', 'with', 'a', 'byte', 'pair', 'encoding', 'vocabulary', 'shared', 'between', 'languages.', 'This', 'work', 'showed', 'that', 'joint', 'training', 'of', 'multiple', 'languages', 'helped', 'to', 'improve', 'the', 'model', 'performance', 'for', 'low-resource', 'languages.', 'LaBSE', '<ref type=""single"">(Feng et al., 2020)</ref>', 'used', 'the', 'mBERT', '<ref type=""single"">(Devlin et al., 2018)</ref>', 'encoder', 'pre-trained', 'with', 'masked', 'language', 'modelling', 'and', 'translation', 'language', 'modelling', '<ref type=""single"">(Lample and Conneau, 2019)</ref>', 'tasks.', 'It', 'attempted', 'to', 'optimize', 'the', 'dual', 'encoder', 'translation', 'ranking', '<ref type=""single"">(Guo et al., 2018)</ref>', 'loss', 'during', 'pre-training', 'to', 'achieve', 'similar', 'embedding', 'for', 'the', 'same', 'text', 'in', 'different', 'languages.']",46,"[3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d1f7bbfd-8039-4468-b0f5-f271da43a751,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,"['Revisiting fewsample {bert} fine-tuning', 'On the stability of fine-tuning {bert}: Misconceptions, explanations, and strong baselines']","['2021', '2021']","['Tianyi Zhang;Felix Wu;Arzoo Katiyar;Q Kilian;Yoav Weinberger;unk Artzi', 'Marius Mosbach;Maksym Andriushchenko;Dietrich Klakow']",group,"['Recently,', '<ref type=""single"">Pires et al. (2019)</ref>', 'and', '<ref type=""single"">Conneau et al. (2020)</ref>', 'have', 'shown', 'that', 'multilingual', 'models', 'underperformed,', 'when', 'applied', 'on', 'poorly', 'endowed', 'languages.', 'Additionally,', 'as', 'mentioned', 'in', 'subsection', '2.1,', 'recent', 'works', '<ref type=""group"">(Zhang et al., 2021, Mosbach et al., 2021)</ref>', 'have', 'highlighted', 'the', 'limitation', 'of', 'Transformer-based', 'transfer', 'learning', 'with', 'strong', 'instabilities', 'arising', 'from', 'the', 'small-scale', 'learning.']",24,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d21bc691-ccc4-47ff-8f17-6715a20183d5,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['CharNER: Character-level named entity recognition'],['2016'],['Onur Kuru;Deniz Ozan Arkan Can;unk Yuret'],single,"['For', 'the', 'downstream', 'NER', 'tasks', 'we', 'map', 'or', 'encode', 'the', 'NER', 'annotations', 'into', 'the', 'phonetic', 'representation.', 'We', 'thus', 'edited', 'the', 'labels', '(PER,', 'ORG,', 'DATE,', 'and', 'LOC)', 'to', 'convert', 'them', 'from', 'word-level', 'labels', 'to', 'phone-level', 'labels', 'as', 'shown', 'in', 'Fig.', '3.', 'Unlike', '<ref type=""single"">(Kuru et al., 2016),</ref>', 'we', 'leave', 'in', 'the', 'B-and', 'I-prefixes.']",41,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0]"
d3050638-de02-47ee-b244-5fd40b3b4e0b,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,"['The university of south florida free association, rhyme, and word fragment norms']",['2004'],['Cathy Douglas L Nelson;Thomas A Mcevoy;unk Schreiber'],single,"['Furthermore,', 'Kumar', 'et', 'al.', '(2021)', 'studied', 'if', 'the', 'decisions', 'of', 'human', 'players', 'can', 'be', 'predicted', 'in', 'an', 'amended', 'version', 'of', 'Codenames.', 'For', 'the', 'predictions,', 'they', 'used', 'word2vec', 'and', 'GloVe', 'word', 'embeddings,', 'as', 'well', 'as', 'several', 'similarity', 'measures', 'on', 'free', 'association', 'datasets,', 'in', 'particular', 'SWOW', '<ref type=""single"">(De Deyne et al., 2019)</ref>', 'and', 'USF', '<ref type=""single"">(Nelson et al., 2004).</ref>', 'They', 'found', 'that', 'similarity', 'based', 'on', 'random', 'walks', 'in', 'SWOW', 'performed', 'the', 'best,', 'from', 'which', 'they', 'concluded', 'that', 'not', 'only', 'direct', 'associations,', 'but', 'indirect', 'connections', 'are', 'also', 'important', 'in', 'this', 'game.']",47,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
d3161053-a0cd-465e-9d0f-114785f3f95f,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['seqeval: A python framework for sequence labeling evaluation'],['2018'],['Hiroki Nakayama'],single,"['Table', '2', 'presents', 'the', 'F1', 'scores', 'for', 'our', 'various', 'training', 'scenarios', 'in', 'the', 'downstream', 'NER3', 'task,', 'which', 'should', 'be', 'the', 'most', 'challenging', 'for', 'our', 'phonetic', 'models.', 'The', 'influence', 'of', 'pre-training', 'is', 'more', 'noticeable', 'for', 'this', 'task.', 'Further,', 'the', 'models', 'pretrained', 'on', 'the', 'kin', 'audio', 'and', 'text', 'data', 'have', 'the', 'best', 'performance.', 'This', 'is', 'likely', 'due', 'to', 'the', 'fact', 'that', 'the', 'kin', 'data', 'is', 'both', 'large', 'and', 'higher', 'quality', '(in', 'terms', 'of', 'sound', 'quality)', 'as', 'compared', 'to', 'the', 'ALFFA', 'Swahili', 'data.', 'This', 'benefit', 'of', 'this', 'data', 'size', 'and', 'quality', 'appears', 'to', 'outweigh', 'any', 'degradation', 'due', 'to', 'the', 'pre-training', 'occurring', 'in', 'a', 'different', '(although', 'related)', 'language.', '<ref type=""single"">).</ref>', 'Average', 'of', 'at', 'least', 'three', 'trials', 'per', 'experiment,', 'scores', 'calculated', 'with', 'seqeval', 'library.', '<ref type=""single"">(Nakayama, 2018)</ref>', 'The', 'importance', '(or', 'relative', 'impact)', 'of', 'pretraining', 'phonetic', 'language', 'models', 'increases', 'with', 'the', 'complexity', 'of', 'the', 'NER', 'task.', 'Fig.', '4', 'shows', 'the', 'maximum', 'percentage', 'improvement', 'due', 'to', 'pretraining', 'for', 'each', 'of', 'our', 'NER', 'tasks.', 'This', 'suggests', 'that', 'simple', 'NLP', 'tasks', 'with', 'a', 'small', 'number', 'of', 'output', 'classes', 'are', 'much', 'easier', 'to', 'port', 'to', 'phonetic', 'representations,', 'even', 'without', 'pre-training,', 'while', 'more', 'complicated', 'NLP', 'tasks', 'may', 'require', 'a', 'more', 'significant', 'amount', 'of', 'text', 'and/or', 'audio', 'data', 'for', 'pretraining.', 'We', 'expect', 'this', 'trend', 'to', 'carry', 'through', 'to', 'tasks', 'like', 'sentiment', 'analysis,', 'which', 'could', 'be', 'formulated', 'as', 'a', 'simple', 'classification', 'task', 'with', 'NEG,', 'NEU,', 'and', 'POS', 'sentiment', 'labels', 'or', 'a', 'more', 'complicated', 'aspect', 'based', 'sentiment', 'analysis', 'task.']",118,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d39dd45a-2fc8-46a1-9ad9-9624d3a124e2,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Language models are few-shot learners'],['2020'],['Tom Brown;Benjamin Mann;Nick Ryder;Melanie Subbiah;Jared Kaplan;Prafulla Dhariwal;Arvind Neelakantan;Pranav Shyam;Girish Sastry;Amanda Askell'],single,"['We', 'define', 'realism', 'as', 'the', 'inability', 'to', 'distinguish', 'between', 'human-and', 'machine-generated', 'ads.', 'Human', 'annotators', 'are', 'best', 'placed', 'to', 'assess', 'realism', '(e.g.', 'see', '<ref type=""single"">Brown et al., 2020)</ref>', 'but', 'employing', 'and', 'paying', 'them', 'to', 'assess', 'over', '10,000', 'ads', 'was', 'not', 'feasible.', 'Therefore,', 'we', 'train', 'a', 'discriminator', 'model', 'tasked', 'with', 'the', 'binary', 'prediction', 'of', 'whether', 'a', 'given', 'input', 'text', 'was', 'generated', 'by', 'a', 'human', 'or', 'GPT-3', 'and', 'validate', 'a', 'sample', 'of', 'ads', 'using', 'human', 'annotators.', 'Real', 'ads', 'were', 'longer', '(M', '=', '2,846', 'characters,', 'SD', '=', '2,038)', 'than', 'generated', 'ones', '(M', '=', '514,', 'SD', '=', '210)', 'so', 'we', 'truncate', 'texts', 'to', '500', 'characters.', 'For', 'prediction,', 'we', 'use', 'a', 'Multinominal', 'Naive-Bayes', '(MNB)', 'model,', 'which', 'we', 'train,', 'validate', 'and', 'test', 'using', 'an', '80:10:10', 'split', 'taken', 'from', 'the', 'real', 'and', 'generated', 'ads', '(described', 'in', 'Sec.', '3.2).', '6', 'For', 'our', 'realism', 'metric,', 'we', 'then', 'use', 'this', ""model's"", 'predicted', 'probability', 'that', 'an', 'ad', 'is', 'real.', 'To', 'assess', 'the', 'robustness', 'of', 'this', 'metric,', 'we', 'randomly', 'sample', '10', 'ads', 'from', 'each', 'job', 'category', '(female-biased,', 'male-biased', 'and', 'neutral)', 'for', 'each', 'experimental', 'condition', '(N', '=', '150).', 'We', 'then', 'ask', 'three', 'independent', 'annotators', 'to', 'label', 'the', 'ad', 'for', 'whether', 'it', 'was', 'human-or', 'machine-generated', 'and', 'take', 'the', 'majority', 'vote.', '7', 'The', 'accuracy', 'of', 'the', 'majority', 'label', 'compared', 'against', 'the', 'ground', 'truth', 'ad', 'origin', '(real-world', 'or', 'GPT-3', 'generated)', 'proxies', 'ad', 'quality', 'and', 'realism.']",22,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d3c16d9f-45b5-42d7-874c-c4663b7400e3,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Statistical Significance Tests for Machine Translation Evaluation'],['2004'],['P Koehn'],single,"['Table', '2', 'shows', 'BLEU,', 'TER', 'and', 'METEOR', 'scores', 'for', 'the', 'baseline', 'and', 'CCG-based', 'HPB', 'systems', 'on', 'Ar-En', 'translation', 'using', 'just', 'TED', 'data', 'for', 'the', 'translation', 'and', 'language', 'models.', 'HPB-CCG', 'contextual', 'labels', 'system', 'was', 'the', 'best', 'performing', 'system', 'in', 'terms', 'of', 'BLEU,', 'outperforming', 'the', 'PB', 'and', 'HPB', 'baseline', 'systems', 'by', '0.1', 'and', '0.12', 'absolute', 'BLEU', 'points', '(0.42%', 'and', '0.51%', 'relative),', 'respectively.', 'However,', 'these', 'improvements', 'are', 'not', 'statistically', 'significant', '<ref type=""single"">[25].</ref>', 'The', 'results', 'also', 'show', 'that', 'dropping', 'features', 'from', 'the', 'CCG', 'categories', 'and', 'contextual', 'labels', 'had', 'a', 'negative', 'effect', 'on', 'performance.', 'Table', '3', 'shows', 'the', 'evaluation', 'results', 'for', 'the', 'baseline', 'and', 'CCG-based', 'HPB', 'systems', 'on', 'Ar-En', 'translation', 'using', 'TED', 'data', 'for', 'the', 'translation', 'model', 'and', 'mixture', 'adapted', 'language', 'models.', 'Using', 'mixture', 'adaptation', 'of', 'language', 'model', 'leads', 'to', 'an', 'increase', 'of', '5.99', 'absolute', 'BLEU', 'points', '(25.41%', 'relative)', 'for', 'the', 'best', 'performing', 'system', '(CCG', 'contextual', 'labels', 'system)', 'over', 'the', 'corresponding', 'TED-trained', 'model', 'score', 'in', 'Table', '2.', 'Language', 'model', 'adaptation', 'also', 'caused', 'the', 'PB-SMT', 'model', 'scores', 'to', 'improve', 'by', '5.16', 'absolute', 'BLEU', 'points', '(21.99%', 'relative)', 'over', 'the', 'corresponding', 'unadapted', 'PBSMT', 'models.', 'As', 'with', 'the', 'unadapted', 'systems,', 'the', 'HPB-CCG', 'contextual', 'labels', 'system', 'is', 'also', 'the', 'best', 'performing', 'system', 'within', 'all', 'the', 'systems', 'with', 'adapted', 'language', 'models,', 'across', 'all', 'evaluation', 'metrics.', 'It', 'outperformed', 'the', 'mixture-model', 'adapted', 'HPB', 'systems', 'by', 'a', 'statistically', 'insignificant', '0.1', 'absolute', 'BLEU', 'points', '(0.34%', 'relative).', 'However,', 'it', 'improved', 'over', 'the', 'UN-enhanced', 'mixture-model', 'adapted', 'PB', 'system', 'by', '0.93', 'absolute', 'BLEU', 'points', '(3.25%', 'relative)', 'providing', 'a', 'statistically', 'significance', 'at', 'p-level=0.05.', 'The', 'results', 'further', 'demonstrate', 'that', 'dropping', 'features', 'from', 'CCG', 'labels', 'caused', 'the', 'performance', 'of', 'the', 'CCG-based', 'systems', 'to', 'deteriorate.', 'For', 'the', 'Ar-En', 'translation', 'task,', 'the', 'best', 'performing', 'system', 'i.e.', 'the', 'HPB-CCG', 'contextual', 'labels', 'system', '(HPB-CCG', 'context)', 'was', 'submitted', 'as', 'the', 'primary', 'run', 'in', 'the', 'evaluation', 'campaign.']",67,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d40cd438-72ce-43a1-9b11-53f93a7fafae,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Bayesian variable selection in linear regression'],['1988'],['T Mitchell;J Beauchamp'],single,"['E', 'q', 'φ', '(z|x)', '[log', 'p', 'θ', '(x|z)]', '−', 'βD', 'KL', '(q', 'φ', '(z|x),', 'p(z))', '−λD', 'M', 'M', 'D', '(q', 'φ', '(z),', 'p(z))where', 'D', 'M', 'M', 'D', 'is', 'computed', 'using', 'maximum', 'mean', 'discrepancy', '<ref type=""single"">(Gretton et al. (2012),</ref>', 'MMD)', 'and', 'λ', 'is', 'the', 'scalar', 'weight.', 'This', 'term', 'regularises', 'the', 'aggregated', 'posterior', 'q', 'φ', '(z)', 'with', 'a', 'factorised', 'spikeand-slab', 'prior', '<ref type=""single"">(Mitchell and Beauchamp, 1988),</ref>', 'which', 'aims', 'for', 'disentanglement', 'via', 'clustering', 'and', 'sparsifying', 'the', 'representations', 'of', 'z.']",55,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d44f0100-1f97-4b62-91b5-cdfdece6664e,Situation-Specific Multimodal Feature Adaptation,2021,Özge Alac,['The misinterpretation of noncanonical sentences'],['2003'],['Fernanda Ferreira'],single,"['In', 'the', 'second', 'objective,', 'we', 'quantify', 'the', 'contribution', 'of', 'each', 'modality', 'and', 'their', 'aspects', 'given', 'the', 'situation', 'to', 'mimic', 'human', 'heuristic', 'processing', 'capability.', 'Language', 'comprehension', 'involves', 'complex', 'sequential', 'decision', 'making', 'and', 'is', 'affected', 'by', 'both', 'uncertainty', 'about', 'the', 'current', 'input', 'and', 'lack', 'of', 'knowledge', 'about', 'the', 'upcoming', 'material.', 'Thus,', 'people', 'use', '-to', 'a', 'large', 'extent', '-fast', 'and', 'frugal', 'heuristics,', 'i.e.', 'choosing', 'a', 'good-enough', 'representation', '<ref type=""single"">(Ferreira, 2003).</ref>', 'The', 'heuristic', 'view', 'provides', 'a', 'valid', 'explanation', 'for', 'scenarios', 'with', 'a', 'conversation', 'inside', 'noisy', 'conditions.', 'Instead', 'of', 'waiting', '/', 'asking', 'for', 'clarification,', 'the', 'model', 'will', 'reach', 'a', 'good-enough', 'decision', 'based', 'on', 'all', 'information', 'gathered', 'through', 'all', 'available', 'input', 'channels.', 'In', 'order', 'to', 'do', 'that,', 'the', 'set', 'of', 'important', 'features', 'given', 'the', 'situated', 'setting', 'should', 'be', 'chosen', 'automatically.']",64,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d46b2de9-379a-4a20-82ce-641eb4e889c9,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['The intraclass correlation coefficient as a measure of reliability'],['1966'],['J John;unk Bartko'],single,"['Agreement', 'analysis', 'over', 'annotations.', 'Since', 'this', 'annotation', 'task', 'is', 'non-trivial', 'and', 'sometimes', 'subjective,', 'we', 'further', 'compute', 'the', 'intraclass', 'correlation', 'score', '<ref type=""single"">(Bartko, 1966)</ref>', 'for', 'the', 'Amazon', 'Mechanical', 'Turk', 'annotations.', 'Our', 'collected', 'annotations', 'reaches', 'an', 'intraclass', 'correlation', 'score', 'of', '0.72,', 'showing', 'a', 'good', 'agreement', 'among', 'annotators.', 'Another', 'agreement', 'we', 'analyze', 'is', 'showing', 'annotators', '5', 'sample', 'sentences', 'compared', 'to', 'showing', 'them', 'all', 'sentences,', 'to', 'avoid', 'sample', 'bias.', 'We', 'ask', 'annotators', 'to', 'annotate', 'a', 'batch', 'of', '25', 'tokens', 'with', 'all', 'sentences', 'containing', 'the', 'corresponding', 'token', 'shown', 'to', 'them.', 'The', 'agreement', 'reaches', '84.0%,', 'indicating', 'that', 'showing', '5', 'sample', 'sentences', 'does', 'not', 'significantly', 'affect', ""annotator's"", 'decision', 'on', 'the', 'target', 'token.', 'More', 'details', 'of', 'Amazon', 'Mechanical', 'Turk', 'interface', 'can', 'be', 'found', 'in', 'the', 'Appendix.']",20,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d473a327-e9ec-4be0-8fc8-8368a5318b03,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,"['Comprehensive supersense disambiguation of English prepositions and possessives', 'A hierarchy with, of, and for preposition supersenses', 'A corpus of preposition supersenses', 'Supersense and sensibility: Proxy tasks for semantic annotation of prepositions']","['2018', '2015', '2016', '2021']","['Nathan Schneider;Jena Hwang;Vivek Srikumar;Jakob Prange;Austin Blodgett;Sarah Moeller;Aviram Stern;Adi Shalev;Omri Abend', 'Nathan Schneider;Vivek Srikumar;Jena Hwang;Martha Palmer', ""Nathan Schneider;Jena Hwang;Vivek Srikumar;Meredith Green;Abhijit Suresh;Kathryn Conger;O' Tim;Martha Gorman;unk Palmer"", 'Luke Gessler;Shira Wein;Nathan Schneider']",group,"['The', 'Use', 'of', 'Prepositions', 'as', 'Semantic', 'Labels', 'While', 'the', 'relations', 'we', 'identify', 'between', 'NPs', 'can', 'be', 'expressed', 'using', 'prepositions,', 'one', 'could', 'argue', 'that', 'using', 'prepositions', 'as', 'semantic', 'labels', 'is', 'not', 'ideal,', 'due', 'to', 'their', 'inherent', 'ambiguity', '<ref type=""group"">(Schneider et al., 2015 (Schneider et al., , 2016 (Schneider et al., , 2018,, Gessler et al., 2021):</ref>', 'indeed', 'a', 'preposition', 'such', 'as', 'for', 'has', 'multiple', 'senses,', 'and', 'can', 'indicate', 'a', 'large', 'set', 'of', 'semantic', 'relations', 'ranging', 'from', 'BENEFICIARY', 'to', 'DURATION.']",36,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
d4d97802-5a6d-4ad1-a54a-6865f0e370ec,A User-Based Usability Assessment of Raw Machine Translated Technical Instructions,2012,Stephen Doherty;Sharon O'brien,['unknown'],['unknown'],['unknown'],single,"['While', 'there', 'is', 'some', 'divergence', 'around', 'the', 'definition', 'of', 'usability,', 'the', 'majority', 'of', 'terms', 'in', 'the', 'literature', 'closely', 'adhere', 'to', 'the', 'ISO', 'definition.', 'Following', 'the', 'ISO/TR', '16982', 'definition,', 'usability', 'is', 'understood', 'here', 'as', '""the', 'extent', 'to', 'which', 'a', 'product', 'can', 'be', 'used', 'by', 'specified', 'users', 'to', 'achieve', 'specified', 'goals', 'with', 'effectiveness,', 'efficiency,', 'and', 'satisfaction', 'in', 'a', 'specified', 'context', 'of', 'use""', '<ref type=""single"">(ISO, 2002).</ref>', 'The', 'objective', 'of', 'this', 'study', 'was', 'to', 'establish', 'how', 'usable', 'raw', 'machine', 'translated', 'instructions', 'were', 'for', 'end', 'users', 'in', 'comparison', 'with', 'the', 'original', 'source', 'text,', 'which', 'was', 'in', 'English.']",60,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
d5309f1c-3a62-470f-a3ab-e1668003f0f9,Toward High Performance Machine Translation: Preliminary Results from Massively Parallel Memory-Based Translation on SNAP*,1991,Hiroaki Kitano;Dan Moldovan;Seungho Cha,['Unification and Classification: An Experiment in Information-Based Parsing'],['1989'],['R Kasper ; Kasper'],single,"['Syntactic', 'constraint', 'network', '(SCN)', 'is', 'a', 'new', 'feature', 'which', 'has', 'not', 'been', 'used', 'in', 'the', 'previous', 'works', 'in', 'memory-based', 'NLP', 'SCN', 'is', 'used', 'to', 'handle', 'syntactic', 'phenomena', 'without', 'undermining', 'benefits', 'of', 'memory-based', 'approach.', 'Although,', 'unification', 'has', 'been', 'the', 'central', 'operation', 'in', 'the', 'recent', 'syntactic', 'theories', 'such', 'as', 'LFG', '<ref type=""single"">[Kaplan and Bresnan, 1982]</ref>', 'and', 'HPSG', '<ref type=""single"">[Pollard and Sag, 1987],</ref>', 'we', 'prefer', 'SCN', 'over', 'unificationbased', 'approach', 'because', 'unification', 'is', 'computationally', 'expensive', 'and', 'it', 'is', 'not', 'suitable', 'for', 'massively', 'parallel', 'implementation.', 'Although', 'there', 'is', 'a', 'report', 'on', 'an', 'unification', 'algorithm', 'on', 'massively', 'parallel', 'machines', '<ref type=""single"">[Kitano. 1991b],</ref>', 'still', 'it', 'is', 'computationally', 'expensive,', 'and', 'takes', 'up', 'major', 'part', 'of', 'computing', 'lime', 'even', 'on', 'SNAP.', 'In', 'addition.', 'there', 'is', 'a', 'report', 'that', 'unification', 'is', 'not', 'necessary', 'the', 'correct', 'mechanism', 'of', 'enforcing', 'Figure', '2:', 'Concept', 'Sequence', 'on', 'SNAP', 'agreement', '<ref type=""single"">[Ingria, 1990].</ref>', 'Also,', 'the', 'classification-based', 'approach', '<ref type=""single"">[Kasper, 1989],</ref>', 'which', 'pre-compiles', 'a', 'hierarchy', 'of', 'feature', 'structures', 'in', 'the', 'form', 'of', 'a', 'semantic', 'network,', 'can', 'carry', 'out', 'similar', 'task', 'with', 'less', 'computational', 'cost', '<ref type=""single"">[Kim and Moldovan, 1990].</ref>', 'Finally,', 'current', 'unification', 'hard-rejects', 'failure', 'which', 'is', 'not', 'desirable', 'from', 'our', 'point.', 'We', 'want', 'the', 'system', 'to', 'be', 'robust', 'enough', 'that', 'while', 'recognizing', 'minor', 'syntactic', 'violation,', 'it', 'keep', 'processing', 'to', 'get', 'meaning', 'of', 'the', 'sentence.']",130,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d5671bb6-a860-4c87-9eb3-0f6c88f2e069,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['unknown'],['unknown'],['unknown'],single,"['The', 'TNE', 'task', 'we', 'define', 'side-steps', 'all', 'the', 'above', 'issues.', 'It', 'is', 'based', 'on', 'the', 'text', 'alone,', 'without', 'revealing', 'additional', 'information', 'not', 'present', 'in', 'the', 'text.', 'The', 'exhaustive', 'nature', 'of', 'the', 'task', 'entails', 'looking', 'both', 'at', 'positive', 'instances', '(where', 'a', 'relation', 'exists)', 'and', 'negative', 'ones', '(where', 'it', ""doesn't),"", 'making', 'it', 'harder', 'for', 'models', 'to', 'pick', 'up', 'shallow', 'heuristics.', 'We', ""don't"", 'reveal', 'information', 'to', 'a', 'model,', 'beyond', 'the', 'information', 'that', 'the', 'two', 'NPs', 'appear', 'in', 'the', 'same', 'text.', 'Finally,', 'the', 'list', 'of', 'NPs', 'to', 'be', 'considered', 'is', 'pre-specified,', 'isolating', 'the', 'problem', 'of', 'understanding', 'the', 'relations', 'between', 'NPs', 'in', 'the', 'text', 'from', 'the', 'much', 'easier', 'yet', 'intervening', 'problem', 'of', 'identifying', 'NPs', 'and', 'agreeing', 'on', 'their', 'exact', 'spans.', '<ref type=""single"">of, against, in, by, on, about, with, after, to, from, for, among, under, at, between, during, near, over, before, inside, outside, into, around</ref>', 'Table', '1:', 'Prepositions', 'used', 'in', 'TNE.', 'Thus,', 'we', 'consider', 'TNE', 'a', 'less', 'biased', 'and', 'less', 'gameable', 'measure', 'of', 'RC', 'than', 'QA-based', 'benchmarks.', 'Of', 'course,', 'the', 'information', 'captured', 'by', 'TNE', 'is', 'limited', 'and', 'does', 'not', 'cover', 'all', 'levels', 'of', 'text', 'understanding.', 'Yet,', 'performing', 'the', 'task', 'correctly', 'entails', 'a', 'non-trivial', 'comprehension', 'of', 'texts,', 'which', 'human', 'readers', 'do', 'as', 'a', 'byproduct', 'of', 'reading.']",115,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d5ba19e6-4390-4d3b-8ea3-b5c126173671,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Multilingual extractive reading comprehension by runtime machine translation'],['2018'],['Akari Asai;Akiko Eriguchi;Kazuma Hashimoto;Yoshimasa Tsuruoka'],single,"['Another', 'approach', 'consists', 'of', 'translating', 'the', 'QA', 'triples', 'of', 'the', 'target', 'domain', 'into', 'the', 'source', 'domain,', 'so', 'the', 'model', 'trained', 'on', 'the', 'source', 'language', 'can', 'be', 'directly', 'applied', 'on', 'the', 'translated', 'target', 'language', 'testing', 'data.', 'As', 'an', 'exemple,', '<ref type=""single"">Asai et al. (2018)</ref>', ""'s"", 'method', 'consisted', 'of', 'combining', 'the', 'alignment', 'attention', 'scores', 'from', 'a', 'MT', 'model', 'with', 'an', 'English', 'QA', 'model', 'to', 'guide', 'the', 'answer', 'extraction', 'process.']",38,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d5db8202-d4c5-4610-8f66-9649d4038baf,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,"['Machine translation as an expert task', 'Knowledge-based machine translation, the CMU approach', 'Linguistic and extra-linguistic knowledge', 'Machine translation in a monolingual environment', 'Strategies for interactive machine translation: the experience and implications of the UMIST Japanese project', 'Interactive translation: a new approach']","['1987', '1987', '1986', '1990', '1986', '1988']","['R Johnson;P Whitelock', 'J Carbonell;M Tomita', 'K Schubert', 'X Huang', 'P Whitelock;M Wood;B Chandler;N Holden;H Horsfall', 'R Zajac']",group,"['Although', 'first', 'suggested', 'by', 'Kay', '<ref type=""single"">[20],</ref>', 'the', 'alternative', 'idea', 'of', 'an', 'MT', 'system', 'for', 'a', 'monolingual', 'user', 'seems', 'only', 'to', 'have', 'really', 'been', 'followed', 'up', 'about', 'five', 'years', 'ago,', 'when', 'several', 'proposals', 'for', 'interactive', 'MT', 'for', 'monolingual', 'users', 'were', 'apparently', 'initiated', '<ref type=""group"">[7, 14, 17, 38, 48, 49].</ref>']",41,"[0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1]"
d6034a5c-0a60-4c94-bcb0-cf5bc56ab134,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['UNIFIEDQA: Crossing format boundaries with a single QA system'],['2020'],['Daniel Khashabi;Sewon Min;Tushar Khot;Ashish Sabharwal;Oyvind Tafjord;Peter Clark;Hannaneh Hajishirzi'],single,"['We', 'extensively', 'evaluate', 'top-k', 'attention', 'on', 'a', 'wide', 'range', 'of', 'tasks', 'and', 'demonstrate', 'its', 'mentioned', 'advantages.', 'Training', 'from', 'scratch,', 'we', 'show', 'top-k', 'attention', 'performs', 'as', 'well', 'as', 'vanilla', 'self-attention', 'on', 'Long', 'Range', 'Arena,', 'a', 'benchmark', 'dedicated', 'to', 'evaluating', 'the', 'ability', 'of', 'transformers', 'to', 'handle', 'long', 'sequences,', 'and', 'in', 'a', 'language', 'modeling', 'task', '(WikiText-103).', 'Second,', 'we', 'show', 'top-k', 'attention', 'can', 'be', 'used', 'as', 'a', 'drop-in', 'replacement', 'for', 'vanilla', 'attention', 'at', 'inference', 'time', 'without', 'any', 'additional', 'training', 'at', 'the', 'feed-forward', 'layer', 'of', 'the', 'UnifiedQA', 'model', '<ref type=""single"">(Khashabi et al., 2020)</ref>', 'on', '12', 'different', 'question', 'answering', '(QA)', 'datasets,', 'reducing', 'the', 'number', 'of', 'keys', 'used', 'per', 'query', 'by', 'more', 'than', '99%.', 'Last,', 'we', 'show', 'top-k', 'attention', 'obtains', 'similar', 'performance', 'to', 'vanilla', 'attention', 'on', 'a', 'wide', 'range', 'of', 'QA', 'tasks', 'when', 'fine-tuning', 'T5', '<ref type=""single"">(Raffel et al., 2020),</ref>', 'without', 'the', 'need', 'for', 'any', 'corrective', 'pre-training.']",83,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d644c245-27f5-4d66-980b-a6bfc5521453,Entity Attribute Relation Extraction with Attribute-Aware Embeddings,2020,Dan Iter;Xiao Yu;Fangtao Li,['Glove: Global vectors for word representation'],['2014'],['Jeffrey Pennington;Richard Socher;Christopher D Manning'],single,"['We', 'initialize', 'attribute', 'embeddings', 'with', 'Glove', '<ref type=""single"">(Pennington et al., 2014)</ref>', 'word', 'embeddings.', 'For', 'an', 'entity,', 'we', 'take', 'all', 'the', 'known', 'attributes', 'from', 'K', 'e.', 'The', 'representation', 'of', 'each', 'entity', 'is', 'the', 'weighted', 'sum', 'of', 'the', 'known', 'attributes,', 'with', 'learned', 'attention', 'weights.', 'The', 'weights', 'are', 'shared', 'between', 'entities', 'and', 'attributes.']",6,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d648c9a3-a0fe-424e-84ca-46519b1b9be4,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Graph convolutional networks for text classification'],['2019'],['Liang Yao;Chengsheng Mao;Yuan Luo'],single,"['We', 'further', 'compared', 'our', 'strategy', 'with', 'other', 'graph-based', 'approaches:', 'Text', 'Graph', 'Convolutional', 'Network', '(TextGCN)', '<ref type=""single"">(Yao et al., 2019)</ref>', 'and', 'Heterogeneous', 'Graph', 'Attention', 'Network', '(HGAT)', '<ref type=""single"">(Yang et al., 2021).</ref>', 'The', 'former', 'models', 'the', 'whole', 'text', 'corpus', 'as', 'a', 'document-word', 'graph', 'with', 'word', 'co-occurrence', 'relations', 'and', 'applies', 'GCN', 'for', 'classification.', 'The', 'latter', 'models', 'the', 'texts', 'using', 'a', 'heterogeneous', 'information', 'network', 'framework', 'and', 'adopts', 'heterogeneous', 'graph', 'attention', 'to', 'embed', 'that', 'framework', 'for', 'text', 'classification', 'based', 'on', 'a', 'dual-level', 'attention', 'mechanism.', 'Finally,', 'we', 'compared', 'our', 'approach', 'with', 'a', 'transformer-based', 'method', 'as', 'it', 'has', 'achieved', 'remarkable', 'results', 'in', 'several', 'areas', 'of', 'Natural', 'Language', 'Processing', '(NLP).', 'We', 'compared', 'our', 'strategy', 'with', 'BR-BERT', '<ref type=""single"">(Leite et al., 2020),</ref>', 'which', 'is', 'a', 'monolingual', 'BERT,', 'and', 'M-BERT', '<ref type=""single"">(Leite et al., 2020),</ref>', 'which', 'is', 'a', 'multilingual', 'BERT.', 'Table', '5', 'shows', 'the', 'comparison', 'between', 'these', 'methods.', 'As', 'we', 'can', 'see', 'from', 'Table', '5,', 'our', 'approach', 'outperformed', 'the', 'graph-based', 'methods', 'and', 'reached', 'a', 'competitive', 'result', 'compared', 'to', 'transformer', 'models.', 'Although', 'our', 'strategy', 'did', 'not', 'outperform', 'transformers,', 'we', 'believe', 'the', 'results', 'are', 'very', 'promising,', 'since', 'it', 'requires', 'much', 'less', 'computational', 'power', 'than', 'transformers.', 'Moreover,', 'our', 'method', 'requires', 'less', 'annotated', 'data', '(only', '10%)', 'than', 'transformers', 'to', 'achieve', 'interesting', 'results.']",14,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d66953d2-c2ff-4a09-89d0-887c28f12c83,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['ChAII -Hindi and Tamil question answering'],['2021'],['unk Google'],single,"['In', 'our', 'experiments,', 'we', 'use', 'ChAII', '<ref type=""single"">(Google, 2021)</ref>', 'question-answering', 'dataset', 'for', 'fine-tuning', 'and', 'evaluation.', 'This', 'dataset', 'was', 'recently', 'released', 'by', 'Google', 'Research', 'India', 'and', 'has', '1,114', 'records', 'of', 'context,', 'question,', 'answer,', 'and', 'its', 'corresponding', 'start', 'position', 'in', 'the', 'context', 'for', 'Tamil', 'and', 'Hindi', 'languages.', 'Hindi', 'is', 'represented', 'predominantly', 'in', 'the', 'dataset', 'with', 'nearly', 'two-thirds', 'of', 'the', 'records.', 'As', 'the', 'ChAII', 'dataset', 'has', 'been', 'published', 'as', 'part', 'of', 'an', 'ongoing', 'Kaggle', 'competition', '<ref type=""single"">(Google, 2021),</ref>', 'the', 'complete', 'test', 'dataset', 'has', 'not', 'been', 'disclosed', 'to', 'the', 'public.', 'Hence,', 'we', 'have', 'used', ""Scikit-learn's"", 'train_test_split', 'method', 'with', 'a', 'test', 'size', 'of', '100,', 'stratified', 'on', 'language', 'and', 'with', 'a', 'random', 'seed', 'of', '0,', 'to', 'get', 'the', 'test', 'split', 'from', 'the', 'training', 'data.', 'Similarly,', 'we', 'applied', 'the', 'same', 'method', 'over', 'the', 'filtered', 'train', 'split', 'to', 'get', 'the', 'validation', 'split', 'of', '100', 'samples.', 'We', 'also', 'use', 'the', 'translations', 'and', 'transliterations', 'of', 'this', 'training', 'split', 'as', 'augmented', 'samples', 'for', 'fine-tuning', 'the', 'QA', 'model.', 'Stanford', 'Question', 'Answering', 'Dataset', '(SQuAD)', '<ref type=""single"">(Rajpurkar et al., 2016)</ref>', 'is', 'the', 'most', 'popular', 'question-answering', 'dataset', 'in', 'English.', 'This', 'dataset', 'had', 'been', 'crowdsourced', 'to', 'form', '100K', 'records', 'of', 'answerable', 'question-answer', 'pairs', 'along', 'with', 'the', 'context.', 'This', 'dataset', 'is', 'used', 'to', 'pre-train', 'the', 'QA', 'head', 'added', 'to', 'the', 'pre-trained', 'mBERT', 'model,', 'which', 'is', 'subsequently', 'fine-tuned', 'using', 'the', 'ChAII', 'dataset.']",70,"[2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d66a1065-66cb-4417-8154-f69410a94a7e,A Parameter-Based Message-Passing Parser for MT of Korean and English,1994,Bonnie Dorr;Jye-Hoon Lee;Sungki Suh,['Interlingual machine translation: a parameterized approach'],['1993'],['B Dorr'],single,"['We', 'are', 'currently', 'incorporating', 'the', 'parameterized', 'parser', 'into', 'an', 'interlingual', 'MT', 'system', 'called', 'PRINCITRAN.', 'The', 'current', 'framework', 'is', 'well-suited', 'to', 'an', 'interlingual', 'design', 'since', 'the', 'linking', 'rules', 'between', 'the', 'syntactic', 'representations', 'given', 'above', 'and', 'the', 'underlying', 'lexical-semantic', 'representation', 'are', 'well-defined', '(see', '<ref type=""single"">Dorr (1993a)</ref>', ').', 'We', 'adopt', 'the', 'Lexical', 'Conceptual', 'Structure', '(LCS)', 'of', ""Dorr's"", 'work', 'and', 'use', 'a', 'parameter-setting', 'approach', 'to', 'account', 'for', 'the', 'divergences', 'presented', 'in', 'the', 'last', 'section.', '<ref type=""single"">(Dorr (1993b)</ref>', 'describes', 'a', 'parametric', 'approach', 'to', 'mapping', 'between', 'the', 'interlingua', 'and', 'the', 'syntactic', 'structure.)']",68,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d75a0957-3626-4538-bb1e-c836d9d6a796,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Character-level representations improve DRS-based semantic parsing even in the age of BERT'],['2020'],['Rik Van Noord;Antonio Toral;Johan Bos'],single,"['We', 'also', 'compare', 'with', 'the', 'semi-rule-based', 'system', 'used', 'for', 'pre-annotating', 'the', 'Parallel', 'Meaning', 'Bank', '<ref type=""single"">(Abzianidze et al., 2017).</ref>', '<ref type=""single"">Van Noord et al. (2020)</ref>', 'call', 'this', 'system', '""Pro', 'Boxer"".', 'In', 'a', 'sense,', 'Pro', 'Boxer', 'is', 'closest', 'in', 'approach', 'to', 'ours', 'because', 'it', 'makes', 'use', 'of', 'neural', 'taggers', 'for', 'making', 'token-level', 'tagging', 'predictions.', 'It', 'differs', 'from', 'ours', 'and', 'all', 'other', 'systems', 'however', 'in', 'that', 'it', 'is', 'not', 'fully', 'trainable', 'from', 'examples,', 'the', 'translation', 'from', 'tags', 'to', 'DRSs', 'is', 'done', 'via', 'hand-crafted', 'rules.', 'Moreover,', 'it', 'relies', 'on', 'a', 'CCG', 'parser', 'that', 'creates', 'explicit', 'syntactic', 'representation', 'which', 'is', 'perhaps', 'more', 'complexity', 'than', 'needed.', 'As', 'van', 'Noord', 'et', 'al.', 'also', 'point', 'out,', 'the', 'comparison', 'with', 'Pro', 'Boxer', 'is', 'not', 'quite', 'fair', 'because', 'it', 'is', 'the', 'system', 'that', 'produced', 'the', 'PMB', 'pre-annotations', 'and', 'thus', 'profits', 'from', 'anchoring', 'bias.']",15,"[0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d75da8af-87b1-474c-9293-78f64eb12fb7,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,"['Retrieval Evaluation with Incomplete Information', 'The Philosophy of Information Retrieval Evaluation']","['2004', '2002']","['Chris Buckley;Ellen Voorhees', 'Ellen Voorhees']",group,"['Large', 'explanations', 'are', 'typically', 'evaluated', 'on', 'two', 'dimensions:', 'relevance', 'and', 'completeness.', 'Relevance', 'refers', 'to', 'whether', 'each', 'fact', 'in', 'an', 'explanation', 'is', 'relevant,', 'topical,', 'and', 'required', 'to', 'complete', 'the', 'chain', 'of', 'inference', 'that', 'moves', 'from', 'question', 'to', 'correct', 'answer.', 'Conversely,', 'completeness', 'evaluates', 'whether', 'the', 'entire', 'set', 'of', 'facts', 'in', 'the', 'explanation,', 'together,', 'composes', 'a', 'complete', 'chain', 'of', 'inference', 'from', 'question', 'to', 'answer,', 'without', 'significant', 'gaps.', 'In', 'practice,', 'both', 'of', 'these', 'are', 'challenging', 'to', 'evaluate', 'automatically', '<ref type=""group"">(Buckley and Voorhees, 2004, Voorhees, 2002),</ref>', 'given', 'that', 'multi-hop', 'datasets', 'typically', 'include', 'a', 'single', 'example', 'of', 'a', 'complete', 'explanation,', 'in', 'large', 'part', 'due', 'to', 'the', 'time', 'and', 'expense', 'associated', 'with', 'generating', 'such', 'annotation.', 'Underscoring', 'this', 'difficulty,', 'post-competition', 'manual', 'analyses', 'on', 'participating', 'systems', 'in', 'the', 'previous', 'two', 'iterations', 'of', 'this', 'shared', 'task', 'showed', 'that', 'models', 'may', 'be', 'performing', 'up', 'to', '20%', 'better', 'at', 'retrieving', 'correct', 'facts', 'to', 'build', 'their', 'explanation', 'from,', 'highlighting', 'this', 'significant', 'methodological', 'challenge.']",74,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
d76bb0fd-60bd-44b7-a655-784adbdc8e19,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['Learning phrase representations using RNN encoder-decoder for statistical machine translation'],['2014'],['K Cho;B Van Merrienboer;C Gülc ¸ehre;F Bougares;H Schwenk;Y Bengio'],single,"['Neural', 'Machine', 'Translation', '(NMT)', 'approach', 'has', 'been', 'further', 'developed', 'in', 'the', 'last', 'years', '<ref type=""group"">[1, 2].</ref>', 'In', 'contrast', 'to', 'the', 'traditional', 'phrased-based', 'statistical', 'machine', 'translation', '<ref type=""single"">[3]</ref>', 'that', 'represents', 'and', 'translates', 'the', 'input', 'sentence', 'with', 'a', 'set', 'of', 'phrases,', 'NMT', 'uses', 'the', 'sequence', 'to', 'sequence', 'learning', 'architecture', 'and', 'the', 'whole', 'input', 'sentence', 'is', 'considered', 'as', 'one', 'unit', 'for', 'translation', '<ref type=""single"">[4].</ref>', 'Recently,', 'NMT', 'is', 'gaining', 'more', 'and', 'more', 'interest', 'and', 'showing', 'better', 'accuracy', 'than', 'phrase-based', 'system', 'translating', 'several', 'language', 'pairs.', 'In', 'spite', 'of', 'these', 'recent', 'improvements,', 'the', 'NMT', 'systems', 'still', 'have', 'some', 'restrictions', 'and', 'difficulties', 'to', 'translate.', 'One', 'of', 'them', 'is', 'the', 'high', 'computational', 'of', 'the', 'softmax', 'function', 'which', 'requires', 'to', 'normalize', 'all', 'the', 'output', 'vocabulary', 'size.']",56,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d781dc37-7528-4ef1-8fe4-237f761b4520,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['unknown'],['unknown'],['unknown'],single,"['We', 'conduct', 'all', 'experiments', 'with', 'the', 'deep', 'learning', 'framework', 'PaddlePaddle', '<ref type=""single"">(Ma et al., 2019)</ref>', 'on', 'up', 'to', 'eight', 'NVIDIA', 'Tesla', 'V100', 'GPUs', '(with', '32G', 'RAM).']",10,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d782a346-89a3-47e8-892d-8e4a9134de23,Controlled Text Generation with Adversarial Learning,2020,Federico Betti;Giorgia Ramponi;Massimo Piccardi,"['unknown', 'RelGAN: Relational Generative Adversarial Networks for Text Generation']","['2018', '2019']","['Adam Santoro;Ryan Faulkner;David Raposo;Jack Rae;Mike Chrzanowski;Théophane Weber;Daan Wierstra', 'Weili Nie;Nina Narodytska;Ankit Patel']",group,"['The', 'generator', 'is', 'based', 'on', 'a', 'Relational', 'Memory', 'with', 'self-attention', '<ref type=""group"">[18, 16].</ref>', 'This', 'model', 'updates', 'its', '""internal', 'values""', 'and', 'produces', 'its', 'final', 'output', 'by', 'selecting', 'from', 'its', 'memory', 'cells', 'with', 'a', 'self-attention', 'mechanism.', 'Leveraging', 'an', 'idea', 'similar', 'to', 'that', 'of', 'image-based', 'conditional', 'GANs', '<ref type=""single"">[15],</ref>', 'we', 'introduce', 'an', 'external', 'conditioning', 'into', 'the', 'generator.', 'First,', 'given', 'the', 'conditioning', 'input', 'c', '2', 'R', 'd,', 'the', 'model', 'computes', 'an', 'embedding', 't', 'for', 'c', 'using', 'functionf', '✓:', 'R', 'd!', 'R', 'm,', 'with', 'm', '&lt,', 'd.Function', 'f', '✓', 'has', 'been', 'implemented', 'using', 'a', 'feed-forward', 'neural', 'network', 'with', 'a', 'self-attention', 'layer.', 'The', 'conditioning', 'vector', 'c', 'may', 'originate', 'from', 'any', 'type', 'of', 'different', 'source', 'as', 'long', 'as', 'it', 'remains', 'consistent', 'during', 'the', 'individual', 'training.', 'Depending', 'on', 'the', 'required', 'task,', 'as', 'shown', 'in', 'the', 'experiment', 'phase,', 'it', 'will', 'change.', 'This', 'vector', 'c', 'is', 'the', 'only', 'link', 'between', 'the', 'conditioning', 'and', 'the', 'generative', 'model,', 'its', 'influence', 'on', 'the', 'final', 'output', 'will', 'be', 'crucial', 'for', 'the', 'conditioning', 'of', 'the', 'generated', 'sentence.', 'f', '✓', 'has', 'been', 'adopted', 'to', 'give', 'the', 'model', 'the', 'ability', 'to', 'learn', 'the', 'best', 'manipulation', 'of', 'the', 'conditioning', 'vector', 'to', 'insert', 'into', 'the', 'memory.']",10,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d782b259-0217-4707-a5a1-6721f122f734,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['ROUGE: A package for automatic evaluation of summaries'],['2004'],['Chin-Yew Lin'],single,"['All', 'of', 'the', 'models', 'in', 'the', 'pipeline', 'described', 'in', 'Section', '2', 'are', 'trained', 'using', 'only', 'the', 'training', 'set', 'of', 'the', 'original', 'LIGHT', 'and', 'LIGHT-Quests', 'data.', 'LIGHT-Quests', 'inherits', 'characters,', 'locations,', 'and', 'objects', 'from', 'the', 'original', 'LIGHT', 'dataset', 'and', 'adds', 'on', 'motivations', 'and', 'goals', 'in', 'the', 'form', 'of', 'quests.', 'Thus,', 'the', 'character,', 'location,', 'and', 'object', 'retrieval', 'models', 'are', 'evaluated', 'on', 'the', 'LIGHT', 'unseen', 'test', 'set', 'and', 'the', 'motivation', 'and', 'goal', 'generation', 'models', 'are', 'evaluated', 'on', 'the', 'LIGHT-Quests', 'test', 'set.', 'We', 'report', 'the', 'standard', 'array', 'of', 'metrics:', 'hits@10', 'and', 'F1', 'ranking', 'prediction', 'score', 'for', 'retrieval', 'models,', 'and', 'F1', '(as', 'a', 'harmonic', 'average', 'of', '<ref type=""single"">BLEU-1 (Papineni et al., 2002)</ref>', 'and', 'ROUGE-1', '<ref type=""single"">(Lin, 2004))</ref>', 'and', 'perplexity', 'for', 'generative', 'models.', 'Hyperparameters', 'for', 'all', 'models', 'are', 'found', 'in', 'Appendix', 'A.6.', 'Analysis.', 'Table', '1', 'presents', 'the', 'results', 'of', 'this', 'evaluation.', 'There', 'are', 'two', 'primary', 'trends', 'to', 'note:', '(1)', 'character', 'retrieval', 'is', 'easier', 'than', 'retrieving', 'location', 'and', 'objects,', 'and', '(2)', 'goal', 'action', 'generation', 'is', 'easier', 'than', 'motivation', 'generation.', 'We', 'hypothesize', 'that', 'the', 'first', 'trend', 'is', 'a', 'direct', 'consequence', 'of', 'the', 'fact', 'that', 'generated', 'motivations', 'and', 'goals', 'regularly', 'contain', 'the', 'names', 'of', 'the', 'characters', 'involved', 'but', 'mostly', 'leave', 'implicit', 'information', 'such', 'as', 'the', 'objects', 'required-e.g.', 'the', 'action', 'hit', 'dragon', 'as', 'a', 'knight', 'would', 'require', 'a', 'weapon', 'such', 'as', 'a', 'sword', 'to', 'be', 'equipped', 'first.', 'The', 'second', 'trend', 'stems', 'from', 'the', 'fact', 'that', 'goal', 'actions', 'can', 'often', 'be', 'thought', 'of', 'as', 'condensed', 'version', 'of', 'the', 'short', 'motivation-number', 'of', 'tokens', 'required', 'to', 'generate', 'goal', 'actions', 'is', 'far', 'less', 'than', 'short', 'motivations.', 'This', 'implies', 'that', 'the', 'goal', 'action', 'model', 'is', 'akin', 'to', 'a', 'summarization', 'model', 'as', 'opposed', 'to', 'the', 'short', 'motivation', 'model', 'which', 'has', 'the', 'more', 'difficult', 'task', 'of', 'generating', 'the', 'motivation', 'with', 'only', 'initial', 'persona', 'and', 'location', 'information.']",103,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d81cfae9-9762-4879-869b-be0318f5413e,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Subword regularization: Improving neural network translation models with multiple subword candidates'],['2018'],['Taku Kudo'],single,"['In', 'this', 'context,', 'the', 'main', 'question', 'then', 'arises:', ""shouldn't"", 'machine', 'translation', 'be', 'multilingual', 'for', 'languages', 'spoken', 'in', 'a', 'multilingual', 'country', 'like', 'Peru?', 'By', 'taking', 'advantage', 'of', 'few', 'resources,', 'and', 'other', 'strategies', 'such', 'as', 'multilingual', 'unsupervised', 'subword', 'segmentation', 'models', '<ref type=""single"">(Kudo, 2018),</ref>', 'pretraining', 'with', 'high', 'resource', 'language-pairs', '<ref type=""single"">(Kocmi and Bojar, 2018),</ref>', 'back-translation', '<ref type=""single"">(Sennrich et al., 2016a),</ref>', 'and', 'fine-tuning', '<ref type=""single"">(Neubig and Hu, 2018),</ref>', 'we', 'deployed', 'the', 'first', 'many-to-one', 'and', 'one-to-many', 'multilingual', 'NMT', 'models', '(paired', 'with', 'Spanish)', 'for', 'four', 'indigenous', 'languages:', 'Aymara,', 'Ashaninka,', 'Quechua', 'and', 'Shipibo-Konibo.']",38,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
d8e0ca45-a15a-4789-99cf-beae9301c6cf,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks'],['1908'],['Jiasen Lu;Dhruv Batra;Devi Parikh;Stefan Lee'],single,"['The', 'use', 'of', 'both', 'language', 'and', 'vision', 'transfer', 'learning', 'is', 'important', 'for', 'multimodal', 'tasks.', 'This', 'line', 'of', 'research', 'has', 'attracted', 'much', 'attention', 'with', 'various', 'new', 'language-vision', 'models,', 'such', 'as', 'VilBERT', '<ref type=""single"">(Lu et al., 2019),</ref>', '12-in-1', '<ref type=""single"">(Lu et al., 2020).</ref>', 'No', 'participants', 'employ', 'into', 'this', 'approach', 'in', 'the', 'ReINTEL', 'challenge', 'due', 'to', 'the', 'lack', 'of', 'language', 'and', 'vision', 'pre-trained', 'models', 'in', 'Vietnamese.', 'Moreover,', 'it', 'is', 'required', 'to', 'have', 'extensive', 'computer', 'resources', 'for', 'applying', 'this', 'approach', 'in', 'a', 'data', 'challenge.', 'In', 'the', 'future,', 'we', 'expect', 'to', 'see', 'more', 'research', 'done', 'in', 'this', 'direction', 'because', 'both', 'images', 'and', 'texts', 'are', 'essential', 'to', 'SNS', 'issues.']",30,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d909c729-1c38-46f4-ba99-17c657130f02,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Statistically-Driven Computer Grammars of English: The IBM/ Lancaster Approach'],['1993'],['E Black;R Garside;G Leech'],single,"['This', 'grammar', 'was', 'developed', 'and', 'refined', 'in', 'a', 'corpus-based', 'fashion', '(e.g.', 'see', '<ref type=""single"">Black, 1993)</ref>', 'by', 'testing', 'against', 'sentences', 'from', 'the', 'Susanne', 'corpus', '<ref type=""single"">(Sampson, 1994),</ref>', 'a', '138K', 'word', 'treebanked', 'and', 'balanced', 'subset', 'of', 'the', 'Brown', 'corpus', '1.']",12,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d91f0dbb-f313-4c5f-8151-61b42c517741,End-to-end ASR to jointly predict transcriptions and linguistic annotations,2021,Motoi Omachi;Yuya Fujita;Shinji Watanabe;Matthew Wiesner,"['Multi-task multi-resolution char-to-BPE cross-attention decoder for end-to-end speech recognition', 'Massively multilingual adversarial speech recognition', 'Acoustic-to-word attention-based model complemented with character-level CTC-based model', 'Hierarchical multitask learning with CTC']","['2019', '2019', '2018', '2018']","['D Gowda;A Garg;K Kim;M Kumar;C Kim', 'O Adams;M Wiesner;S Watanabe;D Yarowsky', 'S Ueno;H Inaguma;M Mimura;T Kawahara', 'R Sanabria;F Metze']",group,"['One', 'frequently', 'used', 'NN', 'architecture', '<ref type=""group"">(Ueno et al., 2018, Gowda et al., 2019, Sanabria and Metze, 2018, Adams et al., 2019)</ref>', 'that', 'maximizes', 'Eq.', '(3)', 'is', 'the', 'O2M', 'model', 'trained', 'with', 'multi-task', 'learning.', 'Fig.', '1(a)', 'shows', 'the', 'architecture', 'of', 'the', 'model.', 'The', 'O2M', 'model', 'outputs', 'several', 'types', 'of', 'sequences', 'independently.', 'In', 'other', 'words,', 'multi-task', 'learning', 'is', 'derived', 'by', 'assuming', 'conditional', 'independence', 'of', 'output', 'token', 'types', 'for', 'Eq.', '(3),', 'as', 'follows:']",5,"[2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d924752c-106d-433e-928a-c21b4fe96a10,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,"['Statistical phrasedbased machine translation', 'A systematic comparison of various statistical alignement models']","['2003', '2003']","['P Koehn;F Och;D Marcu', 'F Och;H Ney']",group,"['The', 'goal', 'of', 'statistical', 'machine', 'translation', 'is', 'to', 'produce', 'a', 'target', 'sentence', 'e', 'from', 'a', 'source', 'sentence', 'f.', 'It', 'is', 'today', 'common', 'practice', 'to', 'use', 'phrases', 'as', 'translation', 'units', '<ref type=""group"">[4, 5]</ref>', 'and', 'a', 'log', 'linear', 'framework', 'in', 'order', 'to', 'introduce', 'several', 'models', 'explaining', 'the', 'translation', 'process:']",29,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
d92d23a4-a980-473e-b089-052ea437c200,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['Arabic named entity recognition: An svm-based approach'],['2008'],['Yassine Benajiba;Mona Diab;Paolo Rosso'],single,"['Early', 'work', 'on', 'the', 'detection', 'and', 'classification', 'of', 'Named', 'Entities', 'in', 'Arabic', 'NER', 'used', 'a', 'rule-based', 'or', 'grammar-based', 'approach', '<ref type=""group"">(Mesfar, 2007, Shaalan and Raza, 2007).</ref>', 'Subsequently,', 'the', 'field', 'shifted', 'generally', 'to', 'a', 'machine', 'learning', 'approach', '-thus', 'avoiding', 'the', 'time-consuming', 'and', 'expensive', 'maintenance', 'of', 'rule-sets.', 'Within', 'this', 'general', 'approach', 'a', 'wide', 'variety', 'of', 'techniques', 'have', 'all', 'been', 'applied', 'to', 'the', 'Arabic', 'NER', 'problem', 'including', 'Support', 'Vector', 'Machines', '(SVM)', '<ref type=""single"">(Benajiba et al., 2008b),</ref>', 'Conditional', 'Random', 'Fields', '(CRF)', '<ref type=""group"">(Abdul-Hamid and Darwish, 2010, Benajiba et al., 2008a, AbdelRahman et al., 2010),</ref>', 'Maximum', 'Entropy', '(ME)', '<ref type=""single"">(Benajiba et al., 2007),</ref>', 'Hidden', 'Markov', 'Models', '(HMM)', 'and', 'Decision', 'Trees', '<ref type=""single"">(Nadeau and Sekine, 2007).</ref>', 'Notably,', '<ref type=""single"">Benajiba et al. (2007)</ref>', 'developed', 'an', 'Arabic', 'NER', 'system,', 'ANERsys', '1.0,', 'which', 'employed', 'maximum', 'entropy', 'and', 'could', 'recognize', 'four', 'types', 'of', 'Named', 'Entities.']",62,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
d933e38e-3e62-4671-8792-708f83927afb,Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets,2021,George-Andrei Dima;Dumitru-Clementin Cercel;Mihai Dascalu,['Multitask learning'],['1997'],['Rich Caruana'],single,"['All', 'three', 'subtasks', 'are', 'addressed', 'simultaneously', 'using', 'a', 'Multi-Task', 'Learning', '(MTL)', 'architecture', '<ref type=""single"">(Caruana, 1997)</ref>', 'that', 'leverages', 'acquired', 'knowledge', 'from', 'one', 'subtask', 'to', 'another.', 'Furthermore,', 'we', 'approached', 'the', 'challenge', 'of', 'unbalanced', 'classes', 'in', 'the', 'first', 'subtask', 'by', 'considering', 'class', 'weights', 'and', 'by', 'augmenting', 'the', 'training', 'data', 'set.']",12,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
d9469df9-033b-4bd6-aaa5-677ef78c9517,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Hierarchical sparse variational autoencoder for text encoding'],['2020'],['Victor Prokhorov;Yingzhen Li;Ehsan Shareghi;Nigel Collier'],single,"['that', 'disentangled', 'representations', 'are', 'likely', 'to', 'be', 'easier', 'to', 'discriminate,', 'although', 'the', 'role', 'of', 'sparsely', 'learned', 'representations', 'could', 'contribute', 'to', ""MAT-VAE's"", 'success', 'as', 'well', '<ref type=""single"">(Prokhorov et al., 2020).</ref>']",24,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]"
d963ddf8-2591-4a7f-9c2f-9f83e44440b3,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,"['Free to play: Hate, harassment and positive social experiences in online games']",['2019'],['Adl unk'],single,"['As', 'the', 'popularity', 'of', 'multi-player', 'online', 'games', 'has', 'grown,', 'the', 'phenomenon', 'of', 'in-game', 'toxic', 'behavior', 'has', 'taken', 'root', 'within', 'them.', 'Toxic', 'behavior', 'is', 'strongly', 'present', 'in', 'recent', 'online', 'games', 'and', 'is', 'problematic', 'to', 'the', 'gaming', 'industry', '<ref type=""single"">(Adinolf and Turkay, 2018).</ref>', 'For', 'instance,', '74%', 'of', 'US', 'players', 'of', 'such', 'games', 'report', 'harassment', 'with', '65%', 'experiencing', 'severe', 'harassment.', '<ref type=""single"">(ADL, 2019).</ref>']",53,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
d96c1858-24e6-4bd2-8674-796121d73a46,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['For', 'the', 'experiments,', 'we', 'used', 'a', 'Transformer-base', 'model', '<ref type=""single"">(Vaswani et al., 2017)</ref>', 'with', 'the', 'default', 'configuration', 'in', 'Marian', 'NMT', '<ref type=""single"">(Junczys-Dowmunt et al., 2018).</ref>', 'The', 'steps', 'are', 'as', 'follows:']",8,"[2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0]"
da16dd57-31a8-4be1-b089-10279c3a9b67,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['Poise: Efficient cross-domain chinese named entity recognization via transfer learning'],['2020'],['Jiabao Sheng;Aishan Wumaier;Zhe Li'],single,"['More', 'recently', 'and', 'following', 'the', 'general', 'trend', 'towards', 'neural', 'approaches,', '<ref type=""single"">Gridach (2016)</ref>', 'developed', 'a', 'character', 'aware', 'neural', 'network', 'model', 'which', 'attempts', 'to', 'capture', 'contextual', 'characteristics', 'in', 'Arabic', 'by', 'placing', 'a', 'CRF', 'on', 'top', 'of', 'a', 'Bi-LSTM.', 'This', 'provided', 'a', 'hard', 'state-of-the-art', 'for', 'other', 'systems', 'to', 'beat', 'and', 'provides', 'the', 'foundation', 'of', 'our', 'own', 'approach.', 'Very', 'recently,', '<ref type=""single"">Ali et al. (2019)</ref>', 'applied', 'a', 'neural', 'network', 'model', 'with', 'a', 'multi-attention', 'layer', 'to', 'extract', 'Arabic', 'NEs.', 'They', 'used', 'two', 'attention', 'units,', 'the', 'embedding', 'attention', 'layer,', 'and', 'the', 'self-attention', 'unit.', 'They', 'achieved', 'an', 'F1', 'score', 'of', '91.31', 'to', 'achieve', 'a', 'new', 'stateof-the-art', 'on', 'a', 'large', 'dataset', 'proposed', 'for', 'evaluation', 'in', 'the', 'same', 'work.', 'At', 'the', 'same', 'time,', '<ref type=""single"">Khalifa and Shaalan (2019)</ref>', 'used', 'character', 'Convolutional', 'Neural', 'Networks', '(CNN)', 'as', 'a', 'replacement', 'for', 'characterlevel', 'bidirectional', 'Long', 'Short-Term', 'Memory', '(LSTM)', 'in', 'Arabic', 'NER.', 'Their', 'proposed', 'system', 'was', 'able', 'to', 'outperform', 'the', 'state-of-art', 'systems,', 'including', 'character-level', 'Bi-LSTM', 'on', 'various', 'standard', 'Arabic', 'NER', 'corpora.', '<ref type=""single"">Antoun et al. (2020)</ref>', 'proposed', 'AraBERTv0.1', 'which', 'involves', 'pretraining', 'the', 'BERT', 'transformer', 'model', 'for', 'the', 'Arabic', 'language.', 'They', 'compared', 'AraBERTv0.1', 'and', 'the', 'Bi-LSTM-CRF', 'model', 'on', 'ANERCorp,', 'the', 'former', 'achieved', '84.2', 'F1', 'scores', 'whereas', 'the', 'later', 'achieved', '81.7.', 'Most', 'recently,', '<ref type=""single"">Sheng et al. (2020)</ref>', 'proposed', 'a', 'transfer', 'learning', 'approach', 'for', 'Arabic', 'NER', 'with', 'Deep', 'Neural', 'Networks', 'where', 'they', 'showed', 'that', 'their', 'model', 'outperformed', 'significantly', 'the', 'Bi-LSTM-CRF', 'model.', 'We', 'have', 'not', 'considered', 'this', 'approach', 'here', 'because', 'our', 'aim', 'is', 'not', 'to', 'create', 'a', 'new', 'state', 'of', 'the', 'art', 'model', 'but', 'to', 'show', 'the', 'effectiveness', 'of', 'incorporating', 'language', 'specific', 'characteristics', 'in', 'the', 'form', 'of', 'embeddings.']",184,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
da577feb-fbb8-41ae-a798-6fd9ffaf46a7,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Shortcut learning in deep neural networks'],['2020'],['Robert Geirhos;Jörn-Henrik Jacobsen;Claudio Michaelis;Richard Zemel;Wieland Brendel;Matthias Bethge;Felix Wichmann'],single,"['Robustness', 'and', 'Bias', 'An', 'increasing', 'body', 'of', 'work', 'has', 'been', 'conducted', 'on', 'understanding', 'robustness', 'in', 'deep', 'neural', 'networks,', 'particularly,', 'how', 'models', 'sometimes', 'might', 'exploit', 'spurious', 'correlations', '<ref type=""group"">(Tu et al., 2020, Sagawa et al., 2020)</ref>', 'and', 'take', 'shortcuts', '<ref type=""single"">(Geirhos et al., 2020)</ref>', 'Figure', '2:', 'Our', 'proposed', 'pipeline', 'to', 'identify', 'spurious', 'correlations', 'at', 'scale.', 'In', 'the', 'first', 'step,', 'we', 'extract', 'important', 'tokens', 'from', 'input', 'text.', 'In', 'the', 'second', 'step,', 'we', 'analyze', 'extracted', 'tokens', 'from', 'various', 'datasets', 'to', 'identify', 'likely', '""spurious""', 'tokens.', 'Finally,', 'we', 'further', 'validate', 'the', 'output', 'from', 'the', 'second', 'step', 'through', 'knowledge-aware', 'perturbation.']",30,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
da5e9de2-d926-44ca-b819-5a4c10580559,drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM,2022,Dylan Phelps,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['For', 'predicting', 'the', 'similarity', 'scores,', 'a', 'separate', 'model', 'is', 'used', 'for', 'each', 'of', 'the', 'languages', 'BERT-Base', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'for', 'English,', 'BERTimbau', 'for', 'Portuguese,', 'and', 'Bertinho-Base', 'for', 'Galician.', 'The', 'created', 'BERTRAM', 'embeddings', 'for', 'each', 'of', 'the', 'idioms', 'found', 'within', 'the', 'task', 'are', 'added', 'into', 'the', 'embedding', 'matrix', 'of', 'the', 'relevant', 'model.', 'These', 'models', 'are', 'used', 'within', 'a', 'Sentence', 'BERT', '<ref type=""single"">(Reimers and Gurevych, 2019)</ref>', 'setup,', 'implemented', 'using', 'the', 'SentenceTransformers', 'library,', 'which', 'consists', 'of', 'a', 'siamese', 'network', 'structure', 'that', 'uses', 'mean', 'squared', 'error', 'over', 'the', 'cosine', 'similarities', 'of', 'the', 'input', 'sentences', 'as', ""it's"", 'loss', 'function.', 'This', 'allows', 'us', 'to', 'use', 'the', 'contextualised', 'embedding', 'outputs', 'of', 'our', 'BERT', 'networks', 'to', 'find', 'cosine', 'similarity', 'between', 'a', 'given', 'pair', 'of', 'sentences.']",16,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
daae2ef1-fcce-4e29-8a71-0c489604cffd,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['The', 'caption', 'generation', 'backbone', 'is', 'a', 'transformerbased', 'encoder-decoder', 'proposed', 'by', '<ref type=""single"">Vaswani et al. (2017),</ref>', 'which', 'mainly', 'employs', 'a', 'multi-head', 'attention', 'mechanism', 'and', 'achieves', 'top-tier', 'performance', 'in', 'many', 'sequential', 'related', 'tasks.', 'Here,', 'we', 'highlight', 'several', 'task-oriented', 'modifications.']",10,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]"
daf92ca4-3924-4ac2-919e-1cbcf8ab9bd7,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production'],['1983'],['Kimmo Koskenniemi'],single,"['The', 'last', 'problem', 'is', 'not', 'necessarily', 'linked', 'to', 'finite-state', 'approaches,', 'but', 'in', 'two-level', 'morphology,', 'cf.', '<ref type=""single"">Koskenniemi (1983),</ref>', '<ref type=""single"">Antworth (1990),</ref>', 'the', 'way', 'features', 'are', 'handled', 'is', 'specifically', 'geared', 'towards', 'inflection.', 'The', 'first', 'two', 'problems', 'are', 'inherent', 'in', 'finite-state', 'technology', 'and', 'can', 'only', 'be', 'handled', 'by', 'one', 'of', 'the', 'following', 'strategies:']",15,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
db0138ad-4de2-4e08-b6ef-9a0c1950290f,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Machine learning in the air'],['2019'],['Deniz Gündüz;Nicholas Paul De Kerret;David Sidiropoulos;Chandra Gesbert;Mihaela Murthy;unk Van Der Schaar'],single,"['In', 'fact,', 'deploying', 'ever-larger', 'models', 'raises', 'questions', 'and', 'concerns', 'about', 'the', 'increasing', 'magnitude', 'of', 'the', 'temporal,', 'financial,', 'and', 'environmental', 'cost', 'of', 'training', 'and', 'usability', '<ref type=""group"">(Strubell et al., 2019, Moosavi et al., 2020).</ref>', 'Typically,', 'due', 'to', 'their', 'resource', 'requirements,', 'these', 'models', 'are', 'trained', 'and', 'deployed', 'for', 'industrial', 'operations', 'on', 'remote', 'servers.', 'This', 'leads', 'to', 'a', 'high', 'use', 'of', 'over-the-air', 'communications,', 'which', 'are', 'particularly', 'resourceintensive', '<ref type=""single"">(Gündüz et al., 2019).</ref>', 'In', 'particular,', 'some', 'NLP', 'applications', '(speech', 'recognition,', 'speech', 'to', 'text,', 'etc.)', 'have', 'some', 'known', 'problems', 'related', 'to', 'network', 'latency,', 'transmission', 'path', 'difficulties,', 'or', 'privacy', 'concerns.', 'To', 'reduce', 'the', 'impact', 'of', 'these', 'communications,', 'there', 'is', 'a', 'solution', 'that', 'is', 'to', 'allow', 'these', 'models', 'to', 'run', 'directly', 'on', 'peripheral', 'or', 'mobile', 'devices,', 'that', 'is,', 'in', 'environments', 'with', 'limited', 'resources', 'that', 'require', 'lightweight,', 'responsive', 'models', 'and', 'energy', 'efficiency.', 'Reducing', 'the', 'size', 'of', 'the', 'models', 'is', 'therefore', 'one', 'of', 'the', 'increasingly', 'favoured', 'avenues,', 'especially', 'for', 'the', 'reduction', 'of', 'memory', 'resources', 'and', 'computation', 'time', 'involved', 'in', 'training', 'and', 'use.']",56,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
db55c12d-f54b-4cc8-bc2b-1bfa9539d782,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['Reading Wikipedia to answer opendomain questions'],['2017'],['Danqi Chen;Adam Fisch;Jason Weston;Antoine Bordes'],single,"['Specifically,', 'for', 'the', 'document', 'retrieval', 'step,', 'we', 'narrow', 'the', 'search', 'space', 'with', 'an', 'information', 'retrieval', 'model', 'DRQA', '<ref type=""single"">(Chen et al., 2017)</ref>', 'and', 'then', 'rerank', 'the', 'retrieved', 'pages.', 'For', 'the', 'evidence', 'retrieval', 'step,', 'we', 'design', 'a', 'multi-turn', 'cell', 'selector', 'to', 'extract', 'sentence', 'evidence', 'and', 'table', 'evidence', 'respectively,', 'and', 'select', 'evidence', 'cells', 'from', 'tables.', 'Finally,', 'we', 'propose', 'a', 'Dual', 'Channel', 'Unified', 'Format', 'verification', 'model', '(DCUF,', 'shown', 'in', 'Figure', '2)', 'for', 'the', 'verification', 'step.', 'DCUF', 'converts', 'evidence', 'to', 'a', 'unified', 'table/sentence', 'format', 'with', 'carefully-designed', 'evidence', 'conversion', 'and', 're-organization', 'methods', 'in', 'each', 'channel,', 'and', 'combine', 'dual-channel', 'encodings', 'to', 'make', 'the', 'final', 'prediction.']",17,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
db903d99-0333-41eb-8847-af58e210ef76,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,['Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks'],['2019'],['Jiasen Lu;Dhruv Batra;Devi Parikh;Stefan Lee'],single,"['The', 'existing', 'self-supervised', 'VLP', 'approaches', 'can', 'be', 'largely', 'categorized', 'into', 'two', 'groups:', 'the', 'twostep', 'pretraining', 'and', 'the', 'end-to-end', 'pretraining,', 'depending', 'on', 'whether', 'they', 'rely', 'on', 'visual', 'object', 'embeddings', 'as', 'input', 'for', 'the', 'Transformer.', 'Two-step', 'Pretraining', 'firstly', 'employ', 'an', 'off-theshelf', 'object', 'detector', 'to', 'convert', 'an', 'image', 'into', 'a', 'set', 'of', 'object', 'embeddings,', 'and', 'then', 'feed', 'them', 'into', 'a', 'Transformer', 'jointly', 'with', 'text', 'embeddings', 'to', 'generate', 'their', 'multi-modal', 'representations.', 'Hence', 'their', 'visual', 'feature', 'networks', 'are', 'not', 'optimized', 'during', 'both', 'pretraining', '&amp,', 'finetuning', 'stage.', 'Most', 'of', 'these', 'methods,', 'such', 'as', 'LXMERT', '<ref type=""single"">(Tan and Bansal, 2019)</ref>', ',ViLBert', '<ref type=""single"">(Lu et al., 2019),</ref>', 'VL-Bert', '<ref type=""single"">(Su et al., 2020),</ref>', 'Unicoder-VL', '<ref type=""single"">(Li et al., 2020a)</ref>', 'and', 'UNITER', '<ref type=""single"">(Chen et al., 2020),</ref>', 'adopt', 'BERT-like', 'objectives', 'to', 'train', 'their', 'networks,', 'which', 'include', 'Masked', 'Language', 'Modeling', '(MLM),', 'Masked', 'Vision', 'Modeling', '(MVM)', 'and', 'Image-Text', 'Matching', '(ITM).', 'In', 'addition,', 'VILLA', '<ref type=""single"">(Gan et al., 2020)</ref>', 'develops', 'an', 'advanced', 'adversarial', 'pretraining', 'and', 'finetuning', 'strategy', 'to', 'improve', 'generalization', 'ability.', 'OSCAR', '<ref type=""single"">(Li et al., 2020b)</ref>', 'and', 'VINVL', '<ref type=""single"">(Zhang et al., 2021)</ref>', 'introduce', 'object', 'labels', 'to', 'bridge', 'different', 'modalities', 'and', 'revisit', 'the', 'importance', 'of', 'visual', 'features.', 'Ernie-ViL', '<ref type=""single"">(Yu et al., 2020)</ref>', 'exploits', 'structured', 'knowledge', 'in', 'the', 'text', 'and', 'constructs', 'scene', 'graph', 'prediction', 'tasks', 'to', 'learn', 'joint', 'representations.', 'UNIMO', '<ref type=""single"">(Li et al., 2021)</ref>', 'proposes', 'a', 'unified', 'model', 'to', 'leverage', 'large-scale', 'free', 'text', 'corpus,', 'image', 'collections,', 'and', 'image-text', 'pairs', 'simultaneously', 'through', 'a', 'contrastive', 'learning', 'task.', 'Despite', 'their', 'strong', 'performances,', 'those', 'methods', 'are', 'limited', 'by', 'the', 'object', 'detector', 'and', 'neglect', 'visual', 'cues', 'outside', 'of', 'object', 'regions,', 'often', 'leading', 'to', 'mistakes', 'in', 'downstream', 'tasks.']",90,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
dc4c5f4f-581e-4686-871c-71197b8b9b69,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Practical unification-based parsing of natural language'],['1993'],['J Carroll'],single,"['A', 'probabilistic', 'LR', 'parser', 'was', 'trained', 'with', 'the', 'integrated', 'grammar', 'by', 'exploiting', 'the', 'Susanne', 'treebank', 'bracketing.', 'An', 'LR', 'parser', '<ref type=""single"">(Briscoe and Carroll, 1993)</ref>', 'was', 'applied', 'to', 'unlabelled', 'brack', 'eted', 'sentences', 'from', 'the', 'Susanne', 'treebank,', 'and', 'a', 'new', 'treebank', 'of', '1758', 'correct', 'and', 'complete', 'analyses', 'with', 'respect', 'to', 'the', 'integrated', 'grammar', 'was', 'constructed', 'semi-automatically', 'by', 'manu', 'ally•', 'resolving', 'the', 'remaining', 'ambiguities.', '250', 'sentences', 'from', 'the', 'new', 'treebank', 'were', 'kept', 'back', 'for', 'testing.', 'The', 'remainder,', 'together', 'with', 'a', 'further', 'set', 'of', 'analyses', 'from', '2285', 'tree', 'bank', 'sentences', 'that', 'were', 'not', 'checked', 'manually,', 'were', 'used', 'to', 'train', 'a', 'probabilistic', 'version', 'of', 'the', 'LR', 'parser,', 'using', 'Good-Turing', 'smoothing', 'to', 'estimate', 'the', 'probability', 'of', 'unseen', 'transitions', 'in', 'the', 'LALR(', '1)', 'table', '<ref type=""group"">(Briscoe and Carroll, 1993, Carroll, 1993).</ref>', 'The', 'probabilistic', 'parser', 'can', 'then', 'return', 'a', 'ranking', 'of', 'all', 'possible', 'analyses', 'for', 'a', 'sentence,', 'or', 'efficiently', 'return', 'just', 'the', 'n-most', 'probable', '<ref type=""single"">(Carroll, 1993).</ref>']",136,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
dc51c7f7-12a4-4851-a436-b0219281df69,The LIUM Arabic/English Statistical Machine Translation System for IWSLT 2008,2008,Holger Schwenk;Yannick Estève;Sadaf Rauf,['Moses: Open source toolkit for statistical machine translation'],['2007'],['Philipp Koehn;Hieu Hoang;Alexandra Birch;Chris Callison-Burch;Marcello Federico;Nicola Bertoldi;Brooke Cowan;Wade Shen;Christine Moran;Richard Zens;Chris Dyer;Ondrej Bojar;Alexandra Constantin;Evan Herbst'],single,"['This', 'paper', 'describes', 'the', 'system', 'developed', 'by', 'the', 'LIUM', 'laboratory', 'for', 'the', '2008', 'IWSLT', 'evaluation.', 'We', 'only', 'participated', 'in', 'the', 'Arabic/English', 'BTEC', 'task.', 'The', 'architecture', 'of', 'the', 'system', 'is', 'very', 'similar', 'to', 'a', 'large', 'system', 'built', 'for', 'the', 'NIST', 'Arabic/English', 'task', '<ref type=""single"">[1]</ref>', 'or', 'a', 'system', 'built', 'for', 'the', 'translation', 'between', 'French', 'and', 'English', '<ref type=""single"">[2].</ref>', 'All', 'three', 'are', 'statistical', 'phrase-based', 'machine', 'translation', 'systems', 'based', 'on', 'the', 'freely', 'available', 'Moses', 'decoder', '<ref type=""single"">[3],</ref>', 'with', 'extensions', 'for', 'rescoring', 'nbest', 'lists', 'with', 'a', 'continuous', 'space', 'language', 'model', 'in', 'a', 'second', 'pass.', 'No', 'system', 'combination', 'is', 'used.']",69,"[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0]"
dc597aad-0377-40f8-855d-34efc52a1fe8,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['English Verb Classes and Alternations'],['1993'],['B Levin'],single,"['Levin', 'verb', 'classes', 'are', 'based', 'on', 'the', 'ability', 'of', 'a', 'verb', 'to', 'occur', 'or', 'not', 'occur', 'in', 'pairs', 'of', 'syntactic', 'frames', 'that', 'are', 'in', 'some', 'sense', 'meaning', 'preserving,', 'hence', 'the', 'term', 'diathesis', 'alternations', '<ref type=""single"">[8].</ref>', 'The', 'distribution', 'of', 'syntactic', 'frames', 'a', 'verb', 'can', 'appear', 'in', 'determines', 'its', 'class', 'membership.', 'The', 'fundamental', 'assumption', 'is', 'that', 'the', 'syntactic', 'frames', 'are', 'a', 'direct', 'reflection', 'of', 'the', 'underlying', 'semantics.', 'Levin', 'classes', 'are', 'supposed', 'to', 'provide', 'very', 'specific', 'sets', 'of', 'syntactic', 'frames', 'that', 'are', 'associated', 'with', 'the', 'individual', 'classes.']",33,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
dd28c9a1-7c80-4f89-af04-4d619ebe1142,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['TnT -a statistical part-of-speech tagger'],['2000'],['Thorsten Brants'],single,"['Totale', 'toolkit', '<ref type=""single"">(Erjavec, 2006)</ref>', 'was', 'used', 'to', 'POS', 'tag', '<ref type=""single"">(Brants, 2000)</ref>', 'and', 'lemmatize', '<ref type=""single"">(Erjavec et al., 2004)</ref>', 'words', 'in', 'the', 'bilingual', 'word', 'list,', 'POS', 'tagger', 'was', 'also', 'used', 'in', 'automatic', 'paradigm', 'classifying,', 'see', 'chapter', '3.3.1', 'for', 'further', 'description.']",8,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
dd3e417c-7e23-4a42-b28d-3b28b7bfc5f2,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,"['unknown', 'unknown', 'Vqa: Visual question answering']","['2019', 'unknown', '2015']","['Ning Xie;Farley Lai;Derek Doran;Asim Kadav', 'unknown', 'Stanislaw Antol;Aishwarya Agrawal;Jiasen Lu;Margaret Mitchell;Dhruv Batra;Lawrence Zitnick;Devi Parikh']",group,"['With', 'the', 'success', 'of', 'BERT', '<ref type=""single"">(Devlin et al., 2018)</ref>', 'in', 'language', 'modeling,', 'self-supervised', 'Vision-and-Language', 'Pretraining', '(VLP)', 'has', 'attracted', 'much', 'interest', 'from', 'AI', 'community,', 'which', 'aims', 'to', 'learn', 'generalizable', 'multi-modal', 'representations', 'from', 'largescale', 'image-text', 'data.', 'Combined', 'with', 'a', 'pretrainthen-transfer', 'strategy,', 'it', 'shows', 'great', 'potential', 'in', 'tackling', 'vision', 'and', 'language', 'reasoning', 'tasks,', 'such', 'as', 'image-text', 'retrieval,', 'visual', 'question', 'answering', '(VQA)', 'and', 'visual', 'entailment', '<ref type=""group"">(Antol et al., 2015, Lee et al., 2018, Xie et al., 2019, Liu et al., 2021 Liu et al., , 2020)).</ref>', 'A', 'critical', 'step', 'in', 'such', 'representation', 'learning', 'is', 'to', 'jointly', 'model', 'linguistic', 'entities', 'and', 'visual', 'semantic', 'concepts', '(e.g.,', 'attributes,', 'objects,', 'and', 'relations),', 'as', 'well', 'as', 'their', 'alignment.', 'However,', 'this', 'is', 'particularly', 'challenging', 'due', 'to', 'large', 'discrepancy', 'in', 'visual', 'and', 'language', 'representations', '(pixels', 'vs', 'words)', 'and', 'lack', 'of', 'entity-level', 'cross-modal', 'correspondence', 'in', 'supervision.']",58,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
dd4ef0be-16ed-449e-b488-468f67d747a9,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,"['SQuAD: 100,000+ questions for machine comprehension of text']",['2016'],['Pranav Rajpurkar;Jian Zhang;Konstantin Lopyrev;Percy Liang'],single,"['SQuAD', '(v1.1)', '<ref type=""single"">(Rajpurkar et al., 2016)</ref>']",2,"[1, 1, 1]"
ddc10399-1e68-4ac9-b0f3-ecaa56a4a04a,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing'],['2018'],['Taku Kudo;John Richardson'],single,"['To', 'take', 'advantage', 'of', 'the', 'potential', 'lexical', 'sharing', 'of', 'the', 'languages', '(e.g.', 'loanwords)', 'and', 'address', 'the', 'polysynthetic', 'nature', 'of', 'the', 'indigenous', 'languages,', 'we', 'trained', 'a', 'unique', 'multilingual', 'segmentation', 'model', 'by', 'sampling', 'all', 'languages', 'with', 'a', 'uniform', 'distribution.', 'We', 'used', 'the', 'unigram', 'model', 'implementation', 'in', 'SentencePiece', '<ref type=""single"">(Kudo and Richardson, 2018)</ref>', 'with', 'a', 'vocabulary', 'size', 'of', '32,000.']",45,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
de0b30e0-f0c6-4c52-bb86-3848564257e9,Dual-Channel Evidence Fusion for Fact Verification over Texts and Tables,2022,Nan Hu;Zirui Wu;Yuxuan Lai;Xiao Liu;Yansong Feng,['TaPas: Weakly supervised table parsing via pre-training'],['2020'],['Jonathan Herzig;Krzysztof Nowak;Thomas Müller;Francesco Piccinno;Julian Eisenschlos'],single,"['We', 'get', 'a', 'global', 'evidence', 'table', 'by', 'stacking', 'the', 'm', 'tables', 'from', 'sentences', 'and', 'n', 'tables', 'from', 'tabular', 'evidence,', 'as', 'illustrated', 'in', 'Figure', '3.', 'Then,', 'we', 'feed', 'the', 'claim', 'and', 'the', 'global', 'evidence', 'table', 'to', 'a', 'pretrained', 'table', 'model,', 'TAPAS', '<ref type=""single"">(Herzig et al., 2020),</ref>', 'and', 'get', 'the', 'tabular', 'format', 'evidence', 'representation.']",40,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]"
de17a61d-3b0b-428e-9573-9e1c1e1c5f34,DRS Parsing as Sequence Labeling,2022,Minxing Shen;Kilian Evang,['Viable dependency parsing as sequence labeling'],['2019'],['Michalina Strzyz;David Vilares;Carlos Gómez-Rodríguez'],single,"['2', 'Encoding', 'Anchored', 'DRSs', 'as', 'Sequences', '<ref type=""single"">Gómez-Rodríguez and Vilares (2018),</ref>', '<ref type=""single"">Strzyz et al. (2019),</ref>', '<ref type=""single"">Vilares et al. (2020)</ref>', 'encode', 'syntax', 'trees', 'as', 'token', 'labels', 'to', 'cast', 'syntactic', 'parsing', 'as', 'a', 'sequence', 'labeling', 'task.', 'We', 'apply', 'a', 'similar', 'method', 'to', 'DRS', 'parsing.', 'We', 'will', 'use', 'a', 'simplified', 'example', 'from', 'the', 'Parallel', 'Meaning', 'Bank', '(PMB,', '<ref type=""single"">Abzianidze et al., 2017)</ref>', 'for', 'exposition.']",7,"[0, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
de9d6dfc-c29d-4951-8cb8-85d3731fbfc2,CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection,2021,Henry Weld;Guanghao Huang;Jean Lee;Tongshu Zhang;Kunze Wang;Xinghong Guo;Siqu Long;Josiah Soyeon;Caren Han,['Toxicity detection in multiplayer online games'],['2015'],['Marcus Märtens;Siqi Shen;Alexandru Iosup;Fernando Kuipers'],single,"['For', 'our', 'automated', 'slot', 'labelling,', 'we', 'generated', 'the', 'game', 'toxicity', 'lexicon', 'by', 'taking', 'the', 'supplemental', 'materials', 'released', 'by', '<ref type=""single"">Märtens et al. (2015)</ref>', 'and', '<ref type=""single"">ElSherief et al. (2018)</ref>', 'and', 'the', 'list', 'of', 'words', 'banned', 'by', 'Google', '6.', 'We', 'then', 'added', 'variants', 'or', 'new', 'toxic', 'words', 'found', 'in', 'the', 'utterances', 'extracted', 'from', 'Kaggle.', 'For', 'intent', 'labelling,', 'all', 'volunteer', 'annotators', 'were', 'recruited', 'from', 'academia', 'and', 'research', 'students.', 'They', 'were', 'informed', 'about', 'toxic', 'behavior', 'in', 'online', 'games', 'before', 'handling', 'the', 'data.', 'Our', 'instructions', 'allowed', 'them', 'to', 'feel', 'free', 'to', 'leave', 'if', 'they', 'were', 'uncomfortable', 'with', 'the', 'content.', 'Due', 'to', 'privacy', 'considerations,', 'we', 'group', 'them', 'by', 'online', 'game', 'experiences', 'and', 'do', 'not', 'take', 'into', 'account', ""annotators'"", 'demographic', 'information.']",18,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
deddf69d-1f88-4cc4-9c39-c4e821f6891d,Themes in the work of Margaret Masterman,1988,Yorick Wilks,"['Historical background, principles and methods of intuitionism']",['1952'],['L Brouwer'],single,"['The', 'two', 'structures', 'from', 'which', 'she', 'hoped', 'the', 'most', 'were', 'lattices', 'and', ""'fans',"", 'a', 'notion', 'she', 'derived', 'from', 'some', 'work', 'of', '<ref type=""single"">Brouwer (1952).</ref>', 'MMB', 'believed', 'lattices', '<ref type=""single"">(Masterman, 1959a)</ref>', 'to', 'be', 'the', 'underlying', 'structure', 'of', 'thesauri', 'while', 'fans', '<ref type=""single"">(Masterman, 1957a)</ref>', 'mapped', 'the', 'spreading', 'out', 'of', 'the', 'new', 'senses', 'of', 'words,', 'indefinitely', 'into', 'the', 'future.', 'She', 'spent', 'some', 'time', 'trying', 'to', 'amalgamate', 'both', 'representations', 'into', 'a', 'single', 'structure.', 'These', 'efforts', 'have', 'not', 'met', 'with', 'much', 'success', 'nor', 'have', 'they', 'been', 'taken', 'up', 'by', 'others,', 'although', 'Zellig', 'Harris', 'did', 'at', 'one', 'time', 'toy', 'with', 'lattices', 'as', 'language', 'structures,', 'and', '<ref type=""single"">Mellish has recently (1988)</ref>', 'sought', 'to', 'link', 'lattice', 'structures', 'again', 'to', ""Halliday's"", 'categories', 'of', 'grammar', 'and', 'semantics.']",21,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
df0059af-5216-4ac1-bf44-31a066bee86d,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['unknown'],['unknown'],['unknown'],group,"['We', 'used', ""Plutchik's"", 'core', 'emotions', 'as', 'our', 'annotation', 'scheme', 'resulting', 'in', '8', 'distinct', 'emotion', 'categories', 'plus', 'neutral.', 'The', 'Sentimentator', 'platform', '<ref type=""group"">( Öhman and Kajava, 2018, Öhman et al., 2018)</ref>', 'allows', 'for', 'the', 'annotation', 'of', 'intensities', 'resulting', 'in', 'what', 'is', 'essentially', '30', 'emotions', 'and', 'sentiments,', 'however,', 'as', 'the', 'intensity', 'score', 'is', 'not', 'available', 'for', 'all', 'annotations,', 'the', 'intensity', 'scores', 'were', 'discarded.', 'The', 'granularity', 'of', 'our', 'annotations', 'roughly', 'correspond', 'to', 'sentence-level', 'annotations,', 'although', 'as', 'our', 'source', 'data', 'is', 'movie', 'subtitles,', 'our', 'shortest', 'subtitle', 'is!', 'and', 'the', 'longest', 'subtitle', 'consists', 'of', 'three', 'separate', 'sentences.', 'A', 'majority', 'of', 'the', 'subtitles', 'for', 'English', 'were', 'assigned', 'one', 'emotion', 'label', '(78%),', '17%', 'were', 'assigned', 'two,', 'and', 'roughly', '5%', 'had', 'three', 'or', 'more', 'categories', '(see', 'also', 'Table', '3).']",20,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
df13d196-e144-4523-9dc6-fe102bc04ada,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,"['Assessing the representations of idiomaticity in vector models with a noun compound dataset labeled at type and token levels', 'The PARSEME shared task on automatic identification of verbal multiword expressions', 'Evaluating language models for the retrieval and categorization of lexical collocations', 'Clustering of Russian adjective-noun constructions using word embeddings']","['2021', '2017', '2021', '2017']","['Marcos Garcia;Tiago Vieira;Carolina Scarton;Marco Idiart;Aline Villavicencio', 'Agata Savary;Carlos Ramisch;Silvio Cordeiro;Federico Sangati;Veronika Vincze;Behrang Qasem-Izadeh;Marie Candito;Fabienne Cap;Voula Giouli;Ivelina Stoyanova;Antoine Doucet', 'Luis Espinosa Anke;Joan Codina-Filba;Leo Wanner', 'Andrey Kutuzov;Elizaveta Kuzmenko;Lidia Pivovarova']",group,"['A', 'related', 'literature', 'in', 'corpus', 'linguistics', 'and', 'NLP', 'has', 'explored', 'the', 'nature', 'of', 'restricted', 'binary', 'word', 'co-occurrences,', 'called', 'collocations', '(for', 'recent', 'examples,', 'see', '<ref type=""group"">Savary et al., 2017, Kutuzov et al., 2017, Garcia et al., 2021, Espinosa Anke et al., 2021).</ref>', 'This', 'work', 'focuses', 'narrowly', 'on', 'the', 'estimation', 'of', 'bilexical', 'conditional', 'probabilities,', 'which', 'are', 'often', 'inputs', 'to', 'models', 'for', 'collocation', 'detection.']",23,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
df2bbd85-0f68-4bd7-b10a-e37f2a319469,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['The alice datasets: fMRI & EEG observations of natural language comprehension'],['2020'],['Shohini Bhattasali;Jonathan Brennan;Wen-Ming Luh;Berta Franzluebbers;John Hale'],single,"['Data', 'set.', 'The', 'stimulus', 'set', 'includes', '4,479', 'sentences', '(74,953', 'tokens)', 'selected', 'from', 'the', 'English', 'Web', 'Treebank', '<ref type=""single"">(Bies et al., 2012),</ref>', 'covering', 'the', 'genres', 'weblogs,', 'newsgroups,', 'reviews', 'and', 'Yahoo', 'Answers.', 'The', 'mean', 'sentence', 'length', 'is', '16.7', 'words', '(standard', 'deviation:', '12.23).', '75', 'sessions', 'of', 'EEG', 'data', 'are', 'included', 'over', '20', 'days,', 'each', 'lasting', '20-25', 'minutes,', 'from', 'a', 'single', 'subject', 'who', 'read', 'approximately', 'five', 'and', 'a', 'half', 'iterations', 'of', 'the', 'stimulus', 'set', '(i.e.', '24,323', 'sentences', 'and', '404,205', 'tokens', 'in', 'total,', 'thereby', 'substantially', 'exceeding', 'current', 'freely', 'accessible', 'data', 'sets,', 'e.g.', '<ref type=""single"">(Bhattasali et al., 2020).</ref>', 'Three', 'sessions', 'were', 'excluded', 'because', 'of', 'data', 'corruption.']",83,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]"
df3d43b3-8e7e-49ee-b2ab-12e26f0f270b,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Machine translation and monolingual postediting: The AFRL WMT-14 system'],['2014'],['L Schwartz;T Anderson;J Gwinnup;K Young'],single,"['For', 'each', 'segment,', 'the', 'human', 'rater', 'was', 'presented', 'with', 'a', 'vertically-arranged', 'list', 'showing', 'all', 'variants', 'of', 'that', 'segment.', 'The', 'first', 'entry', 'in', 'each', 'list', 'was', 'the', 'segment', 'in', 'the', 'source', 'language', '(Russian).', 'The', 'source', 'segment', 'was', 'followed', 'by', 'the', 'reference', 'translation', 'in', 'English.', 'The', 'subsequent', 'eight', 'entries', 'were', 'English', 'translations', 'of', 'the', 'source', 'segment,', 'presented', 'in', 'a', 'randomized', 'order.', 'The', 'English', 'translations', 'included', 'the', 'unedited', 'machine', 'translation', 'output,', 'as', 'produced', 'by', 'Moses,', 'a', 'post-edited', 'translation', 'produced', 'by', 'a', 'monolingual', 'post-editor', 'from', '<ref type=""single"">Schwartz et al. (2014),</ref>', 'and', 'the', 'six', 'post-edited', 'translations', 'produced', 'by', 'the', 'Russian-English', 'bilingual', 'posteditors', 'in', 'this', 'study.']",81,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
df63b3d2-68c7-4a74-918a-5dfb787100d8,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['unknown'],['unknown'],['unknown'],group,"['Note', 'that', 'the', 'difference', 'between', 'total', 'annotations', 'excluding', 'neutral', '(24,164)', 'and', 'the', 'combined', 'number', 'of', 'annotations', '<ref type=""group"">(22, 424)</ref>', 'differ', 'because', 'once', 'the', 'dataset', 'was', 'saved', 'as', 'a', 'Python', 'dictionary,', 'identical', 'lines', 'were', 'merged', 'as', 'one', '(i.e.', 'some', 'common', 'movie', 'lines', 'like', '""All', 'right', 'then!""', 'and', '""I', 'love', 'you""', 'appeared', 'multiple', 'times', 'from', 'different', 'sources).', 'Additionally,', 'lines', 'annotated', 'as', 'both', 'neutral', 'and', 'an', 'emotion', 'were', 'removed', 'from', 'the', 'neutral', 'set.']",16,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
df77517d-588a-4c0b-8532-8ddd14712d0e,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['unknown'],['2020'],['Tianyi Zhang;Varsha Kishore;Felix Wu;Kilian Weinberger;Yoav Artzi'],single,"['In', 'this', 'paper,', 'our', 'metric', 'of', 'interest', 'is', 'BERTScore', '<ref type=""single"">(Zhang et al., 2020).</ref>', 'To', 'compute', 'BERTScore,', 'we', 'first', 'feed', 'a', 'reference', 'and', 'candidate', 'translation', 'for', 'a', 'given', 'sentence', 'into', 'BERT,', 'and', 'retrieve', 'their', 'token', 'level', 'vector', 'representations.', 'Let', 'z', 'be', 'the', 'representations', 'of', 'the', 'reference', 'and', 'ẑ', 'those', 'of', 'the', 'candidate.', 'Then', 'we', 'compute', 'the', 'precision', 'and', 'recall', 'metrics', 'for', 'BERTScore', 'by', 'comparing', 'each', 'token', 'representation', 'z', 'i', 'of', 'the', 'reference', 'translation', 'to', 'each', 'token', 'representation', 'ẑj', 'of', 'the', 'candidate', 'translation', 'as', 'follows:P', 'BERT', '=', '1', '|ẑ|', 'ẑj', '∈ẑ', 'max', 'z', 'i', '∈z', 'z', 'i', 'ẑj', 'R', 'BERT', '=', '1', '|z|', 'z', 'i', '∈z', 'max', 'ẑj', '∈ẑ', 'z', 'i', 'ẑjThe', 'F', '1', 'score', 'can', 'be', 'defined', 'as', 'usual.', 'As', 'BERTScore', 'can', 'range', 'from', '-1', 'to', '1,', 'but', 'most', 'often', 'inhabits', 'the', 'upper', 'end', 'of', 'that', 'range,', 'its', 'creators', 'suggest', 'the', 'use', 'of', 'baseline', 'scaling,', 'which', 'generally', 'leaves', 'BERTScore', 'in', 'the', 'range', '[0,1],', 'as', 'desired', 'for', 'use', 'with', 'our', 'prior', 'formalization.', 'Baseline', 'rescaling', 'is', 'performed', 'for', 'P', 'BERT', 'asPBERT', '=', 'P', 'BERT', '−', 'a', '1', '−', 'aand', 'likewise', 'for', 'R', 'BERT,', 'a', 'is', 'an', 'empirical', 'lower', 'bound', 'on', 'observed', 'BERTScore.']",9,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
dfa13521-56fc-4ad0-8034-1d86d63485ea,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Layer normalization. ArXiv'],['2016'],['Jimmy Ba;J Kiros;Geoffrey Hinton'],single,"['Attention-guided', 'Grounding', 'A', 'cross-attention', 'matrix', 'is', 'generated', 'in', 'shape', '(N,', 'T,', 'L,', 'H)', 'during', 'the', ""transformer's"", 'decoding', 'steps.', 'Here', 'N', 'denotes', 'the', 'number', 'of', 'pre-detected', 'visual', 'objects,', 'T', 'denotes', 'the', 'number', 'of', 'tokens', 'in', 'a', 'caption', 'sentence', 'after', 'padding,', 'L', 'denotes', 'the', 'number', 'of', 'transformer', 'layers,', 'and', 'H', 'denotes', 'the', 'number', 'of', 'attention', 'heads', 'in', 'transformer', 'layers.', 'Two', 'linear', 'projections', 'and', 'layer', 'normalization', '<ref type=""single"">(Ba et al., 2016)</ref>', 'are', 'applied', 'sequentially', 'on', 'dimension', 'L', 'and', 'H,', 'respectively', 'reducing', 'the', 'dimension', 'to', '1.', 'Thus,', 'for', 'a', 'single', 'instance,', 'we', 'eventually', 'calculate', 'an', 'attention', 'matrix', 'A', '∈', 'R', 'N', '×T.']",63,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
dfbea9cb-9309-4521-ae76-602a88b6b00f,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Word Manager and Banking Terminology: Industrial Application of a General System'],['2000'],['Daniela Zappatore;Pius Hacken'],single,"['Another', 'domain', 'in', 'which', 'WM', 'databases', 'have', 'been', 'used', 'is', 'terminology.', 'In', 'collaboration', 'with', 'the', 'UBS', 'bank,', 'a', 'module', 'was', 'developed', 'which', 'recognizes', 'banking', 'terminology', 'in', 'unseen', 'text', 'and', 'provides', 'an', 'on-line', 'link', 'to', 'the', 'relevant', 'entry', 'in', 'a', 'terminological', 'database,', 'cf.', '<ref type=""single"">Zappatore &amp, ten Hacken (2000).</ref>', 'Here', 'the', 'WFRules', 'are', 'used', 'not', 'only', 'as', 'a', 'structuring', 'device', 'of', 'the', 'terminological', 'lexicon,', 'but', 'also', 'as', 'a', 'way', 'for', 'recognizing', 'terms', 'when', 'they', 'are', ""'hidden'"", 'in', 'nominalizations,', 'compounds,', 'etc.', 'Thus,', 'Verwaltungsrat', ""('board"", 'of', ""directors')"", 'is', 'also', 'recognized', 'in', 'Verwaltungsratsvakanz', ""('vacancy"", 'in', 'the', 'board', 'of', ""directors')."", 'One', 'of', 'the', 'reasons', 'why', 'WM', 'is', 'particularly', 'suited', 'to', 'this', 'task', 'in', 'a', 'multilingual', 'system', '(German,', 'English,', 'Italian)', 'is', 'that', 'it', 'can', 'treat', 'singleword', 'and', 'multi-word', 'terms', 'equally.']",42,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
dfec6a62-320c-4664-9868-79b9cd78310c,Translation of Multiword Expressions Using Parallel Suffix Arrays,2006,Paul Mcnamee;James Mayfield,['unknown'],['1997'],['D Gusfield'],single,"['In', 'future', 'work', 'we', 'hope', 'to', 'study', 'the', 'effect', 'of', 'corpus', 'size', 'and', 'corpus', 'diversity', 'on', 'translation', 'effectiveness.', 'We', 'also', 'hope', 'to', 'focus', 'on', 'evaluation', 'of', 'longer', 'MWEs', '(i.e.,', 'trigrams', 'and', 'longer)', 'as', 'well', 'as', 'consider', 'the', 'possibility', 'that', 'efficient', 'suffix-based', 'wildcard', 'searches', '<ref type=""single"">(Gusfield, 1997)</ref>', 'may', 'enable', 'correct', 'translation', 'of', 'non-contiguous', 'phrases.']",43,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]"
dff516a6-7520-496d-94f1-7e36f29ab7d1,Themes in the work of Margaret Masterman,1988,Yorick Wilks,"['Agricola in curvo terram dimovit aratro. Cambridge Language Research Unit, Memorandum ML 84', 'unknown']","['1957', 'unknown']","['M Masterman', 'unknown']",group,"['MMB', 'must', 'be', 'credited', 'with', 'helping', 'to', 'keep', 'belief', 'in', 'MT', 'alive', 'during', 'long', 'years', 'of', 'public', 'scepticism,', 'and', 'above', 'all', 'with', 'the', 'belief', 'that', 'MT', 'was', 'an', 'intellectually', 'challenging', 'and', 'interesting', 'task', '<ref type=""group"">(Masterman, 1957b (Masterman, , 1961)).</ref>', 'I', 'think', 'that', 'is', 'now', 'widely', 'granted,', 'although', 'it', 'was', 'not', 'conceded', 'within', 'artificial', 'intelligence,', 'for', 'example,', 'until', 'relatively', 'recently.', 'There', 'it', 'was', 'generally', 'thought', 'that,', 'although', 'language', 'understanding', 'in', 'general', 'required', 'inference', 'knowledge', 'of', 'the', 'world', 'and', 'processing', 'of', 'almost', 'arbitrary', 'complexity,', 'MT', 'did', 'not:', 'it', 'was', 'a', 'task', 'that', 'required', 'only', 'superficial', 'processing', 'of', 'language.', 'I', 'think', 'that', 'now', 'almost', 'everyone', 'concedes', 'that', 'that', 'view', 'is', 'false.']",33,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
dffa2cdb-afa0-4f74-a43d-313fb82177be,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Various', 'studies', 'attempted', 'to', 'generate', 'multiple', 'different', 'definitions', 'for', 'polysemous', 'words.', '<ref type=""single"">Gadetsky et al. (2018)</ref>', 'tackled', 'this', 'problem', 'by', 'computing', 'the', 'AdaGram', 'vectors', '<ref type=""single"">(Bartunov et al., 2016)</ref>', 'of', 'input', 'words,', 'which', 'are', 'capable', 'of', 'learning', 'different', 'representations', 'at', 'desired', 'semantic', 'resolutions.', 'However,', 'generating', 'different', 'definitions', 'based', 'on', 'contexts,', 'i.e.,', 'example', 'sentences,', 'became', 'the', 'mainstream', 'method', '<ref type=""group"">(Chang et al., 2018, Reid et al., 2020, Li et al., 2020, Bevilacqua et al., 2020</ref>', ').', 'Among', 'them,', 'some', 'studies', 'used', 'pre-trained', 'language', 'models', 'to', 'obtain', 'contextualized', 'embeddings.', '<ref type=""single"">Reid et al. (2020)</ref>', 'initialized', 'encoders', 'with', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'and', 'employed', 'variational', 'inference', 'for', 'estimation', 'and', 'leveraged', 'contextualized', 'word', 'embeddings', 'for', 'improved', 'performance.', '<ref type=""single"">Bevilacqua et al. (2020)</ref>', 'employed', 'a', 'novel', 'spanbased', 'encoding', 'scheme', 'to', 'fine-tune', 'a', 'pre-trained', 'English', 'encoder-decoder', 'system', 'to', 'generate', 'definitions.', '<ref type=""single"">Huang et al. (2021)</ref>', 'leveraged', 'the', 'T5', '<ref type=""single"">(Raffel et al., 2019)</ref>', 'model', 'for', 'this', 'task', 'and', 'introduced', 'a', 're-ranking', 'mechanism', 'to', 'model', 'specificity', 'in', 'definitions.']",68,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e00d6fbe-5de1-4217-9aba-4ea52a7705b0,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,"['unknown', 'BERT is Not a Knowledge Base (Yet): Factual Knowledge vs. Name-Based Reasoning in Unsupervised QA']","['unknown', '2019']","['unknown', 'Nina Poerner;Ulli Waltinger;Hinrich Schütze']",group,"['In', 'typical', 'neural', 'NLP', 'systems,', 'entities', 'are', 'embedded', 'in', 'the', 'same', 'space', 'as', 'other', 'words', 'either', 'in', 'context-independent', '<ref type=""group"">(Mikolov et al., 2013, Pennington et al., 2014)</ref>', 'or', 'in', 'context-dependent', 'ways', '<ref type=""group"">(Peters et al., 2018, Devlin et al., 2019).</ref>', 'Such', 'approaches', 'are', 'powerful:', 'pre-trained', 'language', 'models', 'implicitly', 'learn', 'factual', 'knowledge', 'about', 'those', 'entities', '<ref type=""group"">(Petroni et al., 2019, Roberts et al., 2020, Jiang et al., 2020)</ref>', 'and', 'these', 'representations', 'can', 'be', 'grounded', 'in', 'structured', 'and', 'human-curated', 'knowledge', 'bases', '<ref type=""group"">(Logan et al., 2019, Levine et al., 2019, Peters et al., 2019, Zhang et al., 2019, Poerner et al., 2019, Xiong et al., 2020, Wang et al., 2020).</ref>', 'However,', 'these', 'embeddings', 'do', 'not', 'explicitly', 'maintain', 'representations', 'of', 'this', 'knowledge,', 'and', 'dense', 'entity', 'representations', 'are', 'not', 'directly', 'interpretable.', 'Knowledge', 'probing', 'tasks', 'can', 'be', 'used', 'to', 'measure', ""LMs'"", 'factual', 'knowledge', '<ref type=""single"">(Petroni et al., 2019),</ref>', 'but', 'designing', 'the', 'right', 'probing', 'task', 'is', 'another', 'hard', 'problem', '<ref type=""group"">(Chen et al., 2019, Poerner et al., 2019),</ref>', 'particularly', 'if', 'the', 'probes', 'are', 'parameter-rich', '<ref type=""single"">(Hewitt and Manning, 2019).</ref>']",93,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3]"
e01792f6-ebd7-4bbc-b175-f490fac9aac8,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,"['Evidence That Gendered Wording in Job Advertisements Exists and Sustains Gender Inequality', 'Connotation frames of power and agency in modern films', 'unknown', 'A Linguistic Comparison of Letters of Recommendation for Male and Female Chemistry and Biochemistry Job Applicants']","['2011', '2017', '2021', '2007']","['Danielle Gaucher;Justin Friesen;Aaron Kay', 'Maarten Sap;Marcella Prasettio;Ari Holtzman;Hannah Rashkin;Yejin Choi', 'Karolina Stanczak;Isabelle Augenstein', 'Toni Schmader;Jessica Whitehead;Vicki Wysocki']",group,"['We', 'define', 'text-level', 'bias', 'as', 'the', 'frequency', 'of', 'certain', 'words', 'which', 'are', 'recognised', 'as', 'favouring', 'one', 'gender', 'over', 'another.', 'The', 'problem', 'is', 'then', 'in', 'defining', 'this', 'list', 'of', 'words.', 'To', 'avoid', 'overfitting', 'to', 'one', 'axis', 'of', 'gender', 'bias,', 'we', 'construct', 'a', 'composite', 'score', 'based', 'on', 'pre-existing', 'lists', 'which', 'have', 'in', 'turn', 'been', 'defined', 'through', 'experiments', 'and', 'empirical', 'assessments', '<ref type=""group"">(Schmader et al., 2007, Gaucher et al., 2011, Sap et al., 2017, Stanczak and Augenstein, 2021).</ref>', 'The', 'presence', 'of', 'words', 'which', 'are', 'more', 'likely', 'to', 'be', 'associated', 'with', 'one', 'gender', 'does', 'not', 'directly', 'result', 'in', 'biased', 'outcomes.', 'Bias', 'may', 'be', 'more', 'accurately', 'measured', 'as', 'the', 'relative', 'gender', 'distribution', 'of', 'applicants', 'who', 'apply', 'to', 'a', 'given', 'ad.', 'In', 'this', 'work,', 'we', 'focus', 'on', 'gendered', 'word', 'lists', 'as', 'one', 'overt', 'presentation', 'of', 'gender', 'bias', 'but', 'encourage', 'further', 'research', 'to', 'empirically', 'measure', 'allocational', 'harm,', 'so', 'long', 'as', 'any', 'experiments', 'consider', 'the', 'ethical', 'issues', 'of', 'posting', '""fake""', 'ads', 'online.']",58,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e0744dd2-c1b8-4560-ae83-e959a86a8837,USST's System for AutoSimTrans 2022,2022,Jiahui Zhu;Jun Yu,"['Intelligent selection of language model training data', ""Facebook fair's wmt19 news translation task submission""]","['2010', '2019']","['C Robert;William Moore;unk Lewis', 'Nathan Ng;Kyra Yee;Alexei Baevski;Myle Ott;Michael Auli;Sergey Edunov']",group,"['During', 'the', 'fine-tuning', 'phase,', 'we', 'first', 'apply', 'finetuning', 'on', 'a', 'small', 'spoken', 'corpus.', 'For', 'better', 'domain', 'adaptation,', 'we', 'adopt', 'mixed', 'fine-tuning', '<ref type=""single"">(Chu et al., 2017),</ref>', 'which', 'trains', 'on', 'a', 'mixed', 'dataset', 'that', 'includes', 'a', 'subsampled', 'general', 'corpus', 'and', 'an', 'upsampled', 'spoken', 'corpus.', 'Thirdly,', 'we', 'propose', 'a', 'method', 'called', '""in-domain', 'mixed', 'fine-tuning"",', 'which', 'further', 'improve', 'the', 'BLEU', 'score', 'than', 'mixed', 'finetuning.', 'Specifically,', 'inspired', 'by', 'in-domain', 'data', 'filtering', '<ref type=""group"">(Moore and Lewis, 2010, Ng et al., 2019),</ref>', 'we', 'mixed', 'upsampled', 'spoken', 'data', 'with', 'selected', 'in-domain', 'data', 'from', 'general', 'corpus', 'rather', 'than', 'random', 'subsampled.']",63,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
e0804fb0-436f-4200-8f89-a88f21e17ee1,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,"['Decoding word and category-specific spatiotemporal representations from meg and eeg', 'Back-to-back regression: Disentangling the influence of correlated factors from multivariate observations', 'How are visual words represented? insights from eeg-based visual word decoding, feature derivation and image reconstruction']","['2011', '2020', '2019']","['Alexander Chan;Eric Halgren;Ksenija Marinkovic;Sydney Cash', 'Jean-Rémi King;François Charton;David Lopez-Paz;Maxime Oquab', 'Shouyu Ling;Andy Lee;Blair Armstrong;Adrian Nestor']",group,"['Electro-/Magnetoencephalography', '(EEG/MEG),', 'which', 'measures', 'neural', 'activity', 'at', 'millisecond', 'resolution,', 'is', 'a', 'key', 'neuroscientific', 'method', 'to', 'assess', 'how', 'neural', 'representations', 'unfold', 'dynamically', 'in', 'language', 'processing.', 'Early', 'event', 'related', 'potential', '(ERP)', 'studies', 'that', 'rely', 'on', 'averaging', 'EEG', 'activity', 'across', 'multiple', 'trials', 'have', 'shown', 'that', 'EEG', 'signal', 'magnitude', 'and', 'topography', 'depend', 'on', 'word', 'length,', 'frequency', 'and', 'open', 'vs.', 'closed', 'class.', 'Word', 'length', 'effects', 'arose', 'in', 'EEG', 'at', 'about', '150', 'ms,', 'frequency', 'effects', 'at', '200', 'ms', 'and', 'word', 'class', 'effects', 'from', '400-700', 'ms', '<ref type=""group"">(Osterhout et al., 1997, Brown et al., 1999, Neville et al., 1992, Münte et al., 1998, Segalowitz and Lane, 2000, Münte et al., 2001, Dufau et al., 2015).</ref>', 'Recent', 'studies', 'were', 'able', 'to', 'predict', 'these', 'and', 'other', '(e.g.', 'semantic)', 'aspects', 'based', 'on', 'single', 'trial', 'multi-channel', 'EEG/MEG', 'activity', '<ref type=""group"">(Ling et al., 2019, Chan et al., 2011, King et al., 2020).</ref>', 'Importantly,', 'the', 'aim', 'of', 'cognitive', 'neuroscience', 'studies', 'is', 'to', 'dissociate', 'when', '(i.e.', 'latency)', 'and', 'where', '(i.e.']",99,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e0e0dc11-cdef-4a1a-a73a-44d732b50c53,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,['The pushshift reddit dataset'],['2020'],['Jason Baumgartner;Savvas Zannettou;Brian Keegan;Megan Squire;Jeremy Blackburn'],single,"['Reddit.', 'A', 'further', 'tuning', 'dataset', 'is', 'derived', 'from', 'an', 'existing', 'Reddit', 'dataset,', 'pushshift.io', '<ref type=""single"">(Baumgartner et al., 2020)</ref>', 'as', 'seen', 'in', '<ref type=""single"">Roller et al. (2020).</ref>', 'This', 'dataset', 'has', 'been', 'used', 'in', 'several', 'existing', 'dialoguebased', 'studies', 'and', 'has', 'been', 'shown', 'to', 'result', 'in', 'more', 'natural', 'conversations', '<ref type=""group"">(Yang et al., 2018, Mazaré et al., 2018).</ref>']",13,"[0, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]"
e0e76457-0f51-49bb-a709-eb08fc6c3144,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['The protection of children online: a brief scoping review to identify vulnerable groups'],['2011'],['Emily Munro'],single,"['With', 'the', 'advent', 'of', 'social', 'media,', 'anti-social', 'and', 'abusive', 'behavior', 'has', 'become', 'a', 'prominent', 'occurrence', 'online.', 'Undesirable', 'psychological', 'effects', 'of', 'abuse', 'on', 'individuals', 'make', 'it', 'an', 'important', 'societal', 'problem', 'of', 'our', 'time.', '<ref type=""single"">Munro (2011)</ref>', 'studied', 'the', 'ill-effects', 'of', 'online', 'abuse', 'on', 'children,', 'concluding', 'that', 'children', 'may', 'develop', 'depression,', 'anxiety,', 'and', 'other', 'mental', 'health', 'problems', 'as', 'a', 'result', 'of', 'their', 'encounters', 'online.', 'Pew', 'Research', 'Center,', 'in', 'its', 'latest', 'report', 'on', 'online', 'harassment', '<ref type=""single"">(Duggan, 2017),</ref>', 'revealed', 'that', '40%', 'of', 'adults', 'in', 'the', 'United', 'States', 'have', 'experienced', 'abusive', 'behavior', 'online,', 'of', 'which', '18%', 'have', 'faced', 'severe', 'forms', 'of', 'harassment,', 'e.g.,', 'that', 'of', 'sexual', 'nature.', 'These', 'statistics', 'stress', 'the', 'need', 'for', 'automated', 'detection', 'and', 'moderation', 'systems.', 'Hence,', 'in', 'recent', 'years,', 'a', 'new', 'research', 'effort', 'on', 'abusive', 'language', 'detection', 'has', 'sprung', 'up', 'in', 'NLP.']",32,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e0fadaa6-9561-492a-83c6-0cba1610811b,DEVELOPING AND EVALUATING A PROBABILISTIC LR PARSER OF PART-OF-SPEECH AND PUNCTUATION LABELS*,1995,Ted Briscoe;John Carroll,['Parsing {with) Punctuation. Rank Xerox Research Centre'],['1994'],['E Briscoe;J Carroll'],single,"['To', 'our', 'knowledge', 'these', 'are', 'the', 'first', 'experiments', 'which', 'objectively', 'demonstrate', 'the', 'utility', 'of', 'punctuation', 'for', 'resolving', 'syntactic', 'ambiguity', 'and', 'improving', 'parser', 'coverage.', 'They', 'extend', 'work', 'by', '<ref type=""single"">Jones (1994)</ref>', 'and', '<ref type=""single"">Briscoe and Carroll (1994)</ref>', 'by', 'applying', 'a', 'wide-coverage', 'text', 'grammar', 'to', 'substantial', 'quantities', 'of', 'naturally-punctuated', 'text', 'and', 'by', 'quantifying', 'the', 'contribution', 'of', 'punctuation', 'to', 'ambiguity', 'resolution', 'in', 'a', 'well-defined', 'probabilistic', 'parse', 'selection', 'model.']",29,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
e124351d-a18a-4952-9886-210bab3741ca,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Axiomatic attribution for deep networks'],['2017'],['Mukund Sundararajan;Ankur Taly;Qiqi Yan'],single,"['We', 'approach', 'this', 'discussion', 'from', 'three', 'different', 'perspectives,', 'that', 'of', 'the', 'designers', 'of', 'the', 'detection', 'method,', 'that', 'of', 'the', 'user', 'creating', 'comments,', 'and', 'that', 'of', 'the', 'larger', 'communities.', 'By', 'breaking', 'the', 'discussion', 'down', 'in', 'this', 'manner,', 'we', 'explore', 'the', 'different', 'choices', 'that', 'exist', 'for', 'operationalization', 'and', 'the', 'purposes', 'they', 'can', 'serve.', 'Designers', 'of', 'the', 'method.', 'For', 'the', 'designers', 'of', 'the', 'detection', 'method,', 'explainability', 'can', 'serve', 'as', 'a', 'principled', 'mechanism', 'for', 'understanding', 'and', 'reasoning', 'about', 'the', 'behavior', 'of', 'their', 'method,', 'which', 'is', 'important', 'for', 'multiple', 'reasons.', 'Firstly,', 'if', 'the', 'detection', 'method', 'exhibits', 'all', 'the', 'four', 'properties', 'of', 'explain-ability,', 'then', 'the', 'designers', 'can', 'easily', 'gain', 'insights', 'into', 'the', 'factors', 'that', 'contributed', 'to', 'the', 'decision', 'made', 'by', 'the', 'method', 'given', 'a', 'comment.', 'This', 'can', 'allow', 'the', 'designers', 'to', 'recognize', 'when', 'the', 'method', 'may', 'be', 'overly', 'relying', 'on', 'a', 'specific', 'factor,', 'e.g.,', 'the', 'demographic', 'traits.', 'In', 'the', 'case', 'of', 'social', 'feature', 'engineering', 'and', 'user', 'embeddings', 'based', 'methods,', 'operationalization', 'of', 'explainability', 'via', 'feature', 'attribution', 'such', 'as', 'LIME', '<ref type=""single"">(Ribeiro et al., 2016)</ref>', 'and', 'Integrated', 'Gradients', '<ref type=""single"">(Sundararajan et al., 2017)</ref>', 'can', 'be', 'effective', 'in', 'offering', 'such', 'insights.', 'For', 'social', 'graph', 'based', 'methods', 'that', 'employ', 'graph', 'neural', 'networks,', 'attribution', 'techniques', 'like', 'GNNExplainer', '<ref type=""single"">(Ying et al., 2019)</ref>', 'can', 'be', 'used', 'instead.', 'The', 'second', 'reason', 'why', 'explainability', 'is', 'important', 'for', 'the', 'designers', 'is', 'because', 'it', 'can', 'allow', 'them', 'to', 'optimize', 'the', 'method', 'by', 'removing', 'inputs', 'that', 'do', 'not', 'contribute', 'significantly.', 'Here', 'again,', 'explainability', 'via', 'feature', 'attribution', 'can', 'be', 'effective.', 'Lastly,', 'explainability', 'is', 'also', 'important', 'for', 'the', 'designers', 'to', 'understand', 'how', 'their', 'method', 'would', 'perform', 'in', 'cases', 'where', 'a', 'user', 'may', 'try', 'obfuscate', 'abusive', 'language', '<ref type=""single"">(Nobata et al., 2016).</ref>', 'Counterfactual', 'explanations', 'can', 'constitute', 'an', 'effective', 'operationalization', 'for', 'the', 'designers', 'to', 'identify', 'the', 'parts', 'of', 'their', 'method', 'that', 'are', 'most', 'vulnerable', 'to', 'obfuscations.']",166,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e17a0312-40fd-48ec-937b-8ba23793a50c,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['unknown'],['2020'],['unk Nguyen Van Nha'],single,"['To', 'apply', 'RDS', '<ref type=""single"">(Nguyen et al., 2020)</ref>', 'for', 'the', 'data', 'splitting', 'process,', 'it', 'requires', 'to', 'have', 'baseline', 'learners', 'to', 'obtain', 'rewards', 'for', 'the', 'reinforced', 'process.', 'It', 'is', 'recommended', 'to', 'choose', 'representative', 'baseline', 'learners,', 'to', 'let', 'the', 'reinforced', 'learner', 'better', 'capture', 'different', 'learning', 'behaviors.', 'The', 'use', 'of', 'these', 'baseline', 'learners', 'is', 'important', 'since', 'each', 'learner', 'will', 'behave', 'differently', 'depending', 'on', 'the', 'patterns', 'contained', 'in', 'the', 'target', 'data.', 'As', 'a', 'result,', 'RDS', 'helps', 'to', 'increase', 'the', 'diversity', 'of', 'the', 'data', 'samples', 'in', 'different', 'sets.', 'Here', 'we', 'employ', 'three', 'models', 'to', 'classify', 'reliable', 'news', 'using', 'textual', 'features', 'as', 'follows:', 'Bi-LSTM', 'network', 'is', 'a', 'standard', 'baseline', 'for', 'most', 'of', 'text', 'classification', 'tasks.']",3,"[2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e181c429-8548-4c8a-a85a-86f4e56dd798,Classifying Argumentative Relations Using Logical Mechanisms and Argumentation Schemes,2021,Yohan Jo;Seojin Bang;Chris Reed;Eduard Hovy,"['Feasible annotation scheme for capturing policy argument reasoning using argument templates', 'Argument mining using argumentation scheme structures']","['2018', '2016']","['Paul Reisert;Naoya Inoue;Tatsuki Kuribayashi;Kentaro Inui', 'John Lawrence;Chris Reed']",group,"['For', 'each', 'pair', 'of', 'normative', 'claim', 'C', 'and', 'statement', 'S,', 'we', 'annotate', 'the', 'following', 'information:', '(1a)', 'Whether', 'C', 'advocates', 'for', 'or', 'opposes', 'its', 'norm', 'target,', 'and', '(1b)', 'the', 'norm', 'target', 'T', '(Figure', '1', 'TASK', '1),', '(2a)', 'Whether', 'S', 'uses', 'a', 'norm,', 'consequence,', 'or', 'property', 'for', 'justification,', 'and', '(2b)', 'the', 'justification', 'J', '(Figure', '1', 'TASK', '2),', '(3a)', 'Whether', ""J's"", 'focus', 'is', 'on', 'advocating', 'for', 'T', 'or', 'opposing', 'T,', 'and', '(3b)', 'whether', 'J', 'is', 'positive', 'or', 'negative', '(Figure', '1', 'TASK', '3).', '6', 'Our', 'annotation', 'schema', 'is', 'richer', 'than', 'existing', 'ones', '<ref type=""group"">(Lawrence and Reed, 2016, Reisert et al., 2018).</ref>', 'Due', 'to', 'the', 'increased', 'complexity,', 'however,', 'our', 'annotation', 'is', 'split', 'into', 'three', 'pipelined', 'tasks.', 'For', 'this', 'annotation,', 'we', 'randomly', 'sampled', '1,000', 'arguments', 'from', 'Kialo', 'whose', 'claims', 'are', 'normative', '(see', '§6', 'and', 'Table', '4', 'for', 'details).']",88,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e1af8da9-6584-4609-80dd-39bae7b41c78,Associating semantic components with intersective Levin classes,1997,Hoa Dang;Joseph Rosenzweig;Martha Palmer,['English Verb Classes and Alternations'],['1993'],['B Levin'],single,"['In', 'addition', 'to', 'Levin', 'classes', 'like', 'cut', 'whose', 'members', 'have', 'core', 'senses', 'that', 'are', 'closely', 'and', 'systematically', 'related', 'in', 'the', 'WordNet', 'hierarchy,', 'other', 'Levin', 'classes', 'are', 'composed', 'of', 'verbs', 'that', 'exhibit', 'a', 'wider', 'range', 'of', 'possible', 'semantic', 'components.', 'The', 'split', 'verbs', '(blow,', 'break,', 'cut,', 'draw,', 'hack,', 'hew,', 'kick,', 'knock,', 'pry,', 'pull,', 'push,', 'rip,', 'roll,', 'saw,', 'shove,', 'slip,', 'split,', 'tear,', 'tug,', 'yank)', 'do', 'not', 'obviously', 'form', 'a', 'tight', 'semantic', 'class.', 'Instead,', 'in', 'their', 'use', 'as', 'split', 'verbs,', 'each', 'verb', 'manifests', 'an', 'extended', 'sense', 'that', 'can', 'be', 'paraphrased', 'as', '""separate', 'by', 'V-ing,""', 'where', '""V""', 'is', 'the', 'basic', 'meaning', 'of', 'that', 'verb', '<ref type=""single"">[8].</ref>', 'Many', 'of', 'the', 'verbs', '(e.g.,', 'draw,', 'pull,', 'push,', 'shove,', 'tug,', 'yank)', 'that', 'do', 'not', 'have', 'an', 'inherent', 'semantic', 'component', 'of', '""separating""', 'belong', 'to', 'this', 'class', 'because', 'of', 'the', 'component', 'of', 'force', 'in', 'their', 'meaning.', 'They', 'are', 'interpretable', 'as', 'verbs', 'of', 'splitting', 'or', 'separating', 'only', 'in', 'particular', 'syntactic', 'frames.', 'The', 'adjunction', 'of', 'the', 'apart', 'adverb', 'adds', 'a', 'change', 'of', 'state', 'semantic', 'component', 'with', 'respect', 'to', 'the', 'object', 'which', 'is', 'not', 'present', 'otherwise.']",99,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e1f95ae4-099f-43ad-88ba-c90dd5a19005,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['Character convolutions for arabic named entity recognition with long short-term memory networks'],['2019'],['Muhammad Khalifa;Khaled Shaalan'],single,"['Named', 'Entity', 'Recognition', '(NER)', 'and', 'Part-of-Speech', '(POS)', 'tagging', 'have', 'traditionally', 'been', 'used', 'as', 'preprocessing', 'steps', 'in', 'many', 'Natural', 'Language', 'Processing', '(NLP)', 'applications.', 'For', 'example,', '<ref type=""single"">Yadav and Bethard (2018)</ref>', 'discussed', 'the', 'use', 'of', 'NER', 'across', 'question', 'answering,', 'information', 'retrieval,', 'co-reference', 'resolution,', 'topic', 'modeling,', 'and', 'machine', 'translation.', 'Similarly,', 'POS', 'tagging', 'is', 'often', 'applied', 'early', 'in', 'the', 'NLP', 'pipeline', 'for', 'many', 'applications', 'including', 'information', 'retrieval', 'systems,', 'syntax,', 'and', 'semantic', 'analysis,', 'speech', 'recognition', 'systems', 'and', 'machine', 'translation', '<ref type=""single"">(Abumalloh et al., 2016).</ref>', 'In', 'recent', 'years,', 'Arabic', 'has', 'been', 'studied', 'increasingly', 'due', 'to', 'the', 'explosion', 'in', 'the', 'number', 'of', 'Arabic', 'users', 'on', 'social', 'media', 'and', 'the', 'internet', 'in', 'general.', 'Arabic', 'is', 'a', 'morphologically', 'rich', 'language', 'with', 'complex', 'grammatical', 'structure', '<ref type=""single"">(Shaalan et al., 2019).</ref>', 'Arabic', 'NLP', 'researchers', 'have', 'used', 'two', 'types', 'of', 'approaches', 'and', 'sometimes', 'a', 'mixture', 'of', 'both', 'to', 'work', 'with', 'Arabic', 'text.', 'The', 'first', 'approach', 'is', 'the', 'simplification', 'approach', 'where', 'researchers', 'tend', 'to', 'apply', 'preprocessing', '(transformation)', 'that', 'simplify', 'Arabic', 'text', 'such', 'as', 'letter', 'normalization', '<ref type=""single"">(Habash, 2010)</ref>', 'and', 'transliteration', '<ref type=""single"">(Ameur et al., 2017).</ref>', 'The', 'second', 'approach', 'is', 'the', 'enrichment', 'approach', 'where', 'researchers', 'tend', 'to', 'apply', 'minimum', 'modification', 'to', 'the', 'Arabic', 'text', 'and', 'devise', 'a', 'way', 'of', 'incorporating', 'the', 'enriched', 'features', 'and', 'potentially', 'add', 'more', 'features', 'to', 'it.']",107,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e20db031-7148-4536-9ca0-e772224ad4a5,Corpora and Machine Translation,1993,Yorick Wilks,['Stochastic methods of mechanical translation'],['1956'],['G King'],single,"['""It', 'is', 'well', 'known', 'that', 'Western', 'Languages', 'are', '50%', 'redundant.', 'Experiment', 'shows', 'that', 'if', 'an', 'average', 'person', 'guesses', 'the', 'successive', 'words', 'in', 'a', 'completely', 'unknown', 'sentence', 'he', 'has', 'to', 'be', 'told', 'only', 'half', 'of', 'them.', 'Experiment', 'shows', 'that', 'this', 'also', 'applies', 'to', 'guessing', 'the', 'successive', 'word-ideas', 'in', 'a', 'foreign', 'language.', 'How', 'can', 'this', 'fact', 'be', 'used', 'in', 'machine', 'translation""', '<ref type=""single"">(King 1956</ref>', ').']",59,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1]"
e21a289d-865f-4e51-a00a-2c942a1384e4,A Language Invariant Neural Method for TimeML Event Detection,2019,Suhan Prabhu;Pranav Goel;Alok Debnath;Manish Shrivastava,['Data-driven approach using semantics for recognizing and classifying timeml events in italian'],['2011'],['Tommaso Caselli;Hector Llorens;Borja Navarro-Colorado;Estela Saquete'],single,"['For', 'Italian,', 'we', 'train', 'and', 'test', 'solely', 'on', 'the', 'Ita-TimeBank,', 'whereas', 'the', 'current', 'state', 'of', 'the', 'art', 'system', 'trained', 'on', 'an', 'augmented', 'Ita-TimeBank', '<ref type=""single"">(Caselli et al., 2011b),</ref>', 'which', 'was', 'enriched', 'with', 'more', 'labeled', 'data.', 'Similarly,', 'in', 'French,', 'we', 'use', 'the', 'established', 'French', 'TimeBank,', 'while', 'experiments', 'in', 'French', 'so', 'far', 'have', 'been', 'on', 'self-annotated', '<ref type=""single"">(Arnulphy et al., 2015)</ref>', 'or', 'TimeML', 'corpora', '<ref type=""single"">(Bittar, 2009).</ref>', 'Since', 'these', 'repositories', 'of', 'augmented', 'data', 'were', 'not', 'available', 'to', 'us', 'at', 'the', 'time', 'of', 'writing', 'this', 'paper,', 'the', 'values', 'reflect', 'the', 'same.', 'However,', 'it', 'is', 'to', 'be', 'noted', 'that', 'our', 'system', 'does', 'provide', 'an', 'accuracy', 'that', 'is', 'close', 'to', 'the', 'currently', 'reported', 'stateof-the-art', 'even', 'in', 'the', 'absence', 'of', 'language', 'specific', 'features,', 'explaining', 'the', 'fact', 'that', 'sub-word', 'information', 'is', 'necessary', 'for', 'event', 'detection', 'in', 'Italian', 'and', 'French', 'as', 'well.']",23,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e23a8865-802a-405e-b4d1-1683f95e7f3b,Can Semantic Role Labeling Improve SMT?,2009,Dekai Wu;Pascale Fung,['Word sense disambiguation vs. statistical machine translation'],['2005'],['Marine Carpuat;Dekai Wu'],single,"['We', 'approach', 'this', 'promise', 'with', 'caution,', 'however,', 'given', 'the', 'painful', 'lessons', 'learned', 'through', 'the', 'historical', 'difficulty', 'of', 'making', 'syntactic', 'and', 'semantic', 'models', 'contribute', 'to', 'improving', 'SMT', 'accuracy.', 'The', 'past', 'decade', 'has', 'at', 'last', 'seen', 'increasing', 'amounts', 'of', 'evidence', 'that', 'SMT', 'accuracy', 'can', 'indeed', 'be', 'improved', 'via', 'tree-structured', 'and', 'syntactic', 'models', '(e.g.,', '<ref type=""single"">Wu (1997),</ref>', '<ref type=""single"">Chiang and Wu (2008),</ref>', '<ref type=""single"">Wu and Chiang (2009))</ref>', 'despite', 'numerous', 'disappoint-ing', 'attempts', '<ref type=""single"">Och et al. (2004).</ref>', 'More', 'recently,', 'lexical', 'semantics', 'models', 'for', 'word', 'sense', 'disambiguation', 'have', 'also', 'finally', 'been', 'successfully', 'applied', 'to', 'increasing', 'SMT', 'accuracy', '(e.g.,', '<ref type=""group"">Carpuat and Wu (2007), Chan et al. (2007),</ref>', '<ref type=""single"">Giménez and Màrquez (2007a))</ref>', 'again', 'after', 'surprising', 'initial', 'failures', '(e.g.,', '<ref type=""single"">Carpuat and Wu (2005)</ref>', ').', 'In', 'both', 'the', 'syntactic', 'and', 'semantic', 'cases,', 'improving', 'SMT', 'accuracy', 'ultimately', 'required', 'making', 'major', 'adaptations', 'to', 'the', 'original', 'linguistic', 'models.', 'We', 'can', 'reasonably', 'expect', 'it', 'to', 'be', 'at', 'least', 'as', 'difficult', 'to', 'successfully', 'adapt', 'the', 'even', 'more', 'complex', 'types', 'of', 'lexical', 'semantics', 'modeling', 'from', 'semantic', 'parsing', 'and', 'role', 'labeling.']",87,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e2592514-c969-4d5f-882d-81554964e434,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['A general psychoevolutionary theory of emotion'],['1980'],['Robert Plutchik'],single,"['There', 'is', 'an', 'ever', 'increasing', 'need', 'for', 'labeled', 'datasets', 'for', 'machine', 'learning.', 'This', 'is', 'true', 'for', 'English', 'as', 'well', 'as', 'other,', 'often', 'under-resourced,', 'languages.', 'We', 'provide', 'a', 'cross-lingual', 'fine-grained', 'sentence-level', 'emotion', 'and', 'sentiment', 'dataset.', 'The', 'dataset', 'consists', 'of', 'parallel', 'manually', 'annotated', 'data', 'for', 'English', 'and', 'Finnish,', 'with', 'additional', 'parallel', 'datasets', 'of', 'varying', 'sizes', 'for', 'a', 'total', 'of', '32', 'languages', 'created', 'by', 'annotation', 'projection.', 'We', 'use', ""Plutchik's"", 'Wheel', 'of', 'Emotions', '(anger,', 'anticipation,', 'disgust,', 'fear,', 'joy,', 'sadness,', 'surprise,', 'trust)', '<ref type=""single"">(Plutchik, 1980)</ref>', 'as', 'our', 'annotation', 'scheme', 'with', 'the', 'addition', 'of', 'neutral', 'on', 'movie', 'subtitle', 'data', 'from', 'OPUS', '<ref type=""single"">(Lison and Tiedemann, 2016).</ref>']",77,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
e28cbfe9-da2d-4603-8535-35f8ab60178c,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,"['BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension']",['1910'],['Mike Lewis;Yinhan Liu;Naman Goyal;Marjan Ghazvininejad;Abdelrahman Mohamed;Omer Levy;Veselin Stoyanov;Luke Zettlemoyer'],single,"['Besides,', 'we', 'also', 'conduct', 'a', 'manual', 'evaluation', 'on', 'the', 'Chinese', 'test', 'set,', 'and', 'the', 'results', 'are', 'listed', 'in', 'Table', '5.', 'From', 'the', 'averaged', 'scores,', 'we', 'observe', 'that', 'SimpDefiner', 'outperforms', 'MASS', 'by', '0.2', 'in', 'terms', 'of', 'accuracy', '(more', 'accurate)', 'and', '0.18', 'in', 'terms', 'of', 'simplicity', '(more', 'straightforward).', 'On', 'the', 'accuracy', 'score,', 'all', 'three', 'annotators', 'agree', 'that', 'SimpDefiner', 'has', 'higher', 'accuracy', 'than', 'MASS,', 'which', 'shows', 'the', 'superiority', 'of', 'our', 'framework.', 'As', 'expected,', 'the', 'golden', 'definitions', 'have', 'the', 'highest', 'accuracy', 'in', 'the', 'table,', 'far', 'exceeding', 'the', 'definitions', 'generated', 'by', 'the', 'two', 'models.', 'We', 'believe', 'this', 'is', 'caused', 'by', 'insufficient', 'knowledge', 'in', 'the', 'model,', 'and', 'this', 'can', 'be', 'solved', 'by', 'using', 'larger', 'pretrained', 'models,', 'such', 'as', 'BART', '<ref type=""single"">(Lewis et al., 2019).</ref>', 'On', 'the', 'simplicity', 'score,', 'three', 'annotators', 'agree', 'that', 'SimpDefiner', 'generates', 'simpler', 'definitions', 'than', 'MASS,', 'and', 'two', 'of', 'three', 'annotators', 'think', 'SimpDefiner', 'generates', 'simpler', 'definitions', 'than', 'the', 'golden', 'ones.']",113,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e2967de0-c95e-443c-b0e7-364773b98c30,Entity Attribute Relation Extraction with Attribute-Aware Embeddings,2020,Dan Iter;Xiao Yu;Fangtao Li,['Relex-relation extraction using dependency parse trees'],['2006'],['Katrin Fundel;Robert Küffner;Ralf Zimmer'],single,"['Sentences', 'are', 'represented', 'with', 'their', 'shortest', 'dependency', 'path', 'between', 'two', 'candidates,', 'as', 'proposed', 'in', '<ref type=""single"">(Fundel et al., 2006).</ref>', 'The', 'bottom', 'of', 'Figure', '1', 'shows', 'an', 'example', 'of', 'the', 'shortest', 'path', 'between', 'an', 'entity', 'and', 'attribute', 'for', 'one', 'sentence.', 'We', 'converts', 'each', 'sentence', 'from', 'a', 'string', 'to', 'a', 'list', 'of', 'terms,', 'where', 'the', 'first', 'and', 'last', 'term', 'is', 'either', 'the', 'entity', 'or', 'the', 'attribute.', 'Each', 'term', 'in', 'the', 'dependency', 'path', 'is', 'represented', 'by', 'the', 'lemma', 'of', 'the', 'term,', 'the', 'part-of-speech', 'tag,', 'the', 'dependency', 'label,', 'the', 'direction', 'of', 'the', 'dependency', 'path', 'to', 'the', 'parent', '(left,', 'right', 'or', 'root).', 'Each', 'of', 'these', 'features', 'is', 'embedded', 'and', 'concatenated', 'to', 'produce', 'a', 'sequence', 'of', 'vectors', 'that', 'represents', 'the', 'dependency', 'path.', 'The', 'concatenation', 'is', 'the', 'edge', 'representation−', '→', 'v', 'edge', '=', '[−', '→', 'v', 'lemma,', '−', '→', 'v', 'pos,', '−', '→', 'v', 'dep,', '−', '→', 'v', 'dir', ']The', 'sequence', 'of', 'terms', 'in', 'each', 'path', 'is', 'input', 'into', 'an', 'LSTM', 'to', 'produce', 'a', 'single', 'vector', 'representation', 'for', 'the', 'sentence,', '−', '→', 'v', 's.', 'This', 'is', 'repeated', 'for', 'each', 'sentence', 'producing', 'one', 'vector', 'per', 'sentence.', 'The', 'sentences', 'are', 'aggregated', 'with', 'a', 'weighted', 'mean', 'of', 'the', 'sentence', 'representations', 'to', 'form', 'a', 'representation', 'of', 'the', 'multiset', 'of', 'sentences,', '−', '→', 'v', 'sents(e,a).']",14,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e2b6129c-c740-44fe-bc67-b1b39fcdadfc,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Constrained decoding for neural NLG from compositional representations in task-oriented dialogue'],['2019'],['Anusha Balakrishnan;Jinfeng Rao;Kartikeya Upasani;Michael White;Rajen Subba'],single,"['Early', 'studies', 'of', 'conditioned', 'response', 'generation', 'focus', 'on', 'enriching', 'the', 'meaning', 'representations', 'in', 'task-oriented', 'dialogues,', 'e.g.,', 'utilizing', 'graph', 'structures', 'and', 'hierarchies', 'among', 'actions', '<ref type=""group"">(Chen et al., 2019, Yang et al., 2020),</ref>', 'decomposing', 'into', 'fine-grained', 'actions', '<ref type=""single"">(Shu et al., 2019),</ref>', 'or', 'encoding', 'syntax', 'attributes', '<ref type=""single"">(Balakrishnan et al., 2019).</ref>', 'Since', 'these', 'approaches', 'often', 'assume', 'expensive', 'action', 'annotations,', 'recent', 'years', 'have', 'seen', 'a', 'growing', 'interest', 'in', 'learning', 'latent', 'actions', 'in', 'an', 'unsupervised', 'way', '<ref type=""group"">(Zhao et al., 2019, Huang et al., 2020a).</ref>', 'These', 'approaches', 'build', 'on', 'either', 'adversarial', 'learning', '<ref type=""group"">(Hu et al., 2017, Wang et al., 2018, Yang et al., 2018)</ref>', 'or', 'variational', 'inference', '(Kingma', 'and', 'Welling,', '2014)', 'and', 'encode', 'all', 'system', 'utterances', 'via', 'a', 'self-reconstruction', 'task', 'or', 'distant', 'supervision', '<ref type=""single"">(Yarats and Lewis, 2018).</ref>', 'Due', 'to', 'their', 'implicit', 'nature,', 'latent', 'actions', 'are', 'difficult', 'to', 'generalize,', 'and', 'we', 'aim', 'to', 'overcome', 'this', 'limitation', 'by', 'learning', 'explicit', 'action', 'representations.']",33,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e2df4f1f-1c75-4b2f-9dc5-a22e1255bf6d,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['unknown'],['unknown'],['unknown'],single,"['We', 'consider', 'z', 'as', 'a', 'disentangled', 'representation', 'for', 'x,', 'if', 'the', 'changes', 'in', 'single', 'latent', 'dimensions', 'of', 'z', 'are', 'sensitive', 'to', 'changes', 'in', 'single', 'generative', 'factors', 'of', 'x', 'while', 'being', 'relatively', 'invariant', 'to', 'changes', 'in', 'other', 'factors', '<ref type=""single"">(Bengio et al., 2013).</ref>', 'Several', 'probabilistic', 'models', 'are', 'designed', 'to', 'reveal', 'this', 'process,', 'here', 'we', 'look', 'at', 'some', 'of', 'the', 'most', 'widely', 'used', 'ones.']",37,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e34aba93-b24f-468e-bcfd-a446d0dbc201,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Semantic feature production norms for a large set of living and nonliving things'],['2005'],['Ken Mcrae;George Cree;Mark Seidenberg;Chris Mcnorgan'],single,"['A', 'related', 'thrust', 'of', 'the', 'literature', 'has', 'looked', 'at', 'understanding', 'entities', 'using', 'interpretable', 'embeddings', 'based', 'around', 'feature', 'norms', '<ref type=""single"">(McRae et al., 2005),</ref>', 'this', 'has', 'advantages', 'for', 'learning', 'in', 'few-shot', 'setups', '<ref type=""single"">(Wang et al., 2017).</ref>', 'However,', 'most', 'of', 'this', 'past', 'work', 'has', 'used', 'embeddings', 'that', 'are', 'much', 'lowerdimensional', 'than', 'ours,', 'and', ""don't"", 'necessarily', 'to', 'scale', 'to', 'broad-domain', 'text', 'or', 'all', 'of', 'Wikipedia.']",18,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e39f9948-f8df-442d-b919-6e9b478a8be3,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Revisiting fewsample {bert} fine-tuning'],['2021'],['Tianyi Zhang;Felix Wu;Arzoo Katiyar;Q Kilian;Yoav Weinberger;unk Artzi'],single,"['To', 'meet', 'these', 'constraints,', 'compact', 'models', 'represent', 'one', 'of', 'the', 'most', 'promising', 'solutions.', 'As', 'far', 'as', 'we', 'know,', 'they', 'have', 'only', 'been', 'evaluated', 'on', 'the', 'comprehension', 'tasks', 'covered', 'by', 'GLUE', '<ref type=""single"">(Wang et al., 2018)</ref>', 'and', 'the', 'question-answering', 'task', 'with', 'the', 'SQuAD', 'corpus', '<ref type=""single"">(Rajpurkar et al., 2016)</ref>', 'with', 'abundant', 'data,', 'in', 'English.', 'The', 'improvements', 'resulting', 'from', 'the', 'algorithmic', 'optimizations', 'of', 'the', 'models,', 'although', 'significant,', 'raise', 'questions', 'about', 'their', 'effectiveness', 'on', 'lower-scale', 'learning', 'problems', 'on', 'poorly', 'endowed', 'languages.', 'The', 'works', 'of', '<ref type=""single"">Zhang et al. (2021)</ref>', 'and', '<ref type=""single"">Mosbach et al. (2021)</ref>', 'have', 'furthermore', 'shown', 'degraded', 'performance', 'in', 'these', 'conditions.', 'These', 'two', 'reflections', 'are', 'at', 'the', 'origin', 'of', 'a', 'double', 'question', 'which', 'our', 'contribution', 'attempts', 'to', 'answer.', 'On', 'the', 'one', 'hand,', 'what', 'is', 'the', 'behavior', 'of', 'a', 'Transformer-based', 'model', 'in', 'the', 'context', 'of', 'a', 'question-answering', 'task', 'in', 'French,', 'a', 'task', 'that', 'is', 'poorly', 'endowed', 'in', 'this', 'language?', 'On', 'the', 'other', 'hand,', 'what', 'are', 'the', 'impacts', 'of', 'algorithmic', 'improvements', 'of', 'these', 'same', 'models', 'in', 'this', 'context?']",73,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e3f10b78-eab8-4092-bd29-e8643542b8ca,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Regression Shrinkage and Selection Via the Lasso'],['1994'],['Robert Tibshirani'],single,"['Our', 'approach', 'to', 'compression', 'involves', 'learning', 'a', 'sparse', 'trainable', 'mask', 'that', 'restricts', 'the', 'set', 'of', 'types', 'considered.', 'We', 'parameterize', 'the', 'dot', 'product', '6', 'and', 'cosine', 'similarity', '7', 'operations', 'with', 'a', 'weight', 'matrix', 'W,', 'a', 'diagonal', 'matrix', 'diag(w', '1,', 'w', '2,', '...,', 'w', '|T', '|)', 'whose', 'components', 'correspond', 'to', 'the', 'entity', 'types', 'in', 'T.', 'The', 'parameters', 'W', 'can', 'be', 'learned', 'directly', 'on', 'downstream', 'tasks', '(e.g.,', 'CAP', 'and', 'NED).', 'Note', 'that', 'in', 'the', 'cosine', 'scoring', 'function,', 'we', 'clip', 'these', 'parameter', 'values', 'to', 'be', 'between', '0', 'and', '1.', 'We', 'train', 'with', 'the', 'standard', 'downstream', 'task', 'objective,', 'but', 'with', 'an', 'additional', 'L', '1', 'regularization', 'term', 'applied', 'to', 'W', '<ref type=""single"">(Tibshirani, 1994)</ref>', 'to', 'encourage', 'the', 'W', 'values', 'to', 'be', 'sparse.']",104,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]"
e3fe6ca5-b0e6-4731-a9f5-cbce89bb2916,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['On the importance of the Kullback-Leibler divergence term in variational autoencoders for text generation'],['2019'],['Victor Prokhorov;Ehsan Shareghi;Yingzhen Li;Mohammad Taher Pilehvar;Nigel Collier'],single,"['E', 'q', 'φ', '(z|x)', 'log', 'p', 'θ', '(x|z)', '−', 'β', '|D', 'KL', '(q', 'φ', '(z|x),', 'p(z))', '−', 'C|where', 'C', 'is', 'a', 'positive', 'real', 'value', 'which', 'represents', 'the', 'target', 'KL-divergence', 'term', 'value.', 'This', 'has', 'an', 'information-theoretic', 'interpretation,', 'where', 'the', 'placed', 'constraint', 'C', 'on', 'the', 'KL', 'term', 'is', 'seen', 'as', 'the', 'amount', 'of', 'information', 'transmitted', 'from', 'a', 'sender', '(encoder)', 'to', 'a', 'receiver', '(decoder)', 'via', 'the', 'message', '(z)', '<ref type=""single"">(Alemi et al., 2018),</ref>', 'and', 'impacts', 'the', 'sharpness', 'of', 'the', 'posterior', 'distribution', '<ref type=""single"">(Prokhorov et al., 2019).</ref>', 'This', 'constraint', 'allows', 'the', 'model', 'to', 'prioritize', 'underlying', 'factors', 'of', 'data', 'according', 'to', 'the', 'availability', 'of', 'channel', 'capacity', 'and', 'their', 'contributions', 'to', 'the', 'reconstruction', 'loss', 'improvement.', '<ref type=""single"">(Mathieu et al., 2019)</ref>', 'introduces', 'an', 'additional', 'term', 'to', 'β-VAE,', 'D', 'M', 'M', 'D', '(q', 'φ', '(z),', 'p', 'θ', '(z)),']",74,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e4e36957-290f-4e99-8375-2d4daa7046ab,A Fine-Grained Analysis of BERTScore,2021,Michael Hanna;Ondřej Bojar,['unknown'],['2020'],['Tianyi Zhang;Varsha Kishore;Felix Wu;Kilian Weinberger;Yoav Artzi'],single,"['The', 'original', 'paper', 'introducing', 'BERTScore', '<ref type=""single"">(Zhang et al., 2020)</ref>', 'naturally', 'compared', ""BERTScore's"", 'correlations', 'with', 'human', 'judgments', 'to', 'that', 'of', 'other', 'metrics.', 'However,', 'various', 'other', 'surveys', 'of', 'MT', 'metrics,', 'as', 'well', 'as', 'datasets', 'and', 'methodologies', 'have', 'been', 'conducted,', 'offering', 'insights', 'into', 'how', 'MT', 'system', 'and', 'metric', 'performance', 'should', 'be', 'measured.']",5,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e51b688a-af91-406d-a1c8-5e9059fb5224,Diverse dialogue generation with context dependent dynamic loss function,2020,Ayaka Ueyama;Yoshinobu Kano,['Attention is all you need'],['2017'],['Ashish Vaswani;Noam Shazeer;Niki Parmar;Jakob Uszkoreit;Llion Jones;Aidan Gomez;Łukasz Kaiser;Illia Polosukhin'],single,"['Both', 'the', 'encoder', 'and', 'decoder', 'are', 'six-layer', 'Transformer', '<ref type=""single"">(Vaswani et al., 2017),</ref>', 'the', 'number', 'of', 'heads', 'of', 'Multi-Head', 'Attention', 'is', '8,', 'the', 'token', 'embedding', 'dimension', 'is', '512,', 'and', 'the', 'ratio', 'of', 'Dropout', 'is', '0.1.', 'Adam', '(Kingma', 'and', 'Ba,', '2015)', 'was', 'used', 'as', 'the', 'optimization', 'method', 'for', 'parameters', 'during', 'training.', 'The', 'learning', 'rate', 'of', 'Adam', 'was', 'set', 'to', '0.001.', 'Hyperparameters', 'λ,', 'which', 'adjust', 'the', 'frequency', 'of', 'ITF', 'model', 'and', 'INF', 'model,', 'were', 'set', 'as', '0.2,', '0.4,', '0.6,', 'or', '0.8.', 'The', 'INF', 'model', 'uses', 'bi-gram', 'as', 'its', 'n-gram', 'function.']",8,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e556a220-804d-46df-ba92-3381758995a1,A Semi-Supervised Approach to Detect Toxic Comments,2021,Ghivvago Saraiva;Rafael Anchiêta;Francisco Neto;Raimundo Moura,['Portuguese word embeddings: Evaluating on word analogies and natural language tasks'],['2017'],['Nathan Hartmann;Erick Fonseca;Christopher Shulby;Marcos Treviso;Jéssica Silva;Sandra Aluísio'],single,"['The', 'strategy', 'of', 'weighting', 'links', 'between', 'a', 'token', 'and', 'a', 'sentence', 'node', 'is', 'straightforward.', 'The', 'weight', 'is', 'the', 'average', '3', 'of', 'embedding', 'vectors', 'of', 'the', 'token', 'node.', 'To', 'get', 'embedding', 'values', 'for', 'each', 'token,', 'we', 'used', '100-dimensional', 'GloVe', 'embeddings', '4', 'for', 'the', 'Portuguese', 'language', '<ref type=""single"">(Hartmann et al., 2017).</ref>', 'Figure', '3', 'shows', 'the', 'scheme', 'of', 'the', 'network', 'designed', 'for', 'this', 'task.', 'One', 'can', 'see', 'that', 'the', 'edges', 'are', 'undirected', 'and', 'weighted,', 'and', 'a', 'sentence', 'node', 'may', 'share', 'several', 'token', 'nodes', 'whenever', 'the', 'token', 'is', 'in', 'the', 'sentence,', 'i.e.,', 'the', 'edges', 'between', 'token', 'nodes', 'and', 'sentence', 'nodes', 'are', 'based', 'on', 'word', 'occurrence', 'in', 'sentence.']",44,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e5db6294-d9cf-49fc-ba85-e8e656814da3,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['unknown'],['unknown'],['unknown'],single,"['Kinyarwanda', '<ref type=""single"">[kin]</ref>', 'data', 'is', 'used', 'in', 'our', 'experiments', 'as', 'a', 'language', 'related', 'to', 'the', 'target', 'language', '(swh)', 'with', 'existing', 'text', 'and', 'audio', 'resources', 'that,', 'in', 'some', 'ways,', 'surpasses', 'those', 'available', 'in', 'the', 'target', 'language.', 'Thus,', 'we', 'pre-train', 'some', 'models', 'on', 'kin', 'data', 'while', 'fine-tuning', 'for', 'the', 'downstream', 'NER', 'task', 'using', 'swh', 'data.']",1,"[1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
e62e758e-632e-43e5-ae61-3cb4e7fc26a1,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['Statistical phrasebased translation'],['2003'],['P Koehn;F Och;D Marcu'],single,"['Hierarchical', 'Phrase-Based', '(HPB)', 'SMT', '<ref type=""single"">[3]</ref>', 'is', 'a', 'tree-based', 'model', 'which', 'extracts', 'a', 'synchronous', 'Context-Free', 'Grammar', '(CFG)', 'automatically', 'from', 'the', 'training', 'corpus.', 'HPB', 'SMT', 'is', 'based', 'on', 'phrases', 'extracted', 'according', 'to', 'the', 'PB', 'model', '<ref type=""single"">[2].</ref>', 'Thus,', 'HPB', 'SMT', 'tries', 'to', 'build', 'upon', 'the', 'strengths', 'of', 'PB', 'SMT', 'and', 'adds', 'to', 'it', 'the', 'ability', 'to', 'translate', 'discontinuous', 'phrases', 'and', 'learn', 'phrase-reordering', 'in', 'hierarchical', 'rules', 'without', 'a', 'separate', 'reordering', 'model.', 'HPB', 'SMT', 'uses', 'hierarchical', 'rules', 'as', 'a', 'translation', 'unit.', 'These', 'rules', 'are', 'rewrite', 'rules', 'with', 'aligned', 'pairs', 'of', 'right-hand', 'sides,', 'taking', 'the', 'following', 'form:']",33,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e66bd00f-1c74-4aad-8a4e-75f4fc1cf92b,Diverse dialogue generation with context dependent dynamic loss function,2020,Ayaka Ueyama;Yoshinobu Kano,"['Diversity-Promoting GAN: A Cross-Entropy Based Generative Adversarial Network for Diversified Text Generation', 'Auto-encoding variational bayes', 'Generating sentences from a continuous space']","['2018', '2014', '2016']","['Jingjing Xu;Xuancheng Ren;Junyang Lin;Xu Sun', 'P Diederik;Max Kingma;unk Welling', 'R Samuel;Luke Bowman;Oriol Vilnis;Andrew Vinyals;Rafal Dai;Samy Józefowicz;unk Bengio']",group,"['The', 'diversity', 'of', 'neural', 'dialogue', 'generation', 'has', 'been', 'studied', 'actively.', '<ref type=""single"">Li et al. (2016)</ref>', 'first', 'addressed', 'this', 'problem', 'using', 'Maximum', 'Mutual', 'Information', '(MMI)', 'as', 'the', 'objective', 'function', 'of', 'the', 'neural', 'model.', '<ref type=""single"">Takayama and Arase (2019)</ref>', 'used', 'Positive', 'Pointwise', 'Mutual', 'Information', '(PPMI)', 'to', 'identify', 'keywords', 'in', 'the', 'dialogue', 'corpus', 'that', 'were', 'likely', 'to', 'appear', 'both', 'in', 'response', 'utterances', 'and', 'their', 'input', 'utterances.', '<ref type=""single"">Xing et al. (2017)</ref>', 'proposed', 'a', 'model', 'that', 'uses', 'topic', 'words', 'extracted', 'from', 'conversations', 'to', 'simulate', 'human', 'prior', 'knowledge,', 'generating', 'informative', 'and', 'interesting', 'responses.', 'In', 'addition,', 'Variational', 'Au-toEncoder', '(VAE)', 'and', 'Generative', 'Adversarial', 'Network', '(GAN),', 'which', 'were', 'proposed', 'originally', 'for', 'image', 'generation,', 'have', 'also', 'been', 'applied', 'to', 'text', 'and', 'dialogue', 'generation', '<ref type=""group"">(Kingma and Welling, 2014, Bowman et al., 2016, Xu et al., 2018).</ref>', 'Although', 'GAN', 'helps', 'to', 'reduce', 'response', 'text', 'ambiguity,', 'their', 'primary', 'purpose', 'was', 'not', 'diversity.', '<ref type=""single"">Zhang et al. (2018)</ref>', 'proposed', 'and', 'demonstrated', 'the', 'effectiveness', 'of', 'Adversarial', 'Information', 'Maximization', '(AIM)', 'as', 'a', 'new', 'method', 'for', 'generating', 'informative', 'and', 'diverse', 'conversational', 'responses.', 'Their', 'work', 'also', 'resolved', 'instability', 'that', 'arose', 'when', 'training', 'the', 'GAN', 'model.']",102,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e6c849ed-c8b8-4299-a8fb-a31abeb3de36,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,['Toward memory-based translation'],['1990'],['S Sato;M Nagao'],single,"['Earlier,', 'it', 'was', 'stated', 'that', 'the', 'design', 'of', 'the', 'system', 'was', 'in', 'response', 'to', 'perceived', 'weaknesses', 'in', 'the', 'classical', 'approaches', 'to', 'MT.', 'It', 'should', 'now', 'be', 'clear', 'that', 'the', 'approach', 'will', 'avoid', 'structurepreserving', 'translation', 'as', 'a', 'first', 'choice,', 'since', 'the', 'translation', 'process', 'involves', 'no', 'analysis', 'of', 'syntactic', 'structure', 'as', 'such,', 'the', 'stratificational', 'approach', 'to', 'linguistic', 'description', 'is', 'likewise', 'absent,', 'and', 'the', 'predominantly', 'bottom-up', 'compositional', 'theory-driven', 'translation', 'algorithm', 'is', 'replaced', 'by', 'a', 'more', 'global', 'data-driven', 'process,', 'finally,', 'the', 'use', 'of', 'examples', 'rather', 'than', 'rules', 'and', 'lexicons', 'derived', 'from', ""linguists'"", 'introspection', 'mean', 'that', 'the', 'system', 'will', 'produce', 'more', 'natural', 'output', '(especially', 'where', 'source', 'and', 'target', 'are', 'structurally', 'dissimilar:', 'so-called', 'metaphors', 'and', 'idioms),', 'will', 'be', 'more', 'robust,', 'easier', 'to', 'extend', 'and', 'to', 'debug', '<ref type=""single"">([37]</ref>', ').']",120,"[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
e7075c1b-2617-42fd-8f77-dc3386473bb4,Coreference Reasoning in Machine Reading Comprehension,2021,Mingzhu Wu;Nafise Moosavi;Dan Roth;Iryna Gurevych,"['Towards debiasing NLU models from unknown biases', 'A closer look at memorization in deep networks', 'unknown']","['2020', '2017', 'unknown']","['Nafise Sadat Prasetya Ajie Utama;Iryna Moosavi;unk Gurevych', 'Devansh Arpit;Stanisław Jastrzundefinedbski;Nicolas Ballas;David Krueger;Emmanuel Bengio;Maxinder Kanwal;Tegan Maharaj;Asja Fischer;Aaron Courville;Yoshua Bengio;Simon Lacoste-Julien', 'unknown']",group,"['One', 'of', 'the', 'known', 'drawbacks', 'of', 'many', 'NLP', 'datasets', 'is', 'that', 'they', 'contain', 'artifacts.', '2', 'Models', 'tend', 'to', 'ex-ploit', 'these', 'easy-to-learn', 'patterns', 'in', 'the', 'early', 'stages', 'of', 'training', '<ref type=""group"">(Arpit et al., 2017, Liu et al., 2020, Utama et al., 2020b),</ref>', 'and', 'therefore,', 'they', 'may', 'not', 'focus', 'on', 'learning', 'harder', 'patterns', 'of', 'the', 'data', 'that', 'are', 'useful', 'for', 'solving', 'the', 'underlying', 'task.', 'As', 'a', 'result,', 'overfitting', 'to', 'dataset-specific', 'artifacts', 'limits', 'the', 'robustness', 'and', 'generalization', 'of', 'NLP', 'models.']",28,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
e735d5fc-2e9f-4bf8-87ac-8f3dfa200a0b,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties'],['2021'],['Kathleen Siminyu;Xinjian Li;Antonios Anastasopoulos;David Mortensen;Michael Marlo;Graham Neubig'],single,"['3.', 'Simple', 'errors', 'in', 'phone', 'recognition:', 'As', 'noted', 'in', '<ref type=""single"">(Siminyu et al., 2021),</ref>', 'even', 'the', 'best-trained', 'Allosaurus', 'models,', 'fine-tuned', 'on', 'languagespecific', 'data,', 'have', 'a', 'non-trivial', 'Phone', 'Error', 'Rate', '(PER).']",9,"[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
e743246e-7d87-4589-81bc-93cead60236b,Estimating word co-occurrence probabilities from pretrained static embeddings using a log-bilinear model,2022,Richard Futrell,['Adam: A method for stochastic optimization'],['2015'],['P Diederik;Jimmy Kingma;unk Ba'],single,"['Implementation', 'In', 'all', 'experiments', 'reported', 'below,', 'stochastic', 'gradient', 'descent', 'is', 'performed', 'using', 'the', 'Adam', 'algorithm', 'with', 'default', 'initial', 'learning', 'rate', '<ref type=""single"">(Kingma and Ba, 2015).</ref>', 'All', 'experiments', 'are', 'implemented', 'in', 'PyTorch', 'with', 'use', 'of', 'opt_einsum', 'to', 'compute', 'the', 'partition', 'function', '<ref type=""group"">(Smith and Gray, 2018, Paszke et al., 2019).</ref>']",20,"[2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e778e001-3a73-4842-8714-cb172cbc2710,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['unknown'],['unknown'],['unknown'],single,"['The', 'trend', 'of', 'recent', 'years', 'consists', 'in', 'training', 'large', 'pre-trained', 'language', 'models', 'on', 'ever', 'larger', 'corpora,', 'with', 'an', 'ever-increasing', 'amount', 'of', 'parameters,', 'which', 'requires', 'considerable', 'computational', 'resources', 'that', 'only', 'a', 'few', 'companies', 'and', 'institutions', 'can', 'afford.', 'For', 'example,', 'the', 'base', 'model', 'of', 'BERT', 'with', '110', 'million', 'parameters', 'was', 'pre-trained', 'on', '16', 'gigabytes', '(GB)', 'of', 'text,', 'while', 'the', 'GPT-3', 'model', '<ref type=""single"">(Brown et al., 2020)</ref>', 'was', 'pre-trained', 'on', '45', 'terabytes', '(TB)', 'of', 'text', 'and', 'has', '175', 'billion', 'parameters.']",59,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
e790ae5f-dd67-4d90-b80f-1370c88cb0d7,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Ultra-Fine Entity Typing'],['2018'],['Eunsol Choi;Omer Levy;Yejin Choi;Luke Zettlemoyer'],single,"['UFET', 'This', 'ultra-fine', 'entity', 'typing', 'dataset', 'is', 'created', 'by', '<ref type=""single"">Choi et al. (2018).</ref>', 'This', 'dataset', 'consists', 'of', '6k', 'manually', 'annotated', 'examples.', 'The', 'entity', 'mention', 'spans', 'could', 'be', 'named', 'entities,', 'nominal', 'expressions,', 'and', 'pronouns', 'while', 'Wiki-based', 'datasets', 'mostly', 'provide', 'named', 'entity', 'mention', 'spans.', 'We', 'use', '5.5k', 'examples', 'for', 'training', 'and', '500', 'examples', 'for', 'validation.', 'Note', 'that', 'because', 'our', 'goal', 'in', 'this', 'work', 'is', 'downstream', 'task', 'performance,', 'we', 'deviate', 'from', 'the', 'standard', 'train/dev/test', 'splits', 'of', '2k/2k/2k', 'in', 'favor', 'of', 'higher', 'performance.']",9,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
e7b141d5-5a9d-4923-b4bc-cd6a4566cb10,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['Named Entity Disambiguation for Noisy Text'],['2017'],['Yotam Eshel;Noam Cohen;Kira Radinsky;Shaul Markovitch;Ikuya Yamada;Omer Levy'],single,"['We', 'evaluate', 'our', 'embedding', 'approach', 'on', 'benchmark', 'tasks', 'for', 'entity', 'representations.', 'We', 'use', 'coreference', 'arc', 'prediction', '(CAP)', 'and', 'named', 'entity', 'disambiguation', 'on', 'CoNLL-YAGO,', 'two', 'tasks', 'in', 'the', 'EntEval', 'suite', '<ref type=""single"">(Chen et al., 2019),</ref>', 'as', 'well', 'as', 'entity', 'linking', 'on', 'WikilinksNED', '<ref type=""single"">(Eshel et al., 2017),</ref>', 'which', 'covers', 'broader', 'entities', 'and', 'writing', 'styles.', 'We', 'compare', 'our', 'approach', 'against', 'entity', 'representations', 'produced', 'directly', 'by', 'pre-trained', 'models.']",37,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e8271a79-0893-4952-8e30-43e5a196bf29,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['Aravec: A set of arabic word embedding models for use in arabic nlp'],['2017'],['Kareem Abu Bakr Soliman;unk Eissa;unk Samhaa R El-Beltagy'],single,"['Gridach', '(2016)', 'proposed', 'a', 'character', 'aware', 'neural', 'network', 'model', 'using', 'a', 'CRF', 'on', 'top', 'of', 'a', 'Bi-LSTM.', 'The', 'aim', 'of', 'that', 'model', 'was', 'to', 'predict', 'the', 'NER', 'tags', 'by', 'exploiting', 'word', 'and', 'character', 'embeddings.', 'In', 'our', 'approach,', 'we', 'follow', 'the', 'same', 'architecture.', 'First,', 'as', 'shown', 'in', 'Figure', '(2)', 'we', 'use', 'the', 'character', 'model', 'directly', 'to', 'individually', 'train', 'character', 'embeddings.', 'The', 'inputs', 'to', 'this', 'model', 'are', 'word', 'and', 'character', 'input', 'layers', 'as', 'indicated', 'by', 'arrow', '(A).', 'The', 'word', 'embedding', 'layer', 'takes', 'as', 'input', 'pre-trained', 'embedding', 'matrix', 'developed', 'by', '<ref type=""single"">Soliman et al. (2017),</ref>', 'transforming', 'the', 'word', 'input', 'layer', 'into', 'word', 'embeddings.', 'The', 'character', 'embedding', 'layer', 'is', 'randomly', 'initialized', 'and', 'trained', 'by', 'the', 'C-Bi-LSTM.', 'The', 'forward', 'and', 'the', 'backward', 'output', 'from', 'this', 'C-Bi-LSTM', 'is', 'concatenated', 'with', 'the', 'output', 'from', 'the', 'word', 'embedding', 'layer', 'and', 'passed', 'to', 'the', 'main', 'Bi-LSTM.', 'The', 'output', 'from', 'this', 'is', 'passed', 'to', 'a', 'Dense', 'layer', 'which', 'maps', 'the', 'output', 'of', 'the', 'main', 'Bi-LSTM', 'to', 'the', 'CRF', 'layer,', 'following', '<ref type=""single"">Lample et al. (2016).</ref>', 'After', 'training', 'the', 'character', 'model,', 'we', 'extract', 'the', 'forward', 'and', 'the', 'backward', 'output', 'of', 'the', 'C-Bi-LSTM', 'and', 'use', 'them', 'to', 'initialize', 'the', 'character', 'embedding', 'layer', 'in', 'the', 'combination', 'model.']",87,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e8507ea4-8beb-4769-b354-1e20d6cf2be9,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Multiwoz -a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling'],['2018'],['Pawel Budzianowski;Tsung-Hsien Wen;Bo-Hsiang Tseng;Iñigo Casanueva;Stefan Ultes;Milica Osman Ramadan;unk Gasic'],single,"['To', 'this', 'aim,', 'we', 'propose', 'to', 'use', 'a', 'memory', 'component', 'as', 'the', 'additional', 'vocabulary.', 'Note', 'that', 'the', 'selection', 'of', 'words', 'to', 'build', 'the', 'vocabulary', 'is', 'task', 'dependent,', 'and', 'we', 'select', 'the', 'words', 'appearing', 'in', 'state', 'annotations', 'and', 'content', 'words', '2', 'extracted', 'from', 'task', 'descriptions', 'provided', 'in', 'the', 'dataset', '<ref type=""single"">(Budzianowski et al., 2018).</ref>', 'This', 'simple', 'strategy', 'is', 'intuitive', 'and', 'turns', 'out', 'to', 'be', 'empirically', 'competitive.']",48,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e91cbfb4-4cc0-40eb-b398-05e640b28da3,Effects of Word Alignment Visualization on Post-Editing Quality & Speed †,2015,Lane Schwartz;Isabel Lacruz;Tatyana Bystrova,['Correcting automatic translations through collaborations between MT and monolingual target-language users'],['2009'],['J Albrecht;R Hwa;G Marai'],single,"['The', 'Spanish', 'language', 'news', 'articles', 'used', 'in', 'this', 'study', 'lack', 'corresponding', 'reference', 'translations.', 'Thus,', 'unlike', 'the', 'case', 'of', 'our', 'Russian', 'data,', 'no', 'matter', 'how', 'high', 'the', 'quality', 'of', 'machine', 'translations,', 'no', 'Spanish-English', 'machine', 'translation', 'segment', 'could', 'possibly', 'receive', 'a', 'score', 'of', '12.', 'For', 'Spanish-English,', 'we', 'therefore', 'follow', 'the', '10-point', 'adequacy', 'scale', 'of', '<ref type=""single"">Albrecht et al. (2009).</ref>', 'This', 'adequacy', 'scale', 'is', 'shown', 'in', 'Table', '1b', 'on', 'page', '2,', 'this', 'scale', 'is', 'very', 'similar', 'to', 'the', 'former,', 'but', 'has', 'a', 'high', 'of', '10', '(the', 'meaning', 'of', 'the', 'source', 'sentence', 'is', 'fully', 'conveyed', 'in', 'the', 'English', 'translation)', 'instead', 'of', '12.']",52,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e9677c2c-a5eb-4071-81b7-6ac4a71022bb,Diversifying Content Generation for Commonsense Reasoning with Mixture of Knowledge Graph Experts,2022,Wenhao Yu;Chenguang Zhu;Lianhui Qin;Zhihan Zhang;Tong Zhao;Meng Jiang,"['Mixture content selection for diverse sequence generation', 'Diverse beam search for improved description of complex scenes', 'Analyzing uncertainty in neural machine translation', 'unknown']","['2019', '2018', '2018', 'unknown']","['Jaemin Cho;Minjoon Seo;Hannaneh Hajishirzi', 'K Ashwin;Michael Vijayakumar;unk Cogswell;R Ramprasaath;Qing Selvaraju;Stefan Sun;David Lee;Dhruv Crandall;unk Batra', ""Myle Ott;Michael Auli;David Grangier;Marc'aurelio Ranzato"", 'unknown']",group,"['We', 'evaluated', 'the', 'performance', 'of', 'different', 'generation', 'models', 'from', 'two', 'aspects:', 'quality', '(or', 'say', 'accuracy)', 'and', 'diversity.', 'Quality', 'tests', 'the', 'appropriateness', 'of', 'the', 'generated', 'response', 'with', 'respect', 'to', 'the', 'context,', 'and', 'diversity', 'tests', 'the', 'lexical', 'and', 'semantic', 'diversity', 'of', 'the', 'appropriate', 'sequences', 'generated', 'by', 'the', 'model.', 'These', 'evaluation', 'metrics', 'have', 'been', 'widely', 'used', 'in', 'existing', 'work', '<ref type=""group"">(Ott et al., 2018, Vijayakumar et al., 2018, Zhu et al., 2018, Cho et al., 2019, Yu et al., 2021).</ref>']",56,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1]"
e97663ba-0d76-402f-a077-468b09f8d775,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Obtaining well calibrated probabilities using bayesian binning'],['2015'],['Gregory Mahdi Pakdaman Naeini;Milos Cooper;unk Hauskrecht'],single,"['We', 'investigate', 'this', 'relation', 'from', 'the', 'opposite', 'direction', 'by', 'evaluating', 'whether', 'our', 'model', '(BRIO-Mul),', 'which', 'is', 'trained', 'to', 'have', 'better', 'sequencelevel', 'performance,', 'would', 'also', 'be', 'more', 'calibrated', 'at', 'the', 'token-level', 'compared', 'with', 'the', 'baseline', 'models', 'that', 'are', 'trained', 'using', 'MLE', 'and', 'label', 'smoothing.', 'We', 'follow', 'previous', 'work', 'by', 'using', 'the', 'Expected', 'Calibration', 'Error', '<ref type=""single"">(Naeini et al., 2015)</ref>', '(ECE)', 'as', 'the', 'evaluation', 'metric', 'of', 'calibration:ECE', '=', 'M', 'm=1', '|B', 'm', '|', 'n', '|acc(B', 'm)', '−', 'conf(B', 'm', ')|', '(12)where', 'the', 'samples', 'are', 'grouped', 'into', 'M', 'equal-width', 'buckets', 'by', 'confidence', '(conf),', 'B', 'm', 'denotes', 'the', 'm-th', 'bucket,', 'and', 'n', 'is', 'the', 'total', 'number', 'of', 'samples.', 'Following', '<ref type=""single"">Wang et al. (2020),</ref>', 'we', 'evaluate', 'model', 'calibration', 'on', 'the', 'system-generated', 'summaries', 'during', 'inference', 'and', 'use', 'the', 'tercom', 'toolkit', '11', 'to', 'assign', 'labels', '(correct/incorrect)', 'to', 'the', 'system-generated', 'summaries', 'based', 'on', 'the', 'reference', 'summaries.']",53,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
e9a3bd7b-c881-4432-8787-2dbb243f26f6,Amrita_CEN_NLP@SDP2021 Task A and B,2021,Isha Indhu;Kavya Kumar;Lakshaya Karthikeyan,"['Is self-citation biased? an investigation via the lens of citation polarity, density, and location']",['2020'],['Lina Zhou;Uchechukwuka Amadi;Dongsong Zhang'],single,"['In', 'the', 'evolution', 'of', 'the', 'Information', 'Age,', 'where', 'colossal', 'amounts', 'of', 'research', 'papers', 'and', 'scientific', 'literature', 'are', 'now', 'available,', 'the', 'need', 'for', 'a', 'method', 'which', 'measures', 'the', 'scientific', 'impact', 'of', 'a', 'paper', 'has', 'become', 'paramount.', 'One', 'such', 'method', 'is', 'citation', 'analysis.', 'Citations', 'are', 'defined', 'as', 'a', 'reference', 'to', 'the', 'source', 'of', 'information', 'used', 'in', ""one's"", 'research.', 'The', 'conventional', 'approach', 'to', 'citation', 'analysis', 'involves', 'utilising', 'the', 'frequency', 'of', 'citations', '<ref type=""single"">Zhou et al. (2020)</ref>', 'while', 'treating', 'all', 'citations', 'equally.', 'This', 'methodology', 'provides', 'a', 'vague', 'or', 'even', 'inaccurate', 'overview', 'of', 'scientific', 'development.']",68,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
eaa0003b-2712-4cc8-bcc4-03088ed11239,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Characterizing and detecting hateful users on twitter'],['2018'],['Manoel Ribeiro;Pedro Calais;Yuri Santos;Virgílio Almeida;Wagner Meira'],single,"['These', 'methods', 'leverage', 'the', 'social', 'relations', '(e.g.,', 'friendship)', 'that', 'exist', 'amongst', 'users', 'in', 'a', 'social', 'network.', '<ref type=""single"">Mishra et al. (2018a)</ref>', 'constructed', 'a', 'social', 'graph', 'of', 'all', 'the', 'users', 'whose', 'tweets', 'are', 'in', 'the', 'dataset', 'of', 'Waseem', 'and', 'Hovy', '<ref type=""single"">(Waseem and Hovy, 2016).</ref>', 'Nodes', 'were', 'the', 'users', 'and', 'edges', 'the', 'follower-following', 'relationship', 'amongst', 'them', 'on', 'Twitter.', 'The', 'researchers', 'applied', 'node2vec', '<ref type=""single"">(Grover and Leskovec, 2016)</ref>', 'to', 'this', 'graph', 'to', 'generate', 'representations', 'for', 'users,', 'i.e.,', 'profiles,', 'which', 'capture', 'information', 'about', 'their', 'social', 'connections.', 'The', 'addition', 'of', 'these', 'profiles', 'on', 'top', 'of', 'linguistic', 'representations', 'of', 'tweets', 'yielded', 'significant', 'gains', 'whereby', 'the', 'F', '1', 'scores', 'on', 'the', 'racism', 'and', 'sexism', 'classes', 'increased', 'from', '72.28%', 'and', '72.09%', 'to', '75.09%', 'and', '82.75%', 'respectively.', 'The', 'gains', 'were', 'attributed', 'to', 'the', 'fact', 'that', 'the', 'profiles', 'captured', 'not', 'only', 'information', 'about', 'respective', 'communities', 'of', 'users', 'but', 'also', 'enabled', 'modeling', 'of', 'the', 'topical', 'contexts', 'amongst', 'the', 'connected', 'users.', '<ref type=""single"">Mishra et al. (2019)</ref>', 'further', 'expanded', 'on', 'this', 'work', 'by', 'adding', 'tweet', 'nodes', 'to', 'the', 'social', 'graph', 'of', '<ref type=""single"">Mishra et al. (2018a)</ref>', 'alongside', 'user', 'nodes.', 'They', 'connected', 'every', 'tweet', 'node', 'to', 'the', 'corresponding', 'user', 'who', 'posted', 'the', 'tweet.', 'They', 'then', 'used', 'a', 'graph', 'convolutional', 'network', '<ref type=""single"">(Kipf and Welling, 2017)</ref>', 'to', 'create', 'profiles', 'of', 'users', 'that', 'now', 'captured', 'their', 'linguistic', 'behavior', 'too.', 'When', 'they', 'used', 'these', 'profiles', 'together', 'with', 'the', 'linguistic', 'representations', 'of', 'tweets,', 'F', '1', 'scores', 'on', 'the', 'racism', 'and', 'sexism', 'classes', 'further', 'improved', 'to', '79.49%', 'and', '84.44%', 'respectively.', '<ref type=""single"">Ribeiro et al. (2018)</ref>', 'also', 'applied', 'graph', 'neural', 'networks,', 'Graph-Sage', '<ref type=""single"">(Hamilton et al., 2017),</ref>', 'to', 'their', 'social', 'graph', 'of', 'approximately', '100k', 'Twitter', 'users', 'to', 'generate', 'profiles', 'that', 'they', 'used', 'to', 'classify', 'the', 'users', 'as', 'hate-ful', 'or', 'normal.', 'They', 'noted', 'that', 'their', 'social', 'graph', 'based', 'method', 'outperformed', 'traditional', 'gradientboosted', 'decision', 'tree', 'classifiers', 'by', '15', 'F', '1', 'points', 'on', 'the', 'same', 'task.', 'Tredici', 'et', 'al.', '(2019)', 'constructed', 'a', 'graph', 'of', 'users', 'whose', 'tweets', 'are', 'in', 'the', 'hate-speech', 'dataset', 'of', '<ref type=""single"">Founta et al. (2018b).</ref>', 'Nodes', 'were', 'uses', 'and', 'edges', 'between', 'them', 'signified', 'that', 'one', 'user', 'retweeted', 'the', 'other.', 'They', 'used', 'Graph', 'Attention', 'Networks', '<ref type=""single"">(Veličković et al., 2018)</ref>', 'to', 'generate', 'representations', 'of', 'users', 'from', 'this', 'graph,', 'which', 'when', 'used', 'alongside', 'linguistic', 'representations,', 'provided', 'a', 'gain', 'of', '5', 'F', '1', 'points.', 'Cecillon', 'et', 'al.', '(2021)', 'worked', 'with', 'a', 'social', 'graph', 'of', 'users', 'from', 'a', 'French', 'gaming', 'website', 'where', 'weighted', 'edges', 'represented', 'the', 'intensity', 'of', 'communication', 'between', 'the', 'users.', 'Then', 'for', 'each', 'comment', 'to', 'be', 'classified,', 'the', 'researchers', 'extracted', 'the', 'ego-graph', 'of', 'its', 'author', 'and', 'created', 'a', 'feature', 'vector', 'for', 'the', 'comment', 'from', 'the', 'ego-graph', 'using', 'node2vec', 'along', 'with', 'measures', 'like', 'degree', 'centrality.', 'An', 'SVM', 'trained', 'with', 'these', 'graph-based', 'feature', 'vectors', 'reached', '89', 'F', '1', 'points', 'as', 'opposed', 'to', '81', 'F', '1', 'points', 'when', 'trained', 'with', 'content', 'features.']",218,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
eadd5eef-badc-49f1-8b09-215e5b9eef83,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['Reading wikipedia to answer opendomain questions'],['2017'],['Danqi Chen;Adam Fisch;Jason Weston;Antoine Bordes'],single,"['Open-domain', 'question', 'answering', '(QA)', 'aims', 'to', 'find', 'the', 'answers', 'to', 'natural', 'language', 'questions', 'from', 'a', 'large', 'collection', 'of', 'documents.', 'Early', 'QA', 'systems', '<ref type=""group"">(Brill et al., 2002, Dang et al., 2007, Ferrucci et al., 2010)</ref>', 'constructed', 'complicated', 'pipelines', 'consisting', 'of', 'multiple', 'components,', 'including', 'question', 'understanding,', 'document', 'retrieval,', 'passage', 'ranking', 'and', 'answer', 'extraction.', 'Recently,', 'inspired', 'by', 'the', 'advancements', 'of', 'machine', 'reading', 'comprehension', '(MRC),', '<ref type=""single"">Chen et al. (2017)</ref>', 'proposed', 'a', 'simplified', 'two-stage', 'approach,', 'where', 'a', 'traditional', 'IR', '*', 'Corresponding', 'authors.']",50,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
eb7dba90-186b-44d4-a7fe-ab5cc7e27fff,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Global inference for bridging anaphora resolution'],['2013'],['Yufang Hou;Katja Markert;Michael Strube'],single,"['Bridging', 'vs.', 'TNE', 'Bridging', 'has', 'been', 'extensively', 'studied', 'in', 'the', 'past', 'decades,', 'as', 'we', 'discuss', 'in', '§10.', 'Here,', 'we', 'explore', 'how', 'many', 'of', 'the', 'relations', 'we', 'collected', 'correspond', 'to', 'the', 'definition', 'of', 'bridging.', 'We', 'use', 'the', 'same', 'three', 'documents', 'from', 'the', 'analysis', 'described', 'above,', 'and', 'follow', 'the', 'annotation', 'scheme', 'from', 'ISNotes1.0', '<ref type=""single"">(Markert et al., 2012)</ref>', '16', 'to', 'annotate', 'them', 'for', 'bridging.', 'We', 'found', 'that', '15', 'out', 'of', 'the', '590', 'links', '(2.5%)', 'in', 'these', 'documents', 'are', 'bridging', 'links', '(i.e.,', 'meet', 'the', 'criteria', 'for', 'bridging', 'defined', 'in', 'ISNotes).', 'These', 'three', 'documents', 'contain', '104', 'NPs,', 'that', 'is,', 'the', 'ratio', 'of', 'bridging', 'links', 'per', 'NP', 'is', '0.14.', 'While', 'the', 'ratio', 'is', 'small,', 'it', 'is', 'larger', 'than', 'the', 'ratio', 'in', 'ISNotes,', 'which', 'contains', '663', 'bridging', 'links', 'out', 'of', '11K', 'annotated', 'NPs', '<ref type=""single"">(Hou et al., 2013b),</ref>', 'that', 'is,', '0.06', 'bridging', 'links', 'per', 'NP.']",123,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
ebf371c7-124b-4743-8aa8-c2e75dac012d,XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection,2020,Emily Öhman;Marc Pàmies;Kaisla Kajava;Jörg Tiedemann,['Crowdsourcing a word-emotion association lexicon'],['2013'],['M Saif;Peter Mohammad;unk Turney'],single,"['The', 'final', 'dataset', 'contained', '17,520', 'unique', 'emotion-annotated', 'subtitles', 'as', 'shown', 'in', 'table', '3.', 'In', 'addition', 'there', 'are', 'some', '6.5k', 'subtitles', 'annotated', 'as', 'neutral.', 'The', 'label', 'distribution', 'can', 'be', 'seen', 'in', 'table', '3', 'The', 'emotion', 'labels', 'are', 'surprisingly', 'balanced', 'with', 'the', 'exception', 'of', 'anger', 'and', 'anticipation,', 'which', 'are', 'more', 'common', 'than', 'the', 'other', 'labels.', 'In', 'comparison', 'with', 'one', 'of', 'the', 'most', 'well-known', 'emotion', 'datasets', 'using', 'the', 'same', 'annotation', 'scheme,', 'the', 'NRC', 'emotion', 'lexicon', '(EmoLex)', '<ref type=""single"">(Mohammad and Turney, 2013),</ref>', 'the', 'distribution', 'differs', 'somewhat.', 'Although', 'anger', 'is', 'a', 'large', 'category', 'in', 'both', 'datasets,', 'fear', 'is', 'average', 'in', 'our', 'dataset,', 'but', 'the', 'largest', 'category', 'in', 'EmoLex.', 'It', 'is', 'hard', 'to', 'speculate', 'why', 'this', 'is,', 'but', 'one', 'possible', 'reason', 'is', 'the', 'different', 'source', 'data.']",73,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
ec4fcdb8-a454-4760-a5d2-23cc233d8269,Comparison of post-editing productivity between professional translators and lay users,2014,Nora Aranberri;Gorka Labaka,"['Building a Lexicon for an English-Basque Machine translation System from Heteogeneous Wide-Coverage dictionaries', 'Reusability of Wide-Coverage Linguistic Resources in the Construction of a Multilingual Machine Translation System', 'Matxin, an open-source rule-based machine translation system for Basque', 'Hybrid Machine Translation Guided by a Rule-Based System', 'Comparing Rule-Based and Data-Driven Approaches to Spanish-to-Basque Machine Translation']","['2000', '2000', '2011', '2011', '2007']","['A Diaz De Ilarraza;A Mayor;K Sarasola', 'A Diaz De Ilarraza;A Mayor;K Sarasola', 'A Mayor;I Alegria;A Diaz De Ilarraza;G Labaka;M Lersundi;K Sarasola', 'C España-Bonet;G Labaka;A Diaz De Ilarraza;L Màrquez;K Sarasola', 'G Labaka;N Stroppa;A Way;K Sarasola']",group,"['Post-editing', 'research', 'has', 'so', 'far', 'focused', 'on', 'mainstream', 'languages.', 'An', 'added', 'challenge', 'of', 'this', 'work', 'is', 'the', 'use', 'of', 'an', 'English', 'to', 'Basque', 'MT', 'system', 'for', 'post-editing.', 'Research', 'on', 'Basque', 'MT', 'has', 'been', 'ongoing', 'for', 'a', 'few', 'years', 'now', '(Diaz', 'de', '<ref type=""group"">Ilarraza et al, 2000a, 2000b, Labaka et al., 2007, España-Bonet et al., 2011, Mayor et al., 2011).</ref>', 'However,', 'Basque', 'being', 'a', 'lowresourced', 'language,', 'researchers', 'and', 'developers', 'have', 'found', 'themselves', 'with', 'limited', 'resources', 'to', 'build', 'competitive', 'MT', 'systems', 'and', 'automated', 'translation', 'has', 'not', 'been', 'included', 'within', 'the', 'translation', 'processes', 'of', 'local', 'LSPs', 'yet.', 'To', 'our', 'knowledge,', 'this', 'is', 'the', 'first', '(open)', 'productivity', 'experiment', 'done', 'for', 'the', 'English', 'to', 'Basque', 'translation', 'direction.', '<ref type=""single"">Laurenzi et al. (2013)</ref>', 'pointed', 'out', 'the', 'existence', 'of', 'many', 'communities', 'that', 'could', 'benefit', 'greatly', 'from', 'machine', 'translation', 'but,', 'as', 'in', 'the', 'case', 'presented', 'in', 'this', 'work,', 'have', 'not', 'yet', 'started', 'to', 'use', 'it,', 'as', 'authors', 'suggest,', 'either', 'due', 'to', 'lack', 'of', 'awareness', 'or', 'barriers', 'to', 'adoption.', 'The', 'work', 'in', '<ref type=""single"">Laurenzi et al. (2013)</ref>', 'presents', 'a', 'feasibility', 'study', 'to', 'introduce', 'MT', 'coupled', 'with', 'post-editing', 'in', 'local', 'and', 'regional', 'health', 'departments', 'in', 'the', 'United', 'States.', 'It', 'highlights', 'a', 'number', 'of', 'requirements', 'the', 'translation', 'platform', 'should', 'address,', 'such', 'as', 'being', 'intuitive', 'and', 'easy', 'to', 'install,', 'allowing', 'users', 'to', 'share', 'ongoing', 'and', 'completed', 'jobs.', 'Our', 'work', 'builds', 'on', 'this', 'first', 'feasibility', 'study', 'and', 'goes', 'a', 'step', 'forward', 'by', 'assessing', 'the', 'actual', 'translation', 'performance.', 'We', 'identify', 'a', 'suitable', 'tool', 'for', 'our', 'users', 'that', 'is', 'intuitive,', 'easy', 'to', 'access', 'and', 'allows', 'sharing', 'translation', 'resources', 'such', 'as', 'translation', 'memories', '(TM)', 'or', 'specialized', 'MT', 'engines', 'and', 'measure', 'productivity', 'gain,', 'while', 'comparing', 'it', 'with', 'the', 'performance', 'of', 'professional', 'translators.']",41,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ec7ccbf9-e7ec-46dc-9dc5-c30dd0a94ea8,Word Formation in Computational Linguistics,2002,Pius Ten Hacken,['Grundriss der deutschen Grammatik'],['1998'],['Peter Eisenberg'],single,"['In', 'an', 'Item', 'and', 'Process', 'approach', 'stem', 'changes', 'are', 'dealt', 'with', 'via', 'rules.', 'Since', 'stem', 'changes', 'in', 'German', 'are', 'not', 'regular', 'or', 'predictable', 'we', 'follow', '<ref type=""single"">Fuhrhop (1998)</ref>', 'and', '<ref type=""single"">Eisenberg (1998)</ref>', 'on', 'listing', 'the', 'forms', 'that', 'an', 'element', 'may', 'take.', 'These', 'forms', 'are', 'called', 'word', 'formation', 'stem', 'forms.', 'Free', 'and', 'bound', 'morphological', 'elements', 'have', 'one', 'or', 'more', 'derivation', 'stem', 'form(s)', 'and', 'one', 'or', 'more', 'compounding', 'stem', 'form(s).', 'Very', 'often', 'these', 'stem', 'forms', 'look', 'just', 'like', 'the', 'regular', 'stem.', 'Consider', 'the', 'examples', 'in', 'Table', '4', 'Here', 'you', 'can', 'see', 'that', 'the', 'suffix', '-keit', 'has', 'no', 'derivation', 'stem', 'form.', 'That', 'means', 'that', 'it', 'cannot', 'be', 'used', 'in', 'further', 'derivation', '(it', 'is', 'a', 'so-called', 'closing', 'suffix,', 'see', '<ref type=""single"">Aronoff &amp, Fuhrhop 2001</ref>', ').', 'It', 'has', 'a', 'compounding', 'stem', 'form,', 'however.', 'The', 'word', 'formation', 'stem', 'forms', 'are', 'propagated', 'in', 'complex', 'words', 'using', 'these', 'elements:', 'each', 'complex', 'word', 'ending', 'in', '-keit,', 'for', 'example,', 'will', 'automatically', 'have', 'a', 'compounding', 'stem', 'form', 'ending', 'in', '-keits.', '17', 'Such', 'an', 'approach', 'minimized', 'the', 'ambiguities', 'that', 'stem', 'changes', 'can', 'cause.', 'However,', 'one', 'has', 'to', 'acquire', 'all', 'the', 'word', 'formation', 'stem', 'forms.', 'For', 'our', 'lexicon', 'this', 'is', 'done', 'semi-automatically', 'as', 'described', 'in', '<ref type=""single"">Heid, Säuberlich &amp, Fitschen (2002).</ref>']",27,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
eca92735-123a-498e-8eeb-2a0e95161ac0,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Tree-adjoining grammars'],['1997'],['A Joshi;Y Schabes'],single,"['Thee', 'Adjoining', 'Grammars', '(TAG)', '<ref type=""single"">[8]</ref>', 'and', 'Linear', 'Indexed', 'Grammars', '(LIG)', '<ref type=""single"">[7 ]</ref>', 'are', 'extensions', 'of', 'Con', 'text', 'Free', 'Grammars', '(CFG).', 'Thee', 'adjoining', 'grammars', 'use', 'trees', 'instead', 'of', 'productions', 'as', 'primary', 'representing', 'structure', 'and', 'seems', 'to', 'be', 'adequate', 'to', 'describe', 'syntactic', 'phenomena', 'occurring', 'in', 'nat', 'ural', 'language,', 'due', 'to', 'their', 'extended', 'domain', 'of', 'locality', 'and', 'to', 'their', 'ability', 'for', 'factoring', 'recursion', 'from', 'the', 'domain', 'of', 'dependencies.', 'Linear', 'indexed', 'grammars', 'associate', 'a', 'stack', 'of', 'indices', 'with', 'each', 'non-terminal', 'symbol,', 'with', 'the', 'restriction', 'that', 'the', 'indices', 'stack', 'of', 'the', 'head', 'non-terminal', 'of', 'each', 'pro', 'duction', '(the', 'fa', 'ther)', 'can', 'be', 'inherited', 'by', 'at', 'most', 'one', 'body', 'non-terminal', '(the', 'dependent', 'child)', 'while', 'the', 'other', 'stacks', 'must', 'have', 'a', 'bounded', 'stack', 'size.']",4,"[1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ecd9b935-3ee4-46e1-8a03-9d48ff7e372d,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Distributional semantics in technicolor'],['2012'],['Elia Bruni;Gemma Boleda;Marco Baroni;Nam-Khanh Tran'],single,"['To', 'investigate', 'the', 'relationship', 'of', 'the', 'above', 'defined', 'relatedness', 'measures,', 'we', 'compute', 'correlations', 'between', 'the', 'score', 'they', 'assign', 'to', '100.000', 'random', 'word', 'pairs.', 'As', 'Table', '1', 'shows,', 'none', 'of', 'the', 'measures', 'are', 'near', 'equivalent,', 'but', 'they', 'have', 'nonzero', 'correlations.', 'They', 'also', 'show', 'high', 'positive', 'correlations', 'with', 'MEN', '<ref type=""single"">(Bruni et al., 2012)</ref>', 'and', 'WS-353', 'relatedness', '<ref type=""single"">(Agirre et al., 2009),</ref>', 'as', 'can', 'be', 'seen', 'in', 'Table', '2,', 'which', 'is', 'hopeful', 'for', 'their', 'usability', 'as', 'relatedness', 'in', 'Codenames', 'agents.']",47,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
ed0c6f7f-6df2-4a97-84ab-48e31f8c1b38,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,"['Multi-way, multilingual neural machine translation with a shared attention mechanism']",['2016'],['O Firat;K Cho;Y Bengio'],single,"['Figure', '1:', 'Pipeline', 'of', 'NMT', 'system', 'with', 'Factored', 'output', 'Multiple', 'output', 'neural', 'networks', 'were', 'previously', 'pro-posed', '<ref type=""single"">[16]</ref>', 'using', 'scheduled', 'decoders', 'with', 'multiple', 'source', 'and', 'target', 'languages.', 'In', 'contrast', 'to', 'this,', 'the', 'FNMT', 'system', 'simultaneously', 'produces', 'several', 'outputs.', 'Given', 'both', 'outputs', '(lemma', 'and', 'factors)', 'and', 'linguistic', 'resources,', 'the', 'final', 'surface', 'form', 'is', 'easily', 'generated.']",16,"[0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ed38a348-392a-4574-b1ee-6122ed6afc7e,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['Apologies and remedial exchanges. The Hague. Mouton'],['1983'],['Marion Owen'],single,"['A', 'three-fold', 'analysis', 'of', 'the', 'selected', 'keywords', 'was', 'done.', 'The', 'semantics', 'of', 'the', 'words', 'was', 'studied', 'by', 'using', 'WordNet.', 'In', 'dialogue', 'acts', 'such', 'as', 'apologizing,', 'thanking,', 'or', 'expressing', 'sympathy,', 'affective', 'language', 'is', 'often', 'employed', 'to', 'represent', 'and', 'convey', 'psychological', 'attitudes', '<ref type=""single"">(Novielli et al, 2013).</ref>', 'Also,', 'there', 'is', 'what', 'is', 'called', 'a', ""'heartfelt"", ""apology'"", 'as', 'against', ""'routine"", 'apology', '<ref type=""single"">(Owen, 1983</ref>', ').', 'Hence,', 'it', 'was', 'decided', 'to', 'further', 'explore', 'the', 'sentiments', 'and', 'emotions', 'associated', 'with', 'the', 'keywords.', 'The', 'sentiments', 'were', 'studied', 'using', 'SentiWordNet', 'and', 'the', 'emotion', 'labels', 'were', 'determined', 'through', 'WordNet-Affect.', 'The', 'analysis', 'and', 'conclusions', 'thus', 'drawn', 'are', 'presented', 'below.']",54,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ee0ec525-b395-41ce-9057-8fa92bdcd10d,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Influence: The psychology of persuasion'],['2007'],['B Robert;unk Cialdini'],single,"['Communities.', 'There', 'can', 'be', 'scenarios', 'where', 'whole', 'communities', 'of', 'users', 'on', 'a', 'platform', 'may', 'be', 'indulging', 'in', 'abusive', 'behavior,', 'e.g.,', 'by', 'widely', 'circulating', 'an', 'abusive', 'view', 'against', 'a', 'demographic', 'group', 'based', 'on', 'shared', 'beliefs,', 'common', 'stereotypes', 'or', 'other', 'homophilic', 'ties.', 'In', 'such', 'cases,', 'just', 'taking', 'down', 'specific', 'instances', 'of', 'abusive', 'language', 'and', 'providing', 'justifications', 'individually', 'to', 'the', 'respective', 'users', 'may', 'not', 'prove', 'effective.', 'Users', 'may', 'continue', 'to', 'promote', 'the', 'abusive', 'view,', 'defying', 'the', 'norms', 'of', 'the', 'platform', 'in', 'the', 'process', 'and', 'ignoring', 'the', 'justifications', 'given', 'to', 'them.', 'The', 'reason', 'for', 'this', 'comes', 'from', 'social', 'influence', 'theory', 'which', 'says', 'that', 'a', ""user's"", 'behavior', 'is', 'affected', 'by', 'three', 'broad', 'varieties', 'of', 'social', 'influence', '<ref type=""single"">(Kelman, 1958),</ref>', 'i.e.,', 'compliance,', 'identification,', 'and', 'internalization.', 'Compliance', 'occurs', 'when', 'the', 'user', 'behaves', 'a', 'certain', 'way', 'so', 'as', 'to', 'appear', 'in', 'congruence', 'with', 'opinions', 'of', 'others', 'who', 'matter', 'to', 'them,', 'identification', 'occurs', 'when', 'the', 'user', 'adopts', 'behaviors', 'in', 'order', 'to', 'associate', 'with', 'others', 'they', 'admire,', 'and', 'internalization', 'is', 'when', 'the', 'user', 'adopts', 'the', 'values', 'and', 'beliefs', 'of', 'others.', 'The', 'influences', 'occur', 'because', 'of', 'two', 'needs', 'of', 'the', 'user,', 'the', 'need', 'to', 'be', 'liked', '(normative)', 'and', 'the', 'need', 'to', 'be', 'right', '(informational).', 'In', 'order', 'to', 'fulfill', 'the', 'latter,', 'people', 'may', 'accept', 'the', 'three', 'varieties', 'of', 'influence', 'when', 'there', 'is', 'lack', 'of', 'information,', 'a', 'concept', 'known', 'as', 'social', 'proof', '<ref type=""single"">(Cialdini, 2007).</ref>']",217,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1]"
ee872191-3ed6-47f9-b616-f1f304b01bf3,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Denoising neural machine translation training with trusted data and online data selection'],['2018'],['Wei Wang;Taro Watanabe;Macduff Hughes;Tetsuji Nakagawa;Ciprian Chelba'],single,"['One', 'of', 'the', 'most', 'exciting', 'outcomes', 'is', 'the', 'deteriorated', 'performance', 'of', 'the', 'multilingual', 'models', 'using', 'BT', 'data,', 'as', 'we', 'usually', 'expect', 'that', 'added', 'backtranslated', 'texts', 'would', 'benefit', 'performance.', 'Using', 'tags', '<ref type=""single"">(BT[t])</ref>', 'to', 'differentiate', 'which', 'data', 'is', 'synthetic', 'or', 'not', 'is', 'only', 'a', 'simple', 'step', 'to', 'address', 'this', 'issue,', 'however,', 'there', 'could', 'be', 'evaluated', 'more', 'informed', 'strategies', 'for', 'denoising', 'or', 'performing', 'online', 'data', 'selection', '<ref type=""single"">(Wang et al., 2018).</ref>']",63,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
eea1a9c4-6cbe-4ddd-98a2-681ad43b6985,Interactive multilingual text generation for a monolingual user,1992,Harold Somers,"['Repetitions processing using a metric space and the angle of similarity', 'Text-translation alignment', 'Analogical Modeling of Language']","['1990', '1988', '1989']","['J Carroll', 'M Kay;M Röscheisen', 'R Skousen']",group,"['EBMT', 'proceeds', 'by', 'finding', 'suitable', 'examples', 'in', 'the', 'database', 'and', 'then', ""'recombining'"", 'them', 'appropriately.', 'Key', 'factors', 'are', 'therefore', 'the', 'efficient', 'retrieval', 'of', 'texts', 'from', 'the', 'database', 'which', 'are', 'sufficiently', 'similar', 'to', 'the', 'given', 'text', '<ref type=""group"">([8, 22, 40]</ref>', '),', 'and', 'the', 'alignment', 'of', 'translation', 'pairs,', 'given', 'a', 'bilingual', 'corpus', '<ref type=""single"">([6,9,10,12,23]</ref>', ').']",34,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3]"
eedb26e0-ee97-4f69-9b19-97fcea3f5db6,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Fusion of acoustic and linguistic information using supervised autoencoder for improved emotion recognition'],['2021'],['Bogdan Vlasenko;Ravishankar Prasad;Mathew Magimai.-Doss unk'],single,"['Outside', 'of', 'speech', 'recognition', 'focused', 'work,', '<ref type=""single"">Shen et al. (2020)</ref>', '(and', 'other', 'researchers', 'cited', 'therein)', 'attempt', 'to', '""fuse""', 'audio', 'and', 'text', 'at', 'the', 'word', 'level', 'for', 'emotion', 'recognition.', 'They', 'introduce', 'another', 'architecture', 'that', 'internally', 'represents', 'both', 'audio', 'and', 'text.', 'However,', 'the', 'so-called', 'WISE', 'framework', 'relies', 'on', 'speech', 'recognition', 'to', 'generate', 'the', 'text', 'corresponding', 'to', 'audio', 'frames', 'in', 'real-time.', 'The', 'current', 'work', 'explicitly', 'avoids', 'reliance', 'on', 'speech', 'recognition.', 'The', '2021', 'Multimodal', 'Sentiment', 'Analysis', '(MuSe)', 'challenge', 'continues', 'this', 'vein', 'of', 'research', 'integrating', 'audio,', 'video,', 'text,', 'and', 'physiology', 'data', 'in', 'an', 'emotion', 'recognition', 'task', '<ref type=""single"">(Stappen et al., 2021).</ref>', 'Contributions', 'to', 'this', 'challenge,', 'such', 'as', '<ref type=""single"">Vlasenko et al. (2021),</ref>', 'introduce', 'a', 'variety', 'of', 'ways', 'to', '""fuse""', 'audio', 'and', 'text', 'inputs.', 'However,', 'these', 'contributions', 'are', 'squarely', 'focused', 'on', 'emotion/sentiment', 'analysis', 'and', 'do', 'not', 'propose', 'methods', 'for', 'flexible,', 'phonetic', 'language', 'models.', '<ref type=""single"">Lakhotia et al. (2021)</ref>', 'introduced', 'functionality', 'for', '""textless""', 'NLP.', 'They', 'explored', 'the', 'possibility', 'of', 'creating', 'a', 'dialogue', 'system', 'from', 'only', 'audio', 'inputs', '(i.e.,', 'without', 'text).', 'As', 'part', 'of', 'this', 'system,', 'language', 'models', 'are', 'directly', 'trained', 'on', 'audio', 'units', 'without', 'any', 'text.', 'This', 'advances', 'the', 'state-of-the-art', 'with', 'regard', 'to', 'self-supervised', 'speech', 'methods,', 'but', 'it', 'does', 'not', 'provide', 'the', 'flexibility', 'in', 'audio', 'and/or', 'text', 'language', 'modeling', 'introduced', 'here.']",95,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
eedc2ab3-7226-4adb-846d-56c74047e42b,Decoding Part-of-Speech from Human EEG Signals,2022,Alex Murphy;Bernd Bohnet;Ryan Mcdonald;Uta Noppeney,['Decoding dynamic brain patterns from evoked responses: A tutorial on multivariate pattern analysis applied to time series neuroimaging data'],['2017'],['Tijl Grootswagers;Susan Wardle;Thomas Carlson'],single,"['To', 'minimise', 'confounds', 'arising', 'from', 'the', 'preceding', 'word', 'in', 'the', 'sentence,', 'we', 'balanced', 'the', 'test', 'set', 'with', 'respect', 'to', 'the', 'open/closed', 'class', 'status', 'of', 'the', 'previous', 'word.', 'Similarly,', 'we', 'controlled', 'the', 'decoding', 'of', 'word', 'frequency', 'for', 'word', 'length,', 'and', 'the', 'analysis', 'of', 'word', 'length', 'for', 'word', 'frequency,', 'and', 'both', 'analyses', 'for', 'open/closed', 'class', 'and', 'sentence', 'position.', '2', 'shows', 'the', 'mean', 'accuracy', 'values', '(averaged', 'across', '10', 'seed', 'points)', 'from', 'the', 'test', 'set', '(centred', 'on', 'the', 'last', 'bin', 'of', 'each', 'time', 'window', '<ref type=""single"">(Grootswagers et al., 2017))</ref>', 'with', '±', '68%', 'CI.', 'The', 'classification', 'responses', 'for', 'the', 'test', 'set', 'from', 'the', 'model', 'that', 'performed', 'best', 'on', 'the', 'dev', 'set', 'were', 'entered', 'into', 'a', 'two-sided', 'binomial', 'test,', 'separately', 'for', 'each', 'time', 'window.', 'Solid', 'lines', 'in', 'Figure', '2', 'above', 'the', 'decoding', 'accuracy', 'time', 'courses', 'indicate', 'time', 'points', 'that', 'were', 'significant', 'at', '(p', '&lt,', '0.05)', 'False', 'Discovery', 'Rate', '(FDR)', 'corrected', 'for', 'multiple', 'comparisons', '<ref type=""single"">(Rouam, 2013)</ref>', 'across', 'time', '(i.e.', '160', 'tests).']",80,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ef6a7075-81fc-486b-900e-17700bba307e,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['Reinforced mnemonic reader for machine reading comprehension'],['2018'],['Minghao Hu;Yuxing Peng;Zhen Huang;Xipeng Qiu;Furu Wei;Ming Zhou'],single,"['The', 'interaction', 'layer', 'is', 'the', 'core', 'element', 'of', 'the', 'architecture', 'for', 'which', 'several', 'kinds', 'attention', 'mechanisms', 'has', 'been', 'developed', 'to', 'improve', 'the', 'QA', 'matching', 'process', 'such', 'as', 'bi-attention', '<ref type=""single"">(Seo et al., 2017),</ref>', 'co-attention', '<ref type=""group"">(Xiong et al., 2017 , 2018 ), multi-level inter-attention (Huang et al., 2018)</ref>', 'or', 're-attention', '<ref type=""single"">(Hu et al., 2018),</ref>', 'to', 'name', 'just', 'a', 'few.']",33,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2]"
efd4b71f-acc4-48fa-bed5-474e63370c02,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['SpanBERT: Improving pre-training by representing and predicting spans'],['2020'],['Mandar Joshi;Danqi Chen;Yinhan Liu;Daniel Weld;Luke Zettlemoyer;Omer Levy'],single,"['Technical', 'Details', 'All', 'neural', 'models', 'are', 'trained', 'using', 'cross-entropy', 'loss', 'and', 'optimized', 'with', 'Adam', '(Kingma', 'and', 'Ba,', '2015),', 'using', 'the', 'AllenNLP', 'library', '<ref type=""single"">(Gardner et al., 2018).</ref>', 'We', 'train', 'using', 'a', '1e', '−', '5', 'learning', 'rate', 'for', '40', 'epochs,', 'with', 'early', 'stopping', 'based', 'the', 'F1', 'metric', 'on', 'the', 'development', 'set.', 'We', 'use', 'SpanBERT', '<ref type=""single"">(Joshi et al., 2020)</ref>', 'as', 'the', 'pretrained', 'MLM,', 'as', 'it', 'was', 'found', 'to', 'work', 'well', 'on', 'span-based', 'tasks', 'with', 'its', 'base', 'and', 'the', 'large', 'variants.', 'The', 'anchor', 'and', 'complement', 'encoding', 'MLPs', 'have', 'one', '500-dim', 'hidden', 'layer', 'and', 'output', '500dim', 'representations.', 'The', 'prediction', 'MLPs', 'have', 'one', '100-dim', 'hidden', 'layer.', 'All', 'MLPs', 'use', 'the', 'ReLU', 'activation.', 'We', 'used', 'the', 'same', 'hyperparameters', 'for', 'all', 'baselines', 'and', 'did', 'not', 'tune', 'them.', '18']",49,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f019f2b4-aa79-4238-8c85-ccbf4ebf96fc,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['Developments of Swahili resources for an automatic speech recognition system'],['2012'],['Hadrien Gelas;Laurent Besacier;Francois Pellegrino'],single,"['For', 'swh', 'pre-training', 'data', 'we', 'use:', '(i)', 'the', '""Language', 'Modeling', 'Data', 'for', 'Swahili""', 'dataset', '(Shikali', 'and', 'Refuoe,', '2019)', 'hosted', 'on', 'Hugging', 'Face', '(which', 'we', 'refer', 'to', 'as', 'the', '""HF', 'Swahili""', 'data', 'set),', 'and', '(ii)', 'the', 'ALFFA', 'speech', 'dataset', '<ref type=""single"">(Gelas et al., 2012).</ref>', 'For', 'ALFFA', 'data', 'we', 'process', 'both', 'the', 'audio', 'files', '(using', 'Allosaurus)', 'and', 'the', 'original', '""gold""', 'text', 'transcriptions', '(using', 'Epitran).']",38,"[2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
f04ecbbd-4328-45d5-b4f1-4eba8d91459e,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,"['Language (technology) is power: A critical survey of ""bias"" in NLP']",['2020'],['unk Su Lin;Solon Blodgett;Hal Barocas;Iii Daumé;Hanna Wallach'],single,"['The', 'reward', 'and', 'risk', 'of', 'using', 'generative', 'models', 'in', 'tasks', 'related', 'to', 'job', 'search', 'are', 'debated.', 'While', 'some', 'argue', 'for', 'the', 'value', 'of', 'text', 'generation', 'and', 'summarisation', 'technologies', 'to', 'promote', 'inclusive', 'hiring', '<ref type=""single"">(Somers et al., 1997),</ref>', 'others', 'suggest', 'model', 'biases', 'towards', 'occupational', 'associations', 'pose', 'a', 'risk', 'of', 'their', 'use.', 'Specifically,', 'research', 'has', 'uncovered', 'gender', 'bias', 'in', 'large-scale', 'language', 'models', 'by', 'examining', 'the', 'strength', 'of', 'statistical', 'association', 'between', 'a', 'given', 'gender', 'and', 'a', 'set', 'of', 'jobs', 'using', 'prompts', 'such', 'as', '""the', 'woman', 'works', 'as', 'a', '[token]""', '<ref type=""group"">(Sheng et al., 2019, Kirk et al., 2021).</ref>', 'These', 'associations', 'lead', 'to', 'representational', 'harms', '<ref type=""single"">(Blodgett et al., 2020),</ref>', 'by', 'perpetuating', 'the', 'notion', 'of', 'gendered', 'roles', 'in', 'the', 'labour', 'force', 'and', 'entrenching', 'stereotypes', 'such', 'as', 'women', 'possessing', 'more', 'caregiving', 'qualities.', 'However,', 'it', 'is', 'unclear', 'how', 'these', 'model', 'biases', 'translate', 'directly', 'to', 'language', 'generation', 'in', 'applied', 'downstream', 'tasks,', 'that', 'is,', 'how', 'they', 'may', 'give', 'rise', 'to', 'allocational', 'harms.', 'One', 'example', 'of', 'such', 'a', 'task', 'is', 'the', 'generation', 'of', 'job', 'advertisements', '(ads)', 'which', 'exemplifies', 'the', 'risk', 'of', 'allocational', 'harms', 'because', 'candidates', 'from', 'a', 'given', 'group', 'may', 'be', 'discouraged', 'to', 'apply', 'as', 'a', 'result', 'of', 'biased', 'language.', 'Prior', 'research', 'has', 'demonstrated', 'gendered', 'wording', 'in', 'job', 'ads', 'can', 'act', 'as', 'an', 'institutional-level', 'mechanism', 'to', 'entrench', 'traditional', 'gender', 'divisions', '<ref type=""single"">(Gaucher et al., 2011).</ref>', '1', 'Gender', 'bias', 'in', 'natural', 'language', 'processing', '(NLP)', 'has', 'been', 'more', 'widely-discussed', '<ref type=""group"">(Sun et al., 2019, Blodgett et al., 2020, Lu et al., 2020),</ref>', 'with', 'some', 'specific', 'work', 'documenting', 'bias', 'of', 'generative', 'language', 'models', '<ref type=""group"">(Solaiman et al., 2019, Brown et al., 2020, Kirk et al., 2021).</ref>', 'Early', 'debiasing', 'attempts', 'in', 'NLP', 'focused', 'on', 'word', 'embeddings', '<ref type=""group"">(Bolukbasi et al., 2016, Kurita et al., 2019),</ref>', 'though', 'the', 'efficacy', 'of', 'these', 'methods', 'has', 'been', 'challenged', '<ref type=""single"">(Gonen and Goldberg, 2019).</ref>', 'Some', 'recent', 'research', 'seeks', 'to', 'align', 'generative', 'language', 'models', 'with', 'societally-desirable', 'values', '<ref type=""single"">(Solaiman and Dennison, 2021),</ref>', 'reduce', 'various', 'dimensions', 'of', 'groupdirected', 'bias', '<ref type=""group"">(Liu et al., 2021b, Smith and Williams, 2021)</ref>', 'and', 'decrease', 'risk', 'of', 'toxicity', '<ref type=""single"">(Ouyang et al., 2022).</ref>', 'There', 'is', 'less', 'research', 'on', 'how', 'gender', 'bias', 'in', 'generative', 'models', 'affects', 'applied', 'tasks,', 'and', 'to', 'our', 'knowledge,', 'no', 'prior', 'work', 'on', 'bias', 'in', 'generated', 'job', 'ads.', 'Furthermore,', 'there', 'is', 'a', 'lack', 'of', 'research', 'advising', 'on', 'how', 'industry', 'practitioners', 'can', 'effectively', 'and', 'cheaply', 'debias', 'outputs', 'whilst', 'retaining', 'quality,', 'accuracy', 'and', 'realism.']",89,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f0c0a129-1e3b-42d4-b107-a0d043e90e6f,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Bert: Pre-training of deep bidirectional transformers for language understanding'],['2018'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Bidirectional', 'Encoder', 'Representations', 'from', 'Transformers', '(BERT)', '<ref type=""single"">(Devlin et al., 2018)</ref>', 'is', 'a', 'deep', 'learning', 'model', 'for', 'general-purpose', 'language', 'representations.', 'BERT', 'is', 'often', 'used', 'as', 'the', 'backbone', 'model', 'for', 'several', 'NLP', 'tasks', 'like', 'semantic', 'analysis,', 'question', 'answering,', 'and', 'named', 'entity', 'recognition.', 'The', 'bidirectional', 'transformer', 'used', 'in', 'BERT', 'has', 'a', 'deeper', 'sense', 'of', 'language', 'context', 'and', 'generates', 'intricate', 'semantic', 'feature', 'representations.', 'These', 'representations', 'are', 'learned', 'through', 'a', 'pre-training', 'step', 'using', 'Next', 'Sentence', 'Prediction', '(NSP)', 'and', 'Masked', 'Language', 'Modelling', '(MLM)', 'as', 'pretext', 'tasks', 'and', 'transferred', 'to', 'the', 'downstream', 'NLP', 'tasks.', 'The', 'goal', 'of', 'the', 'Next', 'Sentence', 'Prediction', 'task', 'is', 'to', 'identify', 'whether', 'the', 'two', 'input', 'sentences', 'are', 'consecutive', 'or', 'not.', 'In', 'Masked', 'Language', 'Modelling,', 'BERT', 'is', 'trained', 'to', 'predict', 'randomly', 'masked', 'words', 'in', 'a', 'sentence.', 'The', 'Transformer', 'network', 'receives', 'a', 'sequence', 'of', 'tokens', 'as', 'input', 'and', 'utilizes', 'the', 'attention', 'mechanism', 'to', 'learn', 'the', 'contextual', 'relationships', 'between', 'words', 'in', 'a', 'text.', 'These', 'relationships', 'can', 'then', 'be', 'used', 'to', 'extract', 'high-quality']",6,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f100b61d-f511-48e3-b577-779b391db96f,Rapid development of RBMT systems for related languages,2007,Jernej Vicic,['TnT -a statistical part-of-speech tagger'],['2000'],['Thorsten Brants'],single,"['The', 'TNT', 'tagger', '<ref type=""single"">(Brants, 2000),</ref>', 'which', 'was', 'used', 'in', 'the', 'process,', 'relies', 'heavily', 'on', 'context', 'to', 'disambiguate', 'ambiguities.', 'In', 'a', 'word', 'list', 'each', 'word', 'is', 'treated', 'separately,', 'there', 'is', 'no', 'context,', 'so', 'the', 'word', 'tagging', 'quality', 'is', 'lower', 'than', 'the', 'values', 'on', 'running', 'text.']",3,"[1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f210640e-8557-4dbf-a2e3-23d65f44e1a5,Embed More Ignore Less (EMIL): Exploiting Enriched Representations for Arabic NLP,2020,Ahmed Younes;Julie Weeds,['unknown'],['unknown'],['unknown'],single,"['The', 'authors', 'also', 'built', 'their', 'own', 'linguistic', 'resources,', 'ANERcorp', '(an', 'annotated', 'corpus)', 'and', 'ANERgazet', '(a', 'gazetteer),', 'which', 'have', 'become', 'benchmarks', 'for', 'evaluation.', 'At', 'this', 'time,', 'work', 'was', 'also', 'done', 'on', 'incorporating', 'POS', 'information', 'to', 'improve', 'NER.', 'For', 'example,', '<ref type=""single"">Benajiba and Rosso (2007)</ref>', 'proposed', 'ANERsys', '2.0,', 'where', 'they', 'used', 'a', 'POS', 'tagger', 'and', 'a', 'two', 'step', 'approach', 'to', 'enhance', 'the', 'performance', 'of', 'ANERsys', '1.0.']",38,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
f265f8da-598f-4b3d-a9ce-b1d85810e598,DeepBlueAI at SemEval-2021 Task 1: Lexical Complexity Prediction with A Deep Ensemble Approach,2021,Chunguang Pan;Bingyan Song;Shengguang Wang;Zhipeng Luo,"['Deep learning architecture for complexword identification', 'Nilc at cwi 2018: Exploring feature engineering and feature learning']","['2018', '2018']","['Dirk De Hertog;Anaïs Tack', 'Nathan Hartmann;Leandro Borges Dos Santos']",group,"['In', '<ref type=""group"">CWI 2018 (Yimam et al., 2018),</ref>', 'a', 'multilingual', 'dataset', 'was', 'provided', 'containing', 'English,', 'German,', 'Spanish', 'and', 'French', 'and', 'there', 'were', 'two', 'subtasks:', 'binary', 'classification', 'and', 'probabilistic', 'classification.', 'The', 'submitted', 'systems', 'mainly', 'use', 'traditional', 'machine', 'learning', 'classifiers(e.g.', 'SVM,', 'Random', 'Forests)', 'with', 'features', '<ref type=""group"">(Butnaru and Ionescu, 2018, Kajiwara and Komachi, 2018),</ref>', 'deep', 'learning', 'methods', '<ref type=""group"">(Hartmann and Dos Santos, 2018, De Hertog and Tack, 2018)</ref>', 'and', 'ensemble', 'methods', '<ref type=""group"">(Gooding and Kochmar, 2018, Aroyehun et al., 2018).</ref>', 'More', 'recently,', '<ref type=""single"">(Gooding and Kochmar, 2019)</ref>', 'propose', 'a', 'new', 'perspective', 'by', 'treating', 'CWI', 'as', 'a', 'sequence', 'labeling', 'task', 'that', 'can', 'detect', 'both', 'complex', 'words', 'and', 'phrases.', 'All', 'these', 'methods', 'are', 'different', 'from', 'ours', 'which', 'utilizes', 'heterogeneous', 'PLMs', 'with', 'various', 'training', 'strategies.']",41,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 1, 1, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f288c696-1dbe-4551-9bbc-555110eea7e6,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['Dimensionality reduction by learning an invariant mapping'],['2006'],['Raia Hadsell;Sumit Chopra;Yann Lecun'],single,"['the', 'candidate', 'summaries.', 'In', 'other', 'words,', 'we', 'give', 'the', 'abstractive', 'model', 'a', 'dual', 'role:', 'as', 'a', 'generation', 'model,', 'it', 'generates', 'the', 'output', 'summaries', 'in', 'an', 'autoregressive', 'way,', 'as', 'an', 'evaluation', 'model,', 'it', 'can', 'be', 'used', 'to', 'score', 'the', 'quality', 'of', 'candidate', 'summaries', 'by', 'estimating', 'a', 'probability', 'distribution', 'over', 'candidate', 'outputs.', 'The', 'generation', 'model', 'is', 'trained', 'using', 'the', 'standard', 'MLE', 'loss,', 'but', 'to', 'train', 'the', 'evaluation', 'model', 'we', 'introduce', 'a', 'contrastive', 'loss', '<ref type=""single"">(Hadsell et al., 2006)</ref>', 'defined', 'over', 'different', 'candidate', 'summaries', 'generated', 'by', 'pre-trained', 'abstractive', 'models', '(Fig.', '1),', 'following', 'previous', 'work', 'on', 'ranking-based', 'or', 'contrastive', 'learning', '<ref type=""group"">(Hopkins and May, 2011, Zhong et al., 2020, Liu et al., 2021b).</ref>']",71,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
f3cc896a-b43b-43c4-b1c1-14dcf7217f09,Looking for a Handsome Carpenter! Debiasing GPT-3 Job Advertisements,2022,Conrad Borchers;Dalia Sara Gala;Benjamin Gilburt;Eduard Oravkin;Wilfried Bounsi;Yuki Asano;Hannah Kirk,['Attenuating bias in word vectors'],['2019'],['Sunipa Dev;Jeff Phillips'],single,"['Gender', 'bias', 'in', 'language', 'is', 'complex', 'and', 'no', 'single', 'measure', 'can', 'capture', 'all', 'presentations', 'of', 'societal', 'harms', '<ref type=""single"">(Blodgett et al., 2020).</ref>', 'Several', 'methodologies', 'to', 'measure', 'and', 'mitigate', 'bias', 'cannot', 'be', 'applied', 'in', 'our', 'setting', 'given', 'the', 'lack', 'of', 'public', 'access', 'to', ""GPT-3's"", 'model', 'architecture', 'or', 'training', 'dataset,', 'and', 'the', 'enormous', 'resources', 'needed', 'to', 'retrain', 'the', 'model', 'from', 'scratch.', 'In', 'particular,', 'this', 'includes', 'training', 'data', 'augmentation', '<ref type=""single"">(Sen et al., 2021),</ref>', 'adjusting', 'model', 'behaviour', 'via', 'adversarial', 'learning', '<ref type=""group"">(Zhang et al., 2018, Berg et al., 2022),</ref>', 'and', 'amending', 'model', 'embeddings', '<ref type=""single"">(Dev and Phillips, 2019).</ref>']",74,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1]"
f3fffb9e-8839-4b93-b7f1-3bc8d779addd,drsphelps at SemEval-2022 Task 2: Learning idiom representations using BERTRAM,2022,Dylan Phelps,"['Distributed representations of words and phrases and their compositionality', 'Unsupervised compositionality prediction of nominal compounds']","['2013', '2019']","['Tomas Mikolov;Ilya Sutskever;Kai Chen;Greg Corrado;Jeff Dean', 'Silvio Cordeiro;Aline Villavicencio;Marco Idiart;Carlos Ramisch']",group,"['Adopting', 'the', 'idiom', 'principle', '<ref type=""single"">(Sinclair, 1991)</ref>', 'to', 'produce', 'a', 'single', 'token', 'representation', 'for', 'MWEs', 'has', 'been', 'used', 'widely', 'within', 'static', 'embedding', 'distributional', 'semantic', 'models', '<ref type=""group"">(Mikolov et al., 2013, Cordeiro et al., 2019).</ref>', 'Within', 'contextualised', 'representation', 'models,', '<ref type=""single"">Hashempour and Villavicencio, 2020</ref>', 'show', 'that', 'the', 'contextualised', 'representations', 'produced', 'by', 'context2vec', '<ref type=""single"">(Melamud et al., 2016)</ref>', 'and', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'models', 'can', 'be', 'used', 'to', 'differentiate', 'between', 'idiomatic', 'and', 'literal', 'uses', 'of', 'MWEs.', 'However,', 'the', 'MWEs', 'are', 'only', 'represented', 'by', 'one', 'token', 'in', 'the', 'input,', 'before', 'being', 'broken', 'into', 'many', 'tokens', 'using', 'BERTs', 'word', 'piece', 'tokenizer.', 'Tayyar', 'Madabushi', 'et', 'al.,', '2021', 'add', 'a', 'token', 'to', 'the', 'BERT', 'embedding', 'matrix', 'and', 'shows', 'that', 'this', 'method', 'improves', 'representations', 'through', 'increased', 'performance', 'on', 'their', 'proposed', 'STS', 'task.', 'The', 'embeddings', 'they', 'add', 'to', 'BERT', 'are', 'randomly', 'initialised,', 'however,', 'and', 'only', 'trained', 'during', 'the', 'fine-tun', 'step', 'on', 'limited', 'data.', 'Form', 'embeddings', 'are', 'then', 'learnt', 'using', 'trained', 'ngram', 'character', 'embeddings,', 'before', 'being', 'passed', 'with', 'a', 'context', 'into', 'a', 'BERT', 'model.', 'The', 'output', 'of', 'the', 'BERT', 'model', 'forms', 'the', 'embedding', 'for', 'that', 'specific', 'context.', 'To', 'incorporate', 'knowledge', 'from', 'many', 'contexts', 'an', 'attention', 'layer', 'is', 'applied', 'over', 'the', 'outputs', 'for', 'each', 'context', 'to', 'get', 'the', 'final', 'embedding.', 'There', 'exist', 'other', 'models', 'to', 'produce', 'effective', 'embeddings', 'from', 'a', 'small', 'number', 'of', 'contexts', '<ref type=""group"">(Zhao et al., 2018, Pinter et al., 2017),</ref>', 'however,', 'BERTRAM', 'is', 'the', 'only', 'model', 'that', 'is', 'non-bag-ofwords', 'and', 'incorporates', 'both', 'form', 'and', 'context', 'information', 'when', 'creating', 'the', 'embedding.']",23,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f466aa70-6b4e-41e6-8d38-f5c6b80095ce,Amrita_CEN_NLP@SDP2021 Task A and B,2021,Isha Indhu;Kavya Kumar;Lakshaya Karthikeyan,['Overview of the 2020 wosp 3c citation context classification task'],['2020'],['N Suchetha;David Kunnath;Bikash Pride;Petr Gyawali;unk Knoth'],single,"['Though', 'the', 'importance', 'of', 'categorizing', 'scientific', 'literature', 'according', 'to', 'context', 'is', 'apparent,', 'the', 'reported', 'amount', 'of', 'research', 'that', 'has', 'been', 'carried', 'out', 'is', 'insufficient.', 'Along', 'with', 'a', 'classification', 'model,', '<ref type=""single"">Teufel et al. (2006)</ref>', 'also', 'proposed', 'an', 'annotation', 'scheme', 'for', 'the', 'categorization', 'of', 'the', 'citations.', '12', 'classes', 'were', 'considered', 'for', 'annotation.', 'From', '116', 'articles,', '2829', 'citation', 'samples', 'were', 'gathered.', 'These', 'were', 'used', 'to', 'train', 'the', 'machine', 'learning', 'model.', '113K', 'algorithms', 'were', 'used', 'for', 'classification', 'with', 'hand-engineered', 'features.', 'One', 'of', 'such', 'features', 'was', 'cue', 'phrases.', 'Features', 'such', 'as', 'patternbased', 'features,', 'topic-based', 'features,', 'and', 'prototypical', 'argument', 'features', 'were', 'used', 'by', 'D.', '<ref type=""single"">Jurgens Jurgens et al. (2018)</ref>', 'to', 'separate', 'the', 'documents', 'into', 'its', '6', 'corresponding', 'classes.', 'The', 'RandomForest', 'algorithm', 'was', 'used', 'for', 'classification.', '<ref type=""single"">Cohan et al. (2019)</ref>', 'also', 'utilised', 'Glove,', 'ELMO', 'word', 'embedding', 'features,', 'and', 'Bi-LSTM', 'with', 'attention', 'models', 'to', 'aid', 'in', 'the', 'classification', 'of', 'the', 'citations.', '<ref type=""single"">Kunnath et al. (2020)</ref>', 'organized', 'the', 'first', 'shared', 'task', 'on', 'citation', 'classification', 'in', '2020,', 'where', 'different', 'teams', 'came', 'up', 'with', 'different', 'approaches', 'to', 'solve', '3c', 'classification', 'problem.']",133,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
f4a88566-0d6e-434f-b41b-0c9f26dbd8af,Themes in the work of Margaret Masterman,1988,Yorick Wilks,['unknown'],['unknown'],['unknown'],single,"['What', 'MMB', 'sought', 'was', 'a', 'compromise', 'system', 'of', 'meaning', 'representation', 'for', 'MT:', 'one', 'that', 'was', 'fundamental', 'to', 'the', 'process', 'of', 'translation,', 'but', 'did', 'not', 'constitute', 'a', 'detailed', 'representation', 'of', 'all', 'the', 'relevant', 'knowledge', 'of', 'the', 'world.', 'She', 'believed', 'there', 'was', 'a', 'level', 'of', 'representation,', 'linguistic', 'if', 'you', 'will,', 'probably', 'vague', 'as', 'well,', 'but', 'which', 'was', 'sufficient', 'for', 'MT.', 'In', 'that', 'sense,', 'she', 'totally', 'denied', 'the', 'assumption', 'behind', ""Bar-Hillel's"", 'critique', 'of', '<ref type=""single"">MT (1953)</ref>', '-which', 'was', 'taken', 'up', 'by', 'some', 'artificial', 'intelligence', 'researchers', 'afterwards', '(although', 'not,', 'of', 'course,', 'the', 'same', 'ones', 'as', 'referred', 'to', 'in', 'the', 'last', 'paragraph)', '-that', 'MT', 'and', 'language', 'understanding', 'in', 'general', 'did', 'require', 'the', 'explicit', 'representation', 'of', 'all', 'world', 'knowledge.', 'This', 'position', 'of', 'hers', 'cannot', 'be', 'separated', 'from', 'her', 'quasi-idealist', 'belief', '(see', 'further', 'below)', 'that', 'world', 'knowledge', 'cannot', 'be', 'represented', 'independently', 'of', 'some', 'language,', 'and', 'hence', 'that', 'any', 'true', 'distinction', 'between', 'meaning', 'representation', 'and', 'the', 'representation', 'of', 'world', 'knowledge', 'is,', 'ultimately,', 'misconceived', '(see', 'her', 'discussion', 'of', 'Whorf', '<ref type=""single"">[Masterman, 1961]</ref>', ').', 'The', 'only', 'dispute', 'can', 'be', 'about', 'the', ""'level'"", 'or', ""'grain'"", 'of', 'representation', 'that', 'particular', 'acts', 'of', 'translation', 'require.']",70,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f4beca71-804e-4845-9657-796efa73b421,Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation,2021,Chong Zhang;Jieyu Zhao;Huan Zhang;Kai-Wei Chang;Cho-Jui Hsieh,['Counterfactual fairness'],['2017'],['J Matt;Joshua Kusner;Chris Loftus;Ricardo Russell;unk Silva'],single,"['Furthermore,', 'we', 'extend', 'the', 'double', 'perturbation', 'framework', 'to', 'evaluate', 'counterfactual', 'biases', '<ref type=""single"">(Kusner et al., 2017)</ref>', '(§4)', 'in', 'English.', 'When', 'the', 'test', 'dataset', 'is', 'small,', 'our', 'framework', 'can', 'help', 'improve', 'the', 'evaluation', 'robustness', 'by', 'revealing', 'the', 'hidden', 'biases', 'not', 'directly', 'shown', 'in', 'the', 'test', 'dataset.', 'Intuitively,', 'a', 'fair', 'model', 'should', 'make', 'the', 'same', 'prediction', 'for', 'nearly', 'identical', 'examples', 'referencing', 'different', 'groups', '<ref type=""single"">(Garg et al., 2019)</ref>', 'with', 'different', 'protected', 'attributes', '(e.g.,', 'gender,', 'race).', 'In', 'our', 'evaluation,', 'we', 'consider', 'a', 'model', 'biased', 'if', 'substituting', 'tokens', 'associated', 'with', 'protected', 'attributes', 'changes', 'the', 'expected', 'prediction,', 'which', 'is', 'the', 'average', 'prediction', 'among', 'all', 'examples', 'within', 'the', 'neighborhood.', 'For', 'instance,', 'a', 'toxicity', 'classifier', 'is', 'biased', 'if', 'it', 'tends', 'to', 'increase', 'the', 'toxicity', 'if', 'we', 'substitute', 'straight', '→', 'gay', 'in', 'an', 'input', 'sentence', '<ref type=""single"">(Dixon et al., 2018).</ref>', 'In', 'the', 'experiments,', 'we', 'evaluate', 'the', 'expected', 'sentiment', 'predictions', 'on', 'pairs', 'of', 'protected', 'tokens', '(e.g.,', '(he,', 'she),', '(gay,', 'straight)),', 'and', 'demonstrate', 'that', 'our', 'method', 'is', 'able', 'to', 'reveal', 'the', 'hidden', 'model', 'biases.']",11,"[0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f4c3474d-756f-412b-96c2-8605a2896d17,"Peru is Multilingual, Its Machine Translation Should Be Too?",2021,Arturo Oncevay,['Neural machine translation with a polysynthetic low resource language'],['2020'],['E John;Richard Ortega;Kyunghyun Castro Mamani;unk Cho'],single,"['Pre-training', 'We', 'pre-trained', 'two', 'MT', 'models', 'with', 'the', 'Spanish-English', 'language-pair', 'in', 'both', 'directions.', 'We', 'did', 'not', 'include', 'an', 'agglutinative', 'language', 'like', 'Finnish', '<ref type=""single"">(Ortega et al., 2020b)</ref>', 'for', 'two', 'reasons:', 'it', 'is', 'not', 'a', 'must', 'to', 'consider', 'highly', 'related', 'languages', 'for', 'effective', 'transfer', 'learning', '(e.g.', 'English-German', 'to', 'English-Tamil', '<ref type=""single"">(Bawden et al., 2020)</ref>', '),', 'and', 'we', 'wanted', 'to', 'translate', 'the', 'English', 'side', 'of', 'en-aym,', 'en-quy', 'and', 'en-quz', 'to', 'augment', 'their', 'correspondent', 'Spanish-paired', 'datasets.', 'The', 'en→es', 'and', 'es→en', 'models', 'achieved', '34.4', 'and', '32.3', 'BLEU', 'points,', 'respectively,', 'in', 'the', 'newsdev2013', 'set.']",22,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f51d6772-3f8a-4f44-85c4-422de48e14a7,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Generating natural language adversarial examples'],['2018'],['Moustafa Alzantot;Yash Sharma;Ahmed Elgohary;Bo-Jhang Ho;Mani Srivastava;Kai-Wei Chang'],single,"['The', 'benefits', 'of', 'a', 'New', 'York', 'Subway', 'system', 'is', 'that', 'a', 'person', 'can', 'get', 'from', 'A', 'to', 'B', 'without', 'being', 'stuck', 'in', 'traffic', 'and', 'subway', 'trains', 'are', 'faster', 'than', 'buses.', '(Prediction:', 'Negative)', 'Natural', 'Language', 'Inference', '<ref type=""single"">(McCoy et al., 2019),</ref>', 'synonym', 'substitutions', '<ref type=""single"">(Alzantot et al., 2018),</ref>', 'or', 'adding', 'adversarial', 'sentences', 'for', 'QA', '<ref type=""single"">(Jia and Liang, 2017).</ref>', 'More', 'recent', 'work', 'on', 'testing', ""models'"", 'behaviour', 'using', '<ref type=""single"">CheckList (Ribeiro et al., 2020)</ref>', 'also', 'used', 'a', 'pre-defined', 'series', 'of', 'test', 'types,', 'e.g.,', 'adding', 'negation,', 'temporal', 'change,', 'and', 'switching', 'locations/person', 'names.', 'However,', 'for', 'safe', 'deployment', 'of', 'NLP', 'models', 'in', 'the', 'real', 'world,', 'in', 'addition', 'to', 'predefining', 'a', 'small', 'or', 'limited', 'set', 'of', 'patterns', 'which', 'the', 'model', 'could', 'be', 'vulnerable', 'to,', 'it', 'is', 'also', 'important', 'to', 'proactively', 'discover', 'and', 'identify', ""models'"", 'unrobust', 'regions', 'automatically', 'and', 'comprehensively.']",38,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f5503cf8-0586-4384-a9af-619ff3e4f385,"Phone-ing it in: Towards Flexible, Multi-Modal Language Model Training using Phonetic Representations of Data",2022,Colin Leong;Daniel Whitenack,['unknown'],['unknown'],['unknown'],single,"['For', 'fine-tuning', 'the', 'downstream', 'NER', 'task,', 'we', 'use', 'the', 'MasakhaNER', 'data', 'set', '<ref type=""single"">(Adelani et al., 2021).</ref>', 'As', 'with', 'other', 'text-based', 'data', 'sets,', 'we', 'transform', 'the', 'NER', 'sample', 'with', 'Epitran', 'to', 'map', 'the', 'samples', 'into', 'the', 'phonetic', 'representation.']",12,"[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
f5a38cce-af2a-4d85-806d-b86709c0053b,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Representing general relational knowledge in ConceptNet 5'],['2012'],['Robyn Speer;Catherine Havasi'],single,"['connection', 'according', 'to', 'the', 'knowledge', 'graph', 'ConceptNet5', '<ref type=""single"">(Speer and Havasi, 2012),</ref>']",7,"[2, 2, 2, 1, 1, 1, 1, 1]"
f5a49007-d18b-445d-bc63-6a2ceb50dc66,MuCoT: Multilingual Contrastive Training for Question-Answering in Low-resource Languages,2022,Karthik Gokul;Abhishek Kumar;Gehlot Singh;Shaji Sahal;Karthik Mullappilly;unk Nandakumar,['Exploiting similarities among languages for machine translation'],['2013'],['Tomas Mikolov;V Quoc;Ilya Le;unk Sutskever'],single,"['First,', 'we', 'observe', 'from', 'Table', '2', 'that', 'just', 'having', 'intermediate', 'SQuAD', 'pre-training', 'in', 'English,', 'improves', 'the', 'overall', 'Jaccard', 'score', 'significantly', 'from', '0.44', 'to', '0.5.', 'Furthermore,', 'we', 'fine-tune', 'by', 'dividing', 'translated', 'and', 'transliterated', 'data', 'into', 'Indo-Aryan', 'and', 'Dravidian', 'language', 'families', 'to', 'study', 'how', 'translated', 'and', 'transliterated', 'pairs', 'serve', 'as', 'supervised', 'cross-lingual', 'signals', 'when', 'languages', 'share', 'semantics', 'and', 'structure', '<ref type=""single"">(Mikolov et al., 2013).</ref>', 'Although', 'transliteration', 'improves', 'the', 'Jaccard', 'scores', 'in', 'certain', 'cases', 'compared', 'to', 'the', 'baseline,', 'the', 'trend', 'is', 'not', 'consistent.', 'Moreover,', 'contrastive', 'training', 'does', 'not', 'help', 'in', 'the', 'case', 'of', 'transliteration', 'as', 'shown', 'in', 'Table', '3.', 'This', 'could', 'be', 'because', 'the', 'QA', 'model', 'is', 'pre-trained', 'only', 'with', 'regular', 'text', 'and', 'not', 'with', 'transliteration', 'style', 'text.']",57,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f5a6696c-7497-4c37-845a-0e116e2dc31d,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,['On NMT search errors and model errors: Cat got your tongue?'],['2019'],['Felix Stahlberg;Bill Byrne'],single,"['Increasing', 'the', 'Beam', 'Width', 'While', 'theoretically', 'a', 'larger', 'beam', 'width', '(i.e.', 'the', 'number', 'of', 'candidates', 'maintained', 'during', 'beam', 'search)', 'would', 'allow', 'more', 'candidates', 'to', 'be', 'considered', 'and', 'therefore', 'increase', 'the', 'upper', 'bound', 'of', 'the', 'performance,', 'in', 'practice', 'model', 'performance', 'may', 'be', 'lower', 'if', 'the', 'beam', 'width', 'is', 'too', 'large.', 'The', 'reason', 'for', 'this', 'phenomenon', 'is', 'closely', 'related', 'to', 'the', 'low', 'sequence-level', 'coordination', 'of', 'the', 'generator.', 'Specifically,', 'increasing', 'the', 'beam', 'width', 'may', 'introduce', 'candidates', 'with', 'lower', 'quality', '<ref type=""single"">(Stahlberg and Byrne, 2019),</ref>', 'and', 'the', 'generator', 'may', 'not', 'be', 'able', 'to', 'differentiate', 'them', 'from', 'high-quality', 'candidates.', 'In', 'Tab.', '5,', 'we', 'compare', 'the', 'performance', 'of', 'the', 'pre-trained', 'BART', 'and', 'our', 'model', '(BRIO-Mul)', 'with', 'different', 'beam', 'widths', 'used', 'during', 'inference.', 'We', 'observe', 'that', 'the', 'performance', 'of', 'BART', 'goes', 'down', 'as', 'the', 'beam', 'width', 'increases.', 'On', 'the', 'other', 'hand,', 'our', 'model', 'is', 'able', 'to', 'achieve', 'better', 'performance', 'with', 'a', 'larger', 'number', 'of', 'beams,', 'demonstrating', 'that', 'our', 'training', 'method', 'can', 'improve', 'the', 'coordination', 'of', 'the', 'model', 'by', 'encouraging', 'the', 'model', 'to', 'assign', 'estimated', 'probabilities', 'to', 'candidate', 'summaries', 'wellcorrelated', 'with', 'their', 'quality.', 'Training', 'with', 'Different', 'Evaluation', 'Metrics', 'In', 'the', 'previous', 'experiments,', 'we', 'used', 'ROUGE', 'as', 'the', 'evaluation', 'metric', 'to', 'define', 'the', 'target', 'ordering', 'of', 'the', 'candidate', 'summaries', '(Eq.7).', 'To', 'evaluate', 'our', ""method's"", 'performance', 'beyond', 'ROUGE,', 'we', 'use', 'a', 'model-based', 'semantic', 'similarity', 'metric,', 'BERTScore', '<ref type=""single"">(Zhang* et al., 2020),</ref>', '7', 'as', 'the', 'evaluation', 'metric', 'M', 'in', 'Eq.7', 'to', 'compare', 'the', 'performance', 'of', 'different', 'candidate', 'summaries.', 'Then,', 'we', 'trained', 'another', 'version', 'of', 'BRIO-Mul', 'based', 'on', 'the', 'order', 'of', 'candidate', 'summaries', 'calculated', 'by', 'BERTScore.']",76,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f5f89e3d-8963-4b5c-a3b0-b7fb58af2738,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['unknown'],['unknown'],['unknown'],single,"['First', 'and', 'foremost,', 'we', 'observed', 'the', 'fact', 'that,', 'due', 'to', 'a', 'mix', 'of', 'factors', 'such', 'as', 'greater', 'media', 'vigilance,', 'and', 'the', 'viral', 'nature', 'of', 'social', 'media,', 'there', 'is', 'certainly', 'an', 'increased', 'willingness', 'to', 'issue', 'public', 'apologies', 'in', 'India', '<ref type=""single"">(Kaul et.al, 2015).</ref>', 'However,', 'apologies', 'available', 'in', 'the', 'public', 'domain', 'are', 'still', 'limited,', 'and', 'so', 'we', 'cannot', 'draw', 'any', 'generalizations', 'from', 'them.', 'Hence,', 'we', 'can', 'put', 'forth', 'certain', 'trends', 'and', 'suggestions', 'which', 'need', 'to', 'be', 'tested', 'further', 'on', 'a', 'much', 'bigger', 'corpus.']",38,"[0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f66c7d9c-d8ab-42a9-b67f-1252d2a123a7,A Parameter-Based Message-Passing Parser for MT of Korean and English,1994,Bonnie Dorr;Jye-Hoon Lee;Sungki Suh,['Principle-based parsing for machine translation'],['1991'],['B Dorr'],single,"['This', 'paper', 'presents', 'an', 'efficient,', 'implemented', 'approach', 'to', 'cross-linguistic', 'parsing', 'for', 'interlingual', 'MT.', 'Our', 'design', 'is', 'based', 'on', 'Government-Binding', '(GB)', 'Theory', '<ref type=""group"">(Chomsky, 1981, Haegeman, 1991, van Riemsdijk and Williams, 1986).</ref>', 'One', 'of', 'the', 'drawbacks', 'to', 'alternative', 'GBbased', 'parsing', 'approaches', 'is', 'that', 'they', 'generally', 'adopt', 'a', 'filter-based', 'paradigm,', 'generating', 'all', 'possible', 'candidate', 'structures', 'of', 'the', 'sentence', 'that', 'satisfy', 'Xbar', 'theory,', 'and', 'then', 'subsequently', 'applying', 'filters', 'to', 'eliminate', 'those', 'structures', 'that', 'violate', 'GB', 'principles.', '(See,', 'for', 'example,', '<ref type=""single"">Abney (1989),</ref>', '<ref type=""single"">Correa (1991),</ref>', '<ref type=""single"">Dorr (1991),</ref>', '<ref type=""single"">Fong (1991),</ref>', '<ref type=""single"">and Frank 1990.)</ref>', 'The', 'current', 'approach', 'provides', 'an', 'alternative', 'to', 'filter-based', 'designs', 'which', 'avoids', 'these', 'difficulties', 'by', 'applying', 'principles', 'to', 'descriptions', 'of', 'structures', 'without', 'actually', 'building', 'the', 'structures', 'themselves.', 'In', 'effect,', 'structure', 'building', 'is', 'deferred', 'until', 'the', 'descriptions', 'satisfy', 'all', 'principles.']",69,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f6ee4f73-7dcd-4ff3-aeaa-ac18dbfbce87,Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets,2021,Lan Zhang;Victor Prokhorov;Ehsan Shareghi,['Generating sentences from a continuous space'],['2016'],['R Samuel;Luke Bowman;Oriol Vilnis;Andrew Vinyals;Rafal Dai;Samy Józefowicz;unk Bengio'],single,"['Training', 'Configuration.', 'We', 'adopt', 'the', 'VAE', 'architecture', 'from', '<ref type=""single"">(Bowman et al., 2016),</ref>', 'using', 'a', 'LSTM', 'encoder-decoder.', 'Unless', 'stated', 'otherwise,', '(word', 'embedding,', 'LSTM,', 'representation', 'embedding)', 'dimensionalities', 'for', 'YNOC', 'and', 'POS', 'datasets', 'are', '(4D,', '32D,', '4D)', 'and', '(4D,', '64D,', '8D),', 'respectively,', 'and', 'we', 'use', 'the', 'latent', 'code', 'to', 'initialize', 'the', 'hidden', 'state', 'of', 'the', 'LSTM', 'decoder.', 'We', 'use', 'greedy', 'decoding.', 'All', 'models', 'are', 'trained', 'from', 'multiple', 'random', 'starts', 'using', 'Adam', '(Kingma', 'and', 'Ba,', '2015)', 'with', 'learning', 'rate', '0.001', 'for', '10', 'epochs.', 'We', 'set', 'batch', 'size', 'to', '256', 'and', '512', 'for', 'YNOC', 'and', 'POS,', 'respectively.']",8,"[0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
f76fa34a-843b-4a53-829f-75a57c020b30,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,2022,Tianlu Wang;Rohit Sridhar;Diyi Yang;Xuezhi Wang,['Learning to deceive with attention-based explanations'],['2020'],['Danish Pruthi;Mansi Gupta;Bhuwan Dhingra;Graham Neubig;Zachary Lipton'],single,"['Task', '2:', 'Occupation', 'classification.', 'Following', '<ref type=""single"">Pruthi et al. (2020),</ref>', 'we', 'use', 'the', 'biographies', '<ref type=""single"">(De-Arteaga et al., 2019)</ref>', 'to', 'predict', 'whether', 'the', 'occupation', 'is', 'a', 'surgeon', 'or', 'physician', '(non-surgeon).', 'The', 'training', 'data', 'consists', 'of', '17,', '629', 'biographies', 'and', 'the', 'dev', 'set', 'contains', '2,', '519', 'samples.']",5,"[0, 0, 3, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
f79c701a-2a82-4e76-a7d0-1672497e2fb2,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['ImageNet: A Large-Scale Hierarchical Image Database'],['2009'],['J Deng;W Dong;R Socher;L.-J Li;K Li;L Fei-Fei'],single,"['Trained', 'on', 'ImageNet', '<ref type=""single"">(Deng et al., 2009)</ref>', 'YOLO', '<ref type=""single"">(Redmon et al., 2015)</ref>', 'x', 'Trained', 'on', 'ImageNet', '<ref type=""single"">(Deng et al., 2009)</ref>', 'EfficientNet', 'B7', '<ref type=""single"">(Tan and Le, 2019)</ref>', 'x', 'Trained', 'on', 'ImageNet', '<ref type=""single"">(Deng et al., 2009)</ref>', 'Table', '1:', 'List', 'of', 'pre-trained', 'models', 'registered', 'by', 'all', 'participants', 'of', 'ReINTEL', 'challenge', 'in', '2020.']",3,"[3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
f7e6993f-8d3d-48ba-a4c3-b1d113bf0777,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,"['unknown', 'Rethinking attention with performers', 'Random feature attention']","['unknown', '2021', '2021']","['unknown', 'Valerii Krzysztof Marcin Choromanski;David Likhosherstov;Xingyou Dohan;Andreea Song;Tamas Gane;Peter Sarlos;Jared Hawkins;Afroz Davis;Lukasz Mohiuddin;David Kaiser;Lucy Belanger;Adrian Colwell;unk Weller', 'Hao Peng;Nikolaos Pappas;Dani Yogatama;Roy Schwartz;Noah Smith;Lingpeng Kong']",group,"['Top-k', 'attention', 'is', 'a', 'highly', 'accurate', 'approximation', 'to', 'vanilla', 'attention', 'and', 'is', 'a', 'plug-andplay', 'replacement', 'at', 'both', 'multi-head', 'attention', 'and', 'feed-forward', 'layers', 'of', 'a', 'Transformer.', 'This', 'is', 'unlike', 'past', 'attention', 'variants', '<ref type=""group"">(Katharopoulos et al., 2020, Choromanski et al., 2021, Peng et al., 2021)</ref>', 'that', 'require', 'an', 'expensive', 'corrective', 'pretraining', 'stage', 'to', 'adjust', 'model', 'weights', 'to', 'the', 'new', 'variant,', 'which', 'can', 'be', 'prohibitive', 'for', 'large', 'models.', 'We', 'show', 'top-k', 'attention', 'can', 'replace', 'vanilla', 'attention', 'in', 'a', 'zero-shot', 'inference', 'setup', 'and', 'at', 'finetuning', 'time', 'without', 'any', 'corrective', 'pre-training.']",31,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f867655e-b5f0-4cd0-8136-1c24bbb4ce07,Multitasking Framework for Unsupervised Simple Definition Generation,2022,Cunliang Kong;Yun Chen;Hengyuan Zhang;Liner Yang;Erhong Yang,['Making monolingual sentence embeddings multilingual using knowledge distillation'],['2020'],['Nils Reimers;Iryna Gurevych'],single,"['Semantic', 'Similarity', 'In', 'addition', 'to', 'the', 'BLEU', 'score,', 'we', 'use', 'the', 'sentence-transformers', 'toolkit', '<ref type=""single"">(Reimers and Gurevych, 2020)</ref>', 'to', 'convert', 'the', 'generated', 'definitions', 'and', 'references', 'into', 'sentence', 'vectors,', 'and', 'calculate', 'cosine', 'similarity', 'between', 'them.']",13,"[0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
f9297770-ed8c-4eef-b0ed-a84aabb59127,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['End-to-End Learning of Visual Representations from Uncurated Instructional Videos'],['2020'],['Antoine Miech;Jean-Baptiste Alayrac;Lucas Smaira;Ivan Laptev;Josef Sivic;Andrew Zisserman'],single,"['There', 'is', 'a', 'person', 'sitting', 'on', 'a', 'horse.', 'he', 'is', 'holding', 'a', 'horse', 'thread', 'and', 'he', 'is', 'wearing', 'a', 'cap.', 'there', 'are', 'flags,', 'board', 'on', 'the', 'left', 'side.', 'we', 'can', 'see', 'in', 'the', 'background', 'sky,', 'trees.', 'Contrastive', 'Learning', 'Recently,', 'contrastive', 'learning', 'has', 'been', 'widely', 'studied', 'in', 'unsupervised', 'representation', 'learning', 'for', 'vision,', '<ref type=""group"">(He et al., 2020, Chen et al., 2020, Grill et al., 2020, Caron et al., 2020, Chen and He, 2020),</ref>', 'language', '<ref type=""group"">(Mikolov et al., 2013, Saunshi et al., 2019, Chi et al., 2020, Fang and Xie, 2020, Giorgi et al., 2020, Kong et al., 2020, Gunel et al., 2021),</ref>', 'or', 'multi-modal', '<ref type=""group"">(Sun et al., 2019, Luo et al., 2020).</ref>', 'The', 'goal', 'is', 'to', 'learn', 'semantic', 'representation', 'between', 'two', 'views', 'by', 'allowing', 'the', 'positive', 'sample', 'to', 'be', 'similar', '(in', 'semantic', 'space)', 'and', 'negatives', 'to', 'be', 'dissimilar', 'semantically', 'simultaneously.', 'CLIP', '<ref type=""single"">(Radford et al.)</ref>', 'and', 'MIL-NCE', '<ref type=""single"">(Miech et al., 2020)</ref>', 'has', 'demonstrated', 'the', 'effectiveness', 'for', 'learning', 'the', 'semantic', 'mapping', 'between', 'vision', 'and', 'language.', 'Previous', 'attempts', 'mainly', 'exploit', 'the', 'InfoNCE', '<ref type=""single"">(Oord et al., 2018)</ref>', 'objective', 'to', 'maximize', 'a', 'lower', 'bound', 'of', 'the', 'mutual', 'information.', 'This', 'paper', 'extends', 'the', 'multimodal', 'contrastive', 'learning', 'between', 'the', 'trace', 'in', 'the', 'image', 'and', 'captioning', 'sentence.', 'In', 'the', 'same', 'image,', 'they', 'correspond', 'to', 'each', 'other', 'semantically.', 'This', 'motivates', 'us', 'to', 'design', 'a', 'contrastive', 'loss', 'for', 'better', '2022', 'alignment', 'between', 'the', 'trace', 'and', 'language.']",89,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f93665c3-5c07-429e-914c-d30824fa3f03,SemEval 2022 Task 12: Symlink Linking Mathematical Symbols to their Descriptions,2022,Viet Lai;Amir Pouran;Ben Veyseh;Franck Dernoncourt;Thien Nguyen,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Ping', 'and', 'Chi', '(2022)', '(AN(L)P)', 'participated', 'in', 'the', 'Entity', 'Extraction', 'only.', 'They', 'finetuned', 'a', 'BERTlarge', 'model', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'for', 'each', 'domain.', 'For', 'cs.ai', 'domain,', 'they', 'used', 'data', 'from', 'cs.ai', 'only,', 'whereas,', 'for', 'the', 'other', 'domain,', 'they', 'augmented', 'the', 'in-domain', 'data', 'with', 'the', 'data', 'from', 'cs.ai.']",16,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
f9477533-842c-4699-a7a5-3bc1b576f679,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['Tree pushdown automata'],['1985'],['K Schimpf;J Gallier'],single,"['If', 'the', 'pattern', 'tree', 'we', 'want', 'to', 'complete', 'is', 'only', 'the', 'most', 'embedded-that', 'is,', 'it', 'is', 'not', 'possible', 'to', 'overlap', 'gNCNs-this', 'corresponds', 'to', 'the', 'operation', 'of', 'unrestricted', 'TAG', 'adjoining.', 'That', 'is,', 'from', 'the', 'example,', 'only', 'the', 'last', '¬', '½annotation', 'is', 'accessible,', 'so', 'the', 'obvious', 'model', 'is', 'a', 'stack.', 'The', 'procedure', 'is', 'then', 'an', 'implementation', 'of', 'some', 'form', 'of', 'bottom-up', 'tree', 'pushdown', 'automaton', '(buTPDA)', '<ref type=""single"">(Schimpf and Gallier, 1985),</ref>', 'a', 'tree', 'automaton', 'augmented', 'with', 'a', 'stack,', 'in', 'the', 'same', 'way', 'a', 'pushdown', 'automaton', '(PDA)', 'is', 'a', 'a', 'finite-state', 'automaton', '(FSA)', 'plus', 'a', 'stack.']",63,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
f965ab21-b971-4deb-9dc8-9ca7b83695cd,Non-Contiguous Tree Parsing,2004,Mark Dras;Chung-Hye Han,['A study of tree adjoining grammars'],['1987'],['K Vijay-Shanker'],single,"['automaton.', 'Thus', 'it', 'is', 'possible', 'for', 'the', 'stack', 'to', 'be', 'accessed', 'on', 'different', 'paths,', 'and', 'so', 'it', 'is', 'possible', 'for', 'paths', 'to', 'be', 'dependent', '(e.g.', 'one', 'path', 'in', 'the', 'tree', 'is', 'Ò,', 'another', 'is', 'Ò', ').', 'Grammars', 'that', 'generate', 'MCSLs', 'cannot', 'have', 'dependent', 'paths', '<ref type=""single"">(Weir, 1988).</ref>', 'But', 'if', 'access', 'to', 'the', 'stack', 'is', 'restricted', 'to', 'a', 'single', 'path-in', 'the', 'same', 'manner', 'that', 'restricting', 'stack', 'passing', 'to', 'a', 'single', 'non-terminal', 'child', 'in', 'an', 'indexed', 'grammar', 'produces', 'a', 'linear', 'indexed', 'grammar', '<ref type=""single"">(Gazdar, 1988),</ref>', 'which', 'generates', 'MCSLs-the', 'power', 'of', 'the', 'TPDA', 'is', 'suitably', 'restricted.', 'The', 'idea', 'is', 'related', 'to', 'the', 'Embedded', 'Pushdown', 'Automaton', '(EPDA)', 'of', '<ref type=""single"">Vijay-Shanker (1987),</ref>', 'although', 'this', 'is', 'of', 'course', 'a', 'string', 'automaton', 'rather', 'than', 'a', 'tree', 'automaton.']",100,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
f9d0218b-2756-4538-b196-6b650e03d626,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['Another facet of LIG parsing'],['1996'],['P Boullier'],single,"['vComp[oo][oo-y]', '1', '_', '[E,', 'h', 'I', 'C➔', 'Y4•,,', '1,', 'p,q', 'I', 'D,', 'r,', 's]', 'Earley', '-', '[E,', 'h', 'I', 'A[oo]', '➔', 'Y1', 'B[oo', '1]', 'Y2', "",'Y',"", 'i,', 'k', 'I', 'D,', 'r,', 's]As', 'an', 'alternative', 'approach,', 'Boullier', '<ref type=""single"">[4]</ref>', 'defines', 'the', 'shared', 'forest', 'for', 'a', 'LIG', 'g', '=', '(Vr,', 'VN,', 'Vi,', 'P,', 'S)', 'and', 'an', 'input', 'string', 'w', 'by', 'means', 'of', 'a', 'linear', 'derivation', 'grammar,', 'a', 'context-free', 'grammar', 'recognizing', 'the', 'language', 'defined', 'by', 'the', 'sequences', 'of', 'LIG', 'of', 'g', 'that', 'could', 'be', 'used', 'to', 'derive', 'w.', 'Previously', 'to', 'the', 'construction', 'of', 'the', 'linear', 'derivation', 'grammar,', 'we', 'must', 'compute', 'the', 'transitive', 'closure', 'for', 'a', 'set', 'of', 'relations', 'on', 'V', 'N', 'x', 'V', 'N.']",36,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f9e23ad5-7e99-4111-a0ac-7cd808cfeedc,Text-based NP Enrichment,2022,Yanai Elazar;Victoria Basmov;Yoav Goldberg;Reut Tsarfaty,['Controlled crowdsourcing for high-quality QA-SRL annotation'],['2020'],['Paul Roit;Ayal Klein;Daniela Stepanov;Jonathan Mamou;Julian Michael;Gabriel Stanovsky;Luke Zettlemoyer;Ido Dagan'],single,"['We', 'trained', 'and', 'qualified', '23', 'workers', 'on', 'the', 'Amazon', 'Mechanical', 'Turk', '(AMT)', 'platform,', 'to', 'participate', 'in', 'the', 'coreference,', 'NP', 'relations,', 'and', 'consolidation', 'tasks.', 'We', 'follow', 'the', 'controlled', 'crowdsourcing', 'protocol', 'suggested', 'by', '<ref type=""single"">Roit et al. (2020)</ref>', 'and', '<ref type=""single"">Pyatkin et al. (2020),</ref>', 'giving', 'detailed', 'than', 'two', 'prepositions', 'for', 'the', 'same', 'NP', 'pairs', 'is', 'not', 'common,', 'and', 'two', 'prepositions', 'occur', 'in', '11.6%', 'of', 'the', 'test-set.', 'For', 'simplicity,', 'in', 'this', 'work,', 'we', 'consider', 'a', 'single', 'preposition', 'for', 'each', 'NP', 'pair,', 'but', 'the', 'collected', 'data', 'may', 'contain', 'two', 'prepositions', 'for', 'some', 'pairs.', 'We', 'paid', '$1.50,', '$2.50,', 'and', '$1.5)', 'for', 'each', 'HIT', 'in', 'the', 'coreference,', 'NP-relations,', 'and', 'consolidation', 'tasks,', 'respectively.', 'The', 'price', 'for', 'the', 'NPrelations', 'task', 'was', 'raised', 'to', '$2.70', 'for', 'the', 'test', 'and', 'out-of-domain', 'subsets.', 'We', 'additionally', 'paid', 'bonus', 'payments', 'on', 'multiple', 'occasions.', 'Overall,', 'we', 'aimed', 'at', 'paying', 'at', 'least', 'the', 'minimum', 'wage', 'in', 'the', 'United', 'States.']",31,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
f9f4ea46-0ffe-4b4e-9bfe-e514b146bc86,Interpretable Entity Representations through Large-Scale Typing,2020,Yasumasa Onoe;Greg Durrett,['PreCo: A large-scale dataset in preschool vocabulary for coreference resolution'],['2018'],['Hong Chen;Zhenhua Fan;Hao Lu;Alan Yuille;Shu Rong'],single,"['Coreference', 'Arc', 'Prediction', '(CAP)', 'We', 'use', 'the', 'English', 'CAP', 'dataset', 'derived', 'from', 'PreCo', '<ref type=""single"">(Chen et al., 2018)</ref>', 'by', '<ref type=""single"">Chen et al. (2019).</ref>', 'The', 'creators', 'of', 'the', 'dataset', 'partition', 'the', 'data', 'by', 'cosine', 'similarity', 'of', 'GloVe', '<ref type=""single"">(Pennington et al., 2014)</ref>', 'embeddings', 'of', 'mention', 'spans', 'and', 'balance', 'the', 'number', 'of', 'positive', 'and', 'negative', 'examples', 'in', 'each', 'bucket,', 'so', 'that', 'models', 'do', 'not', 'solve', 'the', 'task', 'by', 'capturing', 'surface', 'features', 'of', 'entity', 'mention', 'spans.', 'The', 'original', 'data', 'split', 'provides', '8k', 'examples', 'for', 'each', 'of', 'the', 'training,', 'development,', 'and', 'test', 'sets.']",13,"[0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
fb535e52-d4db-4986-aae1-005ad71f8346,Situated Dialogue Learning through Procedural Environment Generation,2022,Prithviraj Ammanabrolu;Renee Jia;Mark Riedl;Sanmit Narvekar;Bei Peng;Matteo Leonetti;Jivko Sinapov;Matthew Taylor;Peter Stone;Olivier Pietquin;Matthieu Geist;Senthilkumar Chan;Shrimai Prabhumoye;Margaret Li;Jack Urbanek;Sebastien Racaniere;Andrew Lampinen;Adam Santoro;David Reichert;Vlad Firoiu;Tim- Othy Lillicrap;Stephen Roller;Emily Dinan;Naman Goyal;Da Ju;Mary Williamson;Yinhan Liu;Jing Xu;Myle Ott;Kurt Shuster;Mikayel Samvelyan;Robert Kirk;Vitaly Kurin;Jack Parker-Holder;Minqi Jiang;Eric Hambro;Fabio Petroni;Heinrich Kuttler;Edward Grefenstette;Tim Rocktäschel;unk Minihack;Satinder Singh;Michael Kearns;Diane Litman;Marilyn Walker;unk Reinforcement;Sainbayar Sukhbaatar;Zeming Lin;Ilya Kostrikov;Gabriel Synnaeve;Angela Fan;Siddharth Karamcheti;Saachi Jain;Samuel Humeau;Douwe Kiela;Arthur Szlam;Yinfei Yang;Steve Yuan;Daniel Cer;Sheng-Yi Kong;Noah Constant;Petr Pilar;Heming Ge,"['unknown', 'Leveraging procedural generation to benchmark reinforcement learning']","['unknown', '2020']","['unknown', 'Karl Cobbe;Chris Hesse;Jacob Hilton;John Schulman']",group,"['In', 'sequential', 'decision', 'making', 'problems', 'in', 'particular,', 'this', 'generalization', 'gap', 'is', 'the', 'result', 'of', 'an', 'agent', 'simply', 'memorizing', 'trajectories,', 'e.g.', 'the', 'sequence', 'of', 'actions', 'and', 'dialogues', 'required', 'to', 'finish', 'a', 'game,', 'and', 'thus', 'being', 'unable', 'to', 'react', 'in', 'novel', 'scenarios-i.e.', 'the', 'agent', 'learns', 'from', 'the', 'head', 'the', 'training', 'data', 'and', 'simply', 'memorizes', 'the', 'long', 'tail.', 'One', 'way', 'of', 'decreasing', 'this', 'generalization', 'gap', 'is', 'by', 'training', 'agents', 'on', 'procedurally', 'generated', 'environments-wherein', 'the', 'agent', 'learns', 'a', 'family', 'of', 'parametrized', 'tasks', 'with', 'a', 'significantly', 'larger', 'state-action', 'spaces', 'than', 'singular', 'environments,', 'thus', 'effectively', 'making', 'the', 'memorization', 'of', 'trajectories', 'impossible', '<ref type=""group"">(Justesen et al., 2018, Cobbe et al., 2020).</ref>', 'Drawing', 'inspiration', 'from', 'all', 'of', 'these', 'ideas,', 'we', 'create', 'a', 'method', 'that', 'learns', 'to', 'create', 'a', 'training', 'curriculum', 'of', 'increasingly', 'more', 'difficult', 'novel', 'procedurally', 'generated', 'environments.']",95,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
fb63048b-1992-45a5-8c25-83ea3ab5ca77,Modeling Users and Online Communities for Abuse Detection: A Position on Ethics and Explainability,2021,Pushkar Mishra;Helen Yannakoudakis;Ekaterina Shutova,['Birds of a feather: Homophily in social networks'],['2001'],['Miller Mcpherson;Lynn Smith-Lovin;James M Cook'],single,"['Homophily,', 'i.e.,', 'the', 'tendency', 'of', 'users', 'in', 'a', 'social', 'space', 'forge', 'ties', 'with', 'others', 'who', 'are', 'similar', 'to', 'them', 'in', 'socially', 'significant', 'ways', '<ref type=""single"">(McPherson et al., 2001).</ref>']",23,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
fb7abf79-4193-40b1-837f-faf336334e97,NEW TABULAR ALGORITHMS FOR LIG PARSING,2000,Mi G Uel Alonso Jor G E Grana;Manuel Vilares,['The use of shared forest in tree adjoining grammar parsing'],['1993'],['K Vijay-Shanker;D Weir'],single,"['To', 'avoid', 'the', 'use', 'of', 'additional', 'data', 'structures,', 'such', 'as', 'finite', 'automata', 'or', 'precomputed', 'relations,', 'we', 'have', 'been', 'inspired', 'by', 'the', 'use', 'of', 'context-free', 'grammars', 'to', 'represent', 'the', 'parse', 'forest', 'of', 'tree', 'adjoining', 'grammars', '<ref type=""single"">[18]</ref>', 'in', 'order', 'to', 'capture', 'the', 'context-freeness', 'of', 'production', 'application', 'in', 'the', 'case', 'of', 'LIG.']",34,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
fb89456d-b72b-4869-ab47-787138efce3b,BRIO: Bringing Order to Abstractive Summarization,2022,Yixin Liu;Pengfei Liu;Dragomir Radev;Graham Neubig,"['Classical structured prediction losses for sequence to sequence learning', 'Sequence-to-sequence learning as beam-search optimization']","['2018', '2016']","[""Sergey Edunov;Myle Ott;Michael Auli;David Grangier;Marc'aurelio Ranzato"", 'Sam Wiseman;Alexander Rush']",group,"['Training', 'Methods', 'of', 'Seq2Seq', 'Models', 'In', 'order', 'to', 'align', 'the', 'training', 'objective', 'and', 'evaluation', 'metric,', 'structured', 'losses', 'have', 'been', 'used', 'for', 'the', 'Seq2Seq', 'model', 'training.', 'Among', 'them,', 'marginbased', 'losses', '<ref type=""group"">(Herbrich et al., 1999, Taskar et al., 2004, Gimpel and Smith, 2010),</ref>', 'which', 'require', 'the', 'model', 'to', 'assign', 'higher', 'probability', 'to', 'the', 'better', 'output,', 'are', 'a', 'major', 'category.', 'Many', 'margin-based', 'losses', 'used', 'in', 'modern', 'seq2seq', 'models', '<ref type=""group"">(Wiseman and Rush, 2016, Edunov et al., 2018)</ref>', 'assume', 'a', 'deterministic', '(one-point)', 'distribution:', 'a', 'model', 'can', 'achieve', 'zero', 'loss', 'if', 'it', 'can', 'assign', 'a', 'much', 'higher', 'probability', 'to', 'the', '(pseudo)-reference,', 'regardless', 'of', 'relative', 'comparisons', 'of', 'other', 'candidate', 'summaries.', 'By', 'contrast,', 'our', 'method', 'has', 'a', 'non-deterministic', 'assumption', '(Eq.', '7),', 'which', 'focuses', 'on', 'the', 'pair-wise', 'ranking', 'of', 'a', 'set', 'of', 'candidate', 'summaries.']",54,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
fbd1fc3f-52f2-445d-88ad-09b62369efef,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,"['The covid-19 risk perception: A survey on socioeconomics and media attention', 'Assessment of public attention, risk perception, emotional and behavioural responses to the covid-19 outbreak: social media surveillance in china. Risk Perception, Emotional and Behavioural Responses to the COVID-19 Outbreak: Social Media']","['2020', '2020']","['Toan Luu Huynh', 'Zhiyuan Hou;Fanxing Du;Hao Jiang;Xinyu Zhou;Leesa Lin']",group,"['All', 'the', 'collected', 'data', 'were', 'originally', 'posted', 'in', 'the', 'period', 'of', 'March', '-June', '2020.', 'During', 'this', 'time,', 'Vietnam', 'was', 'facing', 'a', 'second', 'wave', 'of', 'Covid-19', 'with', 'a', 'drastic', 'increase', 'from', '20', 'to', '355', 'cases', '<ref type=""single"">(WHO, 2020).</ref>', 'The', 'spread', 'of', 'Covid-19', 'results', 'in', 'an', ""'infodemic'"", 'in', 'which', 'misleading', 'information', 'is', 'disseminated', 'rapidly', 'especially', 'on', 'social', 'media', '<ref type=""group"">(Hou et al., 2020, Huynh et al., 2020).</ref>', 'Hence,', 'this', 'period', 'is', 'a', 'potential', 'source', 'of', 'fake', 'news.', 'Besides', 'Covid-19,', 'the', 'items', 'in', 'our', 'dataset', 'cover', 'a', 'wide', 'range', 'of', 'domains', 'including', 'entertainment,', 'sport,', 'finance', 'and', 'healthcare.', 'The', 'result', 'of', 'the', 'data', 'collection', 'stage', 'is', '10,007', 'items', 'that', 'are', 'prepared', 'for', 'the', 'annotation', 'process.']",54,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
fc71c5ec-81ec-4676-b68b-8230221c48a3,Factored Neural Machine Translation Architectures,2016,Mercedes García-Martínez;Loïc Barrault;Fethi Bougares,['Neural machine translation by jointly learning to align and translate'],['2014'],['D Bahdanau;K Cho;Y Bengio'],single,"['The', 'encoder-decoder', 'architecture,', 'used', 'for', 'NMT,', 'consists', 'of', 'two', 'recurrent', 'neural', 'networks', '(RNN),', 'one', 'for', 'the', 'encoder', 'and', 'the', 'other', 'for', 'the', 'decoder.', 'The', 'encoder', 'maps', 'a', 'source', 'sequence', 'into', 'a', 'sequence', 'of', 'continuous', 'space', 'vectors', 'and', 'the', 'decoder', 'maps', 'this', 'representation', 'back', 'to', 'a', 'target', 'sequence.', 'Our', 'trained', 'neural', 'translation', 'models', 'are', 'based', 'on', 'an', 'encoder-decoder', 'deep', 'neural', 'network,', 'equipped', 'with', 'an', 'attention', 'mechanism', '<ref type=""single"">[1],</ref>', 'as', 'described', 'in', 'Figure', '2.', 'This', 'architecture', 'consists', 'of', 'a', 'bidirectional', 'RNN', 'encoder', '(as', 'seen', 'in', 'stage', '1', 'of', 'Figure', '2).', 'An', 'input', 'sentence', 'is', 'encoded', 'in', 'a', 'sequence', 'of', 'annotations', '(one', 'for', 'each', 'input', 'word),', 'corresponding', 'to', 'the', 'concatenation', 'of', 'the', 'outputs', 'of', 'a', 'forward', 'and', 'a', 'backward', 'RNN.', 'Each', 'annotation', 'represents', 'the', 'full', 'sentence', 'with', 'a', 'strong', 'focus', 'on', 'the', 'current', 'word.', 'The', 'decoder', 'is', 'composed', 'of', 'a', 'conditional', 'RNN', 'as', 'provided', 'for', 'the', 'DL4MT', 'winter', 'school', '1', '(see', 'stage', '3', 'of', 'Figure', '2),', 'equipped', 'with', 'an', 'attention', 'mechanism', '(stage', '2).', 'The', 'attention', 'mechanism', 'aims', 'at', 'providing', 'weights', 'for', 'each', 'annotation', 'in', 'order', 'to', 'generate', 'a', 'context', 'vector', '(by', 'performing', 'a', 'weighted', 'sum', 'over', 'the', 'annotations).', 'The', 'attention', 'mechanism', 'uses', 'the', 'hidden', 'state', 'at', 'timestep', 'j', 'of', 'the', 'decoder', 'RNN', 'along', 'with', 'the', 'annotation', 'h', 'i', 'to', 'generate', 'a', 'coefficient', 'e', 'ij.', 'A', 'softmax', 'operation', 'is', 'performed', 'over', 'those', 'coefficients', 'to', 'generate', 'the', 'annotation', 'weights', 'α', 'ij.', 'As', 'described', 'in', '<ref type=""single"">[1],</ref>', 'the', 'annotation', 'weights', 'can', 'be', 'used', 'to', 'align', 'the', 'input', 'words', 'to', 'the', 'output', 'words.', 'The', 'RNN', 'takes', 'as', 'input', 'the', 'context', 'vector,', 'the', 'embedding', 'of', 'the', 'previous', 'output', 'word', '(stage', '4', 'of', 'Figure', '2),', 'and', 'of', 'course,', 'its', 'hidden', 'state.', 'Finally,', 'on', 'stage', '5', 'of', 'the', 'Figure', '2,', 'the', 'output', 'probabilities', 'of', 'the', 'target', 'vocabulary', 'are', 'computed.', 'The', 'word', 'with', 'the', 'highest', 'probability', 'is', 'selected', 'to', 'be', 'the', 'translation', 'output', 'at', 'each', 'timestep.', 'The', 'encoder', 'and', 'the', 'decoder', 'are', 'trained', 'jointly', 'to', 'maximize', 'the', 'conditional', 'probability', 'of', 'the', 'correct', 'translation.']",65,"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
fc751059-495e-4b8c-8b15-0743718bd138,TextGraphs 2021 Shared Task on Multi-Hop Inference for Explanation Regeneration,2021,Mokanarangan Thayaparan;Marco Valentino;Peter Jansen;Dmitry Ustalov,['Simple and Effective Multi-Paragraph Reading Comprehension'],['2018'],['Christopher Clark;Matt Gardner'],single,"['Semantic', 'Drift.', 'Multi-hop', 'question', 'answering', 'systems', 'suffer', 'from', 'the', 'tendency', 'of', 'composing', 'out-of-context', 'inference', 'chains', 'as', 'the', 'number', 'of', 'required', 'hops', '(aggregated', 'facts)', 'increases.', 'This', 'phenomenon,', 'known', 'as', 'semantic', 'drift,', 'has', 'been', 'observed', 'in', 'a', 'number', 'of', 'works', '<ref type=""group"">(Fried et al., 2015, Jansen, 2017),</ref>', 'which', 'have', 'empirically', 'demonstrated', 'that', 'multi-hop', 'inference', 'models', 'exhibit', 'a', 'substantial', 'drop', 'in', 'performance', 'when', 'aggregating', 'more', 'than', '2', 'facts', 'or', 'paragraphs.', 'Semantic', 'drift', 'has', 'been', 'observed', 'across', 'a', 'variety', 'of', 'representations', 'and', 'traversal', 'methods,', 'including', 'word', 'and', 'dependency', 'level', '<ref type=""group"">(Pan et al., 2017, Fried et al., 2015),</ref>', 'sentence', 'level', '<ref type=""single"">(Jansen et al., 2017),</ref>', 'and', 'paragraph', 'level', '<ref type=""single"">(Clark and Gardner, 2018).</ref>', '<ref type=""single"">Khashabi et al. (2019)</ref>', 'have', 'demonstrated', 'that', 'ongoing', 'efforts', 'on', '""very', 'long""', 'multi-hop', 'reasoning', 'are', 'unlikely', 'to', 'succeed', 'without', 'the', 'adoption', 'of', 'a', 'richer', 'underlying', 'representation', 'that', 'allows', 'for', 'reasoning', 'with', 'fewer', 'hops.']",86,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
fc96b33b-04c3-4529-a68d-b44daed0300c,RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering,2021,Yingqi Qu;Yuchen Ding;Jing Liu;Kai Liu;Ruiyang Ren;Wayne Zhao;Daxiang Dong;Hua Wu;Haifeng Wang,['MS MARCO: A human generated machine reading comprehension dataset'],['2016'],['Tri Nguyen;Mir Rosenberg;Xia Song;Jianfeng Gao;Saurabh Tiwary;Rangan Majumder;Li Deng'],single,"['We', 'conduct', 'the', 'experiments', 'on', 'two', 'popular', 'QA', 'benchmarks:', 'MSMARCO', 'Passage', 'Ranking', '<ref type=""single"">(Nguyen et al., 2016)</ref>', 'and', 'Natural', 'Questions', '(NQ)', '<ref type=""single"">(Kwiatkowski et al., 2019).</ref>', 'The', 'statistics', 'of', 'the', 'datasets', 'are', 'listed', 'in', 'Table', '1.', 'MSMARCO', 'Passage', 'Ranking', 'MSMARCO', 'is', 'originally', 'designed', 'for', 'multiple', 'passage', 'MRC,', 'and', 'its', 'questions', 'were', 'sampled', 'from', 'Bing', 'search', 'logs.', 'Based', 'on', 'the', 'questions', 'and', 'passages', 'in', 'MS-MARCO', 'Question', 'Answering,', 'a', 'dataset', 'for', 'passage', 'ranking', 'was', 'created,', 'namely', 'MSMARCO', 'Passage', 'Ranking,', 'consisting', 'of', 'about', '8.8', 'million', 'passages.', 'The', 'goal', 'is', 'to', 'find', 'positive', 'passages', 'that', 'answer', 'the', 'questions.']",12,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
fcd4b288-f863-407e-bac2-453847791966,Control Image Captioning Spatially and Temporally,2021,Kun Yan;Ji Lei;Huaishao Luo;Ming Zhou;Nan Duan;Shuai Ma,['Image captioning at will: A versatile scheme for effectively injecting sentiments into image descriptions'],['2018'],['Quanzeng You;Jin Hailin;Jiebo Luo'],single,"['Most', 'previous', 'attempts', 'aim', 'to', 'describe', 'the', 'image', 'indicating', 'the', 'salient', 'objects', 'and', 'relations', 'without', 'considering', 'user', 'intention.', 'To', 'generate', 'controllable', 'and', 'explainable', 'captions,', 'recent', 'works', 'dedicated', 'to', 'establishing', 'a', 'new', 'controllable', 'image', 'captioning', 'task', 'to', 'generate', 'the', 'caption', 'at', 'will.', 'The', 'captioning', 'process', 'can', 'be', 'controlled', 'by', 'POS', 'tagging', '<ref type=""single"">(Deshpande et al., 2018),</ref>', 'sentiment', '<ref type=""single"">(You et al., 2018),</ref>', 'length', '<ref type=""single"">(Deng et al., 2020),</ref>', 'bounding', 'boxes', '<ref type=""single"">(Cornia et al., 2019),</ref>', 'and', 'mouse', 'traces', '<ref type=""single"">(Pont-Tuset et al., 2020).</ref>']",52,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
fcf16339-bf4f-455b-b1f3-98fe9fe1c09f,On the Usability of Transformers-based models for a French Question-Answering task,2021,Oralie Cattan;Christophe Servan;Sophie Rosset,['BERT: Pre-training of deep bidirectional transformers for language understanding'],['2019'],['Jacob Devlin;Ming-Wei Chang;Kenton Lee;Kristina Toutanova'],single,"['Transformer-based', 'language', 'models', 'such', 'as', 'BERT', '<ref type=""single"">(Devlin et al., 2019)</ref>', 'are', 'pre-trained', 'on', 'largescale', 'data', 'collections', 'sourced', 'from', 'Wikipedia', 'or', 'Common', 'Crawl', '(CC)', 'with', 'one', 'or', 'multiple', 'training', 'objectives', '(masked', 'language', 'modeling,', 'next', 'sentence', 'or', 'sentence', 'order', 'prediction).', 'This', 'pretraining', 'can', 'be', 'followed', 'by', 'supervised', 'fine-tuning', 'according', 'to', 'the', 'tasks,', 'whether', 'generatives', '(machine', 'translation,', 'abstractive', 'summarization)', 'or', 'discriminatives', '(classification,', 'question-answering).', 'The', 'ensuing', 'fine-tuning', 'phase', 'allows', 'for', 'better', 'initialization', 'of', 'the', 'models', 'parameters', 'while', 'requiring', 'less', 'task-specific', 'data', 'so', 'as', 'to', 'make', 'the', 'training', 'of', 'subsequent', 'tasks', 'faster.']",6,"[3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
fd501c3f-97d1-4aed-a124-6dd00f87ba16,Generalizable and Explainable Dialogue Generation via Explicit Action Learning,2020,Xinting Huang;Jianzhong Qi;Yu Sun;Rui Zhang,['Anchors: High-precision modelagnostic explanations'],['2018'],['Sameer Marco Tulio Ribeiro;Carlos Singh;unk Guestrin'],single,"['Obtaining', 'salient', 'words', 'by', 'applying', 'existing', 'saliency', 'identification', 'approaches', '<ref type=""single"">(Ribeiro et al., 2018)</ref>', 'is,', 'however,', 'unable', 'to', 'produce', 'unified', 'action', 'representations.', 'Specifically,', 'system', 'utterances', 'with', 'the', 'same', 'intention', 'might', 'not', 'share', 'similar', 'wordings,', 'and', 'existing', 'attribution', 'approaches', 'can', 'only', 'identify', 'salient', 'words', 'within', 'utterances.', 'We', 'tackle', 'this', 'challenge', 'by', 'proposing', 'a', 'memoryaugmented', 'saliency', 'approach', 'that', 'identifies', 'salient', 'words', 'from', 'a', 'broader', 'vocabulary.', 'The', 'vocabulary', 'consists', 'of', 'all', 'the', 'words', 'that', 'could', 'compose', 'natural', 'language', 'actions,', '1', 'and', 'each', 'word', 'is', 'stored', 'as', 'a', 'slot', 'in', 'the', 'memory', 'component.', 'By', 'incorporating', 'the', 'memory', 'component', 'into', 'a', 'dialogue', 'state', 'tracking', 'model,', 'we', 'use', 'each', 'system', 'utterance', 'as', 'a', 'query', 'to', 'perform', 'memory', 'retrieval,', 'and', 'the', 'retrieval', 'results', 'are', 'considered', 'as', 'salient', 'words.', 'The', 'retrieval', 'results', 'might', 'contain', 'words', 'that', 'are', 'redundant', 'since', 'we', 'do', 'not', 'have', 'direct', 'supervision', 'for', 'the', 'retrieval', 'operations.', 'For', 'example,', 'the', 'resulting', 'salient', 'words', 'might', 'be', '""but', 'turn', 'bland""', 'in', 'the', 'example', 'shown', 'earlier,', 'which', 'include', 'unnecessary', 'words', 'and', 'may', 'lead', 'to', 'degenerated', 'action', 'results.', 'To', 'obtain', 'compact', 'action', 'representations,', 'we', 'propose', 'an', 'auxiliary', 'task', 'based', 'on', 'pseudo', 'parallel', 'corpus,', 'i.e.,', 'dialogue', 'context', 'and', 'state', 'annotation', 'pairs.', 'We', 'observe', 'that', 'dialogue', 'states', 'serve', 'as', 'good', 'examples', 'of', 'how', 'compact', 'representation', 'should', 'be.', 'Therefore,', 'we', 'use', 'the', 'encoded', 'dialogue', 'context', 'as', 'query', 'and', 'ask', 'the', 'memory', 'component', 'to', 'reconstruct', 'its', 'text-based', 'dialogue', 'states.', 'In', 'this', 'way,', 'the', 'obtained', 'concise', 'actions', 'generalize', 'better', 'and', 'can', 'be', 'easily', 'interpreted.']",9,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
fdc151e0-68dd-48f4-97a6-4d35585f56e6,Codenames as a Game of Co-occurrence Counting,2022,Réka Cserháti;István Kolláth;András Kicsi;Gábor Berend,['Playing codenames with language graphs and word embeddings'],['2021'],['Divya Koyyalagunta;Anna Sun;Rachel Draelos;Cynthia Rudin'],single,"['We', 'also', 'introduced', 'innovations', 'in', 'terms', 'of', 'scoring', 'functions,', 'firstly', 'by', 'refining', 'the', 'scoring', 'function', 'of', '<ref type=""single"">Koyyalagunta et al. (2021),</ref>', 'and', 'secondly', 'by', 'using', 'the', 'harmonic', 'mean', 'of', 'the', 'relatedness', 'to', 'the', 'clue', 'word.', 'This', 'improved', 'the', 'performance', 'of', 'the', 'best', 'agents', 'substantially.']",16,"[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
fe0b0157-b696-414c-9194-c546f6bb253b,TransWiC at SemEval-2021 Task 2: Transformer-based Multilingual and Cross-lingual Word-in-Context Disambiguation,2021,Hansi Hettiarachchi;Tharindu Ranasinghe,"[""Siamese recurrent architectures for learning sentence similarity. AAAI'16"", 'Semantic textual similarity with Siamese neural networks']","['2016', '2019']","['Jonas Mueller;Aditya Thyagarajan', 'Tharindu Ranasinghe;Constantin Orasan;Ruslan Mitkov']",group,"['As', 'future', 'work,', 'we', 'would', 'be', 'looking', 'to', 'improve', 'our', 'results', 'more', 'with', 'new', 'strategies.', 'We', 'would', 'like', 'to', 'experiment', 'with', 'whether', 'adding', 'languagespecific', 'processing', 'and', 'resources', 'would', 'improve', 'the', 'results.', 'We', 'are', 'keen', 'to', 'add', 'different', 'neural', 'network', 'architectures', 'like', 'Siamese', 'transformer', 'networks', '<ref type=""single"">(Reimers and Gurevych, 2019)</ref>', 'that', 'perform', 'well', 'in', 'sentence', 'pair', 'classification', 'tasks', '<ref type=""group"">(Ranasinghe et al., 2019b, Mueller and Thyagarajan, 2016)</ref>', 'to', 'the', 'TransWiC', 'framework.', 'Furthermore,', 'we', 'are', 'hoping', 'to', 'work', 'in', 'a', 'multi-task', 'environment', 'and', 'experiment', 'whether', 'transfer', 'learning', 'from', 'a', 'similar', 'task', 'like', 'semantic', 'textual', 'similarity', '<ref type=""single"">(Cer et al., 2017)</ref>', 'would', 'improve', 'the', 'results', 'for', 'this', 'task.']",53,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
feb46988-6785-4ae8-86c9-8bc66a6623c5,Memory-efficient Transformers via Top-k Attention,2021,Ankit Gupta;Guy Dar;Shaya Goodman;David Ciprut;Jonathan Berant;Ibm Research,['Training deep nets with sublinear memory cost'],['2016'],['T Chen;B Xu;C Zhang;Carlos Guestrin'],single,"['Taking', 'inspiration', 'from', 'gradient', 'checkpointing', '<ref type=""single"">(Chen et al., 2016),</ref>', 'we', 'observe', 'that', 'if', 'the', 'inputs', 'Q', 'C,', 'K,', 'V', 'are', 'available', 'during', 'the', 'backward', 'pass,', 'we', 'can', 're-compute', 'o', 'C', 'and', 'then', 'use', 'the', 'produced', 'intermediate', 'activations', 'to', 'computed', '(Q', 'C)', 'from', 'd', '(o', 'C', ').', 'Once', 'd', '(Q', 'C)', 'is', 'computed,', 'we', 'can', 'again', 'discard', 'the', 'intermediate', 'activations', 'and', 'gradients', 'produced', 'during', 'this', 'step', 'and', 'move', 'on', 'to', 'the', 'next', 'chunk.', 'This', 'ensures', 'that', 'the', 'peak', 'memory', 'usage', 'during', 'the', 'backward', 'pass', 'through', 'the', 'attention', 'layer', 'is', 'bounded', 'by', 'the', 'memory', 'required', 'to', 'backpropagate', 'through', 'a', 'single', 'chunk.']",5,"[2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
fefb3024-cbe0-4d1e-97b3-ba94c58bea03,Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking,2021,Yue Zhang;Chengcheng Hu;Yuqi Liu;Hui Fang;Jimmy Lin,"['unknown', 'unknown']","['unknown', '2019']","['unknown', 'Rodrigo Nogueira;Kyunghyun Cho']",group,"['For', 'the', 'final-stage', 'neural', 'reranker,', 'we', 'experiment', 'with', 'BERT-large', 'and', 'T5-base', 'in', 'the', 'PyGaggle', 'library', 'fine-tuned', 'on', 'the', 'MS', 'MARCO', 'passage', 'data.', '4', 'We', 'simply', 'use', 'checkpoints', 'provided', 'by', 'the', 'library,', 'as', 'our', 'work', 'is', 'not', 'specifically', 'focused', 'on', 'final-stage', 'neural', 'reranking.', 'Previous', 'evaluations', '<ref type=""group"">(Nogueira and Cho, 2019, Nogueira et al., 2020, Pradeep et al., 2021)</ref>', 'have', 'already', 'verified', 'that', 'these', 'two', 'models', 'serve', 'as', 'competitive', 'baselines.', 'We', 'pad', 'all', 'the', 'token', 'sequences', 'in', 'the', 'batch', 'to', 'have', 'the', 'same', 'length', 'and', 'truncate', 'them', 'if', 'their', 'lengths', 'exceed', '512', 'tokens.']",44,"[0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ff0e76c1-ea64-4737-88db-16b26fe3017f,ReINTEL: A Multimodal Data Challenge for Responsible Information Identification on Social Network Sites,2020,Duc-Trong Le;Xuan-Son Vu;Nhu-Dung To;Huu-Quang Nguyen;Thuy-Trinh Nguyen;Linh Le;Anh-Tuan Nguyen;Minh-Duc Hoang;Nghia Le;Huyen Nguyen;Hoang Nguyen,['Very deep convolutional networks for large-scale image recognition'],['2015'],['Karen Simonyan;Andrew Zisserman'],single,"['Trained', 'on', '20GB', 'texts', 'of', 'both', 'Vietnamese', 'news', 'and', 'Vietnamese', 'Wikipedia', 'Bert4News', '<ref type=""single"">(Nha, 2020)</ref>', 'x', 'Trained', 'on', 'more', 'than', '20GB', 'texts', 'of', 'Vietnamese', 'news', 'vElectra', 'and', 'ViBERT', '<ref type=""single"">(The et al., 2020)</ref>', 'x', 'vElectra', 'was', 'trained', 'on', '10GB', 'texts,', 'whereas', 'ViBERT', 'was', 'trained', 'on', '60GB', 'texts', 'of', 'Vietnamese', 'news', 'VGG16', '<ref type=""single"">(Simonyan and Zisserman, 2015)</ref>', 'x']",45,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1]"
ff7d6a09-4ff8-4d2a-a879-96d1e23381d2,KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation,2022,Yongfei Liu;Chenfei Wu;Shao-Yen Tseng;Vasudev Lal;Xuming He;Nan Duan,"['unknown', 'Pixel-bert: Aligning image pixels with text by deep multi-modal transformers', 'E2e-vlp: End-to-end vision-language pre-training enhanced by visual learning']","['unknown', '2020', '2021']","['unknown', 'Zhicheng Huang;Zhaoyang Zeng;Bei Liu;Dongmei Fu;Jianlong Fu', 'Haiyang Xu;Ming Yan;Chenliang Li;Bin Bi;Songfang Huang;Wenming Xiao;Fei Huang']",group,"['Pretraining', 'Corpus:', 'Following', 'the', 'E2E', 'pretraining', 'strategy', '<ref type=""group"">(Huang et al., 2021 (Huang et al., , 2020,, Xu et al., 2021),</ref>', 'we', 'take', 'indomain', 'datasets:', 'MSCOCO', '<ref type=""single"">(Lin et al., 2014)</ref>', 'and', 'VG', '<ref type=""single"">(Krishna et al., 2016)</ref>', 'as', 'pretraining', 'datasets', 'since', 'it', 'is', 'widely', 'used', 'in', 'literature.', 'In', 'total,', 'two', 'datasets', 'comprise', 'about', '200K', 'images', 'and', '5.6M', 'image-text', 'pairs,', 'where', 'each', 'image', 'is', 'associated', 'with', 'multiple', 'captions.', 'VQA2.0', 'R@1', '/', 'R@5/', 'R@10', 'R@1', '/', 'R@5', '/', 'R@10', 'val', '/', 'test', 'dev', '/', 'test-p', 'test-dev', '/', '-std', 'two-step', 'pretraining', 'ViLBert', '<ref type=""single"">(Lu et al.,</ref>', 'MSCOCO-TR(5K)', 'VCR', 'R@1', '/', 'R@5', '/', 'R@10', 'R@1', '/', 'R@5', '/', 'R@10', 'R@1', '/', 'R@5', '/', 'R@10', 'R@1', '/', 'R@5', '/', 'R@10', 'Q→A', 'QA→R', 'Q→AR', 'two-step', 'pretraining', 'Unicoder-VL', '<ref type=""single"">(Li et al., 2020a)</ref>', 'Implementation', 'Details:', 'We', 'follow', 'BERT', 'to', 'tokenize', 'caption', 'into', 'word', 'tokens', 'by', 'using', 'Word-Piece,', 'and', 'resize', 'the', 'image', 'into', '(800,', '1333)', 'as', 'prior', 'works.', 'For', 'model', 'architecture,', 'a', 'widely-used', 'ResNet101', 'for', 'visual', 'encoding', 'and', '12-layer', 'Transformer', 'for', 'multi-modal', 'fusion', 'are', 'adopted', 'for', 'a', 'fair', 'comparison.', 'Both', 'networks', 'are', 'initialized', 'with', 'Im-ageNet', 'and', 'BERT', 'pretrained', 'parameters.', 'Besides,', 'following', 'the', 'majority', 'of', 'two-step', 'methods,', 'we', 'apply', 'the', 'widely-used', 'object', 'detector', 'BUTD', '<ref type=""single"">(Anderson et al., 2018)</ref>', 'to', 'generate', 'object', 'proposals', 'as', 'well', 'as', 'their', 'RoI', 'embeddings', 'as', 'our', 'supervision.']",7,"[0, 0, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ff962ec5-2856-4848-a1d2-09919d4e49b3,"Public Apologies in India -Semantics, Sentiment and Emotion",2018,Sangeeta Shukla;Rajita Shukla,['WordNet: an electronic lexical database'],['1998'],['Christiane Fellbaum'],single,"['The', 'nouns', 'are', 'organized', 'as', 'an', 'inheritance', 'system', 'in', 'WordNet', '<ref type=""single"">(Fellbaum, 1998).</ref>', 'Under', 'this', 'system', 'there', 'is', 'a', 'sequence', 'of', 'levels,', 'a', 'hierarchy,', 'in', 'which', 'the', 'lower', 'levels', 'inherit', 'the', 'features', 'of', 'the', 'top', 'levels,', 'plus', 'have', 'at', 'least', 'one', 'distinguishing', 'feature.', 'The', 'two', 'semantic', 'relations', 'of', 'interest', 'in', 'the', 'present', 'study', 'are', 'hypernymy', 'and', 'hyponymy', '<ref type=""single"">(Fellbaum, 1998).</ref>', 'The', 'selected', 'sense', 'of', 'the', 'noun', 'apology', 'has', 'the', 'gloss', '-an', 'expression', 'of', 'regret', 'at', 'having', 'caused', 'trouble', 'for', 'someone.', 'It', 'has', 'acknowledgement', 'as', 'its', 'direct', 'hypernymy,', 'which', 'is', 'defined', 'as', 'a', 'statement', 'acknowledging', 'something', 'or', 'someone.', 'From', 'the', 'communicative', 'perspective', 'this', 'acknowledgment', 'is', 'a', 'precursor', 'to', 'the', 'expectation', 'of', 'some', 'sort', 'of', 'reparation', 'or', 'compensation', 'on', 'the', 'part', 'of', 'the', 'offended.', 'In', 'the', 'corpus,', 'the', 'apology', 'number', '7,', 'has', 'the', 'sentence,', 'We', 'would', 'like', 'to', 'tender', 'an', 'unconditional', 'apology', 'to', 'the', 'society', 'at', 'large', 'and', 'especially', 'to', 'the', 'affected', 'families', 'and', 'to', 'everyone', 'whom', 'we', 'have', 'offended.', 'This', 'is', 'an', 'unequivocal', 'expression', 'of', 'apology', 'and', 'shows', 'that', 'tenderers', 'do', 'not', 'want', 'to', 'make', 'any', 'excuses', 'for', 'their', 'wrongdoing.', 'The', 'gloss', 'of', 'selected', 'sense', 'of', 'the', 'noun', 'regret', 'is', 'sadness', 'associated', 'with', 'some', 'wrong', 'done', 'or', 'some', 'disappointment.', 'The', 'direct', 'hypernymy', 'of', 'this', 'is', 'the', 'concept', 'of', 'sadness', 'which', 'is', 'emotions', 'experienced', 'when', 'not', 'in', 'a', 'state', 'of', 'well-being.', 'This', 'is', 'followed', 'by', 'the', 'concept', 'of', 'feeling', 'or', 'the', 'experiencing', 'of', 'affective', 'and', 'emotional', 'states.', 'Thus', 'the', 'hypernymy', 'relation', 'makes', 'it', 'clear', 'that', 'regret', 'is', 'a', 'kind', 'of', 'feeling', 'associated', 'with', 'sadness.', 'From', 'a', 'communicative', 'point', 'of', 'view,', 'it', 'is', 'simply', 'an', 'expression', 'of', 'an', 'emotion', 'on', 'the', 'part', 'of', 'the', 'tenderer', 'of', 'the', 'apology', 'and', 'not', 'necessarily', 'expression', 'of', 'remorse', 'or', 'liability.', 'For', 'example,', 'in', 'apology', 'number', '13,', 'the', 'Member', 'of', 'Parliament', 'states,', 'I', 'write', 'to', 'convey', 'my', 'regrets', 'for', 'the', 'unfortunate', 'incident', 'that', 'took', 'place', 'on', '23rd', 'March', '2017', 'in', 'the', 'Air', 'India', 'flight', 'No.', 'AI', '852,', 'seat', 'No.1F.', 'Given', 'that', 'the', 'writer', 'only', 'uses', 'the', 'noun', 'regret,', 'it', 'can', 'be', 'implied', 'that', 'the', 'writer', 'feels', 'sad', 'about', 'the', 'incident', 'but', 'not', 'necessarily', 'repentant.', 'However,', 'it', 'is', 'important', 'to', 'look', 'at', 'the', 'results', 'of', 'SentiWordNet', 'and', 'WordNet-Affect', 'to', 'understand', 'the', 'implications', 'and', 'underlying', 'emotions', 'and', 'sentiments', 'before', 'arriving', 'at', 'any', 'further', 'conclusions.']",10,"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
ffb43d18-fe53-40e7-9dcf-556f8356276c,The DCU Machine Translation Systems for IWSLT 2011,2011,Pratyush Banerjee;Hala Almaghout;Sudip Naskar;Johann Roturier;Jie Jiang;Andy Way;Josef Van Genabith,['A conditional random field word segmenter'],['2005'],['H Tseng;P Chang;G Andrew;D Jurafsky;C Manning'],single,"['Arabic', 'being', 'a', 'morphologically', 'rich', 'language,', 'has', 'many', 'different', 'surface', 'forms', 'of', 'words', 'with', 'same', 'root.', 'This', 'phenomenon', 'poses', 'a', 'data', 'sparsity', 'problem', 'for', 'SMT', 'systems.', 'In', 'order', 'to', 'reduce', 'data', 'sparsity,', 'we', 'segment', 'the', 'Arabic', 'data', 'morphologically', 'before', 'training.', 'The', 'Arabic', 'data', 'is', 'segmented', 'according', 'to', 'the', 'D3', 'segmentation', 'scheme', 'using', 'MADA', '(Morphological', 'Analysis', 'and', 'Disambiguation', 'for', 'Arabic).', '5', 'For', 'all', 'the', 'available', 'Chinese', 'data,', 'we', 'segment', 'the', 'sentences', 'to', 'words', 'using', 'the', 'Stanford', 'Chinese', 'Word', 'Segmenter', '<ref type=""single"">[22].</ref>', 'English', 'data', 'is', 'lower-cased', 'and', 'tokenized', 'in', 'the', 'preprocessing', 'step.']",78,"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"

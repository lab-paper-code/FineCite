token_context,word_context,seg_context,sent_cotext,label
"['', '', '', 'sense LDO appears less reliable', 'error', '', 'Ideally , to distinguish between raising and equi verbs , a number of syntactic criteria should be employed #TAUTHOR_TAG :460 ff .', ', only two of these criteria are explicit in the coding system.']","['', '', '', 'sense LDOCE appears less reliable.', 'error', '', 'Ideally , to distinguish between raising and equi verbs , a number of syntactic criteria should be employed #TAUTHOR_TAG :460 ff .', 'However, only two of these criteria are explicit in the coding system.']","['', '', '', 'appears less reliable.', 'error', '', 'Ideally , to distinguish between raising and equi verbs , a number of syntactic criteria should be employed #TAUTHOR_TAG :460 ff .', ', only two of these criteria are explicit in the coding system.']","['', '', '', '', '', '', 'Ideally , to distinguish between raising and equi verbs , a number of syntactic criteria should be employed #TAUTHOR_TAG :460 ff . )', 'However, only two of these criteria are explicit in the coding system.']",3
"['', '', 'a fully flexible access system allows the retrieval of dictionary entries on the basis of constraints specifying any combination of phonetic , lexical , syntactic , and semantic information #TAUTHOR_TAG .', 'entries to allow the testing of software on an unbiased sample.']","['', '', 'a fully flexible access system allows the retrieval of dictionary entries on the basis of constraints specifying any combination of phonetic , lexical , syntactic , and semantic information #TAUTHOR_TAG .', 'entries to allow the testing of software on an unbiased sample.']","['', '', 'a fully flexible access system allows the retrieval of dictionary entries on the basis of constraints specifying any combination of phonetic , lexical , syntactic , and semantic information #TAUTHOR_TAG .', 'dictionary entries to allow the testing of software on an unbiased sample.']","['', '', 'In addition , a fully flexible access system allows the retrieval of dictionary entries on the basis of constraints specifying any combination of phonetic , lexical , syntactic , and semantic information #TAUTHOR_TAG .', 'Independently, random selection of dictionary entries is also provided to allow the testing of software on an unbiased sample.']",0
"['We tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Figure 16 gives the number of ver classified under each these authors and the number successfully into the categories the.']","['We tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Figure 16 gives the number of verbs classified under each these authors and the number successfully into the categories the system.']","['We tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Figure 16 gives the number of ver classified under each category these authors and the number successfully into the same categories the system.']","['We tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in #TAUTHOR_TAG and #AUTHOR_TAG .', 'Figure 16 gives the number of verbs classified under each category by these authors and the number successfully classified into the same categories by the system.']",5
"['', '', '', 'As #TAUTHOR_TAG points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage, this simple and conventional access strategy is perfectly adequate.', 'The use of such standard database indexing techniques makes it possible for an active dictionary process to be veryemanding with respect to main memory utilisation.', '', '']","['', '', '', 'As #TAUTHOR_TAG points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage, this simple and conventional access strategy is perfectly adequate.', 'The use of such standard database indexing techniques makes it possible for an active dictionary process to be very undemanding with respect to main memory utilisation.', '', '']","['', '', '', 'As #TAUTHOR_TAG points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage, this simple and conventional access strategy is perfectly adequate.', 'The use of such standard database indexing techniques makes it possible for an active dictionary process to be veryemanding with respect to main memory utilisation.', '', '']","['', '', '', 'As #TAUTHOR_TAG points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage, this simple and conventional access strategy is perfectly adequate.', 'The use of such standard database indexing techniques makes it possible for an active dictionary process to be very undemanding with respect to main memory utilisation.', '', '']",0
"['Recent developments in lingu and especially on grammatical theory', '', '', 'research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['Recent developments in and especially on grammatical theory', '', '', 'research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['Recent developments in lingu and especially on grammat', '', '', 'The research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']","['', '', '', 'The research described below is taking place in the context of three collaborative projects #TAUTHOR_TAG to develop a general-purpose , wide coverage morphological and syntactic analyser for English .', '']",0
"['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g. #TAUTHOR_TAG ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g. #TAUTHOR_TAG ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g. #TAUTHOR_TAG ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g. #TAUTHOR_TAG ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '', '', '', '', '', '', '']",4
"['In previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer #TAUTHOR_TAG .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'we saw significant improvements in the resulting synthesized speech system.', 'these stemmed our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing', '', '']","['In previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer #TAUTHOR_TAG .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'we saw significant improvements in the resulting synthesized speech, system.', 'these stemmed our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', '', '']","['In previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer #TAUTHOR_TAG .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'we saw significant improvements in the resulting synthesized speech, the system.', 'these stemmed our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', '', '']","['In previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer #TAUTHOR_TAG .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', '', '']",0
"['Existing text-to-ech systems perform well on word pronunci and short sentences, 2 but when it comes to sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand', 'investigators (eg.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; Luce et al.1983 ; #TAUTHOR_TAG have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'sophisticated', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; Luce et al. 1983 ; #TAUTHOR_TAG have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'sophisticated', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand', 'Many investigators (eg.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; Luce et al. 1983 ; #TAUTHOR_TAG have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; Luce et al. 1983 ; #TAUTHOR_TAG have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '', '', '', '', '', '', '']",4
"['We have built an experimental text-to-speech system that uses our analysis of prosody to generate phrase boundaries for the Olive -- Liberman synthesizer #TAUTHOR_TAG .', '', 'the system syntax a unre sentences', '']","['We have built an experimental text-to-speech system that uses our analysis of prosody to generate phrase boundaries for the Olive -- Liberman synthesizer #TAUTHOR_TAG .', '', 'the system syntax a sentences.', '']","['We have built an experimental text-to-speech system that uses our analysis of prosody to generate phrase boundaries for the Olive -- Liberman synthesizer #TAUTHOR_TAG .', '', 'the system syntax sentences', '']","['We have built an experimental text-to-speech system that uses our analysis of prosody to generate phrase boundaries for the Olive -- Liberman synthesizer #TAUTHOR_TAG .', '', '', '']",5
"['ody be viewed as resulting in part from semantic considerations', 'relations and discourse examined for', '', '', '', '', '', '', '', '', '', 'see Section 2.1.3.).', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', ' #TAUTHOR_TAG and #AUTHOR_TAG also examine the relation between discourse and prosodic phrasing .', 'Their work succeeds in distinguishing the use of items like now, so, and well as discourse cues from their denotative lexical use on the basis of a complex combination of pitch accent type and phrasing.']","['be viewed as resulting in part from semantic considerations.', 'relations and discourse examined for', '', '', '', '', '', '', '', '', '', '(see Section 2.1.3.).', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', ' #TAUTHOR_TAG and #AUTHOR_TAG also examine the relation between discourse and prosodic phrasing .', 'Their work succeeds in distinguishing the use of items like now, so, and well as discourse cues from their denotative lexical use on the basis of a complex combination of pitch accent type and phrasing.']","['may be viewed as resulting in part from semantic considerations.', 'and discourse factors for', '', '', '', '', '', '', '', '', '', 'see Section 2.1.3.).', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', ' #TAUTHOR_TAG and #AUTHOR_TAG also examine the relation between discourse and prosodic phrasing .', 'Their work succeeds in distinguishing the use of items like now, so, and well as discourse cues from their denotative lexical use on the basis of a complex combination of pitch accent type and phrasing.']","['The syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', '', '', '', '', '', '', '', '', '', '', '', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', ' #TAUTHOR_TAG and #AUTHOR_TAG also examine the relation between discourse and prosodic phrasing .', 'Their work succeeds in distinguishing the use of items like now, so, and well as discourse cues from their denotative lexical use on the basis of a complex combination of pitch accent type and phrasing.']",0
"['ody is', 'has', 'this claim controversial of the misadgnments occur between the two levels ofasing', 'For example, in considering the connection between syntax and phrasing, the linguistic literature most often refers to examples of embedded sentences.', 'Sentences like 12 , from #TAUTHOR_TAG , are frequently cited .', '(Square brackets mark off the NP constituents that contain embed- ded sentences.)']","['is', 'has', ""this claim controversial of the misa'dgnments occur between the two levels of"", 'For example, in considering the connection between syntax and phrasing, the linguistic literature most often refers to examples of embedded sentences.', 'Sentences like 12 , from #TAUTHOR_TAG , are frequently cited .', '(Square brackets mark off the NP constituents that contain embed- ded sentences.)']","['', 'has led', ""this claim controversial of the misa'dgnments occur between the two levels ofasing"", 'For example, in considering the connection between syntax and phrasing, the linguistic literature most often refers to examples of embedded sentences.', 'Sentences like 12 , from #TAUTHOR_TAG , are frequently cited .', '(Square brackets mark off the NP constituents that contain embed- ded sentences.)']","['', '', ""However, this claim is controversial because of the misa'dgnments that occur between the two levels of phrasing."", 'For example, in considering the connection between syntax and phrasing, the linguistic literature most often refers to examples of embedded sentences.', 'Sentences like 12 , from #TAUTHOR_TAG , are frequently cited .', '(Square brackets mark off the NP constituents that contain embed- ded sentences.)']",0
"['In previous work #TAUTHOR_TAG , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', 'This re', '']","['In previous work #TAUTHOR_TAG , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', 'This', '']","['In previous work #TAUTHOR_TAG , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', 'This paper re', '']","['In previous work #TAUTHOR_TAG , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .', 'The system generated phrase boundaries using information derived from the syntactic structure of a sentence.', 'While we saw significant improvements in the resulting synthesized speech, we also observed problems with the system.', 'Often these stemmed from our assumptions that both clausal structure and predicateargument relations were important in determining prosodic phrasing.', '', '']",2
"['', '', '', '', '', '', '', '', '', 'only indirectly related syntax since readjust is done rules outside the grammar proper', ' #TAUTHOR_TAG proposes readjustment rules similar to those of Chomsky and Halle , but he claims that the readjustment of structure is part of the grammar , not part of the performance model .', 'He is often a tacit assumption in both the linguistic and psycholinguistic literature2--that there is a direct connection between syntactic constituency and prosodic phrasing, with apparent misalignments readjusted before syntax interface,; with prosodic phonology.']","['', '', '', '', '', '', '', '', '', 'only indirectly related syntax, since readjustment is done rules outside the grammar proper.', ' #TAUTHOR_TAG proposes readjustment rules similar to those of Chomsky and Halle , but he claims that the readjustment of structure is part of the grammar , not part of the performance model .', 'He is often a tacit assumption in both the linguistic and psycholinguistic literature2--that there is a direct connection between syntactic constituency and prosodic phrasing, with apparent misalignments readjusted before syntax interface,; with prosodic phonology.']","['', '', '', '', '', '', '', '', '', 'is only indirectly related syntax since readjust is done special rules outside the grammar proper.', ' #TAUTHOR_TAG proposes readjustment rules similar to those of Chomsky and Halle , but he claims that the readjustment of structure is part of the grammar , not part of the performance model .', 'He is often a tacit assumption in both the linguistic and psycholinguistic literature2--that there is a direct connection between syntactic constituency and prosodic phrasing, with apparent misalignments readjusted before syntax interface,; with prosodic phonology.']","['', '', '', '', '', '', '', '', '', 'Thus phrasing, in their approach, is only indirectly related to syntax, since readjustment is done by special rules outside the grammar proper.', ' #TAUTHOR_TAG proposes readjustment rules similar to those of Chomsky and Halle , but he claims that the readjustment of structure is part of the grammar , not part of the performance model .', 'He thus makes explicit what is often a tacit assumption in both the linguistic and psycholinguistic literature2--that there is a direct connection between syntactic constituency and prosodic phrasing, with apparent misalignments readjusted before syntax interface,; with prosodic phonology.']",0
"['The psycholinguistic studies of #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', 'subject and verb do occur, there also exist prosodic patterns in which the boundary comes between the verb and object,', '', '', '']","['The psycholinguistic studies of #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', 'subject and verb do occur, there also exist prosodic patterns in which the boundary comes between the verb and object,', '', '', '']","['The psycholinguistic studies of #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', 'subject and verb do occur, there also exist prosodic patterns in which the boundary comes between the verb and object,', '', '', '']","['The psycholinguistic studies of #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '', '', '', '']",0
"['', '3 Suchasing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in #TAUTHOR_TAG , which ""are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when there is no good reason to take some other option"" (p. 251) .', 'This approach to prosodic phrase boundary determination brings us a framework in which phonological, syntactic, and discourse features all contribute to prosodic phrasing']","['', '3 Such phrasing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in #TAUTHOR_TAG , which ""are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when there is no good reason to take some other option"" (p. 251) .', 'This approach to prosodic phrase boundary determination brings us a framework in which phonological, syntactic, and discourse features all contribute to prosodic phrasing.']","['', '3 Such phrasing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in #TAUTHOR_TAG , which ""are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when there is no good reason to take some other option"" (p. 251) .', 'This approach to prosodic phrase boundary determination brings us a framework in which phonological, syntactic, and discourse features all contribute to prosodic phrasing']","['', '3 Such phrasing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in #TAUTHOR_TAG , which ""are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when there is no good reason to take some other option"" (p. 251) .', 'This approach to prosodic phrase boundary determination brings us closer to a framework in which phonological, syntactic, and discourse features all contribute to prosodic phrasing.']",1
"['', '', '', '', 'for such mismatches, ""readjustment rules"" that change constituent structure by adjoining each embedded sente, nce to the node dominating it have been posited.', 'The result is a flattened structure that more accurately reflects the prosodic phrasing.', 'In #TAUTHOR_TAG , this flattening process is not part of the grammar .', 'it is viewed as ""... a performance factor, related to the difficulty of producing right branching structures such as [ 12]"" (p.', '372).', 'is only indirectly related to since readjust outsidemar', '', '']","['', '', '', '', 'for such mismatches, ""readjustment rules"" that change constituent structure by adjoining each embedded sente, nce to the node dominating it have been posited.', 'The result is a flattened structure that more accurately reflects the prosodic phrasing.', 'In #TAUTHOR_TAG , this flattening process is not part of the grammar .', 'it is viewed as ""... a performance factor, related to the difficulty of producing right branching structures such as [ 12]"" (p.', '372).', 'is only indirectly related to since readjustment outside grammar', '', '']","['', '', '', '', 'for such mismatches, ""readjustment rules"" that change constituent structure by adjoining each embedded sente, nce to the node dominating it have been posited.', 'The result is a flattened structure that more accurately reflects the prosodic phrasing.', 'In #TAUTHOR_TAG , this flattening process is not part of the grammar .', 'it is viewed as ""... a performance factor, related to the difficulty of producing right branching structures such as [ 12]"" (p.', '372).', 'is only indirectly related to since readjust outside', '', '']","['', '', '', '', 'Sentences like 12, from #AUTHOR_TAG To account for such mismatches, ""readjustment rules"" that change constituent structure by adjoining each embedded sente, nce to the node dominating it have been posited.', 'The result is a flattened structure that more accurately reflects the prosodic phrasing.', 'In #TAUTHOR_TAG , this flattening process is not part of the grammar .', 'Rather, it is viewed as ""... a performance factor, related to the difficulty of producing right branching structures such as [ 12]"" (p.', '372).', '', '', '']",0
"['Following G&, we require that the prosody rules build a binary tree whose terminals are phonological words and whose node labels are indices that mark boundary salience.', 'An alternative representation based on #TAUTHOR_TAG is presented in #AUTHOR_TAG , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .', 'more des suitable for some aspects prosody (for, #AUTHOR_TAG use the grid representation for their implementation of stress in compound nom']","['Following G&G, we require that the prosody rules build a binary tree whose terminals are phonological words and whose node labels are indices that mark boundary salience.', 'An alternative representation based on #TAUTHOR_TAG is presented in #AUTHOR_TAG , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .', 'more suitable for some aspects prosody (for example, #AUTHOR_TAG use the grid representation for their implementation of stress in compound']","['Following G&G, we require that the prosody rules build a binary tree whose terminals are phonological words and whose node labels are indices that mark boundary salience.', 'An alternative representation based on #TAUTHOR_TAG is presented in #AUTHOR_TAG , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .', 'suitable for some aspects prosody (for example, #AUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nom']","['Following G&G, we require that the prosody rules build a binary tree whose terminals are phonological words and whose node labels are indices that mark boundary salience.', 'An alternative representation based on #TAUTHOR_TAG is presented in #AUTHOR_TAG , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .', '']",1
"['The syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', ' #TAUTHOR_TAG claims that prosodic phrase boundaries will co-occur with grammatical functions such as subject , predicate , modifier , and adjunct .', '', '', '', '', '', '', '', '', '', '', '', '']","['The syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', ' #TAUTHOR_TAG claims that prosodic phrase boundaries will co-occur with grammatical functions such as subject , predicate , modifier , and adjunct .', '', '', '', '', '', '', '', '', '', '', '', '']","['The syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', ' #TAUTHOR_TAG claims that prosodic phrase boundaries will co-occur with grammatical functions such as subject , predicate , modifier , and adjunct .', '', '', '', '', '', '', '', '', '', '', '', '']","['The syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', ' #TAUTHOR_TAG claims that prosodic phrase boundaries will co-occur with grammatical functions such as subject , predicate , modifier , and adjunct .', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['The psycholinguistic studies of #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', 'subject and verb do occur, there also exist prosodic patterns in which the boundary comes between the verb and object,', '', '', '']","['The psycholinguistic studies of #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', 'subject and verb do occur, there also exist prosodic patterns in which the boundary comes between the verb and object,', '', '', '']","['The psycholinguistic studies of #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', 'subject and verb do occur, there also exist prosodic patterns in which the boundary comes between the verb and object,', '', '', '']","['The psycholinguistic studies of #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , responding to the idea of readjusted syntax as the source of prosodic phrasing , show that grammatical structure , even if readjusted , is not in itself a reliable predictor of prosodic phrasing : mismatches between syntax and prosody occur often and systematically , and can be related to specific nonsyntactic factors such as length and word frequency .', '', '', '', '']",0
"['Existing text-to-ech systems perform well on word pronunciation and short sentences, 12 but when it comes to sentences and paragraphs, synthetic speech tends to be difficult to listen to and', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; #TAUTHOR_TAG ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to sentences and paragraphs, synthetic speech tends to be difficult to listen to and', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; #TAUTHOR_TAG ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; #TAUTHOR_TAG ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', 'And', '', '', '', '', '', '']","['Existing text-to-speech systems perform well on word pronunciation and short sentences, 12 but when it comes to long sentences and paragraphs, synthetic speech tends to be difficult to listen to and understand.', 'Many investigators (e.g.', 'Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; #TAUTHOR_TAG ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .', '', '', '', '', '', '', '']",4
"['ody build a terminals areological words whose node labels are indices boundary sal', 'presented pros', 'Although a grid may be more descriptively suitable for some aspects of prosody ( for example , #TAUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nominals ) , we are not aware of any evidence for or against a grid representation of discourseneutral phrasing .']","['prosody build a terminals are words whose node labels are indices boundary', 'presented', 'Although a grid may be more descriptively suitable for some aspects of prosody ( for example , #TAUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nominals ) , we are not aware of any evidence for or against a grid representation of discourseneutral phrasing .']","['build terminals areological words whose node labels are indices boundary salience.', 'is presented pros', 'Although a grid may be more descriptively suitable for some aspects of prosody ( for example , #TAUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nominals ) , we are not aware of any evidence for or against a grid representation of discourseneutral phrasing .']","['', '', 'Although a grid may be more descriptively suitable for some aspects of prosody ( for example , #TAUTHOR_TAG use the grid representation for their implementation of stress assignment in compound nominals ) , we are not aware of any evidence for or against a grid representation of discourseneutral phrasing .']",1
"['syntaxsodyalignment may be viewed as resulting in part from semantic considerations', 'predargument relations and discourse have been examined for their possible input to prosodic phrasing', '', '', 'Previous versions of our work , as described in #TAUTHOR_TAG also assume that phrasing is dependent on predicate-argument structure .', 'The problem here is that the phrasing in observed data often ignores the argument status of constituents.', '.', '', '', '', '', '', '', '', '']","['syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'predicateargument relations and discourse have been examined for their possible input to prosodic phrasing.', '', '', 'Previous versions of our work , as described in #TAUTHOR_TAG also assume that phrasing is dependent on predicate-argument structure .', 'The problem here is that the phrasing in observed data often ignores the argument status of constituents.', '', '', '', '', '', '', '', '', '']","['The syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing', '', '', 'Previous versions of our work , as described in #TAUTHOR_TAG also assume that phrasing is dependent on predicate-argument structure .', 'The problem here is that the phrasing in observed data often ignores the argument status of constituents.', '.', '', '', '', '', '', '', '', '']","['The syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', 'Both predicateargument relations and discourse factors have been examined for their possible input to prosodic phrasing.', '', '', 'Previous versions of our work , as described in #TAUTHOR_TAG also assume that phrasing is dependent on predicate-argument structure .', 'The problem here is that the phrasing in observed data often ignores the argument status of constituents.', '', '', '', '', '', '', '', '', '']",2
"['When itody especiallyasing it is often aactic node co more', 'This observation has led some researchers , e.g. , #TAUTHOR_TAG , to claim a direct mapping between the syntactic phrase and the prosodic phrase .', 'claim controversial because of the misadgnments that occur between the two levels of phrasing.', '', '', '', '', '', '', '', '', '']","['When it especially it is often a syntactic node cohere more', 'This observation has led some researchers , e.g. , #TAUTHOR_TAG , to claim a direct mapping between the syntactic phrase and the prosodic phrase .', ""claim controversial because of the misa'dgnments that occur between the two levels of phrasing."", '', '', '', '', '', '', '', '', '']","['When it comes especiallyasing it is often a sequence co more', 'This observation has led some researchers , e.g. , #TAUTHOR_TAG , to claim a direct mapping between the syntactic phrase and the prosodic phrase .', ""this claim controversial because of the misa'dgnments that occur between the two levels of phrasing."", '', '', '', '', '', '', '', '', '']","['', 'This observation has led some researchers , e.g. , #TAUTHOR_TAG , to claim a direct mapping between the syntactic phrase and the prosodic phrase .', ""However, this claim is controversial because of the misa'dgnments that occur between the two levels of phrasing."", '', '', '', '', '', '', '', '', '']",0
"['', 'pros patterns the boundary the object,', '', '', '4 The most explicit version of this approach is the analysis presented in #TAUTHOR_TAG ( henceforth G&G ) .']","['', 'patterns the boundary the object,', '', '', '.4 The most explicit version of this approach is the analysis presented in #TAUTHOR_TAG ( henceforth G&G ) .']","['', 'prosic patterns the boundary the verb object,', '', '', '4 The most explicit version of this approach is the analysis presented in #TAUTHOR_TAG ( henceforth G&G ) .']","['', '', '', '', '']",1
"['sody may be viewed as resulting in part from semantic considerations.', 'argument relations and discourse have examined forasing', '', '', '', '', '', '', '', 'The relation between discourse and prosodic phrasing has been examined in some detail by #TAUTHOR_TAG , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse .', 'Bing also observes that constituents that refer to items newly introduced into a discourse tend to be longer.', 'This may be the reason that word count and syllable count play a prominent role in prosodic phrasing (see Section 2.1.3', 'To our explicitly relation between the length a constituent and its in the disc', '', '']","['may be viewed as resulting in part from semantic considerations.', 'relations and discourse have examined for', '', '', '', '', '', '', '', 'The relation between discourse and prosodic phrasing has been examined in some detail by #TAUTHOR_TAG , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse .', 'Bing also observes that constituents that refer to items newly introduced into a discourse tend to be longer.', 'This may be the reason that word count and syllable count play a prominent role in prosodic phrasing (see Section 2.1.3.).', 'To our explicitly relation between the length a constituent and its in the', '', '']","['may be viewed as resulting in part from semantic considerations.', 'and discourse factors have been examined forasing', '', '', '', '', '', '', '', 'The relation between discourse and prosodic phrasing has been examined in some detail by #TAUTHOR_TAG , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse .', 'Bing also observes that constituents that refer to items newly introduced into a discourse tend to be longer.', 'This may be the reason that word count and syllable count play a prominent role in prosodic phrasing (see Section 2.1.3.).', 'To our has explicitly the relation between the length a constituent and its in the discourse.', '', '']","['The syntax/prosody misalignment may be viewed as resulting in part from semantic considerations.', '', '', '', '', '', '', '', '', 'The relation between discourse and prosodic phrasing has been examined in some detail by #TAUTHOR_TAG , who argues that each noun phrase in an utterance constitutes a separate prosodic phrase unless it is destressed because of reference to previous discourse .', 'Bing also observes that constituents that refer to items newly introduced into a discourse tend to be longer.', 'This may be the reason that word count and syllable count play a prominent role in prosodic phrasing (see Section 2.1.3.).', 'To our knowledge, no work has explicitly explored the relation between the length of a constituent and its status in the discourse.', '', '']",0
"['Our rules for phonological word formation are adopted , for the most part , from G & G , #TAUTHOR_TAG , and the account of monosyllabic destressing in #AUTHOR_TAG .', 'Thus in our analysis, rules of phonological word formation apply to the non-null terminal nodes in a syntax tree.', 'If the is a content word noun verb or then this may have the ph', 'internal', '', '', 'auxpos conj', '']","['Our rules for phonological word formation are adopted , for the most part , from G & G , #TAUTHOR_TAG , and the account of monosyllabic destressing in #AUTHOR_TAG .', 'Thus in our analysis, rules of phonological word formation apply to the non-null terminal nodes in a syntax tree.', 'If the is a content word, noun, verb, or then this may have the', 'internal', '', '', 'auxiliary', '']","['Our rules for phonological word formation are adopted , for the most part , from G & G , #TAUTHOR_TAG , and the account of monosyllabic destressing in #AUTHOR_TAG .', 'Thus in our analysis, rules of phonological word formation apply to the non-null terminal nodes in a syntax tree.', 'If the terminal is noun or then this terminal may have the status', '', '', '', 'aux conj', '']","['Our rules for phonological word formation are adopted , for the most part , from G & G , #TAUTHOR_TAG , and the account of monosyllabic destressing in #AUTHOR_TAG .', 'Thus in our analysis, rules of phonological word formation apply to the non-null terminal nodes in a syntax tree.', '', '', '', '', '', '']",5
"['', 'construction', 'ly the cooperative principle of #TAUTHOR_TAG , 1978 ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ; this to should .', '', '']","['', 'construction', 'Secondly the cooperative principle of #TAUTHOR_TAG , 1978 ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ; this to should .', '', '']","['', '', 'ly the cooperative principle of #TAUTHOR_TAG , 1978 ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ; this to', '', '']","['', '', 'Secondly , the cooperative principle of #TAUTHOR_TAG , 1978 ) , under the assumption that referential levels of a writer and a reader are quite similar , implies that the writer should structure the text in a way that makes the construction of his intended model easy for the reader ; and this seems to imply that he should appeal only to the most direct knowledge of the reader .', '', '']",4
"['At this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.', 'We are going to make such a comparison with the theories proposed by J. #TAUTHOR_TAG , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W. #AUTHOR_TAG , who are more interested in addressing psychological and cognitive aspects of discourse coherence .', 'The quoted works seem to be good representatives for each of the directions; they also point to related.']","['At this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.', 'We are going to make such a comparison with the theories proposed by J. #TAUTHOR_TAG , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W. #AUTHOR_TAG , who are more interested in addressing psychological and cognitive aspects of discourse coherence .', 'The quoted works seem to be good representatives for each of the directions; they also point to related literature.']","['At this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.', 'We are going to make such a comparison with the theories proposed by J. #TAUTHOR_TAG , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W. #AUTHOR_TAG , who are more interested in addressing psychological and cognitive aspects of discourse coherence .', 'The quoted works seem to be good representatives for each of the directions; they also point to related.']","['At this point it may be proper to comment on the relationship between our theory of coherence and theories advocated by others.', 'We are going to make such a comparison with the theories proposed by J. #TAUTHOR_TAG , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W. #AUTHOR_TAG , who are more interested in addressing psychological and cognitive aspects of discourse coherence .', 'The quoted works seem to be good representatives for each of the directions; they also point to related literature.']",1
"['Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure as- sumption"" (ibid.), ""domain circumscription"" (cf. #TAUTHOR_TAG , and their kin.', 'Similarly the notion of R+ M-duction is relatedosis from', '', '']","['Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure as- sumption"" (ibid.), ""domain circumscription"" (cf. #TAUTHOR_TAG , and their kin.', 'Similarly, the notion of R+ M-abduction is related from', '', '']","['Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure as- sumption"" (ibid.), ""domain circumscription"" (cf. #TAUTHOR_TAG , and their kin.', 'Similarly the notion of R+ M-abduction related from', '', '']","['Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure as- sumption"" (ibid.), ""domain circumscription"" (cf. #TAUTHOR_TAG , and their kin.', '', '', '']",1
['W. #TAUTHOR_TAG discussed sentences of the form * This is a chair but you can sit on it .'],['W. #TAUTHOR_TAG discussed sentences of the form * This is a chair but you can sit on it .'],['W. #TAUTHOR_TAG discussed sentences of the form * This is a chair but you can sit on it .'],['W. #TAUTHOR_TAG discussed sentences of the form * This is a chair but you can sit on it .'],0
"['ives function words conjunctions and some adbs--that are for co for signaling', 'And,""or,"" and ""but"" are the three main coordinating connectives in English', '""but"" does twoant, ""but a contrad and it have three subfunctions:', 'Opposition (called ""adversative"" or ""contrary-to-expectation"" by Halliday and Hasan 1976;cf. also #TAUTHOR_TAG , p. 672 ) .']","['Connectives function conjunctions and some adverbs--that are for for signaling', '""And,"" ""or,"" and ""but"" are the three main coordinating connectives in English.', '""but"" does two--semantically, ""but"" a and it have three subfunctions:', 'Opposition (called ""adversative"" or ""contrary-to-expectation"" by Halliday and Hasan 1976;cf. also #TAUTHOR_TAG , p. 672 ) .']","['ives function words--like conjunctions and some adverbs--that are for for sign', 'And,"" ""or,"" and ""but"" are the three main coordinating connectives in English', ', ""but"" does not a contradiction, and it seems have three subfunctions: . .', 'Opposition (called ""adversative"" or ""contrary-to-expectation"" by Halliday and Hasan 1976;cf. also #TAUTHOR_TAG , p. 672 ) .']","['', '""And,"" ""or,"" and ""but"" are the three main coordinating connectives in English.', '', 'Opposition (called ""adversative"" or ""contrary-to-expectation"" by Halliday and Hasan 1976;cf. also #TAUTHOR_TAG , p. 672 ) .']",0
"['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , #TAUTHOR_TAG , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , #TAUTHOR_TAG , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , #TAUTHOR_TAG , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , #TAUTHOR_TAG , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']",1
"['', ""ars allow nonsens collections words ( e.g. , `` colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ; #TAUTHOR_TAG , p. 546 ) gives 10 definitions of a sentence .""]","['', ""allow nonsensical collections words ( e.g. , `` colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ; #TAUTHOR_TAG , p. 546 ) gives 10 definitions of a sentence .""]","['', ""allow nonsensable collections words ( e.g. , `` colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ; #TAUTHOR_TAG , p. 546 ) gives 10 definitions of a sentence .""]","['', ""This problem may be similar to the situation in which current formal grammars allow nonsensical but parsable collections of words ( e.g. , `` colorless green ideas ... '' ) , while before the advent of Chomskyan formalisms , a sentence was defined as the smallest meaningful collection of words ; #TAUTHOR_TAG , p. 546 ) gives 10 definitions of a sentence .""]",0
"['All not going such as theory or model, will be finitary', ', a model fewer elements', '', 'The of not so for at the logic', 'This Principle of Finitism is also assumed by #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'possible fin to developics that is or has potential applications natural sciencecf.', '']","['All notions going such as theory or model, will be finitary.', 'example, a model fewer elements', '', 'The of not so for at the logic.', 'This Principle of Finitism is also assumed by #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'possible finitary to develop mathematics that is or has potential applications natural science, (cf.', '']","['All logical notions such as theory or model, will be finitary', ', a model fewer', '', 'The issues of are not so for at describing the logic.', 'This Principle of Finitism is also assumed by #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'possible to developics that is used or has potential applications natural science,cf.', '']","['All logical notions that we are going to consider, such as theory or model, will be finitary.', '', '', '', 'This Principle of Finitism is also assumed by #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', '', '']",1
"['', '', '', ""But , obviously , there are other possibilities -- for instance , the discourse representation structures ( DRS 's ) of #TAUTHOR_TAG , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora ."", '', '', '', '', '', '', '']","['', '', '', ""But , obviously , there are other possibilities -- for instance , the discourse representation structures ( DRS 's ) of #TAUTHOR_TAG , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora ."", '', '', '', '', '', '', '']","['', '', '', ""But , obviously , there are other possibilities -- for instance , the discourse representation structures ( DRS 's ) of #TAUTHOR_TAG , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora ."", '', '', '', '', '', '', '']","['', '', '', ""But , obviously , there are other possibilities -- for instance , the discourse representation structures ( DRS 's ) of #TAUTHOR_TAG , which have been used to translate a subset of English into logical formulas , to model text ( identified with a list of sentences ) , to analyze a fragment of English , and to deal with anaphora ."", '', '', '', '', '', '', '']",1
"['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the of abduction, which in this framework helps determine the universe of the model ( is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping #TAUTHOR_TAG must play a role , too .', 'of those the above metar, and syntactic clues, appears to be an interesting topic in itself.']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping #TAUTHOR_TAG must play a role , too .', 'of those the above metarules, and syntactic clues, appears to be an interesting topic in itself.']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model ( is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping #TAUTHOR_TAG must play a role , too .', 'of those factors, the above metarules, and syntactic clues, appears to be an interesting topic in itself.']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping #TAUTHOR_TAG must play a role , too .', 'Determining the relative importance of those factors, the above metarules, and syntactic clues, appears to be an interesting topic in itself.']",0
"['According to #TAUTHOR_TAG , p. 67 ) , these two sentences are incoherent .', 'However, the same fragment, augmented with the third sentence Mary told him yesterday that the French spinach crop failed and Turkey is the only country... (ibid.)', 'suddenly (for Hobbs) becomes coherent.', 'It that any of coherence in terms of the relation between subsequent sentences cannot explain this sudden change; after all, the first two sentences didn change when the third one was added.', '', '', '']","['According to #TAUTHOR_TAG , p. 67 ) , these two sentences are incoherent .', 'However, the same fragment, augmented with the third sentence Mary told him yesterday that the French spinach crop failed and Turkey is the only country... (ibid.)', 'suddenly (for Hobbs) becomes coherent.', 'It that any of coherence in terms of the relation between subsequent sentences cannot explain this sudden change; after all, the first two sentences change when the third one was added.', '', '', '']","['According to #TAUTHOR_TAG , p. 67 ) , these two sentences are incoherent .', 'However, the same fragment, augmented with the third sentence Mary told him yesterday that the French spinach crop failed and Turkey is the only country... (ibid.)', 'suddenly (for Hobbs) becomes coherent.', 'It seems that any analysis of coherence in terms of the relation between subsequent sentences cannot explain this sudden change; after all, the first two sentences didn change when the third one was added.', '', '', '']","['According to #TAUTHOR_TAG , p. 67 ) , these two sentences are incoherent .', 'However, the same fragment, augmented with the third sentence Mary told him yesterday that the French spinach crop failed and Turkey is the only country... (ibid.)', 'suddenly (for Hobbs) becomes coherent.', ""It seems that any analysis of coherence in terms of the relation between subsequent sentences cannot explain this sudden change; after all, the first two sentences didn't change when the third one was added."", '', '', '']",1
"['', '', 'this appar many natural language inferences are based on defaults, and quite often they can be reduced choosing most plausible interpretations of predicates.', 'For instance , relating ""they"" to ""apples"" in the sentence ( cfXXX #TAUTHOR_TAG p. 195 ; Zadrozny 1987a ) : We bought the boys apples because they were so cheap']","['', '', 'this apparatus many natural language inferences are based on defaults, and quite often they can be reduced choosing most plausible interpretations of predicates.', 'For instance , relating ""they"" to ""apples"" in the sentence ( cfXXX #TAUTHOR_TAG p. 195 ; Zadrozny 1987a ) : We bought the boys apples because they were so cheap']","['', '', 'this apparatus, many natural language inferences are based on defaults, and quite often they can be reduced choosing most plausible interpretations of predicates.', 'For instance , relating ""they"" to ""apples"" in the sentence ( cfXXX #TAUTHOR_TAG p. 195 ; Zadrozny 1987a ) : We bought the boys apples because they were so cheap']","['', '', 'It should not come as a surprise that we can now use this apparatus for text/discourse analysis; after all, many natural language inferences are based on defaults, and quite often they can be reduced to choosing most plausible interpretations of predicates.', 'For instance , relating ""they"" to ""apples"" in the sentence ( cfXXX #TAUTHOR_TAG p. 195 ; Zadrozny 1987a ) : We bought the boys apples because they were so cheap']",0
"['An of psych oriented research be in', 'These authors a paragraph a psychologically real unit of discourse', 'three to paragraph: ( wordsoun ad adverbs);2) pronoun reference; and (3) paragraph length, as determined spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in #AUTHOR_TAG and #TAUTHOR_TAG .']","['An of oriented research be in', 'These authors a paragraph a psychologically real unit of discourse,', 'three to paragraph: words adverbs); (2) pronoun reference; and (3) paragraph length, as determined spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in #AUTHOR_TAG and #TAUTHOR_TAG .']","['An example of psych oriented research work in', 'These authors a paragraph a psychologically real unit of discourse', 'to a paragraph: ( content wordsoun, adjectives, adverbs);2) pronoun reference; and (3) paragraph length, as determined spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in #AUTHOR_TAG and #TAUTHOR_TAG .']","['', '', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in #AUTHOR_TAG and #TAUTHOR_TAG .']",0
"['', '', '', 'information text furthermore , our reading of the analysis of five paragraphs by #TAUTHOR_TAG strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .', '']","['', '', '', 'information text furthermore , our reading of the analysis of five paragraphs by #TAUTHOR_TAG strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .', '']","['', '', '', 'information text furthermore , our reading of the analysis of five paragraphs by #TAUTHOR_TAG strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .', '']","['', '', '', 'Finally , it has been shown by #AUTHOR_TAG that the ratio of derived to explicit information necessary for understanding a piece of text is about 8:1 ; furthermore , our reading of the analysis of five paragraphs by #TAUTHOR_TAG strongly suggests that only the most direct or obvious inferences are being made in the process of building a model or constructing a theory of a paragraph .', '']",4
"['The last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX #TAUTHOR_TAG .', 'Brachman et al. 1985', 'KRYPTONs A-box encoding the object theory as a set of assertions, standard first order logicbox frame', 'purely functional systems', 'the the ent', '', '']","['The last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX #TAUTHOR_TAG .', 'Brachman et al. 1985).', ""KRYPTON's A-box, encoding the object theory as a set of assertions, standard first order logic;"", ""purely system's"", 'the the', '', '']","['The last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX #TAUTHOR_TAG .', 'Brachman et al. 1985', 'KRYPTONs A-box, encoding the object theory as a set of assertions, uses standard first order logic', 'is purely functional', 'the union the entailment', '', '']","['The last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX #TAUTHOR_TAG .', 'Brachman et al. 1985).', '', '', '', '', '']",1
"['may prove for comparison is worth mentioning at this point that the proposedar are distant cous of ""unique-name assumptionGen andsson), ""domain closure assumption"" (ibid.),', '""domain circumscription"" (cf.', 'Etherington and Mercer 1987), and.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of #TAUTHOR_TAG , the `` diagnosis from first principles '' of #AUTHOR_TAG , `` explainability '' of #AUTHOR_TAG , and the subset principle of #AUTHOR_TAG"", 'or the the Rdu', '']","['may prove for comparison, is worth mentioning at this point that the proposed are distant cousins of ""unique-name assumption"" and ""domain closure assumption"" (ibid.),', '""domain circumscription"" (cf.', 'Etherington and Mercer 1987), and kin.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of #TAUTHOR_TAG , the `` diagnosis from first principles '' of #AUTHOR_TAG , `` explainability '' of #AUTHOR_TAG , and the subset principle of #AUTHOR_TAG"", 'or the the R', '']","['may prove for comparison it is worth mentioning at this point that the proposedar are distant cousins of ""unique-name assumption""Gen and ""domain closure assumption"" (ibid.),', '""domain circumscription"" (cf.', 'Etherington and Mercer 1987), and.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of #TAUTHOR_TAG , the `` diagnosis from first principles '' of #AUTHOR_TAG , `` explainability '' of #AUTHOR_TAG , and the subset principle of #AUTHOR_TAG ."", 'or', '']","['Since techniques developed elsewhere may prove useful, at least for comparison, it is worth mentioning at this point that the proposed metarules are distant cousins of ""unique-name assumption"" (Genesereth and Nilsson 1987), ""domain closure assumption"" (ibid.),', '""domain circumscription"" (cf.', 'Etherington and Mercer 1987), and their kin.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of #TAUTHOR_TAG , the `` diagnosis from first principles '' of #AUTHOR_TAG , `` explainability '' of #AUTHOR_TAG , and the subset principle of #AUTHOR_TAG ."", '', '']",1
"['', '', '', '', 'The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ; #TAUTHOR_TAG to see what a formal interpretation of events in time might look like .', '', '']","['', '', '', '', 'The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ; #TAUTHOR_TAG to see what a formal interpretation of events in time might look like .', '', '']","['', '', '', '', 'The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ; #TAUTHOR_TAG to see what a formal interpretation of events in time might look like .', '', '']","['', '', '', '', 'The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ; #TAUTHOR_TAG to see what a formal interpretation of events in time might look like .', '', '']",0
"['', '', '', 'According to #TAUTHOR_TAG , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .', 'Paragraphs therefore give hierarchical structure to sentences.s discusses three major types of paragraphs, and their segment types.', 'The three types are procedural (how-to), ex- pository (essay), and narrative (in this, spont conversation).', 'For each type, its segments are distinguished by bearing distinct relationships to the paragraph topic (which is central,', '']","['', '', '', 'According to #TAUTHOR_TAG , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .', 'Paragraphs therefore give hierarchical structure to sentences. Hinds discusses three major types of paragraphs, and their segment types.', 'The three types are procedural (how-to), ex- pository (essay), and narrative (in this case, spontaneous conversation).', 'For each type, its segments are distinguished by bearing distinct relationships to the paragraph topic (which is central,', '']","['', '', '', 'According to #TAUTHOR_TAG , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .', 'Paragraphs therefore give hierarchical structure to sentences.s discusses three major types of paragraphs, and their corresponding segment types.', 'The three types are procedural (how-to), ex- pository (essay), and narrative (in this, spontaneous conversation).', 'For each type, its segments are distinguished by bearing distinct relationships to the paragraph topic (which is central,', '']","['', '', '', 'According to #TAUTHOR_TAG , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .', 'Paragraphs therefore give hierarchical structure to sentences. Hinds discusses three major types of paragraphs, and their corresponding segment types.', 'The three types are procedural (how-to), ex- pository (essay), and narrative (in this case, spontaneous conversation).', 'For each type, its segments are distinguished by bearing distinct relationships to the paragraph topic (which is central, but nowhere clearly defined).', '']",0
"['may prove for is worth mentioning at this point that the proposedar are distant cous of ""unique-name assumptionGen), ""domain assumption"" (ib.),', '""domain circumscription"" (cf.', 'ther and Mercer 1987), and.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of #AUTHOR_TAG , the `` diagnosis from first principles '' of #TAUTHOR_TAG , `` explainability '' of #AUTHOR_TAG , and the subset principle of #AUTHOR_TAG ."", 'or the provability and the R + M-duction', '']","['may prove for is worth mentioning at this point that the proposed are distant cousins of ""unique-name assumption"" ""domain assumption"" (ibid.),', '""domain circumscription"" (cf.', 'and Mercer 1987), and kin.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of #AUTHOR_TAG , the `` diagnosis from first principles '' of #TAUTHOR_TAG , `` explainability '' of #AUTHOR_TAG , and the subset principle of #AUTHOR_TAG ."", 'or the provability and the R + M-abduction', '']","['may prove for it is worth mentioning at this point that the proposedar are distant cousins of ""unique-name assumption""Gen ""domain closure assumption"" (ib.),', '""domain circumscription"" (cf.', 'ther and Mercer 1987), and.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of #AUTHOR_TAG , the `` diagnosis from first principles '' of #TAUTHOR_TAG , `` explainability '' of #AUTHOR_TAG , and the subset principle of #AUTHOR_TAG ."", 'or the provability and the R + M-abduction', '']","['', '""domain circumscription"" (cf.', 'Etherington and Mercer 1987), and their kin.', ""Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of #AUTHOR_TAG , the `` diagnosis from first principles '' of #TAUTHOR_TAG , `` explainability '' of #AUTHOR_TAG , and the subset principle of #AUTHOR_TAG ."", '', '']",1
"['Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ; #TAUTHOR_TAG ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', 'wet pursue this topic further.']","['Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ; #TAUTHOR_TAG ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', 'we pursue this topic further here.']","['Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ; #TAUTHOR_TAG ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', ""we won't pursue this topic further.""]","['Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ; #TAUTHOR_TAG ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', ""But we won't pursue this topic further here.""]",1
"['Unless explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=) of L is going to be used only in Section 5 for dealing with noun phrase references.', ""This means that natural language expressions such as `` A is B , '' `` A is the same as B , '' etc. are not directly represented by logical equality ; similarly , `` not '' is often not treated as logical negation ; cfXXX #TAUTHOR_TAG ."", ' #AUTHOR_TAG .']","['Unless explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=) of L is going to be used only in Section 5 for dealing with noun phrase references.', ""This means that natural language expressions such as `` A is B , '' `` A is the same as B , '' etc. are not directly represented by logical equality ; similarly , `` not '' is often not treated as logical negation ; cfXXX #TAUTHOR_TAG ."", ' #AUTHOR_TAG .']","['Unless explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=) of L is going to be used only in Section 5 for dealing with noun phrase references.', ""This means that natural language expressions such as `` A is B , '' `` A is the same as B , '' etc. are not directly represented by logical equality ; similarly , `` not '' is often not treated as logical negation ; cfXXX #TAUTHOR_TAG ."", ' #AUTHOR_TAG .']","['Unless explicitly stated otherwise, we assume that formulas are expressed in a certain (formal) language L without equality; the extension L(=) of L is going to be used only in Section 5 for dealing with noun phrase references.', ""This means that natural language expressions such as `` A is B , '' `` A is the same as B , '' etc. are not directly represented by logical equality ; similarly , `` not '' is often not treated as logical negation ; cfXXX #TAUTHOR_TAG ."", ' #AUTHOR_TAG .']",1
"['Note: The notions of strong provability and strong R + M-abduction can be in- troduced by replacing ""there exists"" by ""all"" in the above definitions (cf. #TAUTHOR_TAG b ).', 'We will have, however, no need for ""strong"" notions in this paper', 'satisf']","['Note: The notions of strong provability and strong R + M-abduction can be in- troduced by replacing ""there exists"" by ""all"" in the above definitions (cf. #TAUTHOR_TAG b ).', 'We will have, however, no need for ""strong"" notions in this paper.', '']","['Note: The notions of strong provability and strong R + M-abduction can be in- troduced by replacing ""there exists"" by ""all"" in the above definitions (cf. #TAUTHOR_TAG b ).', 'We will have, however, no need for ""strong"" notions in this paper.', '']","['Note: The notions of strong provability and strong R + M-abduction can be in- troduced by replacing ""there exists"" by ""all"" in the above definitions (cf. #TAUTHOR_TAG b ).', 'We will have, however, no need for ""strong"" notions in this paper.', '']",1
"['Adding selectional restrictions ( semantic feature information , #TAUTHOR_TAG does not solve the problem , because isolated features offer only part of the background knowledge necessary for reference disambiguation .', '']","['Adding selectional restrictions ( semantic feature information , #TAUTHOR_TAG does not solve the problem , because isolated features offer only part of the background knowledge necessary for reference disambiguation .', '']","['Adding selectional restrictions ( semantic feature information , #TAUTHOR_TAG does not solve the problem , because isolated features offer only part of the background knowledge necessary for reference disambiguation .', '']","['Adding selectional restrictions ( semantic feature information , #TAUTHOR_TAG does not solve the problem , because isolated features offer only part of the background knowledge necessary for reference disambiguation .', '']",0
"['', '', '', 'to a formal semantics', 'The reader may consult recent papers on this subject ( e.g. #TAUTHOR_TAG ; Webber 1987 ) to see what a formal interpretation of events in time might look like .', '', '']","['', '', '', 'to a formal semantics', 'The reader may consult recent papers on this subject ( e.g. #TAUTHOR_TAG ; Webber 1987 ) to see what a formal interpretation of events in time might look like .', '', '']","['', '', '', 'to a formal semantics', 'The reader may consult recent papers on this subject ( e.g. #TAUTHOR_TAG ; Webber 1987 ) to see what a formal interpretation of events in time might look like .', '', '']","['', '', '', '', 'The reader may consult recent papers on this subject ( e.g. #TAUTHOR_TAG ; Webber 1987 ) to see what a formal interpretation of events in time might look like .', '', '']",0
"['Since it is the ""hhest"" path, fint is the most plausible (relative to R) interpretation of the words that appear in the sentence.', 'Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX #TAUTHOR_TAG a , 1987b ) .', 'Zadrozny 1987a #AUTHOR_TAG b.', '', 'is constructed']","['Since it is the ""highest"" path, fint is the most plausible (relative to R) interpretation of the words that appear in the sentence.', 'Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX #TAUTHOR_TAG a , 1987b ) .', 'Zadrozny 1987a #AUTHOR_TAG b.', '', 'is constructed']","['Since it is the ""highest"" path, fint is the most plausible (relative to R) interpretation of the words that appear in the sentence.', 'Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX #TAUTHOR_TAG a , 1987b ) .', 'Zadrozny 1987a #AUTHOR_TAG b.', '', 'is never constructed']","['Since it is the ""highest"" path, fint is the most plausible (relative to R) interpretation of the words that appear in the sentence.', 'Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX #TAUTHOR_TAG a , 1987b ) .', 'Zadrozny 1987a #AUTHOR_TAG b.', '', '']",0
"['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , #TAUTHOR_TAG , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , #TAUTHOR_TAG , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , #TAUTHOR_TAG , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , #TAUTHOR_TAG , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']",1
"['All going theory or model, will be finitary', 'a fewer elements', '', '', '', 'As a logical postulate not very it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX #TAUTHOR_TAG .', 'Mycielski 1981).']","['All going theory or model, will be finitary.', 'a fewer elements', '', '', '', 'As a logical postulate not very it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX #TAUTHOR_TAG .', 'Mycielski 1981).']","['theory or model, will be finitary', 'fewer', '', '', '', 'As a logical postulate it is not very it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX #TAUTHOR_TAG .', 'Mycielski 1981).']","['', '', '', '', '', 'As a logical postulate it is not very radical ; it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX #TAUTHOR_TAG .', 'Mycielski 1981).']",0
"['We have shown elsewhere #TAUTHOR_TAG ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory.']","['We have shown elsewhere #TAUTHOR_TAG ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory.']","['We have shown elsewhere #TAUTHOR_TAG ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory.']","['We have shown elsewhere #TAUTHOR_TAG ; Zadrozny 1987a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory.']",2
"['The necessity of this kind of merging of arguments has been recognized before : #TAUTHOR_TAG call it abductive unification/matching , #AUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .']","['The necessity of this kind of merging of arguments has been recognized before : #TAUTHOR_TAG call it abductive unification/matching , #AUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .']","['The necessity of this kind of merging of arguments has been recognized before : #TAUTHOR_TAG call it abductive unification/matching , #AUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .']","['The necessity of this kind of merging of arguments has been recognized before : #TAUTHOR_TAG call it abductive unification/matching , #AUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .']",0
"['', '', '', 'to', 'The logical notation of #TAUTHOR_TAG is more sophisticated , and may be considered another possibility .', '', '', '', '', '', '']","['', '', '', 'to', 'The logical notation of #TAUTHOR_TAG is more sophisticated , and may be considered another possibility .', '', '', '', '', '', '']","['', '', '', 'to', 'The logical notation of #TAUTHOR_TAG is more sophisticated , and may be considered another possibility .', '', '', '', '', '', '']","['', '', '', '', 'The logical notation of #TAUTHOR_TAG is more sophisticated , and may be considered another possibility .', '', '', '', '', '', '']",1
"['All not going such theory or model, will be finitary', ', a model fewer a hundred elements', '', 'The', 'This Principle of Finitism is also assumed by Johnson- #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'very possible fin to developics that is or has potential applications in natural sciencecf.', '']","['All notions going such theory or model, will be finitary.', 'example, a model fewer a hundred elements', '', 'The', 'This Principle of Finitism is also assumed by Johnson- #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'very possible finitary to develop mathematics that is or has potential applications in natural science, (cf.', '']","['All logical notions such theory or model, will be finitary', ', a model fewer a hundred elements', '', 'The issues', 'This Principle of Finitism is also assumed by Johnson- #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'possible to developics that is used or has potential applications in natural science,cf.', '']","['All logical notions that we are going to consider, such as theory or model, will be finitary.', '', '', '', 'This Principle of Finitism is also assumed by Johnson- #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', '', '']",1
"['paragraph', 'tax', 'lists , class and discuss in `` the linguistic-logical notions of consequent and presupposition #TAUTHOR_TAG :112 ) have collected convincing evidence of the existence of language chunks -- real structures , not just orthographic conventions -- that are smaller than a discourse , larger a sentence , generally composed of sentences , and recursive in nature ( like sentences ) .', 'These chunks are sometimes called ""episodes ""paragraph', '', '', '', '', '', '']","['paragraph', '', 'lists , classifies and discusses inference `` the linguistic-logical notions of consequent and presupposition #TAUTHOR_TAG :112 ) have collected convincing evidence of the existence of language chunks -- real structures , not just orthographic conventions -- that are smaller than a discourse , larger a sentence , generally composed of sentences , and recursive in nature ( like sentences ) .', 'These chunks are sometimes called ""episodes,"" ""paragraphs.""', '', '', '', '', '', '']","['paragraph', '', 'He lists , class and discuss in `` the linguistic-logical notions of consequent and presupposition #TAUTHOR_TAG :112 ) have collected convincing evidence of the existence of language chunks -- real structures , not just orthographic conventions -- that are smaller than a discourse , larger a sentence , generally composed of sentences , and recursive in nature ( like sentences ) .', 'These chunks are sometimes called ""episodes ""paragraph', '', '', '', '', '', '']","['', '', 'He lists , classifies , and discusses various types of inference , by which he means , generally , `` the linguistic-logical notions of consequent and presupposition #TAUTHOR_TAG :112 ) have collected convincing evidence of the existence of language chunks -- real structures , not just orthographic conventions -- that are smaller than a discourse , larger than a sentence , generally composed of sentences , and recursive in nature ( like sentences ) .', 'These chunks are sometimes called ""episodes,"" and sometimes ""paragraphs.""', '', '', '', '', '', '']",0
"['the word ""up"" is given its meaning relative to our experience with gravity, it is not free to ""slip"" into its opposite', '', '', 'beautyically ""Death is the beautys', 'It is otherual', 'We investigate here only the ""grounding"" in logical theories.', 'However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX #TAUTHOR_TAG .', '1987']","['the word ""up"" is given its meaning relative to our experience with gravity, it is not free to ""slip"" into its opposite.', '', '', 'beauty"" poetically ""Death is the beauty"" succeeds', 'It is other conceptual', 'We investigate here only the ""grounding"" in logical theories.', 'However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX #TAUTHOR_TAG .', '1987).']","['Once the word ""up"" is given its meaning relative to our experience with gravity, it is not free to ""slip"" into its opposite', '', '', 'beautyically ""Death is the mother beautys', 'It is precisely other conceptual structures', 'We investigate here only the ""grounding"" in logical theories.', 'However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX #TAUTHOR_TAG .', 'Woods 1987).']","['Once the word ""up"" is given its meaning relative to our experience with gravity, it is not free to ""slip"" into its opposite.', '', '', '', '', 'We investigate here only the ""grounding"" in logical theories.', 'However , it is possible to think about constraining linguistic or logical predicates by simulating physical experiences ( cfXXX #TAUTHOR_TAG .', 'Woods 1987).']",0
"['', '', '', '', 'notation of #AUTHOR_TAG is more be.', ' #AUTHOR_TAG formalism is richer and resembles more closely an English grammar.', "" #TAUTHOR_TAG , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''"", 'Therefore a formalism of the kind he advocates would probably be most suitable for an implementation of our semantics.', 'It will also be a model for our simplified logical notation (cf.', '', '']","['', '', '', '', 'notation of #AUTHOR_TAG is more be possibility.', ' #AUTHOR_TAG formalism is richer and resembles more closely an English grammar.', "" #TAUTHOR_TAG , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''"", 'Therefore a formalism of the kind he advocates would probably be most suitable for an implementation of our semantics.', 'It will also be a model for our simplified logical notation (cf.', '', '']","['', '', '', '', 'of #AUTHOR_TAG is more', ' #AUTHOR_TAG formalism is richer and resembles more closely an English grammar.', "" #TAUTHOR_TAG , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''"", 'Therefore a formalism of the kind he advocates would probably be most suitable for an implementation of our semantics.', 'It will also be a model for our simplified logical notation (cf.', '', '']","['', '', '', '', '', ' #AUTHOR_TAG formalism is richer and resembles more closely an English grammar.', "" #TAUTHOR_TAG , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''"", 'Therefore a formalism of the kind he advocates would probably be most suitable for an implementation of our semantics.', 'It will also be a model for our simplified logical notation (cf.', '', '']",1
"['An example of psycholinguistically oriented research work can be found in #TAUTHOR_TAG .', 'These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholinguistic studies that confirm the validity of paragraph units can be found in #AUTHOR_TAG and #AUTHOR_TAG .']","['An example of psycholinguistically oriented research work can be found in #TAUTHOR_TAG .', 'These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholinguistic studies that confirm the validity of paragraph units can be found in #AUTHOR_TAG and #AUTHOR_TAG .']","['An example of psycholinguistically oriented research work can be found in #TAUTHOR_TAG .', 'These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholinguistic studies that confirm the validity of paragraph units can be found in #AUTHOR_TAG and #AUTHOR_TAG .']","['An example of psycholinguistically oriented research work can be found in #TAUTHOR_TAG .', 'These authors take the position that a paragraph is a psychologically real unit of discourse, and, in fact, a formal grammatical unit.', 'Bond and Hayes found three major formal devices that are used, by readers, to identify a paragraph: (1) the repetition of content words (nouns, verbs, adjectives, adverbs); (2) pronoun reference; and (3) paragraph length, as determined by spatial and/or sentence-count information.', 'Other psycholinguistic studies that confirm the validity of paragraph units can be found in #AUTHOR_TAG and #AUTHOR_TAG .']",0
"['This demonstr information needed to identify and resolve anaphoric can be to an interesting d and thesaur.', '(Other reference works could be treated as additional sources of world knowledge.)', 'This type of consultation uses existing natural language texts as a referential level for processing purposes.', 'It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit.', "" #TAUTHOR_TAG , p. 112 ) , for example , bemoans the fact that his `` theory lacks a world knowledge component , a mental ` encyclopedia , ' which could be invoked to generate inferences ... '' ."", '', '', '', '']","['This demonstrates information needed to identify and resolve anaphoric can be to an interesting and thesauri.', '(Other reference works could be treated as additional sources of world knowledge.)', 'This type of consultation uses existing natural language texts as a referential level for processing purposes.', 'It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit.', "" #TAUTHOR_TAG , p. 112 ) , for example , bemoans the fact that his `` theory lacks a world knowledge component , a mental ` encyclopedia , ' which could be invoked to generate inferences ... '' ."", '', '', '', '']","['This demonstr information needed to identify and resolve anaphoric references can be found, to an interesting extent, and thesaur.', '(Other reference works could be treated as additional sources of world knowledge.)', 'This type of consultation uses existing natural language texts as a referential level for processing purposes.', 'It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit.', "" #TAUTHOR_TAG , p. 112 ) , for example , bemoans the fact that his `` theory lacks a world knowledge component , a mental ` encyclopedia , ' which could be invoked to generate inferences ... '' ."", '', '', '', '']","['This demonstrates that information needed to identify and resolve anaphoric references can be found, to an interesting extent, in standard dictionaries and thesauri.', '(Other reference works could be treated as additional sources of world knowledge.)', 'This type of consultation uses existing natural language texts as a referential level for processing purposes.', 'It is the lack of exactly this notion of referential level that has stood in the way of other linguists who have been interested in the paragraph as a unit.', "" #TAUTHOR_TAG , p. 112 ) , for example , bemoans the fact that his `` theory lacks a world knowledge component , a mental ` encyclopedia , ' which could be invoked to generate inferences ... '' ."", '', '', '', '']",0
"['6.1.1 Was the Use of a Gricean Maxim Necessary?', 'Can one deal effectivelywith the problem of reference without axiomatized Gricean maxims, for instance by using only ""petty conversational implicature"" #TAUTHOR_TAG , or the metarules of Section 5.2?', 'It seems to us that the answer is no.']","['6.1.1 Was the Use of a Gricean Maxim Necessary?', 'Can one deal effectivelywith the problem of reference without axiomatized Gricean maxims, for instance by using only ""petty conversational implicature"" #TAUTHOR_TAG , or the metarules of Section 5.2?', 'It seems to us that the answer is no.']","['6.1.1 Was the Use of a Gricean Maxim Necessary?', 'Can one deal effectivelywith the problem of reference without axiomatized Gricean maxims, for instance by using only ""petty conversational implicature"" #TAUTHOR_TAG , or the metarules of Section 5.2?', 'It seems to us that the answer is no.']","['6.1.1 Was the Use of a Gricean Maxim Necessary?', 'Can one deal effectivelywith the problem of reference without axiomatized Gricean maxims, for instance by using only ""petty conversational implicature"" #TAUTHOR_TAG , or the metarules of Section 5.2?', 'It seems to us that the answer is no.']",0
"['We adopt the three-level semantics as a formal tool for the analysis of paragraphs.', 'This semantics was constructed #TAUTHOR_TAG a , 1987b ) as a formal framework for default and commonsense reasoning .', 'It should not come as a surprise that we can now use this apparatus for text/discourse analysis many in are', 'ap', '']","['We adopt the three-level semantics as a formal tool for the analysis of paragraphs.', 'This semantics was constructed #TAUTHOR_TAG a , 1987b ) as a formal framework for default and commonsense reasoning .', 'It should not come as a surprise that we can now use this apparatus for text/discourse analysis; many inferences are', '', '']","['We adopt the three-level semantics as a formal tool for the analysis of paragraphs.', 'This semantics was constructed #TAUTHOR_TAG a , 1987b ) as a formal framework for default and commonsense reasoning .', 'It should not come as a surprise that we can now use this apparatus for text/discourse analysis; are based', 'ap', '']","['We adopt the three-level semantics as a formal tool for the analysis of paragraphs.', 'This semantics was constructed #TAUTHOR_TAG a , 1987b ) as a formal framework for default and commonsense reasoning .', '', '', '']",5
"['may prove for is worth mentioning at this point that the proposedar are distant cousins of ""unique-name assumption""Gensson), ""domain assumption"" (ib.),', '""domain circumscription"" (cf.', 'andcer 7),', 'the notion of R + M-abduction is spiritually related to the ""abductive inference"" of #AUTHOR_TAG , the ""diagnosis from first principles"" of #AUTHOR_TAG , ""explainability"" of #AUTHOR_TAG , and the subset principle of #TAUTHOR_TAG .', 'to establish precise connections for the metar or the provability and the R + M-abduction scope for', '']","['may prove for is worth mentioning at this point that the proposed are distant cousins of ""unique-name assumption"" ""domain assumption"" (ibid.),', '""domain circumscription"" (cf.', 'and Mercer 1987),', 'the notion of R + M-abduction is spiritually related to the ""abductive inference"" of #AUTHOR_TAG , the ""diagnosis from first principles"" of #AUTHOR_TAG , ""explainability"" of #AUTHOR_TAG , and the subset principle of #TAUTHOR_TAG .', 'to establish precise connections for the metarules or the provability and the R + M-abduction scope for', '']","['may prove for it is worth mentioning at this point that the proposedar are distant cousins of ""unique-name assumption""Gen ""domain closure assumption"" (ib.),', '""domain circumscription"" (cf.', 'andcer 1987),', 'the notion of R + M-abduction is spiritually related to the ""abductive inference"" of #AUTHOR_TAG , the ""diagnosis from first principles"" of #AUTHOR_TAG , ""explainability"" of #AUTHOR_TAG , and the subset principle of #TAUTHOR_TAG .', 'to establish precise connections for the metarules or the provability and the R + M-abduction the scope for', '']","['', '""domain circumscription"" (cf.', '', 'Similarly, the notion of R + M-abduction is spiritually related to the ""abductive inference"" of #AUTHOR_TAG , the ""diagnosis from first principles"" of #AUTHOR_TAG , ""explainability"" of #AUTHOR_TAG , and the subset principle of #TAUTHOR_TAG .', '', '']",1
"['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 , #TAUTHOR_TAG , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 , #TAUTHOR_TAG , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 , #TAUTHOR_TAG , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']","['Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 , #TAUTHOR_TAG , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']",1
"['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; #TAUTHOR_TAG or quantifier scoping ( Webber 1983 ) must play a role , too .', 'of those, the abovear synt clues, appears to an interesting in.']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; #TAUTHOR_TAG or quantifier scoping ( Webber 1983 ) must play a role , too .', 'of those factors, the above syntactic clues, appears to an interesting in itself.']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; #TAUTHOR_TAG or quantifier scoping ( Webber 1983 ) must play a role , too .', 'of those factors, the above metarules, syntactic clues, appears to an interesting topic in.']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus ( Grosz 1977 , 1978 ; #TAUTHOR_TAG or quantifier scoping ( Webber 1983 ) must play a role , too .', 'Determining the relative importance of those factors, the above metarules, and syntactic clues, appears to be an interesting topic in itself.']",0
"['The referential structures we are going to use are collections of logical theories, but the concept of reference is more general.', 'Some of the intuitions we associate with this notion have been very well expressed by #TAUTHOR_TAG , pp. 7-8 ) : ... Semantics is constrained by our models of ourselves and our worlds .', 'We have models of']","['The referential structures we are going to use are collections of logical theories, but the concept of reference is more general.', 'Some of the intuitions we associate with this notion have been very well expressed by #TAUTHOR_TAG , pp. 7-8 ) : ... Semantics is constrained by our models of ourselves and our worlds .', 'We have models of']","['The referential structures we are going to use are collections of logical theories, but the concept of reference is more general.', 'Some of the intuitions we associate with this notion have been very well expressed by #TAUTHOR_TAG , pp. 7-8 ) : ... Semantics is constrained by our models of ourselves and our worlds .', 'We have models of']","['The referential structures we are going to use are collections of logical theories, but the concept of reference is more general.', 'Some of the intuitions we associate with this notion have been very well expressed by #TAUTHOR_TAG , pp. 7-8 ) : ... Semantics is constrained by our models of ourselves and our worlds .', '']",0
"['The idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be a declar ( or static version of marker passing ( Hirst 1987 ; #TAUTHOR_TAG with one difference : the activation spreads to theories that share a predicate , not through the IS-A hierarchy , and is limited to elementary facts about predicates appearing in the text .""]","['The idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be a declarative ( or static version of marker passing ( Hirst 1987 ; #TAUTHOR_TAG with one difference : the activation spreads to theories that share a predicate , not through the IS-A hierarchy , and is limited to elementary facts about predicates appearing in the text .""]","['The idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood a declar ( or static version of marker passing ( Hirst 1987 ; #TAUTHOR_TAG with one difference : the activation spreads to theories that share a predicate , not through the IS-A hierarchy , and is limited to elementary facts about predicates appearing in the text .""]","['The idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing ( Hirst 1987 ; #TAUTHOR_TAG , with one difference : the activation spreads to theories that share a predicate , not through the IS-A hierarchy , and is limited to elementary facts about predicates appearing in the text .""]",1
"['Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX #TAUTHOR_TAG ; Frisch 1987 ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', 'wet pursue this topic further here.']","['Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX #TAUTHOR_TAG ; Frisch 1987 ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', 'we pursue this topic further here.']","['Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX #TAUTHOR_TAG ; Frisch 1987 ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', ""we won't pursue this topic further here.""]","['Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX #TAUTHOR_TAG ; Frisch 1987 ; Patel-Schneider 1985 ) .', 'Levesque 1984;Frisch 1987;Patel-Schneider 1985).', ""But we won't pursue this topic further here.""]",1
"['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus #TAUTHOR_TAG , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too', 'thosear interesting']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus #TAUTHOR_TAG , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too', 'those interesting']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus #TAUTHOR_TAG , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too .', '']","['We have no doubts that various other metarules will be necessary; clearly, our two metarules cannot constitute the whole theory of anaphora resolution.', 'They are intended as an illustration of the power of abduction, which in this framework helps determine the universe of the model (that is the set of entities that appear in it).', 'Other factors , such as the role of focus #TAUTHOR_TAG , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too .', '']",0
"['', '3', 'This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose #TAUTHOR_TAG , p. 329 ) .']","['', '', 'This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose #TAUTHOR_TAG , p. 329 ) .']","['', '3', 'This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose #TAUTHOR_TAG , p. 329 ) .']","['', '', 'This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose #TAUTHOR_TAG , p. 329 ) .']",4
"['We can also hope for some fine-tuning of the notion of topic, which would prevent many offensive examples.', 'This approach is taken in computational syntactic grammars (e.g.', ' #TAUTHOR_TAG ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the so-called grammatical strings of a language .']","['We can also hope for some fine-tuning of the notion of topic, which would prevent many offensive examples.', 'This approach is taken in computational syntactic grammars (e.g.', ' #TAUTHOR_TAG ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the so-called grammatical strings of a language .']","['We can also hope for some fine-tuning of the notion of topic, which would prevent many offensive examples.', 'This approach is taken in computational syntactic grammars (e.g.', ' #TAUTHOR_TAG ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the so-called grammatical strings of a language .']","['We can also hope for some fine-tuning of the notion of topic, which would prevent many offensive examples.', 'This approach is taken in computational syntactic grammars (e.g.', ' #TAUTHOR_TAG ; the number of unlikely parses is severely reduced whenever possible , but no attempt is made to define only the so-called grammatical strings of a language .']",0
"['The idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing #TAUTHOR_TAG ; Charnak 1983""]","['The idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing #TAUTHOR_TAG ; Charniak 1983""]","['The idea of using preferences among theories is new, hence it was described in more detail.', ""`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing #TAUTHOR_TAG ; Charnak 1983""]","['The idea of using preferences among theories is new, hence it was described in more detail.', '']",1
"['We Gla way rule', 'we can aomatize andively a rule', 'We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by #TAUTHOR_TAG .']","['We Gla way rule', 'we can axiomatize and productively a rule.', 'We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by #TAUTHOR_TAG .']","['Gla unique way', 'we stress can axiomatize andively such a rule.', 'We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by #TAUTHOR_TAG .']","['', '', 'We shall see this in the next example : two sentences , regarded as a fragment of paragraph , are a variation on a theme by #TAUTHOR_TAG .']",2
"['Connectives function words-- conjunctions and some adverbs--that are responsible simultaneously maintaining co within for signaling the and', 'And,""or,"" and ""but"" are the three main coordinating connectives in English', ', ""but"" does not behave quite like the other two--semantically, ""but"" signals a contradiction, and in this role it seems to have three subfunctions:', 'Opposition ( called ""adversative"" or ""contrary-to-expectation"" by #TAUTHOR_TAG ; cfXXX also Quirk et al. 1972 , p. 672 ) .']","['Connectives function words--like conjunctions and some adverbs--that are responsible simultaneously maintaining within for signaling the and', '""And,"" ""or,"" and ""but"" are the three main coordinating connectives in English.', 'However, ""but"" does not behave quite like the other two--semantically, ""but"" signals a contradiction, and in this role it seems to have three subfunctions:', 'Opposition ( called ""adversative"" or ""contrary-to-expectation"" by #TAUTHOR_TAG ; cfXXX also Quirk et al. 1972 , p. 672 ) .']","['Connectives function words--like conjunctions and some adverbs--that are responsible simultaneously maintaining cohesiveness within for signaling the nature and', 'And,"" ""or,"" and ""but"" are the three main coordinating connectives in English', ', ""but"" does not behave quite like the other two--semantically, ""but"" signals a contradiction, and in this role it seems to have three subfunctions: . .', 'Opposition ( called ""adversative"" or ""contrary-to-expectation"" by #TAUTHOR_TAG ; cfXXX also Quirk et al. 1972 , p. 672 ) .']","['Connectives are function words--like conjunctions and some adverbs--that are responsible simultaneously for maintaining cohesiveness within the text and for signaling the nature of the relationships that hold between and among various text units.', '""And,"" ""or,"" and ""but"" are the three main coordinating connectives in English.', 'However, ""but"" does not behave quite like the other two--semantically, ""but"" signals a contradiction, and in this role it seems to have three subfunctions: . .', 'Opposition ( called ""adversative"" or ""contrary-to-expectation"" by #TAUTHOR_TAG ; cfXXX also Quirk et al. 1972 , p. 672 ) .']",0
"['Although there are other discussions of the paragraph as a central element of discourse (e.g.', ' #TAUTHOR_TAG , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure', '', '']","['Although there are other discussions of the paragraph as a central element of discourse (e.g.', ' #TAUTHOR_TAG , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure', '', '']","['Although there are other discussions of the paragraph as a central element of discourse (e.g.', ' #TAUTHOR_TAG , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']","['Although there are other discussions of the paragraph as a central element of discourse (e.g.', ' #TAUTHOR_TAG , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .', '', '']",1
"['All not going such theory or model, will be finitary', ', a model fewer hundred elements', '', 'The', 'This Principle of Finitism is also assumed by Johnson- #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'fin to developics that is used or has potential applications in natural sciencecf.', '']","['All notions going such theory or model, will be finitary.', 'example, a model fewer hundred elements', '', 'The', 'This Principle of Finitism is also assumed by Johnson- #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'finitary to develop mathematics that is used or has potential applications in natural science, (cf.', '']","['All logical notions such theory or model, will be finitary', ', a model fewer a hundred elements', '', 'The issues', 'This Principle of Finitism is also assumed by Johnson- #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', 'to developics that is used or has potential applications in natural science,cf.', '']","['All logical notions that we are going to consider, such as theory or model, will be finitary.', '', '', '', 'This Principle of Finitism is also assumed by Johnson- #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and implicitly or explicitly by almost all researchers in computational linguistics .', '', '']",1
"['of psych orient research in', 'These authors a paragraph a psych unit ofourse', 'to paragraph: (ounverbs);2) pronoun reference; and () paragraph length, as determined spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in #TAUTHOR_TAG and #AUTHOR_TAG .']","['of oriented research in', 'These authors a paragraph a psychologically unit of', 'to paragraph: adverbs); (2) pronoun reference; and (3) paragraph length, as determined spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in #TAUTHOR_TAG and #AUTHOR_TAG .']","['of psych orient research work in', 'These authors a paragraph a psychologically real unit ofourse', 'to a paragraph: (oun2) pronoun reference; and () paragraph length, as determined spatial and/or sentence-count information.', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in #TAUTHOR_TAG and #AUTHOR_TAG .']","['', '', '', 'Other psycholing-uistic studies that confirm the validity of paragraph units can be found in #TAUTHOR_TAG and #AUTHOR_TAG .']",0
"['We have shown elsewhere ( Jensen and Binot 1988 ; #TAUTHOR_TAG a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory.']","['We have shown elsewhere ( Jensen and Binot 1988 ; #TAUTHOR_TAG a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory.']","['We have shown elsewhere ( Jensen and Binot 1988 ; #TAUTHOR_TAG a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory.']","['We have shown elsewhere ( Jensen and Binot 1988 ; #TAUTHOR_TAG a , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .', 'This means that information contained in grammars and dictionaries can be used to constrain possible interpretations of the logical predicates of an object-level theory.']",2
"['', 'reflected in definition a', '', '', 'The partial theories pick up from the referential level the most obvious or the most important information about a formula.', 'This immediate information may be insufficient to decide the truth of certain predicates.', 'It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX #TAUTHOR_TAG b ) .', 'Zadrozny 1987b).']","['', 'reflected in definition a', '', '', 'The partial theories pick up from the referential level the most obvious or the most important information about a formula.', 'This immediate information may be insufficient to decide the truth of certain predicates.', 'It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX #TAUTHOR_TAG b ) .', 'Zadrozny 1987b).']","['', 'in the definition', '', '', 'The partial theories pick up from the referential level the most obvious or the most important information about a formula.', 'This immediate information may be insufficient to decide the truth of certain predicates.', 'It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX #TAUTHOR_TAG b ) .', 'Zadrozny 1987b).']","['', '', '', '', 'The partial theories pick up from the referential level the most obvious or the most important information about a formula.', 'This immediate information may be insufficient to decide the truth of certain predicates.', 'It would seem therefore that the iteration of the PT operation to form a closure is needed ( cfXXX #TAUTHOR_TAG b ) .', 'Zadrozny 1987b).']",1
"['Adding selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the background knowledge necessary for reference disambiguation.', ""Later , #TAUTHOR_TAG , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base .""]","['Adding selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the background knowledge necessary for reference disambiguation.', ""Later , #TAUTHOR_TAG , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base .""]","['Adding selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the background knowledge necessary for reference disambiguation.', ""Later , #TAUTHOR_TAG , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base .""]","['Adding selectional restrictions (semantic feature information, Hobbs 1977) does not solve the problem, because isolated features offer only part of the background knowledge necessary for reference disambiguation.', ""Later , #TAUTHOR_TAG , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base .""]",0
"['The necessity of this kind of merging of arguments has been recognized before : Charniak and Mc #AUTHOR_TAG call it abductive unification/matching , #TAUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .']","['The necessity of this kind of merging of arguments has been recognized before : Charniak and Mc #AUTHOR_TAG call it abductive unification/matching , #TAUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .']","['The necessity of this kind of merging of arguments has been recognized before : Charniak and Mc #AUTHOR_TAG call it abductive unification/matching , #TAUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .']","['The necessity of this kind of merging of arguments has been recognized before : Charniak and Mc #AUTHOR_TAG call it abductive unification/matching , #TAUTHOR_TAG , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .']",0
"['', '', '', '', '', '', '', '', 'we may need also a quotation operator ; #TAUTHOR_TAG describes how first order logic can be augmented with such an operator .', '', '', '', '', '']","['', '', '', '', '', '', '', '', 'we may need also a quotation operator ; #TAUTHOR_TAG describes how first order logic can be augmented with such an operator .', '', '', '', '', '']","['', '', '', '', '', '', '', '', 'we may need also a quotation operator ; #TAUTHOR_TAG describes how first order logic can be augmented with such an operator .', '', '', '', '', '']","['', '', '', '', '', '', '', '', 'Since sentences can refer to events described by other sentences , we may need also a quotation operator ; #TAUTHOR_TAG describes how first order logic can be augmented with such an operator .', '', '', '', '', '']",0
"['A paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings.', ""For instance , #TAUTHOR_TAG , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's ? ''"", 'The pairing of these two sentences may be said to create a small paragraph.', '', '', '', '']","['A paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings.', ""For instance , #TAUTHOR_TAG , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's ? ''"", 'The pairing of these two sentences may be said to create a small paragraph.', '', '', '', '']","['A paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings.', ""For instance , #TAUTHOR_TAG , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's ''"", 'The pairing of these two sentences may be said to create a small paragraph.', '', '', '', '']","['A paragraph can be thought of as a grammatical unit in the following sense: it is the discourse unit in which a functional (or a predicate-argument) structure can be definitely assigned to sentences/strings.', ""For instance , #TAUTHOR_TAG , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's favorite fruit ? ''"", 'The pairing of these two sentences may be said to create a small paragraph.', '', '', '', '']",4
"['', '', '', 'the of the DAR speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', 'the of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', 'the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', '', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG .']",0
['A formula for the test set perplexity #TAUTHOR_TAG is :13'],['A formula for the test set perplexity #TAUTHOR_TAG is :13'],['A formula for the test set perplexity #TAUTHOR_TAG is :13'],['A formula for the test set perplexity #TAUTHOR_TAG is :13'],0
"['four-specific of have implemented', '', 'in', 'The third version ( VOYAGER ) serves as an interface both with a recognizer and with a functioning database back-end #TAUTHOR_TAG .', 'TheAGER', '']","['four domain-specific of have implemented.', '', 'in', 'The third version ( VOYAGER ) serves as an interface both with a recognizer and with a functioning database back-end #TAUTHOR_TAG .', 'The', '']","['of have been implemented', '', 'in', 'The third version ( VOYAGER ) serves as an interface both with a recognizer and with a functioning database back-end #TAUTHOR_TAG .', '', '']","['', '', '', 'The third version ( VOYAGER ) serves as an interface both with a recognizer and with a functioning database back-end #TAUTHOR_TAG .', '', '']",5
"['task system', 'the', ', aner in a typed in the utter subject.', 'Subsequent processing by the natural language and response generation components was done automatically by the computer #TAUTHOR_TAG .']","['task, system', 'the', 'Instead, an experimenter in a typed in the utterances subject.', 'Subsequent processing by the natural language and response generation components was done automatically by the computer #TAUTHOR_TAG .']","['the system', '', ', an experimenter in typed in the utterances the subject.', 'Subsequent processing by the natural language and response generation components was done automatically by the computer #TAUTHOR_TAG .']","['', '', 'Instead, an experimenter in a separate room typed in the utterances as spoken by the subject.', 'Subsequent processing by the natural language and response generation components was done automatically by the computer #TAUTHOR_TAG .']",5
[' #TAUTHOR_TAG .'],[' #TAUTHOR_TAG .'],[' #TAUTHOR_TAG .'],[' #TAUTHOR_TAG .'],0
"['', '', '', '', 'This approach resembles the work by #AUTHOR_TAG and #TAUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', 'more to']","['', '', '', '', 'This approach resembles the work by #AUTHOR_TAG and #TAUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', 'more to']","['', '', '', '', 'This approach resembles the work by #AUTHOR_TAG and #TAUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', 'more work to']","['', '', '', '', 'This approach resembles the work by #AUTHOR_TAG and #TAUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']",1
"['At we have available at MIT twoER involving specific', '', '', '', '', '', 'entered', 'The search algorithm is the standard Viterbi search #TAUTHOR_TAG , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence .']","['At we have available at MIT two involving specific', '', '', '', '', '', 'entered', 'The search algorithm is the standard Viterbi search #TAUTHOR_TAG , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence .']","['At we have available at MIT two, involving', '', '', '', '', '', 'is entered', 'The search algorithm is the standard Viterbi search #TAUTHOR_TAG , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence .']","['', '', '', '', '', '', '', 'The search algorithm is the standard Viterbi search #TAUTHOR_TAG , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence .']",5
"['Semantic filters can also be used to prevent multiple versions of the same case frame #TAUTHOR_TAG showing up as complements', '', '', '', '', '']","['Semantic filters can also be used to prevent multiple versions of the same case frame #TAUTHOR_TAG showing up as complements', '', '', '', '', '']","['Semantic filters can also be used to prevent multiple versions of the same case frame #TAUTHOR_TAG showing up as complements .', '', '', '', '', '']","['Semantic filters can also be used to prevent multiple versions of the same case frame #TAUTHOR_TAG showing up as complements .', '', '', '', '', '']",5
"['', '', '', ' be in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', '2 be in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', 'in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', 'Current advances in research and development of spoken language systems 2 can be found, for example, in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']",0
"['Whereas loosely coupled system the parser acts as a filter only on completed candidate solutions (ue al. the coupled allows the parser to discard theories.', ', each partial theory is first extended by the parser to specify possible next words, which are then scored by theizer.', ""We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance #TAUTHOR_TAG ."", 'want to']","['Whereas loosely coupled system the parser acts as a filter only on completed candidate solutions (Zue al. the coupled allows the parser to discard theories continuing.', 'search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', ""We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance #TAUTHOR_TAG ."", 'want to']","['Whereas the loosely coupled system the parser acts as a filter only on completed candidate solutions (ue the coupled allows the parser to discard partial theories.', ', each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', ""We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance #TAUTHOR_TAG ."", 'we want to']","['Whereas in the loosely coupled system the parser acts as a filter only on completed candidate solutions (Zue et al. 1991), the tightly coupled system allows the parser to discard partial theories that have no way of continuing.', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', ""We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance #TAUTHOR_TAG ."", '']",5
"['To date, four distinct domain-specific versions of TINA have been implemented.', 'The first version ( TIMIT ) was developed for the 450 phonetically rich sentences of the TIMIT database #TAUTHOR_TAG .', 'task ', '', '', '']","['To date, four distinct domain-specific versions of TINA have been implemented.', 'The first version ( TIMIT ) was developed for the 450 phonetically rich sentences of the TIMIT database #TAUTHOR_TAG .', 'task', '', '', '']","['To date, four distinct domain-specific versions of TINA have been implemented.', 'The first version ( TIMIT ) was developed for the 450 phonetically rich sentences of the TIMIT database #TAUTHOR_TAG .', '', '', '', '']","['To date, four distinct domain-specific versions of TINA have been implemented.', 'The first version ( TIMIT ) was developed for the 450 phonetically rich sentences of the TIMIT database #TAUTHOR_TAG .', '', '', '', '']",5
"['Exactly how to get from the parse tree to an appropriate meaning representation is a current research topic in our group.', 'However , the method we are currently using in the ATIS domain #TAUTHOR_TAG represents our most promising approach to this problem .', 'We have decided to limit semantic frame types to set of choices such as CLAUSE (for a sentence-level concept, such as request), PREDICATE (for a functional operation), REFERENCE (essentially proper noun), and QSET (for a set of objects).', 'a frame to passing frames node node parse', '', '', '', '', '']","['Exactly how to get from the parse tree to an appropriate meaning representation is a current research topic in our group.', 'However , the method we are currently using in the ATIS domain #TAUTHOR_TAG represents our most promising approach to this problem .', 'We have decided to limit semantic frame types to set of choices such as CLAUSE (for a sentence-level concept, such as request), PREDICATE (for a functional operation), REFERENCE (essentially proper noun), and QSET (for a set of objects).', 'a frame to passing frames node node parse', '', '', '', '', '']","['Exactly how to get from the parse tree to an appropriate meaning representation is a current research topic in our group.', 'However , the method we are currently using in the ATIS domain #TAUTHOR_TAG represents our most promising approach to this problem .', 'We have decided to limit semantic frame types to of choices such as CLAUSE (for a sentence-level concept, such as request), PREDICATE (for a functional operation), REFERENCE (essentially proper noun), and QSET (for a set of objects).', 'a to passing frames node node', '', '', '', '', '']","['Exactly how to get from the parse tree to an appropriate meaning representation is a current research topic in our group.', 'However , the method we are currently using in the ATIS domain #TAUTHOR_TAG represents our most promising approach to this problem .', 'We have decided to limit semantic frame types to a small set of choices such as CLAUSE (for a sentence-level concept, such as request), PREDICATE (for a functional operation), REFERENCE (essentially proper noun), and QSET (for a set of objects).', '', '', '', '', '', '']",3
"['We currently have two application domains that can carry on a spoken dialog with a user.', 'the VOYAGER (Zue199 in an urban our case vicinity MIT and Harvard University', 'The second one, ATIS #TAUTHOR_TAG et al. 1991), is a system for accessing data in the Official 80 Stephanie Seneff TINA: A Natural Language System for Spoken Language Applications Airline Guide and booking flights.', 'continues on improving all aspects of these']","['We currently have two application domains that can carry on a spoken dialog with a user.', 'the VOYAGER (Zue 1990), in an urban our case, vicinity MIT and Harvard University.', 'The second one, ATIS #TAUTHOR_TAG et al. 1991), is a system for accessing data in the Official 80 Stephanie Seneff TINA: A Natural Language System for Spoken Language Applications Airline Guide and booking flights.', 'continues on improving all aspects of these']","['We currently have two application domains that can carry on a spoken dialog with a user.', 'the VOYAGER domain (Zue in an urban area, our case the vicinity MIT and Harvard University.', 'The second one, ATIS #TAUTHOR_TAG et al. 1991), is a system for accessing data in the Official 80 Stephanie Seneff TINA: A Natural Language System for Spoken Language Applications Airline Guide and booking flights.', 'continues on improving all aspects of these']","['We currently have two application domains that can carry on a spoken dialog with a user.', '', 'The second one, ATIS #TAUTHOR_TAG et al. 1991), is a system for accessing data in the Official 80 Stephanie Seneff TINA: A Natural Language System for Spoken Language Applications Airline Guide and booking flights.', '']",5
"['', '', '', 'decision to accept', 'This approach resembles the work by #TAUTHOR_TAG and #AUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', 'more work to']","['', '', '', 'decision to accept', 'This approach resembles the work by #TAUTHOR_TAG and #AUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', 'more work to']","['', '', '', 'to accept', 'This approach resembles the work by #TAUTHOR_TAG and #AUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', 'more work to']","['', '', '', '', 'This approach resembles the work by #TAUTHOR_TAG and #AUTHOR_TAG on selectional restrictions .', 'The semantic conditions that pass could even ultimately be associated with probabilities, obtained by frequency counts on their occurrences.', '']",1
"['', '', '', '', 'some arcs willitably be zeroed', 'is desired to intentionally as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model #TAUTHOR_TAG .']","['', '', '', '', 'some arcs will inevitably be zeroed', 'is desired to intentionally as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model #TAUTHOR_TAG .']","['', '', '', '', 'some arcs willitably be zeroed', 'it is desired to intentionally as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model #TAUTHOR_TAG .']","['', '', '', '', '', 'Unless it is desired to intentionally filter these out as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model #TAUTHOR_TAG .']",0
"['', '', '', '', '', '', '', '', '', '', '', '', 'To a first approximation , a CURRENT-FOCUS reaches only nodes that are c-commanded #TAUTHOR_TAG by its generator .', 'transferOBJECT children']","['', '', '', '', '', '', '', '', '', '', '', '', 'To a first approximation , a CURRENT-FOCUS reaches only nodes that are c-commanded #TAUTHOR_TAG by its generator .', 'transfer children.']","['', '', '', '', '', '', '', '', '', '', '', '', 'To a first approximation , a CURRENT-FOCUS reaches only nodes that are c-commanded #TAUTHOR_TAG by its generator .', 'the transfer children']","['', '', '', '', '', '', '', '', '', '', '', '', 'To a first approximation , a CURRENT-FOCUS reaches only nodes that are c-commanded #TAUTHOR_TAG by its generator .', '']",0
"['We_currently have two application domains that can carry on a spoken dialog with a user.', 'One , the VOYAGER domain #TAUTHOR_TAG , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .', 'second', '']","['We_currently have two application domains that can carry on a spoken dialog with a user.', 'One , the VOYAGER domain #TAUTHOR_TAG , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .', 'second', '']","['We_currently have two application domains that can carry on a spoken dialog with a user.', 'One , the VOYAGER domain #TAUTHOR_TAG , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .', '', '']","['We_currently have two application domains that can carry on a spoken dialog with a user.', 'One , the VOYAGER domain #TAUTHOR_TAG , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .', '', '']",5
"[""The example used to illustrate the power of ATNs #TAUTHOR_TAG , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator"", 'crossed', '', '', '', '', '', '']","[""The example used to illustrate the power of ATNs #TAUTHOR_TAG , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator"", 'crossed', '', '', '', '', '', '']","[""The example used to illustrate the power of ATNs #TAUTHOR_TAG , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator ."", 'crossed traces', '', '', '', '', '', '']","[""The example used to illustrate the power of ATNs #TAUTHOR_TAG , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator ."", '', '', '', '', '', '', '']",1
"['', '', '', 'the proceedings of the DAR speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', 'the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', 'the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']","['', '', '', 'Current advances in research and development of spoken language systems 2 can be found, for example, in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG .']",0
"[', four distinct domain-specific versions of TINA have been implemented.', 'The', 'The second version ( RM ) concerns the Resource Management task #TAUTHOR_TAG that has been popular within the DARPA community in recent years .', 'The third version ()', '', '']","['date, four distinct domain-specific versions of TINA have been implemented.', 'The', 'The second version ( RM ) concerns the Resource Management task #TAUTHOR_TAG that has been popular within the DARPA community in recent years .', 'The third version', '', '']","[', four distinct domain-specific versions of TINA have been implemented.', '', 'The second version ( RM ) concerns the Resource Management task #TAUTHOR_TAG that has been popular within the DARPA community in recent years .', 'The third version ()', '', '']","['To date, four distinct domain-specific versions of TINA have been implemented.', '', 'The second version ( RM ) concerns the Resource Management task #TAUTHOR_TAG that has been popular within the DARPA community in recent years .', '', '', '']",5
"['of scheme is necessary stream is determin', 'For the A * algorithm #TAUTHOR_TAG as applied to speech recognition , the actual path score is typically augmented with an estimated score for the unseen portion .', 'some kind of normalization is done, the short theories have an, been multi', '']","['of scheme is necessary stream is', 'For the A * algorithm #TAUTHOR_TAG as applied to speech recognition , the actual path score is typically augmented with an estimated score for the unseen portion .', 'some kind of normalization is done, the short theories have an advantage, been', '']","['of this scheme is necessary is not determin', 'For the A * algorithm #TAUTHOR_TAG as applied to speech recognition , the actual path score is typically augmented with an estimated score for the unseen portion .', 'some kind of normalization is done, the short theories have an unfair advantage, have been multi', '']","['', 'For the A * algorithm #TAUTHOR_TAG as applied to speech recognition , the actual path score is typically augmented with an estimated score for the unseen portion .', 'Unless some kind of normalization is done, the short theories have an unfair advantage, simply because fewer probability scores have been multiplied.', '']",5
"['we have available at MIT two', 'interface', '', '', 'therefore not be in', 'The recognizer for these systems is the SUMMIT system #TAUTHOR_TAG , which uses a segmental-based framework and includes an auditory model in the front-end processing .', 'The lexicon is entered as phonetic pronunciations that are then augmented to account for a number of phonological rules.', 'The search is the standard Vbi (Viterbi 196 a networknetwork alignment']","['we have available at MIT two', 'interface', '', '', 'therefore not be in', 'The recognizer for these systems is the SUMMIT system #TAUTHOR_TAG , which uses a segmental-based framework and includes an auditory model in the front-end processing .', 'The lexicon is entered as phonetic pronunciations that are then augmented to account for a number of phonological rules.', 'The search is the standard Viterbi (Viterbi 1967), a alignment']","['we have available at MIT two', 'the interface', '', '', 'therefore not be covered in', 'The recognizer for these systems is the SUMMIT system #TAUTHOR_TAG , which uses a segmental-based framework and includes an auditory model in the front-end processing .', 'The lexicon is entered as phonetic pronunciations that are then augmented to account for a number of phonological rules.', 'The search algorithm is the standard Viterbi search (Viterbi 196 a network-to-network alignment problem']","['', '', '', '', '', 'The recognizer for these systems is the SUMMIT system #TAUTHOR_TAG , which uses a segmental-based framework and includes an auditory model in the front-end processing .', 'The lexicon is entered as phonetic pronunciations that are then augmented to account for a number of phonological rules.', '']",5
"['part the a', ')', 'The gap mechanism resembles the Hold register idea of ATNs #TAUTHOR_TAG and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff these in the process of filling the Hold register equivalent involves two steps separately initiated by two independent nodes.']","['part the a', '', 'The gap mechanism resembles the Hold register idea of ATNs #TAUTHOR_TAG and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff these in the process of filling the Hold register equivalent involves two steps separately initiated by two independent nodes.']","['part the task', ')', 'The gap mechanism resembles the Hold register idea of ATNs #TAUTHOR_TAG and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff . ), these in that the process of filling the Hold register equivalent involves two steps separately initiated by two independent nodes.']","['', '', 'The gap mechanism resembles the Hold register idea of ATNs #TAUTHOR_TAG and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff . ), but it is different from these in that the process of filling the Hold register equivalent involves two steps separately initiated by two independent nodes.']",1
"['', '', '', ' be the proceedings of the DAR speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['', '', '', '2 be the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['', '', '', 'the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']","['', '', '', 'Current advances in research and development of spoken language systems 2 can be found, for example, in the proceedings of the DARPA speech and natural language workshops, as well as in publications from participants of the ESPRIT SUNDIAL project.', 'Representative systems are described in #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG .']",0
"['', 'grammar', '', ""We have since improved the interface by incorporating a capability in the recognizer to propose additional solutions in turn once the first one fails to parse #TAUTHOR_TAG To produce these `` N-best '' alternatives , we make use of a standard A * search algorithm Hart"", '', '', '']","['', 'grammar', '', ""We have since improved the interface by incorporating a capability in the recognizer to propose additional solutions in turn once the first one fails to parse #TAUTHOR_TAG To produce these `` N-best '' alternatives , we make use of a standard A * search algorithm Hart"", '', '', '']","['', '', '', ""We have since improved the interface by incorporating a capability in the recognizer to propose additional solutions in turn once the first one fails to parse #TAUTHOR_TAG To produce these `` N-best '' alternatives , we make use of a standard A * search algorithm"", '', '', '']","['', '', '', ""We have since improved the interface by incorporating a capability in the recognizer to propose additional solutions in turn once the first one fails to parse #TAUTHOR_TAG To produce these `` N-best '' alternatives , we make use of a standard A * search algorithm ( Hart 1968 , Jelinek 1976 ) ."", '', '', '']",5
"['Whereas in the loosely coupled system the parser acts as a filter only on completed candidate solutions #TAUTHOR_TAG , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', '', '']","['Whereas in the loosely coupled system the parser acts as a filter only on completed candidate solutions #TAUTHOR_TAG , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', '', '']","['Whereas in the loosely coupled system the parser acts as a filter only on completed candidate solutions #TAUTHOR_TAG , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', '', '']","['Whereas in the loosely coupled system the parser acts as a filter only on completed candidate solutions #TAUTHOR_TAG , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .', 'Following the Viterbi search, each partial theory is first extended by the parser to specify possible next words, which are then scored by the recognizer.', '', '']",5
"['One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by #TAUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps : A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1 .', 'This description can then be given the standard set-theoretical interpretation of #AUTHOR_TAG 99']","['One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by #TAUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps : A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1 .', 'This description can then be given the standard set-theoretical interpretation of #AUTHOR_TAG 1994).']","['One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by #TAUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps : A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1 .', 'This description can then be given the standard set-theoretical interpretation of #AUTHOR_TAG 99']","['One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by #TAUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps : A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1 .', 'This description can then be given the standard set-theoretical interpretation of #AUTHOR_TAG , 1994).']",0
"['most specific generalization does not additional', '', '', '', '', '', '', 'The reader is referred to #TAUTHOR_TAG for a more detailed discussion of our use of constraint propagation.']","['most specific generalization does not additional', '', '', '', '', '', '', 'The reader is referred to #TAUTHOR_TAG for a more detailed discussion of our use of constraint propagation.']","['most specific generalization does not necessarily', '', '', '', '', '', '', 'The reader is referred to #TAUTHOR_TAG for a more detailed discussion of our use of constraint propagation.']","['', '', '', '', '', '', '', 'The reader is referred to #TAUTHOR_TAG for a more detailed discussion of our use of constraint propagation.']",0
"['Another common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB ( Copestake 1992 ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules #TAUTHOR_TAG , 31 ) .', '', '']","['Another common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB ( Copestake 1992 ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules #TAUTHOR_TAG , 31 ) .', '', '']","['Another common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB ( Copestake 1992 ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules #TAUTHOR_TAG , 31 ) .', '', '']","['Another common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB ( Copestake 1992 ) where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules #TAUTHOR_TAG , 31 ) .', '', '']",1
"['The way these predicates interconnect is represented in Figure 19.', '27 #TAUTHOR_TAG argue that semi-productivity of lexical rules , which can be understood as a generalization of exceptions to lexical rules , can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry .', ' the indexes names', '']","['The way these predicates interconnect is represented in Figure 19.', '27 #TAUTHOR_TAG argue that semi-productivity of lexical rules , which can be understood as a generalization of exceptions to lexical rules , can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry .', 'the indexes names', '']","['The way these predicates interconnect is represented in Figure 19.', '27 #TAUTHOR_TAG argue that semi-productivity of lexical rules , which can be understood as a generalization of exceptions to lexical rules , can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry .', ' the compiler indexes the names', '']","['The way these predicates interconnect is represented in Figure 19.', '27 #TAUTHOR_TAG argue that semi-productivity of lexical rules , which can be understood as a generalization of exceptions to lexical rules , can be integrated with our approach by assigning probabilities to the automaton associated with a particular lexical entry .', '', '']",0
"['', '', '', '', '', 'example for all proposals with verical entries raise the arguments of a verbal complement (inrichs and Nakazawa9) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Extraction Lexical Rule #TAUTHOR_TAG to operate on those raised elements.', 'an analysis treating adjunct extractionxical) results in an infinitex']","['', '', '', '', '', 'example, for all proposals with verbal entries raise the arguments of a verbal complement (Hinrichs and Nakazawa that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Extraction Lexical Rule #TAUTHOR_TAG to operate on those raised elements.', 'an analysis treating adjunct extraction lexical results in an infinite']","['', '', '', '', '', 'example for all proposals working with ver raise the arguments of a verbal complement (inrichs and Nakaz that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Extraction Lexical Rule #TAUTHOR_TAG to operate on those raised elements.', 'Also an analysis treating adjunct extractionxical rules results in an infinite lexicon.']","['', '', '', '', '', '/b4home.html 1 This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Extraction Lexical Rule #TAUTHOR_TAG to operate on those raised elements.', '']",0
"['', '', '', '', 'recurs', 'setup the DLR formalization therefore requires all words feedingxical rules to be grammatical with respect to the theory.', 'Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata.', 'This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as , for example , adopted in the LKB system #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', 'recursion', 'setup, the DLR formalization therefore requires all words feeding lexical rules to be grammatical with respect to the theory.', 'Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata.', 'This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as , for example , adopted in the LKB system #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', 'setup the DLR formalization therefore requires all words feedingxical rules to be grammatical with respect to the theory.', 'Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata.', 'This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as , for example , adopted in the LKB system #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', 'Contrary to the MLR setup, the DLR formalization therefore requires all words feeding lexical rules to be grammatical with respect to the theory.', 'Since lexical rules are expressed in the theory just like any other part of the theory, they are represented in the same way, as unary immediate dominance schemata.', 'This conception of lexical rules thus can be understood as underlying the computational approach that treats lexical rules as unary phrase structure rules as , for example , adopted in the LKB system #TAUTHOR_TAG .', '', '', '', '']",0
"['', '', '', '', '', '', 'resulting', '', '', 'evaluation', 'literal can be removed from the body This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body #TAUTHOR_TAG .', 'x frame', '', '']","['', '', '', '', '', '', 'resulting', '', '', 'evaluation', 'literal can be removed from the body This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body #TAUTHOR_TAG .', 'frame', '', '']","['', '', '', '', '', '', '', '', '', 'the evaluation', 'literal can be removed from the body9 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body #TAUTHOR_TAG .', 'all frame', '', '']","['', '', '', '', '', '', '', '', '', '', 'As a result, the literal can be removed from the body of 29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body #TAUTHOR_TAG .', '', '', '']",1
"['3 In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ; #TAUTHOR_TAG can be used to circumvent constraint propagation .', 'lex in, instead of with defin attach, all relevant', '']","['In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ; #TAUTHOR_TAG can be used to circumvent constraint propagation .', 'lexical in way, instead of with definite attachments, all relevant', '']","['3 In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ; #TAUTHOR_TAG can be used to circumvent constraint propagation .', 'lex in, instead of with defin', '']","['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ; #TAUTHOR_TAG can be used to circumvent constraint propagation .', '', '']",0
"['', '', '2 In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in #TAUTHOR_TAG .', 'The reader interested in that language and its precise interpretation can find the relevant details in that paper.', '13 A can be in Minnen (in preparation).', '', '', '', '']","['', '', 'In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in #TAUTHOR_TAG .', 'The reader interested in that language and its precise interpretation can find the relevant details in that paper.', '13 A can be in Minnen (in preparation).', '', '', '', '']","['', '', '2 In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in #TAUTHOR_TAG .', 'The reader interested in that language and its precise interpretation can find the relevant details in that paper.', '13 A can be found in Minnen (in preparation).', '', '', '', '']","['', '', '12 In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in #TAUTHOR_TAG .', 'The reader interested in that language and its precise interpretation can find the relevant details in that paper.', '13 A more detailed presentation can be found in Minnen (in preparation).', '', '', '', '']",0
"['', '', '', '', '5-depth including a comparison of both approaches is provided in Calcagno, Meurers, andard (in preparation).', '6 The Partial-VP Topicalization Lexical Rule proposed by #TAUTHOR_TAG , 10 ) is a linguistic example .', 'The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries serving as its input.', 'In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement.']","['', '', '', '', '5 in-depth including a comparison of both approaches is provided in Calcagno, Meurers, and Pollard (in preparation).', '6 The Partial-VP Topicalization Lexical Rule proposed by #TAUTHOR_TAG , 10 ) is a linguistic example .', 'The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries serving as its input.', 'In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement.']","['', '', '', '', '5 An in-depth discussion including a comparison of both approaches is provided in Calcagno, Meurers, andard (in preparation).', '6 The Partial-VP Topicalization Lexical Rule proposed by #TAUTHOR_TAG , 10 ) is a linguistic example .', 'The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries serving as its input.', 'In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement.']","['', '', '', '', '5 An in-depth discussion including a comparison of both approaches is provided in Calcagno, Meurers, and Pollard (in preparation).', '6 The Partial-VP Topicalization Lexical Rule proposed by #TAUTHOR_TAG , 10 ) is a linguistic example .', 'The in-specification of this lexical rule makes use of an append relation to constrain the valence attribute of the auxiliaries serving as its input.', 'In the lexicon, however, the complements of an auxiliary are uninstantiated because it raises the arguments of its verbal complement.']",0
"['', '', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ; #TAUTHOR_TAG .', '5 An-depth discussion including a comparison both approaches is provided in Calcagno, Meurers, andard (in preparation).', '6', '', '']","['', '', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ; #TAUTHOR_TAG .', '5 An in-depth discussion including a comparison both approaches is provided in Calcagno, Meurers, and Pollard (in preparation).', '6', '', '']","['', '', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ; #TAUTHOR_TAG .', '5 An in-depth discussion including a comparison both approaches is provided in Calcagno, Meurers, andard (in preparation).', '', '', '']","['', '', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ; #TAUTHOR_TAG .', '5 An in-depth discussion including a comparison of both approaches is provided in Calcagno, Meurers, and Pollard (in preparation).', '', '', '']",0
"['', '', '', 'frame we therefore refer to the specifications theist as the frame specification or simply frame a leical rule.', 'Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up #TAUTHOR_TAG .']","['', '', '', 'frame we therefore refer to the specifications the linguist as the frame specification, or simply frame, a lexical rule.', 'Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up #TAUTHOR_TAG .']","['', '', '', 'we will therefore refer to the specifications the linguist as the frame specification, or simply frame, a lexical rule.', 'Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up #TAUTHOR_TAG .']","['', '', '', '', 'Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up #TAUTHOR_TAG .']",0
"['', '', '', '', '', 'As shown in #TAUTHOR_TAG this is a well-motivated convention since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries .']","['', '', '', '', '', 'As shown in #TAUTHOR_TAG this is a well-motivated convention since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries .']","['', '', '', '', '', 'As shown in #TAUTHOR_TAG this is a well-motivated convention since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries .']","['', '', '', '', '', 'As shown in #TAUTHOR_TAG this is a well-motivated convention since it avoids splitting up lexical rules to transfer the specifications that must be preserved for different lexical entries .']",4
"['The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques #TAUTHOR_TAG .', 'unf referred to as partial by #AUTHOR_TAG', 'es the evaluation of a literal the', '', '']","['The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques #TAUTHOR_TAG .', 'unfolding referred to as partial by #AUTHOR_TAG', 'comprises the evaluation of a literal the', '', '']","['The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques #TAUTHOR_TAG .', 'referred to as by #AUTHOR_TAG .', 'es the evaluation of a particular literal the body', '', '']","['The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques #TAUTHOR_TAG .', '', '', '', '']",5
"['Lex rules have not gone uned as a mechanism for expressing generaliza- tions over le information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993; Oliva 1994; Frank 1994; #TAUTHOR_TAG ; Sanfilippo 1995).', 'The lex are only and']","['Lexical rules have not gone as a mechanism for expressing generaliza- tions over information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993; Oliva 1994; Frank 1994; #TAUTHOR_TAG ; Sanfilippo 1995).', 'The lexical are only and']","['Lexical rules have not gone uned as a mechanism for expressing generaliza- tions over leical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993; Oliva 1994; Frank 1994; #TAUTHOR_TAG ; Sanfilippo 1995).', 'The lexical entries are only partially and']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993; Oliva 1994; Frank 1994; #TAUTHOR_TAG ; Sanfilippo 1995).', '']",1
"['ical to phrase structure', 'x introducedx', 'A similar method is included in PATR-II #TAUTHOR_TAG and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .', '']","['to phrase structure', 'introduced', 'A similar method is included in PATR-II #TAUTHOR_TAG and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .', '']","['ical rules to', 'x are introducedx', 'A similar method is included in PATR-II #TAUTHOR_TAG and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .', '']","['', '', 'A similar method is included in PATR-II #TAUTHOR_TAG and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .', '']",1
"['', '', 'be used to encodexical rules as binary relations in the CUF system ( Dorre and Eisele 991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; #TAUTHOR_TAG .', 'xical']","['', '', 'be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; #TAUTHOR_TAG .', 'lexical']","['', '', 'can be used to encodexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; #TAUTHOR_TAG .', 'x']","['', '', 'A similar method is included in PATR-II ( Shieber et al. 1983 ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; #TAUTHOR_TAG .', '']",1
"['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ; #TAUTHOR_TAG and the .', 'lexical rules (DLRs; Meurers 1995).', '5']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ; #TAUTHOR_TAG and the .', 'lexical rules (DLRs; Meurers 1995).', '5']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ; #TAUTHOR_TAG and the .', 'lexical rules (DLRs; Meurers 1995).', '5']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ; #TAUTHOR_TAG and the .', 'lexical rules (DLRs; Meurers 1995).', '5']",0
"['The computational treatment ofxical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and #TAUTHOR_TAG ; Gotz and Meurers 1997a ) .', 'ari complex an aux three', '', '', '']","['The computational treatment of lexical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and #TAUTHOR_TAG ; Gotz and Meurers 1997a ) .', 'complex an three', '', '', '']","['The computational treatment ofxical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and #TAUTHOR_TAG ; Gotz and Meurers 1997a ) .', '', '', '', '']","['The computational treatment of lexical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and #TAUTHOR_TAG ; Gotz and Meurers 1997a ) .', '', '', '', '']",5
"['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; #TAUTHOR_TAG ; Calcagno and Pollard 1995 ) and the .', 'lexical rules (DLRs; Meurers 1995).', '5']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; #TAUTHOR_TAG ; Calcagno and Pollard 1995 ) and the .', 'lexical rules (DLRs; Meurers 1995).', '5']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; #TAUTHOR_TAG ; Calcagno and Pollard 1995 ) and the .', 'lexical rules (DLRs; Meurers 1995).', '5']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; #TAUTHOR_TAG ; Calcagno and Pollard 1995 ) and the .', 'lexical rules (DLRs; Meurers 1995).', '5']",0
"['', '', '', '', '', '1 This is, for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement #TAUTHOR_TAG that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction viaxical rulesvan No and94) results in an infinite lexicon']","['', '', '', '', '', '1 This is, for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement #TAUTHOR_TAG that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via lexical rules (van Noord and 1994) results in an infinite lexicon.']","['', '', '', '', '', 'html 1 This is, for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement #TAUTHOR_TAG that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction viaxical rulesvan No and results in an infinite lexicon.']","['', '', '', '', '', '/b4home.html 1 This is, for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement #TAUTHOR_TAG that also use lexical rules such as the Complement Extraction Lexical Rule (Pollard and Sag 1994) or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon.']",0
"['A common computational treatment of lexical rules adopted , for example , in the ALE system #TAUTHOR_TAG consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time .', 'While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation.', '', '', '', '']","['A common computational treatment of lexical rules adopted , for example , in the ALE system #TAUTHOR_TAG consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time .', 'While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation.', '', '', '', '']","['A common computational treatment of lexical rules adopted , for example , in the ALE system #TAUTHOR_TAG consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time .', 'While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation.', '', '', '', '']","['A common computational treatment of lexical rules adopted , for example , in the ALE system #TAUTHOR_TAG consists of computing the transitive closure of the base lexical entries under lexical rule application at compile-time .', 'While this provides a front-end to include lexical rules in the grammars, it has the disadvantage that the generalizations captured by lexical rules are not used for computation.', '', '', '', '']",1
"['A logic that provides the formal architecture required by #AUTHOR_TAG was defined by #TAUTHOR_TAG , 1994 ) .', 'The formal language of allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects', 'conj', '']","['A logic that provides the formal architecture required by #AUTHOR_TAG was defined by #TAUTHOR_TAG , 1994 ) .', 'The formal language of allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects.', '', '']","['A logic that provides the formal architecture required by #AUTHOR_TAG was defined by #TAUTHOR_TAG , 1994 ) .', 'The formal language of allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects', 'conj', '']","['A logic that provides the formal architecture required by #AUTHOR_TAG was defined by #TAUTHOR_TAG , 1994 ) .', 'The formal language of King allows the expression of grammatical principles using type assignments to refer to the type of an object and path equalities to require the (token) identity of objects.', '', '']",0
"['The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques ( Tamaki and Sato 1984 )', 'The unfolding transformation is also referred to as partial execution , for example , by #TAUTHOR_TAG .', ', unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time', '', 'going']","['The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques ( Tamaki and Sato 1984 )', 'The unfolding transformation is also referred to as partial execution , for example , by #TAUTHOR_TAG .', 'understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time.', '', 'going']","['The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques ( Tamaki and Sato 1984 )', 'The unfolding transformation is also referred to as partial execution , for example , by #TAUTHOR_TAG .', ', unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time', '', 'going forward']","['The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques ( Tamaki and Sato 1984 ) .29', 'The unfolding transformation is also referred to as partial execution , for example , by #TAUTHOR_TAG .', 'Intuitively understood, unfolding comprises the evaluation of a particular literal in the body of a clause at compile-time.', '', '']",0
"['', '', 'included be used to encodexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system #TAUTHOR_TAG ; Emele 1994 ) .', '']","['', '', 'included be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system #TAUTHOR_TAG ; Emele 1994 ) .', '']","['', '', 'is included can be used to encodexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system #TAUTHOR_TAG ; Emele 1994 ) .', '']","['', '', 'A similar method is included in PATR-II ( Shieber et al. 1983 ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system #TAUTHOR_TAG ; Emele 1994 ) .', '']",1
"['One thus needs to distinguish thexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by #AUTHOR_TAG a formalxical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1.', ""This description can then be given the standard set-theoretical interpretation of #TAUTHOR_TAG , 1994 ) . '"", '11 10 Note le', '', '', '', '', '']","['One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by #AUTHOR_TAG a formal lexical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1.', ""This description can then be given the standard set-theoretical interpretation of #TAUTHOR_TAG , 1994 ) . '"", '11 10 Note', '', '', '', '', '']","['One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by #AUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1.', ""This description can then be given the standard set-theoretical interpretation of #TAUTHOR_TAG , 1994 ) . '"", '11 10 Note le', '', '', '', '', '']","['One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory.', 'The formalization of DLRs provided by #AUTHOR_TAG defines a formal lexical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1.', ""This description can then be given the standard set-theoretical interpretation of #TAUTHOR_TAG , 1994 ) . '"", '', '', '', '', '', '']",0
"['Lexical rules have not gone uned as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; #TAUTHOR_TAG ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical are']","['Lexical rules have not gone as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; #TAUTHOR_TAG ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical are']","['Lexical rules have not gone uned as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; #TAUTHOR_TAG ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; #TAUTHOR_TAG ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', '']",1
['11 #TAUTHOR_TAG proposes to unify these two steps by including an update operator in the description language.'],['11 #TAUTHOR_TAG proposes to unify these two steps by including an update operator in the description language.'],['11 #TAUTHOR_TAG proposes to unify these two steps by including an update operator in the description language.'],['11 #TAUTHOR_TAG proposes to unify these two steps by including an update operator in the description language.'],0
"['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints #TAUTHOR_TAG ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .', 'Encoding disjxical rule way, instead of with defin attach, all', '']","['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints #TAUTHOR_TAG ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .', 'Encoding disjunctive lexical rule way, instead of with definite attachments, all', '']","['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints #TAUTHOR_TAG ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .', 'Encxical rule application way, instead of with defin', '']","['32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints #TAUTHOR_TAG ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .', '', '']",0
"['The powerful mechanism of lexical rules #TAUTHOR_TAG has been used in many natural language processing systems .', 'In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper.']","['The powerful mechanism of lexical rules #TAUTHOR_TAG has been used in many natural language processing systems .', 'In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper.']","['The powerful mechanism of lexical rules #TAUTHOR_TAG has been used in many natural language processing systems .', 'In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper.']","['The powerful mechanism of lexical rules #TAUTHOR_TAG has been used in many natural language processing systems .', 'In this section we briefly discuss some of the more prominent approaches and compare them with the treatment proposed in this paper.']",0
"['are the', '', '', 'This idea of preserving properties can be considered an instance of the well-known frame problem in AT #TAUTHOR_TAG , and we will therefore refer to the specifications left implicit by the linguist as the frame specification , or simply frame , of a lexical rule .', 'Not to frame explicitly enables things compact']","['are the', '', '', 'This idea of preserving properties can be considered an instance of the well-known frame problem in AT #TAUTHOR_TAG , and we will therefore refer to the specifications left implicit by the linguist as the frame specification , or simply frame , of a lexical rule .', 'Not to frame explicitly enables things, compact']","['are preserved', '', '', 'This idea of preserving properties can be considered an instance of the well-known frame problem in AT #TAUTHOR_TAG , and we will therefore refer to the specifications left implicit by the linguist as the frame specification , or simply frame , of a lexical rule .', 'Not to the frame explicitly enables compact representation']","['', '', '', 'This idea of preserving properties can be considered an instance of the well-known frame problem in AT #TAUTHOR_TAG , and we will therefore refer to the specifications left implicit by the linguist as the frame specification , or simply frame , of a lexical rule .', '']",1
"['Encstate straightforward', '', 'in the automaton is translated into aite relation in which thexical rule pred, and state', 'Using an accumulator passing technique #TAUTHOR_TAG , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .', ' le']","['Encoding straightforward.', '', 'in the automaton is translated into a definite relation in which the lexical rule predicate called, and state', 'Using an accumulator passing technique #TAUTHOR_TAG , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .', '']","['Enc straightforward', '', 'in the automaton is translated into a definite relation in which the corresponding lexical rule predicate, and', 'Using an accumulator passing technique #TAUTHOR_TAG , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .', '']","['', '', 'Each transition in the automaton is translated into a definite relation in which the corresponding lexical rule predicate is called, and each final state is encoded by a unit clause.', 'Using an accumulator passing technique #TAUTHOR_TAG , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .', '']",5
"['', '', '', '', '', 'We use rather abstractxical rules in the examples to be able to focus on the relevant aspects', '15 #TAUTHOR_TAG show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .', 'We here assume unification as the application criterion, which formally corresponds to the conjunction of descriptions and their conversion to normal form (G6tz 1994).', 'Computationally, a subsumption test could equally well be used in our compiler.']","['', '', '', '', '', 'We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects.', '15 #TAUTHOR_TAG show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .', 'We here assume unification as the application criterion, which formally corresponds to the conjunction of descriptions and their conversion to normal form (G6tz 1994).', 'Computationally, a subsumption test could equally well be used in our compiler.']","['', '', '', '', '', 'We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects.', '15 #TAUTHOR_TAG show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .', 'We here assume unification as the application criterion, which formally corresponds to the conjunction of descriptions and their conversion to normal form (G6tz 1994).', 'Computationally, a subsumption test could equally well be used in our compiler.']","['', '', '', '', '', '14 We use rather abstract lexical rules in the examples to be able to focus on the relevant aspects.', '15 #TAUTHOR_TAG show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .', 'We here assume unification as the application criterion, which formally corresponds to the conjunction of descriptions and their conversion to normal form (G6tz 1994).', 'Computationally, a subsumption test could equally well be used in our compiler.']",0
"['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; #TAUTHOR_TAG ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; #TAUTHOR_TAG ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; #TAUTHOR_TAG ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; #TAUTHOR_TAG ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .', '']",1
"['rules have not gone un as a mechanism for expressing generaliza- tions over le information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; Oliva 1994 ; #TAUTHOR_TAG ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially and special']","['rules have not gone as a mechanism for expressing generaliza- tions over information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; Oliva 1994 ; #TAUTHOR_TAG ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially and specializations']","['ical rules have not gone un as a mechanism for expressing generaliza- tions over leical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; Oliva 1994 ; #TAUTHOR_TAG ; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially and']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992; Riehemann 1993 ; Oliva 1994 ; #TAUTHOR_TAG ; Opalka 1995 ; Sanfilippo 1995 ) .', '']",1
"['', '', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and #TAUTHOR_TAG ; Gerdemann 1995 ) .', '5depth provided Mein preparation', '', '', '']","['', '', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and #TAUTHOR_TAG ; Gerdemann 1995 ) .', '5 provided (in preparation).', '', '', '']","['', '', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and #TAUTHOR_TAG ; Gerdemann 1995 ) .', ' is providedin preparation).', '', '', '']","['', '', 'To avoid confusion, we will only use the terminology introduced in the text.', '4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and #TAUTHOR_TAG ; Gerdemann 1995 ) .', '', '', '', '']",0
"['', '', '', '', '', 'for all proposals with verical entries raise the arguments of a verbal complement ( Hinrichs and Nakazawa9 that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule #TAUTHOR_TAG to operate on those raised elements .', 'an analysis treating adjunct extraction viaxical) results in an infinitex']","['', '', '', '', '', 'for all proposals with verbal entries raise the arguments of a verbal complement ( Hinrichs and Nakazawa that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule #TAUTHOR_TAG to operate on those raised elements .', 'an analysis treating adjunct extraction via lexical results in an infinite']","['', '', '', '', '', 'for all proposals working with ver raise the arguments of a verbal complement ( Hinrichs and Nakaz that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule #TAUTHOR_TAG to operate on those raised elements .', 'Also an analysis treating adjunct extraction viaxical rules results in an infinite lexicon.']","['', '', '', '', '', '', '']",0
"['1 A linguistic example based on the signature given by #TAUTHOR_TAG would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given by #AUTHOR_TAG , fn. 20).', '']","['16 A linguistic example based on the signature given by #TAUTHOR_TAG would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given by #AUTHOR_TAG , fn. 20).', '']","['16 A linguistic example based on the signature given by #TAUTHOR_TAG would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given by #AUTHOR_TAG , fn. 20).', '']","['16 A linguistic example based on the signature given by #TAUTHOR_TAG would be a lexical rule deriving predicative signs from nonpredicative ones, i.e., changing the PRD value of substantive signs from - to +, much like the lexical rule for NPs given by #AUTHOR_TAG , fn. 20).', '']",0
"['interaction transform', '', 'The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and #TAUTHOR_TAG , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program .']","['interaction transformations', '', 'The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and #TAUTHOR_TAG , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program .']","['', '', 'The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and #TAUTHOR_TAG , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program .']","['', '', 'The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and #TAUTHOR_TAG , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program .']",2
"['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification #TAUTHOR_TAG ; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; Sanfilippo 1995 )', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy,ite clause attachments, or a macro hierarchy.']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification #TAUTHOR_TAG ; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; Sanfilippo 1995 )', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy.']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification #TAUTHOR_TAG ; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; Sanfilippo 1995 )', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy.']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification #TAUTHOR_TAG ; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; Sanfilippo 1995 ) .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy.']",1
"['Lex rules have not gone uned as a mechanism for expressing generaliza- tions over le information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; #TAUTHOR_TAG .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attach, or a macro hierarchy.']","['Lexical rules have not gone as a mechanism for expressing generaliza- tions over information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; #TAUTHOR_TAG .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy.']","['Lexical rules have not gone uned as a mechanism for expressing generaliza- tions over leical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; #TAUTHOR_TAG .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy.']","['Lexical rules have not gone unchallenged as a mechanism for expressing generaliza- tions over lexical information.', 'In a number of proposals, lexical generalizations are captured using lexical underspecification (Kathol 1994; Krieger and Nerbonne 1992 ; Riehemann 1993 ; Oliva 1994 ; Frank 1994; Opalka 1995 ; #TAUTHOR_TAG .', 'The lexical entries are only partially specified, and various specializations are encoded via the type hierarchy, definite clause attachments, or a macro hierarchy.']",1
"['', '', '', '', '', 'This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule #TAUTHOR_TAG or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction viaxical rules results in an infinite lex']","['', '', '', '', '', 'This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule #TAUTHOR_TAG or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via lexical rules results in an infinite lexicon.']","['', '', '', '', '', 'html 1 This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule #TAUTHOR_TAG or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction viaxical rules results in an infinite lexicon.']","['', '', '', '', '', '/b4home.html 1 This is, for example, the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement (Hinrichs and Nakazawa 1989) that also use lexical rules such as the Complement Extraction Lexical Rule #TAUTHOR_TAG or the Complement Cliticization Lexical Rule (Miller and Sag 1993) to operate on those raised elements.', 'Also an analysis treating adjunct extraction via lexical rules (van Noord and Bouma 1994) results in an infinite lexicon.']",0
"['Based on the research results reported in #TAUTHOR_TAG , 1996 ) , we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG .', 'a that le ded ne- ess not', '', '']","['Based on the research results reported in #TAUTHOR_TAG , 1996 ) , we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG .', 'a that nec- essary not', '', '']","['Based on the research results reported in #TAUTHOR_TAG , 1996 ) , we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG .', 'a compiler that le ded not', '', '']","['Based on the research results reported in #TAUTHOR_TAG , 1996 ) , we propose a new computational treatment of lexical rules that overcomes these short- comings and results in a more efficient processing of lexical rules as used in HPSG .', '', '', '']",4
"['Another common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB #TAUTHOR_TAG where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules ( Copestake 1993 , 31 ) .', '', '']","['Another common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB #TAUTHOR_TAG where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules ( Copestake 1993 , 31 ) .', '', '']","['Another common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB #TAUTHOR_TAG where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules ( Copestake 1993 , 31 ) .', '', '']","['Another common approach to lexical rules is to encode them as unary phrase structure rules.', 'This approach is taken , for example , in LKB #TAUTHOR_TAG where lexical rules are introduced on a par with phrase structure rules and the parser makes no distinction between lexical and nonlexical rules ( Copestake 1993 , 31 ) .', '', '']",1
"['To that no information is lost as a axical, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case.', 'In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value.', 'In the latter case, we can also take care of transferring the value of z.', 'However , as discussed by #TAUTHOR_TAG , creating several instances of lexical rules can be avoided .', 'introduced frame spec attached le rule', '', '']","['To that no information is lost as a a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case.', 'In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value.', 'In the latter case, we can also take care of transferring the value of z.', 'However , as discussed by #TAUTHOR_TAG , creating several instances of lexical rules can be avoided .', 'introduced frame specification attached rule.', '', '']","['To that no information is lost as a result applying a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case.', 'In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value.', 'In the latter case, we can also take care of transferring the value of z.', 'However , as discussed by #TAUTHOR_TAG , creating several instances of lexical rules can be avoided .', 'introduced are attached', '', '']","['To ensure that no information is lost as a result of applying a lexical rule, it seems to be necessary to split up the lexical rule to make each instance deal with a specific case.', 'In the above example, this would result in two lexical rules: one for words with tl as their c value and one for those with t2 as their c value.', 'In the latter case, we can also take care of transferring the value of z.', 'However , as discussed by #TAUTHOR_TAG , creating several instances of lexical rules can be avoided .', '', '', '']",4
"['written as', 'example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by #AUTHOR_TAG , 215 ) in terms of the setup of #TAUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ', '']","['written as', 'example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by #AUTHOR_TAG , 215 ) in terms of the setup of #TAUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ', '']","['written as', 'example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by #AUTHOR_TAG , 215 ) in terms of the setup of #TAUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2 ', '']","['', 'Consider , for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by #AUTHOR_TAG , 215 ) in terms of the setup of #TAUTHOR_TAG , ch .', '', '']",0
"['Lexical rules have not gone unchallenged as a mechanism for expressing generalizations over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ; #TAUTHOR_TAG ; Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).', 'The lexical entries are and special']","['Lexical rules have not gone unchallenged as a mechanism for expressing generalizations over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ; #TAUTHOR_TAG ; Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).', 'The lexical entries are and specializations']","['Lexical rules have not gone unchallenged as a mechanism for expressing generalizations over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ; #TAUTHOR_TAG ; Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).', 'The lexical entries and']","['Lexical rules have not gone unchallenged as a mechanism for expressing generalizations over lexical information.', 'In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ; #TAUTHOR_TAG ; Riehemann 1993; Oliva 1994; Frank 1994; Opalka 1995; Sanfilippo 1995).', '']",1
"['written as relations between supposed is specified', ', for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by #TAUTHOR_TAG , 215 ) in terms of the setup of #AUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form', '']","['written as relations between supposed is specified.', ', for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by #TAUTHOR_TAG , 215 ) in terms of the setup of #AUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2', '']","['written as relations between is supposed specified', ', for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by #TAUTHOR_TAG , 215 ) in terms of the setup of #AUTHOR_TAG , ch .', 'This lexical rule could be used in a grammar of English to relate past participle forms of verbs to their passive form2', '']","['', 'Consider , for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by #TAUTHOR_TAG , 215 ) in terms of the setup of #AUTHOR_TAG , ch .', '', '']",1
"['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the description-level lexical rules ( DLRs ; #TAUTHOR_TAG']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the description-level lexical rules ( DLRs ; #TAUTHOR_TAG']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the description-level lexical rules ( DLRs ; #TAUTHOR_TAG']","['While the setup of King provides a clear formal basis for basic HPSG grammars, nothing is said about how special linguistic mechanisms like lexical rules fit into this formal setup.', 'Two formalizations of lexical rules as used by HPSG linguists have been proposed, the meta-level lexical rules (MLRs; Calcagno 1995; Calcagno and Pollard 1995) and the description-level lexical rules ( DLRs ; #TAUTHOR_TAG']",0
"['', '', '', '', 'the detected are not necessarily ment to', ' #TAUTHOR_TAG present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .', 'N be regarded as aential labeling', '.', 'B was ; O']","['', '', '', '', 'the detected are not necessarily mentions to', ' #TAUTHOR_TAG present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .', 'NER be regarded as a sequential labeling', '.', 'BIO was ; OC']","['', '', '', '', 'the phrases detected are not necessarily ment to', ' #TAUTHOR_TAG present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .', 'N can be regarded as a sequential labeling problem,', ' #AUTHOR_TAG .', 'was introduced ; O']","['', '', '', '', '', ' #TAUTHOR_TAG present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .', '', '', '']",0
"['linked', 'weions core', 'For this mention-pair coreference model \x86 ( u , v ) , we use the same set of features used in #TAUTHOR_TAG .']","['linked.', 'we mentions', 'For this mention-pair coreference model \x86 ( u , v ) , we use the same set of features used in #TAUTHOR_TAG .']","['linked', 'core', 'For this mention-pair coreference model \x86 ( u , v ) , we use the same set of features used in #TAUTHOR_TAG .']","['', '', 'For this mention-pair coreference model \x86 ( u , v ) , we use the same set of features used in #TAUTHOR_TAG .']",5
"['theions and the are mention', '', '', '', 'the mention heads are sufficient to support the decisions: ""they"" refers to ""companies"", and ""They"" refers to ""ufacturers"".', 'In fact , most of the features3 implemented in existing coreference resolution systems rely solely on mention heads #TAUTHOR_TAG .']","['the mentions and the are mention', '', '', '', 'the mention heads are sufficient to support the decisions: ""they"" refers to ""companies"", and ""They"" refers to ""manufacturers"".', 'In fact , most of the features3 implemented in existing coreference resolution systems rely solely on mention heads #TAUTHOR_TAG .']","['ions and are', '', '', '', 'the mention heads are sufficient to support the decisions: ""they"" refers to ""companies"", and ""They"" refers to ""ufacturers"".', 'In fact , most of the features3 implemented in existing coreference resolution systems rely solely on mention heads #TAUTHOR_TAG .']","['', '', '', '', 'In both cases, the mention heads are sufficient to support the decisions: ""they"" refers to ""companies"", and ""They"" refers to ""manufacturers"".', 'In fact , most of the features3 implemented in existing coreference resolution systems rely solely on mention heads #TAUTHOR_TAG .']",0
"['', '', 'results Berkeley and H on A-200 dataset as they', '', 'For Berkeley system , we use the reported results from #TAUTHOR_TAG .']","['', '', 'results Berkeley and on ACE-2004 dataset as they', '', 'For Berkeley system , we use the reported results from #TAUTHOR_TAG .']","['', '', 'results Berkeley and H on A-2004 dataset as', '', 'For Berkeley system , we use the reported results from #TAUTHOR_TAG .']","['', '', '', '', 'For Berkeley system , we use the reported results from #TAUTHOR_TAG .']",1
"['', '', '', '', '', '', '', '', '', '', 'We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system #AUTHOR_TAG , Berkeley system #TAUTHOR_TAG and HOTCoref system ( Bj  orkelund and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', 'We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system #AUTHOR_TAG , Berkeley system #TAUTHOR_TAG and HOTCoref system ( Bj  orkelund and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', 'We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system #AUTHOR_TAG , Berkeley system #TAUTHOR_TAG and HOTCoref system ( Bj  orkelund and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', 'Baseline Systems We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system #AUTHOR_TAG , Berkeley system #TAUTHOR_TAG and HOTCoref system ( Bj  orkelund and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '']",1
"['ACE2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents #TAUTHOR_TAG .', 'Notes-5. dataset is Task', '', '', '', '', '', '']","['ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents #TAUTHOR_TAG .', 'OntoNotes-5.0 dataset, is Task', '', '', '', '', '', '']","['The ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents #TAUTHOR_TAG .', 'The OntoNotes-5.0 dataset, is released', '', '', '', '', '', '']","['The ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents #TAUTHOR_TAG .', '', '', '', '', '', '', '']",5
"['', '', '', 'we train on a set candidates with%.', 'We then use Illinois Chunker #AUTHOR_TAG 6 to extract more noun phrases from the text and employ Collins head rules #TAUTHOR_TAG to identify their heads .', 'When these extracted heads do not overlap with gold mention heads, we treat them as negative examples.']","['', '', '', 'we train on a set candidates with', 'We then use Illinois Chunker #AUTHOR_TAG 6 to extract more noun phrases from the text and employ Collins head rules #TAUTHOR_TAG to identify their heads .', 'When these extracted heads do not overlap with gold mention heads, we treat them as negative examples.']","['', '', '', 'we train on a set candidates with%.', 'We then use Illinois Chunker #AUTHOR_TAG 6 to extract more noun phrases from the text and employ Collins head rules #TAUTHOR_TAG to identify their heads .', 'When these extracted heads do not overlap with gold mention heads, we treat them as negative examples.']","['', '', '', '', 'We then use Illinois Chunker #AUTHOR_TAG 6 to extract more noun phrases from the text and employ Collins head rules #TAUTHOR_TAG to identify their heads .', 'When these extracted heads do not overlap with gold mention heads, we treat them as negative examples.']",5
"['Mention detection is rarely studied as a stand-alone research problem ( #AUTHOR_TAG is one key exception).', 'Most coreference resolution work simply mentions it in passing as a module in the pipelined system #TAUTHOR_TAG Bj  orkelund and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['Mention detection is rarely studied as a stand-alone research problem ( #AUTHOR_TAG is one key exception).', 'Most coreference resolution work simply mentions it in passing as a module in the pipelined system #TAUTHOR_TAG Bj  orkelund and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['Mention detection is rarely studied as a stand-alone research problem ( #AUTHOR_TAG is one key exception).', 'Most coreference resolution work simply mentions it in passing as a module in the pipelined system #TAUTHOR_TAG Bj  orkelund and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['Mention detection is rarely studied as a stand-alone research problem ( #AUTHOR_TAG is one key exception).', 'Most coreference resolution work simply mentions it in passing as a module in the pipelined system #TAUTHOR_TAG Bj  orkelund and #AUTHOR_TAG .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",0
"['Based on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in #TAUTHOR_TAG .', 'The BILOUrepresentation suggests learning classifiers that identify the Beginning Inside and Last tokens of multi-token chunks as as Unit-length', '']","['Based on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in #TAUTHOR_TAG .', 'The BILOUrepresentation suggests learning classifiers that identify the Beginning, Inside and Last tokens of multi-token chunks as as Unit-length', '']","['Based on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in #TAUTHOR_TAG .', 'The BILOUrepresentation suggests learning classifiers that identify the Beginning, Inside and Last tokens of multi-token chunks as as Unit-', '']","['Based on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in #TAUTHOR_TAG .', 'The BILOUrepresentation suggests learning classifiers that identify the Beginning, Inside and Last tokens of multi-token chunks as well as Unit-length chunks.', '']",4
"['', '', 'OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task #TAUTHOR_TAG , contains 3,145 annotated documents .', 'These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs.', '', '', '', '', '']","['', '', 'OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task #TAUTHOR_TAG , contains 3,145 annotated documents .', 'These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs.', '', '', '', '', '']","['', '', 'The OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task #TAUTHOR_TAG , contains 3,145 annotated documents .', 'These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs.', '', '', '', '', '']","['', '', 'The OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task #TAUTHOR_TAG , contains 3,145 annotated documents .', 'These documents come from a wide range of sources which include newswire, bible, transcripts, magazines, and web blogs.', '', '', '', '', '']",5
"['', '', '', '', '', '', '', '', '', '', '', 'Developed Systems Our developed system is built on the work by #TAUTHOR_TAG , using Constrained Latent Left-Linking Model ( CL3M ) as our mention-pair coreference model in the joint framework10 .', 'Gold', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'Developed Systems Our developed system is built on the work by #TAUTHOR_TAG , using Constrained Latent Left-Linking Model ( CL3M ) as our mention-pair coreference model in the joint framework10 .', 'Gold;', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'Developed Systems Our developed system is built on the work by #TAUTHOR_TAG , using Constrained Latent Left-Linking Model ( CL3M ) as our mention-pair coreference model in the joint framework10 .', '', '', '', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', 'Developed Systems Our developed system is built on the work by #TAUTHOR_TAG , using Constrained Latent Left-Linking Model ( CL3M ) as our mention-pair coreference model in the joint framework10 .', '', '', '', '', '', '', '', '', '']",5
"['extensthe', '', '', '', '', 'In this paper , we use the Constrained Latent Left-Linking Model ( CL3M ) described in #TAUTHOR_TAG in our experiments .']","['extensively', '', '', '', '', 'In this paper , we use the Constrained Latent Left-Linking Model ( CL3M ) described in #TAUTHOR_TAG in our experiments .']","['', '', '', '', '', 'In this paper , we use the Constrained Latent Left-Linking Model ( CL3M ) described in #TAUTHOR_TAG in our experiments .']","['', '', '', '', '', 'In this paper , we use the Constrained Latent Left-Linking Model ( CL3M ) described in #TAUTHOR_TAG in our experiments .']",5
"['ACE2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents #TAUTHOR_TAG .', 'Notes-5. dataset is Task', '', '', '', '', '', '']","['ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents #TAUTHOR_TAG .', 'OntoNotes-5.0 dataset, is Task', '', '', '', '', '', '']","['The ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents #TAUTHOR_TAG .', 'The OntoNotes-5.0 dataset, is released', '', '', '', '', '', '']","['The ACE-2004 dataset contains 443 documents.', 'We use a standard split of 268 training documents , 68 development documents , and 106 testing documents #TAUTHOR_TAG .', '', '', '', '', '', '', '']",5
"['More details can be found in #TAUTHOR_TAG et al. (2013).', 'The difference here is that we also consider the validity of mention heads using (u),(m)']","['More details can be found in #TAUTHOR_TAG et al. (2013).', 'The difference here is that we also consider the validity of mention heads using (u),(m)']","['More details can be found in #TAUTHOR_TAG et al. (2013).', 'The difference here is that we also consider the validity of mention heads using (u),(m)']","['More details can be found in #TAUTHOR_TAG et al. (2013).', 'The difference here is that we also consider the validity of mention heads using (u),(m)']",0
"['Several recent works suggest studying coreference jointly with other tasks.', ' #AUTHOR_TAG model entity coreference and event coreference jointly ; #TAUTHOR_TAG consider joint coreference and entity-linking .', '', '']","['Several recent works suggest studying coreference jointly with other tasks.', ' #AUTHOR_TAG model entity coreference and event coreference jointly ; #TAUTHOR_TAG consider joint coreference and entity-linking .', '', '']","['Several recent works suggest studying coreference jointly with other tasks.', ' #AUTHOR_TAG model entity coreference and event coreference jointly ; #TAUTHOR_TAG consider joint coreference and entity-linking .', '', '']","['Several recent works suggest studying coreference jointly with other tasks.', ' #AUTHOR_TAG model entity coreference and event coreference jointly ; #TAUTHOR_TAG consider joint coreference and entity-linking .', '', '']",0
"['', '', ', we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules #TAUTHOR_TAG with gold constituency parsing information and gold named entity information .', 'to training data', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', ', we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules #TAUTHOR_TAG with gold constituency parsing information and gold named entity information .', 'to training data', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', ', we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules #TAUTHOR_TAG with gold constituency parsing information and gold named entity information .', 'to training data', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']","['', '', 'Therefore , we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules #TAUTHOR_TAG with gold constituency parsing information and gold named entity information .', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",5
"['This section describes our joint coreference resolution and mention head detection framework.', 'Our work is inspired by the latent left-linking model in #TAUTHOR_TAG and the ILP formulation from #AUTHOR_TAG .', '', '', '', '', '', '']","['This section describes our joint coreference resolution and mention head detection framework.', 'Our work is inspired by the latent left-linking model in #TAUTHOR_TAG and the ILP formulation from #AUTHOR_TAG .', '', '', '', '', '', '']","['This section describes our joint coreference resolution and mention head detection framework.', 'Our work is inspired by the latent left-linking model in #TAUTHOR_TAG and the ILP formulation from #AUTHOR_TAG .', '', '', '', '', '', '']","['This section describes our joint coreference resolution and mention head detection framework.', 'Our work is inspired by the latent left-linking model in #TAUTHOR_TAG and the ILP formulation from #AUTHOR_TAG .', '', '', '', '', '', '']",5
"['We present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0 #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'performance']","['We present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0 #TAUTHOR_TAG .', ' #AUTHOR_TAG .', 'performance']","['We present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0 #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '']","['We present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0 #TAUTHOR_TAG .', ' #AUTHOR_TAG .', '']",5
"['', 'we extend the category generator of our previous work, which we will call P CAT .', 'We can define PCAT using a probabilistic grammar #TAUTHOR_TAG .', 'The grammar may first generate a start or end category ( , E ) with probability p se or a special tokendeletion category ( D ; explained in 5) with probability p del , or a standardG category C:']","['', 'we extend the category generator of our previous work, which we will call P CAT .', 'We can define PCAT using a probabilistic grammar #TAUTHOR_TAG .', 'The grammar may first generate a start or end category ( , E ) with probability p se or a special tokendeletion category ( D ; explained in 5) with probability p del , or a standard CCG category C:']","['', 'we extend the category generator of our previous work, which we will call P CAT .', 'We can define PCAT using a probabilistic grammar #TAUTHOR_TAG .', 'The grammar may first generate a start or end category ( , E ) with probability p se or a special tokendeletion category ( D ; explained in 5) with probability p del , or a standard CCG category C:']","['', '', 'We can define PCAT using a probabilistic grammar #TAUTHOR_TAG .', 'The grammar may first generate a start or end category ( S , E ) with probability p se or a special tokendeletion category ( D ; explained in 5) with probability p del , or a standard CCG category C:']",0
"["" #TAUTHOR_TAG 's CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) ."", 'They found that modeling constituent context aids in parser learning because it is able to capture the observation that the same contexts tend to appear repeatedly in a corpus, even with different constituents.', 'C designed tag likely context constitu about']","["" #TAUTHOR_TAG 's CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) ."", 'They found that modeling constituent context aids in parser learning because it is able to capture the observation that the same contexts tend to appear repeatedly in a corpus, even with different constituents.', 'CCM designed tag likely constituents about']","["" #TAUTHOR_TAG 's CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) ."", 'They found that modeling constituent context aids in parser learning because it is able to capture the observation that the same contexts tend to appear repeatedly in a corpus, even with different constituents.', 'C is designed tag pairs likely contexts, about']","["" #TAUTHOR_TAG 's CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) ."", 'They found that modeling constituent context aids in parser learning because it is able to capture the observation that the same contexts tend to appear repeatedly in a corpus, even with different constituents.', '']",0
"['to an words super', 'In order to estimate the parameters of our model , we develop a blocked sampler based on that of #TAUTHOR_TAG to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .', '', '']","['to an words', 'In order to estimate the parameters of our model , we develop a blocked sampler based on that of #TAUTHOR_TAG to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .', '', '']","['to some words', 'In order to estimate the parameters of our model , we develop a blocked sampler based on that of #TAUTHOR_TAG to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .', '', '']","['', 'In order to estimate the parameters of our model , we develop a blocked sampler based on that of #TAUTHOR_TAG to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .', '', '']",5
"['In our evaluation we compared our supercontext approach to (our reimplementation of) the best-performing model #AUTHOR_TAG SCM extends', 'We evaluated on the English CCGBank #AUTHOR_TAG , which is a transformation of the Penn Treebank #TAUTHOR_TAG ; the #AUTHOR_TAG transformation Tree #AUTHOR_TAG the CCUTpus #AUTHOR_TAG , from']","['In our evaluation we compared our supertagcontext approach to (our reimplementation of) the best-performing model #AUTHOR_TAG SCM extends.', 'We evaluated on the English CCGBank #AUTHOR_TAG , which is a transformation of the Penn Treebank #TAUTHOR_TAG ; the #AUTHOR_TAG transformation Treebank #AUTHOR_TAG the corpus #AUTHOR_TAG , from']","['In our evaluation we compared our supercontext approach to (our reimplementation of) the best-performing model #AUTHOR_TAG SCM extends.', 'We evaluated on the English CCGBank #AUTHOR_TAG , which is a transformation of the Penn Treebank #TAUTHOR_TAG ; #AUTHOR_TAG transformation #AUTHOR_TAG the CCG-TUT corpus #AUTHOR_TAG , from']","['In our evaluation we compared our supertagcontext approach to (our reimplementation of) the best-performing model of our previous work #AUTHOR_TAG , which SCM extends.', '']",5
"[""The right-side context of a non-terminal category -- the probability of generating a category to the right of the current constituent 's category -- corresponds directly to the category transitions used for the HMM supertagger of #TAUTHOR_TAG ."", ""Thus, the right-side context prior mean  RCTX-0 t can be biased in exactly the same way as the HMM supertagger's transitions: toward context supertags that connect to the constituent label.""]","[""The right-side context of a non-terminal category -- the probability of generating a category to the right of the current constituent 's category -- corresponds directly to the category transitions used for the HMM supertagger of #TAUTHOR_TAG ."", ""Thus, the right-side context prior mean  RCTX-0 t can be biased in exactly the same way as the HMM supertagger's transitions: toward context supertags that connect to the constituent label.""]","[""The right-side context of a non-terminal category -- the probability of generating a category to the right of the current constituent 's category -- corresponds directly to the category transitions used for the HMM supertagger of #TAUTHOR_TAG ."", ""Thus, the right-side context prior mean  RCTX-0 t can be biased in exactly the same way as the HMM supertagger's transitions: toward context supertags that connect to the constituent label.""]","[""The right-side context of a non-terminal category -- the probability of generating a category to the right of the current constituent 's category -- corresponds directly to the category transitions used for the HMM supertagger of #TAUTHOR_TAG ."", ""Thus, the right-side context prior mean  RCTX-0 t can be biased in exactly the same way as the HMM supertagger's transitions: toward context supertags that connect to the constituent label.""]",1
"['Each corpus was divided into four distinct data sets: a set from which the tag d a ( set a set.', 'We use the same splits as #TAUTHOR_TAG .', 'Since these treebanks use special representations for conjunctions, we chose to rewrite the trees to use conjunction categories of the form (X\\X)/ rather than introducing specialunction rules.', '', '', '']","['Each corpus was divided into four distinct data sets: a set from which the tag a set, a set.', 'We use the same splits as #TAUTHOR_TAG .', 'Since these treebanks use special representations for conjunctions, we chose to rewrite the trees to use conjunction categories of the form (X\\X)/X rather than introducing special conjunction rules.', '', '', '']","['Each corpus was divided into four distinct data sets: a set from which the tag d a set ( a test set.', 'We use the same splits as #TAUTHOR_TAG .', 'Since these treebanks use special representations for conjunctions, we chose to rewrite the trees to use conjunction categories of the form (X\\X)/X rather than introducing special conjunction rules.', '', '', '']","['Each corpus was divided into four distinct data sets: a set from which we extract the tag dictionaries, a set of raw (unannotated) sentences, a development set, and a test set.', 'We use the same splits as #TAUTHOR_TAG .', 'Since these treebanks use special representations for conjunctions, we chose to rewrite the trees to use conjunction categories of the form (X\\X)/X rather than introducing special conjunction rules.', '', '', '']",5
"['', '', '', '', '', '', 'This is similar to the ""deletion"" strategy employed by #TAUTHOR_TAG , but we do it directly in the grammar .', 'We add un the u for every potential supertag u in the tree.', '', '', '']","['', '', '', '', '', '', 'This is similar to the ""deletion"" strategy employed by #TAUTHOR_TAG , but we do it directly in the grammar .', 'We add unary the u for every potential supertag u in the tree.', '', '', '']","['', '', '', '', '', '', 'This is similar to the ""deletion"" strategy employed by #TAUTHOR_TAG , but we do it directly in the grammar .', 'We add un the form D u for every potential supertag u in the tree.', '', '', '']","['', '', '', '', '', '', 'This is similar to the ""deletion"" strategy employed by #TAUTHOR_TAG , but we do it directly in the grammar .', 'We add unary rules of the form D u for every potential supertag u in the tree.', '', '', '']",1
"['ars structures when possible structures', '', 'CC', 'We previously showed that incorporating this intuition into a Bayesian prior can help train a CCG supertagger #TAUTHOR_TAG .']","['structures when possible, structures.', '', '', 'We previously showed that incorporating this intuition into a Bayesian prior can help train a CCG supertagger #TAUTHOR_TAG .']","['when possible', '', 'CC', 'We previously showed that incorporating this intuition into a Bayesian prior can help train a CCG supertagger #TAUTHOR_TAG .']","['', '', '', 'We previously showed that incorporating this intuition into a Bayesian prior can help train a CCG supertagger #TAUTHOR_TAG .']",2
"['We employ the same procedure as our previous work for setting the terminal production prior distributions _TERM-0(w) by estimating word-given- category relationships from the weak supervision : the tag dictionary and raw corpus #TAUTHOR_TAG .', 'This procedure attempts to automatically estimate the frequency of each word/tag combination by dividing the number of raw-corpus occurrences of each word in the dictionary evenly across all of its associated tags.', 'These then combined with of the ness each to with']","['We employ the same procedure as our previous work for setting the terminal production prior distributions _TERM-0(w) by estimating word-given- category relationships from the weak supervision : the tag dictionary and raw corpus #TAUTHOR_TAG .4', 'This procedure attempts to automatically estimate the frequency of each word/tag combination by dividing the number of raw-corpus occurrences of each word in the dictionary evenly across all of its associated tags.', 'These then combined with of the openness each to with']","['We employ the same procedure as our previous work for setting the terminal production prior distributions _TERM-0(w) by estimating word-given- category relationships from the weak supervision : the tag dictionary and raw corpus #TAUTHOR_TAG .4', 'This procedure attempts to automatically estimate the frequency of each word/tag combination by dividing the number of raw-corpus occurrences of each word in the dictionary evenly across all of its associated tags.', 'These counts are then combined with of the openness each tag to with']","['We employ the same procedure as our previous work for setting the terminal production prior distributions _TERM-0(w) by estimating word-given- category relationships from the weak supervision : the tag dictionary and raw corpus #TAUTHOR_TAG .4', 'This procedure attempts to automatically estimate the frequency of each word/tag combination by dividing the number of raw-corpus occurrences of each word in the dictionary evenly across all of its associated tags.', '']",5
"['Like CCM, this model is deficient since the same supertags are generated multiple times, and parses with conflicting supertags are not valid.', 'Since we are not generating from the model , this does not introduce difficulties #TAUTHOR_TAG .']","['Like CCM, this model is deficient since the same supertags are generated multiple times, and parses with conflicting supertags are not valid.', 'Since we are not generating from the model , this does not introduce difficulties #TAUTHOR_TAG .']","['Like CCM, this model is deficient since the same supertags are generated multiple times, and parses with conflicting supertags are not valid.', 'Since we are not generating from the model , this does not introduce difficulties #TAUTHOR_TAG .']","['Like CCM, this model is deficient since the same supertags are generated multiple times, and parses with conflicting supertags are not valid.', 'Since we are not generating from the model , this does not introduce difficulties #TAUTHOR_TAG .']",4
"['in Figure .', 'The direction of the slash operator gives the behavior of the function', '( an in verb with apositional complement; on ( with aent with and on (\\ with', '- binary grammar.', 'We further add rules for combining with punctuation to the left and right and allow for the merge rule X \x86\x92 X X of #TAUTHOR_TAG .']","['in Figure 1.', 'The direction of the slash operator gives the behavior of the function.', 'an verb with a prepositional complement; on (/) with a constituent with and on (\\) with', 'binary grammar rules.', 'We further add rules for combining with punctuation to the left and right and allow for the merge rule X \x86\x92 X X of #TAUTHOR_TAG .']","['in Figure 1.', 'The direction of the slash operator gives the behavior of the function.', '( an intransitive verb with a prepositional phrase complement; on ( with a constituent with and on (\\ with', '- binary grammar rules.', 'We further add rules for combining with punctuation to the left and right and allow for the merge rule X \x86\x92 X X of #TAUTHOR_TAG .']","['', 'The direction of the slash operator gives the behavior of the function.', '', '', 'We further add rules for combining with punctuation to the left and right and allow for the merge rule X \x86\x92 X X of #TAUTHOR_TAG .']",5
"['To sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed by #AUTHOR_TAG and used by #TAUTHOR_TAG that samples entire parse trees .', '', '']","['To sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed by #AUTHOR_TAG and used by #TAUTHOR_TAG that samples entire parse trees .', '', '']","['To sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed by #AUTHOR_TAG and used by #TAUTHOR_TAG that samples entire parse trees .', '', '']","['To sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed by #AUTHOR_TAG and used by #TAUTHOR_TAG that samples entire parse trees .', '', '']",5
"['We wish to infer the distribution over parses, given model just.', 'way analyt modes Gibbs sampling to an solution', 'Our strategy is based on the approach presented by #TAUTHOR_TAG .', 'At a level, we alternate between resampling model parameters (_ROOT _, ___,_ , given the current of parse trees and respling those given the', '', '']","['We wish to infer the distribution over parses, given model just sentences.', 'way analytically modes, Gibbs sampling to an solution.', 'Our strategy is based on the approach presented by #TAUTHOR_TAG .', 'At a level, we alternate between resampling model parameters (_ROOT, _BIN, _ ,_ ,_,_ ,_ given the current of parse trees and resampling those given the', '', '']","['We wish to infer the distribution overG parses, given the model just.', 'no way analyt Gibbs sampling to an approximate solution.', 'Our strategy is based on the approach presented by #TAUTHOR_TAG .', 'At a high level, we alternate between resampling model parameters (_ROOT _, _ ,__,_ , given the current set of parse trees and respling those trees given', '', '']","['We wish to infer the distribution over CCG parses, given the model we just described and a corpus of sentences.', '', 'Our strategy is based on the approach presented by #TAUTHOR_TAG .', 'At a high level, we alternate between resampling model parameters (_ROOT, _BIN, _ ,_ ,_,_ ,_ ) given the current set of parse trees and resampling those trees given the current model parameters and observed word sequences.', '', '']",5
"['One important example is the constituentcontext model ( CCM ) of #TAUTHOR_TAG , which was specifically designed to capture the linguistic observation made by #AUTHOR_TAG that there are regularities to the contexts in which constituents appear', 'phenomenon, known as substitutability says that phrases of the same type appear in contexts', ', the-of-speech () sequence ADJ NOUN frequently occurs between the tags DET and VERB.', 'This DET-VERB context also frequently applies to the single-word sequence NOUN and to ADJ ADJ NOUN.', 'VERB is a foroun', 'CCM is able to learn which POS contexts are likely and does so via a probabilistic generative model, providing a statistical, data-driven on substitutability', '', '', '', '', '']","['One important example is the constituentcontext model ( CCM ) of #TAUTHOR_TAG , which was specifically designed to capture the linguistic observation made by #AUTHOR_TAG that there are regularities to the contexts in which constituents appear', 'phenomenon, known as substitutability, says that phrases of the same type appear in contexts.', 'example, the part-of-speech (POS) sequence ADJ NOUN frequently occurs between the tags DET and VERB.', 'This DET-VERB context also frequently applies to the single-word sequence NOUN and to ADJ ADJ NOUN.', 'is a for noun', 'CCM is able to learn which POS contexts are likely, and does so via a probabilistic generative model, providing a statistical, data-driven on substitutability.', '', '', '', '', '']","['One important example is the constituentcontext model ( CCM ) of #TAUTHOR_TAG , which was specifically designed to capture the linguistic observation made by #AUTHOR_TAG that there are regularities to the contexts in which constituents appear .', 'This phenomenon, known as substitutability says that phrases of the same type appear in similar contexts.', ', the part-of-speech () sequence ADJ NOUN frequently occurs between the tags DET and VERB.', 'This DET-VERB context also frequently applies to the single-word sequence NOUN and to ADJ ADJ NOUN.', 'VERB is for', 'CCM is able to learn which POS contexts are likely and does so via a probabilistic generative model, providing a statistical, data-driven take on substitutability', '', '', '', '', '']","['One important example is the constituentcontext model ( CCM ) of #TAUTHOR_TAG , which was specifically designed to capture the linguistic observation made by #AUTHOR_TAG that there are regularities to the contexts in which constituents appear .', 'This phenomenon, known as substitutability, says that phrases of the same type appear in similar contexts.', 'For example, the part-of-speech (POS) sequence ADJ NOUN frequently occurs between the tags DET and VERB.', 'This DET-VERB context also frequently applies to the single-word sequence NOUN and to ADJ ADJ NOUN.', '', 'CCM is able to learn which POS contexts are likely, and does so via a probabilistic generative model, providing a statistical, data-driven take on substitutability.', '', '', '', '', '']",0
"['seen in Figure 1.', 'The direction of the slash operator gives the behavior of the function', 'with apos complement; on with and (\\ with', 'We follow #TAUTHOR_TAG in allowing a small set of generic , linguistically-plausible unary and binary grammar rules .', ' X X']","['seen in Figure 1.', 'The direction of the slash operator gives the behavior of the function.', 'with a complement; on with and (\\) with', 'We follow #TAUTHOR_TAG in allowing a small set of generic , linguistically-plausible unary and binary grammar rules .', ' X X']","['seen in Figure 1.', 'The direction of the slash operator gives the behavior of the function.', 'with a prepositional phrase complement; on with and (\\ with', 'We follow #TAUTHOR_TAG in allowing a small set of generic , linguistically-plausible unary and binary grammar rules .', '']","['', 'The direction of the slash operator gives the behavior of the function.', '', 'We follow #TAUTHOR_TAG in allowing a small set of generic , linguistically-plausible unary and binary grammar rules .', '']",5
"['Rankboost, like other machine learning programs of the boosting family, can handle a very large number of features.', '', '31.', 'Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by #TAUTHOR_TAG .', 'The for the features was to capture declaratively decisions made by the randomized SPG.', 'particular text']","['Rankboost, like other machine learning programs of the boosting family, can handle a very large number of features.', '', '3,291', 'Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by #TAUTHOR_TAG .', 'The for the features was to capture declaratively decisions made by the randomized SPG.', 'particular text']","['Rankboost, like other machine learning programs of the boosting family, can handle a very large number of features.', '', '31 features', 'Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by #TAUTHOR_TAG .', 'The motivation for the features was to capture declaratively decisions made by the randomized SPG.', 'particular text plans']","['Rankboost, like other machine learning programs of the boosting family, can handle a very large number of features.', '', '', 'Features were discovered from the actual sentence plan trees that the SPG generated through the feature derivation process described below , in a manner similar to that used by #TAUTHOR_TAG .', 'The motivation for the features was to capture declaratively decisions made by the randomized SPG.', '']",1
"['Previous work in sentence planning in the natural language generation ( NLG ) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus ( see #TAUTHOR_TAG for a recent example with further references ) .', 'This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions #AUTHOR_TAG , and it is difficult to new applications quickly', '']","['Previous work in sentence planning in the natural language generation ( NLG ) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus ( see #TAUTHOR_TAG for a recent example with further references ) .', 'This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions #AUTHOR_TAG , and it is difficult to new applications quickly.', '']","['Previous work in sentence planning in the natural language generation ( NLG ) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus ( see #TAUTHOR_TAG for a recent example with further references ) .', 'This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions #AUTHOR_TAG , and it is difficult to new applications quickly', '']","['Previous work in sentence planning in the natural language generation ( NLG ) community uses hand-written rules to approximate the distribution of linguistic phenomena in a corpus ( see #TAUTHOR_TAG for a recent example with further references ) .', 'This approach is difficult to scale due to the nonrobustness of rules and unexpected interactions #AUTHOR_TAG , and it is difficult to develop new applications quickly.', '']",0
"['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Our primary contribution is', 'a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Our primary contribution is', 'a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'Our primary contribution is', 'a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to #TAUTHOR_TAG .']","['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a method for training the SPR. The SPR uses rules automatically learned from training data , using techniques similar to #TAUTHOR_TAG .']",1
"['', '', '', '', '', '', '', '', '', '', 'a', 'These operations are not domain-specific and are similar to those of previous aggregation components #TAUTHOR_TAG , although the various MERGE operations are , to our knowledge , novel in this form .']","['', '', '', '', '', '', '', '', '', '', 'a', 'These operations are not domain-specific and are similar to those of previous aggregation components #TAUTHOR_TAG , although the various MERGE operations are , to our knowledge , novel in this form .']","['', '', '', '', '', '', '', '', '', '', '', 'These operations are not domain-specific and are similar to those of previous aggregation components #TAUTHOR_TAG , although the various MERGE operations are , to our knowledge , novel in this form .']","['', '', '', '', '', '', '', '', '', '', '', 'These operations are not domain-specific and are similar to those of previous aggregation components #TAUTHOR_TAG , although the various MERGE operations are , to our knowledge , novel in this form .']",0
"['', '', '', '', '', '', '', '', 'sp- is inspired by #AUTHOR_TAG', 'The representations used by #AUTHOR_TAG , #AUTHOR_TAG , or #TAUTHOR_TAG are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes', '', '', '', '', '']","['', '', '', '', '', '', '', '', 'sp-tree is inspired by #AUTHOR_TAG', 'The representations used by #AUTHOR_TAG , #AUTHOR_TAG , or #TAUTHOR_TAG are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes', '', '', '', '', '']","['', '', '', '', '', '', '', '', 'is inspired by #AUTHOR_TAG .', 'The representations used by #AUTHOR_TAG , #AUTHOR_TAG , or #TAUTHOR_TAG are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes .', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', 'The representations used by #AUTHOR_TAG , #AUTHOR_TAG , or #TAUTHOR_TAG are similar , but do not ( always ) explicitly represent the clause combining operations as labeled nodes .', '', '', '', '', '']",0
"['2The algorithm was implemented by the the authors , following the description in #TAUTHOR_TAG .']","['2The algorithm was implemented by the the authors , following the description in #TAUTHOR_TAG .']","['2The algorithm was implemented by the the authors , following the description in #TAUTHOR_TAG .']","['2The algorithm was implemented by the the authors , following the description in #TAUTHOR_TAG .']",5
"['The paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system #TAUTHOR_TAG .']","['The paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system #TAUTHOR_TAG .']","['The paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system #TAUTHOR_TAG .']","['The paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system #TAUTHOR_TAG .']",1
"['The data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by #TAUTHOR_TAG .']","['The data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by #TAUTHOR_TAG .']","['The data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by #TAUTHOR_TAG .']","['The data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by #TAUTHOR_TAG .']",5
"[""\x80 The regular TBL , as described in section 2 ; \x80 An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; \x80 The FastTBL algorithm ; \x80 The ICA algorithm #TAUTHOR_TAG .""]","[""\x80 The regular TBL , as described in section 2 ; \x80 An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; \x80 The FastTBL algorithm ; \x80 The ICA algorithm #TAUTHOR_TAG .""]","[""\x80 The regular TBL , as described in section 2 ; \x80 An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; \x80 The FastTBL algorithm ; \x80 The ICA algorithm #TAUTHOR_TAG .""]","[""\x80 The regular TBL , as described in section 2 ; \x80 An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; \x80 The FastTBL algorithm ; \x80 The ICA algorithm #TAUTHOR_TAG .""]",1
['The ICA system #TAUTHOR_TAG aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance .'],['The ICA system #TAUTHOR_TAG aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance .'],['The ICA system #TAUTHOR_TAG aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance .'],['The ICA system #TAUTHOR_TAG aims to reduce the training time by introducing independence assumptions on the training samples that dramatically reduce the training time with the possible downside of sacrificing performance .'],0
"['Using the tree-cut technique described above , our previous work #TAUTHOR_TAG extracted systematic polysemy from WordNet .', 'method']","['Using the tree-cut technique described above , our previous work #TAUTHOR_TAG extracted systematic polysemy from WordNet .', 'method,']","['Using the tree-cut technique described above , our previous work #TAUTHOR_TAG extracted systematic polysemy from WordNet .', '']","['Using the tree-cut technique described above , our previous work #TAUTHOR_TAG extracted systematic polysemy from WordNet .', '']",2
"['this we describes a poly', '', 'In our previous work #TAUTHOR_TAG , we applied this method to a small subset of WordNet nouns and showed potential applicability .', 'work, we applied method to all nouns and verbs in WordNet, and built a lexicon in which word areed by systematic poly', '', '']","['this we describes a', '', 'In our previous work #TAUTHOR_TAG , we applied this method to a small subset of WordNet nouns and showed potential applicability .', 'work, we applied method to all nouns and verbs in WordNet, and built a lexicon in which word are partitioned by systematic', '', '']","['we describes', '', 'In our previous work #TAUTHOR_TAG , we applied this method to a small subset of WordNet nouns and showed potential applicability .', 'the current work, we applied the method to all nouns and verbs in WordNet, and built a lexicon in which word senses are partitioned by', '', '']","['', '', 'In our previous work #TAUTHOR_TAG , we applied this method to a small subset of WordNet nouns and showed potential applicability .', 'In the current work, we applied the method to all nouns and verbs in WordNet, and built a lexicon in which word senses are partitioned by systematic polysemy.', '', '']",2
"['In order to obtain semantic representations of each word , we apply our previous strategy #TAUTHOR_TAG .', 'using a termdocument matrix, we had followed an approach akin to that of Schtze3),', '', '']","['In order to obtain semantic representations of each word , we apply our previous strategy #TAUTHOR_TAG .', 'using a termdocument matrix, we had followed an approach akin to that of Schtze', '', '']","['In order to obtain semantic representations of each word , we apply our previous strategy #TAUTHOR_TAG .', 'using a termdocument matrix, we had followed an approach akin to that of Schtze3),', '', '']","['In order to obtain semantic representations of each word , we apply our previous strategy #TAUTHOR_TAG .', '', '', '']",2
"['', '', '', '', 'Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes- #AUTHOR_TAG a ; #TAUTHOR_TAG , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges #AUTHOR_TAG b ) and made freely', '', '', '', '']","['', '', '', '', 'Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes- #AUTHOR_TAG a ; #TAUTHOR_TAG , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges #AUTHOR_TAG b ) and made freely', '', '', '', '']","['', '', '', '', 'Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes- #AUTHOR_TAG a ; #TAUTHOR_TAG , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges #AUTHOR_TAG b ) and made freely', '', '', '', '']","['', '', '', '', 'Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes- #AUTHOR_TAG a ; #TAUTHOR_TAG , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges #AUTHOR_TAG b ) and made freely available in the openSMILE Toolkit #AUTHOR_TAG .', '', '', '', '']",2
"['Finite state transducers , which can be learned from bilingual corpora , have been proposed for automatic translation #AUTHOR_TAG , as have been bilingual stochastic grammars #TAUTHOR_TAG .']","['Finite state transducers , which can be learned from bilingual corpora , have been proposed for automatic translation #AUTHOR_TAG , as have been bilingual stochastic grammars #TAUTHOR_TAG .']","['Finite state transducers , which can be learned from bilingual corpora , have been proposed for automatic translation #AUTHOR_TAG , as have been bilingual stochastic grammars #TAUTHOR_TAG .']","['Finite state transducers , which can be learned from bilingual corpora , have been proposed for automatic translation #AUTHOR_TAG , as have been bilingual stochastic grammars #TAUTHOR_TAG .']",0
['It also shows the structural identity to bilingual grammars as used in #TAUTHOR_TAG .'],['It also shows the structural identity to bilingual grammars as used in #TAUTHOR_TAG .'],['It also shows the structural identity to bilingual grammars as used in #TAUTHOR_TAG .'],['It also shows the structural identity to bilingual grammars as used in #TAUTHOR_TAG .'],5
['It can be shown #TAUTHOR_TAG that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values .3 There is no requirement that the components of f represent disjoint orically independent events .'],['It can be shown #TAUTHOR_TAG that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values .3 There is no requirement that the components of f represent disjoint or statistically independent events .'],['It can be shown #TAUTHOR_TAG that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values .3 There is no requirement that the components of f represent disjoint orically independent events .'],['It can be shown #TAUTHOR_TAG that the use of this model with maximum likelihood parameter estimation is justified on information-theoretic grounds when q represents some prior knowledge about the true distribution and when the expected values of f in the training corpus are identical to their true expected values .3 There is no requirement that the components of f represent disjoint or statistically independent events .'],4
[' #TAUTHOR_TAG describe an efficient algorithm for accomplishing this in which approximations to Pst ( TIS ) are computed in parallel for all ( new ) features ft by holding all weights in the existing model fixed and optimizing only over a8t .'],[' #TAUTHOR_TAG describe an efficient algorithm for accomplishing this in which approximations to Pst ( TIS ) are computed in parallel for all ( new ) features ft by holding all weights in the existing model fixed and optimizing only over a8t .'],[' #TAUTHOR_TAG describe an efficient algorithm for accomplishing this in which approximations to Pst ( TIS ) are computed in parallel for all ( new ) features ft by holding all weights in the existing model fixed and optimizing only over a8t .'],[' #TAUTHOR_TAG describe an efficient algorithm for accomplishing this in which approximations to Pst ( TIS ) are computed in parallel for all ( new ) features ft by holding all weights in the existing model fixed and optimizing only over a8t .'],0
['A statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence ( MEMD ) modeling #TAUTHOR_TAG .'],['A statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence ( MEMD ) modeling #TAUTHOR_TAG .'],['A statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence ( MEMD ) modeling #TAUTHOR_TAG .'],['A statistical technique which has recently become popular for NLP is Maximum Entropy/Minimum Divergence ( MEMD ) modeling #TAUTHOR_TAG .'],5
"['As #TAUTHOR_TAG show , lexical information improves on NP and VP chunking as well .']","['As #TAUTHOR_TAG show , lexical information improves on NP and VP chunking as well .']","['As #TAUTHOR_TAG show , lexical information improves on NP and VP chunking as well .']","['As #TAUTHOR_TAG show , lexical information improves on NP and VP chunking as well .']",3
"['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG , and became a common testbed .']",1
"['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ) .']",0
"['It is not aimed at handling dependencies , which require heavy use of lexical information #TAUTHOR_TAG , for PP attachment ) .']","['It is not aimed at handling dependencies , which require heavy use of lexical information #TAUTHOR_TAG , for PP attachment ) .']","['It is not aimed at handling dependencies , which require heavy use of lexical information #TAUTHOR_TAG , for PP attachment ) .']","['It is not aimed at handling dependencies , which require heavy use of lexical information #TAUTHOR_TAG , for PP attachment ) .']",1
['Another approach for partial parsing was presented by #TAUTHOR_TAG .'],['Another approach for partial parsing was presented by #TAUTHOR_TAG .'],['Another approach for partial parsing was presented by #TAUTHOR_TAG .'],['Another approach for partial parsing was presented by #TAUTHOR_TAG .'],0
"['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG ) .']",0
"['Our results are lower than those of full parsers , e.g. , #TAUTHOR_TAG as might be expected since much less structural data , and no lexical data are being used .']","['Our results are lower than those of full parsers , e.g. , #TAUTHOR_TAG as might be expected since much less structural data , and no lexical data are being used .']","['Our results are lower than those of full parsers , e.g. , #TAUTHOR_TAG as might be expected since much less structural data , and no lexical data are being used .']","['Our results are lower than those of full parsers , e.g. , #TAUTHOR_TAG as might be expected since much less structural data , and no lexical data are being used .']",1
"['In a similar vain to #AUTHOR_TAG and #TAUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures .']","['In a similar vain to #AUTHOR_TAG and #TAUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures .']","['In a similar vain to #AUTHOR_TAG and #TAUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures .']","['In a similar vain to #AUTHOR_TAG and #TAUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures .']",3
"['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ) .']","['A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG , #AUTHOR_TAG , #AUTHOR_TAG , and #AUTHOR_TAG ) .']",0
"['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #AUTHOR_TAG , #AUTHOR_TAG , and #TAUTHOR_TAG , and became a common testbed .']",1
"['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG , and became a common testbed .']","['The system was trained on the Penn Treebank #AUTHOR_TAG WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by #AUTHOR_TAG , #TAUTHOR_TAG , and #AUTHOR_TAG , and became a common testbed .']",1
"['One approach to partial parsing was presented by #TAUTHOR_TAG , who extended a shallow-parsing technique to partial parsing .']","['One approach to partial parsing was presented by #TAUTHOR_TAG , who extended a shallow-parsing technique to partial parsing .']","['One approach to partial parsing was presented by #TAUTHOR_TAG , who extended a shallow-parsing technique to partial parsing .']","['One approach to partial parsing was presented by #TAUTHOR_TAG , who extended a shallow-parsing technique to partial parsing .']",0
"['In a similar vain to #TAUTHOR_TAG and #AUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures .']","['In a similar vain to #TAUTHOR_TAG and #AUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures .']","['In a similar vain to #TAUTHOR_TAG and #AUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures .']","['In a similar vain to #TAUTHOR_TAG and #AUTHOR_TAG , the method extends an existing flat shallow-parsing method to handle composite structures .']",3
"['the evidence for the first order is quite a bit than the evidence for the.', 'The ordered are more as are the individual adjectives', 'To quantify the relative strengths of these transitive inferences , #TAUTHOR_TAG propose to assign a weight to each link .', 'Say the order a, b occurs m times and the pair {a, b} occurs n times in total.', 'Then the weight of the pair a  b is:']","['the evidence for the first order is quite a bit than the evidence for the second.', 'The ordered are more as are the individual adjectives', 'To quantify the relative strengths of these transitive inferences , #TAUTHOR_TAG propose to assign a weight to each link .', 'Say the order a, b occurs m times and the pair {a, b} occurs n times in total.', 'Then the weight of the pair a  b is:']","['the evidence for the first order is quite a bit than the evidence for the second.', 'The ordered are more as are the individual adjectives', 'To quantify the relative strengths of these transitive inferences , #TAUTHOR_TAG propose to assign a weight to each link .', 'Say the order a, b occurs m times and the pair {a, b} occurs n times in total.', 'Then the weight of the pair a  b is:']","['Intuitively, the evidence for the first order is quite a bit stronger than the evidence for the second.', 'The first ordered pairs are more frequent, as are the individual adjectives involved.', 'To quantify the relative strengths of these transitive inferences , #TAUTHOR_TAG propose to assign a weight to each link .', 'Say the order a, b occurs m times and the pair {a, b} occurs n times in total.', 'Then the weight of the pair a  b is:']",0
"['', '', '', '', 'distributional clustering techniques ( Sch  utze , 1992 ; #TAUTHOR_TAG could be applied to extract semantic classes from the corpus itself .', 'Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results.']","['', '', '', '', 'distributional clustering techniques ( Sch  utze , 1992 ; #TAUTHOR_TAG could be applied to extract semantic classes from the corpus itself .', 'Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results.']","['', '', '', '', 'distributional clustering techniques ( Sch  utze , 1992 ; #TAUTHOR_TAG could be applied to extract semantic classes from the corpus itself .', 'Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results.']","['', '', '', '', 'More generally , distributional clustering techniques ( Sch  utze , 1992 ; #TAUTHOR_TAG could be applied to extract semantic classes from the corpus itself .', 'Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results.']",3
"['The simplest strategy for ordering adjectives is what #TAUTHOR_TAG call the direct evidence method .', 'order, b}, count how many times the ordered sequences a and b, a appear in the training data and output the pair in the which occurred more']","['The simplest strategy for ordering adjectives is what #TAUTHOR_TAG call the direct evidence method .', 'order b}, count how many times the ordered sequences a, and b, a appear in the training data and output the pair in the which occurred more']","['The simplest strategy for ordering adjectives is what #TAUTHOR_TAG call the direct evidence method .', 'order the pair {a, b}, count how many times the ordered sequences a and b, a appear in the training data and output the pair in the order which occurred more']","['The simplest strategy for ordering adjectives is what #TAUTHOR_TAG call the direct evidence method .', 'To order the pair {a, b}, count how many times the ordered sequences a, b and b, a appear in the training data and output the pair in the order which occurred more often.']",0
"['the methods way information sources are', 'The method described in section 3', 'be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature #AUTHOR_TAG .', 'In particular , boosting #TAUTHOR_TAG offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly .']","['the methods way information sources are', 'The method described in section 3.7', 'be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature #AUTHOR_TAG .', 'In particular , boosting #TAUTHOR_TAG offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly .']","['the methods the way multiple information sources are', 'The technique method described in section 3.7', 'worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature #AUTHOR_TAG .', 'In particular , boosting #TAUTHOR_TAG offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly .']","['', '', 'It would be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature #AUTHOR_TAG .', 'In particular , boosting #TAUTHOR_TAG offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly .']",3
"['of the direct is to a  on', '', '', '', ' #TAUTHOR_TAG propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .', ' c and c  b, we can conclude a', '', '', '']","['of the direct is to a  on', '', '', '', ' #TAUTHOR_TAG propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .', ' c and c  b, we can conclude a', '', '', '']","['of the direct evidence method is to a relation  on', '', '', '', ' #TAUTHOR_TAG propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .', 'a  c and c  b, we can conclude', '', '', '']","['', '', '', '', ' #TAUTHOR_TAG propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .', '', '', '', '']",0
"['The problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system.', ""One approach to this more general problem , taken by the ` Nitrogen ' generator #TAUTHOR_TAG a ; #AUTHOR_TAG b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."", 'Langkilde and this strategy yields results problems coll a', '', '', '']","['The problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system.', ""One approach to this more general problem , taken by the ` Nitrogen ' generator #TAUTHOR_TAG a ; #AUTHOR_TAG b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."", 'Langkilde and this strategy yields results problems a', '', '', '']","['The problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system.', ""One approach to this more general problem , taken by the ` Nitrogen ' generator #TAUTHOR_TAG a ; #AUTHOR_TAG b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."", 'Langkilde and this strategy yields good results problems', '', '', '']","['The problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system.', ""One approach to this more general problem , taken by the ` Nitrogen ' generator #TAUTHOR_TAG a ; #AUTHOR_TAG b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model ."", '', '', '', '']",5
"['The availability of toolkits for this weighted case #AUTHOR_TAG van #AUTHOR_TAG promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition #AUTHOR_TAG and machine translation #TAUTHOR_TAG ."", '']","['The availability of toolkits for this weighted case #AUTHOR_TAG van #AUTHOR_TAG promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition #AUTHOR_TAG and machine translation #TAUTHOR_TAG ."", '']","['The availability of toolkits for this weighted case #AUTHOR_TAG van #AUTHOR_TAG promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition #AUTHOR_TAG and machine translation #TAUTHOR_TAG ."", '']","['The availability of toolkits for this weighted case #AUTHOR_TAG van #AUTHOR_TAG promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition #AUTHOR_TAG and machine translation #TAUTHOR_TAG ."", '']",0
"['log(strength) values are called weights, but this paper uses ""weight"" to mean something else.', 'f on demand #TAUTHOR_TAG can pay off here , since only part of f may be needed subsequently . )']","['log(strength) values are called weights, but this paper uses ""weight"" to mean something else.', 'f on demand #TAUTHOR_TAG can pay off here , since only part of f may be needed subsequently . )']","['log(strength) values are called weights, but this paper uses ""weight"" to mean something else.', 'f on demand #TAUTHOR_TAG can pay off here , since only part of f may be needed subsequently . )']","['10 Traditionally log(strength) values are called weights, but this paper uses ""weight"" to mean something else.', 'f on demand #TAUTHOR_TAG can pay off here , since only part of f may be needed subsequently . )']",0
"['', '', '', '', ' #TAUTHOR_TAG give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .', 'binary operations .', '', '', 'probabilities fall sem', '']","['', '', '', '', ' #TAUTHOR_TAG give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .', 'binary operations K.', '', '', 'probabilities fall semiring', '']","['', '', '', '', ' #TAUTHOR_TAG give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .', 'binary operations ', '', '', 'inary probabilities fall', '']","['', '', '', '', ' #TAUTHOR_TAG give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .', '', '', '', '', '']",5
"['In many cases of interest i is an acyclic graph.2', ""henjan's method computes w 0 for each top t a of  and  operations."", 'For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm #TAUTHOR_TAG .', '', 'cum cum', '']","['In many cases of interest, i is an acyclic graph.', ""hen Tarjan's method computes w 0j for each topologically t a of  and  operations."", 'For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm #TAUTHOR_TAG .', '', 'cumulative cumulative', '']","['In many cases of interest is an acyclic graph. 20', ""hen Tarjan's method computes w 0 for each j top of  and  operations."", 'For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm #TAUTHOR_TAG .', '', 'cum', '']","[' In many cases of interest, T i is an acyclic graph. 20', ""hen Tarjan's method computes w 0j for each j in topologically sorted order, thereby finding t i in a linear number of  and  operations."", 'For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm #TAUTHOR_TAG .', '', '', '']",0
"['The availability of toolkits for this weighted case #TAUTHOR_TAG ; van #AUTHOR_TAG promises to unify much of statistical NLP .', 'up', '']","['The availability of toolkits for this weighted case #TAUTHOR_TAG ; van #AUTHOR_TAG promises to unify much of statistical NLP .', '', '']","['The availability of toolkits for this weighted case #TAUTHOR_TAG ; van #AUTHOR_TAG promises to unify much of statistical NLP .', '', '']","['The availability of toolkits for this weighted case #TAUTHOR_TAG ; van #AUTHOR_TAG promises to unify much of statistical NLP .', '', '']",0
"['Unfortunately, there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'only these methods require additional outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm #AUTHOR_TAG trains only Hidden Markov Models , while #TAUTHOR_TAG trains only stochastic edit distance .']","['Unfortunately, there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'only these methods require additional outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm #AUTHOR_TAG trains only Hidden Markov Models , while #TAUTHOR_TAG trains only stochastic edit distance .']","['Unfortunately, there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'only these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm #AUTHOR_TAG trains only Hidden Markov Models , while #TAUTHOR_TAG trains only stochastic edit distance .']","['Unfortunately, there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm #AUTHOR_TAG trains only Hidden Markov Models , while #TAUTHOR_TAG trains only stochastic edit distance .']",0
"['', '', '', 'and backward probabilities , p0j and pkn , can be computed using single-source algebraic path for the simpler semiring ( R , + , , \x88\x97 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations #TAUTHOR_TAG .']","['', '', '', 'and backward probabilities , p0j and pkn , can be computed using single-source algebraic path for the simpler semiring ( R , + , , \x88\x97 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations #TAUTHOR_TAG .']","['', '', '', 'and backward probabilities , p0j and pkn , can be computed using single-source algebraic path for the simpler semiring ( R , + , , \x88\x97 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations #TAUTHOR_TAG .']","['', '', '', 'The forward and backward probabilities , p0j and pkn , can be computed using single-source algebraic path for the simpler semiring ( R , + , x , \x88\x97 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations #TAUTHOR_TAG .']",0
"['4To prove ( 1 ) \x87\x92 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch  utzenberger construction #TAUTHOR_TAG , taking care to write each regexp in the construction as a constant times a probabilistic regexp .', 'A']","['4To prove ( 1 ) \x87\x92 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch  utzenberger construction #TAUTHOR_TAG , taking care to write each regexp in the construction as a constant times a probabilistic regexp .', 'A']","['4To prove ( 1 ) \x87\x92 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch  utzenberger construction #TAUTHOR_TAG , taking care to write each regexp in the construction as a constant times a probabilistic regexp .', '']","['4To prove ( 1 ) \x87\x92 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch  utzenberger construction #TAUTHOR_TAG , taking care to write each regexp in the construction as a constant times a probabilistic regexp .', '']",5
"['Division and subtraction are also possible: (p,) = (p, v) and (p, v) 1 = (p 1 , p 1 vp 1 ).', 'Division is commonly used in defining f  (for normalization). 19', 'Multiple edges from j to k are summed into a single edge.', ' #AUTHOR_TAG .', 'Efficient hardware implementation is also possible via chip-level parallelism #TAUTHOR_TAG .']","['Division and subtraction are also possible: (p, v) = (p, v) and (p, v) 1 = (p 1 , p 1 vp 1 ).', 'Division is commonly used in defining f  (for normalization). 19', 'Multiple edges from j to k are summed into a single edge.', ' #AUTHOR_TAG .', 'Efficient hardware implementation is also possible via chip-level parallelism #TAUTHOR_TAG .']","['Division and subtraction are also possible: (p, v) = (p, v) and (p, v) 1 = (p 1 , p 1 vp 1 ).', 'Division is commonly used in defining f  (for normalization). 19', 'Multiple edges from j to k are summed into a single edge.', ' #AUTHOR_TAG .', 'Efficient hardware implementation is also possible via chip-level parallelism #TAUTHOR_TAG .']","['Division and subtraction are also possible: (p, v) = (p, v) and (p, v) 1 = (p 1 , p 1 vp 1 ).', 'Division is commonly used in defining f  (for normalization). 19', 'Multiple edges from j to k are summed into a single edge.', ' #AUTHOR_TAG .', 'Efficient hardware implementation is also possible via chip-level parallelism #TAUTHOR_TAG .']",3
"['', '', '', 'Per-state joint normalization #TAUTHOR_TAG b ,  8.2 ) is similar but drops the dependence on a .', '', '']","['', '', '', 'Per-state joint normalization #TAUTHOR_TAG b ,  8.2 ) is similar but drops the dependence on a .', '', '']","['', '', '', 'Per-state joint normalization #TAUTHOR_TAG b ,  8.2 ) is similar but drops the dependence on a .', '', '']","['', '', '', 'Per-state joint normalization #TAUTHOR_TAG b ,  8.2 ) is similar but drops the dependence on a .', '', '']",1
"['The EM algorithm #TAUTHOR_TAG can maximize these functions .', 'the E step guesses hidden information: if (x i ) was generated from the current f  a of', '', ' to more', 'EM alternates these steps and converges to a local optimum.', ""The M steps form depends on the parameterization and the E step serves the M step's needs.""]","['The EM algorithm #TAUTHOR_TAG can maximize these functions .', 'the E step guesses hidden information: if (x i ) was generated from the current f  a of', '', ' to more', 'EM alternates these steps and converges to a local optimum.', ""The M step's form depends on the parameterization and the E step serves the M step's needs.""]","['The EM algorithm #TAUTHOR_TAG can maximize these functions .', 'the E step guesses hidden information: if (x i ) was generated from the current f  a chance of', '', 'to more', 'EM alternates these steps and converges to a local optimum.', ""The M step's form depends on the parameterization and the E step serves the M step's needs.""]","['The EM algorithm #TAUTHOR_TAG can maximize these functions .', 'Roughly, the E step guesses hidden information: if (x i , y i ) was generated from the current f  , which FST paths stand a chance of having been the path used?', '', '', 'EM alternates these steps and converges to a local optimum.', ""The M step's form depends on the parameterization and the E step serves the M step's needs.""]",5
"['For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules #AUTHOR_TAG , ( 3 ) by compilation of decision trees #TAUTHOR_TAG , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and van #AUTHOR_TAG ,5 ( 5 ) by conditionalization of a as below']","['For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules #AUTHOR_TAG , ( 3 ) by compilation of decision trees #TAUTHOR_TAG , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and van #AUTHOR_TAG ,5 ( 5 ) by conditionalization of a as below']","['For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules #AUTHOR_TAG , ( 3 ) by compilation of decision trees #TAUTHOR_TAG , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and van #AUTHOR_TAG ,5 ( 5 ) by conditionalization of as below']","['For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules #AUTHOR_TAG , ( 3 ) by compilation of decision trees #TAUTHOR_TAG , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and van #AUTHOR_TAG ,5 ( 5 ) by conditionalization of a joint relation as discussed below .']",0
"['Now for some important remarks on efficiency : \x80 Computing ti is an instance of the well-known algebraic path problem #TAUTHOR_TAG ; Tar an , 1981a ) . Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed W to be unique and un- weighted', 'is waste to (__xi', '', '', '']","['Now for some important remarks on efficiency : \x80 Computing ti is an instance of the well-known algebraic path problem #TAUTHOR_TAG ; Tar an , 1981a ) . Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and un- weighted).', 'is wasteful to', '', '', '']","['Now for some important remarks on efficiency : \x80 Computing ti is an instance of the well-known algebraic path problem #TAUTHOR_TAG ; Tar an , 1981a ) . Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed W to be unique and un- weighted).', 'It is waste to (__xi', '', '', '']","['Now for some important remarks on efficiency : \x80 Computing ti is an instance of the well-known algebraic path problem #TAUTHOR_TAG ; Tar an , 1981a ) . Then ti is the total semiring weight w0n of paths in Ti from initial state 0 to final state n (assumed WLOG to be unique and un- weighted).', '', '', '', '']",0
"['o:e , and a:ae  share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized either per-state globally, to obtain a joint or a cond distribution as desired.', 'Such approaches have been tried recently in restricted cases ( Mc #AUTHOR_TAG b ; #TAUTHOR_TAG .']","['o:e , and a:ae  share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized, either per-state globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases ( Mc #AUTHOR_TAG b ; #TAUTHOR_TAG .']","['o:e , and a:ae  share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized either per-state globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases ( Mc #AUTHOR_TAG b ; #TAUTHOR_TAG .']","['o:e , and a:ae  share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases ( Mc #AUTHOR_TAG b ; #TAUTHOR_TAG .']",0
"['Maximum-posterior estimation tries to maximize P ()  i f  (x i , y i ) where P () is a prior probability.', 'In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting #TAUTHOR_TAG .']","['Maximum-posterior estimation tries to maximize P ()  i f  (x i , y i ) where P () is a prior probability.', 'In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting #TAUTHOR_TAG .']","['Maximum-posterior estimation tries to maximize P ()  i f  (x i , y i ) where P () is a prior probability.', 'In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting #TAUTHOR_TAG .']","['Maximum-posterior estimation tries to maximize P ()  i f  (x i , y i ) where P () is a prior probability.', 'In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting #TAUTHOR_TAG .']",5
"['', '', 'observed (partly supervised training): thus x _  may be given as regular sets in which input and output were observed to fall.', 'For example , in ordinary HMM training , xi = E * and represents a completely hidden state sequence ( cfXXX #TAUTHOR_TAG , who allows any regular set ) , while yi is a single string representing a completely observed emission sequence .11']","['', '', 'observed (partly supervised training): thus xi _ _ may be given as regular sets in which input and output were observed to fall.', 'For example , in ordinary HMM training , xi = E * and represents a completely hidden state sequence ( cfXXX #TAUTHOR_TAG , who allows any regular set ) , while yi is a single string representing a completely observed emission sequence .11']","['', '', 'observed (partly supervised training): may be given as regular sets in which input and output were observed to fall.', 'For example , in ordinary HMM training , xi = E * and represents a completely hidden state sequence ( cfXXX #TAUTHOR_TAG , who allows any regular set ) , while yi is a single string representing a completely observed emission sequence .11']","['', '', 'Samples need not be fully observed (partly supervised training): thus xi _ __, yi _ _ may be given as regular sets in which input and output were observed to fall.', 'For example , in ordinary HMM training , xi = E * and represents a completely hidden state sequence ( cfXXX #TAUTHOR_TAG , who allows any regular set ) , while yi is a single string representing a completely observed emission sequence .11']",0
"['The availability of toolkits for this weighted case #AUTHOR_TAG van #AUTHOR_TAG promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition #TAUTHOR_TAG and machine translation ( Knight and Al- #AUTHOR_TAG ."", '']","['The availability of toolkits for this weighted case #AUTHOR_TAG van #AUTHOR_TAG promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition #TAUTHOR_TAG and machine translation ( Knight and Al- #AUTHOR_TAG ."", '']","['The availability of toolkits for this weighted case #AUTHOR_TAG van #AUTHOR_TAG promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition #TAUTHOR_TAG and machine translation ( Knight and Al- #AUTHOR_TAG ."", '']","['The availability of toolkits for this weighted case #AUTHOR_TAG van #AUTHOR_TAG promises to unify much of statistical NLP.', ""Such tools make it easy to run most current approaches to statistical markup , chunking , normalization , segmentation , alignment , and noisy-channel decoding , ' including classic models for speech recognition #TAUTHOR_TAG and machine translation ( Knight and Al- #AUTHOR_TAG ."", '']",0
"['', '', '', 'since then the real work is done by an c-closure step #TAUTHOR_TAG that implements the all-pairs version of algebraic path , whereas all we need is the single-source version', 'O', '', '']","['', '', '', 'since then the real work is done by an c-closure step #TAUTHOR_TAG that implements the all-pairs version of algebraic path , whereas all we need is the single-source version', '', '', '']","['', '', '', 'since then the real work is done by an c-closure step #TAUTHOR_TAG that implements the all-pairs version of algebraic path , whereas all we need is the single-source version .', 'O', '', '']","['', '', '', '', '', '', '']",0
"['An easy approach is to normalize the options at each state to make the FST Markovian.', 'Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation.', 'Undesirable consequences of this fact have been termed ""label bias"" #TAUTHOR_TAG .', 'the conditional case such per-state normalization is only correct if all states accept all input suffixes (since ""dead ends"" leak probability mass).', 'is global']","['An easy approach is to normalize the options at each state to make the FST Markovian.', 'Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation.', 'Undesirable consequences of this fact have been termed ""label bias"" #TAUTHOR_TAG .', 'the conditional case such per-state normalization is only correct if all states accept all input suffixes (since ""dead ends"" leak probability mass).', 'is global']","['An easy approach is to normalize the options at each state to make the FST Markovian.', 'Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation.', 'Undesirable consequences of this fact have been termed ""label bias"" #TAUTHOR_TAG .', 'the conditional case such per-state normalization is only correct if all states accept all input suffixes (since ""dead ends"" leak probability mass). 8', 'is']","[' An easy approach is to normalize the options at each state to make the FST Markovian.', 'Unfortunately, the result may differ for equivalent FSTs that express the same weighted relation.', 'Undesirable consequences of this fact have been termed ""label bias"" #TAUTHOR_TAG .', 'Also, in the conditional case such per-state normalization is only correct if all states accept all input suffixes (since ""dead ends"" leak probability mass). 8', '']",0
"['A brief version of this work, with some additional material, first appeared as #TAUTHOR_TAG a ) .', 'A leisurely journal-length version with more details has been prepared and is available.']","['A brief version of this work, with some additional material, first appeared as #TAUTHOR_TAG a ) .', 'A leisurely journal-length version with more details has been prepared and is available.']","['A brief version of this work, with some additional material, first appeared as #TAUTHOR_TAG a ) .', 'A leisurely journal-length version with more details has been prepared and is available.']","['A brief version of this work, with some additional material, first appeared as #TAUTHOR_TAG a ) .', 'A leisurely journal-length version with more details has been prepared and is available.']",2
"['', 'areedST prob', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7  arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs #TAUTHOR_TAG , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution.""]","['', 'are weighted', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7  arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs #TAUTHOR_TAG , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution.""]","['', 'are also prob', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7  arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs #TAUTHOR_TAG , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution.""]","['', '', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7  arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs #TAUTHOR_TAG , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution.""]",0
"['For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules #TAUTHOR_TAG , ( 3 ) by compilation of decision trees #AUTHOR_TAG , ( 4 ) as a relation that input sub ( Gerd and #AUTHOR_TAG ,']","['For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules #TAUTHOR_TAG , ( 3 ) by compilation of decision trees #AUTHOR_TAG , ( 4 ) as a relation that input substrings ( Gerdemann and #AUTHOR_TAG ,5']","['For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules #TAUTHOR_TAG , ( 3 ) by compilation of decision trees #AUTHOR_TAG , ( 4 ) as a relation that input substrings ( Gerd and #AUTHOR_TAG ,5']","['For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules #TAUTHOR_TAG , ( 3 ) by compilation of decision trees #AUTHOR_TAG , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and van #AUTHOR_TAG ,5 ( 5 ) by conditionalization of a joint relation as discussed below .']",0
"['o: , and a: share context ""vowfronting feature, then their weights rise and fall together with the of that feature.', 'The resulting must be normalized either- globally, to obtain a joint or a cond distribution as desired.', 'Such approaches have been tried recently in restricted cases #TAUTHOR_TAG b ; #AUTHOR_TAG .']","['o:e , and a:ae share contextual ""vowel-fronting"" feature, then their weights rise and fall together with the of that feature.', 'The resulting must be normalized, either globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases #TAUTHOR_TAG b ; #AUTHOR_TAG .']","['o:e , and a: a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized either- globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases #TAUTHOR_TAG b ; #AUTHOR_TAG .']","['o:e , and a:ae  share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases #TAUTHOR_TAG b ; #AUTHOR_TAG .']",0
"['', 'areedST prob', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7  arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs #TAUTHOR_TAG , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution.""]","['', 'are weighted', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7  arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs #TAUTHOR_TAG , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution.""]","['', 'are also prob', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7  arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs #TAUTHOR_TAG , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution.""]","['', '', 'Arbitrary weights such as 2.7 may be assigned to arcs or sprinkled through a regexp (to be compiled into : /2.7  arcs).', 'A more subtle example is weighted FSAs that approximate PCFGs #TAUTHOR_TAG , or to extend the idea , weighted FSTs that approximate joint or conditional synchronous PCFGs built for translation .', ""These are parameterized by the PCFG's parameters, but add or remove strings of the PCFG to leave an improper probability distribution.""]",0
"['Unfortunately, there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'only these methods require additional outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm #TAUTHOR_TAG trains only Hidden Markov Models , while #AUTHOR_TAG trains only stochastic edit distance .']","['Unfortunately, there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'only these methods require additional outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm #TAUTHOR_TAG trains only Hidden Markov Models , while #AUTHOR_TAG trains only stochastic edit distance .']","['Unfortunately, there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'only these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm #TAUTHOR_TAG trains only Hidden Markov Models , while #AUTHOR_TAG trains only stochastic edit distance .']","['Unfortunately, there is a stumbling block: Where do the weights come from?', 'After all, statistical models require supervised or unsupervised training.', 'Currently, finite-state practitioners derive weights using exogenous training methods, then patch them onto transducer arcs.', 'Not only do these methods require additional programming outside the toolkit, but they are limited to particular kinds of models and training regimens.', 'For example , the forward-backward algorithm #TAUTHOR_TAG trains only Hidden Markov Models , while #AUTHOR_TAG trains only stochastic edit distance .']",0
"['o: , and a: share context ""vowfronting feature, then their weights rise and fall together with the of that feature.', 'The resulting must be normalized either- globally, to obtain a joint or a cond distribution as desired.', 'Such approaches have been tried recently in restricted cases #TAUTHOR_TAG b ; #AUTHOR_TAG .']","['o:e , and a:ae share contextual ""vowel-fronting"" feature, then their weights rise and fall together with the of that feature.', 'The resulting must be normalized, either globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases #TAUTHOR_TAG b ; #AUTHOR_TAG .']","['o:e , and a: a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized either- globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases #TAUTHOR_TAG b ; #AUTHOR_TAG .']","['o:e , and a:ae  share a contextual ""vowel-fronting"" feature, then their weights rise and fall together with the strength of that feature.', 'The resulting machine must be normalized, either per-state or globally, to obtain a joint or a conditional distribution as desired.', 'Such approaches have been tried recently in restricted cases #TAUTHOR_TAG b ; #AUTHOR_TAG .']",0
"[' If arc prob linear parameter the E step must compute c i ec ( a', 'The M step then treats c as fixed , observed data and adjusts 0 until the predicted vector of total feature counts equals c , using Improved Iterative Scaling ( Della #TAUTHOR_TAG ; Chen and', 'For globally normalized, joint models, the predicted vector is ec f ( * ,  * ).', 'the-linear probabilities are condition predicted vector is to describe ( easier to']","[' If arc probabilities loglinear the E step must compute c i ec (x a', 'The M step then treats c as fixed , observed data and adjusts 0 until the predicted vector of total feature counts equals c , using Improved Iterative Scaling ( Della #TAUTHOR_TAG ; Chen and', 'For globally normalized, joint models, the predicted vector is ec f ( * ,  * ).', 'the log-linear probabilities are conditioned predicted vector is to describe (though easier to']","[' If arc probabilities  parameter then the E step must compute c = i ec (', 'The M step then treats c as fixed , observed data and adjusts 0 until the predicted vector of total feature counts equals c , using Improved Iterative Scaling ( Della #TAUTHOR_TAG ; Chen and', 'For globally normalized, joint models, the predicted vector is ec f ( * ,  * ).', 'the log-linear probabilities are conditioned the predicted vector is to describe ( easier to']","['', 'The M step then treats c as fixed , observed data and adjusts 0 until the predicted vector of total feature counts equals c , using Improved Iterative Scaling ( Della #TAUTHOR_TAG ; Chen and', 'For globally normalized, joint models, the predicted vector is ec f ( * ,  * ).', '']",5
"['A central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 #TAUTHOR_TAG .', 'The general form is illustrated by 3 Conceptually, the parameters represent the probabilities of reading another a (); reading b (); transducing b to p rather than q (); to transduce p to rather than ( To)(3), express f as an FST and applyknown KleeneSchtzenberger construction #AUTHOR_TAG , taking care to write each in the construction as a constant times a probabilistic', '']","['A central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 #TAUTHOR_TAG .', 'The general form is illustrated by 3 Conceptually, the parameters represent the probabilities of reading another a (); reading b (); transducing b to p rather than q (); to transduce p to rather than To (1)(3), express f as an FST and apply Kleene-Schtzenberger construction #AUTHOR_TAG , taking care to write each in the construction as a constant times a probabilistic', '']","['A central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 #TAUTHOR_TAG .', 'The general form is illustrated by 3 Conceptually, the parameters represent the probabilities of reading another a (); reading another b (); transducing b to p rather than q (); to transduce p to rather than ( To)(3), express f as an FST and apply the well-known Kleene-Schtzenberger construction #AUTHOR_TAG , taking care to write in the construction as a constant times a probabilistic regexp.', '']","['A central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 #TAUTHOR_TAG .', 'The general form is illustrated by 3 Conceptually, the parameters represent the probabilities of reading another a (); reading another b (); transducing b to p rather than q (); starting to transduce p to rather than x (). 4 To prove (1)(3), express f as an FST and apply the well-known Kleene-Schtzenberger construction #AUTHOR_TAG , taking care to write each regexp in the construction as a constant times a probabilistic regexp.', '']",0
"['The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq #TAUTHOR_TAG , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and', 'Additionally, several model organism databases or nomenature databases were', '', '']","['The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq #TAUTHOR_TAG , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and', 'Additionally, several model organism databases or nomenclature databases were', '', '']","['The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq #TAUTHOR_TAG , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and', 'Additionally, several model organism databases or nomenature databases were', '', '']","['The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq #TAUTHOR_TAG , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and', 'Additionally, several model organism databases or nomenclature databases were used.', '', '']",5
"['molecular bi dat We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome MGD ) 18 , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) #TAUTHOR_TAG , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] ,omenclature']","['molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome MGD ) 18 , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) #TAUTHOR_TAG , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Nomenclature']","['Other molecular biology dat We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database MGD ) 18 ] , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) #TAUTHOR_TAG , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Human Nomenclature Database']",[''],5
"['Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) #TAUTHOR_TAG , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) , worm -- WBase omenclUGO Mend']","['Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) #TAUTHOR_TAG , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) , worm -- WormBase Nomenclature HUGO']","['Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) #TAUTHOR_TAG , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) , worm -- WBase UGO']",[''],5
"['molecular We also included several model organism databases or nomenclature databases in the construction of the dictionary , i Gen fly FlyBase 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase #TAUTHOR_TAG , NomenclatureUGO ) 23 Mend']","['molecular We also included several model organism databases or nomenclature databases in the construction of the dictionary , Genome fly FlyBase 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase #TAUTHOR_TAG , Nomenclature HUGO ) 23']","['We also included several model organism databases or nomenclature databases in the construction of the dictionary , i fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase #TAUTHOR_TAG , Human Nomenclature DatabaseUGO ) 23 ]']",[''],5
"['The UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM ) #TAUTHOR_TAG .', 'It contains three knowledge sources: the Metathesaurus (META), the SPECIALIST lexicon, and the Semantic Network.', 'The META provides a uniform, integrated platform for over 60 biomedical vocabularies and classifications, and group different names for the same concept.', 'The SPECIALISTxicon contains syntactic information for many terms, words, and English words, includingbs,', 'The Semantic Network contains information about the types or categories (e.g., ""Disease or Syndrome"", ""irus"") to which all META concepts have been assigned.']","['The UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM ) #TAUTHOR_TAG .', 'It contains three knowledge sources: the Metathesaurus (META), the SPECIALIST lexicon, and the Semantic Network.', 'The META provides a uniform, integrated platform for over 60 biomedical vocabularies and classifications, and group different names for the same concept.', 'The SPECIALIST lexicon contains syntactic information for many terms, words, and English words, including verbs,', 'The Semantic Network contains information about the types or categories (e.g., ""Disease or Syndrome"", ""Virus"") to which all META concepts have been assigned.']","['The UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM ) #TAUTHOR_TAG .', 'It contains three knowledge sources: the Metathesaurus (META), the SPECIALIST lexicon, and the Semantic Network.', 'The META provides a uniform, integrated platform for over 60 biomedical vocabularies and classifications, and group different names for the same concept.', 'The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, includingbs,', 'The Semantic Network contains information about the types or categories (e.g., ""Disease or Syndrome"", ""Virus"") to which all META concepts have been assigned.']","['The UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM ) #TAUTHOR_TAG .', 'It contains three knowledge sources: the Metathesaurus (META), the SPECIALIST lexicon, and the Semantic Network.', 'The META provides a uniform, integrated platform for over 60 biomedical vocabularies and classifications, and group different names for the same concept.', 'The SPECIALIST lexicon contains syntactic information for many terms, component words, and English words, including verbs, which do not appear in the META.', 'The Semantic Network contains information about the types or categories (e.g., ""Disease or Syndrome"", ""Virus"") to which all META concepts have been assigned.']",0
"['With the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible #TAUTHOR_TAG .', 'One requirement for NLP is the ability to accurately recognize terms that represent biological entities in free text.', 'Another requirement is the ability to associate these terms with corresponding biological entities (e., records in databases) in to be for', 'called', '']","['With the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible #TAUTHOR_TAG .', 'One requirement for NLP is the ability to accurately recognize terms that represent biological entities in free text.', 'Another requirement is the ability to associate these terms with corresponding biological entities (i.e., records in databases) in to be for', 'called', '']","['With the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible #TAUTHOR_TAG .', 'One requirement for NLP is the ability to accurately recognize terms that represent biological entities in free text.', 'Another requirement is the ability to associate these terms with corresponding biological entities (e., records in biological databases) in to be used for', 'is called', '']","['With the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible #TAUTHOR_TAG .', 'One requirement for NLP is the ability to accurately recognize terms that represent biological entities in free text.', 'Another requirement is the ability to associate these terms with corresponding biological entities (i.e., records in biological databases) in order to be used by other automated systems for literature mining.', '', '']",0
"['molecular We also included several model organism databases or nomenclature databases in the construction of the dictionary , Rat wormomenclature ( HUGO )23 , Online Mendelian Inheritance in Man ( OMIM ) #TAUTHOR_TAG , and Enzyme Nomenclature ( ECNUM ) [ 25 ,2']","['molecular We also included several model organism databases or nomenclature databases in the construction of the dictionary , Rat worm Nomenclature ( HUGO ) 23 , Online Mendelian Inheritance in Man ( OMIM ) #TAUTHOR_TAG , and Enzyme Nomenclature ( ECNUM ) [ 25 ,']","['We also included several model organism databases or nomenclature databases in the construction of the dictionary , worm Human Nomenclature Database ( HUGO )23 ] , Online Mendelian Inheritance in Man ( OMIM ) #TAUTHOR_TAG , and Enzyme Nomenclature Database ( ECNUM ) [ 25 ,2']",[''],5
"['', '', 'a information descriptions structure for all', 'to  biological', '', '', 'clusters based on the CD-HIT algorithm #TAUTHOR_TAG each cluster is composed of sequences that have at least 90 % or 50 % sequence similarity , respectively , to the representative sequence', '', '', '', '', '']","['', '', 'a information, descriptions structure for all', 'to biological', '', '', 'clusters based on the CD-HIT algorithm #TAUTHOR_TAG each cluster is composed of sequences that have at least 90 % or 50 % sequence similarity , respectively , to the representative sequence', '', '', '', '', '']","['', '', 'summary descriptions structure for', 'to ', '', '', 'clusters based on the CD-HIT algorithm #TAUTHOR_TAG each cluster is composed of sequences that have at least 90 % or 50 % sequence similarity , respectively , to the representative sequence .', '', '', '', '', '']","['', '', '', '', '', '', '', '', '', '', '', '']",5
"['molecular We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. Mouse Gen , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) #TAUTHOR_TAG , worm -- WormBase [ 22 ] ,omenclatureGO23 Mend']","['molecular We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. Mouse Genome , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) #TAUTHOR_TAG , worm -- WormBase [ 22 ] , Nomenclature 23']","['We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) #TAUTHOR_TAG , worm -- WormBase [ 22 ] , Human Nomenclature DatabaseGO23 ]']",[''],5
"['The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) #TAUTHOR_TAG , and', 'Additionally, several model organism databases or nomenclature databases were used.', 'Correspondences among records from these databases are identified using the', '']","['The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) #TAUTHOR_TAG , and', 'Additionally, several model organism databases or nomenclature databases were used.', 'Correspondences among records from these databases are identified using the', '']","['The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) #TAUTHOR_TAG , and', 'Additionally, several model organism databases or nomenclature databases were used.', 'Correspondences among records from these databases are identified using', '']","['The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) #TAUTHOR_TAG , and', 'Additionally, several model organism databases or nomenclature databases were used.', '', '']",5
"['Other molecular bi databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase #TAUTHOR_TAG , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database RGD ) [ 21 ] , worm -- WormBase [ 22 ] ,omenclatureGO Mend']","['Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase #TAUTHOR_TAG , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Nomenclature']","['Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase #TAUTHOR_TAG , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Human Nomenclature DatabaseGO']",[''],5
"['molecular We also included several model organism databases or nomenclature databases in the construction of the dictionary RatomenUGO2 Mend Inheritance in Man (MIM ) [ 4 ] , and Enzyme Nomenclature Database ( ECNUM ) #TAUTHOR_TAG .']","['molecular We also included several model organism databases or nomenclature databases in the construction of the dictionary Rat HUGO Inheritance in Man ( OMIM ) [ 24 ] , and Enzyme Nomenclature Database ( ECNUM ) #TAUTHOR_TAG .']","['We also included several model organism databases or nomenclature databases in the construction of the dictionaryUGO2 Online Mendelian Inheritance in Man (MIM ) [ 4 ] , and Enzyme Nomenclature Database ( ECNUM ) #TAUTHOR_TAG .']",[''],5
"['For our experiments, we use naive Bayes as the learning algorithm.', 'The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.', 'These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work #TAUTHOR_TAG .']","['For our experiments, we use naive Bayes as the learning algorithm.', 'The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.', 'These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work #TAUTHOR_TAG .']","['For our experiments, we use naive Bayes as the learning algorithm.', 'The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.', 'These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work #TAUTHOR_TAG .']","['For our experiments, we use naive Bayes as the learning algorithm.', 'The knowledge sources we use include parts-of-speech, local collocations, and surrounding words.', 'These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work #TAUTHOR_TAG .']",2
"['knowledge-lean approaches have significantly influenced research inoun', 'knowledge-lean approaches, coreference resolvers employ only-syntactic cues as knowledge sources in the resolution process (.g., , #AUTHOR_TAG', 'While these approaches have been reasonably successful ( see #AUTHOR_TAG ) , #TAUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '', '']","['knowledge-lean approaches have significantly influenced research in noun', 'knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., , #AUTHOR_TAG', 'While these approaches have been reasonably successful ( see #AUTHOR_TAG ) , #TAUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '', '']","['knowledge-lean approaches have significantly influenced research inoun phrase', 'knowledge-lean approaches, coreference resolvers employ only-syntactic cues as knowledge sources in the resolution process (.g., , #AUTHOR_TAG ).', 'While these approaches have been reasonably successful ( see #AUTHOR_TAG ) , #TAUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '', '']","['', 'In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., #AUTHOR_TAG , #AUTHOR_TAG ).', 'While these approaches have been reasonably successful ( see #AUTHOR_TAG ) , #TAUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '', '']",0
"['', '', '', '', 'importantly, the ACE participants do not evaluate the role of induced SC knowledge in coreference resolution: many of them evaluate coreference performance on perfect mentions (e.g., #TAUTHOR_TAG ; and for those that do report per- formance on automatically extracted mentions, they do not explain whether or how the induced SC information is used in their coreference algorithms.']","['', '', '', '', 'importantly, the ACE participants do not evaluate the role of induced SC knowledge in coreference resolution: many of them evaluate coreference performance on perfect mentions (e.g., #TAUTHOR_TAG ; and for those that do report per- formance on automatically extracted mentions, they do not explain whether or how the induced SC information is used in their coreference algorithms.']","['', '', '', '', 'importantly, the ACE participants do not evaluate the role of induced SC knowledge in coreference resolution: many of them evaluate coreference performance on perfect mentions (e.g., #TAUTHOR_TAG ; and for those that do report per- formance on automatically extracted mentions, they do not explain whether or how the induced SC information is used in their coreference algorithms.']","['', '', '', '', 'More importantly, the ACE participants do not evaluate the role of induced SC knowledge in coreference resolution: many of them evaluate coreference performance on perfect mentions (e.g., #TAUTHOR_TAG ; and for those that do report per- formance on automatically extracted mentions, they do not explain whether or how the induced SC information is used in their coreference algorithms.']",1
"['In the past decade, knowledge-lean approaches have significantly influenced research in noun phrase (NP) coreference resolution -the problem of determining which NPs refer to the same real-world entity in a.', 'In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG .', 'reasonably (see #AUTHOR_TAG', '', '']","['In the past decade, knowledge-lean approaches have significantly influenced research in noun phrase (NP) coreference resolution -the problem of determining which NPs refer to the same real-world entity in a document.', 'In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG .', 'reasonably (see #AUTHOR_TAG', '', '']","['In the past decade, knowledge-lean approaches have significantly influenced research in noun phrase (NP) coreference resolution -the problem of determining which NPs refer to the same real-world entity in a document.', 'In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG .', '(see #AUTHOR_TAG ),', '', '']","['In the past decade, knowledge-lean approaches have significantly influenced research in noun phrase (NP) coreference resolution -the problem of determining which NPs refer to the same real-world entity in a document.', 'In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG .', '', '', '']",0
"['adopted', '', 'A our SC classifier instead, we use the BBN Entity Type Corpus #TAUTHOR_TAG , which consists of all the Penn Treebank Wall Street Journal articles with the ACE mentions manually identified and annotated with their SCs.', 'This provides us with a training set that is approximately five times bigger than that of ACE.', '']","['adopted', '', 'ACE our SC classifier; instead, we use the BBN Entity Type Corpus #TAUTHOR_TAG , which consists of all the Penn Treebank Wall Street Journal articles with the ACE mentions manually identified and annotated with their SCs.', 'This provides us with a training set that is approximately five times bigger than that of ACE.', '']","['adopted', '', 'our SC classifier; instead, we use the BBN Entity Type Corpus #TAUTHOR_TAG , which consists of all the Penn Treebank Wall Street Journal articles with the ACE mentions manually identified and annotated with their SCs.', 'This provides us with a training set that is approximately five times bigger than that of ACE.', '']","['', '', '', 'This provides us with a training set that is approximately five times bigger than that of ACE.', '']",5
"['knowledge-lean approaches have significantly influenced research inoun problem', 'knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., #AUTHOR_TAG , #AUTHOR_TAG ).', 'While these approaches have been reasonably successful ( see #TAUTHOR_TAG , #AUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '', '']","['knowledge-lean approaches have significantly influenced research in noun problem', 'knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., #AUTHOR_TAG , #AUTHOR_TAG ).', 'While these approaches have been reasonably successful ( see #TAUTHOR_TAG , #AUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '', '']","['knowledge-lean approaches have significantly influenced research inoun phrase', 'knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., #AUTHOR_TAG , #AUTHOR_TAG ).', 'While these approaches have been reasonably successful ( see #TAUTHOR_TAG , #AUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '', '']","['', 'In knowledge-lean approaches, coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process (e.g., #AUTHOR_TAG , #AUTHOR_TAG ).', 'While these approaches have been reasonably successful ( see #TAUTHOR_TAG , #AUTHOR_TAG speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .', '', '']",0
"['we train anVM classifier for SC determination by combining the output of five clas- sification methods: DL NNB, and Soon et al.s method described in the introduction, the exam whether SC classifica- tion accuracy can be improved combining the output of individual classifiers a supervised ner', 'Soon al.; and (3) train an SVM classifier (using the LIBSVM package #TAUTHOR_TAG ) on these 20% of the instances, where each instance, i, is represented by a PER ORG GPE FAC LOC OTH Training Test 199. . .     ', '', '']","['we train an SVM classifier for SC determination by combining the output of five clas- sification methods: DL, NB, and Soon et al.s method described in the introduction,8 the examining whether SC classifica- tion accuracy can be improved combining the output of individual classifiers a supervised ner.', 'Soon al.s instances; and (3) train an SVM classifier (using the LIBSVM package #TAUTHOR_TAG ) on these 20% of the instances, where each instance, i, is represented by a PER ORG GPE FAC LOC OTH Training Test 19.8 1.2', '', '']","['we train an SVM classifier for SC determination by combining the output of five clas- sification methods: DL, NN and Soon et al.s method described in the introduction,8 the goal exam whether SC classifica- tion accuracy can be improved combining the output of individual classifiers a supervised man- ner.', 'Soon al. and (3) train an SVM classifier (using the LIBSVM package #TAUTHOR_TAG ) on these 20% of the instances, where each instance, i, is represented by', '', '']","['In addition, we train an SVM classifier for SC determination by combining the output of five clas- sification methods: DL, 1-NN, ME, NB, and Soon et al.s method as described in the introduction,8 with the goal of examining whether SC classifica- tion accuracy can be improved by combining the output of individual classifiers in a supervised man- ner.', '', '', '']",5
"[""( 4 NE : We use BBN 's IdentiFinder #TAUTHOR_TAG , a MUC-style NE recognizer to determine the NE type of NPZ ."", 'ORGAN', '', '']","[""( 4 NE : We use BBN 's IdentiFinder #TAUTHOR_TAG , a MUC-style NE recognizer to determine the NE type of NPZ ."", 'ORGANIZATION,', '', '']","[""( 4 NE : We use BBN 's IdentiFinder #TAUTHOR_TAG , a MUC-style NE recognizer to determine the NE type of NPZ ."", 'ORGAN', '', '']","[""( 4 ) NE : We use BBN 's IdentiFinder #TAUTHOR_TAG , a MUC-style NE recognizer to determine the NE type of NPZ ."", '', '', '']",5
"['type of semantic knowledge that been employed coreference resolvers is the semantic class (', 'learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG .', 'It is not easy to measure the accuracy thisur, the SC agreement feature is used Soon']","['type of semantic knowledge that been employed coreference resolvers is the semantic class', 'learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG .', 'It is not easy to measure the accuracy this heuristic, the SC agreement feature is used Soon']","['Another type of semantic knowledge that has been employed coreference resolvers is the semantic class (', 'learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG .', 'It is not easy to measure the accuracy this heuristic, the SC agreement feature is not used Soon']","['', 'However , learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , #AUTHOR_TAG , #TAUTHOR_TAG .', '']",0
"['Learning algorithms.', 'We experiment with four learners commonly employed in language learning : Decision List ( DL : We use the DL learner as described in #TAUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation #AUTHOR_TAG and NE classification #AUTHOR_TAG .', '.']","['Learning algorithms.', 'We experiment with four learners commonly employed in language learning : Decision List ( DL : We use the DL learner as described in #TAUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation #AUTHOR_TAG and NE classification #AUTHOR_TAG .', '']","['Learning algorithms.', 'We experiment with four learners commonly employed in language learning : Decision List ( DL : We use the DL learner as described in #TAUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation #AUTHOR_TAG and NE classification #AUTHOR_TAG .', '']","['Learning algorithms.', 'We experiment with four learners commonly employed in language learning : Decision List ( DL ) : We use the DL learner as described in #TAUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation #AUTHOR_TAG and NE classification #AUTHOR_TAG .', '']",5
"['As in SC indu we ACE corpus for evaluation purposes acquiring theference class evaluating output 97.', 'We report performance in terms of two metrics : ( 1 ) the Fmeasure score as computed by the commonly-used MUC scorer #TAUTHOR_TAG , and ( 2 ) the accuracy on the anaphoric references , computed as the fraction of anaphoric references correctly resolved .', '', '']","['As in SC we ACE corpus for evaluation purposes, acquiring the coreference classifiers evaluating output 97 texts.', 'We report performance in terms of two metrics : ( 1 ) the Fmeasure score as computed by the commonly-used MUC scorer #TAUTHOR_TAG , and ( 2 ) the accuracy on the anaphoric references , computed as the fraction of anaphoric references correctly resolved .', '', '']","['As in SC induction, we useference corpus for evaluation purposes, acquiring the coreference classifiers evaluating output the 97 test texts.', 'We report performance in terms of two metrics : ( 1 ) the Fmeasure score as computed by the commonly-used MUC scorer #TAUTHOR_TAG , and ( 2 ) the accuracy on the anaphoric references , computed as the fraction of anaphoric references correctly resolved .', '', '']","['', 'We report performance in terms of two metrics : ( 1 ) the Fmeasure score as computed by the commonly-used MUC scorer #TAUTHOR_TAG , and ( 2 ) the accuracy on the anaphoric references , computed as the fraction of anaphoric references correctly resolved .', '', '']",5
"['After training, the decision tree classifier is used to select an antecedent for each NP in a test.', 'Following #TAUTHOR_TAG , we select as the antecedent of each NP, NPj, the closest preceding NP that is classified as coreferent with NPj.', 'If no such NP exists, no antecedent is selected for NPj.']","['After training, the decision tree classifier is used to select an antecedent for each NP in a test text.', 'Following #TAUTHOR_TAG , we select as the antecedent of each NP, NPj, the closest preceding NP that is classified as coreferent with NPj.', 'If no such NP exists, no antecedent is selected for NPj.']","['After training, the decision tree classifier is used to select an antecedent for each NP in a test text.', 'Following #TAUTHOR_TAG , we select as the antecedent of each NP, NPj, the closest preceding NP that is classified as coreferent with NPj.', 'If no such NP exists, no antecedent is selected for NPj.']","['After training, the decision tree classifier is used to select an antecedent for each NP in a test text.', 'Following #TAUTHOR_TAG , we select as the antecedent of each NP, NPj, the closest preceding NP that is classified as coreferent with NPj.', 'If no such NP exists, no antecedent is selected for NPj.']",4
"['Many ACE participants have also adopted a corpus-based approach to SC determination that is investigated as part of the mention detection (MD) task ( e.g. , #TAUTHOR_TAG .', 'Briefly, the goal of MD is to identify the boundary of a mention, its mention type (e.g., pronoun, name), and its semantic type (e.g., person, location).', '', '', '']","['Many ACE participants have also adopted a corpus-based approach to SC determination that is investigated as part of the mention detection (MD) task ( e.g. , #TAUTHOR_TAG .', 'Briefly, the goal of MD is to identify the boundary of a mention, its mention type (e.g., pronoun, name), and its semantic type (e.g., person, location).', '', '', '']","['Many ACE participants have also adopted a corpus-based approach to SC determination that is investigated as part of the mention detection (MD) task ( e.g. , #TAUTHOR_TAG .', 'Briefly, the goal of MD is to identify the boundary of a mention, its mention type (e.g., pronoun, name), and its semantic type (e.g., person, location).', '', '', '']","['Many ACE participants have also adopted a corpus-based approach to SC determination that is investigated as part of the mention detection (MD) task ( e.g. , #TAUTHOR_TAG .', 'Briefly, the goal of MD is to identify the boundary of a mention, its mention type (e.g., pronoun, name), and its semantic type (e.g., person, location).', '', '', '']",1
"['Our baselineference system uses the C s', 'and; and a negative instance is created for NPj paired with each of the intervening NPs, NPi+\x0e, NPi+2,   , NPj positional features that have been employed by high- performing resolvers such as #AUTHOR_TAG and #TAUTHOR_TAG , as described below .']","['Our baseline coreference system uses the sion', 'and and a negative instance is created for NPj paired with each of the intervening NPs, NPi+\x0e, NPi+2,   , NPj positional features that have been employed by high- performing resolvers such as #AUTHOR_TAG and #TAUTHOR_TAG , as described below .']","['Our baseline coreference system uses', 'and and a negative instance is created for NPj paired with each of the intervening NPs, NPi+\x0e, NPi+2,   , NPj positional features that have been employed by high- performing resolvers such as #AUTHOR_TAG and #TAUTHOR_TAG , as described below .']","['', 'Following previous work (e.g., #AUTHOR_TAG and #AUTHOR_TAG ), we generate training instances as follows: a positive instance is created for each anaphoric NP, NPj, and its closest antecedent, NPi; and a negative instance is created for NPj paired with each of the intervening NPs, NPi+\x0e, NPi+2,   , NPj positional features that have been employed by high- performing resolvers such as #AUTHOR_TAG and #TAUTHOR_TAG , as described below .']",1
"['Our baseline coreference system uses the C4 .5 decision tree learner #TAUTHOR_TAG to acquire a classifier on the training texts for determining whether two NPs are coreferent .', 'work created', '', '']","['Our baseline coreference system uses the C4 .5 decision tree learner #TAUTHOR_TAG to acquire a classifier on the training texts for determining whether two NPs are coreferent .', 'work created', '', '']","['Our baseline coreference system uses the C4 .5 decision tree learner #TAUTHOR_TAG to acquire a classifier on the training texts for determining whether two NPs are coreferent .', 'is created', '', '']","['Our baseline coreference system uses the C4 .5 decision tree learner #TAUTHOR_TAG to acquire a classifier on the training texts for determining whether two NPs are coreferent .', '', '', '']",5
"['', '', 'Each instance is represented by 33 lexical, grammatical, semantic, andpositional features that have been employed by high- performing resolvers such as #TAUTHOR_TAG and #AUTHOR_TAG , as described below.']","['', '', 'Each instance is represented by 33 lexical, grammatical, semantic, andpositional features that have been employed by high- performing resolvers such as #TAUTHOR_TAG and #AUTHOR_TAG , as described below.']","['', '', 'Each instance is represented by 33 lexical, grammatical, semantic, andpositional features that have been employed by high- performing resolvers such as #TAUTHOR_TAG and #AUTHOR_TAG , as described below.']","['', '', 'Each instance is represented by 33 lexical, grammatical, semantic, andpositional features that have been employed by high- performing resolvers such as #TAUTHOR_TAG and #AUTHOR_TAG , as described below.']",1
"['', 'two andaphoric asaphoric', 'Following #TAUTHOR_TAG , we consider an anaphoric reference , NPi , correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition .', 'use automatically extracted']","['', 'two and anaphoric as anaphoric', 'Following #TAUTHOR_TAG , we consider an anaphoric reference , NPi , correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition .', 'use automatically extracted']","['', 'and asaphoric references', 'Following #TAUTHOR_TAG , we consider an anaphoric reference , NPi , correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition .', 'we use automatically extracted']","['', '', 'Following #TAUTHOR_TAG , we consider an anaphoric reference , NPi , correctly resolved if NPi and its closest antecedent are in the same coreference chain in the resulting partition .', '']",5
"['lean', '', '', '', 'a researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #AUTHOR_TAG , and the contextual role played by an NP ( see #TAUTHOR_TAG .']","['', '', '', '', 'a researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #AUTHOR_TAG , and the contextual role played by an NP ( see #TAUTHOR_TAG .']","['lean approaches', '', '', '', 'a result researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #AUTHOR_TAG , and the contextual role played by an NP ( see #TAUTHOR_TAG .']","['', '', '', '', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #AUTHOR_TAG , and the contextual role played by an NP ( see #TAUTHOR_TAG .']",0
"['type of semantic knowledge that been employed coreference resolvers is the semantic class', 'learning-based resolvers have not been able to benefit from having an SC agreement feature , because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , #TAUTHOR_TAG , #AUTHOR_TAG ) .', 'It is not easy measure the thisur, SC is used']","['type of semantic knowledge that been employed coreference resolvers is the semantic class', 'learning-based resolvers have not been able to benefit from having an SC agreement feature , because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , #TAUTHOR_TAG , #AUTHOR_TAG ) .', 'It is not easy measure the this heuristic, SC is used']","['Another type of semantic knowledge that has been employed coreference resolvers is the semantic class', 'learning-based resolvers have not been able to benefit from having an SC agreement feature , because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , #TAUTHOR_TAG , #AUTHOR_TAG ) .', 'It is not easy measure the accuracy this heuristic, is not used']","['', 'However , learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , #TAUTHOR_TAG , #AUTHOR_TAG ) .', '']",0
"['Our baseline coreference system uses the C4.5 decision tree learner #AUTHOR_TAG to acquire a classifier on the training texts for determining whether two NPs are coreferent.', 'Following previous work ( e.g. , #TAUTHOR_TAG and #AUTHOR_TAG ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .', '., NP j1 .', '']","['Our baseline coreference system uses the C4.5 decision tree learner #AUTHOR_TAG to acquire a classifier on the training texts for determining whether two NPs are coreferent.', 'Following previous work ( e.g. , #TAUTHOR_TAG and #AUTHOR_TAG ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .', '., NP j1 .', '']","['Our baseline coreference system uses the C4.5 decision tree learner #AUTHOR_TAG to acquire a classifier on the training texts for determining whether two NPs are coreferent.', 'Following previous work ( e.g. , #TAUTHOR_TAG and #AUTHOR_TAG ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .', '., NP j1 .', '']","['Our baseline coreference system uses the C4.5 decision tree learner #AUTHOR_TAG to acquire a classifier on the training texts for determining whether two NPs are coreferent.', 'Following previous work ( e.g. , #TAUTHOR_TAG and #AUTHOR_TAG ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .', '., NP j1 .', '']",5
"['', 'We with four learners commonly employed in language learning : We use the DL learner as described in #AUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation #TAUTHOR_TAG and NE classification #AUTHOR_TAG .', '.']","['', 'We with four learners commonly employed in language learning : We use the DL learner as described in #AUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation #TAUTHOR_TAG and NE classification #AUTHOR_TAG .', '']","['', 'We experiment with four learners commonly employed in language learning : We use the DL learner as described in #AUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation #TAUTHOR_TAG and NE classification #AUTHOR_TAG .', '']","['', 'We experiment with four learners commonly employed in language learning : Decision List ( DL ) : We use the DL learner as described in #AUTHOR_TAG , motivated by its success in the related tasks of word sense disambiguation #TAUTHOR_TAG and NE classification #AUTHOR_TAG .', '']",4
"['', '', '', '', 'researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #TAUTHOR_TAG , and the contextual role played by an NP ( see #AUTHOR_TAG ) .']","['', '', '', '', 'researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #TAUTHOR_TAG , and the contextual role played by an NP ( see #AUTHOR_TAG ) .']","['', '', '', '', 'researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #TAUTHOR_TAG , and the contextual role played by an NP ( see #AUTHOR_TAG ) .']","['', '', '', '', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #AUTHOR_TAG ) , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #TAUTHOR_TAG , and the contextual role played by an NP ( see #AUTHOR_TAG ) .']",0
"['', '', '', '', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #TAUTHOR_TAG , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #AUTHOR_TAG , and the contextual role played by an NP ( see #AUTHOR_TAG ) .']","['', '', '', '', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #TAUTHOR_TAG , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #AUTHOR_TAG , and the contextual role played by an NP ( see #AUTHOR_TAG ) .']","['', '', '', '', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #TAUTHOR_TAG , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #AUTHOR_TAG , and the contextual role played by an NP ( see #AUTHOR_TAG ) .']","['', '', '', '', 'As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , #TAUTHOR_TAG , their semantic similarity as computed using WordNet ( e.g. , #AUTHOR_TAG ) or Wikipedia #AUTHOR_TAG , and the contextual role played by an NP ( see #AUTHOR_TAG ) .']",0
"['', '', '', '', '', '', '', 'in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs ( see #TAUTHOR_TAG a ) ) .', 'Motivated by this observation, we create']","['', '', '', '', '', '', '', 'in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs ( see #TAUTHOR_TAG a ) ) .', 'Motivated by this observation, we create']","['', '', '', '', '', '', '', 'in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs ( see #TAUTHOR_TAG a ) ) .', 'Motivated by this observation, we create']","['', '', '', '', '', '', '', '( 7 ) NEIGHBOR : Research in lexical semantics suggests that the SC of an NP can be inferred from its distributionally similar NPs ( see #TAUTHOR_TAG a ) ) .', 'Motivated by this observation, we create']",4
"['', '', '', '-sense heuristic used in the previous feature may not be accurate in capturing the SC of an N , we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. , #TAUTHOR_TAG .', ' we use to relations', '', '', '', '']","['', '', '', 'first-sense heuristic used in the previous feature may not be accurate in capturing the SC of an NP , we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. , #TAUTHOR_TAG .', '3 we use to relations.', '', '', '', '']","['', '', '', 'the first-sense heuristic used in the previous feature may not be accurate in capturing the SC of an NP , we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. , #TAUTHOR_TAG .', 'we use to', '', '', '', '']","['', '', '', '', '', '', '', '', '']",4
"['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all ofistic prosures.', '', '', '', '', '']","['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all of linguistic gestures.', '', '', '', '', '']","['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all ofures.', '', '', '', '', '']","['', '', '', 'Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['All communicative head gestures in the videos were found and annotated with ANVIL using a subset of the attributes defined in the MUMIN annotation scheme #TAUTHOR_TAG .', 'The MU- general for study of gestures in interpersonal communication', '', '', '']","['All communicative head gestures in the videos were found and annotated with ANVIL using a subset of the attributes defined in the MUMIN annotation scheme #TAUTHOR_TAG .', 'The MU-MIN general for study of gestures in interpersonal communication.', '', '', '']","['All communicative head gestures in the videos were found and annotated with ANVIL using a subset of the attributes defined in the MUMIN annotation scheme #TAUTHOR_TAG .', 'The MU-MIN scheme for the study of gestures in interpersonal communication.', '', '', '']","['All communicative head gestures in the videos were found and annotated with ANVIL using a subset of the attributes defined in the MUMIN annotation scheme #TAUTHOR_TAG .', 'The MU-MIN scheme is a general framework for the study of gestures in interpersonal communication.', '', '', '']",5
"['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', ' #AUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while #TAUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '', '', '', '', '', '', '', '']","['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', ' #AUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while #TAUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '', '', '', '', '', '', '', '']","['has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', ' #AUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while #TAUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '', '', '', '', '', '', '', '']","['Work has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', ' #AUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while #TAUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '', '', '', '', '', '', '', '']",0
"['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all ofistic prosures.', '', '', '', '', '']","['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all of linguistic gestures.', '', '', '', '', '']","['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all ofures.', '', '', '', '', '']","['', '', '', 'Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena ( see #TAUTHOR_TAG for an overview ) .', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'dependence', '']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena ( see #TAUTHOR_TAG for an overview ) .', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'dependence', '']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena ( see #TAUTHOR_TAG for an overview ) .', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'a dependence', '']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena ( see #TAUTHOR_TAG for an overview ) .', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', '', '']",0
"['', '', 'derived each an feature the agreement analysis facility', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa #AUTHOR_TAG 1 and corrected kappa #TAUTHOR_TAG 2 ."", '', '', '']","['', '', 'derived each feature the agreement analysis facility', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa #AUTHOR_TAG 1 and corrected kappa #TAUTHOR_TAG 2 ."", '', '', '']","['', '', 'was derived each annotated feature using the agreement analysis facility', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa #AUTHOR_TAG 1 and corrected kappa #TAUTHOR_TAG 2 ."", '', '', '']","['', '', '', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa #AUTHOR_TAG 1 and corrected kappa #TAUTHOR_TAG 2 ."", '', '', '']",5
"['', '', 'and #AUTHOR_TAG study the relation eye gaze , expression pauses and dialogue structure in annotated English map-task dialogues #TAUTHOR_TAG and find correlations between the various modalities both within and across speakers', '', '', '', '', '', '', '']","['', '', 'and #AUTHOR_TAG study the relation eye gaze , expression pauses and dialogue structure in annotated English map-task dialogues #TAUTHOR_TAG and find correlations between the various modalities both within and across speakers', '', '', '', '', '', '', '']","['', '', 'and #AUTHOR_TAG study the relation eye gaze , facial expression pauses and dialogue structure in annotated English map-task dialogues #TAUTHOR_TAG and find correlations between the various modalities both within and across speakers .', '', '', '', '', '', '', '']","['', '', ' #AUTHOR_TAG and #AUTHOR_TAG study the relation between eye gaze , facial expression , pauses and dialogue structure in annotated English map-task dialogues #TAUTHOR_TAG and find correlations between the various modalities both within and across speakers .', '', '', '', '', '', '', '']",0
"['multim we the linguistic annotations fromnotation data and the other the subset of a as shown in Table 4.', 'These two sets of data were used for automatic dialogue act classification , which was run in the Weka system #TAUTHOR_TAG .', 'We experimented with various Weka classifiers, comprising Hidden Naive Bayes, SMO, ID3, LADTree and Decision Table .', '', '', '']","['multimodal we the linguistic annotations from annotation data, and the other the subset of a as shown in Table 4.', 'These two sets of data were used for automatic dialogue act classification , which was run in the Weka system #TAUTHOR_TAG .', 'We experimented with various Weka classifiers, comprising Hidden Naive Bayes, SMO, ID3, LADTree and Decision Table .', '', '', '']","['we obtained combining the linguistic annotations from data and the other the subset of as shown in Table 4.', 'These two sets of data were used for automatic dialogue act classification , which was run in the Weka system #TAUTHOR_TAG .', 'We experimented with various Weka classifiers, comprising Hidden Naive Bayes, SMO, ID3, LADTree and Decision Table .', '', '', '']","['', 'These two sets of data were used for automatic dialogue act classification , which was run in the Weka system #TAUTHOR_TAG .', 'We experimented with various Weka classifiers, comprising Hidden Naive Bayes, SMO, ID3, LADTree and Decision Table .', '', '', '']",5
"['Work has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', ' #TAUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while #AUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '', '', '', '', '', '', '', '']","['Work has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', ' #TAUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while #AUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '', '', '', '', '', '', '', '']","['Work has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', ' #TAUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while #AUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '', '', '', '', '', '', '', '']","['Work has also been done on prosody and gestures in the specific domain of map-task dialogues, also targeted in this paper.', ' #TAUTHOR_TAG obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while #AUTHOR_TAG examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .', '', '', '', '', '', '', '', '']",0
"['', '', 'derived feature agreement analysis', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa #TAUTHOR_TAG 1 and corrected kappa #AUTHOR_TAG 2 ."", '', '', '']","['', '', 'derived feature agreement analysis', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa #TAUTHOR_TAG 1 and corrected kappa #AUTHOR_TAG 2 ."", '', '', '']","['', '', 'was derived the agreement analysis facility', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa #TAUTHOR_TAG 1 and corrected kappa #AUTHOR_TAG 2 ."", '', '', '']","['', '', '', ""Agreement between two annotation sets is calculated here in terms of Cohen 's kappa #TAUTHOR_TAG 1 and corrected kappa #AUTHOR_TAG 2 ."", '', '', '']",5
"['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all ofistic prosures.', '', '', '', '', '']","['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all of linguistic gestures.', '', '', '', '', '']","['', '', '', 'feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', 'Our these all ofures.', '', '', '', '', '']","['', '', '', 'Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication #TAUTHOR_TAG .', '', '', '', '', '', '']",0
"['not for of the three semantic', 'be Ag and a TurnEit at the, thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see #TAUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent #AUTHOR_TAG ."", 'the of disag we could see that fact that the annot features automaticallyV']","['for of the three semantic', 'be Agree and a TurnElicit at the time, thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see #TAUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent #AUTHOR_TAG ."", 'the of disagreement we could see that fact that the annotators features automatically']","['for of the three semantic dimensions.', 'can be and a TurnElicit at the same time, thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see #TAUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent #AUTHOR_TAG ."", 'the cases of disag we could see that the fact that the annotators the features automaticallyV']","['', 'For example, a yes can be an Answer to a question, an Agree and a TurnElicit at the same time, thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see #TAUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent #AUTHOR_TAG ."", '']",0
"['Several authors in head are relevant to feedback phenomena (see overview', 'looked application of machine learning algorithms to annotatedal corpor', 'dependence', 'Related are also the studies by Rieks op den #AUTHOR_TAG and #TAUTHOR_TAG : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus .']","['Several authors in head are relevant to feedback phenomena (see overview).', 'looked application of machine learning algorithms to annotated', 'dependence', 'Related are also the studies by Rieks op den #AUTHOR_TAG and #TAUTHOR_TAG : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus .']","['Several authors in head movements are relevant to feedback phenomena (see', 'have looked the application of machine learning algorithms to annotatedal corpora.', 'a dependence', 'Related are also the studies by Rieks op den #AUTHOR_TAG and #TAUTHOR_TAG : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus .']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', '', 'Related are also the studies by Rieks op den #AUTHOR_TAG and #TAUTHOR_TAG : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus .']",0
"['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example , #TAUTHOR_TAG and #AUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , while #AUTHOR_TAG show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related also the den']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example , #TAUTHOR_TAG and #AUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , while #AUTHOR_TAG show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related also the den']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example , #TAUTHOR_TAG and #AUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , while #AUTHOR_TAG show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related are also the studies op den']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example , #TAUTHOR_TAG and #AUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , while #AUTHOR_TAG show that there is a dependence between focus of attention and assignment of dialogue act labels .', '']",0
"['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example , #AUTHOR_TAG and #TAUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , while #AUTHOR_TAG show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example , #AUTHOR_TAG and #TAUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , while #AUTHOR_TAG show that there is a dependence between focus of attention and assignment of dialogue act labels .', 'Related']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example , #AUTHOR_TAG and #TAUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , while #AUTHOR_TAG show that there is a dependence between focus of attention and assignment of dialogue act labels .', '']","['Several authors in communication studies have pointed out that head movements are relevant to feedback phenomena (see Mc #AUTHOR_TAG for an overview).', 'Others have looked at the application of machine learning algorithms to annotated multimodal corpora.', 'For example , #AUTHOR_TAG and #TAUTHOR_TAG find that machine learning algorithms can be trained to recognise some of the functions of head movements , while #AUTHOR_TAG show that there is a dependence between focus of attention and assignment of dialogue act labels .', '']",0
"['not', 'a Turnit at the thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see #AUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent #TAUTHOR_TAG ."", '']","['', 'a TurnElicit at the thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see #AUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent #TAUTHOR_TAG ."", '']","['', 'a TurnElicit at thus making the semantic classification very fine-grained.', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see #AUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent #TAUTHOR_TAG ."", '']","['', '', ""Table 1 Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures, see #AUTHOR_TAG , it is usually assumed that Cohen's kappa figures over 60 are good while those over are excellent #TAUTHOR_TAG ."", '']",0
"['', 'then used to measure interoder agreementIL as it the case for the annotations on feedback expressions', 'In the case ofures we also measured agreement on gesture segmentation.', 'The figures obtained are given in Table 3.', 'These results are slightly worse than those obtained in previous studies using the same annotation scheme #TAUTHOR_TAG , but are still sat -isfactory given the high number of categories provided by the scheme.']","['', 'then used to measure inter-coder agreement as it the case for the annotations on feedback expressions.', 'In the case of gestures we also measured agreement on gesture segmentation.', 'The figures obtained are given in Table 3.', 'These results are slightly worse than those obtained in previous studies using the same annotation scheme #TAUTHOR_TAG , but are still sat -isfactory given the high number of categories provided by the scheme.']","['', 'were then used to measure interoder agreementIL as it was the case for the annotations on feedback expressions.', 'In the case ofures we also measured agreement on gesture segmentation.', 'The figures obtained are given in Table 3.', 'These results are slightly worse than those obtained in previous studies using the same annotation scheme #TAUTHOR_TAG , but are still sat -isfactory given the high number of categories provided by the scheme.']","['', 'The annotations of this video were then used to measure inter-coder agreement in ANVIL as it was the case for the annotations on feedback expressions.', 'In the case of gestures we also measured agreement on gesture segmentation.', 'The figures obtained are given in Table 3.', 'These results are slightly worse than those obtained in previous studies using the same annotation scheme #TAUTHOR_TAG , but are still sat -isfactory given the high number of categories provided by the scheme.']",1
"['', '', '', '', '', '', '', 'acts to the', 'The results , which partly confirm those obtained on a smaller dataset in #TAUTHOR_TAG , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions', 'ks']","['', '', '', '', '', '', '', 'acts to the', 'The results , which partly confirm those obtained on a smaller dataset in #TAUTHOR_TAG , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions', 'jerks']","['', '', '', '', '', '', '', 'dialogue acts to', 'The results , which partly confirm those obtained on a smaller dataset in #TAUTHOR_TAG , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions .', 'ks']","['', '', '', '', '', '', '', '', 'The results , which partly confirm those obtained on a smaller dataset in #TAUTHOR_TAG , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions .', '']",1
"['Table', '', 'compr Table', 'The best results on most of our data were obtained using Hidden Naive Bayes ( HNB ) #TAUTHOR_TAG .', 'Therefore, here we show the results of this classifier.', 'cross']","['Table', '', 'comprising Table', 'The best results on most of our data were obtained using Hidden Naive Bayes ( HNB ) #TAUTHOR_TAG .', 'Therefore, here we show the results of this classifier.', 'crossvalidation']","['Table', '', '', 'The best results on most of our data were obtained using Hidden Naive Bayes ( HNB ) #TAUTHOR_TAG .', 'Therefore, here we show the results of this classifier.', '']","['', '', '', 'The best results on most of our data were obtained using Hidden Naive Bayes ( HNB ) #TAUTHOR_TAG .', 'Therefore, here we show the results of this classifier.', '']",5
"['all in areonetically and prosodically annotated', '', 'For this study, we added semantic labels -including dialogue acts -and gesture annotation.', 'Both kinds of annotation were carried out using ANVIL #TAUTHOR_TAG .', 'that categories ', '', '', '']","['all in are phonetically and prosodically annotated.', '', 'For this study, we added semantic labels -including dialogue acts -and gesture annotation.', 'Both kinds of annotation were carried out using ANVIL #TAUTHOR_TAG .', 'that categories', '', '', '']","['all words in are phonetically and prosodically annotated', '', 'For this study, we added semantic labels -including dialogue acts -and gesture annotation.', 'Both kinds of annotation were carried out using ANVIL #TAUTHOR_TAG .', 'that the categories ', '', '', '']","['As already mentioned, all words in DanPASS are phonetically and prosodically annotated.', '', 'For this study, we added semantic labels -including dialogue acts -and gesture annotation.', 'Both kinds of annotation were carried out using ANVIL #TAUTHOR_TAG .', '', '', '', '']",5
"['Phonetic andodic segmentation and annotation were performed independently in annot an agreed version was produced with the supervision of an expert annot, for more information see Grnnum (2006).', 'The Praat tool was used #TAUTHOR_TAG .']","['Phonetic and prosodic segmentation and annotation were performed independently in annotators an agreed version was produced with the supervision of an expert annotator, for more information see Grnnum (2006).', 'The Praat tool was used #TAUTHOR_TAG .']","['Phonetic andodic segmentation and annotation were performed independently in an agreed version was produced with the supervision of an expert annotator, for more information see Grnnum (2006).', 'The Praat tool was used #TAUTHOR_TAG .']","['Phonetic and prosodic segmentation and annotation were performed independently and in parallel by two annotators and then an agreed upon version was produced with the supervision of an expert annotator, for more information see Grnnum (2006).', 'The Praat tool was used #TAUTHOR_TAG .']",5
"['The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', ""The diagnoser , based on #TAUTHOR_TAG b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer ."", 'matching to']","['The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', ""The diagnoser , based on #TAUTHOR_TAG b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer ."", 'matching to']","['The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', ""The diagnoser , based on #TAUTHOR_TAG b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer ."", 'to']","['The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', ""The diagnoser , based on #TAUTHOR_TAG b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer ."", '']",2
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share providing stepaff.', 'the', 'tut number-edi.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing problems.', 'the', 'tutoring number remediations.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step', '', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['), passed', 'The uses a domain-specific content planner to produce input to the strategy decision , and a FUF/SURGE #TAUTHOR_TAG generation system to produce the appropriate text', '']","['confirm), passed', 'The uses a domain-specific content planner to produce input to the strategy decision , and a FUF/SURGE #TAUTHOR_TAG generation system to produce the appropriate text', '']","['), is passed', 'The system uses a domain-specific content planner to produce input to the strategy decision , and a FUF/SURGE #TAUTHOR_TAG generation system to produce the appropriate text .', '']","['', 'The system uses a domain-specific content planner to produce input to the surface realizer based on the strategy decision , and a FUF/SURGE #TAUTHOR_TAG generation system to produce the appropriate text .', '']",5
"['planning', '', 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain #TAUTHOR_TAG .', 'Using a deep to automatically generate system feedback gives us a level of control over the output will.']","['planning', '', 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain #TAUTHOR_TAG .', 'Using a deep to automatically generate system feedback gives us a level of control over the output will detail.']","['', '', 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain #TAUTHOR_TAG .', 'Using a deep generator to automatically generate system feedback gives us a level of control over the output will allow']","['', '', 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain #TAUTHOR_TAG .', 'Using a deep generator to automatically generate system feedback gives us a level of control over the output and will allow us to devise experiments to study those issues in more detail.']",3
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share providing stepaff.', 'the', 'tut number-edi.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing problems.', 'the', 'tutoring number remediations.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step', '', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['Interaction between components is coordinated by the dialogue manager which uses the informationstate approach #TAUTHOR_TAG .', 'The dialogue state is represented by a cumulative answer analysis which tracks, over multiple, the correct, incorrect, and not-yet-mentioned parts of the answer.', 'Once the complete answer has been accumulated, the system accepts it and moves on.', 'Tutors can contribute the cumulative state as the system to joint the solution with the student.']","['Interaction between components is coordinated by the dialogue manager which uses the informationstate approach #TAUTHOR_TAG .', 'The dialogue state is represented by a cumulative answer analysis which tracks, over multiple turns, the correct, incorrect, and not-yet-mentioned parts of the answer.', 'Once the complete answer has been accumulated, the system accepts it and moves on.', 'Tutor hints can contribute the cumulative state as the system to jointly the solution with the student.']","['Interaction between components is coordinated by the dialogue manager which uses the informationstate approach #TAUTHOR_TAG .', 'The dialogue state is represented by a cumulative answer analysis which tracks, over multiple, the correct, incorrect, and not-yet-mentioned parts of the answer.', 'Once the complete answer has been accumulated, the system accepts it and moves on.', 'Tutor hints can contribute the answer the cumulative state as the system to joint the solution with the student.']","['Interaction between components is coordinated by the dialogue manager which uses the informationstate approach #TAUTHOR_TAG .', 'The dialogue state is represented by a cumulative answer analysis which tracks, over multiple turns, the correct, incorrect, and not-yet-mentioned parts of the answer.', 'Once the complete answer has been accumulated, the system accepts it and moves on.', 'Tutor hints can contribute parts of the answer to the cumulative state as well, allowing the system to jointly construct the solution with the student.']",5
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-bystepaff and potentially additional.', 'disadvantage students theed for the error', 'tut']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step and potentially additional problems.', 'disadvantage students the for the error', 'tutoring']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-bystep scaffolding and potentially suggesting additional problems.', 'The disadvantage: students for the same error regardless', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['key issue we are planning to investigate is that of linguistic alignment.', ""The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed #TAUTHOR_TAG ."", 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain #AUTHOR_TAG', '']","['key issue we are planning to investigate is that of linguistic alignment.', ""The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed #TAUTHOR_TAG ."", 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain #AUTHOR_TAG', '']","['the key issue we are planning to investigate is that of linguistic alignment.', ""The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed #TAUTHOR_TAG ."", 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain #AUTHOR_TAG .', '']","['In dialogue management and generation, the key issue we are planning to investigate is that of linguistic alignment.', ""The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed #TAUTHOR_TAG ."", 'Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain #AUTHOR_TAG .', '']",3
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share providing stepaff.', 'the', 'tut number-edi.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing problems.', 'the', 'tutoring number remediations.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step', '', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-bystepaff and potentially additional.', 'disadvantage students theed for the error', 'tut']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step and potentially additional problems.', 'disadvantage students the for the error', 'tutoring']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-bystep scaffolding and potentially suggesting additional problems.', 'The disadvantage: students for the same error regardless', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['The tutorial policy makes a-level decision as to which strategy to (foracknow the correct and give a high specificity"")', 'the system into consideration the incorrect received in response to current question and the number of uninterpret1 In addition to a remediation policy , the tutorial planner implements an error recovery policy #TAUTHOR_TAG .', '', '', '', '', '']","['The tutorial policy makes a high-level decision as to which strategy to (for ""acknowledge the correct and give a high specificity hint"")', 'the system into consideration the incorrect received in response to current question and the number of uninterpretable .1 In addition to a remediation policy , the tutorial planner implements an error recovery policy #TAUTHOR_TAG .', '', '', '', '', '']","['The tutorial policy makes a high-level decision as to which strategy to (acknow the correct part and give a high specificity hint"")', 'the system into consideration the number incorrect answers received in response to the current question and the number of uninterpret1 In addition to a remediation policy , the tutorial planner implements an error recovery policy #TAUTHOR_TAG .', '', '', '', '', '']","['The tutorial policy makes a high-level decision as to which strategy to use (for example, ""acknowledge the correct part and give a high specificity hint"") based on the answer analysis and dialogue context.', 'At present , the system takes into consideration the number of incorrect answers received in response to the current question and the number of uninterpretable answers .1 In addition to a remediation policy , the tutorial planner implements an error recovery policy #TAUTHOR_TAG .', '', '', '', '', '']",5
"['We use parser #AUTHOR_TAG to parse utterances', 'a domain- semantic representation including high-level word senses and semantic role labels.', ""contextual interpreter then uses a reference resolution approach similar to #TAUTHOR_TAG , and an ontology mapping mechanism #AUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output"", '', '', '', '', '', '']","['We use parser #AUTHOR_TAG to parse utterances.', 'a domain-independent semantic representation including high-level word senses and semantic role labels.', ""contextual interpreter then uses a reference resolution approach similar to #TAUTHOR_TAG , and an ontology mapping mechanism #AUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output"", '', '', '', '', '', '']","['We use #AUTHOR_TAG to parse the utterances.', 'a domain-independent semantic representation including high-level word senses and semantic role labels.', ""The contextual interpreter then uses a reference resolution approach similar to #TAUTHOR_TAG , and an ontology mapping mechanism #AUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '', '', '', '', '', '']","['We use the TRIPS dialogue parser #AUTHOR_TAG to parse the utterances.', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', ""The contextual interpreter then uses a reference resolution approach similar to #TAUTHOR_TAG , and an ontology mapping mechanism #AUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '', '', '', '', '', '']",1
"['The BEETLE II system architecture is designed to overcome these limitations #TAUTHOR_TAG .', 'It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically.', 'This allows the system to consistently apply the same tutorial policy across a range of questions.', 'this at the expense of being able to address studentcon', '']","['The BEETLE II system architecture is designed to overcome these limitations #TAUTHOR_TAG .', 'It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically.', 'This allows the system to consistently apply the same tutorial policy across a range of questions.', 'this at the expense of being able to address student', '']","['The BEETLE II system architecture is designed to overcome these limitations #TAUTHOR_TAG .', 'It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically.', 'This allows the system to consistently apply the same tutorial policy across a range of questions.', 'this at the expense of being able to address', '']","['The BEETLE II system architecture is designed to overcome these limitations #TAUTHOR_TAG .', 'It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically.', 'This allows the system to consistently apply the same tutorial policy across a range of questions.', 'To some extent, this comes at the expense of being able to address individual student misconceptions.', '']",0
"['The knowledge base is used to check the factual correctness of the answers first, and then aoser checks the explanation correctness.', ""The on #AUTHOR_TAG b non relations'"", 'At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to #TAUTHOR_TAG .']","['The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', 'The on #AUTHOR_TAG b), relations', 'At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to #TAUTHOR_TAG .']","['The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', 'on #AUTHOR_TAG b), non relations', 'At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to #TAUTHOR_TAG .']","['The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness.', '', 'At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to #TAUTHOR_TAG .']",3
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-bystepaff and potentially additional.', 'disadvantage students theed for the error', 'tut']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step and potentially additional problems.', 'disadvantage students the for the error', 'tutoring']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-bystep scaffolding and potentially suggesting additional problems.', 'The disadvantage: students for the same error regardless', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #AUTHOR_TAG Van #AUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #TAUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share providing stepaff.', 'the', 'tut number-edi.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing problems.', 'the', 'tutoring number remediations.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step', '', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['', '- including high-level word and semantic role', ""contextual interpreter then uses a reference resolution approach similar and an ontology mapping mechanism #TAUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '', '', '', '', '', '']","['', 'including high-level word and semantic role', ""contextual interpreter then uses a reference resolution approach similar and an ontology mapping mechanism #TAUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '', '', '', '', '', '']","['', 'high-level word senses and semantic role labels.', ""The contextual interpreter then uses a reference resolution approach similar and an ontology mapping mechanism #TAUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '', '', '', '', '', '']","['', '', ""The contextual interpreter then uses a reference resolution approach similar to #AUTHOR_TAG , and an ontology mapping mechanism #TAUTHOR_TAG a ) to produce a domain-specific semantic representation of the student 's output ."", '', '', '', '', '', '']",5
['Other factors such as student confidence could be considered as well #TAUTHOR_TAG .'],['Other factors such as student confidence could be considered as well #TAUTHOR_TAG .'],['Other factors such as student confidence could be considered as well #TAUTHOR_TAG .'],['Other factors such as student confidence could be considered as well #TAUTHOR_TAG .'],3
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share providing stepaff.', 'the', 'tut number-edi.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing problems.', 'the', 'tutoring number remediations.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step', '', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share providing stepaff.', 'the', 'tut number-edi.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing problems.', 'the', 'tutoring number remediations.']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step', '', '']","['Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations #TAUTHOR_TAG , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring #AUTHOR_TAG .', 'However, most existing systems use pre-authored tutor responses for addressing student errors.', 'The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems.', '', '']",0
"['', '', '', 'Our recovery policy is modeled on the TargetedHelp #TAUTHOR_TAG policy used in task-oriented dialogue .', '', '', '']","['', '', '', 'Our recovery policy is modeled on the TargetedHelp #TAUTHOR_TAG policy used in task-oriented dialogue .', '', '', '']","['', '', '', 'Our recovery policy is modeled on the TargetedHelp #TAUTHOR_TAG policy used in task-oriented dialogue .', '', '', '']","['', '', '', 'Our recovery policy is modeled on the TargetedHelp #TAUTHOR_TAG policy used in task-oriented dialogue .', '', '', '']",2
"['We use the TRIPS dialogue parser #TAUTHOR_TAG to parse the utterances .', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', '', '', '', '', '', '', '']","['We use the TRIPS dialogue parser #TAUTHOR_TAG to parse the utterances .', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', '', '', '', '', '', '', '']","['We use the TRIPS dialogue parser #TAUTHOR_TAG to parse the utterances .', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', '', '', '', '', '', '', '']","['We use the TRIPS dialogue parser #TAUTHOR_TAG to parse the utterances .', 'The parser provides a domain-independent semantic representation including high-level word senses and semantic role labels.', '', '', '', '', '', '', '']",5
"['The system uses a knowledge base implemented in the KM representation language #TAUTHOR_TAG to represent the state of the world .', 'At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits.']","['The system uses a knowledge base implemented in the KM representation language #TAUTHOR_TAG to represent the state of the world .', 'At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits.']","['The system uses a knowledge base implemented in the KM representation language #TAUTHOR_TAG to represent the state of the world .', 'At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits.']","['The system uses a knowledge base implemented in the KM representation language #TAUTHOR_TAG to represent the state of the world .', 'At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits.']",5
"['All current approaches to monolingual TE , either syntactically oriented #AUTHOR_TAG , or applying logical inference #AUTHOR_TAG , or adopting transformation-based techniques #TAUTHOR_TAG , incorporate different types ofxical knowledge to support textual inference', '', '', '', '', '']","['All current approaches to monolingual TE , either syntactically oriented #AUTHOR_TAG , or applying logical inference #AUTHOR_TAG , or adopting transformation-based techniques #TAUTHOR_TAG , incorporate different types of lexical knowledge to support textual inference', '', '', '', '', '']","['All current approaches to monolingual TE , either syntactically oriented #AUTHOR_TAG , or applying logical inference #AUTHOR_TAG , or adopting transformation-based techniques #TAUTHOR_TAG , incorporate different types ofxical knowledge to support textual inference .', '', '', '', '', '']","['All current approaches to monolingual TE , either syntactically oriented #AUTHOR_TAG , or applying logical inference #AUTHOR_TAG , or adopting transformation-based techniques #TAUTHOR_TAG , incorporate different types of lexical knowledge to support textual inference .', '', '', '', '', '']",0
"['Phrase tables (PHT) contain pairs of corresponding phrases in two languages, together with association probabilities.', 'They are widely used in MT as a way to figure out how to translate input in one language into output in another language #TAUTHOR_TAG .', 'There are several methods to build phrase tables.', 'b', '', '', '', '', '', '', '']","['Phrase tables (PHT) contain pairs of corresponding phrases in two languages, together with association probabilities.', 'They are widely used in MT as a way to figure out how to translate input in one language into output in another language #TAUTHOR_TAG .', 'There are several methods to build phrase tables.', '', '', '', '', '', '', '', '']","['Phrase tables (PHT) contain pairs of corresponding phrases in two languages, together with association probabilities.', 'They are widely used in MT as a way to figure out how to translate input in one language into output in another language #TAUTHOR_TAG .', 'There are several methods to build phrase tables.', '', '', '', '', '', '', '', '']","['Phrase tables (PHT) contain pairs of corresponding phrases in two languages, together with association probabilities.', 'They are widely used in MT as a way to figure out how to translate input in one language into output in another language #TAUTHOR_TAG .', 'There are several methods to build phrase tables.', '', '', '', '', '', '', '', '']",0
"['ones , DIRT #TAUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs fre source of precise rules', '', '', '']","['ones , DIRT #TAUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, fre- source of precise rules', '', '', '']","['ones , DIRT #TAUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs fre a source of', '', '', '']","['ones , DIRT #TAUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are fre- quently used as a source of precise entailment rules between predicates.', '', '', '']",0
"['All current approaches to monolingual TE , either syntactically oriented #AUTHOR_TAG , or applying logical inference ( Tatu and #TAUTHOR_TAG , or adopting transformation-based techniques #AUTHOR_TAG Bar- #AUTHOR_TAG , incorporate different types ofxical knowledge to support textual inference .', '', '', '', '', '']","['All current approaches to monolingual TE , either syntactically oriented #AUTHOR_TAG , or applying logical inference ( Tatu and #TAUTHOR_TAG , or adopting transformation-based techniques #AUTHOR_TAG Bar- #AUTHOR_TAG , incorporate different types of lexical knowledge to support textual inference .', '', '', '', '', '']","['All current approaches to monolingual TE , either syntactically oriented #AUTHOR_TAG , or applying logical inference ( Tatu and #TAUTHOR_TAG , or adopting transformation-based techniques #AUTHOR_TAG Bar- #AUTHOR_TAG , incorporate different types ofxical knowledge to support textual inference .', '', '', '', '', '']","['All current approaches to monolingual TE , either syntactically oriented #AUTHOR_TAG , or applying logical inference ( Tatu and #TAUTHOR_TAG , or adopting transformation-based techniques #AUTHOR_TAG Bar- #AUTHOR_TAG , incorporate different types of lexical knowledge to support textual inference .', '', '', '', '', '']",0
"['', '16', 'Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by #TAUTHOR_TAG .', ""The method relies on translation-validation cycles, defined as separate jobs routed to MTurk's workforce."", 'Translation jobs return one Spanish version for each hypothesis.', 'ation jobs ask multiple workers to check the correctness of each translation using the original English sentence as reference.', 'cycle, the translated hypothesis accepted by the majority of trustful validators 5 are stored in theTEpus, while wrong translations are sent back a new', '', '']","['', '1600', 'Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by #TAUTHOR_TAG .', ""The method relies on translation-validation cycles, defined as separate jobs routed to MTurk's workforce."", 'Translation jobs return one Spanish version for each hypothesis.', 'Validation jobs ask multiple workers to check the correctness of each translation using the original English sentence as reference.', 'cycle, the translated hypothesis accepted by the majority of trustful validators 5 are stored in the CLTE corpus, while wrong translations are sent back a new', '', '']","['', '16', 'Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by #TAUTHOR_TAG .', ""The method relies on translation-validation cycles, defined as separate jobs routed to MTurk's workforce."", 'Translation jobs return one Spanish version for each hypothesis.', 'ation jobs ask multiple workers to check the correctness of each translation using the original English sentence as reference.', 'each cycle, the translated hypothesis accepted by the majority of trustful validators 5 are stored in the CLTE corpus, while wrong translations are sent back', '', '']","['', '', 'Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by #TAUTHOR_TAG .', ""The method relies on translation-validation cycles, defined as separate jobs routed to MTurk's workforce."", 'Translation jobs return one Spanish version for each hypothesis.', 'Validation jobs ask multiple workers to check the correctness of each translation using the original English sentence as reference.', 'At each cycle, the translated hypothesis accepted by the majority of trustful validators 5 are stored in the CLTE corpus, while wrong translations are sent back to workers in a new translation job.', '', '']",5
"['Cross-lingual Textual Entailment ( CLTE ) has been proposed by #TAUTHOR_TAG as an extension of Textual Entailment #AUTHOR_TAG that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', ', the reliance of cur- rent moningual systems onxical resources (e.g. WordNet, VerbOcean, FrameNet) and deep processing (.actic and semantic pars,, press and normal']","['Cross-lingual Textual Entailment ( CLTE ) has been proposed by #TAUTHOR_TAG as an extension of Textual Entailment #AUTHOR_TAG that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', 'instance, the reliance of cur- rent monolingual systems on lexical resources (e.g. WordNet, VerbOcean, FrameNet) and deep processing syntactic and semantic parsers, tools, pressions and']","['Cross-lingual Textual Entailment ( CLTE ) has been proposed by #TAUTHOR_TAG as an extension of Textual Entailment #AUTHOR_TAG that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', ', the reliance of cur- rent moningual TE systems onxical resources (e.g. WordNet, VerbOcean, FrameNet) and deep processing components (.actic and sem and normal']","['Cross-lingual Textual Entailment ( CLTE ) has been proposed by #TAUTHOR_TAG as an extension of Textual Entailment #AUTHOR_TAG that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', '']",0
"['', '', 'block any system.', 'Using the basic solution proposed by #TAUTHOR_TAG as a term of comparison , we experiment with different sources of multilingual lexical knowledge to address the following questions :']","['', '', 'block any system.', 'Using the basic solution proposed by #TAUTHOR_TAG as a term of comparison , we experiment with different sources of multilingual lexical knowledge to address the following questions :']","['', '', 'any TE system.', 'Using the basic solution proposed by #TAUTHOR_TAG as a term of comparison , we experiment with different sources of multilingual lexical knowledge to address the following questions :']","['', '', '', 'Using the basic solution proposed by #TAUTHOR_TAG as a term of comparison , we experiment with different sources of multilingual lexical knowledge to address the following questions :']",1
"['', '', '', '', '', 'We tokenization , and used the Giza + + #TAUTHOR_TAG to align the tokenized corpora at the word level .', 'bilingual phrase', '', '', '', '']","['', '', '', '', '', 'We tokenization , and used the Giza + + #TAUTHOR_TAG to align the tokenized corpora at the word level .', 'bilingual phrase', '', '', '', '']","['', '', '', '', '', 'We run tokenization , and used the Giza + + #TAUTHOR_TAG to align the tokenized corpora at the word level .', 'the bilingual phrase table', '', '', '', '']","['', '', '', '', '', 'We run TreeTagger #AUTHOR_TAG for tokenization , and used the Giza + + #TAUTHOR_TAG to align the tokenized corpora at the word level .', '', '', '', '', '']",5
"['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization #TAUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #AUTHOR_TAG', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization #TAUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #AUTHOR_TAG', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization #TAUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #AUTHOR_TAG .', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization #TAUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #AUTHOR_TAG .', '', '', '']",4
"['consensus on usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, they always component in complex architectures them ways', 'emerges ablation tests reported in , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works #TAUTHOR_TAG indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words .']","['consensus on usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, they always component in complex architectures them ways.', 'emerges ablation tests reported in , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works #TAUTHOR_TAG indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words .']","['the consensus on the usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, they always one component in complex architectures them', 'emerges the ablation tests reported in , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works #TAUTHOR_TAG indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words .']","['Despite the consensus on the usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, as they always represent one component in complex architectures that may use them in different ways.', 'As emerges from the ablation tests reported in #AUTHOR_TAG , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works #TAUTHOR_TAG indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words .']",0
"['To combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight #TAUTHOR_TAG , using each score as a feature .']","['To combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight #TAUTHOR_TAG , using each score as a feature .']","['To combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight #TAUTHOR_TAG , using each score as a feature .']","['To combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight #TAUTHOR_TAG , using each score as a feature .']",5
"['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #TAUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #AUTHOR_TAG', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #TAUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #AUTHOR_TAG', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #TAUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #AUTHOR_TAG .', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #TAUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #AUTHOR_TAG .', '', '', '']",4
"['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #TAUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte-ated as a source of lexical.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet', '', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #TAUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet', '', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #TAUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte-ated as a source of lex', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet', '', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #TAUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection of sta- tistically learned inference rules, that is often inte- grated as a source of lexical paraphrases and entail- ment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', '', '', '']",0
"['Addressing we have to additional and more problem issues related to', '', '', '', 'the only by and the ament', 'Multilingual lexical databases aligned with the English WordNet ( e.g. MultiWordNet #TAUTHOR_TAG ) have been created for several languages , with different degrees of coverage .', 'As an example, the 57,424 synsets of the Spanish section of MultiWordNet aligned to English cover just around 50% of the WordNets synsets, thus making the coverage issue even more problematic than for TE.', 'links between languagesx', '', '']","['Addressing we have to additional and more problematic issues related to:', '', '', '', 'the only by and the aforementioned', 'Multilingual lexical databases aligned with the English WordNet ( e.g. MultiWordNet #TAUTHOR_TAG ) have been created for several languages , with different degrees of coverage .', 'As an example, the 57,424 synsets of the Spanish section of MultiWordNet aligned to English cover just around 50% of the WordNets synsets, thus making the coverage issue even more problematic than for TE.', 'links between languages', '', '']","['Address we have to additional and more problematic issues related to', '', '', '', 'the only exceptions by and the aforementioned resources', 'Multilingual lexical databases aligned with the English WordNet ( e.g. MultiWordNet #TAUTHOR_TAG ) have been created for several languages , with different degrees of coverage .', 'As an example, the 57,424 synsets of the Spanish section of MultiWordNet aligned to English cover just around 50% of the WordNets synsets, thus making the coverage issue even more problematic than for TE.', 'between different languagesx', '', '']","['', '', '', '', '', 'Multilingual lexical databases aligned with the English WordNet ( e.g. MultiWordNet #TAUTHOR_TAG ) have been created for several languages , with different degrees of coverage .', 'As an example, the 57,424 synsets of the Spanish section of MultiWordNet aligned to English cover just around 50% of the WordNets synsets, thus making the coverage issue even more problematic than for TE.', '', '', '']",0
"['Paraphrase tables (HT contain pairs of corresponding the same language, possibly associated with probabilities', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #TAUTHOR_TAG .', '', '', '']","['Paraphrase tables contain pairs of corresponding the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #TAUTHOR_TAG .', '', '', '']","['Paraphrase tables (HT contain pairs of corresponding phrases the same language, possibly associated with probabilities', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #TAUTHOR_TAG .', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #AUTHOR_TAG , and TE #TAUTHOR_TAG .', '', '', '']",4
"['', '', 'One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus #TAUTHOR_TAG .', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', '']","['', '', 'One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus #TAUTHOR_TAG .', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', '']","['', '', 'One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus #TAUTHOR_TAG .', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', '']","['', '', 'One of the proposed methods to extract paraphrases relies on a pivot-based approach using phrase alignments in a bilingual parallel corpus #TAUTHOR_TAG .', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', '']",0
"['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #TAUTHOR_TAG .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, are frequently used as a source of precise entailment rules between predicates.', 'FrameNet', '', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #TAUTHOR_TAG .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, are frequently used as a source of precise entailment rules between predicates.', 'FrameNet', '', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #TAUTHOR_TAG .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, are frequently used as a source of precise entailment rules between predicates.', 'FrameNet', '', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and Wikipedia #TAUTHOR_TAG .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', '', '', '']",0
"['Cross-lingual Textual Entailment ( CLTE ) has been proposed by #AUTHOR_TAG as an extension of Textual Entailment #TAUTHOR_TAG that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level', 'the of cur-ingual onical resources (. Word, Verb, Frame and processing and']","['Cross-lingual Textual Entailment ( CLTE ) has been proposed by #AUTHOR_TAG as an extension of Textual Entailment #TAUTHOR_TAG that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', 'the of cur- monolingual on resources WordNet, VerbOcean, and processing and']","['Cross-lingual Textual Entailment ( CLTE ) has been proposed by #AUTHOR_TAG as an extension of Textual Entailment #TAUTHOR_TAG that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', 'of cur- renting onical resources (. Word, VerbOcean, FrameNet) and and']","['Cross-lingual Textual Entailment ( CLTE ) has been proposed by #AUTHOR_TAG as an extension of Textual Entailment #TAUTHOR_TAG that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .', 'The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level.', '']",0
"['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #TAUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a ofically learned inference rules, is ax', 'VerbOcean is a graph of fine-grained semantic relations between verbs, are frequently used as a source of precise entailment rules between predicates.', 'FrameNet is a knowledge-base of frames describing prototypical situations and the role of the participants they involve', 'It used', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #TAUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a of statistically learned inference rules, is a', 'VerbOcean is a graph of fine-grained semantic relations between verbs, are frequently used as a source of precise entailment rules between predicates.', 'FrameNet is a knowledge-base of frames describing prototypical situations, and the role of the participants they involve.', 'It used', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #TAUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', 'DIRT is a collection ofically learned inference rules, is often a sourcex', 'VerbOcean is a graph of fine-grained semantic relations between verbs, are frequently used as a source of precise entailment rules between predicates.', 'FrameNet is a knowledge-base of frames describing prototypical situations, and the role of the participants they involve.', 'It can be used', '']","['Besides WordNet, the RTE literature documents the use of a variety of lexical information sources #AUTHOR_TAG .', 'These include, just to mention the most popular ones , DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #TAUTHOR_TAG , and Wikipedia #AUTHOR_TAG .', '', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet is a knowledge-base of frames describing prototypical situations, and the role of the participants they involve.', '', '']",0
"['', '', '', 'all the phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases', 'After the extraction , pruning techniques #TAUTHOR_TAG can be applied to increase the precision of the extracted paraphrases .']","['', '', '', 'all the phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', 'After the extraction , pruning techniques #TAUTHOR_TAG can be applied to increase the precision of the extracted paraphrases .']","['', '', '', 'all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases', 'After the extraction , pruning techniques #TAUTHOR_TAG can be applied to increase the precision of the extracted paraphrases .']","['', '', '', 'With this method, all the different phrases in one language that are aligned with the same phrase in the other language are extracted as paraphrases.', 'After the extraction , pruning techniques #TAUTHOR_TAG can be applied to increase the precision of the extracted paraphrases .']",0
"['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #TAUTHOR_TAG , and TE #AUTHOR_TAG', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #TAUTHOR_TAG , and TE #AUTHOR_TAG', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #TAUTHOR_TAG , and TE #AUTHOR_TAG .', '', '', '']","['Paraphrase tables (PPHT) contain pairs of corresponding phrases in the same language, possibly associated with probabilities.', 'They proved to be useful in a number of NLP applications such as natural language generation #AUTHOR_TAG , multidocument summarization ( Mc #AUTHOR_TAG , automatic evaluation of MT #TAUTHOR_TAG , and TE #AUTHOR_TAG .', '', '', '']",4
"['consensus on usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, they always component in complex architectures them ways', 'emerges ablation tests reported in , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works #TAUTHOR_TAG indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words .']","['consensus on usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, they always component in complex architectures them ways.', 'emerges ablation tests reported in , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works #TAUTHOR_TAG indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words .']","['the consensus on the usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, they always one component in complex architectures them', 'emerges the ablation tests reported in , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works #TAUTHOR_TAG indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words .']","['Despite the consensus on the usefulness of lexical knowledge for textual inference, determining the actual impact of these resources is not straightforward, as they always represent one component in complex architectures that may use them in different ways.', 'As emerges from the ablation tests reported in #AUTHOR_TAG , even the most common resources proved to have a positive impact on some systems and a negative impact on others.', 'Some previous works #TAUTHOR_TAG indicate , as main limitations of the mentioned resources , their limited coverage , their low precision , and the fact that they are mostly suitable to capture relations mainly between single words .']",0
"[""For the sake of completeness , we report in this section also the results obtained adopting the `` basic solution '' proposed by #TAUTHOR_TAG ."", 'Although it was presented as an approach to CLTE, the proposed method brings the problem back to the monolingual case by translating H into the language of.']","[""For the sake of completeness , we report in this section also the results obtained adopting the `` basic solution '' proposed by #TAUTHOR_TAG ."", 'Although it was presented as an approach to CLTE, the proposed method brings the problem back to the monolingual case by translating H into the language of T.']","[""For the sake of completeness , we report in this section also the results obtained adopting the `` basic solution '' proposed by #TAUTHOR_TAG ."", 'Although it was presented as an approach to CLTE, the proposed method brings the problem back to the monolingual case by translating H into the language of.']","[""For the sake of completeness , we report in this section also the results obtained adopting the `` basic solution '' proposed by #TAUTHOR_TAG ."", '']",1
"['Our future work address the lex information from bilingual corpora, its for TE CLTE.', 'On one side, we plan to explore alternative ways to build phrase and paraphrase tables.', 'One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by #TAUTHOR_TAG .', 'interesting direction is to investigate the potential of paraphrase (i.e.', 'patterns includingech slots),', '', '', '']","['Our future work address the lexical information from bilingual corpora, its for TE CLTE.', 'On one side, we plan to explore alternative ways to build phrase and paraphrase tables.', 'One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by #TAUTHOR_TAG .', 'interesting direction is to investigate the potential of paraphrase (i.e.', 'patterns including slots),', '', '', '']","['Our future work will address lexical information from bilingual parallel corpora, its for TE CLTE.', 'On one side, we plan to explore alternative ways to build phrase and paraphrase tables.', 'One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by #TAUTHOR_TAG .', 'Another interesting direction is to investigate the potential of paraphrase patterns (i.e.', 'patterns includingech slots),', '', '', '']","['Our future work will address both the extraction of lexical information from bilingual parallel corpora, and its use for TE and CLTE.', 'On one side, we plan to explore alternative ways to build phrase and paraphrase tables.', 'One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by #TAUTHOR_TAG .', 'Another interesting direction is to investigate the potential of paraphrase patterns (i.e.', '', '', '', '']",3
"['Wikipedia (WIKI).', 'We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool #TAUTHOR_TAG to measure the relatedness between words in the dataset .', 'filtered all the pairs similar', '']","['Wikipedia (WIKI).', 'We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool #TAUTHOR_TAG to measure the relatedness between words in the dataset .', 'filtered all the pairs similarity', '']","['Wikipedia (WIKI).', 'We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool #TAUTHOR_TAG to measure the relatedness between words in the dataset .', 'we filtered all the pairs similar', '']","['Wikipedia (WIKI).', 'We performed Latent Semantic Analysis ( LSA ) over Wikipedia using the jLSI tool #TAUTHOR_TAG to measure the relatedness between words in the dataset .', '', '']",5
"['The comparison with the results achieved on monolingual data obtained by automatically translating the Spanish hypotheses (RTE3-G row in Table2) leads to four main observations.', 'we notice that dealing with MT-ived01 leading to highest accuracy of63.50', 'This suggests that the noise introduced by incorrect translations can be tackledhr.', 'Second , in line with the findings of #TAUTHOR_TAG , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .', '63.50%).', 'Third, the accuracy obtained over the CLTE corpus using combined phrase and paraphrase tables (62.88%, as reported in Table 1) is comparable to the best result gained over the automatically translated dataset (63.50%).', '', '', '']","['The comparison with the results achieved on monolingual data obtained by automatically translating the Spanish hypotheses (RTE3-G row in Table 2) leads to four main observations.', 'we notice that dealing with MT-derived leading to highest accuracy of 63.50%.', 'This suggests that the noise introduced by incorrect translations can be tackled table.', 'Second , in line with the findings of #TAUTHOR_TAG , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .', '63.50%).', 'Third, the accuracy obtained over the CLTE corpus using combined phrase and paraphrase tables (62.88%, as reported in Table 1) is comparable to the best result gained over the automatically translated dataset (63.50%).', '', '', '']","['The comparison with the results achieved on monolingual data obtained by automatically translating the Spanish hypotheses (RTE3-G row in Table 2) leads to four main observations.', 'we notice that dealing with MT-ived01 leading to the highest accuracy of63.50', 'This suggests that the noise introduced by incorrect translations can be tackled', 'Second , in line with the findings of #TAUTHOR_TAG , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .', '63.50%).', 'Third, the accuracy obtained over the CLTE corpus using combined phrase and paraphrase tables (62.88%, as reported in Table 1) is comparable to the best result gained over the automatically translated dataset (63.50%).', '', '', '']","['The comparison with the results achieved on monolingual data obtained by automatically translating the Spanish hypotheses (RTE3-G row in Table 2) leads to four main observations.', '', 'This suggests that the noise introduced by incorrect translations can be tackled by increasing the coverage of the paraphrase table.', 'Second , in line with the findings of #TAUTHOR_TAG , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .', '63.50%).', 'Third, the accuracy obtained over the CLTE corpus using combined phrase and paraphrase tables (62.88%, as reported in Table 1) is comparable to the best result gained over the automatically translated dataset (63.50%).', '', '', '']",1
"['', '', '', '', '', '', 'sequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'Subsequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'sequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit #TAUTHOR_TAG .', '', '', '', '']","['', '', '', '', '', '', 'Subsequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit #TAUTHOR_TAG .', '', '', '', '']",5
"['Besides WordNet , the RTE literature documents the use of a variety of lexical information sources #TAUTHOR_TAG .', 'These include, just to mention the most popular ones, DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and #AUTHOR_TAG .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet a frames describing pro', '', '']","['Besides WordNet , the RTE literature documents the use of a variety of lexical information sources #TAUTHOR_TAG .', 'These include, just to mention the most popular ones, DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and #AUTHOR_TAG .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet a frames describing', '', '']","['Besides WordNet , the RTE literature documents the use of a variety of lexical information sources #TAUTHOR_TAG .', 'These include, just to mention the most popular ones, DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and #AUTHOR_TAG .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', 'FrameNet frames describing pro', '', '']","['Besides WordNet , the RTE literature documents the use of a variety of lexical information sources #TAUTHOR_TAG .', 'These include, just to mention the most popular ones, DIRT #AUTHOR_TAG , VerbOcean #AUTHOR_TAG , FrameNet #AUTHOR_TAG , and #AUTHOR_TAG .', 'DIRT is a collection of statistically learned inference rules, that is often integrated as a source of lexical paraphrases and entailment rules.', 'VerbOcean is a graph of fine-grained semantic relations between verbs, which are frequently used as a source of precise entailment rules between predicates.', '', '', '']",0
"['Such questions are typically answered by designing appropriate priming experiments #TAUTHOR_TAG or other lexical decision tasks .', 'The reaction time of the subjects for recognizing various lexical items under appropriate conditions reveals important facts about their organization in the brain.', '(See Sec. 2 for models of morphological organization and access and related experiments).']","['Such questions are typically answered by designing appropriate priming experiments #TAUTHOR_TAG or other lexical decision tasks .', 'The reaction time of the subjects for recognizing various lexical items under appropriate conditions reveals important facts about their organization in the brain.', '(See Sec. 2 for models of morphological organization and access and related experiments).']","['Such questions are typically answered by designing appropriate priming experiments #TAUTHOR_TAG or other lexical decision tasks .', 'The reaction time of the subjects for recognizing various lexical items under appropriate conditions reveals important facts about their organization in the brain.', '(See Sec. 2 for models of morphological organization and access and related experiments).']","['Such questions are typically answered by designing appropriate priming experiments #TAUTHOR_TAG or other lexical decision tasks .', 'The reaction time of the subjects for recognizing various lexical items under appropriate conditions reveals important facts about their organization in the brain.', '(See Sec. 2 for models of morphological organization and access and related experiments).']",0
"['', '', 'up', '', '', 'units', '', '', '', '', '', '', '', 'We measure the inter annotator agreement using the Fleiss Kappa #TAUTHOR_TAG measure ( x ) where the agreement lies around 0.79 .', 'Next common verb sequences were annotated by all the three linguists, we randomly choose 300 V1+V2 pairs and presented them to 36 nativela speakers.', 'We ask each subjects to give a composition']","['', '', 'up)', '', '', 'units', '', '', '', '', '', '', '', 'We measure the inter annotator agreement using the Fleiss Kappa #TAUTHOR_TAG measure ( x ) where the agreement lies around 0.79 .', 'Next, common verb sequences were annotated by all the three linguists, we randomly choose 300 V1+V2 pairs and presented them to 36 native Bangla speakers.', 'We ask each subjects to give a composition']","['', '', 'up', '', '', '', '', '', '', '', '', '', '', 'We measure the inter annotator agreement using the Fleiss Kappa #TAUTHOR_TAG measure ( x ) where the agreement lies around 0.79 .', 'Next the common verb sequences were annotated by all the three linguists, we randomly choose 300 V1+V2 pairs and presented them to 36 native Bangla speakers.', 'We ask each subjects to give a composition']","['', '', '', '', '', '', '', '', '', '', '', '', '', 'We measure the inter annotator agreement using the Fleiss Kappa #TAUTHOR_TAG measure ( x ) where the agreement lies around 0.79 .', 'Next, out of the common verb sequences that were annotated by all the three linguists, we randomly choose 300 V1+V2 pairs and presented them to 36 native Bangla speakers.', 'We ask each subjects to give a composition']",5
"['A plethora of works has been done to linguistic explanations on the formation of such yet so far to any.', '', '', 'to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', 'Similar findings have been proposed by #TAUTHOR_TAG that points out V1 and V2 are paired on the basis of their semantic compatibility , which is subject to syntactic constraints .', '', '', '']","['A plethora of works has been done to linguistic explanations on the formation of such yet so far to any consensus.', '', '', 'to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', 'Similar findings have been proposed by #TAUTHOR_TAG that points out V1 and V2 are paired on the basis of their semantic compatibility , which is subject to syntactic constraints .', '', '', '']","['A plethora of works has been done to linguistic explanations on the formation of so far to any consensus.', '', '', 'to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', 'Similar findings have been proposed by #TAUTHOR_TAG that points out V1 and V2 are paired on the basis of their semantic compatibility , which is subject to syntactic constraints .', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '', '', ' #AUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', 'Similar findings have been proposed by #TAUTHOR_TAG that points out V1 and V2 are paired on the basis of their semantic compatibility , which is subject to syntactic constraints .', '', '', '']",0
"['difficult to classify verb sequencesely the classes', '', '', '', '', '', '', '', 'order to validate such claim we perform a lexical', 'decision experiment using native Bangla speakers with 92 different verb sequences. We followed the same experimental procedure as discussed in #TAUTHOR_TAG for English polymorphemic words .', '', '', '', '', '', '']","['difficult to classify verb sequences discretely the classes', '', '', '', '', '', '', '', 'order to validate such claim we perform a lexical', 'decision experiment using native Bangla speakers with 92 different verb sequences. We followed the same experimental procedure as discussed in #TAUTHOR_TAG for English polymorphemic words .', '', '', '', '', '', '']","['is difficult to classify Bangla verb sequences discretely into the classes', '', '', '', '', '', '', '', 'order to validate such claim we perform a lexical', 'decision experiment using native Bangla speakers with 92 different verb sequences. We followed the same experimental procedure as discussed in #TAUTHOR_TAG for English polymorphemic words .', '', '', '', '', '', '']","['', '', '', '', '', '', '', '', 'to a single expression of meaning. In order to validate such claim we perform a lexical', 'decision experiment using native Bangla speakers with 92 different verb sequences. We followed the same experimental procedure as discussed in #TAUTHOR_TAG for English polymorphemic words . However, rather than derived', '', '', '', '', '', '']",5
"['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '', 'either', ' #TAUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '', 'either', ' #TAUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '', 'either', ' #TAUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '', '', ' #TAUTHOR_TAG tried to construct a semantic analysis based on ""prepared"" and ""unprepared mind"".', '', '', '', '']",0
"['It has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', ' #AUTHOR_TAG with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by #AUTHOR_TAG Taft 1975 ; #TAUTHOR_TAG where it has been claimed that words having low surface frequency tends to decompose .', '', '']","['It has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', ' #AUTHOR_TAG with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by #AUTHOR_TAG Taft 1975 ; #TAUTHOR_TAG where it has been claimed that words having low surface frequency tends to decompose .', '', '']","['It has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', ' #AUTHOR_TAG with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by #AUTHOR_TAG Taft 1975 ; #TAUTHOR_TAG where it has been claimed that words having low surface frequency tends to decompose .', '', '']","['It has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', ' #AUTHOR_TAG with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by #AUTHOR_TAG Taft 1975 ; #TAUTHOR_TAG where it has been claimed that words having low surface frequency tends to decompose .', '', '']",0
"['the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', 'Most of the studies are designed to support one of the two mutually exclusive paradigms: the full-listing and the morphemic model.', 'The full-listing model claims that polymorphic words are represented as a whole in the human mental lexicon #TAUTHOR_TAG .', 'phemic modelues that morphologically complex words are decomposed and represented in terms of the morphemic units.', 'le', '', '']","['the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', 'Most of the studies are designed to support one of the two mutually exclusive paradigms: the full-listing and the morphemic model.', 'The full-listing model claims that polymorphic words are represented as a whole in the human mental lexicon #TAUTHOR_TAG .', 'morphemic model argues that morphologically complex words are decomposed and represented in terms of the morphemic units.', '', '', '']","['the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', 'Most of the studies are designed to support one of the two mutually exclusive paradigms: the full-listing and the morphemic model.', 'The full-listing model claims that polymorphic words are represented as a whole in the human mental lexicon #TAUTHOR_TAG .', 'ues that morphologically complex words are decomposed and represented in terms of the smaller morphemic units.', '', '', '']","['Over the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', 'Most of the studies are designed to support one of the two mutually exclusive paradigms: the full-listing and the morphemic model.', 'The full-listing model claims that polymorphic words are represented as a whole in the human mental lexicon #TAUTHOR_TAG .', 'On the other hand, morphemic model argues that morphologically complex words are decomposed and represented in terms of the smaller morphemic units.', '', '', '']",0
"['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages #TAUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cous.', 'Indianomena, and composite verbs for which', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages #TAUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', 'Indian phenomena like, and composite verbs for which', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages #TAUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', 'Indian, and composite verbs for which', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages #TAUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '', '', '']",0
"['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', 'aspect aux.', ' #TAUTHOR_TAG argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .', '', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', 'aspectual auxiliaries.', ' #TAUTHOR_TAG argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .', '', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '', ' #TAUTHOR_TAG argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .', '', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', '', ' #TAUTHOR_TAG argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .', '', '', '', '', '']",0
"['With respect to this , we apply the different priming and other lexical decision experiments , described in literature #TAUTHOR_TAG ; Bentin , S. and #AUTHOR_TAG specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .', '', '', '', '']","['With respect to this , we apply the different priming and other lexical decision experiments , described in literature #TAUTHOR_TAG ; Bentin , S. and #AUTHOR_TAG specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .', '', '', '', '']","['With respect to this , we apply the different priming and other lexical decision experiments , described in literature #TAUTHOR_TAG ; Bentin , S. and #AUTHOR_TAG specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .', '', '', '', '']","['With respect to this , we apply the different priming and other lexical decision experiments , described in literature #TAUTHOR_TAG ; Bentin , S. and #AUTHOR_TAG specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .', '', '', '', '']",5
"['We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in #TAUTHOR_TAG for Bangla morphologically complex words .', ', the prime is morphologically derived form of the target presented auditorily ( cross modaling) or visually (for maskeding).', 'The', 'probed the', 'the', '']","['We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in #TAUTHOR_TAG for Bangla morphologically complex words .', 'Here, the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for masked priming).', 'The', 'probed the', 'the', '']","['We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in #TAUTHOR_TAG for Bangla morphologically complex words .', ', the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for maskeding).', 'The subjects', 'probed', '', '']","['We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in #TAUTHOR_TAG for Bangla morphologically complex words .', 'Here, the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for masked priming).', '', '', '', '']",5
"['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages #TAUTHOR_TAG ; Grainger , et al. , 1991 ; #AUTHOR_TAG .', 'we do not know of any such investigations for Indian, morphologically rich than of', ', and ver for', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages #TAUTHOR_TAG ; Grainger , et al. , 1991 ; #AUTHOR_TAG .', 'we do not know of any such investigations for Indian languages, morphologically richer than of', 'like, and verbs for', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages #TAUTHOR_TAG ; Grainger , et al. , 1991 ; #AUTHOR_TAG .', 'we do not know of any such investigations for Indian languages, are morphologically rich than of', ', and for', '', '']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages #TAUTHOR_TAG ; Grainger , et al. , 1991 ; #AUTHOR_TAG .', 'However, we do not know of any such investigations for Indian languages, which are morphologically richer than many of their Indo-European cousins.', '', '', '']",0
"['We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in #TAUTHOR_TAG for Bangla morphologically complex words .', ', the prime is morphologically derived form of the target presented auditorily ( cross modaling) or visually (for maskeding).', 'The', 'probed the', 'the', '']","['We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in #TAUTHOR_TAG for Bangla morphologically complex words .', 'Here, the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for masked priming).', 'The', 'probed the', 'the', '']","['We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in #TAUTHOR_TAG for Bangla morphologically complex words .', ', the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for maskeding).', 'The subjects', 'probed', '', '']","['We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in #TAUTHOR_TAG for Bangla morphologically complex words .', 'Here, the prime is morphologically derived form of the target presented auditorily (for cross modal priming) or visually (for masked priming).', '', '', '', '']",5
"['the the processing the mentalx will further our knowledge of how the human', 'interestingational lingu and natural language processing (', 'Their computational significance arises from the issue of their storage in lexical resources like WordNet #TAUTHOR_TAG and raises the questions like , how to store morphologically complex words , in a lexical resource like WordNet keeping in mind the storage and access efficiency .']","['the the processing the mental will further our knowledge of how the human', 'interesting computational linguistics and natural language processing', 'Their computational significance arises from the issue of their storage in lexical resources like WordNet #TAUTHOR_TAG and raises the questions like , how to store morphologically complex words , in a lexical resource like WordNet keeping in mind the storage and access efficiency .']","['the structure the processing mechanism the mental lexicon will further our knowledge of how the human brain processes', 'interesting questionsational linguistics and natural language processing (', 'Their computational significance arises from the issue of their storage in lexical resources like WordNet #TAUTHOR_TAG and raises the questions like , how to store morphologically complex words , in a lexical resource like WordNet keeping in mind the storage and access efficiency .']","['A clear understanding of the structure and the processing mechanism of the mental lexicon will further our knowledge of how the human brain processes language.', '', 'Their computational significance arises from the issue of their storage in lexical resources like WordNet #TAUTHOR_TAG and raises the questions like , how to store morphologically complex words , in a lexical resource like WordNet keeping in mind the storage and access efficiency .']",0
"['onxical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English, He,, French,, and few other (M', '', 'Indian some distinct phenomena like, and composite verbs for which no such investig been', 'On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent #TAUTHOR_TAG .', 'Therefore, the findings from experiments in one language cannot be generalized to all languages making it important to conduct similar experimentations in other languages.']","['on lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English, Hebrew, Italian, French, Dutch, and few other', '', 'Indian some distinct phenomena like, and composite verbs for which no such investigations been', 'On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent #TAUTHOR_TAG .', 'Therefore, the findings from experiments in one language cannot be generalized to all languages making it important to conduct similar experimentations in other languages.']","['onxical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English, Hebrew, Italian, French, Dutch, and few other languages (M', '', 'Indian some distinct phenomena like, and composite verbs for which no such investigations', 'On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent #TAUTHOR_TAG .', 'Therefore, the findings from experiments in one language cannot be generalized to all languages making it important to conduct similar experimentations in other languages.']","['There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English, Hebrew, Italian, French, Dutch, and few other languages (Marslen- #AUTHOR_TAG .', '', 'Moreover, Indian languages show some distinct phenomena like, compound and composite verbs for which no such investigations have been conducted yet.', 'On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent #TAUTHOR_TAG .', 'Therefore, the findings from experiments in one language cannot be generalized to all languages making it important to conduct similar experimentations in other languages.']",0
"['have attempted to understand the representation and processing of morphologically complex words in the brain for languages', '', '', '', '', 'Inter to these two paradigms is the partial decomposition model that argues that different types of morphological forms are processed separately.', 'For instance , the derived morphological forms are believed to be represented as a whole , whereas the representation of the inflected forms follows the morphemic model #TAUTHOR_TAG .']","['have attempted to understand the representation and processing of morphologically complex words in the brain for languages.', '', '', '', '', 'Intermediate to these two paradigms is the partial decomposition model that argues that different types of morphological forms are processed separately.', 'For instance , the derived morphological forms are believed to be represented as a whole , whereas the representation of the inflected forms follows the morphemic model #TAUTHOR_TAG .']","['have attempted to understand the representation and processing of morphologically complex words in the brain for', '', '', '', '', 'Inter to these two paradigms is the partial decomposition model that argues that different types of morphological forms are processed separately.', 'For instance , the derived morphological forms are believed to be represented as a whole , whereas the representation of the inflected forms follows the morphemic model #TAUTHOR_TAG .']","['Over the last few decades many studies have attempted to understand the representation and processing of morphologically complex words in the brain for various languages.', '', '', '', '', 'Intermediate to these two paradigms is the partial decomposition model that argues that different types of morphological forms are processed separately.', 'For instance , the derived morphological forms are believed to be represented as a whole , whereas the representation of the inflected forms follows the morphemic model #TAUTHOR_TAG .']",0
"['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', ' #TAUTHOR_TAG considers the second verb V2 as an aspectual complex comparable to the auxiliaries .', '', '', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', ' #TAUTHOR_TAG considers the second verb V2 as an aspectual complex comparable to the auxiliaries .', '', '', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', ' #TAUTHOR_TAG considers the second verb V2 as an aspectual complex comparable to the auxiliaries .', '', '', '', '', '', '']","['A plethora of works has been done to provide linguistic explanations on the formation of such word, yet none so far has led to any consensus.', ' #TAUTHOR_TAG considers the second verb V2 as an aspectual complex comparable to the auxiliaries .', '', '', '', '', '', '']",0
"['It has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', ' #AUTHOR_TAG with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by #TAUTHOR_TAG Taft 1975 ; #AUTHOR_TAG where it has been claimed that words having low surface frequency tends to decompose .', 'processing', '']","['It has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', ' #AUTHOR_TAG with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by #TAUTHOR_TAG Taft 1975 ; #AUTHOR_TAG where it has been claimed that words having low surface frequency tends to decompose .', 'processing', '']","['It has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', ' #AUTHOR_TAG with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by #TAUTHOR_TAG Taft 1975 ; #AUTHOR_TAG where it has been claimed that words having low surface frequency tends to decompose .', '', '']","['It has been argued that frequency of a word influences the speed of lexical processing and thus, can serve as a diagnostic tool to observe the nature and organization of lexical representations.', ' #AUTHOR_TAG with his experiment on English inflected words, argued that lexical decision responses of polymorphemic words depends upon the base word frequency.', 'Similar observation for surface word frequency was also observed by #TAUTHOR_TAG Taft 1975 ; #AUTHOR_TAG where it has been claimed that words having low surface frequency tends to decompose .', '', '']",0

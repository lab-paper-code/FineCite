CC,label
"['Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages.', 'A number of alignment techniques have been proposed , varying from statistical methods ( Brown et al. , 1991 ; #AUTHOR_TAG ) to lexical methods ( Kay and Roscheisen , 1993 ; Chen , 1993 ) .', 'Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods.', 'Cognates are identical sequences of characters in corresponding words in two languages.']",0
"['However, a major obstacle to this approach is the lack of parallel corpora for model training.', 'Only a few such corpora exist , including the Hansard English-French corpus and the HKUST EnglishChinese corpus ( #AUTHOR_TAG ) .', 'In this paper, we will describe a method which automatically searches for parallel texts on the Web.', ""We will discuss the text mining algorithm we adopted, some issues in translation model training using the generated parallel corpus, and finally the translation model's performance in CLIR.""]",0
"['Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages.', 'A number of alignment techniques have been proposed , varying from statistical methods ( Brown et al. , 1991 ; Gale and Church , 1991 ) to lexical methods ( Kay and Roscheisen , 1993 ; #AUTHOR_TAG ) .', 'The method we adopted is that of Simard et al. (1992).', 'Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods.', 'Cognates are identical sequences of characters in corresponding words in two languages.']",0
"['Beside HTML markups, other criteria may also be incorporated.', 'For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in ( #AUTHOR_TAG ) .', 'We hope to implement such correspondences in our future research.']",3
"['Aligning English-Chinese parallel texts is already very difficult because of the great differences in the syntactic structures and writing systems of the two languages.', 'A number of alignment techniques have been proposed , varying from statistical methods ( #AUTHOR_TAG ; Gale and Church , 1991 ) to lexical methods ( Kay and Roscheisen , 1993 ; Chen , 1993 ) .', 'Because it considers both length similarity and cognateness as alignment criteria, the method is more robust and better able to deal with noise than pure length-based methods.', 'Cognates are identical sequences of characters in corresponding words in two languages.']",0
"[""Robust natural language understanding in Atlas-Andes is provided by RosÃ© 's CARMEL system ( RosÃ© 2000 ) ; it uses the spelling correction algorithm devised by #AUTHOR_TAG .""]",5
"[""2 See ( #AUTHOR_TAG ) for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .""]",0
"['The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; #AUTHOR_TAG ) ) .', 'To instantiate an attribute, MIMIC adopts the lnfoSeek dialogue act to solicit the missing information.', 'In contrast, when MIMIC has both initiatives, it plays a more active role by presenting the user with additional information comprising valid instantiations of the attribute (GiveOptions).']",1
"['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction ( Whittaker and Stenton , 1988 ; #AUTHOR_TAG ; Chu-Carroll and Brown , 1998 ) .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur-5An alternative strategy to step ( 4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work.']",0
"['Previous work has argued that initiative affects the degree of control an agent has in the dialogue interaction ( #AUTHOR_TAG ; Walker and Whittaker , 1990 ; Chu-Carroll and Brown , 1998 ) .', 'Thus, a cooperative system may adopt different strategies to achieve the same goal depending on the initiative distribution.', 'Since task initiative models contribution to domain/problemsolving goals, while dialogue initiative affects the cur-5An alternative strategy to step ( 4) is to perform a database lookup based on the ambiguous query and summarize the results (Litman et al., 1998), which we leave for future work.']",0
"['In this section we summarize these experiments and their results.', 'A companion paper describes the evaluation process and results in further detail ( #AUTHOR_TAG ) .']",2
"['5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results ( #AUTHOR_TAG ) , which we leave for future work .']",3
"['Furthermore , a number of performance features , largely based on the PARADISE dialogue evaluation scheme ( #AUTHOR_TAG ) , were automatically logged , derived , or manually annotated .']",5
['The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project ( #AUTHOR_TAG ) .'],1
"['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints (Ganssier, 1995;Kupiec, 1993;hua Chen and Chen, 94;Fung, 1995;Evans and Zhai, 1996).', 'It is also possible to focus on non-compositional compounds , a key point in bilingual applications ( #AUTHOR_TAG ; Melamed , 1997 ; Lin , 99 ) .', 'Another interesting approach is to restrict sequences to those that do not cross constituent boundary patterns (Wu, 1995;Furuse and Iida, 96).']",0
"['This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; #AUTHOR_TAG ; Russell , 1998 ) .']",0
"['One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints ( Gaussier , 1995 ; #AUTHOR_TAG ; hua Chen and Chen , 94 ; Fung , 1995 ; Evans and Zhai , 1996 ) .', 'It is also possible to focus on non-compositional compounds, a key point in bilingual applications (Su et al., 1994;Melamed, 1997;Lin, 99).']",5
"['The speech and language processing architecture is based on that of the SRI CommandTalk system ( #AUTHOR_TAG ; Stent et a. , 1999 ) .', 'The system comprises a suite of about 20 agents, connected together using the SPd Open Agent Architecture (OAA; (Martin et al., 1998)).']",5
"['More recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot (Konolige et al., 1993) and NCARArs InterBOT project (Perzanowski et al., 1998;Perzanowski et al., 1999).', 'A number of other systems have addressed part of the task.', 'CornmandTalk ( #AUTHOR_TAG ) , Circuit Fix-It Shop ( Smith , 1997 ) and TRAINS-96 ( Traum and Allen , 1994 ; Traum and Andersen , 1999 ) are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents .']",0
"['~ These forbidden pairs normally involve only one of several possible parts of speech, hence the need to disambiguate them.', 'We do this with a first-order HMM part-ofspeech tagger ( Merialdo #AUTHOR_TAG ) .']",5
"['After identification of word and sentence boundaries the text is processed into a bi-text by an alignment program.', 'This alignment is done on the basis of both length ( Gale and Church #AUTHOR_TAG ) and a notion of cognateness ( Simard [ 16 ] ) .']",5
"['â\x80¢ Before indexing the text , we process it with Textract ( Byrd and Ravin , 1998 ; #AUTHOR_TAG ) , which performs lemmatization , and discovers proper names and technical terms .', 'We added a new module (Resporator) which annotates text segments with QA-Tokens using pattern matching.', 'Thus the text ""for 5 centuries"" matches the DURATIONS pattern ""for :CARDINAL _timeperiod"", where :CAR-DINAL is the label for cardinal numbers, and _timeperiod marks a time expression.']",5
"['MorphAna: Morphological Analysis provided by sines yields the word stems of nouns, verbs and adjectives, as well as the full forms of unknown words.', 'We are using a lexicon of approx.', '100000 word stems of German ( #AUTHOR_TAG ) .']",5
"['Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing ( #AUTHOR_TAG ) .', 'The fundamental design criterion of sines is to provide a set of basic, powerful, robust, and efficient STP components and 4Almost all tools we examined build a single multicategorizer except for SVM-Light, which builds multiple binary classifiers.']",5
"['Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in #AUTHOR_TAG .']",5
"['Although a number of methods for query-dependent text summarization are beginning to be developed and evaluated in a variety of realistic settings ( #AUTHOR_TAG ) , we again propose the use of vector space methods from IR , which can be easily extended to the summarization task ( Salton et al. , 1994 ) :']",1
"['The aim of this paper is to give a detailed account of the techniques used in TnT.', 'The Penn Treebank results reported here for the Markov model approach are at least equivalent to those reported for the Maximum Entropy approach in ( #AUTHOR_TAG ) .']",1
"['According to current tagger comparisons ( van Halteren et al. , 1998 ; Zavrel and Daelemans , 1999 ) , and according to a comparsion of the results presented here with those in ( #AUTHOR_TAG ) , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .']",1
"['Our spread activation based semantic measure (R98( .....,)) improved a.ccura(:y.', ""This confirms that although Kozima 's approach ( #AUTHOR_TAG ) is computationally expensive , it does produce more precise segmentation .""]",1
"[""R98 ( , , , , â\x80\x9e ) uses a variant of Kozima 's semantic similarity measure ( #AUTHOR_TAG ) to compute block similarity ."", 'Word similarity is a function of word co- occurrence statistics in the given document.']",2
"['In related work, Miyao (1999) describes an ap- proach to packing in which alternative feature structures are represented as packed, distributed disjunctions of feature structure fragments.', 'Although the approach may have potential , the shifting of complex accounting into the unification algorithm is at variance with the findings of #AUTHOR_TAG , who report large speed-ups from the elimination of disjunction processing during unification .']",1
"['We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in ( #AUTHOR_TAG ) and ( Chelba and Jelinek , 1998 ) .']",3
"['We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in ( Ratnaparkhi , 1997 ) and ( #AUTHOR_TAG ) .']",3
"['Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by #AUTHOR_TAG .']",5
"['Although this is only true in cases where y occurs in an upward monotone context ( #AUTHOR_TAG ) , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare .', 'We used the Tipster Gazetteer 4 and WordNet to identify meronyms, both of which have high precision but low coverage.']",4
"['We do not use any other lexical φ-features that reference x, for fear that they would enable the learner to explain the rationales without changing θ as desired (see the end of section 5.3). 14', 'We parse each sentence with the Collins parser ( #AUTHOR_TAG ) .', 'Then the document has one big parse tree, whose root is DOC, with each sentence being a child of DOC.']",5
"['In Zaidan et al. (2007), we introduced the �Movie Review Polarity Dataset Enriched with Annotator Rationales.�8', 'It is based on the dataset of #AUTHOR_TAG ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .']",2
"['Thus, observing the rationales helps us infer the true θ.', 'We collect substring rationales for a sentiment classification task ( #AUTHOR_TAG ) and use them to obtain significant accuracy improvements for each annotator .']",5
"['where f (•) extracts a feature vector from a classified document, θ are the corresponding weights of those features, and Z θ (x) def = y u(x, y) is a normalizer.', 'We use the same set of binary features as in previous work on this dataset ( Pang et al. , 2002 ; #AUTHOR_TAG ; Zaidan et al. , 2007 ) .']",5
"['We first evaluate D S P on disambiguating positives from pseudo-negatives, comparing to recently-proposed systems that also require no manually- compiled resources like WordNet.', ""We gather similar words using #AUTHOR_TAGa ) , mining similar verbs from a comparable-sized parsed corpus , and collecting similar nouns from a broader 10 GB corpus of English text .4 We also use Keller and Lapata ( 2003 ) 's approach to obtaining web-counts .""]",5
"['We also made use of the person-name/instance pairs automatically extracted by #AUTHOR_TAG .2This data provides counts for pairs such as ""Edwin Moses , hurdler"" and ""William Farley , industrialist.']",5
"[""We study the cases where a 9Recall that even the #AUTHOR_TAG system , built on the world 's largest corpus , achieves only 34 % recall ( Table 1 ) ( with only 48 % of positives and 27 % of all pairs previously observed , but see Footnote 5 ) .""]",1
"['The DSP parameters for eat, for example, place high weight on features like Pr(n|braise), Pr(n|ration), and Pr(n|garnish).', ""#AUTHOR_TAGa ) 's similar word list for eat misses these but includes sleep ( ranked 6 ) and sit ( ranked 14 ) , because these have similar subjects to eat ."", 'Discriminative, context-specific training seems to yield a better set of similar predicates, e.g. the highest-ranked contexts for DSP cooc on the verb join, 3 lead 1.42, rejoin 1.39, form 1.34, belong to 1.31, found 1.31, quit 1.29, guide 1.19, induct 1.19, launch (subj) 1.18, work at 1.14 give a better SIMS(join) for Equation (1) than the top similarities returned by (Lin, 1998a Other features are also weighted intuitively.']",0
"['This collection was generated from approximately 1 trillion tokens of online text.', 'The similarity-smoothed examples will be undefined if SIMS(w) is empty.', 'Also , the #AUTHOR_TAG approach will be undefined if the pair is unobserved on the web .']",5
"['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models ( Erk , 2007 ; Keller and Lapata , 2003 ; #AUTHOR_TAG ) .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.']",1
"['The advantage of tuning similarity to the application of interest has been shown previously by #AUTHOR_TAG .', 'They optimize a few metaparameters separately for the tasks of thesaurus generation and pseudodisambiguation.']",1
"['Normalizing by Pr(v) (yielding MI) allows us to use a constant threshold across all verbs.', 'MI was also recently used for inference-rule SPs by #AUTHOR_TAG .']",0
"['Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models ( Erk , 2007 ; #AUTHOR_TAG ; Rooth et al. , 1999 ) .', 'This data consists of triples (v, n, n ′ ) where v, n is a predicateargument pair observed in the corpus and v, n ′ has not been observed.']",1
"['For example, we might have a class Mexican Food and learn that the entire class is suitable for eating.', 'Usually , the classes are from WordNet ( Miller et al. , 1990 ) , although they can also be inferred from clustering ( #AUTHOR_TAG ) .']",0
"['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times ( Erk , 2007 ; Keller and Lapata , 2003 ; #AUTHOR_TAG ) .']",1
"['Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules ( #AUTHOR_TAG ; Roberto et al. , 2007 ) .', 'Inferences such as ""[X wins Y] ⇒ [X plays Y]"" are only valid for certain argu-ments X and Y.', 'We follow Pantel et al. (2007) in using automatically-extracted semantic classes to help characterize plausible arguments.']",0
"[""Erk ( 2007 ) compared a number of techniques for creating similar-word sets and found that both the Jaccard coefficient and #AUTHOR_TAGa ) 's information-theoretic metric work best .""]",0
"['We parsed the 3 GB AQUAINT corpus ( Voorhees , 2002 ) using Minipar ( #AUTHOR_TAGb ) , and collected verb-object and verb-subject frequencies , building an empirical MI model from this data .']",5
"['Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times ( Erk , 2007 ; #AUTHOR_TAG ; Rooth et al. , 1999 ) .']",1
"['To create the positives, we automatically parse a large corpus, and then extract the predicate-argument pairs that have a statistical association in this data.', 'We measure this association using pointwise Mutual Information ( MI ) ( #AUTHOR_TAG ) .']",5
"['For example, a feature for a verb-object pair might be, ""the verb is eat and the object is lower-case.""', ""Thus rather than a single training procedure , we can actually partition the examples by predicate , and train a 1For a fixed verb , MI is proportional to #AUTHOR_TAG 's conditional probability scores for pseudodisambiguation of ( v , n , n â\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) .""]",4
"['HOLMES is given the following set of six domainindependent rules , which are similar to the upward monotone rules introduced by ( #AUTHOR_TAG ) .']",1
"['Textual Entailment systems are given two textual fragments, text T and hypothesis H, and attempt to decide if the meaning of H can be inferred from the meaning of T (Dagan et al., 2005).', ""While many approaches have addressed this problem , our work is most closely related to that of ( Raina et al. , 2005 ; #AUTHOR_TAG ; Tatu and Moldovan , 2006 ; Braz et al. , 2005 ) , which convert the inputs into logical forms and then attempt to ` prove ' H from T plus a set of axioms .""]",1
"['The studies presented by #AUTHOR_TAG and Johnson ( 2007 ) differed in the number of states that they used .', 'We ran all our estimators in both conditions here (thanks to Noah Smith for supplying us with his tag set).']",1
"['On small data sets all of the Bayesian estimators strongly outperform EM ( and , to a lesser extent , VB ) with respect to all of our evaluation measures , confirming the results reported in #AUTHOR_TAG .', 'This is perhaps not too surprising, as the Bayesian prior plays a comparatively stronger role with a smaller training corpus (which makes the likelihood term smaller) and the approximation used by Variational Bayes is likely to be less accurate on smaller data sets.']",1
"['The resulting training procedure is analogous to the one presented in ( Brown et al. , 1993 ) and ( #AUTHOR_TAG ) .']",1
"['Their kernel is also very time consuming and in their more general sparse setting it requires O ( mn3 ) time and O ( mn2 ) space , where m and n are the number of nodes of the two trees ( m > = n ) ( #AUTHOR_TAG ) .']",3
"['Firstly, we plan to explore our estimator on other language pairs in order to obtain more evidence on its behavior.', 'Secondly , as ( #AUTHOR_TAG ) show , marginalizing out the different segmentations during decoding leads to improved performance .', 'We plan to build our own decoder (based on ITG) where different ideas can be tested including tractable ways for achieving a marginalization effect.']",3
"['A good study comparing document categorization algorithms can be found in (Yang and Liu, 1999).', 'More recently , ( Sebastiani , 2002 ) has performed a good survey of document categorization ; recent works can also be found in ( Joachims , 2002 ) , ( #AUTHOR_TAG ) , and ( Lewis et al. , 2004 ) .']",0
"['The most similar efforts to ours, mainly (DeNero et al., 2006), conclude that segmentation variables in the generative translation model lead to overfitting while attaining higher likelihood of the training data than the heuristic estimator.', 'Based on this advise ( Moore and #AUTHOR_TAG ) exclude the latent segmentation variables and opt for a heuristic training procedure .']",1
['Latent variables we wish to consider are an increased number of word classes ; more flexible regions -- see #AUTHOR_TAG on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries .'],0
"['We would like to use features that look at wide context on the input side , which is inexpensive ( #AUTHOR_TAG ) .']",3
"['We have presented the Latent Words Language Model and showed how it learns, from unlabeled texts, latent words that capture the meaning of a certain word, depending on the context.', '#AUTHOR_TAG for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .']",0
"['In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , #AUTHOR_TAG ; Bellegarda , 2004 ; Gao et al. , 2006 ) , to ranking models for Web search applications .']",0
"['As already mentioned in the literature , see for example ( #AUTHOR_TAG ) , knowledge about implicit predicates could be potentially useful for a variety of NLP tasks such as language generation , information extraction , question answering or machine translation .']",0
"['Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set, rivaling discriminative reranking approaches (Charniak and Johnson, 2005) and products of latent variable grammars (Petrov, 2010), despite being a single generative PCFG.', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set ( #AUTHOR_TAG ) .']",1
"['Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches ( #AUTHOR_TAG ) and products of latent variable grammars ( Petrov , 2010 ) , despite being a single generative PCFG .']",1
"['Our most accurate single grammar achieves an F score of 91.6 on the WSJ test set , rivaling discriminative reranking approaches ( Charniak and Johnson , 2005 ) and products of latent variable grammars ( #AUTHOR_TAG ) , despite being a single generative PCFG .', 'Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set (Zhang et al., 2009).']",1
"[""Another possibly critical feature is the 'mention of names'."", ""In multi-party discussion people usually mention each other 's name for the purpose of disentanglement ( #AUTHOR_TAG ) ."", ""In our corpus we found 175 instances where a participant mentions other participant's name."", ""In addition to these, 'Subject of the email', 'topic-shift cue words' can also be beneficial for a model.""]",0
"['Finally, we introduced the idea of evaluating induction systems based on their ability to produce useful cluster prototypes.', 'We found that the oldest system ( #AUTHOR_TAG ) yielded the best prototypes , and that using these prototypes gave state-of-the-art performance on WSJ , as well as improvements on nearly all of the non-English corpora .', 'These promising results suggest a new direction for future research: improving POS induction by developing methods targeted towards extracting better prototypes, rather than focusing on improving clustering of the entire data set.']",0
"['Future Work: Functionality is one of the several properties a relation can possess.', 'Others include selectional preferences , transitivity ( #AUTHOR_TAG ) , mutual exclusion , symmetry , etc. .']",0
"['Sophisticated phrase table combination.', 'Finally , we experiment with a method for combining phrase tables proposed in ( #AUTHOR_TAG ; Nakov and Ng , 2012 ) .', 'The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one copy of the Indonesian-English bi-text.', 'The second table is built from the simple concatenation.', 'The two tables are then merged as follows: all phrase pairs from the first one are retained, and to them are added those phrase pairs from the second one that are not present in the first one.']",5
"['A third relevant line of research is on reusing bitexts between related languages without or with very little adaptation, which works well for very closely related languages.', 'For example , our previous work ( #AUTHOR_TAG ; Nakov and Ng , 2012 ) experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all bi-texts was English .', 'However, our previous work did not attempt language adaptation, except for very simple transliteration for Portuguese-Spanish that ignored context entirely; since it could not substitute one word for a completely different word, it did not help much for Malay-Indonesian, which use unified spelling.']",1
"['We found the same number using our previous approach ( #AUTHOR_TAG ) , which is roughly equivalent to our core module .']",2
"['We take some core ideas from our previous work on mining script information ( #AUTHOR_TAG ) .', 'In this earlier work, we focused on event structures and their possible realizations in natural language.', 'The corpus used in those experiments were short crowd-sourced descriptions of everyday tasks written in bullet point style.', 'We aligned them with a hand-crafted similarity measure that was specifically designed for this text type.']",2
['Our own work ( #AUTHOR_TAG ) extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .'],2
"['Provided with the candidate fragment elements , we previously ( #AUTHOR_TAG ) used a chunker3 to finalize the output fragments , in order to follow the linguistic definition of a ( para - ) phrase .']",2
"['Similar to ( #AUTHOR_TAGa ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each sentence ; and then an ILP summarization method to select the best summary sentences from the multiple compressed sentences .']",1
['Our approach to the problem is more compatible with the empirical evidence we presented in our prior work ( #AUTHOR_TAG ) where we analyzed the output of Chinese to English machine translation and found that there is no correlation between sentence length and MT quality .'],1
"['During the tectogrammatical parsing of Czech, the analytical tree structure is converted into the tectogrammatical one.', 'These automatic transformations are based on linguistic rules ( #AUTHOR_TAG ) .']",5
"['The analytical parsing of Czech runs in two steps: the statistical dependency parser, which creates the structure of a dependency tree, and a classifier assigning analytical functors.', 'We carried out two parallel experiments with two parsers available for Czech , parser I ( Hajie et al. , 1998 ) and parser II ( #AUTHOR_TAG ) .', 'In the second step, we used a module for automatic analytical functor assignment (2abokrtskyT et al., 2002).']",5
"['To make the dictionary more sensitive to a specific domain, which is in our case the domain of financial news, we created a probabilistic CzechEnglish dictionary by running GIZA + + training ( translation models 1-4 , see #AUTHOR_TAG ) on the training part of the English-Czech WSJ parallel corpus extended by the parallel corpus of entry/translation pairs from the manual dictionary.', 'As a result, the entry/translation pairs seen in the parallel corpus of WSJ become more probable.']",5
"['The generation process consisting mainly of word reordering and lexical insertions is explained in Section 6, an example illustrating the generation steps is presented in Sec-tion 7.', 'For the evaluation of the results we use the BLEU score ( #AUTHOR_TAG ) .', 'Section 8 compares translations generated from automatically built and manually annotated tectogrammatical representations.']",5
"['The generation process consisting mainly of word reordering and lexical insertions is explained in Section 6, an example illustrating the generation steps is presented in Sec-tion 7.', 'We also compare the results with the output generated by the statistical translation system GIZA + + / ISI ReWrite Decoder ( AlOnaizan et al. , 1999 ; #AUTHOR_TAG ; Germann et al. , 2001 ) , trained on the same parallel corpus .']",1
"[""We evaluated our translations with IBM 's BLEU evaluation metric ( #AUTHOR_TAG ) , using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ( Haji 6 et al. , 2002 ) ."", 'We used four reference retranslations of 490 sentences selected from the WSJ sections 22, 23, and 24, which were themselves used as the fifth reference.']",5
['We performed translation experiments with an implementation of the IBM-4 translation model ( #AUTHOR_TAG ) .'],5
"['The maximum entropy approach ( #AUTHOR_TAG ) presents a powerful framework for the combination of several knowledge sources .', 'This principle recommends to choose the distribution which preserves as much uncertainty as possible in terms of maximizing the entropy.']",5
"['In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example ( Germann et al. , 2001 ; #AUTHOR_TAG ; Tillmann and Ney , 2002 ; Vogel et al. , 2000 ; Wang and Waibel , 1997 ) .']",0
"['For an introduction to maximum entropy modeling and training procedures , the reader is referred to the corresponding literature , for instance ( #AUTHOR_TAG ) or ( Ratnaparkhi , 1997 ) .']",0
"['In the work presented here, we restrict ourselves to transforming only one language of the two: the source, which has the less inflected morphology.', 'For descriptions of SMT systems see for example ( #AUTHOR_TAG ; Och et al. , 1999 ; Tillmann and Ney , 2002 ; Vogel et al. , 2000 ; Wang and Waibel , 1997 ) .']",0
"['Due to using a global model like CRFs , our previous work in ( Zhao et al. , 2006 ; #AUTHOR_TAGc ) reported the best results over the evaluated corpora of Bakeoff-2 until now7 .', 'Though those results are slightly better than the results here, we still see that the results of character-level dependency parsing approach (Scheme E) are comparable to those state-of-the-art ones on each evaluated corpus.']",1
"['1 The representation in #AUTHOR_TAG is even more compact than ours for grammars that are not self-embedding .', 'However, in this paper we use our representation as an intermediate result in approximating an unrestricted context-free grammar, with the final objective of obtaining a single minimal deterministic automaton.', ""For this purpose, Mohri and Pereira's representation offers little advantage.""]",1
"['By restricting the height of the stack of a pushdown automaton, one obstructs recognition of a set of strings in the context-free language, and therefore a subset approximation results.', 'This idea was proposed by Krauwer and des Tombe ( 1981 ) , Langendoen and Langsam ( 1987 ) , and Pulman ( 1986 ) , and was rediscovered by Black ( 1989 ) and recently by #AUTHOR_TAG .']",0
"['We rephrase the method of #AUTHOR_TAG as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .', 'Then an additional mechanism is introduced that ensures for each rule A --~ X1 • .. Xm separately that the list of visits to the states qo,.. • • qm satisfies some reasonable criteria: a visit to qi, with 0 < i < m, should be followed by one to qi+l or q0.']",5
"['This method can be generalized , inspired by #AUTHOR_TAG , who derive N-gram probabilities from stochastic context-free grammars .', 'By ignoring the probabilities, each N = 1, 2, 3 .... gives rise to a superset approximation that can be described as follows: The set of strings derivable from a nonterminal A is approximated by the set of strings al ... an such that • for each substring v = ai+l ... ai+N (0 < i < n --N) we have A --+* wvy, for some w and y,']",0
['See #AUTHOR_TAG for a variant of this approximation that constructs finite transducers rather than finite automata .'],0
"['A very similar formulation , for another grammar transformation , is given in #AUTHOR_TAG .']",1
"['Conventionally, these rules are specified by an expert linguist, conversant with the sound and spelling systems of the language of concern.', 'Typical letter-to-sound rule sets are those described by Ainsworth ( 1973 ) , McIlroy ( 1973 ) , Elovitz et al. ( 1976 ) , Hurmicutt ( 1976 ) , and #AUTHOR_TAG .']",0
"['However, this possibility is not usually given much credence.', ""For instance , #AUTHOR_TAG recently wrote : `` To our knowledge , learning algorithms , although promising , have not ( yet ) reached the level of rule sets developed by humans '' ( p. 520 ) .""]",0
"['Pronunciation by analogy (PbA) is a data-driven technique for the automatic phonemization of text, originally proposed as a model of reading, e.g., by Glushko (1979) and Kay and Marcel (1981).', 'It was first proposed for TTS applications over a decade ago by Dedina andNusbaum (1986, 1991).', 'See also the work of #AUTHOR_TAG , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .']",0
"['Clearly, the above characterization is very wide ranging.', 'Consequently , fusion has been applied to a wide variety of pattern recognition and decision theoretic problems -- using a plethora of theories , techniques , and tools -- including some applications in computational linguistics ( e.g. , #AUTHOR_TAG ; van Halteren , Zavrel , and Daelemans 1998 ) and speech technology ( e.g. , Bowles and Damper 1989 ; Romary and Pierre11989 ) .']",0
"['Many researchers have proposed greedy algorithms for estimating nonprobabilistic word-to-word translation models, also known as translation lexicons (e.g., Catizone, Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa 1994; #AUTHOR_TAG 1995; Wu and Xia 1994).', 'Most of these algorithms can be summarized as follows:']",0
['Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by #AUTHOR_TAGb ) .'],0
"['Unlike the models proposed by #AUTHOR_TAGb ) , this model is symmetric , because both word bags are generated together from a joint probability distribution .', ""Brown and his colleagues' models, reviewed in Section 4.3, generate one half of the bitext given the other hall so they are represented by conditional probability distributions.""]",1
"['in bitext space is another kind of collocation.', ""If each word 's translation is treated as a sense tag ( #AUTHOR_TAG ) , then `` translational '' collocations have the unique property that the collocate and the word sense are one and the same !""]",5
"['In informal experiments described elsewhere ( #AUTHOR_TAG ) , I found that the G2 statistic suggested by Dunning ( 1993 ) slightly outperforms 02 .']",2
"['â\x80¢ cross-language information retrieval ( e.g. , McCarley 1999 ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , #AUTHOR_TAG ) , â\x80¢ certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) , â\x80¢ concordancing for bilingual lexicography ( e.g. , Catizone , Russell , and Warwick 1989 ; Gale and Church 1991 ) ,']",0
"[""In this situation , #AUTHOR_TAGb , 293 ) recommend `` evaluating the expectations using only a single , probable alignment . ''"", 'The single most probable assignment Ama~ is the maximum a posteriori (MAP) assignment:']",4
"['Just as easily , we can model link types that coincide with entries in an on-line bilingual dictionary separately from those that do not ( cfXXX #AUTHOR_TAG ) .', 'When the auxiliary parameters are conditioned on different link classes, their optimization is carried out separately for each class: B (links (u, v)[cooc(u, v), A +) scorec (u, vlZ = class(u, v)) = log B(links(u, v)[cooc(u, v), A z)"" (37) Section 6.1.1 describes the link classes used in the experiments below.']",5
"[""Until now , translation models have been evaluated either subjectively ( e.g. White and O'Connell 1993 ) or using relative metrics , such as perplexity with respect to other models ( #AUTHOR_TAGb ) .""]",1
"['In informal experiments described elsewhere ( Melamed 1995 ) , I found that the G2 statistic suggested by #AUTHOR_TAG slightly outperforms 02 .', 'Let the cells of the contingency table be named as follows:']",0
"['There are many plausible representations , such as pairs of trees from synchronous tree adjoining grammars ( Abeille et al. 1990 ; Shieber 1994 ; #AUTHOR_TAG ) , lexical conceptual structures ( Dorr 1992 ) and WordNet synsets ( Fellbaum 1998 ; Vossen 1998 ) .']",0
"['â\x80¢ cross-language information retrieval ( e.g. , #AUTHOR_TAG ) , â\x80¢ multilingual document filtering ( e.g. , Oard 1997 ) , â\x80¢ computer-assisted language learning ( e.g. , Nerbonne et al. 1997 ) , â\x80¢ certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) , â\x80¢ concordancing for bilingual lexicography ( e.g. , Catizone , Russell , and Warwick 1989 ; Gale and Church 1991 ) ,']",0
"[""Many other such cases are described in Danlos 's book ( #AUTHOR_TAG ) ."", 'The common theme behind many of these examples is that pipelines have difficulties satisfying linguistic constraints (such as unambiguous reference) or performing linguistic optimizations (such as using pronouns instead of longer referring expressions whenever possible) in cases where the constraints or optimizations depend on decisions made in multiple modules.']",0
"['Despite these arguments, most applied NLG systems use a pipelined architecture; indeed, a pipeline was used in every one of the systems surveyed by Reiter (1994) and Paiva (1998).', 'This may be because pipelines have many engineering advantages , and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems ( #AUTHOR_TAG ) .']",0
"['Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by #AUTHOR_TAG and Paiva ( 1998 ) .', 'This may be because pipelines have many engineering advantages, and in practice the sort of problems pointed out by Danlos and other pipeline critics do not seem to be a major problem in current applied NLG systems (Mittal et al. 1998).']",0
"['The lexicon is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model ( #AUTHOR_TAG ) .', 'Although the idea of a two-level representation accommodating language-neutral and language-specific requirements is not new (see for example Nirenburg and Levin [1992], Dorr and Voss [1993], and Di Eugenio [1998]), Stede is among the few who make effective use of those two levels in a complex system.']",0
"[""Shortly after the publication of The Sound Pattern of English ( Chomsky and Halle 1968 ) , Kornai points out , `` Johnson ( 1970 ) demonstrated that the context-sensitive machinery of SPE ... [ could ] be replaced by a much simpler one , based on finite-state transducers ( FSTs ) ; the same conclusion was reached independently by Kaplan and Kay , whose work remained an underground classic until it was finally published in #AUTHOR_TAG . ''"", ""These works inspired Koskenniemi's two-level system, and the Xerox rule compiler (Dalrymple et al. 1987).""]",0
"['OT therefore holds out the promise of simplifying grammars , by factoring all complex phenomena into simple surface-level constraints that partially mask one another .1 Whether this is always possible under an appropriate definition of ""simple constraints"" ( e.g. , #AUTHOR_TAGb ) is of course an empirical question .']",0
"['Second, weights are an annoyance when writing grammars by hand.', 'In some cases rankings may work well enough.', '#AUTHOR_TAG report excellent part-of-speech tagging results using a handcrafted approach that is close to OT .3 More speculatively , imagine an OT grammar for stylistic revision of parsed sentences .']",0
"['For example, consider the relevance to hidden Markov models (HMMs), another restricted class of Gibbs distributions used in speech recognition or part-of-speech tagging.', ""Just like OT grammars, HMM Viterbi decoders are functions that pick the optimal output from ~', based on criteria of well-formedness (transition probabilities) and faithfulness to the input (emission probabilities)."", 'But typical OT grammars offer much richer finite-state models of left context ( #AUTHOR_TAGa ) than provided by the traditional HMM finite-state topologies .']",0
"['It is common practice in information retrieval to discard the lowest-frequency words a priori as nonsignificant (Rijsbergen 1979).', ""In Smadja's collocation algorithm Xtract, the lowest-frequency words are effectively discarded as well (Smadja 1993)."", '#AUTHOR_TAG use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .']",0
"[""For the higherfrequency words, Fisher's exact test leads to a slightly better recall with the same precision scores (0.31 for both tests)."", ""While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure ( #AUTHOR_TAG ) :""]",0
"['For example , #AUTHOR_TAG proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 5000000000000000005000000000000005000000000005000000005000 , are not context-free , which implies that Chinese is not a context-free language and thus might parse in exponential worst-case time .']",0
"['For example , some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes ( #AUTHOR_TAG ) .']",0
"['Using this classification method we can also derive the probability that a case belongs to a particular group (i.e., posterior probabilities), which is roughly proportional to the Mahalanobis distance from that group centroid.', 'Discriminant analysis has been employed by researchers in automatic text genre detection ( #AUTHOR_TAGb ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .']",0
"['The algorithm we implemented is inspired by the work of #AUTHOR_TAG on word sense disambiguation .', 'He classified the senses of a word on the basis of other words that the given word co-occurs with.']",4
"['The automatic annotation of nouns and verbs in the corpus has been done by matching them with the WordNet database files.', 'Before doing the annotation, though, some preprocessing of the data was required to maximize the matching between our corpus and WordNet.', 'The changes made were inspired by those described in #AUTHOR_TAG , page 75 ) .', 'To lemmatize the words we used �morpha,� a lemmatizer developed by John A. Carroll and freely available at the address: http://www.informatics.susx.ac.uk./research/nlp/carroll/morph.html.']",4
"['For the joint segmentation and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work ( #AUTHOR_TAGa ) , while being more than an order of magnitude faster .']",1
"['Previously ( #AUTHOR_TAG ) , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .', 'In each test, the discriminative model was retrained and reevaluated without a particular group of features.', 'We summarize the findings of this study in this section.']",2
"['In order to remove any confounding factors caused by specific documents, we first randomized the annotated predicate instances.', 'This evaluation set-up is an improvement versus the one we previously reported ( #AUTHOR_TAG ) , in which fixed partitions were used for training , development , and testing .']",2
"['CCGBank ( #AUTHOR_TAG ) is used to train the model .', 'For each training sentence, the corresponding CCGBank derivation together with all its sub-derivations are treated as gold-standard hypotheses.']",5
"['In our previous papers ( #AUTHOR_TAG ; Zhang , Blackwood , and Clark 2012 ) , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010 ) .']",1
"['PE-dev was used to obtain w * to define the utility model.', 'This was done by MERT optimization ( #AUTHOR_TAG ) towards post-edits under the TER target metric .']",5
"['Generalization for Online-to-Batch Conversion.', 'In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set ( Freund and Schapire , 1999 ; #AUTHOR_TAG ) .', 'The difference to the online learning scenario is that we treat the multi-epoch algorithm as an empirical risk minimizer that selects a final weight vector w T,K whose expected loss on unseen data we would like to bound.']",1
"['To prepare SMT outputs for post-editing , the creators of the corpus used their own WMT10 system ( Potet et al. , 2010 ) , based on the Moses phrase-based decoder ( #AUTHOR_TAG ) with dense features .', 'We replicated a similar Moses system using the same monolingual and parallel data: a 5-gram language model was estimated with the KenLM toolkit (Heafield, 2011) on news.en']",5
"['In contrast , a single statistical model allows one to maintain a single table ( #AUTHOR_TAG ) .']",0
['IGEN uses standard chart generation techniques ( #AUTHOR_TAG ) in its base generator to efficiently produce generation candidates .'],0
"[""Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen , unless we know in advance all of the properties that can be attributed to a given object , as in the case of Jordan 's work on the COCONUT domain ( #AUTHOR_TAG ) .""]",0
"['It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence ( in the sense of ( Grosz and Sidner , 1986 ) ) ( #AUTHOR_TAGa ) .']",0
"['Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in ( #AUTHOR_TAGb ) .']",0
"[""In addition to a referring function , noun phrases ( NP ) can also serve communicative goals such as providing new information about the referent and expressing the speaker 's emotional attitude towards the referent ( Appelt , 1985 ; #AUTHOR_TAG ) .""]",0
"['In what follows we explain the properties of the model by applying it to a small number of adjective-noun combinations taken from the lexical semantics literature.', 'Table 1 gives the interpretations of eight adjective-noun combinations discussed in #AUTHOR_TAG and Vendler ( 1968 ) .', 'Table 2 shows the five most likely interpretations for these combinations as derived by the model discussed in the previous sections (v is the most likely interpretation, v 2 is the second most likely interpretation, etc.).']",5
"['Much recent work in lexical semantics has been concerned with accounting for regular polysemy, i.e., the regular and predictable sense alternations certain classes of words are subject to.', 'Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see #AUTHOR_TAG and the references therein ) .']",0
"['We chose nine adjectives according to a set of minimal criteria and paired each adjective with 10 nouns randomly selected from the BNC.', 'We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature ( Vendler , 1968 ; #AUTHOR_TAG ) .', 'From these we randomly sampled nine adjectives (difficult, easy, fast, good, hard, right, safe, slow, wrong).', 'These adjectives had to be unambiguous with respect to their part-of-speech: each adjective was unambiguously tagged as ""adjective"" 98.6% of the time, measured as the number of different part-of-speech tags assigned to the word in the BNC.']",5
"['For example, an easy problem is ""a problem that is easy to solve"" or ""a problem that one can solve easily"".', 'An easy problem is usually a problem that is easy to solve, whereas a difficult language is a language that is difficult to learn, speak, or write.', 'Adjectives like good allow either verb-subject or verb-object interpretations: a good cook is a cook who cooks well whereas good soup is soup that tastes good or soup that is good to eat.', '#AUTHOR_TAG avoids enumerating the various senses for adjectives like fast by exploiting the semantics of the nouns they modify .', 'Pustejovsky treats nouns as having a qualia structure as part of their lexical entries, which among other things, specifies possible events associated with the entity.']",0
"['We have presented an ensemble approach to word sense disambiguation ( #AUTHOR_TAG ) where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .']",0
['See ( #AUTHOR_TAG ) for a discussion .'],0
['Other definitions of predicates may be found in ( #AUTHOR_TAG ) .'],0
"['This appeared to solve the problem , and the results presented later for the average degree of generalisation do not show an over-generalisation compared with those given in #AUTHOR_TAG .']",1
['The task we used to compare different generalisation techniques is similar to that used by #AUTHOR_TAG and Rooth et al. ( 1999 ) .'],1
"['The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important ( #AUTHOR_TAG ) .']",4
"['However , #AUTHOR_TAG claims that the log-likelihood chisquared statistic ( G2 ) is more appropriate for corpus-based NLP .']",4
['The task we used to compare different generalisation techniques is similar to that used by Pereira et al. ( 1993 ) and #AUTHOR_TAG .'],1
"['The X2 statistic is performing at least as well as G2 , throwing doubt on the claim by #AUTHOR_TAG that the G2 statistic is better suited for use in corpus-based NLP .']",1
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program ( #AUTHOR_TAG ; Harkema , 2000 ; Niyogi , 2001 ) .""]",1
"['These observations and this line of reasoning has not escaped the attention of theoretical linguists : #AUTHOR_TAG propose that argument structure is , in fact , encoded syntactically .', 'They describe a cascading verb phrase analysis with multiple phonetically empty verbal projections corresponding to concepts such as inchoativity and agentivity.', 'This present framework builds on the work of Hale and Keyser, but in addition to advancing a more refined theory of verbal argument structure, I also describe a computational implementation.']",0
"['The light verb v DO licenses an atelic non-inchoative event, and is compatible with verbal roots expressing activity.', 'It projects a functional head , voice ( #AUTHOR_TAG ) , whose specifier is the external argument .', 'Lexical entries in the system are minimally specified, each consisting of a phonetic form, a list of relevant features, and semantics in the form of a λ expression.']",0
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program ( Stabler , 1997 ; #AUTHOR_TAG ; Niyogi , 2001 ) .""]",1
"['In this paper , I present a computational implementation of Distributed Morphology ( #AUTHOR_TAG ) , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .', 'This framework leads to finer-grained semantics capable of better capturing linguistic generalizations.']",5
"[""This approach has its roots in Fillmore 's Case Grammar ( 1968 ) , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet ( Baker et al. , 1998 ) and PropBank ( #AUTHOR_TAG ) .""]",0
"['In ( #AUTHOR_TAG ) , I present evidence from Mandarin Chinese that this analysis is on the right track .', 'The rest of this paper, however, will be concerned with the computational implementation of my theoretical framework.']",2
"['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques ( Collins , 1997 ; #AUTHOR_TAG ) , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity ( Dowty , 1979 ; Jackendoff , 1983 ; #AUTHOR_TAGb ; Rappaport Hovav and Levin , 1998 ) .']",0
"['With a minimal set of features and a small number of lexical entries , Niyogi ( 2001 ) has successfully modeled many of the argument alternations described by Levin ( 1993 ) using a #AUTHOR_TAG style analysis .', 'I believe that with a suitable lexicon (either hand crafted or automatically induced), my framework can be elaborated into a system whose performance is comparable to that of current statistical parsers, but with the added advantage of simultaneously providing a richer lexical semantic representation of the input sentence than flat predicate argument structures based on semantic roles.']",0
"[""Activities know run believe walk Accomplishments Achievements paint a picture recognize make a chair find Under Vendler's classification, activities and states both depict situations that are inherently temporally unbounded (atelic); states denote static situations, whereas activities denote on-going dynamic situations."", 'Accomplishments and achievements both express a change of state, and hence are temporally bounded (telic); achievements are punctual, whereas accomplishments extend over a period of time.', '#AUTHOR_TAG observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .']",0
"['With a minimal set of features and a small number of lexical entries , Niyogi ( 2001 ) has successfully modeled many of the argument alternations described by #AUTHOR_TAG using a Hale and Keyser ( 1993 ) style analysis .', 'I believe that with a suitable lexicon (either hand crafted or automatically induced), my framework can be elaborated into a system whose performance is comparable to that of current statistical parsers, but with the added advantage of simultaneously providing a richer lexical semantic representation of the input sentence than flat predicate argument structures based on semantic roles.']",0
"[""This framework , where the `` semantic load '' is spread more evenly throughout the lexicon to lexical categories not typically thought to bear semantic content , is essentially the model advocated by #AUTHOR_TAGa ) , among many others .""]",0
"['My theory of verbal argument structure can be imple- mented in a unified morpho-syntactic parsing model that interleaves syntactic and semantic parsing.', ""The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program ( Stabler , 1997 ; Harkema , 2000 ; #AUTHOR_TAG ) .""]",1
"['Following the non-lexicalist tradition, these primitives are argued to occupy functional projections in the syntactic structure, as so-called light verbs.', 'Here , I adopt the model proposed by #AUTHOR_TAG and decompose lexical verbs into verbalizing heads and verbal roots .', 'Verbalizing heads introduce relevant eventive interpretations in the syntax, and correspond to (assumed) universal primitives of the human cognitive system.']",5
"[""This approach has its roots in Fillmore 's Case Grammar ( 1968 ) , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet ( #AUTHOR_TAG ) and PropBank ( Kingsbury et al. , 2002 ) .""]",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity ( #AUTHOR_TAG ; Jackendoff , 1983 ; Pustejovsky , 1991b ; Rappaport Hovav and Levin , 1998 ) .']",0
"['The understanding of natural language text includes not only analysis of syntactic structure, but also of semantic content.', 'Due to advances in statistical syntactic parsing techniques ( #AUTHOR_TAG ; Charniak , 2001 ) , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .']",0
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity ( Dowty , 1979 ; #AUTHOR_TAG ; Pustejovsky , 1991b ; Rappaport Hovav and Levin , 1998 ) .']",0
['#AUTHOR_TAG has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .'],2
"['The typical solution to the redundancy problem is to group verbs according to their argument realization patterns ( #AUTHOR_TAG ) , possibly arranged in an inheritance hierarchy .']",1
"['There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity ( Dowty , 1979 ; Jackendoff , 1983 ; Pustejovsky , 1991b ; Rappaport #AUTHOR_TAG ) .']",0
"['Dowty breaks the event described by (2) into two subevents, the activity of sweeping the floor and its result, the state of the floor being clean.', ""A more recent approach , advocated by Rappaport Hovav and Levin ( 1998 ) , describes a basic set of event templates corresponding to Vendler 's event classes ( #AUTHOR_TAG ) : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )""]",0
"['After embedding the secret message, modified deep structure forms are converted into the surface structure format via language generation tools.', '#AUTHOR_TAGb ) and Topkara et al. ( 2006a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .']",0
"['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by #AUTHOR_TAG .']",0
"['Liu et al. ( 2005 ) , Meral et al. ( 2007 ) , Murphy ( 2001 ) , #AUTHOR_TAG and Topkara et al. ( 2006a ) all belong to the syntactic transformation category .']",0
"['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by Chapman and Davida (1997).', 'Later works , such as #AUTHOR_TAGa ) , Bolshakov ( 2004 ) , Taskiran et al. ( 2006 ) and Topkara et al. ( 2006b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .']",0
"['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'Later works , such as Atallah et al. ( 2001a ) , Bolshakov ( 2004 ) , Taskiran et al. ( 2006 ) and #AUTHOR_TAGb ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .']",0
"['Liu et al. ( 2005 ) , Meral et al. ( 2007 ) , #AUTHOR_TAG , Murphy and Vogel ( 2007 ) and Topkara et al. ( 2006a ) all belong to the syntactic transformation category .']",0
"['The simplest and most straightforward subliminal modification of text is to substitute selected words with their synonyms.', 'The first lexical substitution method was proposed by Chapman and Davida (1997).', 'Later works , such as Atallah et al. ( 2001a ) , #AUTHOR_TAG , Taskiran et al. ( 2006 ) and Topkara et al. ( 2006b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .']",0
"['The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation ( #AUTHOR_TAG ) , and contains English n-grams and their observed frequency counts , for counts of at least 40 .', 'The striking feature of the n-gram corpus is the large number of n-grams and the size of the counts, since the counts were extracted from over 1 trillion word tokens of English text on publicly accessible Web pages collected in January 2006.']",0
"['Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer ( #AUTHOR_TAG ) .']",0
"['Liu et al. ( 2005 ) , Meral et al. ( 2007 ) , Murphy ( 2001 ) , Murphy and Vogel ( 2007 ) and #AUTHOR_TAGa ) all belong to the syntactic transformation category .']",0
"['The semantic transformation method is the most sophisticated approach for linguistic steganography, and perhaps impractical given the current state-ofthe-art for NLP technology.', '#AUTHOR_TAG aimed to embed information by exploiting the linguistic phenomenon of presupposition , with the idea that some presuppositional information can be removed without changing the meaning of a sentence .']",0
"['For example, year end is an unsuitable paraphrase for the end of this year in the sentence The chart compares the gold price at the end of last year with the end of this year.', '#AUTHOR_TAG also note that the applicability of paraphrases is strongly influenced by context .']",0
"['The paraphrase dictionary that we use was generated for us by Chris Callison-Burch , using the technique described in #AUTHOR_TAG , which exploits a parallel corpus and methods developed for statistical machine translation .']",5
"['In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences.', '#AUTHOR_TAG , Meral et al. ( 2007 ) , Murphy ( 2001 ) , Murphy and Vogel ( 2007 ) and Topkara et al. ( 2006a ) all belong to the syntactic transformation category .']",0
"['Section 2 describes some of the previous transformations used in Linguistic Steganography.', 'Note that we are concerned with transformations which are linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words ( #AUTHOR_TAG ) .']",1
"['Our proposed method is based on the automatically acquired paraphrase dictionary described in #AUTHOR_TAG , in which the application of paraphrases from the dictionary encodes secret bits .']",5
"['However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media ( #AUTHOR_TAG ) .', 'The likely reason is that it is easier to make changes to images and other nonlinguistic media which are undetectable by an observer.']",0
['We use the #AUTHOR_TAG CCG parser to analyse the sentence before and after paraphrasing .'],5
"['In other words, instead of performing lexical substitution directly to the text, the secret message is embedded into syntactic parse trees of the sentences.', 'Liu et al. ( 2005 ) , #AUTHOR_TAG , Murphy ( 2001 ) , Murphy and Vogel ( 2007 ) and Topkara et al. ( 2006a ) all belong to the syntactic transformation category .']",0
"['In our previous work ( #AUTHOR_TAG ; Salloum and Habash , 2012 ) , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .', 'We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system.']",1
"['We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data.', 'Our system uses a standard phrase-based architecture.', 'The parallel corpus is word-aligned using GIZA + + ( #AUTHOR_TAG ) .']",5
['This is a similar conclusion to our previous work in #AUTHOR_TAG .'],1
['We use the open-source Moses toolkit ( #AUTHOR_TAG ) to build a phrase-based SMT system trained on mostly MSA data ( 64M words on the Arabic side ) obtained from several LDC corpora including some limited DA data .'],5
"['In humans, speech production and speech processing are done incrementally, using contextual information from the earliest moments of processing (see, e.g., Tanenhaus et al. 1995).', 'Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are Core & Schubert , 1999 ; #AUTHOR_TAG ; Nakatani & Hirschberg , 1994 ; Shriberg , Bear , & Dowding , 1992 ) .']",0
"['Similar to our previous work ( Chan and Ng , 2005b ) , we used the supervised WSD approach described in ( #AUTHOR_TAG ) for our experiments , using the naive Bayes algorithm as our classifier .', 'Knowledge sources used include partsof-speech, surrounding words, and local collocations.']",5
"['Shi and Wang (2007) also chunked the sentences before doing 10-fold cross validation, but used an uneven split.', 'We chose to follow #AUTHOR_TAG and split the sentences evenly to facilitate further comparison .']",5
"['We built a two-stage baseline system , using the perceptron segmentation model from our previous work ( #AUTHOR_TAG ) and the perceptron POS tagging model from Collins ( 2002 ) .']",2
"['We present an extension of the hierarchical Dirichlet process (HDP) model which is able to represent each observable object (i.e., event mention) by a finite number of feature types L.', 'Our HDP extension is also inspired from the Bayesian model proposed by #AUTHOR_TAG .', 'However, their model is strictly customized for entity coreference resolution, and therefore, extending it to include additional features for each observable object is a challenging task (Ng, 2008; Poon and Domingos, 2008).']",4
"['These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work ( He et al. , 2008 ; Gimpel and Smith , 2008 ; #AUTHOR_TAG ; Chiang et al. , 2009 ; Setiawan et al. , 2009 ; Shen et al. , 2009 ; Xiong et al. , 2009 ) : 1 .']",4
"['These features are carefully designed to reduce the data sparseness problem and some of them are inspired by previous work ( He et al. , 2008 ; #AUTHOR_TAG ; Marton and Resnik , 2008 ; Chiang et al. , 2009 ; Setiawan et al. , 2009 ; Shen et al. , 2009 ; Xiong et al. , 2009 ) : 1 .']",4
"['More recently , an alignment selection approach was proposed in ( #AUTHOR_TAG ) , which computes confidence scores for each link and prunes the links from multiple sets of alignments using a hand-picked threshold .', 'The alignments used in that work were generated from different aligners (HMM, block model, and maximum entropy model).']",1
"['The first is simply the phrase type, such as NP, PP, of current chunk.', 'The column CHUNK 1 illustrates this kind of chunk type definition.', 'The second is more complicated.', ""Inspired by ( #AUTHOR_TAG ) , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent ."", 'For example, an NP immediately dominated by a S, will be substituted by NPˆS.']",4
"['The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach ( #AUTHOR_TAG ) .', 'Hasan and Ney ( 2009) introduced a second word to trigger the target word without considering any linguistic information.']",4
"['Previous sentiment-analysis work in different domains has considered inter-document similarity (Agarwal and Bhattacharyya, 2005; Pang and Lee, 2005; Goldberg and Zhu, 2006) or explicit inter-document references in the form of hyperlinks ( #AUTHOR_TAG ) .']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005;Cardie et al., 2006;Kwon et al., 2006).', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) ( #AUTHOR_TAG ; Efron , 2004 ; Mullen and Malouf , 2006 ) .']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; #AUTHOR_TAG ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005;Cardie et al., 2006;Kwon et al., 2006).', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) ( Laver et al. , 2003 ; #AUTHOR_TAG ; Mullen and Malouf , 2006 ) .']",0
"['Notable early papers on graph-based semisupervised learning include Blum and Chawla ( 2001 ) , Bansal et al. ( 2002 ) , Kondor and Lafferty ( 2002 ) , and #AUTHOR_TAG .']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( #AUTHOR_TAG ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['More sophisticated approaches have been proposed ( #AUTHOR_TAG ) , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments ( Galley et al. , 2004 ) .']",0
"['More sophisticated approaches have been proposed (Hillard et al., 2003), including an extension that, in an interesting reversal of our problem, makes use of sentimentpolarity indicators within speech segments (Galley et al., 2004).', 'Also relevant is work on the general problems of dialog-act tagging ( Stolcke et al. , 2000 ) , citation analysis ( Lehnert et al. , 1990 ) , and computational rhetorical analysis ( #AUTHOR_TAG ; Teufel and Moens , 2002 ) .']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit ( Shulman et al. , 2005 ; Cardie et al. , 2006 ; #AUTHOR_TAG ) .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) (Laver et al., 2003;Efron, 2004;Mullen and Malouf, 2006).']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document in- dependently. A few others incorporate various measures of inter-document similarity between the texts to be labeled (Agarwal and Bhattacharyya, 2005; Pang and Lee, 2005; Goldberg and Zhu, 2006).', 'For example, we may find textual4 evidence of a high likelihood of agreement be-tween two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings (see Mullen and Malouf (2006) but cfXXX #AUTHOR_TAG.']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005;Cardie et al., 2006;Kwon et al., 2006).', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) ( Laver et al. , 2003 ; Efron , 2004 ; #AUTHOR_TAG ) .']",0
"['In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.5', 'Fol- lowing standard practice in sentiment analysis ( #AUTHOR_TAG ) , the input to SVMlight con- sisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.']",5
"['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text ( Yang and Callan , 2005 ; #AUTHOR_TAG ) .']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; #AUTHOR_TAG ) .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis, an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language (early work includes Wiebe and Rapaport (1988), Hearst (1992), Sack (1994), and Wiebe (1994); see Esuli (2006) for an active bibliography).', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents ( Das and Chen , 2001 ; Pang et al. , 2002 ; #AUTHOR_TAG ; Dave et al. , 2003 ) .""]",0
"['Previous sentiment-analysis work in different domains has considered inter-document similarity ( #AUTHOR_TAG ; Pang and Lee , 2005 ; Goldberg and Zhu , 2006 ) or explicit inter-document references in the form of hyper- links (Agrawal et al., 2003).']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; #AUTHOR_TAG ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .', 'It would be inter- esting to investigate the application of such meth- ods to our problem.', 'However, we also believe that our approach has important advantages, in- cluding conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work ( #AUTHOR_TAG ; Munson et al. , 2005 ) .']",3
"['More sophisticated approaches have been proposed (Hillard et al., 2003), including an extension that, in an interesting reversal of our problem, makes use of sentimentpolarity indicators within speech segments (Galley et al., 2004).', 'Also relevant is work on the general problems of dialog-act tagging ( Stolcke et al. , 2000 ) , citation analysis ( #AUTHOR_TAG ) , and computational rhetorical analysis ( Marcu , 2000 ; Teufel and Moens , 2002 ) .']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled ( Agarwal and Bhattacharyya , 2005 ; #AUTHOR_TAG ; Goldberg and Zhu , 2006 ) .']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled ( #AUTHOR_TAG ; Pang and Lee , 2005 ; Goldberg and Zhu , 2006 ) .']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'A few others incorporate various measures of inter-document similarity between the texts to be labeled ( Agarwal and Bhattacharyya , 2005 ; Pang and Lee , 2005 ; #AUTHOR_TAG ) .']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; #AUTHOR_TAG ; McCallum and Wellner , 2004 ) .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['More sophisticated approaches have been proposed ( Hillard et al. , 2003 ) , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments ( #AUTHOR_TAG ) .']",0
"['As has been previously observed and exploited in the NLP literature ( #AUTHOR_TAG ; Agarwal and Bhattacharyya , 2005 ; Barzilay and Lapata , 2005 ) , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .']",1
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; #AUTHOR_TAG ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"[""In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' ( #AUTHOR_TAG ) ."", 'Additionally, much media attention has been focused recently on the potential impact that Internet sites may have on politics 2 , or at least on political journalism 3 .', 'Regardless of whether one views such claims as clear-sighted prophecy or mere hype, it is obviously important to help people understand and analyze politically oriented text, given the importance of enabling informed participation in the political process.']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis, an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language (early work includes Wiebe and Rapaport (1988), Hearst (1992), Sack (1994), and Wiebe (1994); see Esuli (2006) for an active bibliography).', 'In particular, since we treat each individual speech within a debate as a single ""document"", we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents ( #AUTHOR_TAG ; Pang et al. , 2002 ; Turney , 2002 ; Dave et al. , 2003 ) .']",0
"['Notable early papers on graph-based semisupervised learning include Blum and Chawla (2001), Bansal et al. (2002), Kondor andLafferty (2002), andJoachims (2003).', '#AUTHOR_TAG maintains a survey of this area .']",0
"['Previous sentiment-analysis work in different domains has considered inter-document similarity ( Agarwal and Bhattacharyya , 2005 ; #AUTHOR_TAG ; Goldberg and Zhu , 2006 ) or explicit inter-document references in the form of hyperlinks (Agrawal et al., 2003).']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes Wiebe and Rapaport ( 1988 ) , Hearst ( 1992 ) , #AUTHOR_TAG , and Wiebe ( 1994 ) ; see Esuli ( 2006 ) for an active bibliography ) .']",0
"['As has been previously observed and exploited in the NLP literature ( Pang and Lee , 2004 ; #AUTHOR_TAG ; Barzilay and Lapata , 2005 ) , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .']",1
"['The support/oppose classification problem can be approached through the use of standard classifiers such as support vector machines (SVMs), which consider each text unit in isolation.', 'Our classification framework , directly inspired by #AUTHOR_TAG , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .']",5
"['Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text ( #AUTHOR_TAG ; Purpura and Hillard , 2006 ) .']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes Wiebe and Rapaport ( 1988 ) , Hearst ( 1992 ) , Sack ( 1994 ) , and #AUTHOR_TAG ; see Esuli ( 2006 ) for an active bibliography ) .']",0
"['Notable early papers on graph-based semisupervised learning include #AUTHOR_TAG , Bansal et al. ( 2002 ) , Kondor and Lafferty ( 2002 ) , and Joachims ( 2003 ) .']",0
"['We currently do not have an efficient means to encode disagreement information as hard constraints; we plan to investigate incorporating such information in future work.', 'Relationships between the unlabeled items #AUTHOR_TAG consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .']",0
"[""Evaluative and persuasive documents, such as a politician's speech regarding a bill or a blogger's commentary on a legislative proposal, form a particularly interesting type of politically oriented text."", 'People are much more likely to consult such evaluative statements than the actual text of a bill or law under discussion , given the dense nature of legislative language and the fact that ( U.S. ) bills often reach several hundred pages in length ( #AUTHOR_TAG ) .']",0
"['As has been previously observed and exploited in the NLP literature ( Pang and Lee , 2004 ; Agarwal and Bhattacharyya , 2005 ; #AUTHOR_TAG ) , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .']",1
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis, an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language (early work includes Wiebe and Rapaport (1988), Hearst (1992), Sack (1994), and Wiebe (1994); see Esuli (2006) for an active bibliography).', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents ( Das and Chen , 2001 ; #AUTHOR_TAG ; Turney , 2002 ; Dave et al. , 2003 ) .""]",0
"['Notable early papers on graph-based semisupervised learning include Blum and Chawla ( 2001 ) , #AUTHOR_TAG , Kondor and Lafferty ( 2002 ) , and Joachims ( 2003 ) .']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis, an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language (early work includes Wiebe and Rapaport (1988), Hearst (1992), Sack (1994), and Wiebe (1994); see Esuli (2006) for an active bibliography).', ""In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents ( Das and Chen , 2001 ; Pang et al. , 2002 ; Turney , 2002 ; #AUTHOR_TAG ) .""]",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit ( Shulman et al. , 2005 ; #AUTHOR_TAG ; Kwon et al. , 2006 ) .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) (Laver et al., 2003;Efron, 2004;Mullen and Malouf, 2006).']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes #AUTHOR_TAG , Hearst ( 1992 ) , Sack ( 1994 ) , and Wiebe ( 1994 ) ; see Esuli ( 2006 ) for an active bibliography ) .']",0
"['Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; #AUTHOR_TAG ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .', 'It would be interesting to investigate the application of such methods to our problem.', 'However, we also believe that our approach has important advantages, including conceptual simplicity and the fact that it is based on an underlying optimization problem that is provably and in practice easy to solve.']",0
"['Notable early papers on graph-based semisupervised learning include Blum and Chawla ( 2001 ) , Bansal et al. ( 2002 ) , #AUTHOR_TAG , and Joachims ( 2003 ) .']",0
"['More sophisticated approaches have been proposed (Hillard et al., 2003), including an extension that, in an interesting reversal of our problem, makes use of sentimentpolarity indicators within speech segments (Galley et al., 2004).', 'Also relevant is work on the general problems of dialog-act tagging ( Stolcke et al. , 2000 ) , citation analysis ( Lehnert et al. , 1990 ) , and computational rhetorical analysis ( Marcu , 2000 ; #AUTHOR_TAG ) .']",0
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005;Cardie et al., 2006;Kwon et al., 2006).', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) (Laver et al., 2003;Efron, 2004;Mullen and Malouf, 2006).', 'An exception is #AUTHOR_TAG , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .']",0
"['SVMlight is available at svmlight.joachims.org.', 'Default parameters were used , although experimentation with different parameter settings is an important direction for future work ( Daelemans and Hoste , 2002 ; #AUTHOR_TAG ) .']",3
"['Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking , allowing the automatic analysis of the opinions that people submit ( #AUTHOR_TAG ; Cardie et al. , 2006 ; Kwon et al. , 2006 ) .', 'There has also been work focused upon determining the political leaning (e.g., ""liberal"" vs. ""conservative"") of a document or author, where most previously-proposed methods make no direct use of relationships between the documents to be classified (the ""unlabeled"" texts) (Laver et al., 2003;Efron, 2004;Mullen and Malouf, 2006).']",0
"['Most sentiment-polarity classifiers proposed in the recent literature categorize each document independently.', 'For example, we may find textual4 evidence of a high likelihood of agreement between two speakers, such as explicit assertions (�I second that!�) or quotation of messages in emails or postings ( see #AUTHOR_TAG but cfXXX Agrawal et al. ( 2003 ) ) .']",0
"['Previous sentiment-analysis work in different domains has considered inter-document similarity ( Agarwal and Bhattacharyya , 2005 ; Pang and Lee , 2005 ; #AUTHOR_TAG ) or explicit inter-document references in the form of hyperlinks (Agrawal et al., 2003).']",0
"['Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes Wiebe and Rapaport ( 1988 ) , #AUTHOR_TAG , Sack ( 1994 ) , and Wiebe ( 1994 ) ; see Esuli ( 2006 ) for an active bibliography ) .']",0
['Our plan is to implement a windowed or moving-average version of BLEU as in ( #AUTHOR_TAG ) .'],3
"['The flexible architecture we have presented enables interesting future research : ( i ) a straightforward improvement is the use of lexical similarity to reduce data sparseness , e.g. ( #AUTHOR_TAG ; Basili et al. , 2006 ; Bloehdorn et al. , 2006 ) .']",0
['This contrasts with the findings described in #AUTHOR_TAG where significant improvements could be achieved by increasing the number of source languages .'],1
"['So far, we always computed translations to single source words.', 'As suggested in #AUTHOR_TAG this can be done by looking up the ranks of each of the four given words ( i.e. the words occurring in a particular word equation ) within the association vector of a translation candidate , and by multiplying these ranks .']",4
"['Whereas #AUTHOR_TAG dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .', 'We were able to shed some light on criteria influencing performance, such as the selection of text type and the direction of a language pair.']",1
"['The current work has focussed on high-level mapping rules which can be used both for generation from databases and knowledge representations and also for generation from text.', 'In future work, we will focus on mapping text (in monologue form) to dialogue.', 'For this we need to combine the highlevel rules with rules for paraphrasing the text in the monologue with text for the dialogue acts that express the same information in dialogue form.', 'For automatically extracting these surface level mappings we will draw on the approach to learning paraphrases from a corpus that is described in #AUTHOR_TAG .']",3
"['It may be that our notion of distance to lexical resource entries is too naive.', 'A possible future direction would be to compare the query string to retrieved results using a method similar to that of #AUTHOR_TAG .', 'This would enable us to retain the advantage of fast approximate string matching, thus being able to utilise larger lexical resources than if we were to calculate sophisticated alignments for each lexical entry.']",3
"['The article classifier is a discriminative model that draws on the state-of-the-art approach described in #AUTHOR_TAG .', 'The model makes use of the Averaged Perceptron (AP) algorithm (Freund and Schapire, 1996) and is trained on the training data of the shared task with rich features.', 'The article module uses the POS and chunker output to generate some of its features and candidates (likely contexts for missing articles).']",5
['The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks ( #AUTHOR_TAG ) .'],4
"['Another line of research that is correlated with ours is recognition of agreement/disagreement ( Misra and Walker , 2013 ; Yin et al. , 2012 ; Abbott et al. , 2011 ; Andreas et al. , 2012 ; #AUTHOR_TAG ; Hillard et al. , 2003 ) and classification of stances ( Walker et al. , 2012 ; Somasundaran and Wiebe , 2010 ) in online forums .', 'For future work, we can utilize textual features (contextual, dependency, discourse markers), relevant multiword expressions and topic modeling (Mukherjee and Liu, 2013), and thread structure (Murakami and Raymond, 2010;Agrawal et al., 2003) to improve the Agree/Disagree classification accuracy.']",1
"['The MI approach discovers the words that are highly associated with Agree/Disagree categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement ( Galley et al. , 2004 ; #AUTHOR_TAG ) .']",4
"['Another line of research that is correlated with ours is recognition of agreement/disagreement ( #AUTHOR_TAG ; Yin et al. , 2012 ; Abbott et al. , 2011 ; Andreas et al. , 2012 ; Galley et al. , 2004 ; Hillard et al. , 2003 ) and classification of stances ( Walker et al. , 2012 ; Somasundaran and Wiebe , 2010 ) in online forums .', 'For future work, we can utilize textual features (contextual, dependency, discourse markers), relevant multiword expressions and topic modeling (Mukherjee and Liu, 2013), and thread structure (Murakami and Raymond, 2010;Agrawal et al., 2003) to improve the Agree/Disagree classification accuracy.']",1
"['The MI approach discovers the words that are highly associated with Agree/Disagree categories and these words turn to be useful features for classification.', 'In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement ( #AUTHOR_TAG ; Misra and Walker , 2013 ) .']",4
